<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"
          integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">

    <title>Glimpse - CVPR2019</title>
</head>

<body>

<header class="container">
    <h1>Glimpse - CVPR2019</h1>
    <p>Last Update: February 24, 2023 - 05:12:43</p>
</header>

<main>
    <section class="container">
        <div class="row">
            

                <div class="col">
                    <dl>
                        
                            <dt>
                                <a>COLT</a>
                            </dt>
                            <dd>
                                
                                    <a href="COLT2016.html">16</a>
                                
                                    <a href="COLT2017.html">17</a>
                                
                                    <a href="COLT2018.html">18</a>
                                
                                    <a href="COLT2019.html">19</a>
                                
                                    <a href="COLT2020.html">20</a>
                                
                                    <a href="COLT2021.html">21</a>
                                
                                    <a href="COLT2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ICLR</a>
                            </dt>
                            <dd>
                                
                                    <a href="ICLR2016.html">16</a>
                                
                                    <a href="ICLR2017.html">17</a>
                                
                                    <a href="ICLR2018.html">18</a>
                                
                                    <a href="ICLR2019.html">19</a>
                                
                                    <a href="ICLR2020.html">20</a>
                                
                                    <a href="ICLR2021.html">21</a>
                                
                                    <a href="ICLR2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ICML</a>
                            </dt>
                            <dd>
                                
                                    <a href="ICML2016.html">16</a>
                                
                                    <a href="ICML2017.html">17</a>
                                
                                    <a href="ICML2018.html">18</a>
                                
                                    <a href="ICML2019.html">19</a>
                                
                                    <a href="ICML2020.html">20</a>
                                
                                    <a href="ICML2021.html">21</a>
                                
                                    <a href="ICML2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>NeurIPS</a>
                            </dt>
                            <dd>
                                
                                    <a href="NeurIPS2016.html">16</a>
                                
                                    <a href="NeurIPS2017.html">17</a>
                                
                                    <a href="NeurIPS2018.html">18</a>
                                
                                    <a href="NeurIPS2019.html">19</a>
                                
                                    <a href="NeurIPS2020.html">20</a>
                                
                                    <a href="NeurIPS2021.html">21</a>
                                
                                    <a href="NeurIPS2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>IJCAI</a>
                            </dt>
                            <dd>
                                
                                    <a href="IJCAI2017.html">17</a>
                                
                                    <a href="IJCAI2018.html">18</a>
                                
                                    <a href="IJCAI2019.html">19</a>
                                
                                    <a href="IJCAI2020.html">20</a>
                                
                                    <a href="IJCAI2021.html">21</a>
                                
                                    <a href="IJCAI2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>AAAI</a>
                            </dt>
                            <dd>
                                
                                    <a href="AAAI2016.html">16</a>
                                
                                    <a href="AAAI2017.html">17</a>
                                
                                    <a href="AAAI2018.html">18</a>
                                
                                    <a href="AAAI2019.html">19</a>
                                
                                    <a href="AAAI2020.html">20</a>
                                
                                    <a href="AAAI2021.html">21</a>
                                
                                    <a href="AAAI2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>UAI</a>
                            </dt>
                            <dd>
                                
                                    <a href="UAI2019.html">19</a>
                                
                                    <a href="UAI2020.html">20</a>
                                
                                    <a href="UAI2021.html">21</a>
                                
                                    <a href="UAI2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>AISTATS</a>
                            </dt>
                            <dd>
                                
                                    <a href="AISTATS2016.html">16</a>
                                
                                    <a href="AISTATS2017.html">17</a>
                                
                                    <a href="AISTATS2018.html">18</a>
                                
                                    <a href="AISTATS2019.html">19</a>
                                
                                    <a href="AISTATS2020.html">20</a>
                                
                                    <a href="AISTATS2021.html">21</a>
                                
                                    <a href="AISTATS2022.html">22</a>
                                
                            </dd>
                        
                    </dl>
                </div>

            

                <div class="col">
                    <dl>
                        
                            <dt>
                                <a>TACL</a>
                            </dt>
                            <dd>
                                
                                    <a href="TACL2016.html">16</a>
                                
                                    <a href="TACL2017.html">17</a>
                                
                                    <a href="TACL2018.html">18</a>
                                
                                    <a href="TACL2019.html">19</a>
                                
                                    <a href="TACL2020.html">20</a>
                                
                                    <a href="TACL2021.html">21</a>
                                
                                    <a href="TACL2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ACL</a>
                            </dt>
                            <dd>
                                
                                    <a href="ACL2016.html">16</a>
                                
                                    <a href="ACL2017.html">17</a>
                                
                                    <a href="ACL2018.html">18</a>
                                
                                    <a href="ACL2019.html">19</a>
                                
                                    <a href="ACL2020.html">20</a>
                                
                                    <a href="ACL2021.html">21</a>
                                
                                    <a href="ACL2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>EMNLP</a>
                            </dt>
                            <dd>
                                
                                    <a href="EMNLP2016.html">16</a>
                                
                                    <a href="EMNLP2017.html">17</a>
                                
                                    <a href="EMNLP2018.html">18</a>
                                
                                    <a href="EMNLP2019.html">19</a>
                                
                                    <a href="EMNLP2020.html">20</a>
                                
                                    <a href="EMNLP2021.html">21</a>
                                
                                    <a href="EMNLP2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>NAACL</a>
                            </dt>
                            <dd>
                                
                                    <a href="NAACL2016.html">16</a>
                                
                                    <a href="NAACL2018.html">18</a>
                                
                                    <a href="NAACL2019.html">19</a>
                                
                                    <a href="NAACL2021.html">21</a>
                                
                                    <a href="NAACL2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>COLING</a>
                            </dt>
                            <dd>
                                
                                    <a href="COLING2016.html">16</a>
                                
                                    <a href="COLING2018.html">18</a>
                                
                                    <a href="COLING2020.html">20</a>
                                
                                    <a href="COLING2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>EACL</a>
                            </dt>
                            <dd>
                                
                                    <a href="EACL2017.html">17</a>
                                
                                    <a href="EACL2021.html">21</a>
                                
                            </dd>
                        
                            <dt>
                                <a>AACL</a>
                            </dt>
                            <dd>
                                
                                    <a href="AACL2020.html">20</a>
                                
                                    <a href="AACL2022.html">22</a>
                                
                            </dd>
                        
                    </dl>
                </div>

            

                <div class="col">
                    <dl>
                        
                            <dt>
                                <a>CVPR</a>
                            </dt>
                            <dd>
                                
                                    <a href="CVPR2016.html">16</a>
                                
                                    <a href="CVPR2017.html">17</a>
                                
                                    <a href="CVPR2018.html">18</a>
                                
                                    <a href="CVPR2019.html">19</a>
                                
                                    <a href="CVPR2020.html">20</a>
                                
                                    <a href="CVPR2021.html">21</a>
                                
                                    <a href="CVPR2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ICCV</a>
                            </dt>
                            <dd>
                                
                                    <a href="ICCV2017.html">17</a>
                                
                                    <a href="ICCV2019.html">19</a>
                                
                                    <a href="ICCV2021.html">21</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ECCV</a>
                            </dt>
                            <dd>
                                
                                    <a href="ECCV2018.html">18</a>
                                
                                    <a href="ECCV2020.html">20</a>
                                
                                    <a href="ECCV2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ACCV</a>
                            </dt>
                            <dd>
                                
                                    <a href="ACCV2020.html">20</a>
                                
                                    <a href="ACCV2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>WACV</a>
                            </dt>
                            <dd>
                                
                                    <a href="WACV2020.html">20</a>
                                
                                    <a href="WACV2021.html">21</a>
                                
                                    <a href="WACV2022.html">22</a>
                                
                                    <a href="WACV2023.html">23</a>
                                
                            </dd>
                        
                    </dl>
                </div>

            
        </div>
    </section>


    <section class="container">
        <h2>1908 Papers (0 missing)</h2>

        
            <div class="row progress">
                <div class="progress-bar progress-bar-striped progress-bar-animated" role="progressbar"
                     aria-valuenow="16.247379454926623" aria-valuemin="0" aria-valuemax="100"
                     style="width: 16.247379454926623%"></div>
            </div>
        

        <div class="row">
            <table class="table table-hover">
                <thead>
                <tr>
                    <th scope="col" class="align-middle text-right">Citations</th>
                    <th scope="col" class="align-middle text-center">Volume</th>
                    <th scope="col" class="align-middle text-left">Title</th>
                </tr>
                </thead>
                <tbody>
                
                    <tr id="ceb2ebef0b41e31c1a21b28c2734123900c005e2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ceb2ebef0b41e31c1a21b28c2734123900c005e2">4487</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Karras_A_Style-Based_Generator_Architecture_for_Generative_Adversarial_Networks_CVPR_2019_paper.html">A Style-Based Generator Architecture for Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="d4f100ca5edfe53b562f1d170b2c48939bab0e27">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d4f100ca5edfe53b562f1d170b2c48939bab0e27">2900</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Deng_ArcFace_Additive_Angular_Margin_Loss_for_Deep_Face_Recognition_CVPR_2019_paper.html">ArcFace: Additive Angular Margin Loss for Deep Face Recognition</a></th>
                    </tr>
                
                    <tr id="ad655c25e052fa4eeed53421344aca6f239c4c9d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ad655c25e052fa4eeed53421344aca6f239c4c9d">2478</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fu_Dual_Attention_Network_for_Scene_Segmentation_CVPR_2019_paper.html">Dual Attention Network for Scene Segmentation</a></th>
                    </tr>
                
                    <tr id="693c97ecedb0a84539b7162c95e89fa3cd84ca73">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/693c97ecedb0a84539b7162c95e89fa3cd84ca73">2026</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tan_MnasNet_Platform-Aware_Neural_Architecture_Search_for_Mobile_CVPR_2019_paper.html">MnasNet: Platform-Aware Neural Architecture Search for Mobile</a></th>
                    </tr>
                
                    <tr id="6303bac53abd725c3b458190a6abe389a4a1e72d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6303bac53abd725c3b458190a6abe389a4a1e72d">1683</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Deep_High-Resolution_Representation_Learning_for_Human_Pose_Estimation_CVPR_2019_paper.html">Deep High-Resolution Representation Learning for Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="889c81b4d7b7ed43a3f69f880ea60b0572e02e27">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/889c81b4d7b7ed43a3f69f880ea60b0572e02e27">1653</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Rezatofighi_Generalized_Intersection_Over_Union_A_Metric_and_a_Loss_for_CVPR_2019_paper.html">Generalized Intersection Over Union: A Metric and a Loss for Bounding Box Regression</a></th>
                    </tr>
                
                    <tr id="dd81523b9accdf1c13cd37f76b22ab27d84b7a42">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dd81523b9accdf1c13cd37f76b22ab27d84b7a42">1612</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Park_DeepSDF_Learning_Continuous_Signed_Distance_Functions_for_Shape_Representation_CVPR_2019_paper.html">DeepSDF: Learning Continuous Signed Distance Functions for Shape Representation</a></th>
                    </tr>
                
                    <tr id="a1a19aaddf57c0546357d890d9269092ba0afb26">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a1a19aaddf57c0546357d890d9269092ba0afb26">1609</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Park_Semantic_Image_Synthesis_With_Spatially-Adaptive_Normalization_CVPR_2019_paper.html">Semantic Image Synthesis With Spatially-Adaptive Normalization</a></th>
                    </tr>
                
                    <tr id="21de3a36cb51adc205fad8a1d3d69118891dc3dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/21de3a36cb51adc205fad8a1d3d69118891dc3dd">1312</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cubuk_AutoAugment_Learning_Augmentation_Strategies_From_Data_CVPR_2019_paper.html">AutoAugment: Learning Augmentation Strategies From Data</a></th>
                    </tr>
                
                    <tr id="2e689bdce24cf3644432505ce2783f03a1445ed2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e689bdce24cf3644432505ce2783f03a1445ed2">1226</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mescheder_Occupancy_Networks_Learning_3D_Reconstruction_in_Function_Space_CVPR_2019_paper.html">Occupancy Networks: Learning 3D Reconstruction in Function Space</a></th>
                    </tr>
                
                    <tr id="7ce6eca495909de2ffa0b6d9c16993757208764e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ce6eca495909de2ffa0b6d9c16993757208764e">1210</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_PointRCNN_3D_Object_Proposal_Generation_and_Detection_From_Point_Cloud_CVPR_2019_paper.html">PointRCNN: 3D Object Proposal Generation and Detection From Point Cloud</a></th>
                    </tr>
                
                    <tr id="3bb322718d64a34b91b29c8230c5978de5d7fb7a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3bb322718d64a34b91b29c8230c5978de5d7fb7a">1182</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lang_PointPillars_Fast_Encoders_for_Object_Detection_From_Point_Clouds_CVPR_2019_paper.html">PointPillars: Fast Encoders for Object Detection From Point Clouds</a></th>
                    </tr>
                
                    <tr id="54036f43acc6c9b49b334270c7237217685f52fb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/54036f43acc6c9b49b334270c7237217685f52fb">959</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cui_Class-Balanced_Loss_Based_on_Effective_Number_of_Samples_CVPR_2019_paper.html">Class-Balanced Loss Based on Effective Number of Samples</a></th>
                    </tr>
                
                    <tr id="fb8cf663a71bf31f59557a35d36aaf8c465b50af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fb8cf663a71bf31f59557a35d36aaf8c465b50af">946</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Selective_Kernel_Networks_CVPR_2019_paper.html">Selective Kernel Networks</a></th>
                    </tr>
                
                    <tr id="987b2db58fbe0bda771f11a046cd23de1ce92b39">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/987b2db58fbe0bda771f11a046cd23de1ce92b39">874</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Deformable_ConvNets_V2_More_Deformable_Better_Results_CVPR_2019_paper.html">Deformable ConvNets V2: More Deformable, Better Results</a></th>
                    </tr>
                
                    <tr id="d1a4135a2edd1af8a1e501109bbf7c2c720f10f8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d1a4135a2edd1af8a1e501109bbf7c2c720f10f8">863</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_SiamRPN_Evolution_of_Siamese_Visual_Tracking_With_Very_Deep_Networks_CVPR_2019_paper.html">SiamRPN++: Evolution of Siamese Visual Tracking With Very Deep Networks</a></th>
                    </tr>
                
                    <tr id="8a8cfa45b4c0d071fbffa091c02670b19c94b693">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8a8cfa45b4c0d071fbffa091c02670b19c94b693">845</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kornblith_Do_Better_ImageNet_Models_Transfer_Better_CVPR_2019_paper.html">Do Better ImageNet Models Transfer Better?</a></th>
                    </tr>
                
                    <tr id="29309743870c825f9645a4803af727402462e513">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/29309743870c825f9645a4803af727402462e513">840</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Bag_of_Tricks_for_Image_Classification_with_Convolutional_Neural_Networks_CVPR_2019_paper.html">Bag of Tricks for Image Classification with Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="45532bffbfbb5553da0b2d0844e95a1b37e59147">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/45532bffbfbb5553da0b2d0844e95a1b37e59147">828</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_FBNet_Hardware-Aware_Efficient_ConvNet_Design_via_Differentiable_Neural_Architecture_Search_CVPR_2019_paper.html">FBNet: Hardware-Aware Efficient ConvNet Design via Differentiable Neural Architecture Search</a></th>
                    </tr>
                
                    <tr id="d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d58e13f7e5e06440c9470a9101ccbb1bfd91b5a1">817</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Fast_Online_Object_Tracking_and_Segmentation_A_Unifying_Approach_CVPR_2019_paper.html">Fast Online Object Tracking and Segmentation: A Unifying Approach</a></th>
                    </tr>
                
                    <tr id="5ee147684b06ffc4db0f6326e0cba017d12ceff3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5ee147684b06ffc4db0f6326e0cba017d12ceff3">785</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_PointConv_Deep_Convolutional_Networks_on_3D_Point_Clouds_CVPR_2019_paper.html">PointConv: Deep Convolutional Networks on 3D Point Clouds</a></th>
                    </tr>
                
                    <tr id="32a69681c103807704f71b838454c7924ceec5ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/32a69681c103807704f71b838454c7924ceec5ce">771</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pang_Libra_R-CNN_Towards_Balanced_Learning_for_Object_Detection_CVPR_2019_paper.html">Libra R-CNN: Towards Balanced Learning for Object Detection</a></th>
                    </tr>
                
                    <tr id="c3294425af6e2c059835ec7f0dca7290b48a8faf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c3294425af6e2c059835ec7f0dca7290b48a8faf">757</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Implicit_Fields_for_Generative_Shape_Modeling_CVPR_2019_paper.html">Learning Implicit Fields for Generative Shape Modeling</a></th>
                    </tr>
                
                    <tr id="fc437af6204008647ea49f81058d5fdaddf75ead">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc437af6204008647ea49f81058d5fdaddf75ead">735</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Meta-Learning_With_Differentiable_Convex_Optimization_CVPR_2019_paper.html">Meta-Learning With Differentiable Convex Optimization</a></th>
                    </tr>
                
                    <tr id="b5375995ab8d679a581ffcc2f2e8d3777d60324b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b5375995ab8d679a581ffcc2f2e8d3777d60324b">717</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ghiasi_NAS-FPN_Learning_Scalable_Feature_Pyramid_Architecture_for_Object_Detection_CVPR_2019_paper.html">NAS-FPN: Learning Scalable Feature Pyramid Architecture for Object Detection</a></th>
                    </tr>
                
                    <tr id="f4838839719cf96951ade45a221700341f57c4d7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f4838839719cf96951ade45a221700341f57c4d7">703</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Auto-DeepLab_Hierarchical_Neural_Architecture_Search_for_Semantic_Image_Segmentation_CVPR_2019_paper.html">Auto-DeepLab: Hierarchical Neural Architecture Search for Semantic Image Segmentation</a></th>
                    </tr>
                
                    <tr id="1365b4a286e607a4902ef11c84a1f309719d946c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1365b4a286e607a4902ef11c84a1f309719d946c">689</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Vu_ADVENT_Adversarial_Entropy_Minimization_for_Domain_Adaptation_in_Semantic_Segmentation_CVPR_2019_paper.html">ADVENT: Adversarial Entropy Minimization for Domain Adaptation in Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="fd2a0a326db4f034fe22340c20b7bacd9a14c3d6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fd2a0a326db4f034fe22340c20b7bacd9a14c3d6">675</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dai_Second-Order_Attention_Network_for_Single_Image_Super-Resolution_CVPR_2019_paper.html">Second-Order Attention Network for Single Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="21248bcc81539e7cd1ef83b3b184768603f6f247">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/21248bcc81539e7cd1ef83b3b184768603f6f247">673</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Hybrid_Task_Cascade_for_Instance_Segmentation_CVPR_2019_paper.html">Hybrid Task Cascade for Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="888b3c0f4cf66926484d53c934b7eda760a19265">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/888b3c0f4cf66926484d53c934b7eda760a19265">657</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Meta-Transfer_Learning_for_Few-Shot_Learning_CVPR_2019_paper.html">Meta-Transfer Learning for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="41071dbbbcbb27af3fec70de045f19c28535f5b7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/41071dbbbcbb27af3fec70de045f19c28535f5b7">643</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Feature_Denoising_for_Improving_Adversarial_Robustness_CVPR_2019_paper.html">Feature Denoising for Improving Adversarial Robustness</a></th>
                    </tr>
                
                    <tr id="ec86ce7f0139e9bb3af7bdf25cba45fbe2a5e93e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ec86ce7f0139e9bb3af7bdf25cba45fbe2a5e93e">640</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kirillov_Panoptic_Segmentation_CVPR_2019_paper.html">Panoptic-DeepLab: A Simple, Strong, and Fast Baseline for Bottom-Up Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="1954a5ef37030002574f1b000cc1192f3bd4cad1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1954a5ef37030002574f1b000cc1192f3bd4cad1">619</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Choy_4D_Spatio-Temporal_ConvNets_Minkowski_Convolutional_Neural_Networks_CVPR_2019_paper.html">4D Spatio-Temporal ConvNets: Minkowski Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="b6dd1e22547ed19582d972472b3f67bf2ad93c6c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b6dd1e22547ed19582d972472b3f67bf2ad93c6c">617</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Bottom-Up_Object_Detection_by_Grouping_Extreme_and_Center_Points_CVPR_2019_paper.html">Bottom-Up Object Detection by Grouping Extreme and Center Points</a></th>
                    </tr>
                
                    <tr id="1e7ff66f484e9c7b235b4335103619c8796af419">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1e7ff66f484e9c7b235b4335103619c8796af419">606</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/TRMTMCT/Luo_Bag_of_Tricks_and_a_Strong_Baseline_for_Deep_Person_CVPRW_2019_paper.html">Bag of Tricks and a Strong Baseline for Deep Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="a970d6b162cfdde4258cc2c356190cf516927b51">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a970d6b162cfdde4258cc2c356190cf516927b51">575</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kolesnikov_Revisiting_Self-Supervised_Visual_Representation_Learning_CVPR_2019_paper.html">Revisiting Self-Supervised Visual Representation Learning</a></th>
                    </tr>
                
                    <tr id="73c07e0a998576bb9d9409e5eed713788c0be037">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/73c07e0a998576bb9d9409e5eed713788c0be037">571</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Large-Scale_Long-Tailed_Recognition_in_an_Open_World_CVPR_2019_paper.html">Large-Scale Long-Tailed Recognition in an Open World</a></th>
                    </tr>
                
                    <tr id="bb5bc0acea8d452a7999c512127b4f7b3acf8a6d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bb5bc0acea8d452a7999c512127b4f7b3acf8a6d">569</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Filter_Pruning_via_Geometric_Median_for_Deep_Convolutional_Neural_Networks_CVPR_2019_paper.html">Filter Pruning via Geometric Median for Deep Convolutional Neural Networks Acceleration</a></th>
                    </tr>
                
                    <tr id="8e66c7e494476eb0dee846349df1bd705ceac6c3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e66c7e494476eb0dee846349df1bd705ceac6c3">569</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chang_Argoverse_3D_Tracking_and_Forecasting_With_Rich_Maps_CVPR_2019_paper.html">Argoverse: 3D Tracking and Forecasting With Rich Maps</a></th>
                    </tr>
                
                    <tr id="a84906dbd4d6640f918d0b6ed2a7313dda0d55f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a84906dbd4d6640f918d0b6ed2a7313dda0d55f1">566</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kirillov_Panoptic_Feature_Pyramid_Networks_CVPR_2019_paper.html">Panoptic Feature Pyramid Networks</a></th>
                    </tr>
                
                    <tr id="b763d492b88c079459e67c28959d616a3f1a572d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b763d492b88c079459e67c28959d616a3f1a572d">544</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sadeghian_SoPhie_An_Attentive_GAN_for_Predicting_Paths_Compliant_to_Social_CVPR_2019_paper.html">SoPhie: An Attentive GAN for Predicting Paths Compliant to Social and Physical Constraints</a></th>
                    </tr>
                
                    <tr id="cebd4ab4ab52be88b26d976aa7d4fb35cc19c2a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cebd4ab4ab52be88b26d976aa7d4fb35cc19c2a2">542</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qin_BASNet_Boundary-Aware_Salient_Object_Detection_CVPR_2019_paper.html">BASNet: Boundary-Aware Salient Object Detection</a></th>
                    </tr>
                
                    <tr id="be2cafced16bb8834bdd322a0a512142c8d05388">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/be2cafced16bb8834bdd322a0a512142c8d05388">539</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Krull_Noise2Void_-_Learning_Denoising_From_Single_Noisy_Images_CVPR_2019_paper.html">Noise2Void - Learning Denoising From Single Noisy Images</a></th>
                    </tr>
                
                    <tr id="1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ab7f7c1d328589f25c79515b9a5d824d7ffbbd1">539</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hudson_GQA_A_New_Dataset_for_Real-World_Visual_Reasoning_and_Compositional_CVPR_2019_paper.html">GQA: A New Dataset for Real-World Visual Reasoning and Compositional Question Answering</a></th>
                    </tr>
                
                    <tr id="4be4707aba8d622a0553aa159dc92ae7f9af9c5e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4be4707aba8d622a0553aa159dc92ae7f9af9c5e">539</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pavlakos_Expressive_Body_Capture_3D_Hands_Face_and_Body_From_a_CVPR_2019_paper.html">Expressive Body Capture: 3D Hands, Face, and Body From a Single Image</a></th>
                    </tr>
                
                    <tr id="1f6d30772a94d978c9f81e2f7c1f4b0bdec117dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1f6d30772a94d978c9f81e2f7c1f4b0bdec117dd">536</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Large_Scale_Incremental_Learning_CVPR_2019_paper.html">Large Scale Incremental Learning</a></th>
                    </tr>
                
                    <tr id="59d56365cabd54c919e023692d3ab6c4cd13fb61">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/59d56365cabd54c919e023692d3ab6c4cd13fb61">532</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Two-Stream_Adaptive_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_CVPR_2019_paper.html">Two-Stream Adaptive Graph Convolutional Networks for Skeleton-Based Action Recognition</a></th>
                    </tr>
                
                    <tr id="852bad998bc2a1c8c86314da3b5b5a162a76d500">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/852bad998bc2a1c8c86314da3b5b5a162a76d500">527</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Guo_Toward_Convolutional_Blind_Denoising_of_Real_Photographs_CVPR_2019_paper.html">Toward Convolutional Blind Denoising of Real Photographs</a></th>
                    </tr>
                
                    <tr id="f78a911f516625d6b7b76a9a33c1eb14613341c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f78a911f516625d6b7b76a9a33c1eb14613341c4">526</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Improving_Transferability_of_Adversarial_Examples_With_Input_Diversity_CVPR_2019_paper.html">Improving Transferability of Adversarial Examples With Input Diversity</a></th>
                    </tr>
                
                    <tr id="ec721b4b280ce593428499d013bc01ca19dbcac3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ec721b4b280ce593428499d013bc01ca19dbcac3">522</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Joint_Discriminative_and_Generative_Learning_for_Person_Re-Identification_CVPR_2019_paper.html">Joint Discriminative and Generative Learning for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="8c328bc048449131d98b545eaa3c99f8356c5620">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c328bc048449131d98b545eaa3c99f8356c5620">522</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Pseudo-LiDAR_From_Visual_Depth_Estimation_Bridging_the_Gap_in_3D_CVPR_2019_paper.html">Pseudo-LiDAR From Visual Depth Estimation: Bridging the Gap in 3D Object Detection for Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="d74169a8fd2f90a06480d1d583d0ae5e980ea951">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d74169a8fd2f90a06480d1d583d0ae5e980ea951">516</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Danelljan_ATOM_Accurate_Tracking_by_Overlap_Maximization_CVPR_2019_paper.html">ATOM: Accurate Tracking by Overlap Maximization</a></th>
                    </tr>
                
                    <tr id="0f736d2067ee9c950b876f14521268c6009e67d6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0f736d2067ee9c950b876f14521268c6009e67d6">514</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Park_Relational_Knowledge_Distillation_CVPR_2019_paper.html">Relational Knowledge Distillation</a></th>
                    </tr>
                
                    <tr id="9721f9b2d5a77b878f6ffc6badd3470e1ade9415">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9721f9b2d5a77b878f6ffc6badd3470e1ade9415">510</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Feature_Selective_Anchor-Free_Module_for_Single-Shot_Object_Detection_CVPR_2019_paper.html">Feature Selective Anchor-Free Module for Single-Shot Object Detection</a></th>
                    </tr>
                
                    <tr id="900ab48d25b44c076e31224b7befa503d9550c53">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/900ab48d25b44c076e31224b7befa503d9550c53">510</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fan_LaSOT_A_High-Quality_Benchmark_for_Large-Scale_Single_Object_Tracking_CVPR_2019_paper.html">LaSOT: A High-Quality Benchmark for Large-Scale Single Object Tracking</a></th>
                    </tr>
                
                    <tr id="7ce7941ffe5220383d4e614ebcf2397e30cb27a7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ce7941ffe5220383d4e614ebcf2397e30cb27a7">509</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Carlucci_Domain_Generalization_by_Solving_Jigsaw_Puzzles_CVPR_2019_paper.html">Domain Generalization by Solving Jigsaw Puzzles</a></th>
                    </tr>
                
                    <tr id="79ed40c04328d8e1600a3a31004b4efb843dbab1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/79ed40c04328d8e1600a3a31004b4efb843dbab1">496</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_DenseFusion_6D_Object_Pose_Estimation_by_Iterative_Dense_Fusion_CVPR_2019_paper.html">DenseFusion: 6D Object Pose Estimation by Iterative Dense Fusion</a></th>
                    </tr>
                
                    <tr id="2ba0905746f38a0409941cf0300b4cb4b95c2dc2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ba0905746f38a0409941cf0300b4cb4b95c2dc2">493</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Mask_Scoring_R-CNN_CVPR_2019_paper.html">Mask Scoring R-CNN</a></th>
                    </tr>
                
                    <tr id="2b954c9750b1d4a96916664ed8ab35d1aa589304">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b954c9750b1d4a96916664ed8ab35d1aa589304">489</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pavllo_3D_Human_Pose_Estimation_in_Video_With_Temporal_Convolutions_and_CVPR_2019_paper.html">3D Human Pose Estimation in Video With Temporal Convolutions and Semi-Supervised Training</a></th>
                    </tr>
                
                    <tr id="94bbc4ea271c918705876b60d98d227a0ab55a43">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/94bbc4ea271c918705876b60d98d227a0ab55a43">476</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Girdhar_Video_Action_Transformer_Network_CVPR_2019_paper.html">Video Action Transformer Network</a></th>
                    </tr>
                
                    <tr id="28b3833743ab00904da1f4a30cd6c771cc164c0d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/28b3833743ab00904da1f4a30cd6c771cc164c0d">473</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Wang_EDVR_Video_Restoration_With_Enhanced_Deformable_Convolutional_Networks_CVPRW_2019_paper.html">EDVR: Video Restoration With Enhanced Deformable Convolutional Networks</a></th>
                    </tr>
                
                    <tr id="743eab7fa743dc00532ea7c2bc0f6f8d87c93405">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/743eab7fa743dc00532ea7c2bc0f6f8d87c93405">469</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Peng_PVNet_Pixel-Wise_Voting_Network_for_6DoF_Pose_Estimation_CVPR_2019_paper.html">PVNet: Pixel-Wise Voting Network for 6DoF Pose Estimation</a></th>
                    </tr>
                
                    <tr id="54c4642d017830e1faddbb49f0377228d2b01493">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/54c4642d017830e1faddbb49f0377228d2b01493">469</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_HAQ_Hardware-Aware_Automated_Quantization_With_Mixed_Precision_CVPR_2019_paper.html">HAQ: Hardware-Aware Automated Quantization With Mixed Precision</a></th>
                    </tr>
                
                    <tr id="b1e245a304de66f6c6dcc8f5fb2254dab94de7d8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b1e245a304de66f6c6dcc8f5fb2254dab94de7d8">467</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Multi-Label_Image_Recognition_With_Graph_Convolutional_Networks_CVPR_2019_paper.html">Multi-Label Image Recognition With Graph Convolutional Networks</a></th>
                    </tr>
                
                    <tr id="89ff54a10869113aa1d5c6754ac4928e64b54292">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/89ff54a10869113aa1d5c6754ac4928e64b54292">466</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Luo_Taking_a_Closer_Look_at_Domain_Shift_Category-Level_Adversaries_for_CVPR_2019_paper.html">Taking a Closer Look at Domain Shift: Category-Level Adversaries for Semantics Consistent Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="4ccd95612be1b970f64871e6c132cd01269d8ad9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ccd95612be1b970f64871e6c132cd01269d8ad9">463</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hou_Learning_a_Unified_Classifier_Incrementally_via_Rebalancing_CVPR_2019_paper.html">Learning a Unified Classifier Incrementally via Rebalancing</a></th>
                    </tr>
                
                    <tr id="2d066beb34469559e0fc5e5ab4d68dc736cfd46f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d066beb34469559e0fc5e5ab4d68dc736cfd46f">454</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Li_Exposing_DeepFake_Videos_By_Detecting_Face_Warping_Artifacts_CVPRW_2019_paper.html">Exposing DeepFake Videos By Detecting Face Warping Artifacts</a></th>
                    </tr>
                
                    <tr id="2e713509e96daf06e65e10bdc438d00a827c914c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e713509e96daf06e65e10bdc438d00a827c914c">453</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deeper_and_Wider_Siamese_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.html">Deeper and Wider Siamese Networks for Real-Time Visual Tracking</a></th>
                    </tr>
                
                    <tr id="619cf9d39abb93fe1ab17921c163fc5734ac1e70">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/619cf9d39abb93fe1ab17921c163fc5734ac1e70">452</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_End-To-End_Multi-Task_Learning_With_Attention_CVPR_2019_paper.html">End-To-End Multi-Task Learning With Attention</a></th>
                    </tr>
                
                    <tr id="fe8907302f9d14233cd03cc2948a1c4e2a50bdb6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fe8907302f9d14233cd03cc2948a1c4e2a50bdb6">451</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Searching_for_a_Robust_Neural_Architecture_in_Four_GPU_Hours_CVPR_2019_paper.html">Searching for a Robust Neural Architecture in Four GPU Hours</a></th>
                    </tr>
                
                    <tr id="a58715797b61588cbd020b9a98292a98f8483420">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a58715797b61588cbd020b9a98292a98f8483420">450</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Relation-Shape_Convolutional_Neural_Network_for_Point_Cloud_Analysis_CVPR_2019_paper.html">Relation-Shape Convolutional Neural Network for Point Cloud Analysis</a></th>
                    </tr>
                
                    <tr id="074611d0c9f527bc0ad06f00df779f3361e38b83">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/074611d0c9f527bc0ad06f00df779f3361e38b83">444</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Si_An_Attention_Enhanced_Graph_Convolutional_LSTM_Network_for_Skeleton-Based_Action_CVPR_2019_paper.html">An Attention Enhanced Graph Convolutional LSTM Network for Skeleton-Based Action Recognition</a></th>
                    </tr>
                
                    <tr id="6dfc2ff03534a4325d06c6f88c3144831996629b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6dfc2ff03534a4325d06c6f88c3144831996629b">441</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zellers_From_Recognition_to_Cognition_Visual_Commonsense_Reasoning_CVPR_2019_paper.html">From Recognition to Cognition: Visual Commonsense Reasoning</a></th>
                    </tr>
                
                    <tr id="f902a64f7d08aaa6bfca7463e8729952ddc6134e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f902a64f7d08aaa6bfca7463e8729952ddc6134e">439</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gupta_LVIS_A_Dataset_for_Large_Vocabulary_Instance_Segmentation_CVPR_2019_paper.html">LVIS: A Dataset for Large Vocabulary Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="66ce56946214ab496c260012d828f7883ebfca22">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/66ce56946214ab496c260012d828f7883ebfca22">425</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Cascaded_Partial_Decoder_for_Fast_and_Accurate_Salient_Object_Detection_CVPR_2019_paper.html">Cascaded Partial Decoder for Fast and Accurate Salient Object Detection</a></th>
                    </tr>
                
                    <tr id="675b96a38f37f92043189d7e90377a6b41a2a9cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/675b96a38f37f92043189d7e90377a6b41a2a9cd">424</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kang_Contrastive_Adaptation_Network_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html">Contrastive Adaptation Network for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="6fc0e648ef6002fe3507107f4f3637c76d54477f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6fc0e648ef6002fe3507107f4f3637c76d54477f">423</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_On_the_Continuity_of_Rotation_Representations_in_Neural_Networks_CVPR_2019_paper.html">On the Continuity of Rotation Representations in Neural Networks</a></th>
                    </tr>
                
                    <tr id="96c05f7f2c2435a7793f17c2ee72cd824e26441a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96c05f7f2c2435a7793f17c2ee72cd824e26441a">422</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Feedback_Network_for_Image_Super-Resolution_CVPR_2019_paper.html">Feedback Network for Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="8c0a2d0d19026583a55e850b513afa5ec6d42ba9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c0a2d0d19026583a55e850b513afa5ec6d42ba9">414</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_A_Simple_Pooling-Based_Design_for_Real-Time_Salient_Object_Detection_CVPR_2019_paper.html">A Simple Pooling-Based Design for Real-Time Salient Object Detection</a></th>
                    </tr>
                
                    <tr id="f6feb1af1809dfd872d868dfcc13021cc42f496c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f6feb1af1809dfd872d868dfcc13021cc42f496c">406</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Auto-Encoding_Scene_Graphs_for_Image_Captioning_CVPR_2019_paper.html">Auto-Encoding Scene Graphs for Image Captioning</a></th>
                    </tr>
                
                    <tr id="0c5d9f4bf8b11a92a4d42b796052aca20a2a43fd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c5d9f4bf8b11a92a4d42b796052aca20a2a43fd">402</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhong_Invariance_Matters_Exemplar_Memory_for_Domain_Adaptive_Person_Re-Identification_CVPR_2019_paper.html">Invariance Matters: Exemplar Memory for Domain Adaptive Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="830918ec06f22c0de40884ccfcb5705823ac9a3f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/830918ec06f22c0de40884ccfcb5705823ac9a3f">394</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Region_Proposal_by_Guided_Anchoring_CVPR_2019_paper.html">Region Proposal by Guided Anchoring</a></th>
                    </tr>
                
                    <tr id="83b8f369a1d02c0d0ca117b667d0ace46510cdc5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/83b8f369a1d02c0d0ca117b667d0ace46510cdc5">393</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_GA-Net_Guided_Aggregation_Net_for_End-To-End_Stereo_Matching_CVPR_2019_paper.html">GA-Net: Guided Aggregation Net for End-To-End Stereo Matching</a></th>
                    </tr>
                
                    <tr id="e2d3abc7008a269880918ee7d903a55d06acdd55">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e2d3abc7008a269880918ee7d903a55d06acdd55">386</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sitzmann_DeepVoxels_Learning_Persistent_3D_Feature_Embeddings_CVPR_2019_paper.html">DeepVoxels: Learning Persistent 3D Feature Embeddings</a></th>
                    </tr>
                
                    <tr id="3ecbd9b6153e9ff2f490950a87853e68c808db4d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ecbd9b6153e9ff2f490950a87853e68c808db4d">384</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mo_PartNet_A_Large-Scale_Benchmark_for_Fine-Grained_and_Hierarchical_Part-Level_3D_CVPR_2019_paper.html">PartNet: A Large-Scale Benchmark for Fine-Grained and Hierarchical Part-Level 3D Object Understanding</a></th>
                    </tr>
                
                    <tr id="a6f4917d043494d2ebaebe6b65cb35e6a07fda41">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a6f4917d043494d2ebaebe6b65cb35e6a07fda41">382</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Molchanov_Importance_Estimation_for_Neural_Network_Pruning_CVPR_2019_paper.html">Importance Estimation for Neural Network Pruning</a></th>
                    </tr>
                
                    <tr id="bf7a96aa4b67c57c81ab7419a164de582ca16dc3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bf7a96aa4b67c57c81ab7419a164de582ca16dc3">380</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Multi-Similarity_Loss_With_General_Pair_Weighting_for_Deep_Metric_Learning_CVPR_2019_paper.html">Multi-Similarity Loss With General Pair Weighting for Deep Metric Learning</a></th>
                    </tr>
                
                    <tr id="206b2aeb81b29463968b8deb1efce51941f18208">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/206b2aeb81b29463968b8deb1efce51941f18208">379</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Baek_Character_Region_Awareness_for_Text_Detection_CVPR_2019_paper.html">Character Region Awareness for Text Detection</a></th>
                    </tr>
                
                    <tr id="8a1744da011375d711ed75fc2d160c6fdca2cf89">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8a1744da011375d711ed75fc2d160c6fdca2cf89">375</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Deep_Modular_Co-Attention_Networks_for_Visual_Question_Answering_CVPR_2019_paper.html">Deep Modular Co-Attention Networks for Visual Question Answering</a></th>
                    </tr>
                
                    <tr id="814b70cd133f97ef039bcc44124d9344dd8b3f64">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/814b70cd133f97ef039bcc44124d9344dd8b3f64">369</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Actional-Structural_Graph_Convolutional_Networks_for_Skeleton-Based_Action_Recognition_CVPR_2019_paper.html">Actional-Structural Graph Convolutional Networks for Skeleton-Based Action Recognition</a></th>
                    </tr>
                
                    <tr id="292f120b2664a37335e557bcb2a860a7a8b507a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/292f120b2664a37335e557bcb2a860a7a8b507a6">364</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Graph_Attention_Convolution_for_Point_Cloud_Semantic_Segmentation_CVPR_2019_paper.html">Graph Attention Convolution for Point Cloud Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="cfb5c4f2e160ea3d99968e50a8264659f54e226f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cfb5c4f2e160ea3d99968e50a8264659f54e226f">357</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Bidirectional_Learning_for_Domain_Adaptation_of_Semantic_Segmentation_CVPR_2019_paper.html">Bidirectional Learning for Domain Adaptation of Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="cafcdab811c7834c9c09960e09f9feb045efc945">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cafcdab811c7834c9c09960e09f9feb045efc945">355</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Iscen_Label_Propagation_for_Deep_Semi-Supervised_Learning_CVPR_2019_paper.html">Label Propagation for Deep Semi-Supervised Learning</a></th>
                    </tr>
                
                    <tr id="68a024d7b70ef3989a6751678f635cbe754440fc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/68a024d7b70ef3989a6751678f635cbe754440fc">355</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Skeleton-Based_Action_Recognition_With_Directed_Graph_Neural_Networks_CVPR_2019_paper.html">Skeleton-Based Action Recognition With Directed Graph Neural Networks</a></th>
                    </tr>
                
                    <tr id="22d7fc18f5be854b7c33ae53bf312fbffa101e8e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/22d7fc18f5be854b7c33ae53bf312fbffa101e8e">355</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ranjan_Competitive_Collaboration_Joint_Unsupervised_Learning_of_Depth_Camera_Motion_Optical_CVPR_2019_paper.html">Competitive Collaboration: Joint Unsupervised Learning of Depth, Camera Motion, Optical Flow and Motion Segmentation</a></th>
                    </tr>
                
                    <tr id="aeef4a512aecb76ca04f102ec8972fe8dbce71e7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aeef4a512aecb76ca04f102ec8972fe8dbce71e7">350</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Learning_RoI_Transformer_for_Oriented_Object_Detection_in_Aerial_Images_CVPR_2019_paper.html">Learning RoI Transformer for Oriented Object Detection in Aerial Images</a></th>
                    </tr>
                
                    <tr id="c8844833b24cc60a0fd5622b1eac7c234da58a75">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c8844833b24cc60a0fd5622b1eac7c234da58a75">348</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Normalized_Object_Coordinate_Space_for_Category-Level_6D_Object_Pose_and_CVPR_2019_paper.html">Normalized Object Coordinate Space for Category-Level 6D Object Pose and Size Estimation</a></th>
                    </tr>
                
                    <tr id="325ffdedab735ac403f06832ca6bbb3539aa4bef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/325ffdedab735ac403f06832ca6bbb3539aa4bef">347</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Aoki_PointNetLK_Robust__Efficient_Point_Cloud_Registration_Using_PointNet_CVPR_2019_paper.html">PointNetLK: Robust &amp; Efficient Point Cloud Registration Using PointNet</a></th>
                    </tr>
                
                    <tr id="3aa681914a7da79f7d7293f51a058eefe61c8bb7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3aa681914a7da79f7d7293f51a058eefe61c8bb7">346</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Bergmann_MVTec_AD_--_A_Comprehensive_Real-World_Dataset_for_Unsupervised_Anomaly_CVPR_2019_paper.html">MVTec AD — A Comprehensive Real-World Dataset for Unsupervised Anomaly Detection</a></th>
                    </tr>
                
                    <tr id="8062f3536fec7647548af53adc191069458fdc9c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8062f3536fec7647548af53adc191069458fdc9c">340</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Underexposed_Photo_Enhancement_Using_Deep_Illumination_Estimation_CVPR_2019_paper.html">Underexposed Photo Enhancement Using Deep Illumination Estimation</a></th>
                    </tr>
                
                    <tr id="00ffb4121cbd03d09ad4672a20eecd25703540ea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00ffb4121cbd03d09ad4672a20eecd25703540ea">340</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Schonfeld_Generalized_Zero-_and_Few-Shot_Learning_via_Aligned_Variational_Autoencoders_CVPR_2019_paper.html">Generalized Zero- and Few-Shot Learning via Aligned Variational Autoencoders</a></th>
                    </tr>
                
                    <tr id="a25b63a6a0071d7d88ff4671c1fd40f320a08533">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a25b63a6a0071d7d88ff4671c1fd40f320a08533">338</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hein_Why_ReLU_Networks_Yield_High-Confidence_Predictions_Far_Away_From_the_CVPR_2019_paper.html">Why ReLU Networks Yield High-Confidence Predictions Far Away From the Training Data and How to Mitigate the Problem</a></th>
                    </tr>
                
                    <tr id="45cb2cbae5c0b4cc52e524cc191a2f8db674ed42">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/45cb2cbae5c0b4cc52e524cc191a2f8db674ed42">335</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Long-Term_Feature_Banks_for_Detailed_Video_Understanding_CVPR_2019_paper.html">Long-Term Feature Banks for Detailed Video Understanding</a></th>
                    </tr>
                
                    <tr id="ddb80e2c3e1c2ba012ff33bafaef86f02b7275b0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ddb80e2c3e1c2ba012ff33bafaef86f02b7275b0">335</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Voigtlaender_MOTS_Multi-Object_Tracking_and_Segmentation_CVPR_2019_paper.html">MOTS: Multi-Object Tracking and Segmentation</a></th>
                    </tr>
                
                    <tr id="5af2d424bb38db7e6a72f7bec2cfd8a5bb8af7fb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5af2d424bb38db7e6a72f7bec2cfd8a5bb8af7fb">332</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qiao_MirrorGAN_Learning_Text-To-Image_Generation_by_Redescription_CVPR_2019_paper.html">MirrorGAN: Learning Text-To-Image Generation by Redescription</a></th>
                    </tr>
                
                    <tr id="97ef575d7049ba0f1aeba4453a6dcd5475567630">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/97ef575d7049ba0f1aeba4453a6dcd5475567630">331</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sarlin_From_Coarse_to_Fine_Robust_Hierarchical_Localization_at_Large_Scale_CVPR_2019_paper.html">From Coarse to Fine: Robust Hierarchical Localization at Large Scale</a></th>
                    </tr>
                
                    <tr id="3d7df210adf70f30f952739553201994b92e5630">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3d7df210adf70f30f952739553201994b92e5630">330</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_PointWeb_Enhancing_Local_Neighborhood_Features_for_Point_Cloud_Processing_CVPR_2019_paper.html">PointWeb: Enhancing Local Neighborhood Features for Point Cloud Processing</a></th>
                    </tr>
                
                    <tr id="8e22a4d2d6af1d21d29fdb875ca8b55fcfa69bf0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e22a4d2d6af1d21d29fdb875ca8b55fcfa69bf0">329</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yoo_Learning_Loss_for_Active_Learning_CVPR_2019_paper.html">Learning Loss for Active Learning</a></th>
                    </tr>
                
                    <tr id="7b50853560e62e94f4d20426a6ddb43b8c9b314f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b50853560e62e94f4d20426a6ddb43b8c9b314f">329</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Shape_Robust_Text_Detection_With_Progressive_Scale_Expansion_Network_CVPR_2019_paper.html">Shape Robust Text Detection With Progressive Scale Expansion Network</a></th>
                    </tr>
                
                    <tr id="1eaee16f6395c9602ad1dc17e69a6e235ec9ddd6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1eaee16f6395c9602ad1dc17e69a6e235ec9ddd6">326</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Graph-Based_Global_Reasoning_Networks_CVPR_2019_paper.html">Graph-Based Global Reasoning Networks</a></th>
                    </tr>
                
                    <tr id="6d411f15a0d17aba58006aa7d2eaebc66a0ca8c8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6d411f15a0d17aba58006aa7d2eaebc66a0ca8c8">326</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ren_Progressive_Image_Deraining_Networks_A_Better_and_Simpler_Baseline_CVPR_2019_paper.html">Progressive Image Deraining Networks: A Better and Simpler Baseline</a></th>
                    </tr>
                
                    <tr id="bd63fef46192e7dd3eec6ab5ed0c2afa19556b3a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bd63fef46192e7dd3eec6ab5ed0c2afa19556b3a">322</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Pyramid_Feature_Attention_Network_for_Saliency_Detection_CVPR_2019_paper.html">Pyramid Feature Attention Network for Saliency Detection</a></th>
                    </tr>
                
                    <tr id="494498bb126b9234f1c1f2fc2dda4ac6f22066d9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/494498bb126b9234f1c1f2fc2dda4ac6f22066d9">319</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_Correspondence_From_the_Cycle-Consistency_of_Time_CVPR_2019_paper.html">Learning Correspondence From the Cycle-Consistency of Time</a></th>
                    </tr>
                
                    <tr id="e4bde6fe33b6c2cf9d1647ac0b041f7d1ba29c5b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e4bde6fe33b6c2cf9d1647ac0b041f7d1ba29c5b">318</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Unsupervised_Embedding_Learning_via_Invariant_and_Spreading_Instance_Feature_CVPR_2019_paper.html">Unsupervised Embedding Learning via Invariant and Spreading Instance Feature</a></th>
                    </tr>
                
                    <tr id="8c31e0862a7f26fd1a4a52045ffcf24b8b82292e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c31e0862a7f26fd1a4a52045ffcf24b8b82292e">318</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Multi-Task_Multi-Sensor_Fusion_for_3D_Object_Detection_CVPR_2019_paper.html">Multi-Task Multi-Sensor Fusion for 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="599fd051c9438011ec5b581983c89e8922b4a5e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/599fd051c9438011ec5b581983c89e8922b4a5e6">316</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Perera_OCGAN_One-Class_Novelty_Detection_Using_GANs_With_Constrained_Latent_Representations_CVPR_2019_paper.html">OCGAN: One-Class Novelty Detection Using GANs With Constrained Latent Representations</a></th>
                    </tr>
                
                    <tr id="9bd795bcbf8eccd12957240127a087a34c54fb04">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9bd795bcbf8eccd12957240127a087a34c54fb04">316</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Evading_Defenses_to_Transferable_Adversarial_Examples_by_Translation-Invariant_Attacks_CVPR_2019_paper.html">Evading Defenses to Transferable Adversarial Examples by Translation-Invariant Attacks</a></th>
                    </tr>
                
                    <tr id="3c667ab03a4e8842847f78227816d944a66afb32">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3c667ab03a4e8842847f78227816d944a66afb32">312</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_From_Synthetic_Data_for_Crowd_Counting_in_the_Wild_CVPR_2019_paper.html">Learning From Synthetic Data for Crowd Counting in the Wild</a></th>
                    </tr>
                
                    <tr id="38be3697a9cd4bf50853d0c2e226e8a5bf9aa052">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38be3697a9cd4bf50853d0c2e226e8a5bf9aa052">311</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Structured_Knowledge_Distillation_for_Semantic_Segmentation_CVPR_2019_paper.html">Structured Knowledge Distillation for Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="dee5d062e70250572e50cda25f08d6a2c02b2bab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dee5d062e70250572e50cda25f08d6a2c02b2bab">311</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lin_Towards_Optimal_Structured_CNN_Pruning_via_Generative_Adversarial_Learning_CVPR_2019_paper.html">Towards Optimal Structured CNN Pruning via Generative Adversarial Learning</a></th>
                    </tr>
                
                    <tr id="a25b63a6a0071d7d88ff4671c1fd40f320a08533">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a25b63a6a0071d7d88ff4671c1fd40f320a08533">310</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Hein_Why_ReLU_networks_yield_high-confidence_predictions_far_away_from_the_CVPRW_2019_paper.html">Why ReLU networks yield high-confidence predictions far away from the training data and how to mitigate the problem</a></th>
                    </tr>
                
                    <tr id="de9949331c81cc8697d48dfd1b9f54d604a7d85a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/de9949331c81cc8697d48dfd1b9f54d604a7d85a">304</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Bounding_Box_Regression_With_Uncertainty_for_Accurate_Object_Detection_CVPR_2019_paper.html">Bounding Box Regression With Uncertainty for Accurate Object Detection</a></th>
                    </tr>
                
                    <tr id="a6376cb4353eafba8284be593029a8ef309ec271">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a6376cb4353eafba8284be593029a8ef309ec271">303</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Salient_Object_Detection_With_Pyramid_Attention_and_Salient_Edges_CVPR_2019_paper.html">Salient Object Detection With Pyramid Attention and Salient Edges</a></th>
                    </tr>
                
                    <tr id="c0dccd9be123057ec82a6747d8fec9cc34699a6d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c0dccd9be123057ec82a6747d8fec9cc34699a6d">302</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/James_Sim-To-Real_via_Sim-To-Sim_Data-Efficient_Robotic_Grasping_via_Randomized-To-Canonical_Adaptation_Networks_CVPR_2019_paper.html">Sim-To-Real via Sim-To-Sim: Data-Efficient Robotic Grasping via Randomized-To-Canonical Adaptation Networks</a></th>
                    </tr>
                
                    <tr id="c4a1f79d62bafabc6447ed885525796786f21e22">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c4a1f79d62bafabc6447ed885525796786f21e22">300</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Pluralistic_Image_Completion_CVPR_2019_paper.html">Pluralistic Image Completion</a></th>
                    </tr>
                
                    <tr id="da4656d88d3363488219682fe2c5dacfbb729480">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/da4656d88d3363488219682fe2c5dacfbb729480">299</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Stereo_R-CNN_Based_3D_Object_Detection_for_Autonomous_Driving_CVPR_2019_paper.html">Stereo R-CNN Based 3D Object Detection for Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="55c5e4753ac6bfa88d2f0e00c8e881c49b72d48e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/55c5e4753ac6bfa88d2f0e00c8e881c49b72d48e">296</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Thys_Fooling_Automated_Surveillance_Cameras_Adversarial_Patches_to_Attack_Person_Detection_CVPRW_2019_paper.html">Fooling Automated Surveillance Cameras: Adversarial Patches to Attack Person Detection</a></th>
                    </tr>
                
                    <tr id="9ce6d7373d307eb14f7ee76357e442f920be631a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9ce6d7373d307eb14f7ee76357e442f920be631a">295</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kolotouros_Convolutional_Mesh_Regression_for_Single-Image_Human_Shape_Reconstruction_CVPR_2019_paper.html">Convolutional Mesh Regression for Single-Image Human Shape Reconstruction</a></th>
                    </tr>
                
                    <tr id="436142577b23f89832fe6ee2d77ee9585e103729">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/436142577b23f89832fe6ee2d77ee9585e103729">292</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kanazawa_Learning_3D_Human_Dynamics_From_Video_CVPR_2019_paper.html">Learning 3D Human Dynamics From Video</a></th>
                    </tr>
                
                    <tr id="098b138f58e43338248e3bc35cb36adfed8008d1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/098b138f58e43338248e3bc35cb36adfed8008d1">291</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Edge-Labeling_Graph_Neural_Network_for_Few-Shot_Learning_CVPR_2019_paper.html">Edge-Labeling Graph Neural Network for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="ecb7fd539c6b32c15ee52d112a8f5003f685124a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ecb7fd539c6b32c15ee52d112a8f5003f685124a">291</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Feng_Attentive_Feedback_Network_for_Boundary-Aware_Salient_Object_Detection_CVPR_2019_paper.html">Attentive Feedback Network for Boundary-Aware Salient Object Detection</a></th>
                    </tr>
                
                    <tr id="c66b8e508718f4b7f14829e5c2cde0add31d2693">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c66b8e508718f4b7f14829e5c2cde0add31d2693">287</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Reinforced_Cross-Modal_Matching_and_Self-Supervised_Imitation_Learning_for_Vision-Language_Navigation_CVPR_2019_paper.html">Reinforced Cross-Modal Matching and Self-Supervised Imitation Learning for Vision-Language Navigation</a></th>
                    </tr>
                
                    <tr id="865100f1b248723f48fc5d2c68be0421fd24ff48">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/865100f1b248723f48fc5d2c68be0421fd24ff48">287</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Sliced_Wasserstein_Discrepancy_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html">Sliced Wasserstein Discrepancy for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="1cb1bfd9af5bda1f712605695e47d37c03522652">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1cb1bfd9af5bda1f712605695e47d37c03522652">286</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Context-Aware_Crowd_Counting_CVPR_2019_paper.html">Context-Aware Crowd Counting</a></th>
                    </tr>
                
                    <tr id="5ca9b18448a2ef8a2443445269ccb151aa100de9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5ca9b18448a2ef8a2443445269ccb151aa100de9">282</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Saito_Strong-Weak_Distribution_Alignment_for_Adaptive_Object_Detection_CVPR_2019_paper.html">Strong-Weak Distribution Alignment for Adaptive Object Detection</a></th>
                    </tr>
                
                    <tr id="21648dd098a3c0ae871844b254775fec14df6904">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/21648dd098a3c0ae871844b254775fec14df6904">281</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fan_Shifting_More_Attention_to_Video_Salient_Object_Detection_CVPR_2019_paper.html">Shifting More Attention to Video Salient Object Detection</a></th>
                    </tr>
                
                    <tr id="5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f1e7c3c81d6a9e716eab660bb7536ecb204ef7d">280</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Abati_Latent_Space_Autoregression_for_Novelty_Detection_CVPR_2019_paper.html">Latent Space Autoregression for Novelty Detection</a></th>
                    </tr>
                
                    <tr id="558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/558aeb7aa38cfcf8dd9951bfd24cf77972bd09aa">278</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Self-Supervised_Spatiotemporal_Learning_via_Video_Clip_Order_Prediction_CVPR_2019_paper.html">Self-Supervised Spatiotemporal Learning via Video Clip Order Prediction</a></th>
                    </tr>
                
                    <tr id="92ebadf9913e6800331e5f9b2699812fe77313ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/92ebadf9913e6800331e5f9b2699812fe77313ff">277</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ahn_Variational_Information_Distillation_for_Knowledge_Transfer_CVPR_2019_paper.html">Variational Information Distillation for Knowledge Transfer</a></th>
                    </tr>
                
                    <tr id="ab995c4273111cde3e31ff7347c475aace10f1a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ab995c4273111cde3e31ff7347c475aace10f1a5">276</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lu_DVC_An_End-To-End_Deep_Video_Compression_Framework_CVPR_2019_paper.html">DVC: An End-To-End Deep Video Compression Framework</a></th>
                    </tr>
                
                    <tr id="ac1f84cc50f31b2ae7775820242d7c71f1c3f42a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ac1f84cc50f31b2ae7775820242d7c71f1c3f42a">276</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Agarwal_Protecting_World_Leaders_Against_Deep_Fakes_CVPRW_2019_paper.html">Protecting World Leaders Against Deep Fakes</a></th>
                    </tr>
                
                    <tr id="e54fe27ed18d513e3e9171661bd9b6e1c982b7d5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e54fe27ed18d513e3e9171661bd9b6e1c982b7d5">275</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lu_See_More_Know_More_Unsupervised_Video_Object_Segmentation_With_Co-Attention_CVPR_2019_paper.html">See More, Know More: Unsupervised Video Object Segmentation With Co-Attention Siamese Networks</a></th>
                    </tr>
                
                    <tr id="cec3bffdb0968cd820863005af54cc519704c24a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cec3bffdb0968cd820863005af54cc519704c24a">274</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mao_Mode_Seeking_Generative_Adversarial_Networks_for_Diverse_Image_Synthesis_CVPR_2019_paper.html">Mode Seeking Generative Adversarial Networks for Diverse Image Synthesis</a></th>
                    </tr>
                
                    <tr id="441a95b80875c7fe0ae98c5d301e2c92feb4c191">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/441a95b80875c7fe0ae98c5d301e2c92feb4c191">274</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xian_F-VAEGAN-D2_A_Feature_Generating_Framework_for_Any-Shot_Learning_CVPR_2019_paper.html">F-VAEGAN-D2: A Feature Generating Framework for Any-Shot Learning</a></th>
                    </tr>
                
                    <tr id="441a95b80875c7fe0ae98c5d301e2c92feb4c191">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/441a95b80875c7fe0ae98c5d301e2c92feb4c191">274</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Xian_f-VAEGAN-D2_A_Feature_Generating_Framework_for_Any-Shot_Learning_CVPRW_2019_paper.html">f-VAEGAN-D2: A Feature Generating Framework for Any-Shot Learning</a></th>
                    </tr>
                
                    <tr id="c2aa0581254ce342c77b2c7a835b3587bd453486">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c2aa0581254ce342c77b2c7a835b3587bd453486">273</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_DFANet_Deep_Feature_Aggregation_for_Real-Time_Semantic_Segmentation_CVPR_2019_paper.html">DFANet: Deep Feature Aggregation for Real-Time Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="db9810031d9e20051904f7591d06f6f58b03924f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db9810031d9e20051904f7591d06f6f58b03924f">271</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Unsupervised_Person_Re-Identification_by_Soft_Multilabel_Learning_CVPR_2019_paper.html">Unsupervised Person Re-Identification by Soft Multilabel Learning</a></th>
                    </tr>
                
                    <tr id="0c0eb3040a32484fcb6270841e14b78f284e7570">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c0eb3040a32484fcb6270841e14b78f284e7570">271</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Flynn_DeepView_View_Synthesis_With_Learned_Gradient_Descent_CVPR_2019_paper.html">DeepView: View Synthesis With Learned Gradient Descent</a></th>
                    </tr>
                
                    <tr id="27ff37bd17a5e59149e645184ed4a0c2fb9cf2f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/27ff37bd17a5e59149e645184ed4a0c2fb9cf2f2">266</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Semantic_Graph_Convolutional_Networks_for_3D_Human_Pose_Regression_CVPR_2019_paper.html">Semantic Graph Convolutional Networks for 3D Human Pose Regression</a></th>
                    </tr>
                
                    <tr id="b3ef7cf2083d7fb2f38b05854939183a2a9e6fa2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b3ef7cf2083d7fb2f38b05854939183a2a9e6fa2">265</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ge_3D_Hand_Shape_and_Pose_Estimation_From_a_Single_RGB_CVPR_2019_paper.html">3D Hand Shape and Pose Estimation From a Single RGB Image</a></th>
                    </tr>
                
                    <tr id="97484a4f67958433ecd73653918ee1b8a16b5b2d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/97484a4f67958433ecd73653918ee1b8a16b5b2d">263</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ahn_Weakly_Supervised_Learning_of_Instance_Segmentation_With_Inter-Pixel_Relations_CVPR_2019_paper.html">Weakly Supervised Learning of Instance Segmentation With Inter-Pixel Relations</a></th>
                    </tr>
                
                    <tr id="7336c45f4049f7a7b91a2e57a4b526faa8eced30">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7336c45f4049f7a7b91a2e57a4b526faa8eced30">263</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lee_FickleNet_Weakly_and_Semi-Supervised_Semantic_Image_Segmentation_Using_Stochastic_Inference_CVPR_2019_paper.html">FickleNet: Weakly and Semi-Supervised Semantic Image Segmentation Using Stochastic Inference</a></th>
                    </tr>
                
                    <tr id="ed398138ac89a2b7680ac4db8cff107d35ffb21c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ed398138ac89a2b7680ac4db8cff107d35ffb21c">261</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_FlowNet3D_Learning_Scene_Flow_in_3D_Point_Clouds_CVPR_2019_paper.html">FlowNet3D: Learning Scene Flow in 3D Point Clouds</a></th>
                    </tr>
                
                    <tr id="a8a742c5bc8eb1f64de7e6b37b146f71317a691f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a8a742c5bc8eb1f64de7e6b37b146f71317a691f">259</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Data_Augmentation_Using_Learned_Transformations_for_One-Shot_Medical_Image_Segmentation_CVPR_2019_paper.html">Data Augmentation Using Learned Transformations for One-Shot Medical Image Segmentation</a></th>
                    </tr>
                
                    <tr id="503bafe063e410050c174fcc741e39b3b1e0eb22">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/503bafe063e410050c174fcc741e39b3b1e0eb22">258</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Target-Aware_Deep_Tracking_CVPR_2019_paper.html">Target-Aware Deep Tracking</a></th>
                    </tr>
                
                    <tr id="6c8a56ae495e5c8871061d1cd0f863d174f5e2ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c8a56ae495e5c8871061d1cd0f863d174f5e2ce">258</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Bao_Depth-Aware_Video_Frame_Interpolation_CVPR_2019_paper.html">Depth-Aware Video Frame Interpolation</a></th>
                    </tr>
                
                    <tr id="9b67eec05ed92afed099c73695989c64aa49e3cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9b67eec05ed92afed099c73695989c64aa49e3cd">256</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Barron_A_General_and_Adaptive_Robust_Loss_Function_CVPR_2019_paper.html">A General and Adaptive Robust Loss Function</a></th>
                    </tr>
                
                    <tr id="ee134bac4bdd3a4ab1a5045058d7f9314370cce9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ee134bac4bdd3a4ab1a5045058d7f9314370cce9">256</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hou_3D-SIS_3D_Semantic_Instance_Segmentation_of_RGB-D_Scans_CVPR_2019_paper.html">3D-SIS: 3D Semantic Instance Segmentation of RGB-D Scans</a></th>
                    </tr>
                
                    <tr id="162d660eaaa1eb2144d8030102f3e6be1e80ce50">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/162d660eaaa1eb2144d8030102f3e6be1e80ce50">256</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dusmanu_D2-Net_A_Trainable_CNN_for_Joint_Description_and_Detection_of_CVPR_2019_paper.html">D2-Net: A Trainable CNN for Joint Description and Detection of Local Features</a></th>
                    </tr>
                
                    <tr id="677c05d8c95a269e6004dc899fc44433d345e0e7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/677c05d8c95a269e6004dc899fc44433d345e0e7">255</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Contrast_Prior_and_Fluid_Pyramid_Integration_for_RGBD_Salient_Object_CVPR_2019_paper.html">Contrast Prior and Fluid Pyramid Integration for RGBD Salient Object Detection</a></th>
                    </tr>
                
                    <tr id="e5d761a0ab2b71ce50a32d90580819da911e8f77">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5d761a0ab2b71ce50a32d90580819da911e8f77">254</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deep_Plug-And-Play_Super-Resolution_for_Arbitrary_Blur_Kernels_CVPR_2019_paper.html">Deep Plug-And-Play Super-Resolution for Arbitrary Blur Kernels</a></th>
                    </tr>
                
                    <tr id="50ebb3f8f19154f6e129ca2f04af094cf17b9ad9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50ebb3f8f19154f6e129ca2f04af094cf17b9ad9">254</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Improving_Semantic_Segmentation_via_Video_Propagation_and_Label_Relaxation_CVPR_2019_paper.html">Improving Semantic Segmentation via Video Propagation and Label Relaxation</a></th>
                    </tr>
                
                    <tr id="532ca0ed6f8f1f2814b270d56a6ebe21501af08b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/532ca0ed6f8f1f2814b270d56a6ebe21501af08b">253</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Progressive_Feature_Alignment_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html">Progressive Feature Alignment for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="5d7b39f46548b9c101e970944ce9d869070a96d3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5d7b39f46548b9c101e970944ce9d869070a96d3">252</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gu_Blind_Super-Resolution_With_Iterative_Kernel_Correction_CVPR_2019_paper.html">Blind Super-Resolution With Iterative Kernel Correction</a></th>
                    </tr>
                
                    <tr id="0089d5b7e386ae6fccef17fb3b7df5c33b9588a4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0089d5b7e386ae6fccef17fb3b7df5c33b9588a4">248</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qu_Enhanced_Pix2pix_Dehazing_Network_CVPR_2019_paper.html">Enhanced Pix2pix Dehazing Network</a></th>
                    </tr>
                
                    <tr id="0fa49ec594ad49cee218543d0d1491425801e1a3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0fa49ec594ad49cee218543d0d1491425801e1a3">246</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xiong_UPSNet_A_Unified_Panoptic_Segmentation_Network_CVPR_2019_paper.html">UPSNet: A Unified Panoptic Segmentation Network</a></th>
                    </tr>
                
                    <tr id="7d1ceeea504d98e60b4bad340775e4492fcda40b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7d1ceeea504d98e60b4bad340775e4492fcda40b">246</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Voigtlaender_FEELVOS_Fast_End-To-End_Embedding_Learning_for_Video_Object_Segmentation_CVPR_2019_paper.html">FEELVOS: Fast End-To-End Embedding Learning for Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="821c0d99eec8e2ee312e08b5605924e284b7cc7c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/821c0d99eec8e2ee312e08b5605924e284b7cc7c">244</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Revisiting_Local_Descriptor_Based_Image-To-Class_Measure_for_Few-Shot_Learning_CVPR_2019_paper.html">Revisiting Local Descriptor Based Image-To-Class Measure for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="29c05c8a2f24ddf9572019b396801ad9bb21e884">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/29c05c8a2f24ddf9572019b396801ad9bb21e884">243</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_3D_Point_Capsule_Networks_CVPR_2019_paper.html">3D Point Capsule Networks</a></th>
                    </tr>
                
                    <tr id="b4673e744d0ded47fe6df3b6314f79a41359578b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b4673e744d0ded47fe6df3b6314f79a41359578b">243</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Abu_Farha_MS-TCN_Multi-Stage_Temporal_Convolutional_Network_for_Action_Segmentation_CVPR_2019_paper.html">MS-TCN: Multi-Stage Temporal Convolutional Network for Action Segmentation</a></th>
                    </tr>
                
                    <tr id="7623616066783e73ad29e84885e1b56dbcf39e97">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7623616066783e73ad29e84885e1b56dbcf39e97">243</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_SR-LSTM_State_Refinement_for_LSTM_Towards_Pedestrian_Trajectory_Prediction_CVPR_2019_paper.html">SR-LSTM: State Refinement for LSTM Towards Pedestrian Trajectory Prediction</a></th>
                    </tr>
                
                    <tr id="ab995f96722969a0dfc6dc9139eef4c9b13c0524">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ab995f96722969a0dfc6dc9139eef4c9b13c0524">242</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_DM-GAN_Dynamic_Memory_Generative_Adversarial_Networks_for_Text-To-Image_Synthesis_CVPR_2019_paper.html">DM-GAN: Dynamic Memory Generative Adversarial Networks for Text-To-Image Synthesis</a></th>
                    </tr>
                
                    <tr id="a5c1156c2c8185df4581cf139df05aab66b3bb22">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a5c1156c2c8185df4581cf139df05aab66b3bb22">241</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deep_Stacked_Hierarchical_Multi-Patch_Network_for_Image_Deblurring_CVPR_2019_paper.html">Deep Stacked Hierarchical Multi-Patch Network for Image Deblurring</a></th>
                    </tr>
                
                    <tr id="eb337033885ff9e34f48d6ae0c810ef5b709efbb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eb337033885ff9e34f48d6ae0c810ef5b709efbb">239</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Choe_Attention-Based_Dropout_Layer_for_Weakly_Supervised_Object_Localization_CVPR_2019_paper.html">Attention-Based Dropout Layer for Weakly Supervised Object Localization</a></th>
                    </tr>
                
                    <tr id="f2f0d709394ae1a449819f834dfe92912e1da049">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f2f0d709394ae1a449819f834dfe92912e1da049">239</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_High-Level_Semantic_Feature_Detection_A_New_Perspective_for_Pedestrian_Detection_CVPR_2019_paper.html">High-Level Semantic Feature Detection: A New Perspective for Pedestrian Detection</a></th>
                    </tr>
                
                    <tr id="8b6555c46a2d02e713dbd339e7ac7230ace5193f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b6555c46a2d02e713dbd339e7ac7230ace5193f">237</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Unsupervised_Deep_Tracking_CVPR_2019_paper.html">Unsupervised Deep Tracking</a></th>
                    </tr>
                
                    <tr id="f98be9a91dbf00b52a494720bd36be9c73a1210e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f98be9a91dbf00b52a494720bd36be9c73a1210e">237</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fan_Siamese_Cascaded_Region_Proposal_Networks_for_Real-Time_Visual_Tracking_CVPR_2019_paper.html">Siamese Cascaded Region Proposal Networks for Real-Time Visual Tracking</a></th>
                    </tr>
                
                    <tr id="d3fa312b1f12ee60391705d3cac34cbcad42db14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d3fa312b1f12ee60391705d3cac34cbcad42db14">236</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Spatial_Attentive_Single-Image_Deraining_With_a_High_Quality_Real_Rain_CVPR_2019_paper.html">Spatial Attentive Single-Image Deraining With a High Quality Real Rain Dataset</a></th>
                    </tr>
                
                    <tr id="4e910df41181637518563cf729d3bdaa166882c6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4e910df41181637518563cf729d3bdaa166882c6">236</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Sabir_Recurrent_Convolutional_Strategies_for_Face_Manipulation_Detection_in_Videos_CVPRW_2019_paper.html">Recurrent Convolutional Strategies for Face Manipulation Detection in Videos</a></th>
                    </tr>
                
                    <tr id="3cd3f1585ced02cbb56a9e1428176a6c2b211da2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3cd3f1585ced02cbb56a9e1428176a6c2b211da2">235</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jung_Learning_to_Quantize_Deep_Networks_by_Optimizing_Quantization_Intervals_With_CVPR_2019_paper.html">Learning to Quantize Deep Networks by Optimizing Quantization Intervals With Task Loss</a></th>
                    </tr>
                
                    <tr id="089c6224cfbcf5c18b63564eb65001c7c42a7acf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/089c6224cfbcf5c18b63564eb65001c7c42a7acf">235</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Orekondy_Knockoff_Nets_Stealing_Functionality_of_Black-Box_Models_CVPR_2019_paper.html">Knockoff Nets: Stealing Functionality of Black-Box Models</a></th>
                    </tr>
                
                    <tr id="91b33e7a08fa030abf7ba550972b6f4944d9b7cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/91b33e7a08fa030abf7ba550972b6f4944d9b7cc">235</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_CANet_Class-Agnostic_Segmentation_Networks_With_Iterative_Refinement_and_Attentive_Few-Shot_CVPR_2019_paper.html">CANet: Class-Agnostic Segmentation Networks With Iterative Refinement and Attentive Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="58b4cf057bdd361be289601ef3dd69b4efbef83e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/58b4cf057bdd361be289601ef3dd69b4efbef83e">233</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yi_Probabilistic_End-To-End_Noise_Correction_for_Learning_With_Noisy_Labels_CVPR_2019_paper.html">Probabilistic End-To-End Noise Correction for Learning With Noisy Labels</a></th>
                    </tr>
                
                    <tr id="c814fa74ed76a761fd71f5d9c9eadde15a5af249">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c814fa74ed76a761fd71f5d9c9eadde15a5af249">232</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Guo_Group-Wise_Correlation_Stereo_Network_CVPR_2019_paper.html">Group-Wise Correlation Stereo Network</a></th>
                    </tr>
                
                    <tr id="d468363414b9ec6507ff24cbeefecb4828f52f6b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d468363414b9ec6507ff24cbeefecb4828f52f6b">231</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_Learning_Pyramid-Context_Encoder_Network_for_High-Quality_Image_Inpainting_CVPR_2019_paper.html">Learning Pyramid-Context Encoder Network for High-Quality Image Inpainting</a></th>
                    </tr>
                
                    <tr id="72d9c9e196e509344cb1f5d13c73f68e21718814">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/72d9c9e196e509344cb1f5d13c73f68e21718814">231</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Transferrable_Prototypical_Networks_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html">Transferrable Prototypical Networks for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="e8874d7d585ae1c355e186efdcc9f704b3d43b49">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e8874d7d585ae1c355e186efdcc9f704b3d43b49">231</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fukui_Attention_Branch_Network_Learning_of_Attention_Mechanism_for_Visual_Explanation_CVPR_2019_paper.html">Attention Branch Network: Learning of Attention Mechanism for Visual Explanation</a></th>
                    </tr>
                
                    <tr id="2f6a6cc8d3763ca4d2e34f4b38738ff722216383">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2f6a6cc8d3763ca4d2e34f4b38738ff722216383">230</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Finding_Task-Relevant_Features_for_Few-Shot_Learning_by_Category_Traversal_CVPR_2019_paper.html">Finding Task-Relevant Features for Few-Shot Learning by Category Traversal</a></th>
                    </tr>
                
                    <tr id="7a7954f4989ebfbaf1f311e988c1ef05ba424738">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a7954f4989ebfbaf1f311e988c1ef05ba424738">230</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_DSFD_Dual_Shot_Face_Detector_CVPR_2019_paper.html">DSFD: Dual Shot Face Detector</a></th>
                    </tr>
                
                    <tr id="c947c89c4a709ad27fe4590294589196642b0214">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c947c89c4a709ad27fe4590294589196642b0214">230</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Destruction_and_Construction_Learning_for_Fine-Grained_Image_Recognition_CVPR_2019_paper.html">Destruction and Construction Learning for Fine-Grained Image Recognition</a></th>
                    </tr>
                
                    <tr id="15c7357994e92b5f617da1c6f1220f5251166890">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15c7357994e92b5f617da1c6f1220f5251166890">229</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_CrowdPose_Efficient_Crowded_Scenes_Pose_Estimation_and_a_New_Benchmark_CVPR_2019_paper.html">CrowdPose: Efficient Crowded Scenes Pose Estimation and a New Benchmark</a></th>
                    </tr>
                
                    <tr id="e8abbf36087d293a3426e2859bdef5f17397f2d7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e8abbf36087d293a3426e2859bdef5f17397f2d7">228</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Understanding_the_Disharmony_Between_Dropout_and_Batch_Normalization_by_Variance_CVPR_2019_paper.html">Understanding the Disharmony Between Dropout and Batch Normalization by Variance Shift</a></th>
                    </tr>
                
                    <tr id="7d2da48f8004f94ec80cea005c3713f514394f60">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7d2da48f8004f94ec80cea005c3713f514394f60">227</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gojcic_The_Perfect_Match_3D_Point_Cloud_Matching_With_Smoothed_Densities_CVPR_2019_paper.html">The Perfect Match: 3D Point Cloud Matching With Smoothed Densities</a></th>
                    </tr>
                
                    <tr id="284f61bb7cec6aa93f2f39482e0a016c2acfa597">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/284f61bb7cec6aa93f2f39482e0a016c2acfa597">227</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xiang_Monocular_Total_Capture_Posing_Face_Body_and_Hands_in_the_CVPR_2019_paper.html">Monocular Total Capture: Posing Face, Body, and Hands in the Wild</a></th>
                    </tr>
                
                    <tr id="a9aee599c8ca734cfdf071830fcd636f60a92fbf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a9aee599c8ca734cfdf071830fcd636f60a92fbf">226</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Adapting_Object_Detectors_via_Selective_Cross-Domain_Alignment_CVPR_2019_paper.html">Adapting Object Detectors via Selective Cross-Domain Alignment</a></th>
                    </tr>
                
                    <tr id="a2e433da83c6e1eb4f4486c900fdfbf1951c4d30">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a2e433da83c6e1eb4f4486c900fdfbf1951c4d30">226</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/You_Universal_Domain_Adaptation_CVPR_2019_paper.html">Universal Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="2e54e38db2b276934d6afce9a0ee9dfae0b03f33">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e54e38db2b276934d6afce9a0ee9dfae0b03f33">226</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yao_Recurrent_MVSNet_for_High-Resolution_Multi-View_Stereo_Depth_Inference_CVPR_2019_paper.html">Recurrent MVSNet for High-Resolution Multi-View Stereo Depth Inference</a></th>
                    </tr>
                
                    <tr id="9be285ae8994b68868b54c16ab355e93adce41ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9be285ae8994b68868b54c16ab355e93adce41ad">225</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tang_CityFlow_A_City-Scale_Benchmark_for_Multi-Target_Multi-Camera_Vehicle_Tracking_and_CVPR_2019_paper.html">CityFlow: A City-Scale Benchmark for Multi-Target Multi-Camera Vehicle Tracking and Re-Identification</a></th>
                    </tr>
                
                    <tr id="6220cac2e0fbebea5c28d9e8b7d399eb5c375357">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6220cac2e0fbebea5c28d9e8b7d399eb5c375357">224</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gecer_GANFIT_Generative_Adversarial_Network_Fitting_for_High_Fidelity_3D_Face_CVPR_2019_paper.html">GANFIT: Generative Adversarial Network Fitting for High Fidelity 3D Face Reconstruction</a></th>
                    </tr>
                
                    <tr id="735ddb8a24aedc27a39d3401de9e942dce4c6983">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/735ddb8a24aedc27a39d3401de9e942dce4c6983">224</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Brooks_Unprocessing_Images_for_Learned_Raw_Denoising_CVPR_2019_paper.html">Unprocessing Images for Learned Raw Denoising</a></th>
                    </tr>
                
                    <tr id="bcba77a81a59dcf0798e538e513d8b15b229634f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bcba77a81a59dcf0798e538e513d8b15b229634f">223</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Haris_Recurrent_Back-Projection_Network_for_Video_Super-Resolution_CVPR_2019_paper.html">Recurrent Back-Projection Network for Video Super-Resolution</a></th>
                    </tr>
                
                    <tr id="a6b242609e4285d8666ca26e0f3b75f1417db9ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a6b242609e4285d8666ca26e0f3b75f1417db9ce">222</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Meta-SR_A_Magnification-Arbitrary_Network_for_Super-Resolution_CVPR_2019_paper.html">Meta-SR: A Magnification-Arbitrary Network for Super-Resolution</a></th>
                    </tr>
                
                    <tr id="e4840bb6d97bb2464288a483e4374ef2a06b1822">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e4840bb6d97bb2464288a483e4374ef2a06b1822">221</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Alldieck_Learning_to_Reconstruct_People_in_Clothing_From_a_Single_RGB_CVPR_2019_paper.html">Learning to Reconstruct People in Clothing From a Single RGB Camera</a></th>
                    </tr>
                
                    <tr id="b05fb9a7d5e3b596325dec6795ce49ec3ac14907">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b05fb9a7d5e3b596325dec6795ce49ec3ac14907">221</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tatarchenko_What_Do_Single-View_3D_Reconstruction_Networks_Learn_CVPR_2019_paper.html">What Do Single-View 3D Reconstruction Networks Learn?</a></th>
                    </tr>
                
                    <tr id="2e4316e7c38373d068f8ff55f26ff83dfc4238b8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e4316e7c38373d068f8ff55f26ff83dfc4238b8">221</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_to_Learn_From_Noisy_Labeled_Data_CVPR_2019_paper.html">Learning to Learn From Noisy Labeled Data</a></th>
                    </tr>
                
                    <tr id="4b4bae07638f988556ec6b8a8f46b514a02841e5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4b4bae07638f988556ec6b8a8f46b514a02841e5">220</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Srinivasan_Pushing_the_Boundaries_of_View_Extrapolation_With_Multiplane_Images_CVPR_2019_paper.html">Pushing the Boundaries of View Extrapolation With Multiplane Images</a></th>
                    </tr>
                
                    <tr id="a0c3a0a2ee00d0e0ca9a65f7b663d22b0be38d98">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a0c3a0a2ee00d0e0ca9a65f7b663d22b0be38d98">220</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_SelFlow_Self-Supervised_Learning_of_Optical_Flow_CVPR_2019_paper.html">SelFlow: Self-Supervised Learning of Optical Flow</a></th>
                    </tr>
                
                    <tr id="e9b13731027418ed38103d1dfc8a70f6881bc684">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e9b13731027418ed38103d1dfc8a70f6881bc684">220</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Dynamic_Fusion_With_Intra-_and_Inter-Modality_Attention_Flow_for_Visual_CVPR_2019_paper.html">Dynamic Fusion With Intra- and Inter-Modality Attention Flow for Visual Question Answering</a></th>
                    </tr>
                
                    <tr id="bdcc60fbc992cf34ad714cad9a327f572c100012">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bdcc60fbc992cf34ad714cad9a327f572c100012">219</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Perceive_Where_to_Focus_Learning_Visibility-Aware_Part-Level_Features_for_Partial_CVPR_2019_paper.html">Perceive Where to Focus: Learning Visibility-Aware Part-Level Features for Partial Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="1ce769ce98175c8bf067acb7bf2dba6d734e4077">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ce769ce98175c8bf067acb7bf2dba6d734e4077">219</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gong_DLOW_Domain_Flow_for_Adaptation_and_Generalization_CVPR_2019_paper.html">DLOW: Domain Flow for Adaptation and Generalization</a></th>
                    </tr>
                
                    <tr id="ae0a728d10e4c61a66021bc02b01e7bdd13030b9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae0a728d10e4c61a66021bc02b01e7bdd13030b9">219</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chang_Domain-Specific_Batch_Normalization_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html">Domain-Specific Batch Normalization for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="06f0fe16fcb8f80bf88746c5ef6d3780531918ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/06f0fe16fcb8f80bf88746c5ef6d3780531918ab">219</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jamal_Task_Agnostic_Meta-Learning_for_Few-Shot_Learning_CVPR_2019_paper.html">Task Agnostic Meta-Learning for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="52b377e589220708c4ec8c4b55dda689d1bb00c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/52b377e589220708c4ec8c4b55dda689d1bb00c4">219</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kreiss_PifPaf_Composite_Fields_for_Human_Pose_Estimation_CVPR_2019_paper.html">PifPaf: Composite Fields for Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="f545fcabdd77a602c893ea16e1201109110005bb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f545fcabdd77a602c893ea16e1201109110005bb">218</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Unsupervised_Event-Based_Learning_of_Optical_Flow_Depth_and_Egomotion_CVPR_2019_paper.html">Unsupervised Event-Based Learning of Optical Flow, Depth, and Egomotion</a></th>
                    </tr>
                
                    <tr id="906b374e53357650477eebb80c6a8896b884b4bf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/906b374e53357650477eebb80c6a8896b884b4bf">218</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xiong_Foreground-Aware_Image_Inpainting_CVPR_2019_paper.html">Foreground-Aware Image Inpainting</a></th>
                    </tr>
                
                    <tr id="073384621e1f469ae2437b8f34a1f8a5de4d7497">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/073384621e1f469ae2437b8f34a1f8a5de4d7497">218</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Multi-Agent_Tensor_Fusion_for_Contextual_Trajectory_Prediction_CVPR_2019_paper.html">Multi-Agent Tensor Fusion for Contextual Trajectory Prediction</a></th>
                    </tr>
                
                    <tr id="b5cc6634724b2238c88bcc324ec01a2c91c1b909">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b5cc6634724b2238c88bcc324ec01a2c91c1b909">218</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_TOUCHDOWN_Natural_Language_Navigation_and_Spatial_Reasoning_in_Visual_Street_CVPR_2019_paper.html">TOUCHDOWN: Natural Language Navigation and Spatial Reasoning in Visual Street Environments</a></th>
                    </tr>
                
                    <tr id="d19356ce442d9c04625b3a253f370feaf00ea6a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d19356ce442d9c04625b3a253f370feaf00ea6a0">217</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_GS3D_An_Efficient_3D_Object_Detection_Framework_for_Autonomous_Driving_CVPR_2019_paper.html">GS3D: An Efficient 3D Object Detection Framework for Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="567dfb6af80f62bbebbdecf46c1d56cc52c32a85">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/567dfb6af80f62bbebbdecf46c1d56cc52c32a85">217</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jiang_Crowd_Counting_and_Density_Estimation_by_Trellis_Encoder-Decoder_Networks_CVPR_2019_paper.html">Crowd Counting and Density Estimation by Trellis Encoder-Decoder Networks</a></th>
                    </tr>
                
                    <tr id="2c9efa87429f5522b755c868f2a3d29897fe43ea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c9efa87429f5522b755c868f2a3d29897fe43ea">217</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Interpreting_CNNs_via_Decision_Trees_CVPR_2019_paper.html">Interpreting CNNs via Decision Trees</a></th>
                    </tr>
                
                    <tr id="af1f7739283bdbd2b7a94903041f6d6afd991907">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/af1f7739283bdbd2b7a94903041f6d6afd991907">217</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Singh_Towards_VQA_Models_That_Can_Read_CVPR_2019_paper.html">Towards VQA Models That Can Read</a></th>
                    </tr>
                
                    <tr id="e425fd5331ad3fee24485bc70bab6fb731e6249f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e425fd5331ad3fee24485bc70bab6fb731e6249f">217</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hasson_Learning_Joint_Reconstruction_of_Hands_and_Manipulated_Objects_CVPR_2019_paper.html">Learning Joint Reconstruction of Hands and Manipulated Objects</a></th>
                    </tr>
                
                    <tr id="c5651aea43997f71891c2cc7694ddf51af95c2c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c5651aea43997f71891c2cc7694ddf51af95c2c0">217</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/Deng_Accurate_3D_Face_Reconstruction_With_Weakly-Supervised_Learning_From_Single_Image_CVPRW_2019_paper.html">Accurate 3D Face Reconstruction With Weakly-Supervised Learning: From Single Image to Image Set</a></th>
                    </tr>
                
                    <tr id="576dd6fd076114b86c108f5364e7f0f2aed21ad7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/576dd6fd076114b86c108f5364e7f0f2aed21ad7">216</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Progressive_Pose_Attention_Transfer_for_Person_Image_Generation_CVPR_2019_paper.html">Progressive Pose Attention Transfer for Person Image Generation</a></th>
                    </tr>
                
                    <tr id="0e96b0a586e3acfcf1602c0e246c04c6080e2315">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e96b0a586e3acfcf1602c0e246c04c6080e2315">215</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Self-Supervised_GANs_via_Auxiliary_Rotation_Loss_CVPR_2019_paper.html">Self-Supervised GANs via Auxiliary Rotation Loss</a></th>
                    </tr>
                
                    <tr id="9e145fc992e983a8d7c193a8933d08532194ae67">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9e145fc992e983a8d7c193a8933d08532194ae67">214</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_CrDoCo_Pixel-Level_Domain_Transfer_With_Cross-Domain_Consistency_CVPR_2019_paper.html">CrDoCo: Pixel-Level Domain Transfer With Cross-Domain Consistency</a></th>
                    </tr>
                
                    <tr id="96c3b2cd463c0dc4ca52ddf9e5f297937dde2be9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96c3b2cd463c0dc4ca52ddf9e5f297937dde2be9">214</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Peeking_Into_the_Future_Predicting_Future_Person_Activities_and_Locations_CVPR_2019_paper.html">Peeking Into the Future: Predicting Future Person Activities and Locations in Videos</a></th>
                    </tr>
                
                    <tr id="96c3b2cd463c0dc4ca52ddf9e5f297937dde2be9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96c3b2cd463c0dc4ca52ddf9e5f297937dde2be9">214</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Precognition/Liang_Peeking_Into_the_Future_Predicting_Future_Person_Activities_and_Locations_CVPRW_2019_paper.html">Peeking Into the Future: Predicting Future Person Activities and Locations in Videos</a></th>
                    </tr>
                
                    <tr id="9a9959260309cd7acfa6b582a5deb33168e0531a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9a9959260309cd7acfa6b582a5deb33168e0531a">213</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Looking_for_the_Devil_in_the_Details_Learning_Trilinear_Attention_CVPR_2019_paper.html">Looking for the Devil in the Details: Learning Trilinear Attention Sampling Network for Fine-Grained Image Recognition</a></th>
                    </tr>
                
                    <tr id="cb4e58d9de165a4fb64eccbe2f4b49c1cd83b650">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cb4e58d9de165a4fb64eccbe2f4b49c1cd83b650">213</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Domain-Symmetric_Networks_for_Adversarial_Domain_Adaptation_CVPR_2019_paper.html">Domain-Symmetric Networks for Adversarial Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="88ec56eee6a787ccda0cf7fbfbec48c6b4ad68fe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/88ec56eee6a787ccda0cf7fbfbec48c6b4ad68fe">213</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tang_Learning_to_Compose_Dynamic_Tree_Structures_for_Visual_Contexts_CVPR_2019_paper.html">Learning to Compose Dynamic Tree Structures for Visual Contexts</a></th>
                    </tr>
                
                    <tr id="e87b5f4c64056431dfc62ebff0f23d9c94252598">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e87b5f4c64056431dfc62ebff0f23d9c94252598">211</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Guo_SpotTune_Transfer_Learning_Through_Adaptive_Fine-Tuning_CVPR_2019_paper.html">SpotTune: Transfer Learning Through Adaptive Fine-Tuning</a></th>
                    </tr>
                
                    <tr id="545e3f4e684f82eaf211bde9558d00a0dad946d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/545e3f4e684f82eaf211bde9558d00a0dad946d2">211</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Pyramidal_Person_Re-IDentification_via_Multi-Loss_Dynamic_Training_CVPR_2019_paper.html">Pyramidal Person Re-IDentification via Multi-Loss Dynamic Training</a></th>
                    </tr>
                
                    <tr id="3ff8dbba650f69b0a9015de40750983545015207">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ff8dbba650f69b0a9015de40750983545015207">210</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Densely_Semantically_Aligned_Person_Re-Identification_CVPR_2019_paper.html">Densely Semantically Aligned Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="b6cf10713451191de8f0d30211f85a1080249a74">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b6cf10713451191de8f0d30211f85a1080249a74">209</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tchapmi_TopNet_Structural_Point_Cloud_Decoder_CVPR_2019_paper.html">TopNet: Structural Point Cloud Decoder</a></th>
                    </tr>
                
                    <tr id="b79fe48ae523dc66185aa04df2dac7041afa8683">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b79fe48ae523dc66185aa04df2dac7041afa8683">209</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Learning_Not_to_Learn_Training_Deep_Neural_Networks_With_Biased_CVPR_2019_paper.html">Learning Not to Learn: Training Deep Neural Networks With Biased Data</a></th>
                    </tr>
                
                    <tr id="b39eec4d962bb1cae0156af6d7f34c1b6302dc51">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b39eec4d962bb1cae0156af6d7f34c1b6302dc51">208</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Variational_Convolutional_Neural_Network_Pruning_CVPR_2019_paper.html">Variational Convolutional Neural Network Pruning</a></th>
                    </tr>
                
                    <tr id="8f1379c4f8901098a191e35c5543b312e569d68f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f1379c4f8901098a191e35c5543b312e569d68f">208</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sattler_Understanding_the_Limitations_of_CNN-Based_Absolute_Camera_Pose_Regression_CVPR_2019_paper.html">Understanding the Limitations of CNN-Based Absolute Camera Pose Regression</a></th>
                    </tr>
                
                    <tr id="edce7f037c840b7db2612f47c35ae374c4a80e3a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/edce7f037c840b7db2612f47c35ae374c4a80e3a">207</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Siarohin_Animating_Arbitrary_Objects_via_Deep_Motion_Transfer_CVPR_2019_paper.html">Animating Arbitrary Objects via Deep Motion Transfer</a></th>
                    </tr>
                
                    <tr id="5ae786deaa875613e85ed2df0dbeec4301109f74">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5ae786deaa875613e85ed2df0dbeec4301109f74">206</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Moosavi-Dezfooli_Robustness_via_Curvature_Regularization_and_Vice_Versa_CVPR_2019_paper.html">Robustness via Curvature Regularization, and Vice Versa</a></th>
                    </tr>
                
                    <tr id="845059251af37baa6b6bc2f497916f0b703bd2b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/845059251af37baa6b6bc2f497916f0b703bd2b1">205</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Karlinsky_RepMet_Representative-Based_Metric_Learning_for_Classification_and_Few-Shot_Object_Detection_CVPR_2019_paper.html">RepMet: Representative-Based Metric Learning for Classification and Few-Shot Object Detection</a></th>
                    </tr>
                
                    <tr id="162a4c6f964880ec90b40fefa6d4d99d3ad321ec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/162a4c6f964880ec90b40fefa6d4d99d3ad321ec">204</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dhar_Learning_Without_Memorizing_CVPR_2019_paper.html">Learning Without Memorizing</a></th>
                    </tr>
                
                    <tr id="4a75cda9341bbdcb9f370181e664508c66aee5d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4a75cda9341bbdcb9f370181e664508c66aee5d4">204</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Efficient_Decision-Based_Black-Box_Adversarial_Attacks_on_Face_Recognition_CVPR_2019_paper.html">Efficient Decision-Based Black-Box Adversarial Attacks on Face Recognition</a></th>
                    </tr>
                
                    <tr id="0a0262328b74b6f59d3d85c0ad2606977af1a22a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a0262328b74b6f59d3d85c0ad2606977af1a22a">204</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mehta_ESPNetv2_A_Light-Weight_Power_Efficient_and_General_Purpose_Convolutional_Neural_CVPR_2019_paper.html">ESPNetv2: A Light-Weight, Power Efficient, and General Purpose Convolutional Neural Network</a></th>
                    </tr>
                
                    <tr id="fc5cb771ef25ed57e4902cf86433db906cdbbc39">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc5cb771ef25ed57e4902cf86433db906cdbbc39">204</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Object-Driven_Text-To-Image_Synthesis_via_Adversarial_Training_CVPR_2019_paper.html">Object-Driven Text-To-Image Synthesis via Adversarial Training</a></th>
                    </tr>
                
                    <tr id="0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a9f1a1321958df7dfb2efce3e9d1e99b9f5ccb3">203</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cadene_MUREL_Multimodal_Relational_Reasoning_for_Visual_Question_Answering_CVPR_2019_paper.html">MUREL: Multimodal Relational Reasoning for Visual Question Answering</a></th>
                    </tr>
                
                    <tr id="e156df0fa6b119dd70216a12b15ff9e2ab9b68e7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e156df0fa6b119dd70216a12b15ff9e2ab9b68e7">202</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yi_GSPN_Generative_Shape_Proposal_Network_for_3D_Instance_Segmentation_in_CVPR_2019_paper.html">GSPN: Generative Shape Proposal Network for 3D Instance Segmentation in Point Cloud</a></th>
                    </tr>
                
                    <tr id="207c073e427ff50b72a3f53975f5c6251551c4cb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/207c073e427ff50b72a3f53975f5c6251551c4cb">201</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Alcorn_Strike_With_a_Pose_Neural_Networks_Are_Easily_Fooled_by_CVPR_2019_paper.html">Strike (With) a Pose: Neural Networks Are Easily Fooled by Strange Poses of Familiar Objects</a></th>
                    </tr>
                
                    <tr id="cc10e4659cb72ef719414cdfc0e3c38a97f9c650">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cc10e4659cb72ef719414cdfc0e3c38a97f9c650">201</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tay_AANet_Attribute_Attention_Network_for_Person_Re-Identifications_CVPR_2019_paper.html">AANet: Attribute Attention Network for Person Re-Identifications</a></th>
                    </tr>
                
                    <tr id="6ab21bdffa91fa2460e7f8f8bb8f756abb29484e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6ab21bdffa91fa2460e7f8f8bb8f756abb29484e">200</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Co-Occurrent_Features_in_Semantic_Segmentation_CVPR_2019_paper.html">Co-Occurrent Features in Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="c256c0fca1f0f6de240743164ae729da3a29fc81">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c256c0fca1f0f6de240743164ae729da3a29fc81">200</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Modeling_Point_Clouds_With_Self-Attention_and_Gumbel_Subset_Sampling_CVPR_2019_paper.html">Modeling Point Clouds With Self-Attention and Gumbel Subset Sampling</a></th>
                    </tr>
                
                    <tr id="740db108d536a8b6f53111407898f4ecaecf80ea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/740db108d536a8b6f53111407898f4ecaecf80ea">199</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gu_Scene_Graph_Generation_With_External_Knowledge_and_Image_Reconstruction_CVPR_2019_paper.html">Scene Graph Generation With External Knowledge and Image Reconstruction</a></th>
                    </tr>
                
                    <tr id="c34e2e3c6bacbe59a175adc20ac7906f9f53b280">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c34e2e3c6bacbe59a175adc20ac7906f9f53b280">199</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhan_ESIR_End-To-End_Scene_Text_Recognition_via_Iterative_Image_Rectification_CVPR_2019_paper.html">ESIR: End-To-End Scene Text Recognition via Iterative Image Rectification</a></th>
                    </tr>
                
                    <tr id="8b4765c33816247cfea7458c3664d162fc044534">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b4765c33816247cfea7458c3664d162fc044534">198</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qiu_DeepLiDAR_Deep_Surface_Normal_Guided_Depth_Prediction_for_Outdoor_Scene_CVPR_2019_paper.html">DeepLiDAR: Deep Surface Normal Guided Depth Prediction for Outdoor Scene From Sparse LiDAR Data and Single Color Image</a></th>
                    </tr>
                
                    <tr id="10cb36f95b6f56b70c1f01bf8f73bbae11c9b2f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/10cb36f95b6f56b70c1f01bf8f73bbae11c9b2f1">197</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Long_Gaussian_Temporal_Awareness_Networks_for_Action_Localization_CVPR_2019_paper.html">Gaussian Temporal Awareness Networks for Action Localization</a></th>
                    </tr>
                
                    <tr id="6d4d26a0444d8047b2aaa867ebef338345be9732">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6d4d26a0444d8047b2aaa867ebef338345be9732">197</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kocabas_Self-Supervised_Learning_of_3D_Human_Pose_Using_Multi-View_Geometry_CVPR_2019_paper.html">Self-Supervised Learning of 3D Human Pose Using Multi-View Geometry</a></th>
                    </tr>
                
                    <tr id="f1990e7c690e9731a350851506a598fa8d279ba0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f1990e7c690e9731a350851506a598fa8d279ba0">194</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Attention-Guided_Unified_Network_for_Panoptic_Segmentation_CVPR_2019_paper.html">Attention-Guided Unified Network for Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="cb2d9b2f171da67f7b47ac3e0eb935a0de223354">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cb2d9b2f171da67f7b47ac3e0eb935a0de223354">194</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pope_Explainability_Methods_for_Graph_Convolutional_Neural_Networks_CVPR_2019_paper.html">Explainability Methods for Graph Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="8f61c28cd63372e03e303714f3cb726ad79a6d62">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f61c28cd63372e03e303714f3cb726ad79a6d62">194</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kampffmeyer_Rethinking_Knowledge_Graph_Propagation_for_Zero-Shot_Learning_CVPR_2019_paper.html">Rethinking Knowledge Graph Propagation for Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="e6c278ea0e66a0b62b5a0fa6298d2e7fbd9ec8bf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e6c278ea0e66a0b62b5a0fa6298d2e7fbd9ec8bf">194</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Meyer_LaserNet_An_Efficient_Probabilistic_3D_Object_Detector_for_Autonomous_Driving_CVPR_2019_paper.html">LaserNet: An Efficient Probabilistic 3D Object Detector for Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="1a8817eea8388580124eee61544fba183904fb29">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a8817eea8388580124eee61544fba183904fb29">193</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_End-To-End_Interpretable_Neural_Motion_Planner_CVPR_2019_paper.html">End-To-End Interpretable Neural Motion Planner</a></th>
                    </tr>
                
                    <tr id="f907826ba0d64dc3bc385088a30e5a492482bc2c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f907826ba0d64dc3bc385088a30e5a492482bc2c">192</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_ADCrowdNet_An_Attention-Injective_Deformable_Convolutional_Network_for_Crowd_Understanding_CVPR_2019_paper.html">ADCrowdNet: An Attention-Injective Deformable Convolutional Network for Crowd Understanding</a></th>
                    </tr>
                
                    <tr id="4ecb1adad81d4ad7cac8908f464d21b2f441e868">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ecb1adad81d4ad7cac8908f464d21b2f441e868">192</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_STGAN_A_Unified_Selective_Transfer_Network_for_Arbitrary_Image_Attribute_CVPR_2019_paper.html">STGAN: A Unified Selective Transfer Network for Arbitrary Image Attribute Editing</a></th>
                    </tr>
                
                    <tr id="2e49d98756868c52dcb37e32a10533c361fbab89">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e49d98756868c52dcb37e32a10533c361fbab89">192</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ge_DeepFashion2_A_Versatile_Benchmark_for_Detection_Pose_Estimation_Segmentation_and_CVPR_2019_paper.html">DeepFashion2: A Versatile Benchmark for Detection, Pose Estimation, Segmentation and Re-Identification of Clothing Images</a></th>
                    </tr>
                
                    <tr id="b7f364584df189977a2f15999eeaf66d062a5267">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b7f364584df189977a2f15999eeaf66d062a5267">192</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Koch_ABC_A_Big_CAD_Model_Dataset_for_Geometric_Deep_Learning_CVPR_2019_paper.html">ABC: A Big CAD Model Dataset for Geometric Deep Learning</a></th>
                    </tr>
                
                    <tr id="a03bda078490e8ee991a1f86b53f27df7cf93a14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a03bda078490e8ee991a1f86b53f27df7cf93a14">191</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhong_Graph_Convolutional_Label_Noise_Cleaner_Train_a_Plug-And-Play_Action_Classifier_CVPR_2019_paper.html">Graph Convolutional Label Noise Cleaner: Train a Plug-And-Play Action Classifier for Anomaly Detection</a></th>
                    </tr>
                
                    <tr id="f9f420484ea9ec40f0eb4e2048798d3b0cbcb272">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f9f420484ea9ec40f0eb4e2048798d3b0cbcb272">191</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Boukhayma_3D_Hand_Shape_and_Pose_From_Images_in_the_Wild_CVPR_2019_paper.html">3D Hand Shape and Pose From Images in the Wild</a></th>
                    </tr>
                
                    <tr id="9a9dcc604321dd2dda93c3ad268e554b7f2b356e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9a9dcc604321dd2dda93c3ad268e554b7f2b356e">191</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dai_ChamNet_Towards_Efficient_Network_Design_Through_Platform-Aware_Model_Adaptation_CVPR_2019_paper.html">ChamNet: Towards Efficient Network Design Through Platform-Aware Model Adaptation</a></th>
                    </tr>
                
                    <tr id="613f59279586bd53aed57bc133246a4eb3c38977">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/613f59279586bd53aed57bc133246a4eb3c38977">190</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_MAN_Moment_Alignment_Network_for_Natural_Language_Moment_Retrieval_via_CVPR_2019_paper.html">MAN: Moment Alignment Network for Natural Language Moment Retrieval via Iterative Graph Adjustment</a></th>
                    </tr>
                
                    <tr id="57eedf785fd9e3ea28b4cd30539cb0fa374f9e74">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/57eedf785fd9e3ea28b4cd30539cb0fa374f9e74">189</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Characterizing_and_Avoiding_Negative_Transfer_CVPR_2019_paper.html">Characterizing and Avoiding Negative Transfer</a></th>
                    </tr>
                
                    <tr id="24cfdfff5e2794600b018e867ddbf07d80467dec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/24cfdfff5e2794600b018e867ddbf07d80467dec">189</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Nah_NTIRE_2019_Challenge_on_Video_Deblurring_and_Super-Resolution_Dataset_and_CVPRW_2019_paper.html">NTIRE 2019 Challenge on Video Deblurring and Super-Resolution: Dataset and Study</a></th>
                    </tr>
                
                    <tr id="e5820233ea8abd27c81c0a83b1b782a9d4ca8db2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5820233ea8abd27c81c0a83b1b782a9d4ca8db2">188</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dai_Visual_Tracking_via_Adaptive_Spatially-Regularized_Correlation_Filters_CVPR_2019_paper.html">Visual Tracking via Adaptive Spatially-Regularized Correlation Filters</a></th>
                    </tr>
                
                    <tr id="6338628d7499b3a438f92b01b05d7a621e80b29c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6338628d7499b3a438f92b01b05d7a621e80b29c">187</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Manhardt_ROI-10D_Monocular_Lifting_of_2D_Detection_to_6D_Pose_and_CVPR_2019_paper.html">ROI-10D: Monocular Lifting of 2D Detection to 6D Pose and Metric Shape</a></th>
                    </tr>
                
                    <tr id="76a129a7451f0e91c14caae8acfa2ad29d96fb53">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/76a129a7451f0e91c14caae8acfa2ad29d96fb53">186</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Rony_Decoupling_Direction_and_Norm_for_Efficient_Gradient-Based_L2_Adversarial_Attacks_CVPR_2019_paper.html">Decoupling Direction and Norm for Efficient Gradient-Based L2 Adversarial Attacks and Defenses</a></th>
                    </tr>
                
                    <tr id="64bd7b8297495af6971cfbb92e17f06d01bab146">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/64bd7b8297495af6971cfbb92e17f06d01bab146">185</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Leveraging_the_Invariant_Side_of_Generative_Zero-Shot_Learning_CVPR_2019_paper.html">Leveraging the Invariant Side of Generative Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="27f197e0401b854d14a41829e09209e38fe920b6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/27f197e0401b854d14a41829e09209e38fe920b6">185</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zou_A_Sufficient_Condition_for_Convergences_of_Adam_and_RMSProp_CVPR_2019_paper.html">A Sufficient Condition for Convergences of Adam and RMSProp</a></th>
                    </tr>
                
                    <tr id="a5f782f08ae8df9b9926200fdc5adbe99565513a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a5f782f08ae8df9b9926200fdc5adbe99565513a">184</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Global_Second-Order_Pooling_Convolutional_Networks_CVPR_2019_paper.html">Global Second-Order Pooling Convolutional Networks</a></th>
                    </tr>
                
                    <tr id="beb335e43da1f518ed7df3a851784925254a6a94">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/beb335e43da1f518ed7df3a851784925254a6a94">183</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Knowledge-Embedded_Routing_Network_for_Scene_Graph_Generation_CVPR_2019_paper.html">Knowledge-Embedded Routing Network for Scene Graph Generation</a></th>
                    </tr>
                
                    <tr id="3636d3f0562f3ab5f5df68c1c9a23530c0fbce64">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3636d3f0562f3ab5f5df68c1c9a23530c0fbce64">182</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Parametric_Noise_Injection_Trainable_Randomness_to_Improve_Deep_Neural_Network_CVPR_2019_paper.html">Parametric Noise Injection: Trainable Randomness to Improve Deep Neural Network Robustness Against Adversarial Attack</a></th>
                    </tr>
                
                    <tr id="01857c101bf51334f5d28f1288618e2cedf97124">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01857c101bf51334f5d28f1288618e2cedf97124">182</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lu_Grid_R-CNN_CVPR_2019_paper.html">Grid R-CNN</a></th>
                    </tr>
                
                    <tr id="8fcd7301470e352b550d6b097f379356c9c1a89c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8fcd7301470e352b550d6b097f379356c9c1a89c">181</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Towards_Rich_Feature_Discovery_With_Class_Activation_Maps_Augmentation_for_CVPR_2019_paper.html">Towards Rich Feature Discovery With Class Activation Maps Augmentation for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="cca9d893b9ce6f21e2565442680690b99c74fa8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cca9d893b9ce6f21e2565442680690b99c74fa8f">181</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hou_Interaction-And-Aggregation_Network_for_Person_Re-Identification_CVPR_2019_paper.html">Interaction-And-Aggregation Network for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="58ef41c5736edc7edc445fcff79914dce03d7ec3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/58ef41c5736edc7edc445fcff79914dce03d7ec3">181</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Orsic_In_Defense_of_Pre-Trained_ImageNet_Architectures_for_Real-Time_Semantic_Segmentation_CVPR_2019_paper.html">In Defense of Pre-Trained ImageNet Architectures for Real-Time Semantic Segmentation of Road-Driving Images</a></th>
                    </tr>
                
                    <tr id="28ad018c39d1578bea84e7cedf94459e3dbe1e70">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/28ad018c39d1578bea84e7cedf94459e3dbe1e70">180</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Marino_OK-VQA_A_Visual_Question_Answering_Benchmark_Requiring_External_Knowledge_CVPR_2019_paper.html">OK-VQA: A Visual Question Answering Benchmark Requiring External Knowledge</a></th>
                    </tr>
                
                    <tr id="278b2fee8ca1b638e234391b583665dab37bc62b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/278b2fee8ca1b638e234391b583665dab37bc62b">180</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Revisiting_Perspective_Information_for_Efficient_Crowd_Counting_CVPR_2019_paper.html">Revisiting Perspective Information for Efficient Crowd Counting</a></th>
                    </tr>
                
                    <tr id="e5dfe7efff8c8032bc84ee0a7e0bd930218ce997">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5dfe7efff8c8032bc84ee0a7e0bd930218ce997">179</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cao_Learning_to_Transfer_Examples_for_Partial_Domain_Adaptation_CVPR_2019_paper.html">Learning to Transfer Examples for Partial Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="c58a3c67f34b83146acab4cee21c062f08b02475">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c58a3c67f34b83146acab4cee21c062f08b02475">179</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Diversify_and_Match_A_Domain_Adaptive_Representation_Learning_Paradigm_for_CVPR_2019_paper.html">Diversify and Match: A Domain Adaptive Representation Learning Paradigm for Object Detection</a></th>
                    </tr>
                
                    <tr id="3f9c2de56950ece198bb6e550e8ab87242d7b256">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f9c2de56950ece198bb6e550e8ab87242d7b256">177</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_to_Reduce_Dual-Level_Discrepancy_for_Infrared-Visible_Person_Re-Identification_CVPR_2019_paper.html">Learning to Reduce Dual-Level Discrepancy for Infrared-Visible Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="fad53f59a3a3803838c50f331de8865e4385d87e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fad53f59a3a3803838c50f331de8865e4385d87e">177</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Generative_Dual_Adversarial_Network_for_Generalized_Zero-Shot_Learning_CVPR_2019_paper.html">Generative Dual Adversarial Network for Generalized Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="3b656bba99dbcf6c6d8fd764d53ea64cd38c7050">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3b656bba99dbcf6c6d8fd764d53ea64cd38c7050">177</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Nixon_Measuring_Calibration_in_Deep_Learning_CVPRW_2019_paper.html">Measuring Calibration in Deep Learning</a></th>
                    </tr>
                
                    <tr id="c4e08cc529520db05618df152ca1adc1f35ef7e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c4e08cc529520db05618df152ca1adc1f35ef7e3">176</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cakir_Deep_Metric_Learning_to_Rank_CVPR_2019_paper.html">Deep Metric Learning to Rank</a></th>
                    </tr>
                
                    <tr id="8fbf011af21921a553bd8b20cd6eb16897f07801">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8fbf011af21921a553bd8b20cd6eb16897f07801">176</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Gupta_Creating_xBD_A_Dataset_for_Assessing_Building_Damage_from_Satellite_CVPRW_2019_paper.html">Creating xBD: A Dataset for Assessing Building Damage from Satellite Imagery</a></th>
                    </tr>
                
                    <tr id="4732ef442a5d0f2ec77600ddd44aaa288a043ace">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4732ef442a5d0f2ec77600ddd44aaa288a043ace">175</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gidaris_Generating_Classification_Weights_With_GNN_Denoising_Autoencoders_for_Few-Shot_Learning_CVPR_2019_paper.html">Generating Classification Weights With GNN Denoising Autoencoders for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="60f791a926ed64830736d3d25ae0dbd89e60671d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/60f791a926ed64830736d3d25ae0dbd89e60671d">175</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Adaptive_Pyramid_Context_Network_for_Semantic_Segmentation_CVPR_2019_paper.html">Adaptive Pyramid Context Network for Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="e8b3f70d99b47a83fd0c8f7ce589a7a4ae3f2f25">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e8b3f70d99b47a83fd0c8f7ce589a7a4ae3f2f25">175</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Neven_Instance_Segmentation_by_Jointly_Optimizing_Spatial_Embeddings_and_Clustering_Bandwidth_CVPR_2019_paper.html">Instance Segmentation by Jointly Optimizing Spatial Embeddings and Clustering Bandwidth</a></th>
                    </tr>
                
                    <tr id="69455376f5ad52cac5b72d5e8c6cf03fb466b55c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/69455376f5ad52cac5b72d5e8c6cf03fb466b55c">175</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Cross-Modal_Self-Attention_Network_for_Referring_Image_Segmentation_CVPR_2019_paper.html">Cross-Modal Self-Attention Network for Referring Image Segmentation</a></th>
                    </tr>
                
                    <tr id="e5af12221bf36a7b0f8a974125e1dcafc25b4d3a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5af12221bf36a7b0f8a974125e1dcafc25b4d3a">174</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Komarichev_A-CNN_Annularly_Convolutional_Neural_Networks_on_Point_Clouds_CVPR_2019_paper.html">A-CNN: Annularly Convolutional Neural Networks on Point Clouds</a></th>
                    </tr>
                
                    <tr id="ed6e68a1b3569e21c6681849643279f82b962bbf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ed6e68a1b3569e21c6681849643279f82b962bbf">172</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chang_All_About_Structure_Adapting_Structural_Information_Across_Domains_for_Boosting_CVPR_2019_paper.html">All About Structure: Adapting Structural Information Across Domains for Boosting Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="2e94e9f3bea847239e8653be10f287d1c74bc4ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e94e9f3bea847239e8653be10f287d1c74bc4ac">171</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Heavy_Rain_Image_Restoration_Integrating_Physics_Model_and_Conditional_Adversarial_CVPR_2019_paper.html">Heavy Rain Image Restoration: Integrating Physics Model and Conditional Adversarial Learning</a></th>
                    </tr>
                
                    <tr id="2faf72ee3ff950009a10020f720db336bf5e63a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2faf72ee3ff950009a10020f720db336bf5e63a0">171</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_AET_vs._AED_Unsupervised_Representation_Learning_by_Auto-Encoding_Transformations_Rather_CVPR_2019_paper.html">AET vs. AED: Unsupervised Representation Learning by Auto-Encoding Transformations Rather Than Data</a></th>
                    </tr>
                
                    <tr id="8bcd98bd5a451c2bbde4a22a4d1affe3c6407af0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8bcd98bd5a451c2bbde4a22a4d1affe3c6407af0">171</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Stutz_Disentangling_Adversarial_Robustness_and_Generalization_CVPR_2019_paper.html">Disentangling Adversarial Robustness and Generalization</a></th>
                    </tr>
                
                    <tr id="a58468dace1b8654f4ab5a92411ad3c76998c280">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a58468dace1b8654f4ab5a92411ad3c76998c280">170</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Dynamic_Scene_Deblurring_With_Parameter_Selective_Sharing_and_Nested_Skip_CVPR_2019_paper.html">Dynamic Scene Deblurring With Parameter Selective Sharing and Nested Skip Connections</a></th>
                    </tr>
                
                    <tr id="4cbaea4c21e15312ef2aeb9529a39baa48bbb522">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4cbaea4c21e15312ef2aeb9529a39baa48bbb522">170</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ghadiyaram_Large-Scale_Weakly-Supervised_Pre-Training_for_Video_Action_Recognition_CVPR_2019_paper.html">Large-Scale Weakly-Supervised Pre-Training for Video Action Recognition</a></th>
                    </tr>
                
                    <tr id="3d46d366d060ed799fd62e1c1bf6b3b160bef0dc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3d46d366d060ed799fd62e1c1bf6b3b160bef0dc">169</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Adaptive_Transfer_Network_for_Cross-Domain_Person_Re-Identification_CVPR_2019_paper.html">Adaptive Transfer Network for Cross-Domain Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="b32ada2aab1e76ba3d0125c7a15615a531c6ce88">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b32ada2aab1e76ba3d0125c7a15615a531c6ce88">169</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gandelsman_Double-DIP_Unsupervised_Image_Decomposition_via_Coupled_Deep-Image-Priors_CVPR_2019_paper.html">&#34;Double-DIP&#34;: Unsupervised Image Decomposition via Coupled Deep-Image-Priors</a></th>
                    </tr>
                
                    <tr id="a30b2a1b9080354bb507954d1ed87ad325a46c86">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a30b2a1b9080354bb507954d1ed87ad325a46c86">168</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Semi-Supervised_Transfer_Learning_for_Image_Rain_Removal_CVPR_2019_paper.html">Semi-Supervised Transfer Learning for Image Rain Removal</a></th>
                    </tr>
                
                    <tr id="cc6a32280064b061c6ca53467e2d5fb11dcce5c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cc6a32280064b061c6ca53467e2d5fb11dcce5c4">168</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_the_Depths_of_Moving_People_by_Watching_Frozen_People_CVPR_2019_paper.html">Learning the Depths of Moving People by Watching Frozen People</a></th>
                    </tr>
                
                    <tr id="5313367e0a350f3e0b632dfb2e588f63fc272b2b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5313367e0a350f3e0b632dfb2e588f63fc272b2b">168</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yin_Feature_Transfer_Learning_for_Face_Recognition_With_Under-Represented_Data_CVPR_2019_paper.html">Feature Transfer Learning for Face Recognition With Under-Represented Data</a></th>
                    </tr>
                
                    <tr id="cf9d7f064a702f165ad8b24b41898cb3a74eb24f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cf9d7f064a702f165ad8b24b41898cb3a74eb24f">166</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ge_Weakly_Supervised_Complementary_Parts_Models_for_Fine-Grained_Image_Classification_From_CVPR_2019_paper.html">Weakly Supervised Complementary Parts Models for Fine-Grained Image Classification From the Bottom Up</a></th>
                    </tr>
                
                    <tr id="e7b7d97042ad2fdf3a7238a724c9dc3195537bea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e7b7d97042ad2fdf3a7238a724c9dc3195537bea">166</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ionescu_Object-Centric_Auto-Encoders_and_Dummy_Anomalies_for_Abnormal_Event_Detection_in_CVPR_2019_paper.html">Object-Centric Auto-Encoders and Dummy Anomalies for Abnormal Event Detection in Video</a></th>
                    </tr>
                
                    <tr id="303108725216724ca07167da5580ba4783d12bcc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/303108725216724ca07167da5580ba4783d12bcc">166</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ku_Monocular_3D_Object_Detection_Leveraging_Accurate_Proposals_and_Shape_Reconstruction_CVPR_2019_paper.html">Monocular 3D Object Detection Leveraging Accurate Proposals and Shape Reconstruction</a></th>
                    </tr>
                
                    <tr id="967d532a66dab7edcb818b0f9dc59fe8da7dc171">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/967d532a66dab7edcb818b0f9dc59fe8da7dc171">164</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Oza_C2AE_Class_Conditioned_Auto-Encoder_for_Open-Set_Recognition_CVPR_2019_paper.html">C2AE: Class Conditioned Auto-Encoder for Open-Set Recognition</a></th>
                    </tr>
                
                    <tr id="8ca91ad7763be4da05238aa17a9e5628f619dc0b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8ca91ad7763be4da05238aa17a9e5628f619dc0b">163</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Neighbourhood_Watch_Referring_Expression_Comprehension_via_Language-Guided_Graph_Attention_Networks_CVPR_2019_paper.html">Neighbourhood Watch: Referring Expression Comprehension via Language-Guided Graph Attention Networks</a></th>
                    </tr>
                
                    <tr id="98333bedec446377cac57d63140ce0d4e79c097d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/98333bedec446377cac57d63140ce0d4e79c097d">162</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tonioni_Real-Time_Self-Adaptive_Deep_Stereo_CVPR_2019_paper.html">Real-Time Self-Adaptive Deep Stereo</a></th>
                    </tr>
                
                    <tr id="425fc8829ff30c4795776a92076b6d6ba8714f51">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/425fc8829ff30c4795776a92076b6d6ba8714f51">162</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wan_C-MIL_Continuation_Multiple_Instance_Learning_for_Weakly_Supervised_Object_Detection_CVPR_2019_paper.html">C-MIL: Continuation Multiple Instance Learning for Weakly Supervised Object Detection</a></th>
                    </tr>
                
                    <tr id="6e93bd99350bf03acf870f83bb9c7ab1a7d17147">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6e93bd99350bf03acf870f83bb9c7ab1a7d17147">162</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Crasto_MARS_Motion-Augmented_RGB_Stream_for_Action_Recognition_CVPR_2019_paper.html">MARS: Motion-Augmented RGB Stream for Action Recognition</a></th>
                    </tr>
                
                    <tr id="fbc0b44b7a93721978a362465a3046646b075e57">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fbc0b44b7a93721978a362465a3046646b075e57">161</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Single_Image_Deraining_A_Comprehensive_Benchmark_Analysis_CVPR_2019_paper.html">Single Image Deraining: A Comprehensive Benchmark Analysis</a></th>
                    </tr>
                
                    <tr id="a23fbf6e7c224e696662b948163cb27e52188356">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a23fbf6e7c224e696662b948163cb27e52188356">160</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Rebecq_Events-To-Video_Bringing_Modern_Computer_Vision_to_Event_Cameras_CVPR_2019_paper.html">Events-To-Video: Bringing Modern Computer Vision to Event Cameras</a></th>
                    </tr>
                
                    <tr id="0e6a84eb1ef0dfe8a8a1f28e0d7e01fb215cd9b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e6a84eb1ef0dfe8a8a1f28e0d7e01fb215cd9b5">160</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chandra_TraPHic_Trajectory_Prediction_in_Dense_and_Heterogeneous_Traffic_Using_Weighted_CVPR_2019_paper.html">TraPHic: Trajectory Prediction in Dense and Heterogeneous Traffic Using Weighted Interactions</a></th>
                    </tr>
                
                    <tr id="c783584140a727bf3951c0489a857750e975d3ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c783584140a727bf3951c0489a857750e975d3ad">160</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xiang_Generating_3D_Adversarial_Point_Clouds_CVPR_2019_paper.html">Generating 3D Adversarial Point Clouds</a></th>
                    </tr>
                
                    <tr id="6a976c123037b138946f6767e1aa0de84b1682d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a976c123037b138946f6767e1aa0de84b1682d4">160</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Dual_Encoding_for_Zero-Example_Video_Retrieval_CVPR_2019_paper.html">Dual Encoding for Zero-Example Video Retrieval</a></th>
                    </tr>
                
                    <tr id="30732c0146c69306a4b62bb0ce6564d7ea4d1c71">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/30732c0146c69306a4b62bb0ce6564d7ea4d1c71">159</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_FSA-Net_Learning_Fine-Grained_Structure_Aggregation_for_Head_Pose_Estimation_From_CVPR_2019_paper.html">FSA-Net: Learning Fine-Grained Structure Aggregation for Head Pose Estimation From a Single Image</a></th>
                    </tr>
                
                    <tr id="150233ece66acabaf5ab7c555270e2cc4104791a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/150233ece66acabaf5ab7c555270e2cc4104791a">158</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tian_SOSNet_Second_Order_Similarity_Regularization_for_Local_Descriptor_Learning_CVPR_2019_paper.html">SOSNet: Second Order Similarity Regularization for Local Descriptor Learning</a></th>
                    </tr>
                
                    <tr id="53970ae69a73f547a56661fd25f6711746d277fb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/53970ae69a73f547a56661fd25f6711746d277fb">157</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Graph_Convolutional_Tracking_CVPR_2019_paper.html">Graph Convolutional Tracking</a></th>
                    </tr>
                
                    <tr id="7c102f8f4ba424a2c7c7b29364f26d89350877a4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c102f8f4ba424a2c7c7b29364f26d89350877a4">157</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cai_Exploring_Object_Relation_in_Mean_Teacher_for_Cross-Domain_Detection_CVPR_2019_paper.html">Exploring Object Relation in Mean Teacher for Cross-Domain Detection</a></th>
                    </tr>
                
                    <tr id="4b04b42dc57b99060a3b9a870012659dca44054f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4b04b42dc57b99060a3b9a870012659dca44054f">156</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yoshihashi_Classification-Reconstruction_Learning_for_Open-Set_Recognition_CVPR_2019_paper.html">Classification-Reconstruction Learning for Open-Set Recognition</a></th>
                    </tr>
                
                    <tr id="7b4ac890f9635d839a043adce0c23090aa8a02f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b4ac890f9635d839a043adce0c23090aa8a02f9">156</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yin_Hierarchical_Discrete_Distribution_Decomposition_for_Match_Density_Estimation_CVPR_2019_paper.html">Hierarchical Discrete Distribution Decomposition for Match Density Estimation</a></th>
                    </tr>
                
                    <tr id="eee324d41e696b743f6f2f9ce0a46d1ac19f08c8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eee324d41e696b743f6f2f9ce0a46d1ac19f08c8">156</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Depth-Attentional_Features_for_Single-Image_Rain_Removal_CVPR_2019_paper.html">Depth-Attentional Features for Single-Image Rain Removal</a></th>
                    </tr>
                
                    <tr id="b101e9d0e5a3b22335e9d2c4228c215fa4fcc8e4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b101e9d0e5a3b22335e9d2c4228c215fa4fcc8e4">156</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhen_Deep_Supervised_Cross-Modal_Retrieval_CVPR_2019_paper.html">Deep Supervised Cross-Modal Retrieval</a></th>
                    </tr>
                
                    <tr id="b7e5d2c78d0eb9cd6db2c1365697ecc08318b94c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b7e5d2c78d0eb9cd6db2c1365697ecc08318b94c">155</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Segmentation-Driven_6D_Object_Pose_Estimation_CVPR_2019_paper.html">Segmentation-Driven 6D Object Pose Estimation</a></th>
                    </tr>
                
                    <tr id="7e488d0ad51fba6b1cde75c439af3052e9d405f3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e488d0ad51fba6b1cde75c439af3052e9d405f3">155</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Distilling_Object_Detectors_With_Fine-Grained_Feature_Imitation_CVPR_2019_paper.html">Distilling Object Detectors With Fine-Grained Feature Imitation</a></th>
                    </tr>
                
                    <tr id="39db3ba7ca7145cecbcb190bb85d6e07a6fb438f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39db3ba7ca7145cecbcb190bb85d6e07a6fb438f">154</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Arnab_Exploiting_Temporal_Context_for_3D_Human_Pose_Estimation_in_the_CVPR_2019_paper.html">Exploiting Temporal Context for 3D Human Pose Estimation in the Wild</a></th>
                    </tr>
                
                    <tr id="e609684188c842092ae7bcae81429471e422df4d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e609684188c842092ae7bcae81429471e422df4d">154</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ginosar_Learning_Individual_Styles_of_Conversational_Gesture_CVPR_2019_paper.html">Learning Individual Styles of Conversational Gesture</a></th>
                    </tr>
                
                    <tr id="2225036fac528936bb0a5a0e22360e233a2e2934">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2225036fac528936bb0a5a0e22360e233a2e2934">154</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Look_More_Than_Once_An_Accurate_Detector_for_Text_of_CVPR_2019_paper.html">Look More Than Once: An Accurate Detector for Text of Arbitrary Shapes</a></th>
                    </tr>
                
                    <tr id="6328723f58c8f296f9551c5be4910f0cf36330e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6328723f58c8f296f9551c5be4910f0cf36330e1">154</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Precognition/Amirian_Social_Ways_Learning_Multi-Modal_Distributions_of_Pedestrian_Trajectories_With_GANs_CVPRW_2019_paper.html">Social Ways: Learning Multi-Modal Distributions of Pedestrian Trajectories With GANs</a></th>
                    </tr>
                
                    <tr id="957cc4d934e5d416628896875b3156422cc9386d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/957cc4d934e5d416628896875b3156422cc9386d">153</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wandt_RepNet_Weakly_Supervised_Training_of_an_Adversarial_Reprojection_Network_for_CVPR_2019_paper.html">RepNet: Weakly Supervised Training of an Adversarial Reprojection Network for 3D Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="dcf94ed1bb465d5979884b0d03c52f3e0154c9b4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dcf94ed1bb465d5979884b0d03c52f3e0154c9b4">152</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Associatively_Segmenting_Instances_and_Semantics_in_Point_Clouds_CVPR_2019_paper.html">Associatively Segmenting Instances and Semantics in Point Clouds</a></th>
                    </tr>
                
                    <tr id="bb1eda8def02ae0481bab46054b14e9e2b47d208">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bb1eda8def02ae0481bab46054b14e9e2b47d208">152</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Ranked_List_Loss_for_Deep_Metric_Learning_CVPR_2019_paper.html">Ranked List Loss for Deep Metric Learning</a></th>
                    </tr>
                
                    <tr id="f4d38c99b8064efba89adddcfac91c85b9e687e9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f4d38c99b8064efba89adddcfac91c85b9e687e9">152</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_ManTra-Net_Manipulation_Tracing_Network_for_Detection_and_Localization_of_Image_CVPR_2019_paper.html">ManTra-Net: Manipulation Tracing Network for Detection and Localization of Image Forgeries With Anomalous Features</a></th>
                    </tr>
                
                    <tr id="eb2f5e00049eb5bd36bea402c2818fe4bbfe0a0e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eb2f5e00049eb5bd36bea402c2818fe4bbfe0a0e">151</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Self-Supervised_Spatio-Temporal_Representation_Learning_for_Videos_by_Predicting_Motion_and_CVPR_2019_paper.html">Self-Supervised Spatio-Temporal Representation Learning for Videos by Predicting Motion and Appearance Statistics</a></th>
                    </tr>
                
                    <tr id="117ac7c5d42bfdbe83432672db05a2de08dae113">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/117ac7c5d42bfdbe83432672db05a2de08dae113">151</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_A_Mutual_Learning_Method_for_Salient_Object_Detection_With_Intertwined_CVPR_2019_paper.html">A Mutual Learning Method for Salient Object Detection With Intertwined Multi-Supervision</a></th>
                    </tr>
                
                    <tr id="40e44c7737cdf254b9701e690549639f7ac5326f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/40e44c7737cdf254b9701e690549639f7ac5326f">150</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Attentive_Region_Embedding_Network_for_Zero-Shot_Learning_CVPR_2019_paper.html">Attentive Region Embedding Network for Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="25841b189e8e362e6dfe8ff57d2f8fa5040f143e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/25841b189e8e362e6dfe8ff57d2f8fa5040f143e">149</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ling_Fast_Interactive_Object_Annotation_With_Curve-GCN_CVPR_2019_paper.html">Fast Interactive Object Annotation With Curve-GCN</a></th>
                    </tr>
                
                    <tr id="2b40fcc5e0019e31d599f167be0b73fbae41face">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b40fcc5e0019e31d599f167be0b73fbae41face">149</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Re-Identification_With_Consistent_Attentive_Siamese_Networks_CVPR_2019_paper.html">Re-Identification With Consistent Attentive Siamese Networks</a></th>
                    </tr>
                
                    <tr id="0268917fdb8422b8c8b3f579ef5b1f53a3a054e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0268917fdb8422b8c8b3f579ef5b1f53a3a054e1">149</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Image_Super-Resolution_by_Neural_Texture_Transfer_CVPR_2019_paper.html">Image Super-Resolution by Neural Texture Transfer</a></th>
                    </tr>
                
                    <tr id="2e94e9f3bea847239e8653be10f287d1c74bc4ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e94e9f3bea847239e8653be10f287d1c74bc4ac">149</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Li_Heavy_Rain_Image_Restoration_Integrating_Physics_Model_and_Conditional_Adversarial_CVPRW_2019_paper.html">Heavy Rain Image Restoration: Integrating Physics Model and Conditional Adversarial Learning</a></th>
                    </tr>
                
                    <tr id="5c5d99eff1377e141be293336a14ffddb323c364">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c5d99eff1377e141be293336a14ffddb323c364">148</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fan_Heterogeneous_Memory_Enhanced_Multimodal_Attention_Model_for_Video_Question_Answering_CVPR_2019_paper.html">Heterogeneous Memory Enhanced Multimodal Attention Model for Video Question Answering</a></th>
                    </tr>
                
                    <tr id="fbadc3f6d71ef5ceb57fbc88d925125a83e14f55">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fbadc3f6d71ef5ceb57fbc88d925125a83e14f55">148</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Deep_Spectral_Clustering_Using_Dual_Autoencoder_Network_CVPR_2019_paper.html">Deep Spectral Clustering Using Dual Autoencoder Network</a></th>
                    </tr>
                
                    <tr id="281c84088a4294bc0c74b4bb21d1800f2f925a5e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/281c84088a4294bc0c74b4bb21d1800f2f925a5e">148</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hur_Iterative_Residual_Refinement_for_Joint_Optical_Flow_and_Occlusion_Estimation_CVPR_2019_paper.html">Iterative Residual Refinement for Joint Optical Flow and Occlusion Estimation</a></th>
                    </tr>
                
                    <tr id="d697f212009159cc97f383c9ee39dc97341abe16">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d697f212009159cc97f383c9ee39dc97341abe16">148</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Knowledge_Distillation_via_Instance_Relationship_Graph_CVPR_2019_paper.html">Knowledge Distillation via Instance Relationship Graph</a></th>
                    </tr>
                
                    <tr id="e1976a516fda5e0e164c5ae7d7ad89dd09387116">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e1976a516fda5e0e164c5ae7d7ad89dd09387116">147</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Completeness_Modeling_and_Context_Separation_for_Weakly_Supervised_Temporal_Action_CVPR_2019_paper.html">Completeness Modeling and Context Separation for Weakly Supervised Temporal Action Localization</a></th>
                    </tr>
                
                    <tr id="248dbe6ddb6ca09c5f69ddb9159a2e562225dd01">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/248dbe6ddb6ca09c5f69ddb9159a2e562225dd01">147</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Towards_Scene_Understanding_Unsupervised_Monocular_Depth_Estimation_With_Semantic-Aware_Representation_CVPR_2019_paper.html">Towards Scene Understanding: Unsupervised Monocular Depth Estimation With Semantic-Aware Representation</a></th>
                    </tr>
                
                    <tr id="52dd94bed56a9d8bfdad352a4aa42377a873e99f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/52dd94bed56a9d8bfdad352a4aa42377a873e99f">147</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tian_Decoders_Matter_for_Semantic_Segmentation_Data-Dependent_Decoding_Enables_Flexible_Feature_CVPR_2019_paper.html">Decoders Matter for Semantic Segmentation: Data-Dependent Decoding Enables Flexible Feature Aggregation</a></th>
                    </tr>
                
                    <tr id="de0db3e37424167c4d08f701beb0b0da0200abc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/de0db3e37424167c4d08f701beb0b0da0200abc1">147</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Transferable_Interactiveness_Knowledge_for_Human-Object_Interaction_Detection_CVPR_2019_paper.html">Transferable Interactiveness Knowledge for Human-Object Interaction Detection</a></th>
                    </tr>
                
                    <tr id="dabc815780ab0aa0c8136b58c0cf1abec1336884">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dabc815780ab0aa0c8136b58c0cf1abec1336884">146</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Su_Pixel-Adaptive_Convolutional_Neural_Networks_CVPR_2019_paper.html">Pixel-Adaptive Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="7a92ede0fc11a7cdc8fc9e87e583e5f2d0d8f40c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a92ede0fc11a7cdc8fc9e87e583e5f2d0d8f40c">146</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_Parallax_Attention_for_Stereo_Image_Super-Resolution_CVPR_2019_paper.html">Learning Parallax Attention for Stereo Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="a7e2c8c52c5a0202c11d9d6b3fe3427976608c1b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a7e2c8c52c5a0202c11d9d6b3fe3427976608c1b">145</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Knowledge_Adaptation_for_Efficient_Semantic_Segmentation_CVPR_2019_paper.html">Knowledge Adaptation for Efficient Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="50fec8e60b63e355241f153d6f5c17d4116b2a9e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50fec8e60b63e355241f153d6f5c17d4116b2a9e">144</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hussein_Timeception_for_Complex_Action_Recognition_CVPR_2019_paper.html">Timeception for Complex Action Recognition</a></th>
                    </tr>
                
                    <tr id="a0852cd9a026bc90168fa85fa422cb0e48f98394">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a0852cd9a026bc90168fa85fa422cb0e48f98394">144</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Hierarchical_Cross-Modal_Talking_Face_Generation_With_Dynamic_Pixel-Wise_Loss_CVPR_2019_paper.html">Hierarchical Cross-Modal Talking Face Generation With Dynamic Pixel-Wise Loss</a></th>
                    </tr>
                
                    <tr id="07c704709448988b6247032277b04e9190d16008">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/07c704709448988b6247032277b04e9190d16008">143</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Semantic_Segmentation_From_Synthetic_Data_A_Geometrically_Guided_Input-Output_CVPR_2019_paper.html">Learning Semantic Segmentation From Synthetic Data: A Geometrically Guided Input-Output Adaptation Approach</a></th>
                    </tr>
                
                    <tr id="2c869fd9db85559a284c1ce22278c5ec4742fe41">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c869fd9db85559a284c1ce22278c5ec4742fe41">143</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tang_Multi-Channel_Attention_Selection_GAN_With_Cascaded_Semantic_Guidance_for_Cross-View_CVPR_2019_paper.html">Multi-Channel Attention Selection GAN With Cascaded Semantic Guidance for Cross-View Image Translation</a></th>
                    </tr>
                
                    <tr id="5b94a0ecfb144423ca7c5275a31d0d16f99c84d1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b94a0ecfb144423ca7c5275a31d0d16f99c84d1">143</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tekin_HO_Unified_Egocentric_Recognition_of_3D_Hand-Object_Poses_and_Interactions_CVPR_2019_paper.html">H+O: Unified Egocentric Recognition of 3D Hand-Object Poses and Interactions</a></th>
                    </tr>
                
                    <tr id="c92c70dbfc2907350a2c547d6126da783aa5e1b6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c92c70dbfc2907350a2c547d6126da783aa5e1b6">143</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yifan_Patch-Based_Progressive_3D_Point_Set_Upsampling_CVPR_2019_paper.html">Patch-Based Progressive 3D Point Set Upsampling</a></th>
                    </tr>
                
                    <tr id="e20dc0e61d4ee3cd197ec32b6e757a54680ee202">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e20dc0e61d4ee3cd197ec32b6e757a54680ee202">143</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Adaptive_NMS_Refining_Pedestrian_Detection_in_a_Crowd_CVPR_2019_paper.html">Adaptive NMS: Refining Pedestrian Detection in a Crowd</a></th>
                    </tr>
                
                    <tr id="c8ccefc4e60dea2755cd23f709fc684395391980">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c8ccefc4e60dea2755cd23f709fc684395391980">143</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Meshry_Neural_Rerendering_in_the_Wild_CVPR_2019_paper.html">Neural Rerendering in the Wild</a></th>
                    </tr>
                
                    <tr id="fbe4481a9548a790bc5226dc05add2dd4633c353">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fbe4481a9548a790bc5226dc05add2dd4633c353">143</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hong_Rules_of_the_Road_Predicting_Driving_Behavior_With_a_Convolutional_CVPR_2019_paper.html">Rules of the Road: Predicting Driving Behavior With a Convolutional Model of Semantic Interactions</a></th>
                    </tr>
                
                    <tr id="6a5f98c6d96a9f8cc308dae202b62e2230716d34">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a5f98c6d96a9f8cc308dae202b62e2230716d34">143</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lifchitz_Dense_Classification_and_Implanting_for_Few-Shot_Learning_CVPR_2019_paper.html">Dense Classification and Implanting for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="ba1f924e2024995beddb3472db0cd8fecebe1b0e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ba1f924e2024995beddb3472db0cd8fecebe1b0e">142</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sanyal_Learning_to_Regress_3D_Face_Shape_and_Expression_From_an_CVPR_2019_paper.html">Learning to Regress 3D Face Shape and Expression From an Image Without 3D Supervision</a></th>
                    </tr>
                
                    <tr id="c99bea6773fc40197e77e0f5c636b7b2f04b37a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c99bea6773fc40197e77e0f5c636b7b2f04b37a5">142</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Porzi_Seamless_Scene_Segmentation_CVPR_2019_paper.html">Seamless Scene Segmentation</a></th>
                    </tr>
                
                    <tr id="58a74609d4c621b0c34f056433890d6aeb9d7281">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/58a74609d4c621b0c34f056433890d6aeb9d7281">142</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Hsu_Progressive_Domain_Adaptation_for_Object_Detection_CVPRW_2019_paper.html">Progressive Domain Adaptation for Object Detection</a></th>
                    </tr>
                
                    <tr id="f0e2b45ce640e47a538611fc30274f24d66bfb3c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f0e2b45ce640e47a538611fc30274f24d66bfb3c">141</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Pattern-Affinitive_Propagation_Across_Depth_Surface_Normal_and_Semantic_Segmentation_CVPR_2019_paper.html">Pattern-Affinitive Propagation Across Depth, Surface Normal and Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="f368e2ed17a01ef743715e8f5daeb4fdda9696ed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f368e2ed17a01ef743715e8f5daeb4fdda9696ed">141</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Guler_HoloPose_Holistic_3D_Human_Reconstruction_In-The-Wild_CVPR_2019_paper.html">HoloPose: Holistic 3D Human Reconstruction In-The-Wild</a></th>
                    </tr>
                
                    <tr id="e0ef93751e19016c51102d3459fa094c20b314fb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e0ef93751e19016c51102d3459fa094c20b314fb">140</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Active_Contour_Models_for_Medical_Image_Segmentation_CVPR_2019_paper.html">Learning Active Contour Models for Medical Image Segmentation</a></th>
                    </tr>
                
                    <tr id="8b88c357917eb24b39f46be7cf7fe7c56834d18b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b88c357917eb24b39f46be7cf7fe7c56834d18b">139</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Song_Generalizable_Person_Re-Identification_by_Domain-Invariant_Mapping_Network_CVPR_2019_paper.html">Generalizable Person Re-Identification by Domain-Invariant Mapping Network</a></th>
                    </tr>
                
                    <tr id="e91dca6e99f2d392953524986f2125be2008d9fc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e91dca6e99f2d392953524986f2125be2008d9fc">139</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_REPAIR_Removing_Representation_Bias_by_Dataset_Resampling_CVPR_2019_paper.html">REPAIR: Removing Representation Bias by Dataset Resampling</a></th>
                    </tr>
                
                    <tr id="d86a332ef4d638d7db57b4170bd51c40fbc5db57">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d86a332ef4d638d7db57b4170bd51c40fbc5db57">139</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ostapenko_Learning_to_Remember_A_Synaptic_Plasticity_Driven_Framework_for_Continual_CVPR_2019_paper.html">Learning to Remember: A Synaptic Plasticity Driven Framework for Continual Learning</a></th>
                    </tr>
                
                    <tr id="fd5129e8ebfaa5dcce3d4ce2839b90c6cd3ca39d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fd5129e8ebfaa5dcce3d4ce2839b90c6cd3ca39d">138</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Vo_Composing_Text_and_Image_for_Image_Retrieval_-_an_Empirical_CVPR_2019_paper.html">Composing Text and Image for Image Retrieval - an Empirical Odyssey</a></th>
                    </tr>
                
                    <tr id="6b252cf10b7d273d65f36fe80a73f0a12f6dbccb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6b252cf10b7d273d65f36fe80a73f0a12f6dbccb">138</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gong_Exploiting_Edge_Features_for_Graph_Neural_Networks_CVPR_2019_paper.html">Exploiting Edge Features for Graph Neural Networks</a></th>
                    </tr>
                
                    <tr id="af0807dca8a11fbaf966c0f8bf9b5e8b69b4d47c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/af0807dca8a11fbaf966c0f8bf9b5e8b69b4d47c">137</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Feature_Distillation_DNN-Oriented_JPEG_Compression_Against_Adversarial_Examples_CVPR_2019_paper.html">Feature Distillation: DNN-Oriented JPEG Compression Against Adversarial Examples</a></th>
                    </tr>
                
                    <tr id="f53761ea6276df40089753a4e008d1283f28e768">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f53761ea6276df40089753a4e008d1283f28e768">137</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_Unsupervised_Video_Object_Segmentation_Through_Visual_Attention_CVPR_2019_paper.html">Learning Unsupervised Video Object Segmentation Through Visual Attention</a></th>
                    </tr>
                
                    <tr id="c1a906c49496216d0eb1b1cdbca165e75e0309a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c1a906c49496216d0eb1b1cdbca165e75e0309a2">136</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Guo_Visual_Attention_Consistency_Under_Image_Transforms_for_Multi-Label_Image_Classification_CVPR_2019_paper.html">Visual Attention Consistency Under Image Transforms for Multi-Label Image Classification</a></th>
                    </tr>
                
                    <tr id="192e3271d658b27b23c7cbbce178a74ccc1002db">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/192e3271d658b27b23c7cbbce178a74ccc1002db">136</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Akkaynak_Sea-Thru_A_Method_for_Removing_Water_From_Underwater_Images_CVPR_2019_paper.html">Sea-Thru: A Method for Removing Water From Underwater Images</a></th>
                    </tr>
                
                    <tr id="cc9935bb4c7e20ca8565b1eac8969171aa894fd9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cc9935bb4c7e20ca8565b1eac8969171aa894fd9">135</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Baek_Pushing_the_Envelope_for_RGB-Based_Dense_3D_Hand_Pose_Estimation_CVPR_2019_paper.html">Pushing the Envelope for RGB-Based Dense 3D Hand Pose Estimation via Neural Rendering</a></th>
                    </tr>
                
                    <tr id="e7243f56643f90c84d48b59ff2f2bf1ca8015bb7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e7243f56643f90c84d48b59ff2f2bf1ca8015bb7">135</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Separate_to_Adapt_Open_Set_Domain_Adaptation_via_Progressive_Separation_CVPR_2019_paper.html">Separate to Adapt: Open Set Domain Adaptation via Progressive Separation</a></th>
                    </tr>
                
                    <tr id="33e3ea69244ac597d61b9e31098b02fbfccd086d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/33e3ea69244ac597d61b9e31098b02fbfccd086d">135</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jia_ComDefend_An_Efficient_Image_Compression_Model_to_Defend_Adversarial_Examples_CVPR_2019_paper.html">ComDefend: An Efficient Image Compression Model to Defend Adversarial Examples</a></th>
                    </tr>
                
                    <tr id="0df81be86926562d02048755e11ca7a6582aa6c5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0df81be86926562d02048755e11ca7a6582aa6c5">135</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lu_L3-Net_Towards_Learning_Based_LiDAR_Localization_for_Autonomous_Driving_CVPR_2019_paper.html">L3-Net: Towards Learning Based LiDAR Localization for Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="c76b8166a4f63f352d3b68bc736cf06760974779">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c76b8166a4f63f352d3b68bc736cf06760974779">135</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pham_JSIS3D_Joint_Semantic-Instance_Segmentation_of_3D_Point_Clouds_With_Multi-Task_CVPR_2019_paper.html">JSIS3D: Joint Semantic-Instance Segmentation of 3D Point Clouds With Multi-Task Pointwise Networks and Multi-Value Conditional Random Fields</a></th>
                    </tr>
                
                    <tr id="75662c7ab05db37c52a2d750af2a8b712bbf3d53">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/75662c7ab05db37c52a2d750af2a8b712bbf3d53">134</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dwibedi_Temporal_Cycle-Consistency_Learning_CVPR_2019_paper.html">Temporal Cycle-Consistency Learning</a></th>
                    </tr>
                
                    <tr id="c615af9c71c8db9826440058a0a9ee26dba3bd60">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c615af9c71c8db9826440058a0a9ee26dba3bd60">133</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tosi_Learning_Monocular_Depth_Estimation_Infusing_Traditional_Stereo_Knowledge_CVPR_2019_paper.html">Learning Monocular Depth Estimation Infusing Traditional Stereo Knowledge</a></th>
                    </tr>
                
                    <tr id="7b8036414396444439cebbdfefca06d988d6ecd6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b8036414396444439cebbdfefca06d988d6ecd6">132</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Hardness-Aware_Deep_Metric_Learning_CVPR_2019_paper.html">Hardness-Aware Deep Metric Learning</a></th>
                    </tr>
                
                    <tr id="b643a7186c08db9f13d7204f6e5e739f97902e71">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b643a7186c08db9f13d7204f6e5e739f97902e71">132</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gao_2.5D_Visual_Sound_CVPR_2019_paper.html">2.5D Visual Sound</a></th>
                    </tr>
                
                    <tr id="85a2ba580f6faa73f38672b0517cbcdeb84cf6c5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/85a2ba580f6faa73f38672b0517cbcdeb84cf6c5">132</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lou_VERI-Wild_A_Large_Dataset_and_a_New_Method_for_Vehicle_CVPR_2019_paper.html">VERI-Wild: A Large Dataset and a New Method for Vehicle Re-Identification in the Wild</a></th>
                    </tr>
                
                    <tr id="ca1a2b86d39495be5524a0e39b663f7c423a0397">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ca1a2b86d39495be5524a0e39b663f7c423a0397">131</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Explainable_and_Explicit_Visual_Reasoning_Over_Scene_Graphs_CVPR_2019_paper.html">Explainable and Explicit Visual Reasoning Over Scene Graphs</a></th>
                    </tr>
                
                    <tr id="a1f76dca554fbabdec0155c0770f12417868d144">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a1f76dca554fbabdec0155c0770f12417868d144">130</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Multispectral_and_Hyperspectral_Image_Fusion_by_MSHS_Fusion_Net_CVPR_2019_paper.html">Multispectral and Hyperspectral Image Fusion by MS/HS Fusion Net</a></th>
                    </tr>
                
                    <tr id="df1a46fa4b10b660ade2d60831cc451007cea51a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/df1a46fa4b10b660ade2d60831cc451007cea51a">130</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yan_Learning_Context_Graph_for_Person_Search_CVPR_2019_paper.html">Learning Context Graph for Person Search</a></th>
                    </tr>
                
                    <tr id="990fb8c10628754e69fa8d0003d1fc0ed3e2027c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/990fb8c10628754e69fa8d0003d1fc0ed3e2027c">130</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Multi-Granularity_Generator_for_Temporal_Action_Proposal_CVPR_2019_paper.html">Multi-Granularity Generator for Temporal Action Proposal</a></th>
                    </tr>
                
                    <tr id="00fc8f3affc09d8c0d2be64d1ef7eeb21e863235">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00fc8f3affc09d8c0d2be64d1ef7eeb21e863235">130</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Zoom_to_Learn_Learn_to_Zoom_CVPR_2019_paper.html">Zoom to Learn, Learn to Zoom</a></th>
                    </tr>
                
                    <tr id="e5bea0fddd9acb316179b895bb1d5f0e72a5c402">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5bea0fddd9acb316179b895bb1d5f0e72a5c402">130</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_An_Iterative_and_Cooperative_Top-Down_and_Bottom-Up_Inference_Network_for_CVPR_2019_paper.html">An Iterative and Cooperative Top-Down and Bottom-Up Inference Network for Salient Object Detection</a></th>
                    </tr>
                
                    <tr id="edb293b7e75a9fae5dae80dc76af90e46da27a65">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/edb293b7e75a9fae5dae80dc76af90e46da27a65">129</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shao_Multi-Adversarial_Discriminative_Deep_Domain_Generalization_for_Face_Presentation_Attack_Detection_CVPR_2019_paper.html">Multi-Adversarial Discriminative Deep Domain Generalization for Face Presentation Attack Detection</a></th>
                    </tr>
                
                    <tr id="8b4b96526df8e1b99b4bc5b5017b2f6e2f95f0c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b4b96526df8e1b99b4bc5b5017b2f6e2f95f0c0">129</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Rajasegaran_DeepCaps_Going_Deeper_With_Capsule_Networks_CVPR_2019_paper.html">DeepCaps: Going Deeper With Capsule Networks</a></th>
                    </tr>
                
                    <tr id="5cfd9641dbafa988cd64739b2a8c7897dccf355a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5cfd9641dbafa988cd64739b2a8c7897dccf355a">128</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Avetisyan_Scan2CAD_Learning_CAD_Model_Alignment_in_RGB-D_Scans_CVPR_2019_paper.html">Scan2CAD: Learning CAD Model Alignment in RGB-D Scans</a></th>
                    </tr>
                
                    <tr id="9c7dec575f55c9b4d1b58358b0df734bbfdd88dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c7dec575f55c9b4d1b58358b0df734bbfdd88dd">128</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Bi-Directional_Cascade_Network_for_Perceptual_Edge_Detection_CVPR_2019_paper.html">Bi-Directional Cascade Network for Perceptual Edge Detection</a></th>
                    </tr>
                
                    <tr id="c2775267c0b6ef92678b6b1730d3791a1f1822ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c2775267c0b6ef92678b6b1730d3791a1f1822ff">128</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Natsume_SiCloPe_Silhouette-Based_Clothed_People_CVPR_2019_paper.html">SiCloPe: Silhouette-Based Clothed People</a></th>
                    </tr>
                
                    <tr id="78e1c397fe469ae4dfce3770c8352c397d63fc43">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/78e1c397fe469ae4dfce3770c8352c397d63fc43">127</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhuang_Structured_Binary_Neural_Networks_for_Accurate_Image_Classification_and_Semantic_CVPR_2019_paper.html">Structured Binary Neural Networks for Accurate Image Classification and Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="7ea9f9a2fe19206c45ec5c78f9fc89c8bcea2a57">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ea9f9a2fe19206c45ec5c78f9fc89c8bcea2a57">127</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Durand_Learning_a_Deep_ConvNet_for_Multi-Label_Classification_With_Partial_Labels_CVPR_2019_paper.html">Learning a Deep ConvNet for Multi-Label Classification With Partial Labels</a></th>
                    </tr>
                
                    <tr id="2a50e46c3c9553a5d03510fdace701bedbb8e829">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2a50e46c3c9553a5d03510fdace701bedbb8e829">127</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tran_Towards_High-Fidelity_Nonlinear_3D_Face_Morphable_Model_CVPR_2019_paper.html">Towards High-Fidelity Nonlinear 3D Face Morphable Model</a></th>
                    </tr>
                
                    <tr id="db377762f92b35b17fb985b2a853f2ce4906c6e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db377762f92b35b17fb985b2a853f2ce4906c6e1">127</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Deep_Tree_Learning_for_Zero-Shot_Face_Anti-Spoofing_CVPR_2019_paper.html">Deep Tree Learning for Zero-Shot Face Anti-Spoofing</a></th>
                    </tr>
                
                    <tr id="b9011a7c16bc598f543eed7fce88d16461064d0f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b9011a7c16bc598f543eed7fce88d16461064d0f">127</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Park_Arbitrary_Style_Transfer_With_Style-Attentional_Networks_CVPR_2019_paper.html">Arbitrary Style Transfer With Style-Attentional Networks</a></th>
                    </tr>
                
                    <tr id="8ef6983143e8999595def5b668f2f0140fde1185">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8ef6983143e8999595def5b668f2f0140fde1185">126</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Schops_BAD_SLAM_Bundle_Adjusted_Direct_RGB-D_SLAM_CVPR_2019_paper.html">BAD SLAM: Bundle Adjusted Direct RGB-D SLAM</a></th>
                    </tr>
                
                    <tr id="a3252f3aa0675c5299229c1644b74ddf9084cf7f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a3252f3aa0675c5299229c1644b74ddf9084cf7f">126</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Few-Shot_Learning_via_Saliency-Guided_Hallucination_of_Samples_CVPR_2019_paper.html">Few-Shot Learning via Saliency-Guided Hallucination of Samples</a></th>
                    </tr>
                
                    <tr id="c4160cded9e1313ca0d12e26246703a836eccc14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c4160cded9e1313ca0d12e26246703a836eccc14">125</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Deep_Fitting_Degree_Scoring_Network_for_Monocular_3D_Object_Detection_CVPR_2019_paper.html">Deep Fitting Degree Scoring Network for Monocular 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="fba470daf569021d528361b11a9f5b52d6bea493">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fba470daf569021d528361b11a9f5b52d6bea493">125</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Patch-Based_Discriminative_Feature_Learning_for_Unsupervised_Person_Re-Identification_CVPR_2019_paper.html">Patch-Based Discriminative Feature Learning for Unsupervised Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="8902babf787a1acfc6f45be544b78fd46c05dd04">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8902babf787a1acfc6f45be544b78fd46c05dd04">125</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Part-Regularized_Near-Duplicate_Vehicle_Re-Identification_CVPR_2019_paper.html">Part-Regularized Near-Duplicate Vehicle Re-Identification</a></th>
                    </tr>
                
                    <tr id="db0659040cce2c0ee6fc54bdb22814619c40c395">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db0659040cce2c0ee6fc54bdb22814619c40c395">125</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Point_in_Box_Out_Beyond_Counting_Persons_in_Crowds_CVPR_2019_paper.html">Point in, Box Out: Beyond Counting Persons in Crowds</a></th>
                    </tr>
                
                    <tr id="99b5147a7119afe5b8d3c51d3f1a68ec0e84978f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/99b5147a7119afe5b8d3c51d3f1a68ec0e84978f">124</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Image_Deformation_Meta-Networks_for_One-Shot_Learning_CVPR_2019_paper.html">Image Deformation Meta-Networks for One-Shot Learning</a></th>
                    </tr>
                
                    <tr id="7a86bdaf401943e36fe34f4461c7761a3e9b99e9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a86bdaf401943e36fe34f4461c7761a3e9b99e9">124</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/de_Vries_Does_Object_Recognition_Work_for_Everyone_CVPRW_2019_paper.html">Does Object Recognition Work for Everyone?</a></th>
                    </tr>
                
                    <tr id="6834b6a529c969e5feb1fb77713eff8f19704b31">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6834b6a529c969e5feb1fb77713eff8f19704b31">123</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Linkage_Based_Face_Clustering_via_Graph_Convolution_Network_CVPR_2019_paper.html">Linkage Based Face Clustering via Graph Convolution Network</a></th>
                    </tr>
                
                    <tr id="0d9845512c5460ab6a964e7027884f6200ed8452">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0d9845512c5460ab6a964e7027884f6200ed8452">123</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Luo_ContextDesc_Local_Descriptor_Augmentation_With_Cross-Modality_Context_CVPR_2019_paper.html">ContextDesc: Local Descriptor Augmentation With Cross-Modality Context</a></th>
                    </tr>
                
                    <tr id="cdbef23475c744f0e8ebb62dd9ced57948e2442c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cdbef23475c744f0e8ebb62dd9ced57948e2442c">123</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Hierarchical_Deep_Stereo_Matching_on_High-Resolution_Images_CVPR_2019_paper.html">Hierarchical Deep Stereo Matching on High-Resolution Images</a></th>
                    </tr>
                
                    <tr id="2749519e0612c5ccc1f9375439d258a2f782c2aa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2749519e0612c5ccc1f9375439d258a2f782c2aa">123</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Towards_Universal_Object_Detection_by_Domain_Attention_CVPR_2019_paper.html">Towards Universal Object Detection by Domain Attention</a></th>
                    </tr>
                
                    <tr id="d6b1c09b98d0c815952c3dbac4b00c419cdbfac9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d6b1c09b98d0c815952c3dbac4b00c419cdbfac9">122</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_PlaneRCNN_3D_Plane_Detection_and_Reconstruction_From_a_Single_Image_CVPR_2019_paper.html">PlaneRCNN: 3D Plane Detection and Reconstruction From a Single Image</a></th>
                    </tr>
                
                    <tr id="d0bfd3cb732471a0843a39d2d047caf60a844466">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d0bfd3cb732471a0843a39d2d047caf60a844466">122</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_RAVEN_A_Dataset_for_Relational_and_Analogical_Visual_REasoNing_CVPR_2019_paper.html">RAVEN: A Dataset for Relational and Analogical Visual REasoNing</a></th>
                    </tr>
                
                    <tr id="13c2abd38e3f9f5d3eeab177d43a1e0e1a6e64e8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/13c2abd38e3f9f5d3eeab177d43a1e0e1a6e64e8">122</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Learning_Actor_Relation_Graphs_for_Group_Activity_Recognition_CVPR_2019_paper.html">Learning Actor Relation Graphs for Group Activity Recognition</a></th>
                    </tr>
                
                    <tr id="821f2cae0304cd3714ebd7ca31fa68d4029f1d3c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/821f2cae0304cd3714ebd7ca31fa68d4029f1d3c">122</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Feng_Self-Supervised_Representation_Learning_by_Rotation_Feature_Decoupling_CVPR_2019_paper.html">Self-Supervised Representation Learning by Rotation Feature Decoupling</a></th>
                    </tr>
                
                    <tr id="960a6293d068e479435b693df04b839b24ffb7d9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/960a6293d068e479435b693df04b839b24ffb7d9">122</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jiang_Semi-Supervised_Learning_With_Graph_Learning-Convolutional_Networks_CVPR_2019_paper.html">Semi-Supervised Learning With Graph Learning-Convolutional Networks</a></th>
                    </tr>
                
                    <tr id="0728e595e19d35616157c33e6f166d57a4fc5dc8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0728e595e19d35616157c33e6f166d57a4fc5dc8">121</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Khan_Striking_the_Right_Balance_With_Uncertainty_CVPR_2019_paper.html">Striking the Right Balance With Uncertainty</a></th>
                    </tr>
                
                    <tr id="58640dfcd2c57fa3fdf155c4336ee30cc91a0dde">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/58640dfcd2c57fa3fdf155c4336ee30cc91a0dde">121</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Unsupervised_3D_Pose_Estimation_With_Geometric_Self-Supervision_CVPR_2019_paper.html">Unsupervised 3D Pose Estimation With Geometric Self-Supervision</a></th>
                    </tr>
                
                    <tr id="920e0fcca96c4493fa89b9203165f94a6977c068">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/920e0fcca96c4493fa89b9203165f94a6977c068">121</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kolkin_Style_Transfer_by_Relaxed_Optimal_Transport_and_Self-Similarity_CVPR_2019_paper.html">Style Transfer by Relaxed Optimal Transport and Self-Similarity</a></th>
                    </tr>
                
                    <tr id="5ae1d33e36111eda24842bc3fa61ed1319c94da4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5ae1d33e36111eda24842bc3fa61ed1319c94da4">120</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_ODE-Inspired_Network_Design_for_Single_Image_Super-Resolution_CVPR_2019_paper.html">ODE-Inspired Network Design for Single Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="f373bccc69bec811fa93b27d59a560b9e4ed0946">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f373bccc69bec811fa93b27d59a560b9e4ed0946">120</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kwon_Predicting_Future_Frames_Using_Retrospective_Cycle_GAN_CVPR_2019_paper.html">Predicting Future Frames Using Retrospective Cycle GAN</a></th>
                    </tr>
                
                    <tr id="652f431670405ebc56148d77c290a07c8408136f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/652f431670405ebc56148d77c290a07c8408136f">120</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Fast_Human_Pose_Estimation_CVPR_2019_paper.html">Fast Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="580fd9a601314ea32dc85ec98267b411dd3465cf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/580fd9a601314ea32dc85ec98267b411dd3465cf">120</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Feng_Unsupervised_Image_Captioning_CVPR_2019_paper.html">Unsupervised Image Captioning</a></th>
                    </tr>
                
                    <tr id="0fa68cde4db12779adacb70a24961cf09b1adf73">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0fa68cde4db12779adacb70a24961cf09b1adf73">119</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Language-Driven_Temporal_Activity_Localization_A_Semantic_Matching_Reinforcement_Learning_Model_CVPR_2019_paper.html">Language-Driven Temporal Activity Localization: A Semantic Matching Reinforcement Learning Model</a></th>
                    </tr>
                
                    <tr id="9b3637c9379d57479f3d2b63a8d7dc26a2cc6237">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9b3637c9379d57479f3d2b63a8d7dc26a2cc6237">119</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Collaborative_Learning_of_Semi-Supervised_Segmentation_and_Classification_for_Medical_Images_CVPR_2019_paper.html">Collaborative Learning of Semi-Supervised Segmentation and Classification for Medical Images</a></th>
                    </tr>
                
                    <tr id="39d7613f13526852e2330a11686d17d94df41c33">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39d7613f13526852e2330a11686d17d94df41c33">119</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Makansi_Overcoming_Limitations_of_Mixture_Density_Networks_A_Sampling_and_Fitting_CVPR_2019_paper.html">Overcoming Limitations of Mixture Density Networks: A Sampling and Fitting Framework for Multimodal Future Prediction</a></th>
                    </tr>
                
                    <tr id="586bd368968bcf4af408e38e389ade929ded49d9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/586bd368968bcf4af408e38e389ade929ded49d9">118</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_HorizonNet_Learning_Room_Layout_With_1D_Representation_and_Pano_Stretch_CVPR_2019_paper.html">HorizonNet: Learning Room Layout With 1D Representation and Pano Stretch Data Augmentation</a></th>
                    </tr>
                
                    <tr id="457fb193b1432f79f71d44d714f40189118cd515">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/457fb193b1432f79f71d44d714f40189118cd515">118</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tian_Learning_Shape-Aware_Embedding_for_Scene_Text_Detection_CVPR_2019_paper.html">Learning Shape-Aware Embedding for Scene Text Detection</a></th>
                    </tr>
                
                    <tr id="beacc110b576ee667cceda48e367d87d9db60ee4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/beacc110b576ee667cceda48e367d87d9db60ee4">118</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Semantic_Correlation_Promoted_Shape-Variant_Context_for_Segmentation_CVPR_2019_paper.html">Semantic Correlation Promoted Shape-Variant Context for Segmentation</a></th>
                    </tr>
                
                    <tr id="10cb854adb764c1e8c6bd73bb706b1ed59d929b7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/10cb854adb764c1e8c6bd73bb706b1ed59d929b7">117</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ventura_RVOS_End-To-End_Recurrent_Network_for_Video_Object_Segmentation_CVPR_2019_paper.html">RVOS: End-To-End Recurrent Network for Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="3b4439694205d007972af49b423d2ea9f28f7e2b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3b4439694205d007972af49b423d2ea9f28f7e2b">117</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ma_The_Regretful_Agent_Heuristic-Aided_Navigation_Through_Progress_Estimation_CVPR_2019_paper.html">The Regretful Agent: Heuristic-Aided Navigation Through Progress Estimation</a></th>
                    </tr>
                
                    <tr id="a8f82121c67f158082b4a8b79829c3a49ca95f4a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a8f82121c67f158082b4a8b79829c3a49ca95f4a">117</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Moon_PoseFix_Model-Agnostic_General_Human_Pose_Refinement_Network_CVPR_2019_paper.html">PoseFix: Model-Agnostic General Human Pose Refinement Network</a></th>
                    </tr>
                
                    <tr id="a7a8922b0b0d6f3d439520544da7db1fd6e0dce6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a7a8922b0b0d6f3d439520544da7db1fd6e0dce6">117</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Roy_Unsupervised_Domain_Adaptation_Using_Feature-Whitening_and_Consensus_Loss_CVPR_2019_paper.html">Unsupervised Domain Adaptation Using Feature-Whitening and Consensus Loss</a></th>
                    </tr>
                
                    <tr id="f4552c833c692f90f9cb7740588bef95ec502b9a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f4552c833c692f90f9cb7740588bef95ec502b9a">116</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Recurrent_Attentive_Zooming_for_Joint_Crowd_Counting_and_Precise_Localization_CVPR_2019_paper.html">Recurrent Attentive Zooming for Joint Crowd Counting and Precise Localization</a></th>
                    </tr>
                
                    <tr id="0a98ef88bae12639d8770e5680564b8f9a188bec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a98ef88bae12639d8770e5680564b8f9a188bec">116</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_AdaFrame_Adaptive_Frame_Selection_for_Fast_Video_Recognition_CVPR_2019_paper.html">AdaFrame: Adaptive Frame Selection for Fast Video Recognition</a></th>
                    </tr>
                
                    <tr id="0a4a62cccc182c3602ea0c604a21b8d91b99867a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a4a62cccc182c3602ea0c604a21b8d91b99867a">116</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Graphical_Contrastive_Losses_for_Scene_Graph_Parsing_CVPR_2019_paper.html">Graphical Contrastive Losses for Scene Graph Parsing</a></th>
                    </tr>
                
                    <tr id="db20d81d40243d66ff90f11b5c6f058d43d3701f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db20d81d40243d66ff90f11b5c6f058d43d3701f">116</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Morais_Learning_Regularity_in_Skeleton_Trajectories_for_Anomaly_Detection_in_Videos_CVPR_2019_paper.html">Learning Regularity in Skeleton Trajectories for Anomaly Detection in Videos</a></th>
                    </tr>
                
                    <tr id="505e3315b7c5d4094c3160d00956a7d1596c0956">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/505e3315b7c5d4094c3160d00956a7d1596c0956">115</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fang_Scene_Memory_Transformer_for_Embodied_Agents_in_Long-Horizon_Tasks_CVPR_2019_paper.html">Scene Memory Transformer for Embodied Agents in Long-Horizon Tasks</a></th>
                    </tr>
                
                    <tr id="3ff74b685615f50736e10294811281c41de3d61e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ff74b685615f50736e10294811281c41de3d61e">115</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Dissecting_Person_Re-Identification_From_the_Viewpoint_of_Viewpoint_CVPR_2019_paper.html">Dissecting Person Re-Identification From the Viewpoint of Viewpoint</a></th>
                    </tr>
                
                    <tr id="4308c530613ea437fe8224cc65720adf28b1a589">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4308c530613ea437fe8224cc65720adf28b1a589">115</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yin_Semantics_Disentangling_for_Text-To-Image_Generation_CVPR_2019_paper.html">Semantics Disentangling for Text-To-Image Generation</a></th>
                    </tr>
                
                    <tr id="8c8d0031b24937d8a8ec7a4c5ab5fda4f4797803">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c8d0031b24937d8a8ec7a4c5ab5fda4f4797803">115</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gao_NDDR-CNN_Layerwise_Feature_Fusing_in_Multi-Task_CNNs_by_Neural_Discriminative_CVPR_2019_paper.html">NDDR-CNN: Layerwise Feature Fusing in Multi-Task CNNs by Neural Discriminative Dimensionality Reduction</a></th>
                    </tr>
                
                    <tr id="4d21334ea3564c89586e1ba176e11382bdd3d394">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4d21334ea3564c89586e1ba176e11382bdd3d394">115</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wortsman_Learning_to_Learn_How_to_Learn_Self-Adaptive_Visual_Navigation_Using_CVPR_2019_paper.html">Learning to Learn How to Learn: Self-Adaptive Visual Navigation Using Meta-Learning</a></th>
                    </tr>
                
                    <tr id="99a72ee17049b721d8ac061b34b79d50156c1e70">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/99a72ee17049b721d8ac061b34b79d50156c1e70">115</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Williams_Deep_Geometric_Prior_for_Surface_Reconstruction_CVPR_2019_paper.html">Deep Geometric Prior for Surface Reconstruction</a></th>
                    </tr>
                
                    <tr id="5c02a2a4e5a7a23759d1849c75199d66c10fdf40">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c02a2a4e5a7a23759d1849c75199d66c10fdf40">115</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Benenson_Large-Scale_Interactive_Object_Segmentation_With_Human_Annotators_CVPR_2019_paper.html">Large-Scale Interactive Object Segmentation With Human Annotators</a></th>
                    </tr>
                
                    <tr id="e65e8c434895601b27cda0bef9b1bd9ff1475bf3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e65e8c434895601b27cda0bef9b1bd9ff1475bf3">115</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qiu_Learning_Spatio-Temporal_Representation_With_Local_and_Global_Diffusion_CVPR_2019_paper.html">Learning Spatio-Temporal Representation With Local and Global Diffusion</a></th>
                    </tr>
                
                    <tr id="40444ac8db55a9e87b02c6e7b71ea85397485777">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/40444ac8db55a9e87b02c6e7b71ea85397485777">114</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fu_Geometry-Consistent_Generative_Adversarial_Networks_for_One-Sided_Unsupervised_Domain_Mapping_CVPR_2019_paper.html">Geometry-Consistent Generative Adversarial Networks for One-Sided Unsupervised Domain Mapping</a></th>
                    </tr>
                
                    <tr id="41f731d27e2692a0c9601f132f248433ca92577d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/41f731d27e2692a0c9601f132f248433ca92577d">114</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Dense_Intrinsic_Appearance_Flow_for_Human_Pose_Transfer_CVPR_2019_paper.html">Dense Intrinsic Appearance Flow for Human Pose Transfer</a></th>
                    </tr>
                
                    <tr id="7f01ae3a562fd1a47e328c296c7d7d7282e36f3f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7f01ae3a562fd1a47e328c296c7d7d7282e36f3f">114</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yasarla_Uncertainty_Guided_Multi-Scale_Residual_Learning-Using_a_Cycle_Spinning_CNN_for_CVPR_2019_paper.html">Uncertainty Guided Multi-Scale Residual Learning-Using a Cycle Spinning CNN for Single Image De-Raining</a></th>
                    </tr>
                
                    <tr id="20888a7aebaf77a306c0886f165bd0d468db806d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/20888a7aebaf77a306c0886f165bd0d468db806d">114</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Aafaq_Spatio-Temporal_Dynamics_and_Semantic_Attribute_Enriched_Visual_Encoding_for_Video_CVPR_2019_paper.html">Spatio-Temporal Dynamics and Semantic Attribute Enriched Visual Encoding for Video Captioning</a></th>
                    </tr>
                
                    <tr id="f6314c46f5c3c55a69146f0de38d6c3d58bf9b8d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f6314c46f5c3c55a69146f0de38d6c3d58bf9b8d">113</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sariyildiz_Gradient_Matching_Generative_Networks_for_Zero-Shot_Learning_CVPR_2019_paper.html">Gradient Matching Generative Networks for Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="d8ba2965be9cc93439c5bb52961b504c39f16e80">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d8ba2965be9cc93439c5bb52961b504c39f16e80">113</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sarmad_RL-GAN-Net_A_Reinforcement_Learning_Agent_Controlled_GAN_Network_for_Real-Time_CVPR_2019_paper.html">RL-GAN-Net: A Reinforcement Learning Agent Controlled GAN Network for Real-Time Point Cloud Shape Completion</a></th>
                    </tr>
                
                    <tr id="171a027fc6c7f4194569170accc48187c8bb5aaa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/171a027fc6c7f4194569170accc48187c8bb5aaa">113</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Grounded_Video_Description_CVPR_2019_paper.html">Grounded Video Description</a></th>
                    </tr>
                
                    <tr id="16f9bfac4a68cc99c38c06db2aa523bc6537db0d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16f9bfac4a68cc99c38c06db2aa523bc6537db0d">113</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Memory_in_Memory_A_Predictive_Neural_Network_for_Learning_Higher-Order_CVPR_2019_paper.html">Memory in Memory: A Predictive Neural Network for Learning Higher-Order Non-Stationarity From Spatiotemporal Dynamics</a></th>
                    </tr>
                
                    <tr id="bbdf16e1b81cec93b976289439c4cb41e59d73e9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bbdf16e1b81cec93b976289439c4cb41e59d73e9">113</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mentzer_Practical_Full_Resolution_Learned_Lossless_Image_Compression_CVPR_2019_paper.html">Practical Full Resolution Learned Lossless Image Compression</a></th>
                    </tr>
                
                    <tr id="171a027fc6c7f4194569170accc48187c8bb5aaa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/171a027fc6c7f4194569170accc48187c8bb5aaa">113</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MMLV/Zhou_Grounded_Video_Description_CVPRW_2019_paper.html">Grounded Video Description</a></th>
                    </tr>
                
                    <tr id="704cffb06e002faf5d8822e5d9f9a2046deafa3a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/704cffb06e002faf5d8822e5d9f9a2046deafa3a">112</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_Adversarial_Attacks_Beyond_the_Image_Space_CVPR_2019_paper.html">Adversarial Attacks Beyond the Image Space</a></th>
                    </tr>
                
                    <tr id="f6638068266fe436029b7e4b016c74273535aade">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f6638068266fe436029b7e4b016c74273535aade">112</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Gait_Recognition_via_Disentangled_Representation_Learning_CVPR_2019_paper.html">Gait Recognition via Disentangled Representation Learning</a></th>
                    </tr>
                
                    <tr id="9521aaa9f7dcd996773fc699f2a92553bd3b8bdb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9521aaa9f7dcd996773fc699f2a92553bd3b8bdb">112</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hou_VRSTC_Occlusion-Free_Video_Person_Re-Identification_CVPR_2019_paper.html">VRSTC: Occlusion-Free Video Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="f4704d8698b9e50aee53a5970172bd046af58ec6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f4704d8698b9e50aee53a5970172bd046af58ec6">112</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Image_Generation_From_Layout_CVPR_2019_paper.html">Image Generation From Layout</a></th>
                    </tr>
                
                    <tr id="d1f20b7fa529cad39f64ab7cae37c84dddf7018f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d1f20b7fa529cad39f64ab7cae37c84dddf7018f">112</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mou_A_Relation-Augmented_Fully_Convolutional_Network_for_Semantic_Segmentation_in_Aerial_CVPR_2019_paper.html">A Relation-Augmented Fully Convolutional Network for Semantic Segmentation in Aerial Scenes</a></th>
                    </tr>
                
                    <tr id="cd24b3d31f1fd9f77e3a90eab832361fceded8f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd24b3d31f1fd9f77e3a90eab832361fceded8f9">112</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Torkzadehmahani_DP-CGAN_Differentially_Private_Synthetic_Data_and_Label_Generation_CVPRW_2019_paper.html">DP-CGAN: Differentially Private Synthetic Data and Label Generation</a></th>
                    </tr>
                
                    <tr id="e5eba3d8d1139ea1b97e15dcdc12a46ebc1ba44c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5eba3d8d1139ea1b97e15dcdc12a46ebc1ba44c">111</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lan_Modeling_Local_Geometric_Structure_of_3D_Point_Clouds_Using_Geo-CNN_CVPR_2019_paper.html">Modeling Local Geometric Structure of 3D Point Clouds Using Geo-CNN</a></th>
                    </tr>
                
                    <tr id="e27e78c33288728f66f7dab2fe2696ddbc5c1026">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e27e78c33288728f66f7dab2fe2696ddbc5c1026">111</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tang_COIN_A_Large-Scale_Dataset_for_Comprehensive_Instructional_Video_Analysis_CVPR_2019_paper.html">COIN: A Large-Scale Dataset for Comprehensive Instructional Video Analysis</a></th>
                    </tr>
                
                    <tr id="00ccecc56ed83945fafb8e2dc48ffc1609618040">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00ccecc56ed83945fafb8e2dc48ffc1609618040">111</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chang_D3TW_Discriminative_Differentiable_Dynamic_Time_Warping_for_Weakly_Supervised_Action_CVPR_2019_paper.html">D3TW: Discriminative Differentiable Dynamic Time Warping for Weakly Supervised Action Alignment and Segmentation</a></th>
                    </tr>
                
                    <tr id="b12124f7bbdd3a99d6b392024806d0f3124380ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b12124f7bbdd3a99d6b392024806d0f3124380ac">111</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pei_Memory-Attended_Recurrent_Network_for_Video_Captioning_CVPR_2019_paper.html">Memory-Attended Recurrent Network for Video Captioning</a></th>
                    </tr>
                
                    <tr id="35937ab3aaf3b8eee89180a1b892c3daa96d2bab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/35937ab3aaf3b8eee89180a1b892c3daa96d2bab">111</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_AdaCos_Adaptively_Scaling_Cosine_Logits_for_Effectively_Learning_Deep_Face_CVPR_2019_paper.html">AdaCos: Adaptively Scaling Cosine Logits for Effectively Learning Deep Face Representations</a></th>
                    </tr>
                
                    <tr id="65bd8f1b215a1107d3f30087a54058cbb05b3e51">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/65bd8f1b215a1107d3f30087a54058cbb05b3e51">111</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_PCAN_3D_Attention_Map_Learning_Using_Contextual_Information_for_Point_CVPR_2019_paper.html">PCAN: 3D Attention Map Learning Using Contextual Information for Point Cloud Based Retrieval</a></th>
                    </tr>
                
                    <tr id="8433be13db27f7c195cf54999dfd2dd2845b831e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8433be13db27f7c195cf54999dfd2dd2845b831e">110</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Maninis_Attentive_Single-Tasking_of_Multiple_Tasks_CVPR_2019_paper.html">Attentive Single-Tasking of Multiple Tasks</a></th>
                    </tr>
                
                    <tr id="cd961afa9d75e1e7a657a9e11d6f6d3b968282a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd961afa9d75e1e7a657a9e11d6f6d3b968282a0">110</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Improving_Referring_Expression_Grounding_With_Cross-Modal_Attention-Guided_Erasing_CVPR_2019_paper.html">Improving Referring Expression Grounding With Cross-Modal Attention-Guided Erasing</a></th>
                    </tr>
                
                    <tr id="059282edacac41b220f295b5ee1d376aa19871d8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/059282edacac41b220f295b5ee1d376aa19871d8">110</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_SPM-Tracker_Series-Parallel_Matching_for_Real-Time_Visual_Object_Tracking_CVPR_2019_paper.html">SPM-Tracker: Series-Parallel Matching for Real-Time Visual Object Tracking</a></th>
                    </tr>
                
                    <tr id="8bf18d546ae7aea144663136c5704049953ce4e2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8bf18d546ae7aea144663136c5704049953ce4e2">110</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Modas_SparseFool_A_Few_Pixels_Make_a_Big_Difference_CVPR_2019_paper.html">SparseFool: A Few Pixels Make a Big Difference</a></th>
                    </tr>
                
                    <tr id="8abc9fc312fc6916725ec94816ab26c582cf1a90">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8abc9fc312fc6916725ec94816ab26c582cf1a90">110</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Deep_Multimodal_Clustering_for_Unsupervised_Audiovisual_Learning_CVPR_2019_paper.html">Deep Multimodal Clustering for Unsupervised Audiovisual Learning</a></th>
                    </tr>
                
                    <tr id="a39d5919531a56de0e36f6b76142041b5d508213">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a39d5919531a56de0e36f6b76142041b5d508213">109</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Song_Polysemous_Visual-Semantic_Embedding_for_Cross-Modal_Retrieval_CVPR_2019_paper.html">Polysemous Visual-Semantic Embedding for Cross-Modal Retrieval</a></th>
                    </tr>
                
                    <tr id="735a63b58349e07b84c2e31927ce1b1cfaf09980">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/735a63b58349e07b84c2e31927ce1b1cfaf09980">109</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shah_Cycle-Consistency_for_Robust_Visual_Question_Answering_CVPR_2019_paper.html">Cycle-Consistency for Robust Visual Question Answering</a></th>
                    </tr>
                
                    <tr id="f985c91ae59d8664c6e9023da6f3b7c896e0091a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f985c91ae59d8664c6e9023da6f3b7c896e0091a">108</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/RoyChowdhury_Automatic_Adaptation_of_Object_Detectors_to_New_Domains_Using_Self-Training_CVPR_2019_paper.html">Automatic Adaptation of Object Detectors to New Domains Using Self-Training</a></th>
                    </tr>
                
                    <tr id="cc20befe4b33049d8a4eb21fb05572ecaf95acca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cc20befe4b33049d8a4eb21fb05572ecaf95acca">108</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yan_Attention-Guided_Network_for_Ghost-Free_High_Dynamic_Range_Imaging_CVPR_2019_paper.html">Attention-Guided Network for Ghost-Free High Dynamic Range Imaging</a></th>
                    </tr>
                
                    <tr id="a8a70942cec397e6b84de252fa3b9cd24948fa57">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a8a70942cec397e6b84de252fa3b9cd24948fa57">108</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_ClusterNet_Deep_Hierarchical_Cluster_Network_With_Rigorously_Rotation-Invariant_Representation_for_CVPR_2019_paper.html">ClusterNet: Deep Hierarchical Cluster Network With Rigorously Rotation-Invariant Representation for Point Cloud Analysis</a></th>
                    </tr>
                
                    <tr id="48e52aef87084fa17e6ccb20ad9b3a8ec45934f0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/48e52aef87084fa17e6ccb20ad9b3a8ec45934f0">108</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Johnander_A_Generative_Appearance_Model_for_End-To-End_Video_Object_Segmentation_CVPR_2019_paper.html">A Generative Appearance Model for End-To-End Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="79f36f8b6590fd59ac3e75726ccadf2f5c32b124">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/79f36f8b6590fd59ac3e75726ccadf2f5c32b124">108</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lorenz_Unsupervised_Part-Based_Disentangling_of_Object_Shape_and_Appearance_CVPR_2019_paper.html">Unsupervised Part-Based Disentangling of Object Shape and Appearance</a></th>
                    </tr>
                
                    <tr id="c541b4896f6791fd55bed530d80aa9b02cc3890b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c541b4896f6791fd55bed530d80aa9b02cc3890b">108</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tanno_Learning_From_Noisy_Labels_by_Regularized_Estimation_of_Annotator_Confusion_CVPR_2019_paper.html">Learning From Noisy Labels by Regularized Estimation of Annotator Confusion</a></th>
                    </tr>
                
                    <tr id="70848e09b655b0da3f0baa643d1126c78a2fb0c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70848e09b655b0da3f0baa643d1126c78a2fb0c0">108</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Simon_Complexer-YOLO_Real-Time_3D_Object_Detection_and_Tracking_on_Semantic_Point_CVPRW_2019_paper.html">Complexer-YOLO: Real-Time 3D Object Detection and Tracking on Semantic Point Clouds</a></th>
                    </tr>
                
                    <tr id="70848e09b655b0da3f0baa643d1126c78a2fb0c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70848e09b655b0da3f0baa643d1126c78a2fb0c0">108</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Simon_Complexer_YOLO_Real-Time_3D_Object_Detection_and_Tracking_on_Semantic_CVPRW_2019_paper.html">Complexer YOLO: Real-Time 3D Object Detection and Tracking on Semantic Point Clouds</a></th>
                    </tr>
                
                    <tr id="3273f9ca44534d8f6973223103e711badf6935f4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3273f9ca44534d8f6973223103e711badf6935f4">107</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Face_Anti-Spoofing_Model_Matters_so_Does_Data_CVPR_2019_paper.html">Face Anti-Spoofing: Model Matters, so Does Data</a></th>
                    </tr>
                
                    <tr id="2ea3dea3092d803867c3477f6070279e5abb340c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ea3dea3092d803867c3477f6070279e5abb340c">106</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Song_Box-Driven_Class-Wise_Region_Masking_and_Filling_Rate_Guided_Loss_for_CVPR_2019_paper.html">Box-Driven Class-Wise Region Masking and Filling Rate Guided Loss for Weakly Supervised Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="48e59902a49e41f2f16229bb38c27348c461b8c7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/48e59902a49e41f2f16229bb38c27348c461b8c7">106</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Centripetal_SGD_for_Pruning_Very_Deep_Convolutional_Networks_With_Complicated_CVPR_2019_paper.html">Centripetal SGD for Pruning Very Deep Convolutional Networks With Complicated Structure</a></th>
                    </tr>
                
                    <tr id="83ac0851a8f6fa02f5db251b260f635907d7a01e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/83ac0851a8f6fa02f5db251b260f635907d7a01e">106</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ke_Tactical_Rewind_Self-Correction_via_Backtracking_in_Vision-And-Language_Navigation_CVPR_2019_paper.html">Tactical Rewind: Self-Correction via Backtracking in Vision-And-Language Navigation</a></th>
                    </tr>
                
                    <tr id="e4b54f2e0ebbe450e2c527cf5a00d4816980a913">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e4b54f2e0ebbe450e2c527cf5a00d4816980a913">106</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Oh_Speech2Face_Learning_the_Face_Behind_a_Voice_CVPR_2019_paper.html">Speech2Face: Learning the Face Behind a Voice</a></th>
                    </tr>
                
                    <tr id="8b3c54dbd24ffd1b062b157181e0f0a914c1d62f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b3c54dbd24ffd1b062b157181e0f0a914c1d62f">106</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EarthVision/Shermeyer_The_Effects_of_Super-Resolution_on_Object_Detection_Performance_in_Satellite_CVPRW_2019_paper.html">The Effects of Super-Resolution on Object Detection Performance in Satellite Imagery</a></th>
                    </tr>
                
                    <tr id="730666f38edc326439c3250266a7bfe2c6e106ca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/730666f38edc326439c3250266a7bfe2c6e106ca">105</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gu_HPLFlowNet_Hierarchical_Permutohedral_Lattice_FlowNet_for_Scene_Flow_Estimation_on_CVPR_2019_paper.html">HPLFlowNet: Hierarchical Permutohedral Lattice FlowNet for Scene Flow Estimation on Large-Scale Point Clouds</a></th>
                    </tr>
                
                    <tr id="6fad9af558e680f84515e3640877f509b73c5bdb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6fad9af558e680f84515e3640877f509b73c5bdb">105</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gong_Graphonomy_Universal_Human_Parsing_via_Graph_Transfer_Learning_CVPR_2019_paper.html">Graphonomy: Universal Human Parsing via Graph Transfer Learning</a></th>
                    </tr>
                
                    <tr id="537e1530ffdb2620135906927f55353ae5a1e021">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/537e1530ffdb2620135906927f55353ae5a1e021">105</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Barath_MAGSAC_Marginalizing_Sample_Consensus_CVPR_2019_paper.html">MAGSAC: Marginalizing Sample Consensus</a></th>
                    </tr>
                
                    <tr id="7251bc89e4b8abeb16e7b8ac603d57e0046103f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7251bc89e4b8abeb16e7b8ac603d57e0046103f2">104</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lian_Density_Map_Regression_Guided_Detection_Network_for_RGB-D_Crowd_Counting_CVPR_2019_paper.html">Density Map Regression Guided Detection Network for RGB-D Crowd Counting and Localization</a></th>
                    </tr>
                
                    <tr id="f3f1ea39c55e9c85a68fe50450cd7dfa6515e55c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f3f1ea39c55e9c85a68fe50450cd7dfa6515e55c">104</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Deep_Flow-Guided_Video_Inpainting_CVPR_2019_paper.html">Deep Flow-Guided Video Inpainting</a></th>
                    </tr>
                
                    <tr id="5f0c8b5be40518b0ce7876ab152c2b9696ef713e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f0c8b5be40518b0ce7876ab152c2b9696ef713e">104</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Deep_Video_Inpainting_CVPR_2019_paper.html">Deep Video Inpainting</a></th>
                    </tr>
                
                    <tr id="8e59cf8c3becbedced0089028a1cddac8b19b251">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e59cf8c3becbedced0089028a1cddac8b19b251">104</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cornia_Show_Control_and_Tell_A_Framework_for_Generating_Controllable_and_CVPR_2019_paper.html">Show, Control and Tell: A Framework for Generating Controllable and Grounded Captions</a></th>
                    </tr>
                
                    <tr id="47c71b62356adee63f63ff0f7d0a3579f981e973">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47c71b62356adee63f63ff0f7d0a3579f981e973">104</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Nekrasov_Fast_Neural_Architecture_Search_of_Compact_Semantic_Segmentation_Models_via_CVPR_2019_paper.html">Fast Neural Architecture Search of Compact Semantic Segmentation Models via Auxiliary Cells</a></th>
                    </tr>
                
                    <tr id="759e41c0c0d9b7f63303f03a064754dd30916441">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/759e41c0c0d9b7f63303f03a064754dd30916441">103</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Rao_Spherical_Fractal_Convolutional_Neural_Networks_for_Point_Cloud_Recognition_CVPR_2019_paper.html">Spherical Fractal Convolutional Neural Networks for Point Cloud Recognition</a></th>
                    </tr>
                
                    <tr id="d796b68c1cce424d65581de35e93f7f969b71e89">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d796b68c1cce424d65581de35e93f7f969b71e89">103</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Fully_Quantized_Network_for_Object_Detection_CVPR_2019_paper.html">Fully Quantized Network for Object Detection</a></th>
                    </tr>
                
                    <tr id="3605e41ce77dfd259eaebed906804bb60f634f75">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3605e41ce77dfd259eaebed906804bb60f634f75">103</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhukov_Cross-Task_Weakly_Supervised_Learning_From_Instructional_Videos_CVPR_2019_paper.html">Cross-Task Weakly Supervised Learning From Instructional Videos</a></th>
                    </tr>
                
                    <tr id="d6629cfa597c7ff3d9318b2cb58b81554c19f3e0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d6629cfa597c7ff3d9318b2cb58b81554c19f3e0">103</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Binary_Ensemble_Neural_Network_More_Bits_per_Network_or_More_CVPR_2019_paper.html">Binary Ensemble Neural Network: More Bits per Network or More Networks per Bit?</a></th>
                    </tr>
                
                    <tr id="1183d6d59020415854c1e782a5d788a400d1a9dc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1183d6d59020415854c1e782a5d788a400d1a9dc">103</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_Multi-Source_Weak_Supervision_for_Saliency_Detection_CVPR_2019_paper.html">Multi-Source Weak Supervision for Saliency Detection</a></th>
                    </tr>
                
                    <tr id="433243fe9d885eec4cc29d488634aedc153ec48c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/433243fe9d885eec4cc29d488634aedc153ec48c">103</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_An_End-To-End_Network_for_Panoptic_Segmentation_CVPR_2019_paper.html">An End-To-End Network for Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="ecafbd646fa4116c149baa3a6e2e7699163fd2f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ecafbd646fa4116c149baa3a6e2e7699163fd2f9">103</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Paschalidou_Superquadrics_Revisited_Learning_3D_Shape_Parsing_Beyond_Cuboids_CVPR_2019_paper.html">Superquadrics Revisited: Learning 3D Shape Parsing Beyond Cuboids</a></th>
                    </tr>
                
                    <tr id="d8d0be583f79b03c6554faae99b08172439b3636">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d8d0be583f79b03c6554faae99b08172439b3636">102</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhan_Spatial_Fusion_GAN_for_Image_Synthesis_CVPR_2019_paper.html">Spatial Fusion GAN for Image Synthesis</a></th>
                    </tr>
                
                    <tr id="a45b6653a491bf9d5842fc582563500be63f782f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a45b6653a491bf9d5842fc582563500be63f782f">102</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qi_Attentive_Relational_Networks_for_Mapping_Images_to_Scene_Graphs_CVPR_2019_paper.html">Attentive Relational Networks for Mapping Images to Scene Graphs</a></th>
                    </tr>
                
                    <tr id="8d6b0a0afaa515e8c6cd97f608414c2c6ce83ae9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8d6b0a0afaa515e8c6cd97f608414c2c6ce83ae9">102</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Geometry-Aware_Symmetric_Domain_Adaptation_for_Monocular_Depth_Estimation_CVPR_2019_paper.html">Geometry-Aware Symmetric Domain Adaptation for Monocular Depth Estimation</a></th>
                    </tr>
                
                    <tr id="7d8be0302b754c903d96fd056c20207ad90ab4e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7d8be0302b754c903d96fd056c20207ad90ab4e6">102</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Piergiovanni_Representation_Flow_for_Action_Recognition_CVPR_2019_paper.html">Representation Flow for Action Recognition</a></th>
                    </tr>
                
                    <tr id="f09070b62123f6662bc77f4b670d54cc7156bcc5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f09070b62123f6662bc77f4b670d54cc7156bcc5">102</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tewari_FML_Face_Model_Learning_From_Videos_CVPR_2019_paper.html">FML: Face Model Learning From Videos</a></th>
                    </tr>
                
                    <tr id="5ead030d74f27e56cce54d64f8fba3a8ddad8bdb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5ead030d74f27e56cce54d64f8fba3a8ddad8bdb">101</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Supervised_Fitting_of_Geometric_Primitives_to_3D_Point_Clouds_CVPR_2019_paper.html">Supervised Fitting of Geometric Primitives to 3D Point Clouds</a></th>
                    </tr>
                
                    <tr id="bcd27a7e6091b7d44de4ddef28e4669b8027ac34">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bcd27a7e6091b7d44de4ddef28e4669b8027ac34">101</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Acuna_Devil_Is_in_the_Edges_Learning_Semantic_Boundaries_From_Noisy_CVPR_2019_paper.html">Devil Is in the Edges: Learning Semantic Boundaries From Noisy Annotations</a></th>
                    </tr>
                
                    <tr id="ca4d965ab8fd07fd236a2ec5b5c7a520077a3085">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ca4d965ab8fd07fd236a2ec5b5c7a520077a3085">101</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mithun_Weakly_Supervised_Video_Moment_Retrieval_From_Text_Queries_CVPR_2019_paper.html">Weakly Supervised Video Moment Retrieval From Text Queries</a></th>
                    </tr>
                
                    <tr id="bcd12a76bbd39719d8c3302f7031416e3ebf026b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bcd12a76bbd39719d8c3302f7031416e3ebf026b">100</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_LO-Net_Deep_Real-Time_Lidar_Odometry_CVPR_2019_paper.html">LO-Net: Deep Real-Time Lidar Odometry</a></th>
                    </tr>
                
                    <tr id="347f528e30d8f3e66267aa96fdaf20ff3ec89c5c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/347f528e30d8f3e66267aa96fdaf20ff3ec89c5c">99</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_ScratchDet_Training_Single-Shot_Object_Detectors_From_Scratch_CVPR_2019_paper.html">ScratchDet: Training Single-Shot Object Detectors From Scratch</a></th>
                    </tr>
                
                    <tr id="a167d8a4ee261540c2b709dde2d94572c6ea3fc8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a167d8a4ee261540c2b709dde2d94572c6ea3fc8">99</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Snapshot_Distillation_Teacher-Student_Optimization_in_One_Generation_CVPR_2019_paper.html">Snapshot Distillation: Teacher-Student Optimization in One Generation</a></th>
                    </tr>
                
                    <tr id="95e180199ca7cadd638afbeb340be9c84e63aa23">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/95e180199ca7cadd638afbeb340be9c84e63aa23">99</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Deshpande_Max-Sliced_Wasserstein_Distance_and_Its_Use_for_GANs_CVPR_2019_paper.html">Max-Sliced Wasserstein Distance and Its Use for GANs</a></th>
                    </tr>
                
                    <tr id="5320df369b54d88057f1e786b76b31610d157956">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5320df369b54d88057f1e786b76b31610d157956">99</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Habibie_In_the_Wild_Human_Pose_Estimation_Using_Explicit_2D_Features_CVPR_2019_paper.html">In the Wild Human Pose Estimation Using Explicit 2D Features and Intermediate 3D Representations</a></th>
                    </tr>
                
                    <tr id="b517f179ffd609247f0665e7247fbebb7a4e8ea3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b517f179ffd609247f0665e7247fbebb7a4e8ea3">99</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Lee_An_Energy_and_GPU-Computation_Efficient_Backbone_Network_for_Real-Time_Object_CVPRW_2019_paper.html">An Energy and GPU-Computation Efficient Backbone Network for Real-Time Object Detection</a></th>
                    </tr>
                
                    <tr id="370ea9a6a61e7faa682053a365b30c2f16cfb640">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/370ea9a6a61e7faa682053a365b30c2f16cfb640">98</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Pose2Seg_Detection_Free_Human_Instance_Segmentation_CVPR_2019_paper.html">Pose2Seg: Detection Free Human Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="a15487b1fc772568520305acaf6fa18392c2aa18">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a15487b1fc772568520305acaf6fa18392c2aa18">98</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Miao_SIXray_A_Large-Scale_Security_Inspection_X-Ray_Benchmark_for_Prohibited_Item_CVPR_2019_paper.html">SIXray: A Large-Scale Security Inspection X-Ray Benchmark for Prohibited Item Discovery in Overlapping Images</a></th>
                    </tr>
                
                    <tr id="836a143a4bf5b78f883934e3d5de611ca747aa38">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/836a143a4bf5b78f883934e3d5de611ca747aa38">98</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_Linear_Transformations_for_Fast_Image_and_Video_Style_Transfer_CVPR_2019_paper.html">Learning Linear Transformations for Fast Image and Video Style Transfer</a></th>
                    </tr>
                
                    <tr id="e5cd45ee1e91ba7a68d2a18d0735a75ed021766a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5cd45ee1e91ba7a68d2a18d0735a75ed021766a">98</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Perez-Rua_MFAS_Multimodal_Fusion_Architecture_Search_CVPR_2019_paper.html">MFAS: Multimodal Fusion Architecture Search</a></th>
                    </tr>
                
                    <tr id="9c042383bd8eb39eac442da96812e6b2273036bf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c042383bd8eb39eac442da96812e6b2273036bf">98</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lei_Octree_Guided_CNN_With_Spherical_Kernels_for_3D_Point_Clouds_CVPR_2019_paper.html">Octree Guided CNN With Spherical Kernels for 3D Point Clouds</a></th>
                    </tr>
                
                    <tr id="ed78a2671ef61c031759c01434678c282f23faec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ed78a2671ef61c031759c01434678c282f23faec">98</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sudhakaran_LSTA_Long_Short-Term_Attention_for_Egocentric_Action_Recognition_CVPR_2019_paper.html">LSTA: Long Short-Term Attention for Egocentric Action Recognition</a></th>
                    </tr>
                
                    <tr id="07c341ec8b82a3c4df9e0aeff53ef43a73f59829">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/07c341ec8b82a3c4df9e0aeff53ef43a73f59829">98</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_AdaptiveFace_Adaptive_Margin_and_Sampling_for_Face_Recognition_CVPR_2019_paper.html">AdaptiveFace: Adaptive Margin and Sampling for Face Recognition</a></th>
                    </tr>
                
                    <tr id="59be2e766fe2cd02b150a3e469a97a53ccf9b8db">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/59be2e766fe2cd02b150a3e469a97a53ccf9b8db">98</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/DOAI/Zamir_iSAID_A_Large-scale_Dataset_for_Instance_Segmentation_in_Aerial_Images_CVPRW_2019_paper.html">iSAID: A Large-scale Dataset for Instance Segmentation in Aerial Images</a></th>
                    </tr>
                
                    <tr id="5c2b23d8bd04542b43d341515e39bfc169f9788f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c2b23d8bd04542b43d341515e39bfc169f9788f">97</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dey_Doodle_to_Search_Practical_Zero-Shot_Sketch-Based_Image_Retrieval_CVPR_2019_paper.html">Doodle to Search: Practical Zero-Shot Sketch-Based Image Retrieval</a></th>
                    </tr>
                
                    <tr id="09503a2413d80749bf2815b18eb3c1849f60cff2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/09503a2413d80749bf2815b18eb3c1849f60cff2">97</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Goldman_Precise_Detection_in_Densely_Packed_Scenes_CVPR_2019_paper.html">Precise Detection in Densely Packed Scenes</a></th>
                    </tr>
                
                    <tr id="f7d8cbd10e0993385c7ca216eec92b806c9d18b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7d8cbd10e0993385c7ca216eec92b806c9d18b1">97</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Recurrent_Neural_Network_for_Un-Supervised_Learning_of_Monocular_Video_Visual_CVPR_2019_paper.html">Recurrent Neural Network for (Un-)Supervised Learning of Monocular Video Visual Odometry and Depth</a></th>
                    </tr>
                
                    <tr id="af3422d4f953ef54cd367cb48f7a28fba8e0addd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/af3422d4f953ef54cd367cb48f7a28fba8e0addd">97</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_UnOS_Unified_Unsupervised_Optical-Flow_and_Stereo-Depth_Estimation_by_Watching_Videos_CVPR_2019_paper.html">UnOS: Unified Unsupervised Optical-Flow and Stereo-Depth Estimation by Watching Videos</a></th>
                    </tr>
                
                    <tr id="cdc4730a37c9f9add9092a04da762f9abac5e988">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cdc4730a37c9f9add9092a04da762f9abac5e988">97</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_IP102_A_Large-Scale_Benchmark_Dataset_for_Insect_Pest_Recognition_CVPR_2019_paper.html">IP102: A Large-Scale Benchmark Dataset for Insect Pest Recognition</a></th>
                    </tr>
                
                    <tr id="97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/97fb5a7a5ce79da0cdc5f2d28063373303ef4f8f">97</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Attention_Based_Glaucoma_Detection_A_Large-Scale_Database_and_CNN_Model_CVPR_2019_paper.html">Attention Based Glaucoma Detection: A Large-Scale Database and CNN Model</a></th>
                    </tr>
                
                    <tr id="5df5561b55ab872f2b3df559ddd475299f660b42">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5df5561b55ab872f2b3df559ddd475299f660b42">96</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Neural_Task_Graphs_Generalizing_to_Unseen_Tasks_From_a_Single_CVPR_2019_paper.html">Neural Task Graphs: Generalizing to Unseen Tasks From a Single Video Demonstration</a></th>
                    </tr>
                
                    <tr id="a83500237ef2191473be5247639d2caed9be6f3b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a83500237ef2191473be5247639d2caed9be6f3b">96</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Generating_Multiple_Hypotheses_for_3D_Human_Pose_Estimation_With_Mixture_CVPR_2019_paper.html">Generating Multiple Hypotheses for 3D Human Pose Estimation With Mixture Density Network</a></th>
                    </tr>
                
                    <tr id="7834636155c6df9e674317ab2d151aace11ecc21">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7834636155c6df9e674317ab2d151aace11ecc21">96</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lu_Unsupervised_Domain-Specific_Deblurring_via_Disentangled_Representations_CVPR_2019_paper.html">Unsupervised Domain-Specific Deblurring via Disentangled Representations</a></th>
                    </tr>
                
                    <tr id="9e4c467d5bf3cc752f21be0b67e47f75dfb5a4ec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9e4c467d5bf3cc752f21be0b67e47f75dfb5a4ec">96</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Rolinek_Variational_Autoencoders_Pursue_PCA_Directions_by_Accident_CVPR_2019_paper.html">Variational Autoencoders Pursue PCA Directions (by Accident)</a></th>
                    </tr>
                
                    <tr id="aa59761d790e3287471b3b52861fd1f1bdb802a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aa59761d790e3287471b3b52861fd1f1bdb802a2">95</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Blind_Image_Deblurring_With_Local_Maximum_Gradient_Prior_CVPR_2019_paper.html">Blind Image Deblurring With Local Maximum Gradient Prior</a></th>
                    </tr>
                
                    <tr id="714df3e97817ec56b8dbc7217155adadf2a0487f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/714df3e97817ec56b8dbc7217155adadf2a0487f">95</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pu_Iterative_Alignment_Network_for_Continuous_Sign_Language_Recognition_CVPR_2019_paper.html">Iterative Alignment Network for Continuous Sign Language Recognition</a></th>
                    </tr>
                
                    <tr id="c677000c9078fdff8622be15a37db7d4945f36c2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c677000c9078fdff8622be15a37db7d4945f36c2">95</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shuster_Engaging_Image_Captioning_via_Personality_CVPR_2019_paper.html">Engaging Image Captioning via Personality</a></th>
                    </tr>
                
                    <tr id="f985c91ae59d8664c6e9023da6f3b7c896e0091a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f985c91ae59d8664c6e9023da6f3b7c896e0091a">95</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/RoyChowdhury_Automatic_adaptation_of_object_detectors_to_new_domains_using_self-training_CVPRW_2019_paper.html">Automatic adaptation of object detectors to new domains using self-training</a></th>
                    </tr>
                
                    <tr id="ecfaa4cdad213dbc2ececc7cbcea891096103108">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ecfaa4cdad213dbc2ececc7cbcea891096103108">94</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_A_Dataset_and_Benchmark_for_Large-Scale_Multi-Modal_Face_Anti-Spoofing_CVPR_2019_paper.html">A Dataset and Benchmark for Large-Scale Multi-Modal Face Anti-Spoofing</a></th>
                    </tr>
                
                    <tr id="7e42377dbaa3af86bcba0ccd614c6c0a4a7bd6a3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e42377dbaa3af86bcba0ccd614c6c0a4a7bd6a3">94</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Song_Unsupervised_Person_Image_Generation_With_Semantic_Parsing_Transformation_CVPR_2019_paper.html">Unsupervised Person Image Generation With Semantic Parsing Transformation</a></th>
                    </tr>
                
                    <tr id="be237edaec30c5001b3b952ce2e8e9c02b06f32b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/be237edaec30c5001b3b952ce2e8e9c02b06f32b">94</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Detailed_Human_Shape_Estimation_From_a_Single_Image_by_Hierarchical_CVPR_2019_paper.html">Detailed Human Shape Estimation From a Single Image by Hierarchical Mesh Deformation</a></th>
                    </tr>
                
                    <tr id="b09a6690634a41f503c91ca066e3d9ade69171db">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b09a6690634a41f503c91ca066e3d9ade69171db">94</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Inkawhich_Feature_Space_Perturbations_Yield_More_Transferable_Adversarial_Examples_CVPR_2019_paper.html">Feature Space Perturbations Yield More Transferable Adversarial Examples</a></th>
                    </tr>
                
                    <tr id="b437071ba192cb69e48284636b48788612c5f544">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b437071ba192cb69e48284636b48788612c5f544">94</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Landrieu_Point_Cloud_Oversegmentation_With_Graph-Structured_Deep_Metric_Learning_CVPR_2019_paper.html">Point Cloud Oversegmentation With Graph-Structured Deep Metric Learning</a></th>
                    </tr>
                
                    <tr id="358a85b85f3dec83ffaa50c2252615e7a1a42483">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/358a85b85f3dec83ffaa50c2252615e7a1a42483">94</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pilzer_Refine_and_Distill_Exploiting_Cycle-Inconsistency_and_Knowledge_Distillation_for_Unsupervised_CVPR_2019_paper.html">Refine and Distill: Exploiting Cycle-Inconsistency and Knowledge Distillation for Unsupervised Monocular Depth Estimation</a></th>
                    </tr>
                
                    <tr id="37ef97bd03a03d34a40ba5d6bbe4d3889c2b30f0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/37ef97bd03a03d34a40ba5d6bbe4d3889c2b30f0">93</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Iterative_Reorganization_With_Weak_Spatial_Constraints_Solving_Arbitrary_Jigsaw_Puzzles_CVPR_2019_paper.html">Iterative Reorganization With Weak Spatial Constraints: Solving Arbitrary Jigsaw Puzzles for Unsupervised Representation Learning</a></th>
                    </tr>
                
                    <tr id="dc58f99b618fbdb5e8a13d397d475a46f58b0af4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dc58f99b618fbdb5e8a13d397d475a46f58b0af4">93</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dovrat_Learning_to_Sample_CVPR_2019_paper.html">Learning to Sample</a></th>
                    </tr>
                
                    <tr id="0ef3782c4fdcaf5153ce8fed61c2f7446ed5f518">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ef3782c4fdcaf5153ce8fed61c2f7446ed5f518">93</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Attribute-Driven_Feature_Disentangling_and_Temporal_Aggregation_for_Video_Person_Re-Identification_CVPR_2019_paper.html">Attribute-Driven Feature Disentangling and Temporal Aggregation for Video Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="9fd71a80c7fe04d3d9e7693d311e9fe4f8e2b83f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9fd71a80c7fe04d3d9e7693d311e9fe4f8e2b83f">93</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Arbitrary_Shape_Scene_Text_Detection_With_Adaptive_Text_Region_Representation_CVPR_2019_paper.html">Arbitrary Shape Scene Text Detection With Adaptive Text Region Representation</a></th>
                    </tr>
                
                    <tr id="91a1370d26ee903296bb4990a84c23f2fa8e8c83">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/91a1370d26ee903296bb4990a84c23f2fa8e8c83">93</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cudeiro_Capture_Learning_and_Synthesis_of_3D_Speaking_Styles_CVPR_2019_paper.html">Capture, Learning, and Synthesis of 3D Speaking Styles</a></th>
                    </tr>
                
                    <tr id="4e1f12eadb4b2d964f04ac6f5f397833607d83d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4e1f12eadb4b2d964f04ac6f5f397833607d83d2">93</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Aljundi_Task-Free_Continual_Learning_CVPR_2019_paper.html">A Neural Dirichlet Process Mixture Model for Task-Free Continual Learning</a></th>
                    </tr>
                
                    <tr id="293f4397367cab1c648a1f6483f4e5b3eb3d2a2a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/293f4397367cab1c648a1f6483f4e5b3eb3d2a2a">92</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wan_Residual_Regression_With_Semantic_Prior_for_Crowd_Counting_CVPR_2019_paper.html">Residual Regression With Semantic Prior for Crowd Counting</a></th>
                    </tr>
                
                    <tr id="92d3d944d478783e46755b4b5196e360a099393e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/92d3d944d478783e46755b4b5196e360a099393e">92</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wertheimer_Few-Shot_Learning_With_Localization_in_Realistic_Settings_CVPR_2019_paper.html">Few-Shot Learning With Localization in Realistic Settings</a></th>
                    </tr>
                
                    <tr id="646736bca08f11140f0a3e77a2273533acefa6a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/646736bca08f11140f0a3e77a2273533acefa6a6">92</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Dual_Residual_Networks_Leveraging_the_Potential_of_Paired_Operations_for_CVPR_2019_paper.html">Dual Residual Networks Leveraging the Potential of Paired Operations for Image Restoration</a></th>
                    </tr>
                
                    <tr id="e7fe886600399448f3282c8da8fd98ab7e50eae3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e7fe886600399448f3282c8da8fd98ab7e50eae3">92</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Deshpande_Fast_Diverse_and_Accurate_Image_Captioning_Guided_by_Part-Of-Speech_CVPR_2019_paper.html">Fast, Diverse and Accurate Image Captioning Guided by Part-Of-Speech</a></th>
                    </tr>
                
                    <tr id="bbd6a81b792c751e121bfec2d7fcd16cb1d32266">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bbd6a81b792c751e121bfec2d7fcd16cb1d32266">91</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shysheya_Textured_Neural_Avatars_CVPR_2019_paper.html">Textured Neural Avatars</a></th>
                    </tr>
                
                    <tr id="17f2f3f7e58b916175d495109bc74b2757ef952a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/17f2f3f7e58b916175d495109bc74b2757ef952a">91</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Raff_Barrage_of_Random_Transforms_for_Adversarially_Robust_Defense_CVPR_2019_paper.html">Barrage of Random Transforms for Adversarially Robust Defense</a></th>
                    </tr>
                
                    <tr id="41db31c451cd819d22f9c0b90be110edc4424911">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/41db31c451cd819d22f9c0b90be110edc4424911">91</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Niu_Recursive_Visual_Attention_in_Visual_Dialog_CVPR_2019_paper.html">Recursive Visual Attention in Visual Dialog</a></th>
                    </tr>
                
                    <tr id="83069a26a0465120d63d6f4b9dee4e9ec758d466">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/83069a26a0465120d63d6f4b9dee4e9ec758d466">91</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Fast_and_Robust_Multi-Person_3D_Pose_Estimation_From_Multiple_Views_CVPR_2019_paper.html">Fast and Robust Multi-Person 3D Pose Estimation From Multiple Views</a></th>
                    </tr>
                
                    <tr id="42c9eaaa70124af1f41a90286db4a009c616d873">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/42c9eaaa70124af1f41a90286db4a009c616d873">91</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Fast_Spatio-Temporal_Residual_Network_for_Video_Super-Resolution_CVPR_2019_paper.html">Fast Spatio-Temporal Residual Network for Video Super-Resolution</a></th>
                    </tr>
                
                    <tr id="25bb378b1b70cf6a33f150fe02606f4d91ddd321">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/25bb378b1b70cf6a33f150fe02606f4d91ddd321">90</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Munjal_Query-Guided_End-To-End_Person_Search_CVPR_2019_paper.html">Query-Guided End-To-End Person Search</a></th>
                    </tr>
                
                    <tr id="5df04e4f416c0223b7786e478b078c0f6ffd8825">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5df04e4f416c0223b7786e478b078c0f6ffd8825">90</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Learning_to_Detect_Human-Object_Interactions_With_Knowledge_CVPR_2019_paper.html">Learning to Detect Human-Object Interactions With Knowledge</a></th>
                    </tr>
                
                    <tr id="80d2a4db9bc6121bd71458f1d9573981ce0d36ca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/80d2a4db9bc6121bd71458f1d9573981ce0d36ca">90</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qi_Amodal_Instance_Segmentation_With_KINS_Dataset_CVPR_2019_paper.html">Amodal Instance Segmentation With KINS Dataset</a></th>
                    </tr>
                
                    <tr id="7ab155f8f532a238bc29e054b498a6945c157ace">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ab155f8f532a238bc29e054b498a6945c157ace">90</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Salvador_Inverse_Cooking_Recipe_Generation_From_Food_Images_CVPR_2019_paper.html">Inverse Cooking: Recipe Generation From Food Images</a></th>
                    </tr>
                
                    <tr id="e8f442574299f068e2c8c685dcb6d18668e386f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e8f442574299f068e2c8c685dcb6d18668e386f5">89</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lee_CollaGAN_Collaborative_GAN_for_Missing_Image_Data_Imputation_CVPR_2019_paper.html">CollaGAN: Collaborative GAN for Missing Image Data Imputation</a></th>
                    </tr>
                
                    <tr id="45707ac4b40e4e52a22dc7255d68beb6ccaabeb7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/45707ac4b40e4e52a22dc7255d68beb6ccaabeb7">89</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Exploiting_Kernel_Sparsity_and_Entropy_for_Interpretable_CNN_Compression_CVPR_2019_paper.html">Exploiting Kernel Sparsity and Entropy for Interpretable CNN Compression</a></th>
                    </tr>
                
                    <tr id="5304bbad5f03f452bbc23f2870d794198aadd006">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5304bbad5f03f452bbc23f2870d794198aadd006">89</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Multi-Scale_Geometric_Consistency_Guided_Multi-View_Stereo_CVPR_2019_paper.html">Multi-Scale Geometric Consistency Guided Multi-View Stereo</a></th>
                    </tr>
                
                    <tr id="d2d3580faaa56be0eb7243fa119e6a7191924927">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d2d3580faaa56be0eb7243fa119e6a7191924927">89</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wijmans_Embodied_Question_Answering_in_Photorealistic_Environments_With_Point_Cloud_Perception_CVPR_2019_paper.html">Embodied Question Answering in Photorealistic Environments With Point Cloud Perception</a></th>
                    </tr>
                
                    <tr id="6c9bd4d49d7bd70e1610c0f28fbd78ff97d0d0b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c9bd4d49d7bd70e1610c0f28fbd78ff97d0d0b5">89</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Object-Aware_Aggregation_With_Bidirectional_Temporal_Graph_for_Video_Captioning_CVPR_2019_paper.html">Object-Aware Aggregation With Bidirectional Temporal Graph for Video Captioning</a></th>
                    </tr>
                
                    <tr id="01a8c6bc1d2d780a852282229f9112faf366ac4e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01a8c6bc1d2d780a852282229f9112faf366ac4e">89</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_A_Poisson-Gaussian_Denoising_Dataset_With_Real_Fluorescence_Microscopy_Images_CVPR_2019_paper.html">A Poisson-Gaussian Denoising Dataset With Real Fluorescence Microscopy Images</a></th>
                    </tr>
                
                    <tr id="c2cc82c2948c0513628a61d4ff829110750fdf9a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c2cc82c2948c0513628a61d4ff829110750fdf9a">88</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_STEP_Spatio-Temporal_Progressive_Learning_for_Video_Action_Detection_CVPR_2019_paper.html">STEP: Spatio-Temporal Progressive Learning for Video Action Detection</a></th>
                    </tr>
                
                    <tr id="96112f58cae6cbb85528ab1cb01550d106dc4ae8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96112f58cae6cbb85528ab1cb01550d106dc4ae8">88</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dutta_Semantically_Tied_Paired_Cycle_Consistency_for_Zero-Shot_Sketch-Based_Image_Retrieval_CVPR_2019_paper.html">Semantically Tied Paired Cycle Consistency for Zero-Shot Sketch-Based Image Retrieval</a></th>
                    </tr>
                
                    <tr id="d2067a4dd4898037f6279a1d761455144717cfd8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d2067a4dd4898037f6279a1d761455144717cfd8">88</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_SimulCap__Single-View_Human_Performance_Capture_With_Cloth_Simulation_CVPR_2019_paper.html">SimulCap : Single-View Human Performance Capture With Cloth Simulation</a></th>
                    </tr>
                
                    <tr id="63e0c494396c648fe034de1d275194d7a09a8d42">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/63e0c494396c648fe034de1d275194d7a09a8d42">88</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Partial_Order_Pruning_For_Best_SpeedAccuracy_Trade-Off_in_Neural_Architecture_CVPR_2019_paper.html">Partial Order Pruning: For Best Speed/Accuracy Trade-Off in Neural Architecture Search</a></th>
                    </tr>
                
                    <tr id="58a2a3bc72253dbb7368dd1cd502e95570e02f89">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/58a2a3bc72253dbb7368dd1cd502e95570e02f89">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sanakoyeu_Divide_and_Conquer_the_Embedding_Space_for_Metric_Learning_CVPR_2019_paper.html">Divide and Conquer the Embedding Space for Metric Learning</a></th>
                    </tr>
                
                    <tr id="763dc34af43b4d00b8a625ade38d6e314478ecc5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/763dc34af43b4d00b8a625ade38d6e314478ecc5">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kurmi_Attending_to_Discriminative_Certainty_for_Domain_Adaptation_CVPR_2019_paper.html">Attending to Discriminative Certainty for Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ecce0a7b0f9b2bfbc6ca2c99805bddd53178ac35">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Schwartz_Factor_Graph_Attention_CVPR_2019_paper.html">Factor Graph Attention</a></th>
                    </tr>
                
                    <tr id="ca419cdc254e739030c892407ccd12f48566c6a3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ca419cdc254e739030c892407ccd12f48566c6a3">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_DuLa-Net_A_Dual-Projection_Network_for_Estimating_Room_Layouts_From_a_CVPR_2019_paper.html">DuLa-Net: A Dual-Projection Network for Estimating Room Layouts From a Single RGB Panorama</a></th>
                    </tr>
                
                    <tr id="6c5416f0d0c33a111b5263b7e8c99c786a6c1095">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c5416f0d0c33a111b5263b7e8c99c786a6c1095">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gu_Mask-Guided_Portrait_Editing_With_Conditional_GANs_CVPR_2019_paper.html">Mask-Guided Portrait Editing With Conditional GANs</a></th>
                    </tr>
                
                    <tr id="cc17a0034ba91f71966dd0953b2e110de186c893">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cc17a0034ba91f71966dd0953b2e110de186c893">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Halimi_Unsupervised_Learning_of_Dense_Shape_Correspondence_CVPR_2019_paper.html">Unsupervised Learning of Dense Shape Correspondence</a></th>
                    </tr>
                
                    <tr id="f12d63bfe90833fe2bd49d1e7fc67798d76eed4e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f12d63bfe90833fe2bd49d1e7fc67798d76eed4e">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jang_Interactive_Image_Segmentation_via_Backpropagating_Refinement_Scheme_CVPR_2019_paper.html">Interactive Image Segmentation via Backpropagating Refinement Scheme</a></th>
                    </tr>
                
                    <tr id="171794f74f3d4f9da40548897a91638e79e423ae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/171794f74f3d4f9da40548897a91638e79e423ae">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Song_ApolloCar3D_A_Large_3D_Car_Instance_Understanding_Benchmark_for_Autonomous_CVPR_2019_paper.html">ApolloCar3D: A Large 3D Car Instance Understanding Benchmark for Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="85f309e0958a70231c993c4b353fb6412cbcb7bb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/85f309e0958a70231c993c4b353fb6412cbcb7bb">86</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yao_Attention-Aware_Multi-Stroke_Style_Transfer_CVPR_2019_paper.html">Attention-Aware Multi-Stroke Style Transfer</a></th>
                    </tr>
                
                    <tr id="54976d4aa7bd0ff450cba49c7c476b9260a7f2dc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/54976d4aa7bd0ff450cba49c7c476b9260a7f2dc">86</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Sequence-To-Sequence_Domain_Adaptation_Network_for_Robust_Text_Image_Recognition_CVPR_2019_paper.html">Sequence-To-Sequence Domain Adaptation Network for Robust Text Image Recognition</a></th>
                    </tr>
                
                    <tr id="6dc21177bdac4e3486f783bafea5ce9e0e07c878">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6dc21177bdac4e3486f783bafea5ce9e0e07c878">86</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_DistillHash_Unsupervised_Deep_Hashing_by_Distilling_Data_Pairs_CVPR_2019_paper.html">DistillHash: Unsupervised Deep Hashing by Distilling Data Pairs</a></th>
                    </tr>
                
                    <tr id="65ec3cca4d76a9db6dfd4b2e64c5b4c4beecf988">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/65ec3cca4d76a9db6dfd4b2e64c5b4c4beecf988">86</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Singh_FineGAN_Unsupervised_Hierarchical_Disentanglement_for_Fine-Grained_Object_Generation_and_Discovery_CVPR_2019_paper.html">FineGAN: Unsupervised Hierarchical Disentanglement for Fine-Grained Object Generation and Discovery</a></th>
                    </tr>
                
                    <tr id="50ddc50a8dcda5361b8050648eac6b8465dda496">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50ddc50a8dcda5361b8050648eac6b8465dda496">86</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Bringing_a_Blurry_Frame_Alive_at_High_Frame-Rate_With_an_CVPR_2019_paper.html">Bringing a Blurry Frame Alive at High Frame-Rate With an Event Camera</a></th>
                    </tr>
                
                    <tr id="9e5501460f55fe69fea82543098092e3ab34a9f8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9e5501460f55fe69fea82543098092e3ab34a9f8">86</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Leveraging_Heterogeneous_Auxiliary_Tasks_to_Assist_Crowd_Counting_CVPR_2019_paper.html">Leveraging Heterogeneous Auxiliary Tasks to Assist Crowd Counting</a></th>
                    </tr>
                
                    <tr id="001ed0982b09a13975421fcf2c45ac2cd2b579dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/001ed0982b09a13975421fcf2c45ac2cd2b579dd">86</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Cai_NTIRE_2019_Challenge_on_Real_Image_Super-Resolution_Methods_and_Results_CVPRW_2019_paper.html">NTIRE 2019 Challenge on Real Image Super-Resolution: Methods and Results</a></th>
                    </tr>
                
                    <tr id="ac5d96111cf57a2062f627cbcefcd5303ba929d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ac5d96111cf57a2062f627cbcefcd5303ba929d2">85</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_RegularFace_Deep_Face_Recognition_via_Exclusive_Regularization_CVPR_2019_paper.html">RegularFace: Deep Face Recognition via Exclusive Regularization</a></th>
                    </tr>
                
                    <tr id="7c61a2f4349b55ef6e5d62e5606970c8ca3d09ae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c61a2f4349b55ef6e5d62e5606970c8ca3d09ae">85</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Abavisani_Improving_the_Performance_of_Unimodal_Dynamic_Hand-Gesture_Recognition_With_Multimodal_CVPR_2019_paper.html">Improving the Performance of Unimodal Dynamic Hand-Gesture Recognition With Multimodal Training</a></th>
                    </tr>
                
                    <tr id="3b87e795f1f501843f7f99e83e38f125f6af8600">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3b87e795f1f501843f7f99e83e38f125f6af8600">85</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_StoryGAN_A_Sequential_Conditional_GAN_for_Story_Visualization_CVPR_2019_paper.html">StoryGAN: A Sequential Conditional GAN for Story Visualization</a></th>
                    </tr>
                
                    <tr id="92a57020c1bfdc8724841edbb1286da783f8425a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/92a57020c1bfdc8724841edbb1286da783f8425a">85</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Nah_Recurrent_Neural_Networks_With_Intra-Frame_Iterations_for_Video_Deblurring_CVPR_2019_paper.html">Recurrent Neural Networks With Intra-Frame Iterations for Video Deblurring</a></th>
                    </tr>
                
                    <tr id="ed2da6d192ec8aedf8cf736ad58cfdf923d8381c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ed2da6d192ec8aedf8cf736ad58cfdf923d8381c">85</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sarfraz_Efficient_Parameter-Free_Clustering_Using_First_Neighbor_Relations_CVPR_2019_paper.html">Efficient Parameter-Free Clustering Using First Neighbor Relations</a></th>
                    </tr>
                
                    <tr id="b59cf640d0f43c38b5ad4bce0c1991f1078fcd19">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b59cf640d0f43c38b5ad4bce0c1991f1078fcd19">84</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shen_Cyclic_Guidance_for_Weakly_Supervised_Joint_Detection_and_Segmentation_CVPR_2019_paper.html">Cyclic Guidance for Weakly Supervised Joint Detection and Segmentation</a></th>
                    </tr>
                
                    <tr id="163e27c51bf00ae676ce184d04da42f0215ac880">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/163e27c51bf00ae676ce184d04da42f0215ac880">84</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_3DN_3D_Deformation_Network_CVPR_2019_paper.html">3DN: 3D Deformation Network</a></th>
                    </tr>
                
                    <tr id="e2e5093f8164b3c3bb5ac0d223c2100e9f334f6c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e2e5093f8164b3c3bb5ac0d223c2100e9f334f6c">84</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhong_Unequal-Training_for_Deep_Face_Recognition_With_Long-Tailed_Noisy_Data_CVPR_2019_paper.html">Unequal-Training for Deep Face Recognition With Long-Tailed Noisy Data</a></th>
                    </tr>
                
                    <tr id="8573393e8b14e3011ae6ee91dc7bbde7077633c1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8573393e8b14e3011ae6ee91dc7bbde7077633c1">84</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Label_Efficient_Semi-Supervised_Learning_via_Graph_Filtering_CVPR_2019_paper.html">Label Efficient Semi-Supervised Learning via Graph Filtering</a></th>
                    </tr>
                
                    <tr id="7e0d6439b1208bf264a4c79eb69e081a0fa873cf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e0d6439b1208bf264a4c79eb69e081a0fa873cf">84</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Meyer_Sensor_Fusion_for_Joint_3D_Object_Detection_and_Semantic_Segmentation_CVPRW_2019_paper.html">Sensor Fusion for Joint 3D Object Detection and Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="7e0d6439b1208bf264a4c79eb69e081a0fa873cf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e0d6439b1208bf264a4c79eb69e081a0fa873cf">84</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Meyer_Sensor_Fusion_for_Joint_3D_Object_Detection_and_Semantic_Segmentation_CVPRW_2019_paper.html">Sensor Fusion for Joint 3D Object Detection and Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="a85755b2f1e6722fa499dbfda475190386b556ed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a85755b2f1e6722fa499dbfda475190386b556ed">83</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tang_Learning-Based_Sampling_for_Natural_Image_Matting_CVPR_2019_paper.html">Learning-Based Sampling for Natural Image Matting</a></th>
                    </tr>
                
                    <tr id="70b101771060a43ab78bd6ebe4511cef5e7b0d05">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70b101771060a43ab78bd6ebe4511cef5e7b0d05">83</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_InverseRenderNet_Learning_Single_Image_Inverse_Rendering_CVPR_2019_paper.html">InverseRenderNet: Learning Single Image Inverse Rendering</a></th>
                    </tr>
                
                    <tr id="d0d1433f27c90f1128ccd0d3cfe5678655b52224">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d0d1433f27c90f1128ccd0d3cfe5678655b52224">83</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_A_Late_Fusion_CNN_for_Digital_Matting_CVPR_2019_paper.html">A Late Fusion CNN for Digital Matting</a></th>
                    </tr>
                
                    <tr id="044c56af7005c2013ce24c7199af716319378d7f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/044c56af7005c2013ce24c7199af716319378d7f">83</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Alamri_Audio_Visual_Scene-Aware_Dialog_CVPR_2019_paper.html">Audio Visual Scene-Aware Dialog</a></th>
                    </tr>
                
                    <tr id="9060784d1c933e8f77f97577326b1f60f3ba5f7c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9060784d1c933e8f77f97577326b1f60f3ba5f7c">83</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yi_APDrawingGAN_Generating_Artistic_Portrait_Drawings_From_Face_Photos_With_Hierarchical_CVPR_2019_paper.html">APDrawingGAN: Generating Artistic Portrait Drawings From Face Photos With Hierarchical GANs</a></th>
                    </tr>
                
                    <tr id="bcf9f481cc8caa41fbc431d10c588715ee7942cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bcf9f481cc8caa41fbc431d10c588715ee7942cc">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pittaluga_Revealing_Scenes_by_Inverting_Structure_From_Motion_Reconstructions_CVPR_2019_paper.html">Revealing Scenes by Inverting Structure From Motion Reconstructions</a></th>
                    </tr>
                
                    <tr id="f51a4def58a5ded27e9bfe2647110c3cbb15762d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f51a4def58a5ded27e9bfe2647110c3cbb15762d">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hung_SCOPS_Self-Supervised_Co-Part_Segmentation_CVPR_2019_paper.html">SCOPS: Self-Supervised Co-Part Segmentation</a></th>
                    </tr>
                
                    <tr id="2baf7eadbced13b1a7296b9c9dc40f5cedbecf63">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2baf7eadbced13b1a7296b9c9dc40f5cedbecf63">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_DrivingStereo_A_Large-Scale_Dataset_for_Stereo_Matching_in_Autonomous_Driving_CVPR_2019_paper.html">DrivingStereo: A Large-Scale Dataset for Stereo Matching in Autonomous Driving Scenarios</a></th>
                    </tr>
                
                    <tr id="30c63a4a9ba5ab000765b387faded1c223ef277d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/30c63a4a9ba5ab000765b387faded1c223ef277d">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_A_Bayesian_Perspective_on_the_Deep_Image_Prior_CVPR_2019_paper.html">A Bayesian Perspective on the Deep Image Prior</a></th>
                    </tr>
                
                    <tr id="6a4879ab3ae5a506bc836c905bb7ae86c3556b9a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a4879ab3ae5a506bc836c905bb7ae86c3556b9a">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Su_Multi-Person_Pose_Estimation_With_Enhanced_Channel-Wise_and_Spatial_Information_CVPR_2019_paper.html">Multi-Person Pose Estimation With Enhanced Channel-Wise and Spatial Information</a></th>
                    </tr>
                
                    <tr id="08a302f0bb8dc360ae3a0a20fa7b7555920380d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/08a302f0bb8dc360ae3a0a20fa7b7555920380d4">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Unified_Visual-Semantic_Embeddings_Bridging_Vision_and_Language_With_Structured_Meaning_CVPR_2019_paper.html">Unified Visual-Semantic Embeddings: Bridging Vision and Language With Structured Meaning Representations</a></th>
                    </tr>
                
                    <tr id="a794fe1321a9a27867ffba33bb84163c8298b986">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a794fe1321a9a27867ffba33bb84163c8298b986">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Batra_Improved_Road_Connectivity_by_Joint_Learning_of_Orientation_and_Segmentation_CVPR_2019_paper.html">Improved Road Connectivity by Joint Learning of Orientation and Segmentation</a></th>
                    </tr>
                
                    <tr id="2ea0ff9044c2dbb4adc32dd9113a52053ff7eb36">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ea0ff9044c2dbb4adc32dd9113a52053ff7eb36">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Selective_Sensor_Fusion_for_Neural_Visual-Inertial_Odometry_CVPR_2019_paper.html">Selective Sensor Fusion for Neural Visual-Inertial Odometry</a></th>
                    </tr>
                
                    <tr id="f4bc9475c4bc4950cd02d8e9bb8c31fd4ffa75d8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f4bc9475c4bc4950cd02d8e9bb8c31fd4ffa75d8">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_Cross-Modal_Embeddings_With_Adversarial_Networks_for_Cooking_Recipes_and_CVPR_2019_paper.html">Learning Cross-Modal Embeddings With Adversarial Networks for Cooking Recipes and Food Images</a></th>
                    </tr>
                
                    <tr id="057444e01041ffeb50705e0b056532c2e5e15a2e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/057444e01041ffeb50705e0b056532c2e5e15a2e">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gopalakrishnan_A_Neural_Temporal_Model_for_Human_Motion_Prediction_CVPR_2019_paper.html">A Neural Temporal Model for Human Motion Prediction</a></th>
                    </tr>
                
                    <tr id="05ba6878b20f7feba68a6fc63d3e8d348b177b8d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05ba6878b20f7feba68a6fc63d3e8d348b177b8d">81</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Giancola_Leveraging_Shape_Completion_for_3D_Siamese_Tracking_CVPR_2019_paper.html">Leveraging Shape Completion for 3D Siamese Tracking</a></th>
                    </tr>
                
                    <tr id="32873f6111963607d3f768f4685fe8137fdd1253">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/32873f6111963607d3f768f4685fe8137fdd1253">81</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Learning_to_Cluster_Faces_on_an_Affinity_Graph_CVPR_2019_paper.html">Learning to Cluster Faces on an Affinity Graph</a></th>
                    </tr>
                
                    <tr id="ea8d6c2de162e0f9ad89af7b950333cb29e94622">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ea8d6c2de162e0f9ad89af7b950333cb29e94622">81</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xian_Semantic_Projection_Network_for_Zero-_and_Few-Label_Semantic_Segmentation_CVPR_2019_paper.html">Semantic Projection Network for Zero- and Few-Label Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="510b6717750d711f590e4df0e9a9c82ff332ff46">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/510b6717750d711f590e4df0e9a9c82ff332ff46">81</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mandal_Out-Of-Distribution_Detection_for_Generalized_Zero-Shot_Action_Recognition_CVPR_2019_paper.html">Out-Of-Distribution Detection for Generalized Zero-Shot Action Recognition</a></th>
                    </tr>
                
                    <tr id="a34b1a2cb44cbf647fb64dc9de4c128834bd4cef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a34b1a2cb44cbf647fb64dc9de4c128834bd4cef">81</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Jackson_Style_Augmentation_Data_Augmentation_via_Style_Randomization_CVPRW_2019_paper.html">Style Augmentation: Data Augmentation via Style Randomization</a></th>
                    </tr>
                
                    <tr id="9c987e0edec308f87fcdd3cf872318032d46310d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c987e0edec308f87fcdd3cf872318032d46310d">80</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Towards_Real_Scene_Super-Resolution_With_Raw_Images_CVPR_2019_paper.html">Towards Real Scene Super-Resolution With Raw Images</a></th>
                    </tr>
                
                    <tr id="0eac6cbd150b1a7e9d757ccc871eea2bf0d89e42">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0eac6cbd150b1a7e9d757ccc871eea2bf0d89e42">80</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Diaz_Soft_Labels_for_Ordinal_Regression_CVPR_2019_paper.html">Soft Labels for Ordinal Regression</a></th>
                    </tr>
                
                    <tr id="5150454f20ebb8314d00223ad23347d5fa0d1eb8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5150454f20ebb8314d00223ad23347d5fa0d1eb8">80</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Teichmann_Detect-To-Retrieve_Efficient_Regional_Aggregation_for_Image_Search_CVPR_2019_paper.html">Detect-To-Retrieve: Efficient Regional Aggregation for Image Search</a></th>
                    </tr>
                
                    <tr id="1a2c22fb5db87e4348400fc387492690be9e0298">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a2c22fb5db87e4348400fc387492690be9e0298">80</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Self-Supervised_Convolutional_Subspace_Clustering_Network_CVPR_2019_paper.html">Self-Supervised Convolutional Subspace Clustering Network</a></th>
                    </tr>
                
                    <tr id="5809decf0a47a8a6be5c0525cd9f92e1e7d4c75f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5809decf0a47a8a6be5c0525cd9f92e1e7d4c75f">80</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xin_A_Theory_of_Fermat_Paths_for_Non-Line-Of-Sight_Shape_Reconstruction_CVPR_2019_paper.html">A Theory of Fermat Paths for Non-Line-Of-Sight Shape Reconstruction</a></th>
                    </tr>
                
                    <tr id="de315e7f34fd4efa5d709ec1a5531bee4066ebc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/de315e7f34fd4efa5d709ec1a5531bee4066ebc1">79</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_TAFE-Net_Task-Aware_Feature_Embeddings_for_Low_Shot_Learning_CVPR_2019_paper.html">TAFE-Net: Task-Aware Feature Embeddings for Low Shot Learning</a></th>
                    </tr>
                
                    <tr id="f26dc5b1ff5482b368144c41694260cef066942e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f26dc5b1ff5482b368144c41694260cef066942e">79</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Robust_Facial_Landmark_Detection_via_Occlusion-Adaptive_Deep_Networks_CVPR_2019_paper.html">Robust Facial Landmark Detection via Occlusion-Adaptive Deep Networks</a></th>
                    </tr>
                
                    <tr id="1a83564d61aebde360c0be4834cf6eb4c472c1bd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a83564d61aebde360c0be4834cf6eb4c472c1bd">79</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xiao_MeshAdv_Adversarial_Meshes_for_Visual_Recognition_CVPR_2019_paper.html">MeshAdv: Adversarial Meshes for Visual Recognition</a></th>
                    </tr>
                
                    <tr id="bc9a966f00087279414d2794dd56c36fdbde1414">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bc9a966f00087279414d2794dd56c36fdbde1414">79</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Neural_RGBrD_Sensing_Depth_and_Uncertainty_From_a_Video_Camera_CVPR_2019_paper.html">Neural RGB®D Sensing: Depth and Uncertainty From a Video Camera</a></th>
                    </tr>
                
                    <tr id="b351f2fe7e48cffb405f2e593ace88d79ecfbc53">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b351f2fe7e48cffb405f2e593ace88d79ecfbc53">79</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Residual_Networks_for_Light_Field_Image_Super-Resolution_CVPR_2019_paper.html">Residual Networks for Light Field Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="0cdef47d342cae516f67efd6e4991f4825043b70">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0cdef47d342cae516f67efd6e4991f4825043b70">79</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Regularizing_Activation_Distribution_for_Training_Binarized_Deep_Networks_CVPR_2019_paper.html">Regularizing Activation Distribution for Training Binarized Deep Networks</a></th>
                    </tr>
                
                    <tr id="dc9f7580aca1e82744076d441dcbfbf1ac51e69d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dc9f7580aca1e82744076d441dcbfbf1ac51e69d">78</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Dense_Depth_Posterior_DDP_From_Single_Image_and_Sparse_Range_CVPR_2019_paper.html">Dense Depth Posterior (DDP) From Single Image and Sparse Range</a></th>
                    </tr>
                
                    <tr id="2d20253a2c87c8c6a30441051a373d6ce269fb83">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d20253a2c87c8c6a30441051a373d6ce269fb83">78</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Sliced_Wasserstein_Generative_Models_CVPR_2019_paper.html">Sliced Wasserstein Generative Models</a></th>
                    </tr>
                
                    <tr id="7e5f2824219d3f2253245a9a07be5eae877a8ec6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e5f2824219d3f2253245a9a07be5eae877a8ec6">78</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Raaj_Efficient_Online_Multi-Person_2D_Pose_Tracking_With_Recurrent_Spatio-Temporal_Affinity_CVPR_2019_paper.html">Efficient Online Multi-Person 2D Pose Tracking With Recurrent Spatio-Temporal Affinity Fields</a></th>
                    </tr>
                
                    <tr id="edbab8c313fc6d07a2116ab78248ff8af7bd6f4b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/edbab8c313fc6d07a2116ab78248ff8af7bd6f4b">78</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Reasoning_Visual_Dialogs_With_Structural_and_Partial_Observations_CVPR_2019_paper.html">Reasoning Visual Dialogs With Structural and Partial Observations</a></th>
                    </tr>
                
                    <tr id="7e96d0a69f5d81c353ca12ffb201441867a311df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e96d0a69f5d81c353ca12ffb201441867a311df">78</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Quadrianto_Discovering_Fair_Representations_in_the_Data_Domain_CVPR_2019_paper.html">Discovering Fair Representations in the Data Domain</a></th>
                    </tr>
                
                    <tr id="64d08969fe43a80172bb4151a45dc031d2119022">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/64d08969fe43a80172bb4151a45dc031d2119022">78</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Brahmbhatt_ContactDB_Analyzing_and_Predicting_Grasp_Contact_via_Thermal_Imaging_CVPR_2019_paper.html">ContactDB: Analyzing and Predicting Grasp Contact via Thermal Imaging</a></th>
                    </tr>
                
                    <tr id="36eac4877193fe0d137c9fd00962f1c54cca2e2b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/36eac4877193fe0d137c9fd00962f1c54cca2e2b">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Learning_Channel-Wise_Interactions_for_Binary_Convolutional_Neural_Networks_CVPR_2019_paper.html">Learning Channel-Wise Interactions for Binary Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="26c1f4b14eb830f5595b74115578f00b1c27844e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26c1f4b14eb830f5595b74115578f00b1c27844e">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Unsupervised_Moving_Object_Detection_via_Contextual_Information_Separation_CVPR_2019_paper.html">Unsupervised Moving Object Detection via Contextual Information Separation</a></th>
                    </tr>
                
                    <tr id="470f8a226ff414f73e75dd0c6f9258a07809c22a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/470f8a226ff414f73e75dd0c6f9258a07809c22a">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Weng_Photo_Wake-Up_3D_Character_Animation_From_a_Single_Photo_CVPR_2019_paper.html">Photo Wake-Up: 3D Character Animation From a Single Photo</a></th>
                    </tr>
                
                    <tr id="791fa4797683469f91b27940253c7725c9717f24">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/791fa4797683469f91b27940253c7725c9717f24">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_CapSal_Leveraging_Captioning_to_Boost_Semantics_for_Salient_Object_Detection_CVPR_2019_paper.html">CapSal: Leveraging Captioning to Boost Semantics for Salient Object Detection</a></th>
                    </tr>
                
                    <tr id="701e412959ae474ca2699ce0611030f1221eaa70">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/701e412959ae474ca2699ce0611030f1221eaa70">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Large-Scale_Few-Shot_Learning_Knowledge_Transfer_With_Class_Hierarchy_CVPR_2019_paper.html">Large-Scale Few-Shot Learning: Knowledge Transfer With Class Hierarchy</a></th>
                    </tr>
                
                    <tr id="1831fb8b884d3686a638be5d05034d831e81b2e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1831fb8b884d3686a638be5d05034d831e81b2e1">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Monocular_Depth_Estimation_Using_Relative_Depth_Maps_CVPR_2019_paper.html">Monocular Depth Estimation Using Relative Depth Maps</a></th>
                    </tr>
                
                    <tr id="3ad2414d272fce5eec4f3bc1b01e1dc9027c47bf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ad2414d272fce5eec4f3bc1b01e1dc9027c47bf">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lin_DuDoNet_Dual_Domain_Network_for_CT_Metal_Artifact_Reduction_CVPR_2019_paper.html">DuDoNet: Dual Domain Network for CT Metal Artifact Reduction</a></th>
                    </tr>
                
                    <tr id="06545a9e16f778a5faecde7836003830b7fb188f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/06545a9e16f778a5faecde7836003830b7fb188f">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dwivedi_Representation_Similarity_Analysis_for_Efficient_Task_Taxonomy__Transfer_Learning_CVPR_2019_paper.html">Representation Similarity Analysis for Efficient Task Taxonomy &amp; Transfer Learning</a></th>
                    </tr>
                
                    <tr id="3984845ee41dd4bbd3fe5c70521e4a1d2aa05f99">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3984845ee41dd4bbd3fe5c70521e4a1d2aa05f99">77</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Li_AnonymousNet_Natural_Face_De-Identification_With_Measurable_Privacy_CVPRW_2019_paper.html">AnonymousNet: Natural Face De-Identification With Measurable Privacy</a></th>
                    </tr>
                
                    <tr id="623304a67b1fb08f488d60ad7ef3079f1b96a0cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/623304a67b1fb08f488d60ad7ef3079f1b96a0cd">77</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Kim_GRDNGrouped_Residual_Dense_Network_for_Real_Image_Denoising_and_GAN-Based_CVPRW_2019_paper.html">GRDN:Grouped Residual Dense Network for Real Image Denoising and GAN-Based Real-World Noise Modeling</a></th>
                    </tr>
                
                    <tr id="d878aac73038c3bc175ccc2b93acc04675f33bbd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d878aac73038c3bc175ccc2b93acc04675f33bbd">76</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shou_DMC-Net_Generating_Discriminative_Motion_Cues_for_Fast_Compressed_Video_Action_CVPR_2019_paper.html">DMC-Net: Generating Discriminative Motion Cues for Fast Compressed Video Action Recognition</a></th>
                    </tr>
                
                    <tr id="0d6ff2398d85edb0cea8a24df01784696f7c40ca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0d6ff2398d85edb0cea8a24df01784696f7c40ca">76</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Example-Guided_Style-Consistent_Image_Synthesis_From_Semantic_Labeling_CVPR_2019_paper.html">Example-Guided Style-Consistent Image Synthesis From Semantic Labeling</a></th>
                    </tr>
                
                    <tr id="98c6e5c45338c5e718592aa4c04b740fb30f81a4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/98c6e5c45338c5e718592aa4c04b740fb30f81a4">76</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Camera_Lens_Super-Resolution_CVPR_2019_paper.html">Camera Lens Super-Resolution</a></th>
                    </tr>
                
                    <tr id="6226eaa30b3026df602719d05c2cb473cce5013f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6226eaa30b3026df602719d05c2cb473cce5013f">76</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Rochan_Video_Summarization_by_Learning_From_Unpaired_Data_CVPR_2019_paper.html">Video Summarization by Learning From Unpaired Data</a></th>
                    </tr>
                
                    <tr id="6300a88665387476b4db55b24f9f06926857d526">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6300a88665387476b4db55b24f9f06926857d526">76</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Disentangling_Latent_Hands_for_Image_Synthesis_and_Pose_Estimation_CVPR_2019_paper.html">Disentangling Latent Hands for Image Synthesis and Pose Estimation</a></th>
                    </tr>
                
                    <tr id="9734483c27278b107495f963262412a798c858ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9734483c27278b107495f963262412a798c858ab">76</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Event-Based_High_Dynamic_Range_Image_and_Very_High_Frame_Rate_CVPR_2019_paper.html">Event-Based High Dynamic Range Image and Very High Frame Rate Video Generation Using Conditional Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="6239750ec44e3663606db39c0a26662999e0d220">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6239750ec44e3663606db39c0a26662999e0d220">76</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fu_A_Variational_Pan-Sharpening_With_Local_Gradient_Constraints_CVPR_2019_paper.html">A Variational Pan-Sharpening With Local Gradient Constraints</a></th>
                    </tr>
                
                    <tr id="852b75a65e664ccb468ac95cd8ff51b1a371949e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/852b75a65e664ccb468ac95cd8ff51b1a371949e">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_MVF-Net_Multi-View_3D_Face_Morphable_Model_Regression_CVPR_2019_paper.html">MVF-Net: Multi-View 3D Face Morphable Model Regression</a></th>
                    </tr>
                
                    <tr id="832ac3846cec3f6d58b840490094271f0420807e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/832ac3846cec3f6d58b840490094271f0420807e">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lee_SFNet_Learning_Object-Aware_Semantic_Correspondence_CVPR_2019_paper.html">SFNet: Learning Object-Aware Semantic Correspondence</a></th>
                    </tr>
                
                    <tr id="fdf3189a6b3bdea58d4caf827485f038ca17f629">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fdf3189a6b3bdea58d4caf827485f038ca17f629">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Nie_Multi-Level_Context_Ultra-Aggregation_for_Stereo_Matching_CVPR_2019_paper.html">Multi-Level Context Ultra-Aggregation for Stereo Matching</a></th>
                    </tr>
                
                    <tr id="15a30799d117d5b61e1a39fb7c8a8580d71a792f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15a30799d117d5b61e1a39fb7c8a8580d71a792f">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cui_ToothNet_Automatic_Tooth_Instance_Segmentation_and_Identification_From_Cone_Beam_CVPR_2019_paper.html">ToothNet: Automatic Tooth Instance Segmentation and Identification From Cone Beam CT Images</a></th>
                    </tr>
                
                    <tr id="c6a3aff5cb098a402f5384ed46b333dad672044a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c6a3aff5cb098a402f5384ed46b333dad672044a">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Curls__Whey_Boosting_Black-Box_Adversarial_Attacks_CVPR_2019_paper.html">Curls &amp; Whey: Boosting Black-Box Adversarial Attacks</a></th>
                    </tr>
                
                    <tr id="f8c551e3b51aeec4013e2b82d9cc97affd02972a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f8c551e3b51aeec4013e2b82d9cc97affd02972a">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Customizable_Architecture_Search_for_Semantic_Segmentation_CVPR_2019_paper.html">Customizable Architecture Search for Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="f9edf84ca07ba4b17f309b16f685af2819ead564">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f9edf84ca07ba4b17f309b16f685af2819ead564">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Attribute-Aware_Face_Aging_With_Wavelet-Based_Generative_Adversarial_Networks_CVPR_2019_paper.html">Attribute-Aware Face Aging With Wavelet-Based Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="9abc8fa5ea961dd2e9951f298e026de9e6453df1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9abc8fa5ea961dd2e9951f298e026de9e6453df1">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Parsing_R-CNN_for_Instance-Level_Human_Analysis_CVPR_2019_paper.html">Parsing R-CNN for Instance-Level Human Analysis</a></th>
                    </tr>
                
                    <tr id="a1b873100aec4b317674aff0e22b2be2c1a4170b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a1b873100aec4b317674aff0e22b2be2c1a4170b">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Wide-Context_Semantic_Image_Extrapolation_CVPR_2019_paper.html">Wide-Context Semantic Image Extrapolation</a></th>
                    </tr>
                
                    <tr id="d66e1c68c91614433e85418cb879ba7a60f93262">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d66e1c68c91614433e85418cb879ba7a60f93262">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Azinovic_Inverse_Path_Tracing_for_Joint_Material_and_Lighting_Estimation_CVPR_2019_paper.html">Inverse Path Tracing for Joint Material and Lighting Estimation</a></th>
                    </tr>
                
                    <tr id="7770c63a3680730e4602a9b8bf497e9f4a01aca2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7770c63a3680730e4602a9b8bf497e9f4a01aca2">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_d-SNE_Domain_Adaptation_Using_Stochastic_Neighborhood_Embedding_CVPR_2019_paper.html">d-SNE: Domain Adaptation Using Stochastic Neighborhood Embedding</a></th>
                    </tr>
                
                    <tr id="10dca39820f7c60828cba87e25ae7caacc211840">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/10dca39820f7c60828cba87e25ae7caacc211840">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Few-Shot_Adaptive_Faster_R-CNN_CVPR_2019_paper.html">Few-Shot Adaptive Faster R-CNN</a></th>
                    </tr>
                
                    <tr id="076776ebeb287da0d48da25deb276b8bbab7cf79">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/076776ebeb287da0d48da25deb276b8bbab7cf79">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Hyperspectral_Image_Reconstruction_Using_a_Deep_Spatial-Spectral_Prior_CVPR_2019_paper.html">Hyperspectral Image Reconstruction Using a Deep Spatial-Spectral Prior</a></th>
                    </tr>
                
                    <tr id="e4acba889d1fcd7bcf82d4593a9044b9dc119de0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e4acba889d1fcd7bcf82d4593a9044b9dc119de0">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wagner_Interpretable_and_Fine-Grained_Visual_Explanations_for_Convolutional_Neural_Networks_CVPR_2019_paper.html">Interpretable and Fine-Grained Visual Explanations for Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="3efaf9015e28e72cc511f94de5d33378a1364d64">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3efaf9015e28e72cc511f94de5d33378a1364d64">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Su_Kernel_Transformer_Networks_for_Compact_Spherical_Convolution_CVPR_2019_paper.html">Kernel Transformer Networks for Compact Spherical Convolution</a></th>
                    </tr>
                
                    <tr id="3fa9269c973c70fb64c5ebafeb7e120e323a7472">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3fa9269c973c70fb64c5ebafeb7e120e323a7472">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ke_Time-Conditioned_Action_Anticipation_in_One_Shot_CVPR_2019_paper.html">Time-Conditioned Action Anticipation in One Shot</a></th>
                    </tr>
                
                    <tr id="3efaf9015e28e72cc511f94de5d33378a1364d64">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3efaf9015e28e72cc511f94de5d33378a1364d64">74</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SUMO/Su_Kernel_Transformer_Networks_for_Compact_Spherical_Convolution_CVPRW_2019_paper.html">Kernel Transformer Networks for Compact Spherical Convolution</a></th>
                    </tr>
                
                    <tr id="ed0af2310fc7e5c41119e99347d2af64cb356334">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ed0af2310fc7e5c41119e99347d2af64cb356334">73</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ma_Deep_Rigid_Instance_Scene_Flow_CVPR_2019_paper.html">Deep Rigid Instance Scene Flow</a></th>
                    </tr>
                
                    <tr id="ceb056ed2512e988a0b3786193a690b42e3e4af0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ceb056ed2512e988a0b3786193a690b42e3e4af0">73</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qin_Triangulation_Learning_Network_From_Monocular_to_Stereo_3D_Object_Detection_CVPR_2019_paper.html">Triangulation Learning Network: From Monocular to Stereo 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="4184346f9e8548dbae33559a30290def2f0bf0f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4184346f9e8548dbae33559a30290def2f0bf0f1">73</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Single_Image_Reflection_Removal_Exploiting_Misaligned_Training_Data_and_Network_CVPR_2019_paper.html">Single Image Reflection Removal Exploiting Misaligned Training Data and Network Enhancements</a></th>
                    </tr>
                
                    <tr id="f6e06f3189885fb5c6b6ede770d122570fe4584c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f6e06f3189885fb5c6b6ede770d122570fe4584c">73</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ma_GCAN_Graph_Convolutional_Adversarial_Network_for_Unsupervised_Domain_Adaptation_CVPR_2019_paper.html">GCAN: Graph Convolutional Adversarial Network for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="866e158776c422e95829770c0f24dfa4b0a9a4bd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/866e158776c422e95829770c0f24dfa4b0a9a4bd">73</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jain_Accel_A_Corrective_Fusion_Network_for_Efficient_Semantic_Segmentation_on_CVPR_2019_paper.html">Accel: A Corrective Fusion Network for Efficient Semantic Segmentation on Video</a></th>
                    </tr>
                
                    <tr id="f7212e9b731adc77073355c56b7ca0dc8baa4698">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7212e9b731adc77073355c56b7ca0dc8baa4698">73</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cho_Image-To-Image_Translation_via_Group-Wise_Deep_Whitening-And-Coloring_Transformation_CVPR_2019_paper.html">Image-To-Image Translation via Group-Wise Deep Whitening-And-Coloring Transformation</a></th>
                    </tr>
                
                    <tr id="33087426583ad64de8e680469107f50654a70e75">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/33087426583ad64de8e680469107f50654a70e75">72</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Self-Calibrating_Deep_Photometric_Stereo_Networks_CVPR_2019_paper.html">Self-Calibrating Deep Photometric Stereo Networks</a></th>
                    </tr>
                
                    <tr id="ca51e00b0314a2b3b0b1d5ffabe7b15a61c8a733">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ca51e00b0314a2b3b0b1d5ffabe7b15a61c8a733">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Deep_Network_Interpolation_for_Continuous_Imagery_Effect_Transition_CVPR_2019_paper.html">Deep Network Interpolation for Continuous Imagery Effect Transition</a></th>
                    </tr>
                
                    <tr id="249f0a2ae3540dbe4f2a11806d2ac38581b9ad6b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/249f0a2ae3540dbe4f2a11806d2ac38581b9ad6b">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Deep_Metric_Learning_Beyond_Binary_Supervision_CVPR_2019_paper.html">Deep Metric Learning Beyond Binary Supervision</a></th>
                    </tr>
                
                    <tr id="5ad7c05fe1c9837793df0f1db62deffb788fa4a8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5ad7c05fe1c9837793df0f1db62deffb788fa4a8">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Learning_Metrics_From_Teachers_Compact_Networks_for_Image_Embedding_CVPR_2019_paper.html">Learning Metrics From Teachers: Compact Networks for Image Embedding</a></th>
                    </tr>
                
                    <tr id="046b664d0dfcdca74a11fd963ce79f51f69d15b2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/046b664d0dfcdca74a11fd963ce79f51f69d15b2">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Deng_3D_Local_Features_for_Direct_Pairwise_Registration_CVPR_2019_paper.html">3D Local Features for Direct Pairwise Registration</a></th>
                    </tr>
                
                    <tr id="1db245d9d2873ed433774f55b74e5b0274a71bd8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1db245d9d2873ed433774f55b74e5b0274a71bd8">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Cross-Modal_Relationship_Inference_for_Grounding_Referring_Expressions_CVPR_2019_paper.html">Cross-Modal Relationship Inference for Grounding Referring Expressions</a></th>
                    </tr>
                
                    <tr id="df81de654e048f710088fce45ee9846f3abd6b79">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/df81de654e048f710088fce45ee9846f3abd6b79">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ritchie_Fast_and_Flexible_Indoor_Scene_Synthesis_via_Deep_Convolutional_Generative_CVPR_2019_paper.html">Fast and Flexible Indoor Scene Synthesis via Deep Convolutional Generative Models</a></th>
                    </tr>
                
                    <tr id="dc82a539a3e649a331b599c985574ce76519ed14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dc82a539a3e649a331b599c985574ce76519ed14">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_TransGaGa_Geometry-Aware_Unsupervised_Image-To-Image_Translation_CVPR_2019_paper.html">TransGaGa: Geometry-Aware Unsupervised Image-To-Image Translation</a></th>
                    </tr>
                
                    <tr id="e50ddfd173b6e37d2dfdc4ac076840f560c16efe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e50ddfd173b6e37d2dfdc4ac076840f560c16efe">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Weakly-Supervised_Discovery_of_Geometry-Aware_Representation_for_3D_Human_Pose_Estimation_CVPR_2019_paper.html">Weakly-Supervised Discovery of Geometry-Aware Representation for 3D Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="824e9a61dee5b2f441d74c216c5eaf2a3765987e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/824e9a61dee5b2f441d74c216c5eaf2a3765987e">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Facil_CAM-Convs_Camera-Aware_Multi-Scale_Convolutions_for_Single-View_Depth_CVPR_2019_paper.html">CAM-Convs: Camera-Aware Multi-Scale Convolutions for Single-View Depth</a></th>
                    </tr>
                
                    <tr id="b32d64c6a3cebdf59655217eca8b9f8454fbe504">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b32d64c6a3cebdf59655217eca8b9f8454fbe504">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jiang_Disentangled_Representation_Learning_for_3D_Face_Shape_CVPR_2019_paper.html">Disentangled Representation Learning for 3D Face Shape</a></th>
                    </tr>
                
                    <tr id="06938bed85ff8c37132b28028fcb20321163a45d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/06938bed85ff8c37132b28028fcb20321163a45d">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tokunaga_Adaptive_Weighting_Multi-Field-Of-View_CNN_for_Semantic_Segmentation_in_Pathology_CVPR_2019_paper.html">Adaptive Weighting Multi-Field-Of-View CNN for Semantic Segmentation in Pathology</a></th>
                    </tr>
                
                    <tr id="b809837560cf11937ee857338eb1a7ccd2abc7b2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b809837560cf11937ee857338eb1a7ccd2abc7b2">71</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MMLV/Gao_2.5D_Visual_Sound_CVPRW_2019_paper.html">2.5D Visual Sound</a></th>
                    </tr>
                
                    <tr id="4fcdf1e95d91e5f369405a15002869c997c68e0b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4fcdf1e95d91e5f369405a15002869c997c68e0b">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_RENAS_Reinforced_Evolutionary_Neural_Architecture_Search_CVPR_2019_paper.html">RENAS: Reinforced Evolutionary Neural Architecture Search</a></th>
                    </tr>
                
                    <tr id="e6fcd35992e63620600357883b92518884a6c6f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e6fcd35992e63620600357883b92518884a6c6f1">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Lending_Orientation_to_Neural_Networks_for_Cross-View_Geo-Localization_CVPR_2019_paper.html">Lending Orientation to Neural Networks for Cross-View Geo-Localization</a></th>
                    </tr>
                
                    <tr id="b1983976d43dfec7bcc918d67ed826e9b8f3c46c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b1983976d43dfec7bcc918d67ed826e9b8f3c46c">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Non-Local_Meets_Global_An_Integrated_Paradigm_for_Hyperspectral_Denoising_CVPR_2019_paper.html">Non-Local Meets Global: An Integrated Paradigm for Hyperspectral Denoising</a></th>
                    </tr>
                
                    <tr id="5643926262452b061df043de281bb40ba3e452e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5643926262452b061df043de281bb40ba3e452e3">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Quantization_Networks_CVPR_2019_paper.html">UNIQ: Uniform Noise Injection for Non-Uniform Quantization of Neural Networks</a></th>
                    </tr>
                
                    <tr id="4a06fa3178f9ea83d666b0c49a055db9cefbb237">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4a06fa3178f9ea83d666b0c49a055db9cefbb237">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gur_Single_Image_Depth_Estimation_Trained_via_Depth_From_Defocus_Cues_CVPR_2019_paper.html">Single Image Depth Estimation Trained via Depth From Defocus Cues</a></th>
                    </tr>
                
                    <tr id="e4340898a3142921732a6265d7ad2f2b9dd3fd24">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e4340898a3142921732a6265d7ad2f2b9dd3fd24">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Soh_Natural_and_Realistic_Single_Image_Super-Resolution_With_Explicit_Natural_Manifold_CVPR_2019_paper.html">Natural and Realistic Single Image Super-Resolution With Explicit Natural Manifold Discrimination</a></th>
                    </tr>
                
                    <tr id="78e7d35d92dda56e4889154a130b0373e66195f6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/78e7d35d92dda56e4889154a130b0373e66195f6">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Wide-Area_Crowd_Counting_via_Ground-Plane_Density_Maps_and_Multi-View_Fusion_CVPR_2019_paper.html">Wide-Area Crowd Counting via Ground-Plane Density Maps and Multi-View Fusion CNNs</a></th>
                    </tr>
                
                    <tr id="0181eb5f6f94df18586fea79d6ad37e583ff6f0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0181eb5f6f94df18586fea79d6ad37e583ff6f0c">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_A_Structured_Model_for_Action_Detection_CVPR_2019_paper.html">A Structured Model for Action Detection</a></th>
                    </tr>
                
                    <tr id="bdedb3640414ef2d246993ed0b95f8222d2785e0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bdedb3640414ef2d246993ed0b95f8222d2785e0">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yoo_Coloring_With_Limited_Data_Few-Shot_Colorization_via_Memory_Augmented_Networks_CVPR_2019_paper.html">Coloring With Limited Data: Few-Shot Colorization via Memory Augmented Networks</a></th>
                    </tr>
                
                    <tr id="7cfebe5771fe5048c637e120e51423a333399167">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7cfebe5771fe5048c637e120e51423a333399167">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sagong_PEPSI__Fast_Image_Inpainting_With_Parallel_Decoding_Network_CVPR_2019_paper.html">PEPSI : Fast Image Inpainting With Parallel Decoding Network</a></th>
                    </tr>
                
                    <tr id="5a5361d58912c1e8a26cda81f013c88ad93c532a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5a5361d58912c1e8a26cda81f013c88ad93c532a">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cholakkal_Object_Counting_and_Instance_Segmentation_With_Image-Level_Supervision_CVPR_2019_paper.html">Object Counting and Instance Segmentation With Image-Level Supervision</a></th>
                    </tr>
                
                    <tr id="03fdf3abf8d6bb3ff35dc87742ad66722997caeb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/03fdf3abf8d6bb3ff35dc87742ad66722997caeb">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Nguyen_Vision-Based_Navigation_With_Language-Based_Assistance_via_Imitation_Learning_With_Indirect_CVPR_2019_paper.html">Vision-Based Navigation With Language-Based Assistance via Imitation Learning With Indirect Intervention</a></th>
                    </tr>
                
                    <tr id="4e7e694c9a297ffb9c2069326eca42f89bbe8a1f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4e7e694c9a297ffb9c2069326eca42f89bbe8a1f">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Afifi_When_Color_Constancy_Goes_Wrong_Correcting_Improperly_White-Balanced_Images_CVPR_2019_paper.html">When Color Constancy Goes Wrong: Correcting Improperly White-Balanced Images</a></th>
                    </tr>
                
                    <tr id="98b0a78cd74ae501695574e82c768d2c5c19c7db">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/98b0a78cd74ae501695574e82c768d2c5c19c7db">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_AE2-Nets_Autoencoder_in_Autoencoder_Networks_CVPR_2019_paper.html">AE2-Nets: Autoencoder in Autoencoder Networks</a></th>
                    </tr>
                
                    <tr id="3e4a49b86c9c34e27e00a0f250b3d82f269cf153">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3e4a49b86c9c34e27e00a0f250b3d82f269cf153">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Duan_UniformFace_Learning_Deep_Equidistributed_Representation_for_Face_Recognition_CVPR_2019_paper.html">UniformFace: Learning Deep Equidistributed Representation for Face Recognition</a></th>
                    </tr>
                
                    <tr id="2bff7c7a1e18202dc81348d33fe2b7caf54bb3da">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2bff7c7a1e18202dc81348d33fe2b7caf54bb3da">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Garon_Fast_Spatially-Varying_Indoor_Lighting_Estimation_CVPR_2019_paper.html">Fast Spatially-Varying Indoor Lighting Estimation</a></th>
                    </tr>
                
                    <tr id="5d2421c59d383ca3ce9b162c75d97c63a9a8a3db">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5d2421c59d383ca3ce9b162c75d97c63a9a8a3db">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Behl_PointFlowNet_Learning_Representations_for_Rigid_Motion_Estimation_From_Point_Clouds_CVPR_2019_paper.html">PointFlowNet: Learning Representations for Rigid Motion Estimation From Point Clouds</a></th>
                    </tr>
                
                    <tr id="2b089d0e8802170d491cb5944a538bd769c8f032">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b089d0e8802170d491cb5944a538bd769c8f032">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Amodio_TraVeLGAN_Image-To-Image_Translation_by_Transformation_Vector_Learning_CVPR_2019_paper.html">TraVeLGAN: Image-To-Image Translation by Transformation Vector Learning</a></th>
                    </tr>
                
                    <tr id="c14d84ca22c6661c93b38fa0041e7fca2fb9e5a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c14d84ca22c6661c93b38fa0041e7fca2fb9e5a2">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hosu_Effective_Aesthetics_Prediction_With_Multi-Level_Spatially_Pooled_Features_CVPR_2019_paper.html">Effective Aesthetics Prediction With Multi-Level Spatially Pooled Features</a></th>
                    </tr>
                
                    <tr id="935077dc6a68a3008632783b85d0080aa4bafabc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/935077dc6a68a3008632783b85d0080aa4bafabc">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tripathi_Learning_to_Generate_Synthetic_Data_via_Compositing_CVPR_2019_paper.html">Learning to Generate Synthetic Data via Compositing</a></th>
                    </tr>
                
                    <tr id="e60fed397aa021c0dbe50db1dd22ffbf304d755b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e60fed397aa021c0dbe50db1dd22ffbf304d755b">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Duan_Structural_Relational_Reasoning_of_Point_Clouds_CVPR_2019_paper.html">Structural Relational Reasoning of Point Clouds</a></th>
                    </tr>
                
                    <tr id="2c28b9d33a320963229c4810ecc85a358ab480be">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c28b9d33a320963229c4810ecc85a358ab480be">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xue_Learning_Attraction_Field_Representation_for_Robust_Line_Segment_Detection_CVPR_2019_paper.html">Learning Attraction Field Representation for Robust Line Segment Detection</a></th>
                    </tr>
                
                    <tr id="844f549adcf158883e06cd04a70c48cba18c8584">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/844f549adcf158883e06cd04a70c48cba18c8584">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Roy_Mitigating_Information_Leakage_in_Image_Representations_A_Maximum_Entropy_Approach_CVPR_2019_paper.html">Mitigating Information Leakage in Image Representations: A Maximum Entropy Approach</a></th>
                    </tr>
                
                    <tr id="1aa5eb67c443270159e867d9c3a5b44e0cdbf7b7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1aa5eb67c443270159e867d9c3a5b44e0cdbf7b7">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Huang_TextureNet_Consistent_Local_Parametrizations_for_Learning_From_High-Resolution_Signals_on_CVPR_2019_paper.html">TextureNet: Consistent Local Parametrizations for Learning From High-Resolution Signals on Meshes</a></th>
                    </tr>
                
                    <tr id="564d0859cd2130a405f87f64a3a8806c7e74f940">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/564d0859cd2130a405f87f64a3a8806c7e74f940">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Towards_Accurate_One-Stage_Object_Detection_With_AP-Loss_CVPR_2019_paper.html">Towards Accurate One-Stage Object Detection With AP-Loss</a></th>
                    </tr>
                
                    <tr id="c5a757427132fda0c66e18a0d059eca8e2472d13">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c5a757427132fda0c66e18a0d059eca8e2472d13">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mun_Streamlined_Dense_Video_Captioning_CVPR_2019_paper.html">Streamlined Dense Video Captioning</a></th>
                    </tr>
                
                    <tr id="1f278c70c168c0130b5ae1bef196e66308cd5c22">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1f278c70c168c0130b5ae1bef196e66308cd5c22">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Song_Neural_Illumination_Lighting_Prediction_for_Indoor_Environments_CVPR_2019_paper.html">Neural Illumination: Lighting Prediction for Indoor Environments</a></th>
                    </tr>
                
                    <tr id="962d5b9ba212946789f627997f5f13f2c76d0876">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/962d5b9ba212946789f627997f5f13f2c76d0876">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Suh_Stochastic_Class-Based_Hard_Example_Mining_for_Deep_Metric_Learning_CVPR_2019_paper.html">Stochastic Class-Based Hard Example Mining for Deep Metric Learning</a></th>
                    </tr>
                
                    <tr id="2910bec6d4de87e22be5119cef3c488d2ae50e2a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2910bec6d4de87e22be5119cef3c488d2ae50e2a">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Perera_Deep_Transfer_Learning_for_Multiple_Class_Novelty_Detection_CVPR_2019_paper.html">Deep Transfer Learning for Multiple Class Novelty Detection</a></th>
                    </tr>
                
                    <tr id="15e8801290c1a0208fe7e2df465974bd6eed464e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15e8801290c1a0208fe7e2df465974bd6eed464e">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Philion_FastDraw_Addressing_the_Long_Tail_of_Lane_Detection_by_Adapting_CVPR_2019_paper.html">FastDraw: Addressing the Long Tail of Lane Detection by Adapting a Sequential Prediction Network</a></th>
                    </tr>
                
                    <tr id="90bbacad4bf9084d7a76de019b99a4622c238e57">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/90bbacad4bf9084d7a76de019b99a4622c238e57">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Atzmon_Adaptive_Confidence_Smoothing_for_Generalized_Zero-Shot_Learning_CVPR_2019_paper.html">Adaptive Confidence Smoothing for Generalized Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="f7039b8178561ad32b4a34d7482a48e7ba5177d3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7039b8178561ad32b4a34d7482a48e7ba5177d3">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Improving_Few-Shot_User-Specific_Gaze_Adaptation_via_Gaze_Redirection_Synthesis_CVPR_2019_paper.html">Improving Few-Shot User-Specific Gaze Adaptation via Gaze Redirection Synthesis</a></th>
                    </tr>
                
                    <tr id="1d5ccdc6aa63a443c3aafd4817e4261638226640">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d5ccdc6aa63a443c3aafd4817e4261638226640">68</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Yu_Deep_Iterative_Down-Up_CNN_for_Image_Denoising_CVPRW_2019_paper.html">Deep Iterative Down-Up CNN for Image Denoising</a></th>
                    </tr>
                
                    <tr id="c5b74b395606990dda555fc6655837fb699c6ef0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c5b74b395606990dda555fc6655837fb699c6ef0">68</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Abdelhamed_NTIRE_2019_Challenge_on_Real_Image_Denoising_Methods_and_Results_CVPRW_2019_paper.html">NTIRE 2019 Challenge on Real Image Denoising: Methods and Results</a></th>
                    </tr>
                
                    <tr id="15e8801290c1a0208fe7e2df465974bd6eed464e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15e8801290c1a0208fe7e2df465974bd6eed464e">68</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Philion_FastDraw_Addressing_the_Long_Tail_of_Lane_Detection_by_Adapting_CVPRW_2019_paper.html">FastDraw: Addressing the Long Tail of Lane Detection by Adapting a Sequential Prediction Network</a></th>
                    </tr>
                
                    <tr id="6beb1716299c4da7a6608d6b5bb0525807055896">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6beb1716299c4da7a6608d6b5bb0525807055896">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_BridgeNet_A_Continuity-Aware_Probabilistic_Network_for_Age_Estimation_CVPR_2019_paper.html">BridgeNet: A Continuity-Aware Probabilistic Network for Age Estimation</a></th>
                    </tr>
                
                    <tr id="524cb4afc83a36a4f126de541ceadda26797ff54">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/524cb4afc83a36a4f126de541ceadda26797ff54">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tung_Learning_Spatial_Common_Sense_With_Geometry-Aware_Recurrent_Networks_CVPR_2019_paper.html">Learning Spatial Common Sense With Geometry-Aware Recurrent Networks</a></th>
                    </tr>
                
                    <tr id="2f66d531439f5847afa7b31f49db87a44b788690">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2f66d531439f5847afa7b31f49db87a44b788690">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Video_Generation_From_Single_Semantic_Label_Map_CVPR_2019_paper.html">Video Generation From Single Semantic Label Map</a></th>
                    </tr>
                
                    <tr id="c5d15ab9b3d541e53d0b7743bce99a074698394b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c5d15ab9b3d541e53d0b7743bce99a074698394b">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Manjunatha_Explicit_Bias_Discovery_in_Visual_Question_Answering_Models_CVPR_2019_paper.html">Explicit Bias Discovery in Visual Question Answering Models</a></th>
                    </tr>
                
                    <tr id="9e5fab09db23dbff7e4009be7cd0add7c00fc76f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9e5fab09db23dbff7e4009be7cd0add7c00fc76f">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Bai_Re-Ranking_via_Metric_Fusion_for_Object_Retrieval_and_Person_Re-Identification_CVPR_2019_paper.html">Re-Ranking via Metric Fusion for Object Retrieval and Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="fcde8e33821cfd6500096477d8dde7de65653b96">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fcde8e33821cfd6500096477d8dde7de65653b96">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Generalized_Zero-Shot_Recognition_Based_on_Visually_Semantic_Embedding_CVPR_2019_paper.html">Generalized Zero-Shot Recognition Based on Visually Semantic Embedding</a></th>
                    </tr>
                
                    <tr id="0b37c79b81b4adb12a9cb72d101778fd8277336f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0b37c79b81b4adb12a9cb72d101778fd8277336f">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dai_Scan2Mesh_From_Unstructured_Range_Scans_to_3D_Meshes_CVPR_2019_paper.html">Scan2Mesh: From Unstructured Range Scans to 3D Meshes</a></th>
                    </tr>
                
                    <tr id="9835a04f6e5cd8b4c70edda704fddce813d18339">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9835a04f6e5cd8b4c70edda704fddce813d18339">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Otani_Rethinking_the_Evaluation_of_Video_Summaries_CVPR_2019_paper.html">Rethinking the Evaluation of Video Summaries</a></th>
                    </tr>
                
                    <tr id="abee18114d9ff757dc82e44bead6bad39cfb758c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/abee18114d9ff757dc82e44bead6bad39cfb758c">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hou_Robust_Histopathology_Image_Analysis_To_Label_or_to_Synthesize_CVPR_2019_paper.html">Robust Histopathology Image Analysis: To Label or to Synthesize?</a></th>
                    </tr>
                
                    <tr id="d2b80171086208260f433ac2e5b48d30d339b33f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d2b80171086208260f433ac2e5b48d30d339b33f">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xue_Beyond_Tracking_Selecting_Memory_and_Refining_Poses_for_Deep_Visual_CVPR_2019_paper.html">Beyond Tracking: Selecting Memory and Refining Poses for Deep Visual Odometry</a></th>
                    </tr>
                
                    <tr id="c04ef7904474e9d151fc6e84189306f31dcdc951">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c04ef7904474e9d151fc6e84189306f31dcdc951">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Deep_Incremental_Hashing_Network_for_Efficient_Image_Retrieval_CVPR_2019_paper.html">Deep Incremental Hashing Network for Efficient Image Retrieval</a></th>
                    </tr>
                
                    <tr id="2e355eaa0169c16845a01716c1cadc756737dcb0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e355eaa0169c16845a01716c1cadc756737dcb0">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wan_Self-Supervised_3D_Hand_Pose_Estimation_Through_Training_by_Fitting_CVPR_2019_paper.html">Self-Supervised 3D Hand Pose Estimation Through Training by Fitting</a></th>
                    </tr>
                
                    <tr id="f3183228a83b1daffeb458f9041d51612589a5b3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f3183228a83b1daffeb458f9041d51612589a5b3">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Parmar_What_and_How_Well_You_Performed_A_Multitask_Learning_Approach_CVPR_2019_paper.html">What and How Well You Performed? A Multitask Learning Approach to Action Quality Assessment</a></th>
                    </tr>
                
                    <tr id="6682305217104f647db57191765da6bef71c3f1f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6682305217104f647db57191765da6bef71c3f1f">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Spatiotemporal_CNN_for_Video_Object_Segmentation_CVPR_2019_paper.html">Spatiotemporal CNN for Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="9695676deace8c05d4e95274b92f20ed1e97470c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9695676deace8c05d4e95274b92f20ed1e97470c">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_CLEVR-Ref_Diagnosing_Visual_Reasoning_With_Referring_Expressions_CVPR_2019_paper.html">CLEVR-Ref+: Diagnosing Visual Reasoning With Referring Expressions</a></th>
                    </tr>
                
                    <tr id="df45c653f7c7cf388fdd8c524a4ad2a78653dc3b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/df45c653f7c7cf388fdd8c524a4ad2a78653dc3b">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pang_Efficient_Featurized_Image_Pyramid_Network_for_Single_Shot_Detector_CVPR_2019_paper.html">Efficient Featurized Image Pyramid Network for Single Shot Detector</a></th>
                    </tr>
                
                    <tr id="5208e061ede1f1836955d4285b69a6fed9ef198d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5208e061ede1f1836955d4285b69a6fed9ef198d">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Spatial-Aware_Graph_Relation_Network_for_Large-Scale_Object_Detection_CVPR_2019_paper.html">Spatial-Aware Graph Relation Network for Large-Scale Object Detection</a></th>
                    </tr>
                
                    <tr id="0f96ee5997d5951886b6e7c6c4a2e31990595cf2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0f96ee5997d5951886b6e7c6c4a2e31990595cf2">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Towards_Natural_and_Accurate_Future_Motion_Prediction_of_Humans_and_CVPR_2019_paper.html">Towards Natural and Accurate Future Motion Prediction of Humans and Animals</a></th>
                    </tr>
                
                    <tr id="5ddb1e671d8bfca1483fe002742dc0e77dd92594">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5ddb1e671d8bfca1483fe002742dc0e77dd92594">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ying_X2CT-GAN_Reconstructing_CT_From_Biplanar_X-Rays_With_Generative_Adversarial_Networks_CVPR_2019_paper.html">X2CT-GAN: Reconstructing CT From Biplanar X-Rays With Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="23307aad23e0e871bf90332e2d47a9a78833b81c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/23307aad23e0e871bf90332e2d47a9a78833b81c">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gao_FilterReg_Robust_and_Efficient_Probabilistic_Point-Set_Registration_Using_Gaussian_Filter_CVPR_2019_paper.html">FilterReg: Robust and Efficient Probabilistic Point-Set Registration Using Gaussian Filter and Twist Parameterization</a></th>
                    </tr>
                
                    <tr id="908c6b1577a1f5309ae183daf2e24363039f22a8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/908c6b1577a1f5309ae183daf2e24363039f22a8">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Biten_Good_News_Everyone_Context_Driven_Entity-Aware_Captioning_for_News_Images_CVPR_2019_paper.html">Good News, Everyone! Context Driven Entity-Aware Captioning for News Images</a></th>
                    </tr>
                
                    <tr id="b11d14c5812e5f41348beebceaca84b46cc55346">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b11d14c5812e5f41348beebceaca84b46cc55346">65</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Augmented_Human_Humancentric_Understanding_and_2D3D_Synthesis/Liu_Skepxels_Spatio-temporal_Image_Representation_of_Human_Skeleton_Joints_for_Action_CVPRW_2019_paper.html">Skepxels: Spatio-temporal Image Representation of Human Skeleton Joints for Action Recognition</a></th>
                    </tr>
                
                    <tr id="9ac260f624760754cbbccadeeacb0dd969ed508e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9ac260f624760754cbbccadeeacb0dd969ed508e">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_NM-Net_Mining_Reliable_Neighbors_for_Robust_Feature_Correspondences_CVPR_2019_paper.html">NM-Net: Mining Reliable Neighbors for Robust Feature Correspondences</a></th>
                    </tr>
                
                    <tr id="48c601d0029c25ba02480c473d1bd31960acb2e2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/48c601d0029c25ba02480c473d1bd31960acb2e2">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Progressive_Teacher-Student_Learning_for_Early_Action_Prediction_CVPR_2019_paper.html">Progressive Teacher-Student Learning for Early Action Prediction</a></th>
                    </tr>
                
                    <tr id="f28bc580abccb577017d493950e2265874f77dad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f28bc580abccb577017d493950e2265874f77dad">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/LeGendre_DeepLight_Learning_Illumination_for_Unconstrained_Mobile_Mixed_Reality_CVPR_2019_paper.html">DeepLight: Learning Illumination for Unconstrained Mobile Mixed Reality</a></th>
                    </tr>
                
                    <tr id="0104cfe30e897ea16cba40406c76ed40f66a6d3a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0104cfe30e897ea16cba40406c76ed40f66a6d3a">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jia_FOCNet_A_Fractional_Optimal_Control_Network_for_Image_Denoising_CVPR_2019_paper.html">FOCNet: A Fractional Optimal Control Network for Image Denoising</a></th>
                    </tr>
                
                    <tr id="6486fe4c649ff9d076e73c81c6d7dd69f1eaede2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6486fe4c649ff9d076e73c81c6d7dd69f1eaede2">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_DARNet_Deep_Active_Ray_Network_for_Building_Segmentation_CVPR_2019_paper.html">DARNet: Deep Active Ray Network for Building Segmentation</a></th>
                    </tr>
                
                    <tr id="1be69cba7ac970512ef0df482413878eba77af14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1be69cba7ac970512ef0df482413878eba77af14">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Rob-GAN_Generator_Discriminator_and_Adversarial_Attacker_CVPR_2019_paper.html">Rob-GAN: Generator, Discriminator, and Adversarial Attacker</a></th>
                    </tr>
                
                    <tr id="5cb9ddd676e25516f9b273c7714f02b1542cee7e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5cb9ddd676e25516f9b273c7714f02b1542cee7e">63</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Dense_3D_Face_Decoding_Over_2500FPS_Joint_Texture__Shape_CVPR_2019_paper.html">Dense 3D Face Decoding Over 2500FPS: Joint Texture &amp; Shape Convolutional Mesh Decoders</a></th>
                    </tr>
                
                    <tr id="22522f1b1bad8c86737ee7b2040c30b20c039b54">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/22522f1b1bad8c86737ee7b2040c30b20c039b54">63</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tsai_Beyond_Volumetric_Albedo_--_A_Surface_Optimization_Framework_for_Non-Line-Of-Sight_CVPR_2019_paper.html">Beyond Volumetric Albedo -- A Surface Optimization Framework for Non-Line-Of-Sight Imaging</a></th>
                    </tr>
                
                    <tr id="fa247c6200a672fd190766cee2ec3fb155652f5c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fa247c6200a672fd190766cee2ec3fb155652f5c">63</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Reducing_Uncertainty_in_Undersampled_MRI_Reconstruction_With_Active_Acquisition_CVPR_2019_paper.html">Reducing Uncertainty in Undersampled MRI Reconstruction With Active Acquisition</a></th>
                    </tr>
                
                    <tr id="d9e97a293b98292713f4ab28b915b093fb923fb3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d9e97a293b98292713f4ab28b915b093fb923fb3">63</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Osawa_Large-Scale_Distributed_Second-Order_Optimization_Using_Kronecker-Factored_Approximate_Curvature_for_Deep_CVPR_2019_paper.html">Large-Scale Distributed Second-Order Optimization Using Kronecker-Factored Approximate Curvature for Deep Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="2493081e62ad4696dffb26ef6ad6085cdb505af5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2493081e62ad4696dffb26ef6ad6085cdb505af5">63</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cucurull_Context-Aware_Visual_Compatibility_Prediction_CVPR_2019_paper.html">Context-Aware Visual Compatibility Prediction</a></th>
                    </tr>
                
                    <tr id="ef1e4a4db0c4a2bb380d1a8a70df58fbf9a6db96">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ef1e4a4db0c4a2bb380d1a8a70df58fbf9a6db96">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Distant_Supervised_Centroid_Shift_A_Simple_and_Efficient_Approach_to_CVPR_2019_paper.html">Distant Supervised Centroid Shift: A Simple and Efficient Approach to Visual Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="e37daa92ec7464c864b5eb9a103ef4b919bd84bc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e37daa92ec7464c864b5eb9a103ef4b919bd84bc">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Distraction-Aware_Shadow_Detection_CVPR_2019_paper.html">Distraction-Aware Shadow Detection</a></th>
                    </tr>
                
                    <tr id="b675e89a51b563214e632a48cd95768f4adc96ef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b675e89a51b563214e632a48cd95768f4adc96ef">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fan_S4Net_Single_Stage_Salient-Instance_Segmentation_CVPR_2019_paper.html">S4Net: Single stage salient-instance segmentation</a></th>
                    </tr>
                
                    <tr id="7ba93fca7aca3693c40f779eacf2e6cce7ee1b92">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ba93fca7aca3693c40f779eacf2e6cce7ee1b92">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Alfassy_LaSO_Label-Set_Operations_Networks_for_Multi-Label_Few-Shot_Learning_CVPR_2019_paper.html">LaSO: Label-Set Operations Networks for Multi-Label Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="db57c51d84ff1ff3809ba76701e1171118f2f091">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db57c51d84ff1ff3809ba76701e1171118f2f091">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hold-Geoffroy_Deep_Sky_Modeling_for_Single_Image_Outdoor_Lighting_Estimation_CVPR_2019_paper.html">Deep Sky Modeling for Single Image Outdoor Lighting Estimation</a></th>
                    </tr>
                
                    <tr id="a3dd03e187307805719ae4c295fc08003c385b5d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a3dd03e187307805719ae4c295fc08003c385b5d">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Niu_Local_Relationship_Learning_With_Person-Specific_Shape_Regularization_for_Facial_Action_CVPR_2019_paper.html">Local Relationship Learning With Person-Specific Shape Regularization for Facial Action Unit Detection</a></th>
                    </tr>
                
                    <tr id="077b6c5e07fffef7a134bd93fab956316b1342d6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/077b6c5e07fffef7a134bd93fab956316b1342d6">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gallego_Focus_Is_All_You_Need_Loss_Functions_for_Event-Based_Vision_CVPR_2019_paper.html">Focus Is All You Need: Loss Functions for Event-Based Vision</a></th>
                    </tr>
                
                    <tr id="8d04ad17be9ac41c458f13fa281d1b3b3530e8d0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8d04ad17be9ac41c458f13fa281d1b3b3530e8d0">62</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BMTT/Henschel_Multiple_People_Tracking_Using_Body_and_Joint_Detections_CVPRW_2019_paper.html">Multiple People Tracking Using Body and Joint Detections</a></th>
                    </tr>
                
                    <tr id="6edfe8350da54cd563158b0d7d0c664f16cb91a8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6edfe8350da54cd563158b0d7d0c664f16cb91a8">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Relational_Action_Forecasting_CVPR_2019_paper.html">Relational Action Forecasting</a></th>
                    </tr>
                
                    <tr id="e19ed7fe60638875d86e0284d7cd90766e26f7b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e19ed7fe60638875d86e0284d7cd90766e26f7b1">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_ROI_Pooled_Correlation_Filters_for_Visual_Tracking_CVPR_2019_paper.html">ROI Pooled Correlation Filters for Visual Tracking</a></th>
                    </tr>
                
                    <tr id="05bb6925dc3e9ab789bc672fee3e7003b8405b0a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05bb6925dc3e9ab789bc672fee3e7003b8405b0a">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Exploring_Context_and_Visual_Pattern_of_Relationship_for_Scene_Graph_CVPR_2019_paper.html">Exploring Context and Visual Pattern of Relationship for Scene Graph Generation</a></th>
                    </tr>
                
                    <tr id="50f0e8ac834435c3f296ef8d3627f303623020ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50f0e8ac834435c3f296ef8d3627f303623020ad">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_You_Look_Twice_GaterNet_for_Dynamic_Filter_Selection_in_CNNs_CVPR_2019_paper.html">You Look Twice: GaterNet for Dynamic Filter Selection in CNNs</a></th>
                    </tr>
                
                    <tr id="a4fafaf19fd45a0aa21db827d6714fbcbf64e398">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a4fafaf19fd45a0aa21db827d6714fbcbf64e398">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lee_SpherePHD_Applying_CNNs_on_a_Spherical_PolyHeDron_Representation_of_360deg_CVPR_2019_paper.html">SpherePHD: Applying CNNs on a Spherical PolyHeDron Representation of 360° Images</a></th>
                    </tr>
                
                    <tr id="ddeb225eb472c9aab1b86ba8f30c8dc937445b3e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ddeb225eb472c9aab1b86ba8f30c8dc937445b3e">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Grigorev_Coordinate-Based_Texture_Inpainting_for_Pose-Guided_Human_Image_Generation_CVPR_2019_paper.html">Coordinate-Based Texture Inpainting for Pose-Guided Human Image Generation</a></th>
                    </tr>
                
                    <tr id="5354bdc5cae9fe4509b5b187228af2de225d410b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5354bdc5cae9fe4509b5b187228af2de225d410b">61</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Kuznichov_Data_Augmentation_for_Leaf_Segmentation_and_Counting_Tasks_in_Rosette_CVPRW_2019_paper.html">Data Augmentation for Leaf Segmentation and Counting Tasks in Rosette Plants</a></th>
                    </tr>
                
                    <tr id="336433b50560e394239a2da3a12591c84c524052">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/336433b50560e394239a2da3a12591c84c524052">61</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UG2_Prize_Challenge/Uplavikar_All-in-One_Underwater_Image_Enhancement_Using_Domain-Adversarial_Learning_CVPRW_2019_paper.html">All-in-One Underwater Image Enhancement Using Domain-Adversarial Learning</a></th>
                    </tr>
                
                    <tr id="4db6900d0d0fa3bfff53359896fe5553776b70b2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4db6900d0d0fa3bfff53359896fe5553776b70b2">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Detection_Based_Defense_Against_Adversarial_Examples_From_the_Steganalysis_Point_CVPR_2019_paper.html">Detection Based Defense Against Adversarial Examples From the Steganalysis Point of View</a></th>
                    </tr>
                
                    <tr id="de595af4b6dee1fbe57c311f6ba45e6ac22e57ea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/de595af4b6dee1fbe57c311f6ba45e6ac22e57ea">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Deep_Exemplar-Based_Video_Colorization_CVPR_2019_paper.html">Deep Exemplar-Based Video Colorization</a></th>
                    </tr>
                
                    <tr id="e17aac3bbe0aabda715cafad392f31a1e046c17c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e17aac3bbe0aabda715cafad392f31a1e046c17c">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zadeh_Social-IQ_A_Question_Answering_Benchmark_for_Artificial_Social_Intelligence_CVPR_2019_paper.html">Social-IQ: A Question Answering Benchmark for Artificial Social Intelligence</a></th>
                    </tr>
                
                    <tr id="286e9e7f037cf0ad1af725d59e9ad8e8ce424228">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/286e9e7f037cf0ad1af725d59e9ad8e8ce424228">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_PartNet_A_Recursive_Part_Decomposition_Network_for_Fine-Grained_and_Hierarchical_CVPR_2019_paper.html">PartNet: A Recursive Part Decomposition Network for Fine-Grained and Hierarchical Shape Segmentation</a></th>
                    </tr>
                
                    <tr id="ce079b5a18054eb9434bf7032bcdffb599fd4f6e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ce079b5a18054eb9434bf7032bcdffb599fd4f6e">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tsai_Video_Relationship_Reasoning_Using_Gated_Spatio-Temporal_Energy_Graph_CVPR_2019_paper.html">Video Relationship Reasoning Using Gated Spatio-Temporal Energy Graph</a></th>
                    </tr>
                
                    <tr id="d9344534ab39544a3a3c173b27628e0d9c5d4dc5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d9344534ab39544a3a3c173b27628e0d9c5d4dc5">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shrestha_Answer_Them_All_Toward_Universal_Visual_Question_Answering_Models_CVPR_2019_paper.html">Answer Them All! Toward Universal Visual Question Answering Models</a></th>
                    </tr>
                
                    <tr id="a72a11bf9a651038407dcf9530824e545e066b22">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a72a11bf9a651038407dcf9530824e545e066b22">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Efficient_Neural_Network_Compression_CVPR_2019_paper.html">Efficient Neural Network Compression</a></th>
                    </tr>
                
                    <tr id="38c2c67ef599a9702c683795925d80e403b82d5e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38c2c67ef599a9702c683795925d80e403b82d5e">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jiao_Geometry-Aware_Distillation_for_Indoor_Semantic_Segmentation_CVPR_2019_paper.html">Geometry-Aware Distillation for Indoor Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="301c36778a8581a2526d674e7bd5472279f35e07">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/301c36778a8581a2526d674e7bd5472279f35e07">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Compressing_Convolutional_Neural_Networks_via_Factorized_Convolutional_Filters_CVPR_2019_paper.html">Compressing Convolutional Neural Networks via Factorized Convolutional Filters</a></th>
                    </tr>
                
                    <tr id="ba224894fdcc9f38cf0b0570c5e34d527143a17a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ba224894fdcc9f38cf0b0570c5e34d527143a17a">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shen_Networks_for_Joint_Affine_and_Non-Parametric_Image_Registration_CVPR_2019_paper.html">Networks for Joint Affine and Non-Parametric Image Registration</a></th>
                    </tr>
                
                    <tr id="bcc4d9c707dc983eaa78cdb60f34e5b267e96f8c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bcc4d9c707dc983eaa78cdb60f34e5b267e96f8c">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tang_A_Skeleton-Bridged_Deep_Learning_Approach_for_Generating_Meshes_of_Complex_CVPR_2019_paper.html">A Skeleton-Bridged Deep Learning Approach for Generating Meshes of Complex Topologies From Single RGB Images</a></th>
                    </tr>
                
                    <tr id="f36d667dd3eeee1f37fa0a00b28cba862ef20116">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f36d667dd3eeee1f37fa0a00b28cba862ef20116">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Singh_HetConv_Heterogeneous_Kernel-Based_Convolutions_for_Deep_CNNs_CVPR_2019_paper.html">HetConv: Heterogeneous Kernel-Based Convolutions for Deep CNNs</a></th>
                    </tr>
                
                    <tr id="5e5e6223b926bf3554526bbc7b97dfa12a6d8fbf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5e5e6223b926bf3554526bbc7b97dfa12a6d8fbf">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Towards_Robust_Curve_Text_Detection_With_Conditional_Spatial_Expansion_CVPR_2019_paper.html">Towards Robust Curve Text Detection With Conditional Spatial Expansion</a></th>
                    </tr>
                
                    <tr id="40a73c1feb21e57d07d75f17d3f867f175852852">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/40a73c1feb21e57d07d75f17d3f867f175852852">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_MetaCleaner_Learning_to_Hallucinate_Clean_Representations_for_Noisy-Labeled_Visual_Recognition_CVPR_2019_paper.html">MetaCleaner: Learning to Hallucinate Clean Representations for Noisy-Labeled Visual Recognition</a></th>
                    </tr>
                
                    <tr id="a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a2f8f9ae3de0ce1a4d8976c0dd1d9ff90af80ee8">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Collaborative_Spatiotemporal_Feature_Learning_for_Video_Action_Recognition_CVPR_2019_paper.html">Collaborative Spatiotemporal Feature Learning for Video Action Recognition</a></th>
                    </tr>
                
                    <tr id="c63e0a1eb3c3926f55f96a48b6c44d68f78cf08f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c63e0a1eb3c3926f55f96a48b6c44d68f78cf08f">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shen_Discovering_Visual_Patterns_in_Art_Collections_With_Spatially-Consistent_Feature_Learning_CVPR_2019_paper.html">Discovering Visual Patterns in Art Collections With Spatially-Consistent Feature Learning</a></th>
                    </tr>
                
                    <tr id="818ab75722aea9b76a8032c13b8eea9600aa1453">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/818ab75722aea9b76a8032c13b8eea9600aa1453">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Connecting_Touch_and_Vision_via_Cross-Modal_Prediction_CVPR_2019_paper.html">Connecting Touch and Vision via Cross-Modal Prediction</a></th>
                    </tr>
                
                    <tr id="f052c2569de6487482277b3b826feea06282346a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f052c2569de6487482277b3b826feea06282346a">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chabra_StereoDRNet_Dilated_Residual_StereoNet_CVPR_2019_paper.html">StereoDRNet: Dilated Residual StereoNet</a></th>
                    </tr>
                
                    <tr id="413992b048847aa6e82631420799403e61516d23">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/413992b048847aa6e82631420799403e61516d23">59</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BEFA/Kortylewski_Analyzing_and_Reducing_the_Damage_of_Dataset_Bias_to_Face_CVPRW_2019_paper.html">Analyzing and Reducing the Damage of Dataset Bias to Face Recognition With Synthetic Data</a></th>
                    </tr>
                
                    <tr id="77f2842d587813833009783af99cd7506c8779e9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/77f2842d587813833009783af99cd7506c8779e9">59</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UAVision/Unel_The_Power_of_Tiling_for_Small_Object_Detection_CVPRW_2019_paper.html">The Power of Tiling for Small Object Detection</a></th>
                    </tr>
                
                    <tr id="85a3cd627540fea7ef5c195ee1bd2cc9697e413a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/85a3cd627540fea7ef5c195ee1bd2cc9697e413a">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xiong_Less_Is_More_Learning_Highlight_Detection_From_Video_Duration_CVPR_2019_paper.html">Less Is More: Learning Highlight Detection From Video Duration</a></th>
                    </tr>
                
                    <tr id="ac53943582808fc0a260eb347b975515f26dc430">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ac53943582808fc0a260eb347b975515f26dc430">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Circulant_Binary_Convolutional_Networks_Enhancing_the_Performance_of_1-Bit_DCNNs_CVPR_2019_paper.html">Circulant Binary Convolutional Networks: Enhancing the Performance of 1-Bit DCNNs With Circulant Back Propagation</a></th>
                    </tr>
                
                    <tr id="90579a68e46b772a8e9aaca8ecbd06942d0b9b35">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/90579a68e46b772a8e9aaca8ecbd06942d0b9b35">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Describing_Like_Humans_On_Diversity_in_Image_Captioning_CVPR_2019_paper.html">Describing Like Humans: On Diversity in Image Captioning</a></th>
                    </tr>
                
                    <tr id="ecb41d38de9698fae7304c764b1fd2b29bfe2139">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ecb41d38de9698fae7304c764b1fd2b29bfe2139">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ghasedi_Balanced_Self-Paced_Learning_for_Generative_Adversarial_Clustering_Network_CVPR_2019_paper.html">Balanced Self-Paced Learning for Generative Adversarial Clustering Network</a></th>
                    </tr>
                
                    <tr id="56325ed57ae76d591a98d05cf94a9e891e389c40">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/56325ed57ae76d591a98d05cf94a9e891e389c40">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhan_On_Exploring_Undetermined_Relationships_for_Visual_Relationship_Detection_CVPR_2019_paper.html">On Exploring Undetermined Relationships for Visual Relationship Detection</a></th>
                    </tr>
                
                    <tr id="d1848ab867e6f8daf042be84e6e7f83d06b74bc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d1848ab867e6f8daf042be84e6e7f83d06b74bc1">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ribera_Locating_Objects_Without_Bounding_Boxes_CVPR_2019_paper.html">Locating Objects Without Bounding Boxes</a></th>
                    </tr>
                
                    <tr id="2bb57b98a900fe49a9328d8ec76eac600f3c3f88">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2bb57b98a900fe49a9328d8ec76eac600f3c3f88">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tan_Text2Scene_Generating_Compositional_Scenes_From_Textual_Descriptions_CVPR_2019_paper.html">Text2Scene: Generating Compositional Scenes From Textual Descriptions</a></th>
                    </tr>
                
                    <tr id="6aa771e886c41c57d3059e850022168db49ed3e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6aa771e886c41c57d3059e850022168db49ed3e1">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Arun_Dissimilarity_Coefficient_Based_Weakly_Supervised_Object_Detection_CVPR_2019_paper.html">Dissimilarity Coefficient Based Weakly Supervised Object Detection</a></th>
                    </tr>
                
                    <tr id="d3ba039764e38dd4fac37a091867c4c29f5f7855">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d3ba039764e38dd4fac37a091867c4c29f5f7855">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Geng_3D_Guided_Fine-Grained_Face_Manipulation_CVPR_2019_paper.html">3D Guided Fine-Grained Face Manipulation</a></th>
                    </tr>
                
                    <tr id="ece7f51e40856da3e52e62e1eaff9c9c5b1d4e8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ece7f51e40856da3e52e62e1eaff9c9c5b1d4e8f">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Nguyen_A_Neural_Network_Based_on_SPD_Manifold_Learning_for_Skeleton-Based_CVPR_2019_paper.html">A Neural Network Based on SPD Manifold Learning for Skeleton-Based Hand Gesture Recognition</a></th>
                    </tr>
                
                    <tr id="69aac6c8b0d440b6ce9ea8cee9bf2a0a8006393d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/69aac6c8b0d440b6ce9ea8cee9bf2a0a8006393d">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Scalable_Convolutional_Neural_Network_for_Image_Compressed_Sensing_CVPR_2019_paper.html">Scalable Convolutional Neural Network for Image Compressed Sensing</a></th>
                    </tr>
                
                    <tr id="a41c1880e2184a133d3f8d9635b1404b0dd19a63">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a41c1880e2184a133d3f8d9635b1404b0dd19a63">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Putting_Humans_in_a_Scene_Learning_Affordance_in_3D_Indoor_CVPR_2019_paper.html">Putting Humans in a Scene: Learning Affordance in 3D Indoor Environments</a></th>
                    </tr>
                
                    <tr id="542fcc66539ea974f15e22401075742afa684b15">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/542fcc66539ea974f15e22401075742afa684b15">58</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Nandakumar_Towards_Deep_Neural_Network_Training_on_Encrypted_Data_CVPRW_2019_paper.html">Towards Deep Neural Network Training on Encrypted Data</a></th>
                    </tr>
                
                    <tr id="49ece49a337f5f236b352aba0788dfc678e925d0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/49ece49a337f5f236b352aba0788dfc678e925d0">58</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Bridgeman_Multi-Person_3D_Pose_Estimation_and_Tracking_in_Sports_CVPRW_2019_paper.html">Multi-Person 3D Pose Estimation and Tracking in Sports</a></th>
                    </tr>
                
                    <tr id="32899bc91029f7f439e88c8e4514c0e261fcddd8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/32899bc91029f7f439e88c8e4514c0e261fcddd8">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Kervolutional_Neural_Networks_CVPR_2019_paper.html">Kervolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="3f650e8d4d0e8c1d8eb9c8fffbe4d80dadd00d1f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f650e8d4d0e8c1d8eb9c8fffbe4d80dadd00d1f">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wengrowski_Light_Field_Messaging_With_Deep_Photographic_Steganography_CVPR_2019_paper.html">Light Field Messaging With Deep Photographic Steganography</a></th>
                    </tr>
                
                    <tr id="e6258cb5ae8d15870e65c363efea319e012fb249">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e6258cb5ae8d15870e65c363efea319e012fb249">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Krishna_Information_Maximizing_Visual_Question_Generation_CVPR_2019_paper.html">Information Maximizing Visual Question Generation</a></th>
                    </tr>
                
                    <tr id="c4a0167ff3fe9d64e563b881603a3631028692d7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c4a0167ff3fe9d64e563b881603a3631028692d7">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Student_Becoming_the_Master_Knowledge_Amalgamation_for_Joint_Scene_Parsing_CVPR_2019_paper.html">Student Becoming the Master: Knowledge Amalgamation for Joint Scene Parsing, Depth Estimation, and More</a></th>
                    </tr>
                
                    <tr id="4fef1313fd4948fed09dee318e2e231216c4fb3b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4fef1313fd4948fed09dee318e2e231216c4fb3b">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Guo_MSCap_Multi-Style_Image_Captioning_With_Unpaired_Stylized_Text_CVPR_2019_paper.html">MSCap: Multi-Style Image Captioning With Unpaired Stylized Text</a></th>
                    </tr>
                
                    <tr id="c279e565e950c4335060865b6ed5247b9cb5b4f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c279e565e950c4335060865b6ed5247b9cb5b4f2">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wong_Bilateral_Cyclic_Constraint_and_Adaptive_Regularization_for_Unsupervised_Monocular_Depth_CVPR_2019_paper.html">Bilateral Cyclic Constraint and Adaptive Regularization for Unsupervised Monocular Depth Prediction</a></th>
                    </tr>
                
                    <tr id="e0c0ac3bb66203c32be81193fabeee44c3585582">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e0c0ac3bb66203c32be81193fabeee44c3585582">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qin_Look_Back_and_Predict_Forward_in_Image_Captioning_CVPR_2019_paper.html">Look Back and Predict Forward in Image Captioning</a></th>
                    </tr>
                
                    <tr id="e712a5e4d83e1d3a3e9d2d8f67c6612e7b40eca1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e712a5e4d83e1d3a3e9d2d8f67c6612e7b40eca1">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kato_Learning_View_Priors_for_Single-View_3D_Reconstruction_CVPR_2019_paper.html">Learning View Priors for Single-View 3D Reconstruction</a></th>
                    </tr>
                
                    <tr id="64366fd28a9cecdf3156b1fa84d1613ec8161f1c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/64366fd28a9cecdf3156b1fa84d1613ec8161f1c">57</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Hsu_Multi-Camera_Tracking_of_Vehicles_based_on_Deep_Features_Re-ID_and_CVPRW_2019_paper.html">Multi-Camera Tracking of Vehicles based on Deep Features Re-ID and Trajectory-Based Camera Link Models</a></th>
                    </tr>
                
                    <tr id="77353207f4322a827b9af446855f2df71e6065e4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/77353207f4322a827b9af446855f2df71e6065e4">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Poggi_Guided_Stereo_Matching_CVPR_2019_paper.html">Guided Stereo Matching</a></th>
                    </tr>
                
                    <tr id="00b504c1ff34d86356d893ba1f0159b1710c7bc9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00b504c1ff34d86356d893ba1f0159b1710c7bc9">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Distilled_Person_Re-Identification_Towards_a_More_Scalable_System_CVPR_2019_paper.html">Distilled Person Re-Identification: Towards a More Scalable System</a></th>
                    </tr>
                
                    <tr id="625d29d1eb0ca22a28fde27c04766916f12175ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/625d29d1eb0ca22a28fde27c04766916f12175ad">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Blending-Target_Domain_Adaptation_by_Adversarial_Meta-Adaptation_Networks_CVPR_2019_paper.html">Blending-Target Domain Adaptation by Adversarial Meta-Adaptation Networks</a></th>
                    </tr>
                
                    <tr id="ecffb9126f17d157b0a35b0e4f96f741d3f5faf9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ecffb9126f17d157b0a35b0e4f96f741d3f5faf9">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Iterative_Normalization_Beyond_Standardization_Towards_Efficient_Whitening_CVPR_2019_paper.html">Iterative Normalization: Beyond Standardization Towards Efficient Whitening</a></th>
                    </tr>
                
                    <tr id="b430af071a523b03911e35a23bc12ae96e86bd4c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b430af071a523b03911e35a23bc12ae96e86bd4c">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tomei_Art2Real_Unfolding_the_Reality_of_Artworks_via_Semantically-Aware_Image-To-Image_Translation_CVPR_2019_paper.html">Art2Real: Unfolding the Reality of Artworks via Semantically-Aware Image-To-Image Translation</a></th>
                    </tr>
                
                    <tr id="b621afeef5888f8f71fd6ca97a62daa0d0cb6d69">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b621afeef5888f8f71fd6ca97a62daa0d0cb6d69">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Progressive_Attention_Memory_Network_for_Movie_Story_Question_Answering_CVPR_2019_paper.html">Progressive Attention Memory Network for Movie Story Question Answering</a></th>
                    </tr>
                
                    <tr id="b564a44c72572cc179ad81d50ab6ca47d3a0394f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b564a44c72572cc179ad81d50ab6ca47d3a0394f">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yin_Side_Window_Filtering_CVPR_2019_paper.html">Side Window Filtering</a></th>
                    </tr>
                
                    <tr id="ebd6264650306e6fb3b7ae9ab60fef1c77d2f013">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ebd6264650306e6fb3b7ae9ab60fef1c77d2f013">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Seo_Learning_for_Single-Shot_Confidence_Calibration_in_Deep_Neural_Networks_Through_CVPR_2019_paper.html">Learning for Single-Shot Confidence Calibration in Deep Neural Networks Through Stochastic Inferences</a></th>
                    </tr>
                
                    <tr id="213a37f44d28799ebff6b20aa53867d4d7a08cc4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/213a37f44d28799ebff6b20aa53867d4d7a08cc4">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Dance_With_Flow_Two-In-One_Stream_Action_Detection_CVPR_2019_paper.html">Dance With Flow: Two-In-One Stream Action Detection</a></th>
                    </tr>
                
                    <tr id="7d29e102bda996bb648faa31c72ac725a0db5773">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7d29e102bda996bb648faa31c72ac725a0db5773">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_Learning_Image_and_Video_Compression_Through_Spatial-Temporal_Energy_Compaction_CVPR_2019_paper.html">Learning Image and Video Compression Through Spatial-Temporal Energy Compaction</a></th>
                    </tr>
                
                    <tr id="7549690915765187fab38e9756fd0ec37b6e8e58">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7549690915765187fab38e9756fd0ec37b6e8e58">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ehret_Model-Blind_Video_Denoising_via_Frame-To-Frame_Training_CVPR_2019_paper.html">Model-Blind Video Denoising via Frame-To-Frame Training</a></th>
                    </tr>
                
                    <tr id="b95ce8e6249302e9f4c88248ab587f43760d88b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b95ce8e6249302e9f4c88248ab587f43760d88b1">56</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Devaguptapu_Borrow_From_Anywhere_Pseudo_Multi-Modal_Object_Detection_in_Thermal_Imagery_CVPRW_2019_paper.html">Borrow From Anywhere: Pseudo Multi-Modal Object Detection in Thermal Imagery</a></th>
                    </tr>
                
                    <tr id="0b42fd2d5e4167a5b4c29b71e086ce2487032a6e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0b42fd2d5e4167a5b4c29b71e086ce2487032a6e">56</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Claus_ViDeNN_Deep_Blind_Video_Denoising_CVPRW_2019_paper.html">ViDeNN: Deep Blind Video Denoising</a></th>
                    </tr>
                
                    <tr id="88bf3a55c26143e2da976560f50c0e1a24838948">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/88bf3a55c26143e2da976560f50c0e1a24838948">56</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Park_Densely_Connected_Hierarchical_Network_for_Image_Denoising_CVPRW_2019_paper.html">Densely Connected Hierarchical Network for Image Denoising</a></th>
                    </tr>
                
                    <tr id="fae3ff37995414fb9c5f1cac19301b7dff2f2bc8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fae3ff37995414fb9c5f1cac19301b7dff2f2bc8">56</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Naphade_The_2019_AI_City_Challenge_CVPRW_2019_paper.html">The 2019 AI City Challenge</a></th>
                    </tr>
                
                    <tr id="58f32f1e294569f88d20892c11b389105da9c615">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/58f32f1e294569f88d20892c11b389105da9c615">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Bhardwaj_Efficient_Video_Classification_Using_Fewer_Frames_CVPR_2019_paper.html">Efficient Video Classification Using Fewer Frames</a></th>
                    </tr>
                
                    <tr id="dc12d0f6aa8a78ac7e17cc2598e5a6a455b244ae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dc12d0f6aa8a78ac7e17cc2598e5a6a455b244ae">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Frame-Consistent_Recurrent_Video_Deraining_With_Dual-Level_Flow_CVPR_2019_paper.html">Frame-Consistent Recurrent Video Deraining With Dual-Level Flow</a></th>
                    </tr>
                
                    <tr id="4ae0fcf79d63e54e8837db560ebf9b48882949cf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ae0fcf79d63e54e8837db560ebf9b48882949cf">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lai_Bridging_Stereo_Matching_and_Optical_Flow_via_Spatiotemporal_Correspondence_CVPR_2019_paper.html">Bridging Stereo Matching and Optical Flow via Spatiotemporal Correspondence</a></th>
                    </tr>
                
                    <tr id="ec2ba7405320687a715248bf2029e753135bd31f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ec2ba7405320687a715248bf2029e753135bd31f">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shen_Towards_Instance-Level_Image-To-Image_Translation_CVPR_2019_paper.html">Towards Instance-Level Image-To-Image Translation</a></th>
                    </tr>
                
                    <tr id="150b316a32fd9f10b5936f7fccd2179e83bd9ee7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/150b316a32fd9f10b5936f7fccd2179e83bd9ee7">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Object_Instance_Annotation_With_Deep_Extreme_Level_Set_Evolution_CVPR_2019_paper.html">Object Instance Annotation With Deep Extreme Level Set Evolution</a></th>
                    </tr>
                
                    <tr id="fb185c575764ea52dce2674cf03b4593f2d4c46a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fb185c575764ea52dce2674cf03b4593f2d4c46a">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Collaborative_Global-Local_Networks_for_Memory-Efficient_Segmentation_of_Ultra-High_Resolution_Images_CVPR_2019_paper.html">Collaborative Global-Local Networks for Memory-Efficient Segmentation of Ultra-High Resolution Images</a></th>
                    </tr>
                
                    <tr id="ea2d338b8d53d2b4153a42838d090e59842dc2be">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ea2d338b8d53d2b4153a42838d090e59842dc2be">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ploumpis_Combining_3D_Morphable_Models_A_Large_Scale_Face-And-Head_Model_CVPR_2019_paper.html">Combining 3D Morphable Models: A Large Scale Face-And-Head Model</a></th>
                    </tr>
                
                    <tr id="902d00fc7296b2372e48e337c84c80dfa0b021dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/902d00fc7296b2372e48e337c84c80dfa0b021dd">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_DAVANet_Stereo_Deblurring_With_View_Aggregation_CVPR_2019_paper.html">DAVANet: Stereo Deblurring With View Aggregation</a></th>
                    </tr>
                
                    <tr id="f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f5c5c5a2ae127e3e21c1ea94ccad4c17fd02b914">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kart_Object_Tracking_by_Reconstruction_With_View-Specific_Discriminative_Correlation_Filters_CVPR_2019_paper.html">Object Tracking by Reconstruction With View-Specific Discriminative Correlation Filters</a></th>
                    </tr>
                
                    <tr id="089f2072c95c244f3b7f4df404562bb4afe24448">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/089f2072c95c244f3b7f4df404562bb4afe24448">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Peleg_IM-Net_for_High_Resolution_Video_Frame_Interpolation_CVPR_2019_paper.html">IM-Net for High Resolution Video Frame Interpolation</a></th>
                    </tr>
                
                    <tr id="32e277b85802685105254430c4170ad2b1a16c04">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/32e277b85802685105254430c4170ad2b1a16c04">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kaneko_Label-Noise_Robust_Generative_Adversarial_Networks_CVPR_2019_paper.html">Label-Noise Robust Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="31421dcbe01bc0f9f521b1c77cd6beb5679483af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/31421dcbe01bc0f9f521b1c77cd6beb5679483af">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wen_Single_Image_Reflection_Removal_Beyond_Linearity_CVPR_2019_paper.html">Single Image Reflection Removal Beyond Linearity</a></th>
                    </tr>
                
                    <tr id="774b82552352df1befb4cec628fee1e3ca030fd4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/774b82552352df1befb4cec628fee1e3ca030fd4">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_EV-Gait_Event-Based_Robust_Gait_Recognition_Using_Dynamic_Vision_Sensors_CVPR_2019_paper.html">EV-Gait: Event-Based Robust Gait Recognition Using Dynamic Vision Sensors</a></th>
                    </tr>
                
                    <tr id="c90d413c1b7b95c1926569eeab016b31b7a90350">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c90d413c1b7b95c1926569eeab016b31b7a90350">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Brazil_Pedestrian_Detection_With_Autoregressive_Network_Phases_CVPR_2019_paper.html">Pedestrian Detection With Autoregressive Network Phases</a></th>
                    </tr>
                
                    <tr id="ad6865571eccf6cc20d7b4a94b38d1178dc91a88">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ad6865571eccf6cc20d7b4a94b38d1178dc91a88">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lemaire_Structured_Pruning_of_Neural_Networks_With_Budget-Aware_Regularization_CVPR_2019_paper.html">Structured Pruning of Neural Networks With Budget-Aware Regularization</a></th>
                    </tr>
                
                    <tr id="9951c4a7e56629fe44ecc8df0e7392f81c47849c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9951c4a7e56629fe44ecc8df0e7392f81c47849c">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qian_Unsupervised_Face_Normalization_With_Extreme_Pose_and_Expression_in_the_CVPR_2019_paper.html">Unsupervised Face Normalization With Extreme Pose and Expression in the Wild</a></th>
                    </tr>
                
                    <tr id="e6ab7b7fee9a25342ef1cac082c77a7f1021a982">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e6ab7b7fee9a25342ef1cac082c77a7f1021a982">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Modulating_Image_Restoration_With_Continual_Levels_via_Adaptive_Feature_Modification_CVPR_2019_paper.html">Modulating Image Restoration With Continual Levels via Adaptive Feature Modification Layers</a></th>
                    </tr>
                
                    <tr id="09d0f5df43f3e037f7278b8a5d01ce4169e520e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/09d0f5df43f3e037f7278b8a5d01ce4169e520e6">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pang_Generalising_Fine-Grained_Sketch-Based_Image_Retrieval_CVPR_2019_paper.html">Generalising Fine-Grained Sketch-Based Image Retrieval</a></th>
                    </tr>
                
                    <tr id="f8504c90e2e23cfa39ac45a02a28dcb89d047203">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f8504c90e2e23cfa39ac45a02a28dcb89d047203">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yeh_Diverse_Generation_for_Multi-Agent_Sports_Games_CVPR_2019_paper.html">Diverse Generation for Multi-Agent Sports Games</a></th>
                    </tr>
                
                    <tr id="39b615c73810e13998df3df9d5e73aebd3e67dab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39b615c73810e13998df3df9d5e73aebd3e67dab">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Vemulapalli_A_Compact_Embedding_for_Facial_Expression_Similarity_CVPR_2019_paper.html">A Compact Embedding for Facial Expression Similarity</a></th>
                    </tr>
                
                    <tr id="8c0af5f7cd34f7d1d27216525ddce378cbd72c70">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c0af5f7cd34f7d1d27216525ddce378cbd72c70">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Aggregation_Cross-Entropy_for_Sequence_Recognition_CVPR_2019_paper.html">Aggregation Cross-Entropy for Sequence Recognition</a></th>
                    </tr>
                
                    <tr id="18b38ca5d672825bcb12cbc9a3bcf111ec136d98">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/18b38ca5d672825bcb12cbc9a3bcf111ec136d98">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Purohit_Bringing_Alive_Blurred_Moments_CVPR_2019_paper.html">Bringing Alive Blurred Moments</a></th>
                    </tr>
                
                    <tr id="5c4d6220fafa3b4b302edd28c5229041b80727e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c4d6220fafa3b4b302edd28c5229041b80727e1">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kukleva_Unsupervised_Learning_of_Action_Classes_With_Continuous_Temporal_Embedding_CVPR_2019_paper.html">Unsupervised Learning of Action Classes With Continuous Temporal Embedding</a></th>
                    </tr>
                
                    <tr id="ab01af20f8678c17ea45e207acb9aba16871a63c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ab01af20f8678c17ea45e207acb9aba16871a63c">53</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Su_Active_Adversarial_Domain_Adaptation_CVPRW_2019_paper.html">Active Adversarial Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="ee2ec70a9b0740f0275737493ac7678ff2cd4a6a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ee2ec70a9b0740f0275737493ac7678ff2cd4a6a">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lin_Photometric_Mesh_Optimization_for_Video-Aligned_3D_Object_Reconstruction_CVPR_2019_paper.html">Photometric Mesh Optimization for Video-Aligned 3D Object Reconstruction</a></th>
                    </tr>
                
                    <tr id="a3c059979783ae3c4cc262423ee62c9ea0b37097">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a3c059979783ae3c4cc262423ee62c9ea0b37097">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Single-Image_Piece-Wise_Planar_3D_Reconstruction_via_Associative_Embedding_CVPR_2019_paper.html">Single-Image Piece-Wise Planar 3D Reconstruction via Associative Embedding</a></th>
                    </tr>
                
                    <tr id="7c5b1bbc49e4be0efd98e0b513e0b41659a32413">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c5b1bbc49e4be0efd98e0b513e0b41659a32413">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lindell_Acoustic_Non-Line-Of-Sight_Imaging_CVPR_2019_paper.html">Acoustic Non-Line-Of-Sight Imaging</a></th>
                    </tr>
                
                    <tr id="649b03e22186cbbe921c31d8bfa3399ae475d85d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/649b03e22186cbbe921c31d8bfa3399ae475d85d">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xiong_Mixed_Effects_Neural_Networks_MeNets_With_Applications_to_Gaze_Estimation_CVPR_2019_paper.html">Mixed Effects Neural Networks (MeNets) With Applications to Gaze Estimation</a></th>
                    </tr>
                
                    <tr id="86f6fda61a6d778055ba20daf486697d933a220e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/86f6fda61a6d778055ba20daf486697d933a220e">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Doughty_The_Pros_and_Cons_Rank-Aware_Temporal_Attention_for_Skill_Determination_CVPR_2019_paper.html">The Pros and Cons: Rank-Aware Temporal Attention for Skill Determination in Long Videos</a></th>
                    </tr>
                
                    <tr id="d0415f175fdda969c9e92f6f4ac07e9f57bf484f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d0415f175fdda969c9e92f6f4ac07e9f57bf484f">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Shape2Motion_Joint_Analysis_of_Motion_Parts_and_Attributes_From_3D_CVPR_2019_paper.html">Shape2Motion: Joint Analysis of Motion Parts and Attributes From 3D Shapes</a></th>
                    </tr>
                
                    <tr id="2288ad631df10ac206e36db9e04a912a0170f877">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2288ad631df10ac206e36db9e04a912a0170f877">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Point-To-Pose_Voting_Based_Hand_Pose_Estimation_Using_Residual_Permutation_Equivariant_CVPR_2019_paper.html">Point-To-Pose Voting Based Hand Pose Estimation Using Residual Permutation Equivariant Layer</a></th>
                    </tr>
                
                    <tr id="702111d5821ac1962ca7f4c4e3c4ed6a0887b093">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/702111d5821ac1962ca7f4c4e3c4ed6a0887b093">52</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Precognition/Miech_Leveraging_the_Present_to_Anticipate_the_Future_in_Videos_CVPRW_2019_paper.html">Leveraging the Present to Anticipate the Future in Videos</a></th>
                    </tr>
                
                    <tr id="3dd61d6422b7b1de5f61e225c99fb4e277ed5e90">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3dd61d6422b7b1de5f61e225c99fb4e277ed5e90">52</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Cannici_Asynchronous_Convolutional_Networks_for_Object_Detection_in_Neuromorphic_Cameras_CVPRW_2019_paper.html">Asynchronous Convolutional Networks for Object Detection in Neuromorphic Cameras</a></th>
                    </tr>
                
                    <tr id="1c9932feb06a3b873361a3318183396214fba4b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1c9932feb06a3b873361a3318183396214fba4b5">52</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Qi_Visualizing_Deep_Networks_by_Optimizing_with_Integrated_Gradients_CVPRW_2019_paper.html">Visualizing Deep Networks by Optimizing with Integrated Gradients</a></th>
                    </tr>
                
                    <tr id="d68ae09863d3ec1831392204f7a062ebebaacff9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d68ae09863d3ec1831392204f7a062ebebaacff9">52</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Sight_and_Sound/Amanda_Cardoso_Duarte_WAV2PIX_Speech-conditioned_Face_Generation_using_Generative_Adversarial_Networks_CVPRW_2019_paper.html">WAV2PIX: Speech-conditioned Face Generation using Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="175a8162adae369bcdc76821e78f33e4b809ff37">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/175a8162adae369bcdc76821e78f33e4b809ff37">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Maksai_Eliminating_Exposure_Bias_and_Metric_Mismatch_in_Multiple_Object_Tracking_CVPR_2019_paper.html">Eliminating Exposure Bias and Metric Mismatch in Multiple Object Tracking</a></th>
                    </tr>
                
                    <tr id="c97b413fc75bcc68045efbf2cf4ba70af3d67428">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c97b413fc75bcc68045efbf2cf4ba70af3d67428">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Learning_Single-Image_Depth_From_Videos_Using_Quality_Assessment_Networks_CVPR_2019_paper.html">Learning Single-Image Depth From Videos Using Quality Assessment Networks</a></th>
                    </tr>
                
                    <tr id="c945dfec0137bcd7886898fa61f46705e00173dc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c945dfec0137bcd7886898fa61f46705e00173dc">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Brooks_Learning_to_Synthesize_Motion_Blur_CVPR_2019_paper.html">Learning to Synthesize Motion Blur</a></th>
                    </tr>
                
                    <tr id="c8475332c033ff69cf87621d9fc80a0a73967480">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c8475332c033ff69cf87621d9fc80a0a73967480">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Joo_Towards_Social_Artificial_Intelligence_Nonverbal_Social_Signal_Prediction_in_a_CVPR_2019_paper.html">Towards Social Artificial Intelligence: Nonverbal Social Signal Prediction in a Triadic Interaction</a></th>
                    </tr>
                
                    <tr id="299ee0aa0d299fcd5f37ffc97e8850952eebec23">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/299ee0aa0d299fcd5f37ffc97e8850952eebec23">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Self-Supervised_Representation_Learning_From_Videos_for_Facial_Action_Unit_Detection_CVPR_2019_paper.html">Self-Supervised Representation Learning From Videos for Facial Action Unit Detection</a></th>
                    </tr>
                
                    <tr id="ed516c62512a5189c185738172ec0b151912e931">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ed516c62512a5189c185738172ec0b151912e931">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Webster_Detecting_Overfitting_of_Deep_Generative_Networks_via_Latent_Recovery_CVPR_2019_paper.html">Detecting Overfitting of Deep Generative Networks via Latent Recovery</a></th>
                    </tr>
                
                    <tr id="8a11e40284960e3ac0a4240e0c6e3e968593593d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8a11e40284960e3ac0a4240e0c6e3e968593593d">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Imran_Depth_Coefficients_for_Depth_Completion_CVPR_2019_paper.html">Depth Coefficients for Depth Completion</a></th>
                    </tr>
                
                    <tr id="8eabed69bbebd83d90c7c27b731ff76edcd6b0a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8eabed69bbebd83d90c7c27b731ff76edcd6b0a9">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shao_SSN_Learning_Sparse_Switchable_Normalization_via_SparsestMax_CVPR_2019_paper.html">SSN: Learning Sparse Switchable Normalization via SparsestMax</a></th>
                    </tr>
                
                    <tr id="6433553d51fb2c889f799cb91f5585a52c0d1016">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6433553d51fb2c889f799cb91f5585a52c0d1016">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Co-Saliency_Detection_via_Mask-Guided_Fully_Convolutional_Networks_With_Multi-Scale_Label_CVPR_2019_paper.html">Co-Saliency Detection via Mask-Guided Fully Convolutional Networks With Multi-Scale Label Smoothing</a></th>
                    </tr>
                
                    <tr id="5d3e8d704ace4d8b1bd419ea6a436d989ce3c523">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5d3e8d704ace4d8b1bd419ea6a436d989ce3c523">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hu_SAIL-VOS_Semantic_Amodal_Instance_Level_Video_Object_Segmentation_-_A_CVPR_2019_paper.html">SAIL-VOS: Semantic Amodal Instance Level Video Object Segmentation – A Synthetic Dataset and Baselines</a></th>
                    </tr>
                
                    <tr id="4b976c711eb211f67c5bb36c37175eec2f5bb738">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4b976c711eb211f67c5bb36c37175eec2f5bb738">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_All_You_Need_Is_a_Few_Shifts_Designing_Efficient_Convolutional_CVPR_2019_paper.html">All You Need Is a Few Shifts: Designing Efficient Convolutional Neural Networks for Image Classification</a></th>
                    </tr>
                
                    <tr id="c147261ad2a359865d5780607816c05dc4b48b56">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c147261ad2a359865d5780607816c05dc4b48b56">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Azar_Convolutional_Relational_Machine_for_Group_Activity_Recognition_CVPR_2019_paper.html">Convolutional Relational Machine for Group Activity Recognition</a></th>
                    </tr>
                
                    <tr id="bc77291c3620abed2a247db09ca392772e1508ae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bc77291c3620abed2a247db09ca392772e1508ae">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shen_RF-Net_An_End-To-End_Image_Matching_Network_Based_on_Receptive_Field_CVPR_2019_paper.html">RF-Net: An End-To-End Image Matching Network Based on Receptive Field</a></th>
                    </tr>
                
                    <tr id="8920c700e388a00c51bcd7ef6353c968cbf31e07">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8920c700e388a00c51bcd7ef6353c968cbf31e07">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shetty_Not_Using_the_Car_to_See_the_Sidewalk_--_Quantifying_CVPR_2019_paper.html">Not Using the Car to See the Sidewalk — Quantifying and Controlling the Effects of Context in Classification and Segmentation</a></th>
                    </tr>
                
                    <tr id="50f039975093c9340ad0ac0bed9d67d35c783338">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50f039975093c9340ad0ac0bed9d67d35c783338">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dubey_Defense_Against_Adversarial_Images_Using_Web-Scale_Nearest-Neighbor_Search_CVPR_2019_paper.html">Defense Against Adversarial Images Using Web-Scale Nearest-Neighbor Search</a></th>
                    </tr>
                
                    <tr id="aa52bd3f7d791311ee7743db3c81ddc14ce9f76b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aa52bd3f7d791311ee7743db3c81ddc14ce9f76b">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tonioni_Learning_to_Adapt_for_Stereo_CVPR_2019_paper.html">Learning to Adapt for Stereo</a></th>
                    </tr>
                
                    <tr id="2c6afbbb45e1251c937c919cc855ee50daf79554">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c6afbbb45e1251c937c919cc855ee50daf79554">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Majumder_Content-Aware_Multi-Level_Guidance_for_Interactive_Instance_Segmentation_CVPR_2019_paper.html">Content-Aware Multi-Level Guidance for Interactive Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="e9dec624f166aafaf39e9e11b7c9926b75f280a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e9dec624f166aafaf39e9e11b7c9926b75f280a6">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wicker_Robustness_of_3D_Deep_Learning_in_an_Adversarial_Setting_CVPR_2019_paper.html">Robustness of 3D Deep Learning in an Adversarial Setting</a></th>
                    </tr>
                
                    <tr id="7243cc8350f6bc914cc7c50bebcab521919e7a84">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7243cc8350f6bc914cc7c50bebcab521919e7a84">50</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/VOCVALC/Casser_Unsupervised_Monocular_Depth_and_Ego-Motion_Learning_With_Structure_and_Semantics_CVPRW_2019_paper.html">Unsupervised Monocular Depth and Ego-Motion Learning With Structure and Semantics</a></th>
                    </tr>
                
                    <tr id="d7c057b823b5bba24f7d57e300fbbc811bf71d9d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d7c057b823b5bba24f7d57e300fbbc811bf71d9d">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Homomorphic_Latent_Space_Interpolation_for_Unpaired_Image-To-Image_Translation_CVPR_2019_paper.html">Homomorphic Latent Space Interpolation for Unpaired Image-To-Image Translation</a></th>
                    </tr>
                
                    <tr id="d69911fd370775989f7db698f726945676dac7bb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d69911fd370775989f7db698f726945676dac7bb">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lei_Fully_Automatic_Video_Colorization_With_Self-Regularization_and_Diversity_CVPR_2019_paper.html">Fully Automatic Video Colorization With Self-Regularization and Diversity</a></th>
                    </tr>
                
                    <tr id="66c21a179824037becb94105cafea75c746ad89a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/66c21a179824037becb94105cafea75c746ad89a">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Learning_Video_Representations_From_Correspondence_Proposals_CVPR_2019_paper.html">Learning Video Representations From Correspondence Proposals</a></th>
                    </tr>
                
                    <tr id="af3ca737ef14a1900470b5e5ae197be79325f105">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/af3ca737ef14a1900470b5e5ae197be79325f105">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Larsson_A_Cross-Season_Correspondence_Dataset_for_Robust_Semantic_Segmentation_CVPR_2019_paper.html">A Cross-Season Correspondence Dataset for Robust Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="fa31ef7dd6f8616781266355fb52bbac72942b6a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fa31ef7dd6f8616781266355fb52bbac72942b6a">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_BeautyGlow_On-Demand_Makeup_Transfer_Framework_With_Reversible_Generative_Network_CVPR_2019_paper.html">BeautyGlow: On-Demand Makeup Transfer Framework With Reversible Generative Network</a></th>
                    </tr>
                
                    <tr id="6dc67482ee0530e9ff535775891481ed9fd5f6ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6dc67482ee0530e9ff535775891481ed9fd5f6ad">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Pointing_Novel_Objects_in_Image_Captioning_CVPR_2019_paper.html">Pointing Novel Objects in Image Captioning</a></th>
                    </tr>
                
                    <tr id="8b79bfc93c7001dd7bb1eea7715af47d76202827">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b79bfc93c7001dd7bb1eea7715af47d76202827">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Decorrelated_Adversarial_Learning_for_Age-Invariant_Face_Recognition_CVPR_2019_paper.html">Decorrelated Adversarial Learning for Age-Invariant Face Recognition</a></th>
                    </tr>
                
                    <tr id="24032e75325377be73ab5ce33b5cae0ee872d73b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/24032e75325377be73ab5ce33b5cae0ee872d73b">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Bhunia_Handwriting_Recognition_in_Low-Resource_Scripts_Using_Adversarial_Learning_CVPR_2019_paper.html">Handwriting Recognition in Low-Resource Scripts Using Adversarial Learning</a></th>
                    </tr>
                
                    <tr id="1d50eaea52a0739874fa0f80c37c4723d4ef57db">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d50eaea52a0739874fa0f80c37c4723d4ef57db">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hoshen_Non-Adversarial_Image_Synthesis_With_Generative_Latent_Nearest_Neighbors_CVPR_2019_paper.html">Non-Adversarial Image Synthesis With Generative Latent Nearest Neighbors</a></th>
                    </tr>
                
                    <tr id="8001fa4dd0b26cd9604b32f8b6577e327ec77a6e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8001fa4dd0b26cd9604b32f8b6577e327ec77a6e">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cao_Triply_Supervised_Decoder_Networks_for_Joint_Detection_and_Segmentation_CVPR_2019_paper.html">Triply Supervised Decoder Networks for Joint Detection and Segmentation</a></th>
                    </tr>
                
                    <tr id="aa4beb7d2ccb5cee0ca1e9e6561913e60b1b0b39">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aa4beb7d2ccb5cee0ca1e9e6561913e60b1b0b39">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Han_Divergence_Triangle_for_Joint_Training_of_Generator_Model_Energy-Based_Model_CVPR_2019_paper.html">Divergence Triangle for Joint Training of Generator Model, Energy-Based Model, and Inferential Model</a></th>
                    </tr>
                
                    <tr id="0672635f300663b7bce1d59475cf607141335e50">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0672635f300663b7bce1d59475cf607141335e50">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Object_Discovery_in_Videos_as_Foreground_Motion_Clustering_CVPR_2019_paper.html">Object Discovery in Videos as Foreground Motion Clustering</a></th>
                    </tr>
                
                    <tr id="345e68d6bb9d110d504d87506eadd5e77e3acdc6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/345e68d6bb9d110d504d87506eadd5e77e3acdc6">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Le_SDRSAC_Semidefinite-Based_Randomized_Approach_for_Robust_Point_Cloud_Registration_Without_CVPR_2019_paper.html">SDRSAC: Semidefinite-Based Randomized Approach for Robust Point Cloud Registration Without Correspondences</a></th>
                    </tr>
                
                    <tr id="8dba803240e2cf00d143d4b0a82b95933b5883eb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8dba803240e2cf00d143d4b0a82b95933b5883eb">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gurari_VizWiz-Priv_A_Dataset_for_Recognizing_the_Presence_and_Purpose_of_CVPR_2019_paper.html">VizWiz-Priv: A Dataset for Recognizing the Presence and Purpose of Private Visual Information in Images Taken by Blind People</a></th>
                    </tr>
                
                    <tr id="5513e81f4eb9bac4fb4fe5ff8d862da545e7e1b3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5513e81f4eb9bac4fb4fe5ff8d862da545e7e1b3">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tang_Does_Learning_Specific_Features_for_Related_Parts_Help_Human_Pose_CVPR_2019_paper.html">Does Learning Specific Features for Related Parts Help Human Pose Estimation?</a></th>
                    </tr>
                
                    <tr id="75544f83d38ef1686d70c763deb43305c5dc8a48">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/75544f83d38ef1686d70c763deb43305c5dc8a48">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kumawat_LP-3DCNN_Unveiling_Local_Phase_in_3D_Convolutional_Neural_Networks_CVPR_2019_paper.html">LP-3DCNN: Unveiling Local Phase in 3D Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="a198312ee81aee37edaa24a39542017c8c09a633">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a198312ee81aee37edaa24a39542017c8c09a633">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lin_Face_Parsing_With_RoI_Tanh-Warping_CVPR_2019_paper.html">Face Parsing With RoI Tanh-Warping</a></th>
                    </tr>
                
                    <tr id="c4ea507a1a7f82ad39cbb28b065c3034a3396488">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c4ea507a1a7f82ad39cbb28b065c3034a3396488">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jin_Multi-Person_Articulated_Tracking_With_Spatial_and_Temporal_Embeddings_CVPR_2019_paper.html">Multi-Person Articulated Tracking With Spatial and Temporal Embeddings</a></th>
                    </tr>
                
                    <tr id="831b674c05514206dfdc6463ed1c6e232b222cd1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/831b674c05514206dfdc6463ed1c6e232b222cd1">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mancini_AdaGraph_Unifying_Predictive_and_Continuous_Domain_Adaptation_Through_Graphs_CVPR_2019_paper.html">AdaGraph: Unifying Predictive and Continuous Domain Adaptation Through Graphs</a></th>
                    </tr>
                
                    <tr id="ff74e1866a7397462cef8e35145bde9135e015aa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ff74e1866a7397462cef8e35145bde9135e015aa">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hsu_DeepCO3_Deep_Instance_Co-Segmentation_by_Co-Peak_Search_and_Co-Saliency_Detection_CVPR_2019_paper.html">DeepCO3: Deep Instance Co-Segmentation by Co-Peak Search and Co-Saliency Detection</a></th>
                    </tr>
                
                    <tr id="c4e6b18b5573329a5b62f297f6ab9565f841e11b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c4e6b18b5573329a5b62f297f6ab9565f841e11b">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Suganuma_Attention-Based_Adaptive_Selection_of_Operations_for_Image_Restoration_in_the_CVPR_2019_paper.html">Attention-Based Adaptive Selection of Operations for Image Restoration in the Presence of Unknown Combined Distortions</a></th>
                    </tr>
                
                    <tr id="065ed240398c080fba162944846dac5d77561f22">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/065ed240398c080fba162944846dac5d77561f22">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kang_Complete_the_Look_Scene-Based_Complementary_Product_Recommendation_CVPR_2019_paper.html">Complete the Look: Scene-Based Complementary Product Recommendation</a></th>
                    </tr>
                
                    <tr id="78a9eb5c59c349b329a35c6199f01675ebf9156c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/78a9eb5c59c349b329a35c6199f01675ebf9156c">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mohajerin_Multi-Step_Prediction_of_Occupancy_Grid_Maps_With_Recurrent_Neural_Networks_CVPR_2019_paper.html">Multi-Step Prediction of Occupancy Grid Maps With Recurrent Neural Networks</a></th>
                    </tr>
                
                    <tr id="23b27ae9af6ccff4faa04f18c9024fc49f57b4a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/23b27ae9af6ccff4faa04f18c9024fc49f57b4a2">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Engilberge_SoDeep_A_Sorting_Deep_Net_to_Learn_Ranking_Loss_Surrogates_CVPR_2019_paper.html">SoDeep: A Sorting Deep Net to Learn Ranking Loss Surrogates</a></th>
                    </tr>
                
                    <tr id="6ec277821807cbef9dd3f5ec42298604ad875137">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6ec277821807cbef9dd3f5ec42298604ad875137">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Simultaneously_Optimizing_Weight_and_Quantizer_of_Ternary_Neural_Network_Using_CVPR_2019_paper.html">Simultaneously Optimizing Weight and Quantizer of Ternary Neural Network Using Truncated Gaussian Approximation</a></th>
                    </tr>
                
                    <tr id="314a90d3b53e6a2d6c43bf3b9eabe86ae70b5c76">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/314a90d3b53e6a2d6c43bf3b9eabe86ae70b5c76">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Deep_Defocus_Map_Estimation_Using_Domain_Adaptation_CVPR_2019_paper.html">Deep Defocus Map Estimation Using Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="dfc91c82edc49e51952505efc26d04580e2b3d96">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dfc91c82edc49e51952505efc26d04580e2b3d96">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Robinson_Large_Scale_High-Resolution_Land_Cover_Mapping_With_Multi-Resolution_Data_CVPR_2019_paper.html">Large Scale High-Resolution Land Cover Mapping With Multi-Resolution Data</a></th>
                    </tr>
                
                    <tr id="4d7ddad51600a41c19b16aa2a852bbbe0f1866ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4d7ddad51600a41c19b16aa2a852bbbe0f1866ad">47</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MULA/Garbade_Two_Stream_3D_Semantic_Scene_Completion_CVPRW_2019_paper.html">Two Stream 3D Semantic Scene Completion</a></th>
                    </tr>
                
                    <tr id="26d852b7f42dc3f17311eda96da059c26bd46548">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26d852b7f42dc3f17311eda96da059c26bd46548">47</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MBCCV/Fernandez_FERAtt_Facial_Expression_Recognition_With_Attention_Net_CVPRW_2019_paper.html">FERAtt: Facial Expression Recognition With Attention Net</a></th>
                    </tr>
                
                    <tr id="e863a6b1bb39a38a88330f2609a560c3dfed6db5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e863a6b1bb39a38a88330f2609a560c3dfed6db5">47</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Chennupati_MultiNet_Multi-Stream_Feature_Aggregation_and_Geometric_Loss_Strategy_for_Multi-Task_CVPRW_2019_paper.html">MultiNet++: Multi-Stream Feature Aggregation and Geometric Loss Strategy for Multi-Task Learning</a></th>
                    </tr>
                
                    <tr id="e863a6b1bb39a38a88330f2609a560c3dfed6db5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e863a6b1bb39a38a88330f2609a560c3dfed6db5">47</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Chennupati_MultiNet_Multi-Stream_Feature_Aggregation_and_Geometric_Loss_Strategy_for_Multi-Task_CVPRW_2019_paper.html">MultiNet++: Multi-Stream Feature Aggregation and Geometric Loss Strategy for Multi-Task Learning</a></th>
                    </tr>
                
                    <tr id="b582223d509653ed59c653e0334d4703b793311b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b582223d509653ed59c653e0334d4703b793311b">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tang_DeFusionNET_Defocus_Blur_Detection_via_Recurrently_Fusing_and_Refining_Multi-Scale_CVPR_2019_paper.html">DeFusionNET: Defocus Blur Detection via Recurrently Fusing and Refining Multi-Scale Deep Features</a></th>
                    </tr>
                
                    <tr id="bdb5450be3a192034c989a0dbeaa24bccc4903ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bdb5450be3a192034c989a0dbeaa24bccc4903ab">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Social_Relation_Recognition_From_Videos_via_Multi-Scale_Spatial-Temporal_Reasoning_CVPR_2019_paper.html">Social Relation Recognition From Videos via Multi-Scale Spatial-Temporal Reasoning</a></th>
                    </tr>
                
                    <tr id="fa94f0769a7089392ae4ccc521f2b5cb01535f01">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fa94f0769a7089392ae4ccc521f2b5cb01535f01">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chu_Spot_and_Learn_A_Maximum-Entropy_Patch_Sampler_for_Few-Shot_Image_CVPR_2019_paper.html">Spot and Learn: A Maximum-Entropy Patch Sampler for Few-Shot Image Classification</a></th>
                    </tr>
                
                    <tr id="79de42d6ca8d1bf2952c46eb74e6e0561f979257">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/79de42d6ca8d1bf2952c46eb74e6e0561f979257">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Dense_Relational_Captioning_Triple-Stream_Networks_for_Relationship-Based_Captioning_CVPR_2019_paper.html">Dense Relational Captioning: Triple-Stream Networks for Relationship-Based Captioning</a></th>
                    </tr>
                
                    <tr id="68a2eb5890eb67989df5fb42b929d10e5e8e5a47">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/68a2eb5890eb67989df5fb42b929d10e5e8e5a47">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Multi-Target_Embodied_Question_Answering_CVPR_2019_paper.html">Multi-Target Embodied Question Answering</a></th>
                    </tr>
                
                    <tr id="fe976fcc6c6d6b47ce3c1f53f03f1a9318235f0b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fe976fcc6c6d6b47ce3c1f53f03f1a9318235f0b">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Paul_Semantically_Aligned_Bias_Reducing_Zero_Shot_Learning_CVPR_2019_paper.html">Semantically Aligned Bias Reducing Zero Shot Learning</a></th>
                    </tr>
                
                    <tr id="566c5e11542ed56f62cc04110f4658b8d7a4b0ec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/566c5e11542ed56f62cc04110f4658b8d7a4b0ec">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lin_ZigZagNet_Fusing_Top-Down_and_Bottom-Up_Context_for_Object_Segmentation_CVPR_2019_paper.html">ZigZagNet: Fusing Top-Down and Bottom-Up Context for Object Segmentation</a></th>
                    </tr>
                
                    <tr id="b6aabad83dff79b05e267659948f8e8d1695c0e2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b6aabad83dff79b05e267659948f8e8d1695c0e2">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qian_On_Finding_Gray_Pixels_CVPR_2019_paper.html">On Finding Gray Pixels</a></th>
                    </tr>
                
                    <tr id="c7fe452e844e9feaa269857feb319f25dd22f0bc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c7fe452e844e9feaa269857feb319f25dd22f0bc">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Niethammer_Metric_Learning_for_Image_Registration_CVPR_2019_paper.html">Metric Learning for Image Registration</a></th>
                    </tr>
                
                    <tr id="f7ac2022593dd66c09513fab02679bd4bc706c6a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7ac2022593dd66c09513fab02679bd4bc706c6a">46</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Ghose_Pedestrian_Detection_in_Thermal_Images_Using_Saliency_Maps_CVPRW_2019_paper.html">Pedestrian Detection in Thermal Images Using Saliency Maps</a></th>
                    </tr>
                
                    <tr id="83fffcabf0da94cc42d20fdda6ae7832157def0b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/83fffcabf0da94cc42d20fdda6ae7832157def0b">46</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Weakly_Supervised_Learning_for_RealWorld_Computer_Vision_Applications/Yan_A_Dual_Attention_Network_with_Semantic_Embedding_for_Few-shot_Learning_CVPRW_2019_paper.html">A Dual Attention Network with Semantic Embedding for Few-shot Learning</a></th>
                    </tr>
                
                    <tr id="87f0cffad2d7527273a25a945736c1e813c08312">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/87f0cffad2d7527273a25a945736c1e813c08312">46</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Rustowicz_Semantic_Segmentation_of_Crop_Type_in_Africa_A_Novel_Dataset_CVPRW_2019_paper.html">Semantic Segmentation of Crop Type in Africa: A Novel Dataset and Analysis of Deep Learning Methods</a></th>
                    </tr>
                
                    <tr id="3be65a4b0861ac8e214beeb6e8e445d597e9f13d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3be65a4b0861ac8e214beeb6e8e445d597e9f13d">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Which_Way_Are_You_Going_Imitative_Decision_Learning_for_Path_CVPR_2019_paper.html">Which Way Are You Going? Imitative Decision Learning for Path Forecasting in Dynamic Scenes</a></th>
                    </tr>
                
                    <tr id="e799c5c7e169f471950eb76dbb329c2d031347ae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e799c5c7e169f471950eb76dbb329c2d031347ae">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Tracking_by_Animation_Unsupervised_Learning_of_Multi-Object_Attentive_Trackers_CVPR_2019_paper.html">Tracking by Animation: Unsupervised Learning of Multi-Object Attentive Trackers</a></th>
                    </tr>
                
                    <tr id="fd58ca00535abbeab012c27128c459ad875db95f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fd58ca00535abbeab012c27128c459ad875db95f">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Hybrid-Attention_Based_Decoupled_Metric_Learning_for_Zero-Shot_Image_Retrieval_CVPR_2019_paper.html">Hybrid-Attention Based Decoupled Metric Learning for Zero-Shot Image Retrieval</a></th>
                    </tr>
                
                    <tr id="c52902d07bf0ec989a10e74d0ba404f0f9b8339b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c52902d07bf0ec989a10e74d0ba404f0f9b8339b">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Learning_Instance_Activation_Maps_for_Weakly_Supervised_Instance_Segmentation_CVPR_2019_paper.html">Learning Instance Activation Maps for Weakly Supervised Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="23364d3dfab309ef3af5bcfda9a222029ad22b23">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/23364d3dfab309ef3af5bcfda9a222029ad22b23">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Not_All_Areas_Are_Equal_Transfer_Learning_for_Semantic_Segmentation_CVPR_2019_paper.html">Not All Areas Are Equal: Transfer Learning for Semantic Segmentation via Hierarchical Region Selection</a></th>
                    </tr>
                
                    <tr id="603455714bbafaf30f3e4ed7e2dc81744572a8b4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/603455714bbafaf30f3e4ed7e2dc81744572a8b4">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Du_CrossInfoNet_Multi-Task_Information_Sharing_Based_Hand_Pose_Estimation_CVPR_2019_paper.html">CrossInfoNet: Multi-Task Information Sharing Based Hand Pose Estimation</a></th>
                    </tr>
                
                    <tr id="8e7ba862608d5b735aa2f7f64a8c84ee9049f37f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e7ba862608d5b735aa2f7f64a8c84ee9049f37f">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Manderscheid_Speed_Invariant_Time_Surface_for_Learning_to_Detect_Corner_Points_CVPR_2019_paper.html">Speed Invariant Time Surface for Learning to Detect Corner Points With Event-Based Cameras</a></th>
                    </tr>
                
                    <tr id="4be83c3570280068ab527f008f8f7a4a02f14aaf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4be83c3570280068ab527f008f8f7a4a02f14aaf">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_WarpGAN_Automatic_Caricature_Generation_CVPR_2019_paper.html">WarpGAN: Automatic Caricature Generation</a></th>
                    </tr>
                
                    <tr id="1c636230c5afdc556616f235e54ce8bdf92f8a02">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1c636230c5afdc556616f235e54ce8bdf92f8a02">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Progressive_Ensemble_Networks_for_Zero-Shot_Recognition_CVPR_2019_paper.html">Progressive Ensemble Networks for Zero-Shot Recognition</a></th>
                    </tr>
                
                    <tr id="e500b17e4761c630b684e8144d291cdc972f0a95">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e500b17e4761c630b684e8144d291cdc972f0a95">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Generalizing_Eye_Tracking_With_Bayesian_Adversarial_Learning_CVPR_2019_paper.html">Generalizing Eye Tracking With Bayesian Adversarial Learning</a></th>
                    </tr>
                
                    <tr id="b3fea5973fadc188e208bdf9b7e1325dd7c83e1e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b3fea5973fadc188e208bdf9b7e1325dd7c83e1e">45</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Hu_RUNet_A_Robust_UNet_Architecture_for_Image_Super-Resolution_CVPRW_2019_paper.html">RUNet: A Robust UNet Architecture for Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="e65944c464651c93811c7bd059d4f51d3ab75350">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e65944c464651c93811c7bd059d4f51d3ab75350">45</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Alonso_EV-SegNet_Semantic_Segmentation_for_Event-Based_Cameras_CVPRW_2019_paper.html">EV-SegNet: Semantic Segmentation for Event-Based Cameras</a></th>
                    </tr>
                
                    <tr id="f15683cdc4a226455a4eec0cbe446d5931038790">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f15683cdc4a226455a4eec0cbe446d5931038790">45</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Cheng_Deep_Residual_Learning_for_Image_Compression_CVPRW_2019_paper.html">Deep Residual Learning for Image Compression</a></th>
                    </tr>
                
                    <tr id="be52e0996376f579b770473858b79fa57636f7ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/be52e0996376f579b770473858b79fa57636f7ac">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tsuzuku_On_the_Structural_Sensitivity_of_Deep_Convolutional_Networks_to_the_CVPR_2019_paper.html">On the Structural Sensitivity of Deep Convolutional Networks to the Directions of Fourier Basis Functions</a></th>
                    </tr>
                
                    <tr id="b981faf67f377532a8f4b1c9ce7381351186d548">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b981faf67f377532a8f4b1c9ce7381351186d548">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Im2Pencil_Controllable_Pencil_Illustration_From_Photographs_CVPR_2019_paper.html">Im2Pencil: Controllable Pencil Illustration From Photographs</a></th>
                    </tr>
                
                    <tr id="74d0c10ee5ab57377ebeca6b0c0197485e55c1f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/74d0c10ee5ab57377ebeca6b0c0197485e55c1f2">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Speciale_Privacy_Preserving_Image-Based_Localization_CVPR_2019_paper.html">Privacy Preserving Image-Based Localization</a></th>
                    </tr>
                
                    <tr id="6aa6932c22b9bd407e615ec2bfffc20cd88a9069">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6aa6932c22b9bd407e615ec2bfffc20cd88a9069">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Park_Adversarial_Inference_for_Multi-Sentence_Video_Description_CVPR_2019_paper.html">Adversarial Inference for Multi-Sentence Video Description</a></th>
                    </tr>
                
                    <tr id="1dea6b7e791ac98c342c86d4bd258cddfae84ec2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1dea6b7e791ac98c342c86d4bd258cddfae84ec2">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_PPGNet_Learning_Point-Pair_Graph_for_Line_Segment_Detection_CVPR_2019_paper.html">PPGNet: Learning Point-Pair Graph for Line Segment Detection</a></th>
                    </tr>
                
                    <tr id="c980b52b01251be8a2f681c2413f2c010a8e12e2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c980b52b01251be8a2f681c2413f2c010a8e12e2">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Convolutional_Recurrent_Network_for_Road_Boundary_Extraction_CVPR_2019_paper.html">Convolutional Recurrent Network for Road Boundary Extraction</a></th>
                    </tr>
                
                    <tr id="bb82b908e5e51be68172c0adbcb12833aef378a1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bb82b908e5e51be68172c0adbcb12833aef378a1">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jia_Facial_Emotion_Distribution_Learning_by_Exploiting_Low-Rank_Label_Correlations_Locally_CVPR_2019_paper.html">Facial Emotion Distribution Learning by Exploiting Low-Rank Label Correlations Locally</a></th>
                    </tr>
                
                    <tr id="e5eb953608ab5eb95dd054a44980b5258fd7b8d7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5eb953608ab5eb95dd054a44980b5258fd7b8d7">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Guo_Image-Question-Answer_Synergistic_Network_for_Visual_Dialog_CVPR_2019_paper.html">Image-Question-Answer Synergistic Network for Visual Dialog</a></th>
                    </tr>
                
                    <tr id="19c387d4967b0683a7d4cabccdfe01c8321231a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/19c387d4967b0683a7d4cabccdfe01c8321231a9">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhi_SceneCode_Monocular_Dense_Semantic_Reconstruction_Using_Learned_Encoded_Scene_Representations_CVPR_2019_paper.html">SceneCode: Monocular Dense Semantic Reconstruction Using Learned Encoded Scene Representations</a></th>
                    </tr>
                
                    <tr id="cbf3118faf6d00a2ed3adaba1f58598aef04230d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cbf3118faf6d00a2ed3adaba1f58598aef04230d">44</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Bi_RRU-Net_The_Ringed_Residual_U-Net_for_Image_Splicing_Forgery_Detection_CVPRW_2019_paper.html">RRU-Net: The Ringed Residual U-Net for Image Splicing Forgery Detection</a></th>
                    </tr>
                
                    <tr id="737c44a2b665dea28865f7967eaa1f510a2f7997">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/737c44a2b665dea28865f7967eaa1f510a2f7997">44</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/ISIC/Bisla_Towards_Automated_Melanoma_Detection_With_Deep_Learning_Data_Purification_and_CVPRW_2019_paper.html">Towards Automated Melanoma Detection With Deep Learning: Data Purification and Augmentation</a></th>
                    </tr>
                
                    <tr id="6aa6932c22b9bd407e615ec2bfffc20cd88a9069">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6aa6932c22b9bd407e615ec2bfffc20cd88a9069">44</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MMLV/Park_Adversarial_Inference_for_Multi-Sentence_Video_Description_CVPRW_2019_paper.html">Adversarial Inference for Multi-Sentence Video Description</a></th>
                    </tr>
                
                    <tr id="6bb23143bf430b129aa77bd4d71e09991a3d68af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6bb23143bf430b129aa77bd4d71e09991a3d68af">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xue_Learning_to_Calibrate_Straight_Lines_for_Fisheye_Image_Rectification_CVPR_2019_paper.html">Learning to Calibrate Straight Lines for Fisheye Image Rectification</a></th>
                    </tr>
                
                    <tr id="b8df4e6f5f0eee42766b6c8f670025538fe85668">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b8df4e6f5f0eee42766b6c8f670025538fe85668">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lu_Low-Rank_Tensor_Completion_With_a_New_Tensor_Nuclear_Norm_Induced_CVPR_2019_paper.html">Low-Rank Tensor Completion With a New Tensor Nuclear Norm Induced by Invertible Linear Transforms</a></th>
                    </tr>
                
                    <tr id="7cec763510b951fcf8bb93b508e7a49ec5162875">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7cec763510b951fcf8bb93b508e7a49ec5162875">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jain_Two_Body_Problem_Collaborative_Visual_Task_Completion_CVPR_2019_paper.html">Two Body Problem: Collaborative Visual Task Completion</a></th>
                    </tr>
                
                    <tr id="4ef4bdad7673050b3764e06a26085f9f8ef11e50">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ef4bdad7673050b3764e06a26085f9f8ef11e50">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yan_PA3D_Pose-Action_3D_Machine_for_Video_Recognition_CVPR_2019_paper.html">PA3D: Pose-Action 3D Machine for Video Recognition</a></th>
                    </tr>
                
                    <tr id="117779e1256dc6dcd8e1464976122c8a573221b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/117779e1256dc6dcd8e1464976122c8a573221b1">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Variational_Prototyping-Encoder_One-Shot_Learning_With_Prototypical_Images_CVPR_2019_paper.html">Variational Prototyping-Encoder: One-Shot Learning With Prototypical Images</a></th>
                    </tr>
                
                    <tr id="f00f50a75f3d80c42e2ae7d2e3a55d9e503c7828">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f00f50a75f3d80c42e2ae7d2e3a55d9e503c7828">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yao_Trust_Region_Based_Adversarial_Attack_on_Neural_Networks_CVPR_2019_paper.html">Trust Region Based Adversarial Attack on Neural Networks</a></th>
                    </tr>
                
                    <tr id="c245dbb07a85fb0be8cc9aecb98a223dc48bce63">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c245dbb07a85fb0be8cc9aecb98a223dc48bce63">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Adversarial_Defense_by_Stratified_Convolutional_Sparse_Coding_CVPR_2019_paper.html">Adversarial Defense by Stratified Convolutional Sparse Coding</a></th>
                    </tr>
                
                    <tr id="518512621412fd76d47ef9225a45fcc99d0247d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/518512621412fd76d47ef9225a45fcc99d0247d2">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Song_TACNet_Transition-Aware_Context_Network_for_Spatio-Temporal_Action_Detection_CVPR_2019_paper.html">TACNet: Transition-Aware Context Network for Spatio-Temporal Action Detection</a></th>
                    </tr>
                
                    <tr id="337bec9eb207ac2b52b509bf23428f1d692f1d19">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/337bec9eb207ac2b52b509bf23428f1d692f1d19">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Bianco_Quasi-Unsupervised_Color_Constancy_CVPR_2019_paper.html">Quasi-Unsupervised Color Constancy</a></th>
                    </tr>
                
                    <tr id="df5e045543ebaec443b04e277f2cd6ff0b205347">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/df5e045543ebaec443b04e277f2cd6ff0b205347">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_C3AE_Exploring_the_Limits_of_Compact_Model_for_Age_Estimation_CVPR_2019_paper.html">C3AE: Exploring the Limits of Compact Model for Age Estimation</a></th>
                    </tr>
                
                    <tr id="f8c35bdb5b936c174e3e02ec96dfcb13849dbb02">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f8c35bdb5b936c174e3e02ec96dfcb13849dbb02">43</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/Bailo_Red_Blood_Cell_Image_Generation_for_Data_Augmentation_Using_Conditional_CVPRW_2019_paper.html">Red Blood Cell Image Generation for Data Augmentation Using Conditional Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="063ba2f8f6f1624f42de4e9bee0ac5ae6ce06032">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/063ba2f8f6f1624f42de4e9bee0ac5ae6ce06032">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Aakur_A_Perceptual_Prediction_Framework_for_Self_Supervised_Event_Segmentation_CVPR_2019_paper.html">A Perceptual Prediction Framework for Self Supervised Event Segmentation</a></th>
                    </tr>
                
                    <tr id="05137f5bdc32b339febeb04c7a4dd7ec0ce615ea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05137f5bdc32b339febeb04c7a4dd7ec0ce615ea">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Schuster_SDC_-_Stacked_Dilated_Convolution_A_Unified_Descriptor_Network_for_CVPR_2019_paper.html">SDC - Stacked Dilated Convolution: A Unified Descriptor Network for Dense Matching Tasks</a></th>
                    </tr>
                
                    <tr id="cd927430b9a6a7d858ca0f20076eaba0f43cf538">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd927430b9a6a7d858ca0f20076eaba0f43cf538">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Semantic_Alignment_Finding_Semantically_Consistent_Ground-Truth_for_Facial_Landmark_Detection_CVPR_2019_paper.html">Semantic Alignment: Finding Semantically Consistent Ground-Truth for Facial Landmark Detection</a></th>
                    </tr>
                
                    <tr id="67023a838bb66e73258f064caac7c14ae9666972">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/67023a838bb66e73258f064caac7c14ae9666972">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Leveraging_Crowdsourced_GPS_Data_for_Road_Extraction_From_Aerial_Imagery_CVPR_2019_paper.html">Leveraging Crowdsourced GPS Data for Road Extraction From Aerial Imagery</a></th>
                    </tr>
                
                    <tr id="96f68a831d723dc0d841daa8e5c1f457603140d3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96f68a831d723dc0d841daa8e5c1f457603140d3">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Vo_Unsupervised_Image_Matching_and_Object_Discovery_as_Optimization_CVPR_2019_paper.html">Unsupervised Image Matching and Object Discovery as Optimization</a></th>
                    </tr>
                
                    <tr id="15a2fcac7663cb1005b497cb68266608c04b8f25">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15a2fcac7663cb1005b497cb68266608c04b8f25">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Agustsson_Interactive_Full_Image_Segmentation_by_Considering_All_Regions_Jointly_CVPR_2019_paper.html">Interactive Full Image Segmentation by Considering All Regions Jointly</a></th>
                    </tr>
                
                    <tr id="6a133eb625cee083db848cc2f51a5cb54e28f67e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a133eb625cee083db848cc2f51a5cb54e28f67e">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Noise-Tolerant_Paradigm_for_Training_Face_Recognition_CNNs_CVPR_2019_paper.html">Noise-Tolerant Paradigm for Training Face Recognition CNNs</a></th>
                    </tr>
                
                    <tr id="149328470c9a66b9cc6f7f4f4072e99267d28e6b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/149328470c9a66b9cc6f7f4f4072e99267d28e6b">42</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Wang_Privacy-Preserving_Action_Recognition_Using_Coded_Aperture_Videos_CVPRW_2019_paper.html">Privacy-Preserving Action Recognition Using Coded Aperture Videos</a></th>
                    </tr>
                
                    <tr id="581b496cb9f561e5e27d57b41866f64ad35de98d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/581b496cb9f561e5e27d57b41866f64ad35de98d">42</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BEFA/S_Characterizing_the_Variability_in_Face_Recognition_Accuracy_Relative_to_Race_CVPRW_2019_paper.html">Characterizing the Variability in Face Recognition Accuracy Relative to Race</a></th>
                    </tr>
                
                    <tr id="0bc2ef61f1e0d4e8004518c1cadbfc056d33b73c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0bc2ef61f1e0d4e8004518c1cadbfc056d33b73c">42</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/Ghoddoosian_A_Realistic_Dataset_and_Baseline_Temporal_Model_for_Early_Drowsiness_CVPRW_2019_paper.html">A Realistic Dataset and Baseline Temporal Model for Early Drowsiness Detection</a></th>
                    </tr>
                
                    <tr id="c8c422850207355cfd4433d7b4f95cfee3d3525e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c8c422850207355cfd4433d7b4f95cfee3d3525e">42</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CFS/Perez-Cabo_Deep_Anomaly_Detection_for_Generalized_Face_Anti-Spoofing_CVPRW_2019_paper.html">Deep Anomaly Detection for Generalized Face Anti-Spoofing</a></th>
                    </tr>
                
                    <tr id="c1dcea2a38a00ae6f51aea72f0be4acd65125ccc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c1dcea2a38a00ae6f51aea72f0be4acd65125ccc">42</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CFS/Parkin_Recognizing_Multi-Modal_Face_Spoofing_With_Face_Recognition_Networks_CVPRW_2019_paper.html">Recognizing Multi-Modal Face Spoofing With Face Recognition Networks</a></th>
                    </tr>
                
                    <tr id="d89c0f3a3b8ed29bdfc69083e61af18cee97e1e0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d89c0f3a3b8ed29bdfc69083e61af18cee97e1e0">42</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SUMO/Yang_Learning_Single-View_3D_Reconstruction_with_Limited_Pose_Supervision_CVPRW_2019_paper.html">Learning Single-View 3D Reconstruction with Limited Pose Supervision</a></th>
                    </tr>
                
                    <tr id="3f87e03fb0bff375493ba7d146beff1b58136633">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f87e03fb0bff375493ba7d146beff1b58136633">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pal_Zero-Shot_Task_Transfer_CVPR_2019_paper.html">Zero-Shot Task Transfer</a></th>
                    </tr>
                
                    <tr id="b03c510f8e05833fbce212d95158f105dc9f79fd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b03c510f8e05833fbce212d95158f105dc9f79fd">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kossaifi_T-Net_Parametrizing_Fully_Convolutional_Nets_With_a_Single_High-Order_Tensor_CVPR_2019_paper.html">T-Net: Parametrizing Fully Convolutional Nets With a Single High-Order Tensor</a></th>
                    </tr>
                
                    <tr id="1df8ec46b56bf26eb6fc7e213f51f09bf9ffba2a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1df8ec46b56bf26eb6fc7e213f51f09bf9ffba2a">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yan_Holistic_and_Comprehensive_Annotation_of_Clinically_Significant_Findings_on_Diverse_CVPR_2019_paper.html">Holistic and Comprehensive Annotation of Clinically Significant Findings on Diverse CT Images: Learning From Radiology Reports and Label Ontology</a></th>
                    </tr>
                
                    <tr id="f22b814e1107c2ca9a1fb3fdf220b1afce025a59">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f22b814e1107c2ca9a1fb3fdf220b1afce025a59">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Estimating_3D_Motion_and_Forces_of_Person-Object_Interactions_From_Monocular_CVPR_2019_paper.html">Estimating 3D Motion and Forces of Person-Object Interactions From Monocular Video</a></th>
                    </tr>
                
                    <tr id="2bf9aa0efed242697efcc8e475eba5c00fc2c5ee">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2bf9aa0efed242697efcc8e475eba5c00fc2c5ee">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Meng_SIGNet_Semantic_Instance_Aided_Unsupervised_3D_Geometry_Perception_CVPR_2019_paper.html">SIGNet: Semantic Instance Aided Unsupervised 3D Geometry Perception</a></th>
                    </tr>
                
                    <tr id="016f69185ef561d7dfadd2be9901957d55864bb7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/016f69185ef561d7dfadd2be9901957d55864bb7">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cao_SeerNet_Predicting_Convolutional_Neural_Network_Feature-Map_Sparsity_Through_Low-Bit_Quantization_CVPR_2019_paper.html">SeerNet: Predicting Convolutional Neural Network Feature-Map Sparsity Through Low-Bit Quantization</a></th>
                    </tr>
                
                    <tr id="29c53d37cb9bec0210e1584493479df13be85d90">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/29c53d37cb9bec0210e1584493479df13be85d90">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jenni_On_Stabilizing_Generative_Adversarial_Training_With_Noise_CVPR_2019_paper.html">On Stabilizing Generative Adversarial Training With Noise</a></th>
                    </tr>
                
                    <tr id="b4702bad26563a4e1d03b33c0af0b29b095438bc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b4702bad26563a4e1d03b33c0af0b29b095438bc">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Akbari_Multi-Level_Multimodal_Common_Semantic_Space_for_Image-Phrase_Grounding_CVPR_2019_paper.html">Multi-Level Multimodal Common Semantic Space for Image-Phrase Grounding</a></th>
                    </tr>
                
                    <tr id="92650fcd4c288934e7b08c18a86c5cb63f5ce1ae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/92650fcd4c288934e7b08c18a86c5cb63f5ce1ae">41</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MULA/Liao_Natural_Language_Guided_Visual_Relationship_Detection_CVPRW_2019_paper.html">Natural Language Guided Visual Relationship Detection</a></th>
                    </tr>
                
                    <tr id="155d0b8d92ab01508b774b7623b9c0cb04af37c6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/155d0b8d92ab01508b774b7623b9c0cb04af37c6">41</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Chen_Sports_Camera_Calibration_via_Synthetic_Data_CVPRW_2019_paper.html">Sports Camera Calibration via Synthetic Data</a></th>
                    </tr>
                
                    <tr id="4e96e55c4581890dd1c8d9edc0318cb483412a36">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4e96e55c4581890dd1c8d9edc0318cb483412a36">41</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Ma_Efficient_Super_Resolution_Using_Binarized_Neural_Network_CVPRW_2019_paper.html">Efficient Super Resolution Using Binarized Neural Network</a></th>
                    </tr>
                
                    <tr id="fff0749f0c8aa33241098e3c70d70117abed9c2f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fff0749f0c8aa33241098e3c70d70117abed9c2f">41</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Dogan_Exemplar_Guided_Face_Image_Super-Resolution_Without_Facial_Landmarks_CVPRW_2019_paper.html">Exemplar Guided Face Image Super-Resolution Without Facial Landmarks</a></th>
                    </tr>
                
                    <tr id="508dad538d5c63eb6c07fd10794510357a951a58">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/508dad538d5c63eb6c07fd10794510357a951a58">41</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Ding_On_the_Sensitivity_of_Adversarial_Robustness_to_Input_Data_Distributions_CVPRW_2019_paper.html">On the Sensitivity of Adversarial Robustness to Input Data Distributions</a></th>
                    </tr>
                
                    <tr id="c7a46e8d2fe489a5d49d116a35c078c59eb2a4aa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c7a46e8d2fe489a5d49d116a35c078c59eb2a4aa">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_LAF-Net_Locally_Adaptive_Fusion_Networks_for_Stereo_Confidence_Estimation_CVPR_2019_paper.html">LAF-Net: Locally Adaptive Fusion Networks for Stereo Confidence Estimation</a></th>
                    </tr>
                
                    <tr id="e973b927ec80a6d7db9835a7378c7c9d25fd35e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e973b927ec80a6d7db9835a7378c7c9d25fd35e3">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dogan_Neural_Sequential_Phrase_Grounding_SeqGROUND_CVPR_2019_paper.html">Neural Sequential Phrase Grounding (SeqGROUND)</a></th>
                    </tr>
                
                    <tr id="372cdb015ebf54c446ec241eb3a18bc792569638">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/372cdb015ebf54c446ec241eb3a18bc792569638">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Klein_End-To-End_Supervised_Product_Quantization_for_Image_Search_and_Retrieval_CVPR_2019_paper.html">End-To-End Supervised Product Quantization for Image Search and Retrieval</a></th>
                    </tr>
                
                    <tr id="ee10f85ad22085cc389e844a4b7b05f3489f038f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ee10f85ad22085cc389e844a4b7b05f3489f038f">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ding_DeepMapping_Unsupervised_Map_Estimation_From_Multiple_Point_Clouds_CVPR_2019_paper.html">DeepMapping: Unsupervised Map Estimation From Multiple Point Clouds</a></th>
                    </tr>
                
                    <tr id="3ff81c3342922250a650e6919bb8fde9a6d7ba5a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ff81c3342922250a650e6919bb8fde9a6d7ba5a">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ben-Shabat_Nesti-Net_Normal_Estimation_for_Unstructured_3D_Point_Clouds_Using_Convolutional_CVPR_2019_paper.html">Nesti-Net: Normal Estimation for Unstructured 3D Point Clouds Using Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="07b87430053e1ada8aff0a1a40f038f4bc5fed5b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/07b87430053e1ada8aff0a1a40f038f4bc5fed5b">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_All-Weather_Deep_Outdoor_Lighting_Estimation_CVPR_2019_paper.html">All-Weather Deep Outdoor Lighting Estimation</a></th>
                    </tr>
                
                    <tr id="2188bdd251a557952c254a7653f9893a0a1201e2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2188bdd251a557952c254a7653f9893a0a1201e2">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Simeoni_Local_Features_and_Visual_Words_Emerge_in_Activations_CVPR_2019_paper.html">Local Features and Visual Words Emerge in Activations</a></th>
                    </tr>
                
                    <tr id="697dd316d0b99ba1e108a102ce57fbea1ca8eda8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/697dd316d0b99ba1e108a102ce57fbea1ca8eda8">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhong_Unsupervised_Deep_Epipolar_Flow_for_Stationary_or_Dynamic_Scenes_CVPR_2019_paper.html">Unsupervised Deep Epipolar Flow for Stationary or Dynamic Scenes</a></th>
                    </tr>
                
                    <tr id="61a10f6a771f65294f6847d670b10fe3b5725c20">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61a10f6a771f65294f6847d670b10fe3b5725c20">40</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/ISIC/Bissoto_DeConstructing_Bias_on_Skin_Lesion_Datasets_CVPRW_2019_paper.html">(De)Constructing Bias on Skin Lesion Datasets</a></th>
                    </tr>
                
                    <tr id="d8895e0c195cca82cbd7a91d69ba3886c1a86237">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d8895e0c195cca82cbd7a91d69ba3886c1a86237">40</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Nguyen_Real-Time_6DOF_Pose_Relocalization_for_Event_Cameras_With_Stacked_Spatial_CVPRW_2019_paper.html">Real-Time 6DOF Pose Relocalization for Event Cameras With Stacked Spatial LSTM Networks</a></th>
                    </tr>
                
                    <tr id="182df380eb4cba1e1b324cbef4ad177433d00ac1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/182df380eb4cba1e1b324cbef4ad177433d00ac1">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_ELASTIC_Improving_CNNs_With_Dynamic_Scaling_Policies_CVPR_2019_paper.html">ELASTIC: Improving CNNs With Dynamic Scaling Policies</a></th>
                    </tr>
                
                    <tr id="bd79f8b2f19fd510faed4554b3d428ea10bb45fe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bd79f8b2f19fd510faed4554b3d428ea10bb45fe">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yuan_Signal-To-Noise_Ratio_A_Robust_Distance_Metric_for_Deep_Metric_Learning_CVPR_2019_paper.html">Signal-To-Noise Ratio: A Robust Distance Metric for Deep Metric Learning</a></th>
                    </tr>
                
                    <tr id="b31a47d40bf648e0a281dfe5a0cb6555f5ea2b20">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b31a47d40bf648e0a281dfe5a0cb6555f5ea2b20">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Phase-Only_Image_Based_Kernel_Estimation_for_Single_Image_Blind_Deblurring_CVPR_2019_paper.html">Phase-Only Image Based Kernel Estimation for Single Image Blind Deblurring</a></th>
                    </tr>
                
                    <tr id="0c677047026f4f89ee934821da9d880a52cfcba8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c677047026f4f89ee934821da9d880a52cfcba8">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Do_A_Theoretically_Sound_Upper_Bound_on_the_Triplet_Loss_for_CVPR_2019_paper.html">A Theoretically Sound Upper Bound on the Triplet Loss for Improving the Efficiency of Deep Distance Metric Learning</a></th>
                    </tr>
                
                    <tr id="37eaca9f4319c0f20ca9ccadf2389d1fed0cf772">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/37eaca9f4319c0f20ca9ccadf2389d1fed0cf772">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Prakash_RePr_Improved_Training_of_Convolutional_Filters_CVPR_2019_paper.html">RePr: Improved Training of Convolutional Filters</a></th>
                    </tr>
                
                    <tr id="e9e01af30f1507555008f4b0a1b83ea2debe6f19">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e9e01af30f1507555008f4b0a1b83ea2debe6f19">39</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MULA/Zou_WiFi_and_Vision_Multimodal_Learning_for_Accurate_and_Robust_Device-Free_CVPRW_2019_paper.html">WiFi and Vision Multimodal Learning for Accurate and Robust Device-Free Human Activity Recognition</a></th>
                    </tr>
                
                    <tr id="260766d21a66dcfb1cef6abc5c57565139cd604e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/260766d21a66dcfb1cef6abc5c57565139cd604e">39</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BIC/Laibacher_M2U-Net_Effective_and_Efficient_Retinal_Vessel_Segmentation_for_Real-World_Applications_CVPRW_2019_paper.html">M2U-Net: Effective and Efficient Retinal Vessel Segmentation for Real-World Applications</a></th>
                    </tr>
                
                    <tr id="16b9f05d8a0c7bbeb14e9b1583a0e20e29af245c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16b9f05d8a0c7bbeb14e9b1583a0e20e29af245c">39</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/ISIC/Perez_Solo_or_Ensemble_Choosing_a_CNN_Architecture_for_Melanoma_Classification_CVPRW_2019_paper.html">Solo or Ensemble? Choosing a CNN Architecture for Melanoma Classification</a></th>
                    </tr>
                
                    <tr id="aed99738a2ad6d99bad710bdf4938de3403221be">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aed99738a2ad6d99bad710bdf4938de3403221be">39</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Sight_and_Sound/Konstantinos_Vougioukas_End-to-End_Speech-Driven_Realistic_Facial_Animation_with_Temporal_GANs_CVPRW_2019_paper.html">End-to-End Speech-Driven Realistic Facial Animation with Temporal GANs</a></th>
                    </tr>
                
                    <tr id="239e548129d8db958bc0f74e7b7c9c4ffc1cecef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/239e548129d8db958bc0f74e7b7c9c4ffc1cecef">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Punnappurath_Reflection_Removal_Using_a_Dual-Pixel_Sensor_CVPR_2019_paper.html">Reflection Removal Using a Dual-Pixel Sensor</a></th>
                    </tr>
                
                    <tr id="11ea3caa073bda645e1b31f620275aeecbe134ee">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/11ea3caa073bda645e1b31f620275aeecbe134ee">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Learning_Joint_Gait_Representation_via_Quintuplet_Loss_Minimization_CVPR_2019_paper.html">Learning Joint Gait Representation via Quintuplet Loss Minimization</a></th>
                    </tr>
                
                    <tr id="865c0bcd4868e142881e33da150f2d87b55d9237">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/865c0bcd4868e142881e33da150f2d87b55d9237">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Duan_Deep_Embedding_Learning_With_Discriminative_Sampling_Policy_CVPR_2019_paper.html">Deep Embedding Learning With Discriminative Sampling Policy</a></th>
                    </tr>
                
                    <tr id="8d55cc06599e33ce729301b8f59bf109bd5abfde">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8d55cc06599e33ce729301b8f59bf109bd5abfde">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Multi-Task_Self-Supervised_Object_Detection_via_Recycling_of_Bounding_Box_Annotations_CVPR_2019_paper.html">Multi-Task Self-Supervised Object Detection via Recycling of Bounding Box Annotations</a></th>
                    </tr>
                
                    <tr id="349e3e2f912c284c65e52f03728477fa129dbefc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/349e3e2f912c284c65e52f03728477fa129dbefc">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Oh_Fast_User-Guided_Video_Object_Segmentation_by_Interaction-And-Propagation_Networks_CVPR_2019_paper.html">Fast User-Guided Video Object Segmentation by Interaction-And-Propagation Networks</a></th>
                    </tr>
                
                    <tr id="84d3064593ded6838300adc366e485fa54839d3f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/84d3064593ded6838300adc366e485fa54839d3f">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kotovenko_A_Content_Transformation_Block_for_Image_Style_Transfer_CVPR_2019_paper.html">A Content Transformation Block for Image Style Transfer</a></th>
                    </tr>
                
                    <tr id="8d8ff98a5740febb0e03972b7ff6686171f46557">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8d8ff98a5740febb0e03972b7ff6686171f46557">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Viewport_Proposal_CNN_for_360deg_Video_Quality_Assessment_CVPR_2019_paper.html">Viewport Proposal CNN for 360° Video Quality Assessment</a></th>
                    </tr>
                
                    <tr id="d7009c9216beba44f0fb7fb3a4e6c8c89b367b44">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d7009c9216beba44f0fb7fb3a4e6c8c89b367b44">38</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/FFSS-USAD/Zou_FashionAI_A_Hierarchical_Dataset_for_Fashion_Understanding_CVPRW_2019_paper.html">FashionAI: A Hierarchical Dataset for Fashion Understanding</a></th>
                    </tr>
                
                    <tr id="98e42b4c6611a775818bb4747d890350bd07887e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/98e42b4c6611a775818bb4747d890350bd07887e">38</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Chen_Partition_and_Reunion_A_Two-Branch_Neural_Network_for_Vehicle_Re-identification_CVPRW_2019_paper.html">Partition and Reunion: A Two-Branch Neural Network for Vehicle Re-identification</a></th>
                    </tr>
                
                    <tr id="972c5e77a3352b28ac877467937c8a7f5fdd0910">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/972c5e77a3352b28ac877467937c8a7f5fdd0910">38</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Huang_Multi-View_Vehicle_Re-Identification_using_Temporal_Attention_Model_and_Metadata_Re-ranking_CVPRW_2019_paper.html">Multi-View Vehicle Re-Identification using Temporal Attention Model and Metadata Re-ranking</a></th>
                    </tr>
                
                    <tr id="51b415663b39058af33b602c26b4d7ec0e98cf58">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/51b415663b39058af33b602c26b4d7ec0e98cf58">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Marginalized_Latent_Semantic_Encoder_for_Zero-Shot_Learning_CVPR_2019_paper.html">Marginalized Latent Semantic Encoder for Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="f4c90b4a685ea0ffd19ca7a9ef6e9dd913a327ec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f4c90b4a685ea0ffd19ca7a9ef6e9dd913a327ec">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fu_Hyperspectral_Image_Super-Resolution_With_Optimized_RGB_Guidance_CVPR_2019_paper.html">Hyperspectral Image Super-Resolution With Optimized RGB Guidance</a></th>
                    </tr>
                
                    <tr id="3898b0ab3da9b1c1eee31e639f67e98fcd264f61">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3898b0ab3da9b1c1eee31e639f67e98fcd264f61">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lopez_Deep_Single_Image_Camera_Calibration_With_Radial_Distortion_CVPR_2019_paper.html">Deep Single Image Camera Calibration With Radial Distortion</a></th>
                    </tr>
                
                    <tr id="3fdac1028bae028e1185b10f4264980a3f78d391">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3fdac1028bae028e1185b10f4264980a3f78d391">37</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Chen_Attention-Based_Hierarchical_Deep_Reinforcement_Learning_for_Lane_Change_Behaviors_in_CVPRW_2019_paper.html">Attention-Based Hierarchical Deep Reinforcement Learning for Lane Change Behaviors in Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="19d3163950be1b44d44da24c20cad466cec32d0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/19d3163950be1b44d44da24c20cad466cec32d0c">37</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Liu_Learning_Raw_Image_Denoising_With_Bayer_Pattern_Unification_and_Bayer_CVPRW_2019_paper.html">Learning Raw Image Denoising With Bayer Pattern Unification and Bayer Preserving Augmentation</a></th>
                    </tr>
                
                    <tr id="3fdac1028bae028e1185b10f4264980a3f78d391">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3fdac1028bae028e1185b10f4264980a3f78d391">37</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Chen_Attention-Based_Hierarchical_Deep_Reinforcement_Learning_for_Lane_Change_Behaviors_in_CVPRW_2019_paper.html">Attention-Based Hierarchical Deep Reinforcement Learning for Lane Change Behaviors in Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="8dae3a013d83a99e407313be2c9b7c3529cd2440">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8dae3a013d83a99e407313be2c9b7c3529cd2440">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Alayrac_The_Visual_Centrifuge_Model-Free_Layered_Video_Representations_CVPR_2019_paper.html">The Visual Centrifuge: Model-Free Layered Video Representations</a></th>
                    </tr>
                
                    <tr id="89583143a04d7f02a45e0831a4fc55eaf090573c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/89583143a04d7f02a45e0831a4fc55eaf090573c">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mehrasa_A_Variational_Auto-Encoder_Model_for_Stochastic_Point_Processes_CVPR_2019_paper.html">A Variational Auto-Encoder Model for Stochastic Point Processes</a></th>
                    </tr>
                
                    <tr id="1d637b90d6596c152825e92b7f4b89a8d6b2af3b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d637b90d6596c152825e92b7f4b89a8d6b2af3b">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_Deep_Surface_Normal_Estimation_With_Hierarchical_RGB-D_Fusion_CVPR_2019_paper.html">Deep Surface Normal Estimation With Hierarchical RGB-D Fusion</a></th>
                    </tr>
                
                    <tr id="b6b3d6a37e7e77f5d5c763a4abeade256324268c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b6b3d6a37e7e77f5d5c763a4abeade256324268c">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Self-Critical_N-Step_Training_for_Image_Captioning_CVPR_2019_paper.html">Self-Critical N-Step Training for Image Captioning</a></th>
                    </tr>
                
                    <tr id="ffc89876cb1699fa6d9c9d6d6ca144b9b040180c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ffc89876cb1699fa6d9c9d6d6ca144b9b040180c">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cosmo_Isospectralization_or_How_to_Hear_Shape_Style_and_Correspondence_CVPR_2019_paper.html">Isospectralization, or How to Hear Shape, Style, and Correspondence</a></th>
                    </tr>
                
                    <tr id="51dafb7909d690bc34c2979818d1f8a1c4488728">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/51dafb7909d690bc34c2979818d1f8a1c4488728">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_to_Minify_Photometric_Stereo_CVPR_2019_paper.html">Learning to Minify Photometric Stereo</a></th>
                    </tr>
                
                    <tr id="7d52e636de2024f75b43484494ed02a4bbbbe90a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7d52e636de2024f75b43484494ed02a4bbbbe90a">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dansereau_LiFF_Light_Field_Features_in_Scale_and_Depth_CVPR_2019_paper.html">LiFF: Light Field Features in Scale and Depth</a></th>
                    </tr>
                
                    <tr id="dc58092c7029fd6a2b000fb57836f20b8c5161cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dc58092c7029fd6a2b000fb57836f20b8c5161cc">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Enhancing_Diversity_of_Defocus_Blur_Detectors_via_Cross-Ensemble_Network_CVPR_2019_paper.html">Enhancing Diversity of Defocus Blur Detectors via Cross-Ensemble Network</a></th>
                    </tr>
                
                    <tr id="ac359aac85ba5d05c8249bd7dfb5d71aa205db79">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ac359aac85ba5d05c8249bd7dfb5d71aa205db79">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Nguyen_Multi-Task_Learning_of_Hierarchical_Vision-Language_Representation_CVPR_2019_paper.html">Multi-Task Learning of Hierarchical Vision-Language Representation</a></th>
                    </tr>
                
                    <tr id="9d1172b6d42f86b993ecf69113fc756743c233a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9d1172b6d42f86b993ecf69113fc756743c233a2">36</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UAVision/Fan_Real-Time_Dense_Stereo_Embedded_in_a_UAV_for_Road_Inspection_CVPRW_2019_paper.html">Real-Time Dense Stereo Embedded in a UAV for Road Inspection</a></th>
                    </tr>
                
                    <tr id="948a08439aac9e87bef15d18541cec80889f541e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/948a08439aac9e87bef15d18541cec80889f541e">36</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AAMVEM/Pedersen_Detection_of_Marine_Animals_in_a_New_Underwater_Dataset_with_CVPRW_2019_paper.html">Detection of Marine Animals in a New Underwater Dataset with Varying Visibility</a></th>
                    </tr>
                
                    <tr id="b84f2dd6ba857b70dbc329bf0f893be740a86ce7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b84f2dd6ba857b70dbc329bf0f893be740a86ce7">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Feature-Level_Frankenstein_Eliminating_Variations_for_Discriminative_Recognition_CVPR_2019_paper.html">Feature-Level Frankenstein: Eliminating Variations for Discriminative Recognition</a></th>
                    </tr>
                
                    <tr id="51313228846f430e469ba69f7c579b6d0e02b90b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/51313228846f430e469ba69f7c579b6d0e02b90b">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Text_Guided_Person_Image_Synthesis_CVPR_2019_paper.html">Text Guided Person Image Synthesis</a></th>
                    </tr>
                
                    <tr id="efe750702b32fb04d9f5bcfb31d51af1d3d03889">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/efe750702b32fb04d9f5bcfb31d51af1d3d03889">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sekikawa_EventNet_Asynchronous_Recursive_Event_Processing_CVPR_2019_paper.html">EventNet: Asynchronous Recursive Event Processing</a></th>
                    </tr>
                
                    <tr id="c083b54e38c53d91f7fe3cf34f3adb0d1d1f2707">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c083b54e38c53d91f7fe3cf34f3adb0d1d1f2707">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gong_On_the_Intrinsic_Dimensionality_of_Image_Representations_CVPR_2019_paper.html">On the Intrinsic Dimensionality of Image Representations</a></th>
                    </tr>
                
                    <tr id="792e107c92ce0e1a1718038920cb95d9e9f91116">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/792e107c92ce0e1a1718038920cb95d9e9f91116">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Sensitive-Sample_Fingerprinting_of_Deep_Neural_Networks_CVPR_2019_paper.html">Sensitive-Sample Fingerprinting of Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="79ca601c150eb576fccc87881d07332471b32be3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/79ca601c150eb576fccc87881d07332471b32be3">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Fully_Learnable_Group_Convolution_for_Acceleration_of_Deep_Neural_Networks_CVPR_2019_paper.html">Fully Learnable Group Convolution for Acceleration of Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="baceb4b90524cb980ae79d25f2b287f0f53c3c9f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/baceb4b90524cb980ae79d25f2b287f0f53c3c9f">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liao_Spherical_Regression_Learning_Viewpoints_Surface_Normals_and_3D_Rotations_on_CVPR_2019_paper.html">Spherical Regression: Learning Viewpoints, Surface Normals and 3D Rotations on N-Spheres</a></th>
                    </tr>
                
                    <tr id="38410376deedfdfc32e53b7369b9ea2297fa521f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38410376deedfdfc32e53b7369b9ea2297fa521f">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_Understanding_and_Visualizing_Deep_Visual_Saliency_Models_CVPR_2019_paper.html">Understanding and Visualizing Deep Visual Saliency Models</a></th>
                    </tr>
                
                    <tr id="fe876bdd10cdcb347348e5b8418b1e67736e342c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fe876bdd10cdcb347348e5b8418b1e67736e342c">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lu_Learning_Binary_Code_for_Personalized_Fashion_Recommendation_CVPR_2019_paper.html">Learning Binary Code for Personalized Fashion Recommendation</a></th>
                    </tr>
                
                    <tr id="2ecce887c3da0c312d429b64d7de4b5e2ac8f90e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ecce887c3da0c312d429b64d7de4b5e2ac8f90e">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_PMS-Net_Robust_Haze_Removal_Based_on_Patch_Map_for_Single_CVPR_2019_paper.html">PMS-Net: Robust Haze Removal Based on Patch Map for Single Images</a></th>
                    </tr>
                
                    <tr id="b286bd248a25a21433ff1be716a9f26b86b19eed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b286bd248a25a21433ff1be716a9f26b86b19eed">35</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BEFA/Srinivas_Face_Recognition_Algorithm_Bias_Performance_Differences_on_Images_of_Children_CVPRW_2019_paper.html">Face Recognition Algorithm Bias: Performance Differences on Images of Children and Adults</a></th>
                    </tr>
                
                    <tr id="cd33d97fb6b7b4b8786ce959345874cb030e3149">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd33d97fb6b7b4b8786ce959345874cb030e3149">35</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/ISIC/Jaworek-Korjakowska_Melanoma_Thickness_Prediction_Based_on_Convolutional_Neural_Network_With_VGG-19_CVPRW_2019_paper.html">Melanoma Thickness Prediction Based on Convolutional Neural Network With VGG-19 Model Transfer Learning</a></th>
                    </tr>
                
                    <tr id="cd9644acc07aeb9ecf7f8189686374ecfddf3086">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd9644acc07aeb9ecf7f8189686374ecfddf3086">35</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Dudhane_RI-GAN_An_End-To-End_Network_for_Single_Image_Haze_Removal_CVPRW_2019_paper.html">RI-GAN: An End-To-End Network for Single Image Haze Removal</a></th>
                    </tr>
                
                    <tr id="7060003d09260c0522fbab47b8757ff3ca1c1873">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7060003d09260c0522fbab47b8757ff3ca1c1873">35</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CFS/Zhang_FeatherNets_Convolutional_Neural_Networks_as_Light_as_Feather_for_Face_CVPRW_2019_paper.html">FeatherNets: Convolutional Neural Networks as Light as Feather for Face Anti-Spoofing</a></th>
                    </tr>
                
                    <tr id="4ac538efe3d310bd6ca379a9a4db54833f54d42a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ac538efe3d310bd6ca379a9a4db54833f54d42a">35</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Tan_Multi-camera_vehicle_tracking_and_re-identification_based_on_visual_and_spatial-temporal_CVPRW_2019_paper.html">Multi-camera vehicle tracking and re-identification based on visual and spatial-temporal features</a></th>
                    </tr>
                
                    <tr id="17a51f44b43098f629f80f9481fb1875ccc1604e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/17a51f44b43098f629f80f9481fb1875ccc1604e">35</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Volpi_Model_Vulnerability_to_Distributional_Shifts_over_Image_Transformation_Sets_CVPRW_2019_paper.html">Model Vulnerability to Distributional Shifts over Image Transformation Sets</a></th>
                    </tr>
                
                    <tr id="44b891ea586e84b52d6b4aca7411f7237a3fe26e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/44b891ea586e84b52d6b4aca7411f7237a3fe26e">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhan_Self-Supervised_Learning_via_Conditional_Motion_Propagation_CVPR_2019_paper.html">Self-Supervised Learning via Conditional Motion Propagation</a></th>
                    </tr>
                
                    <tr id="c61649e63d89e590a238f3b6a73bd0daab64e10e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c61649e63d89e590a238f3b6a73bd0daab64e10e">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Context-Reinforced_Semantic_Segmentation_CVPR_2019_paper.html">Context-Reinforced Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="0d6e863518d284348fafcf0c9c22d464d5ab7a5e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0d6e863518d284348fafcf0c9c22d464d5ab7a5e">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lv_Taking_a_Deeper_Look_at_the_Inverse_Compositional_Algorithm_CVPR_2019_paper.html">Taking a Deeper Look at the Inverse Compositional Algorithm</a></th>
                    </tr>
                
                    <tr id="e35ffd775fd4431c99b93153abd9104c0a79a886">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e35ffd775fd4431c99b93153abd9104c0a79a886">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_SketchGAN_Joint_Sketch_Completion_and_Recognition_With_Generative_Adversarial_Network_CVPR_2019_paper.html">SketchGAN: Joint Sketch Completion and Recognition With Generative Adversarial Network</a></th>
                    </tr>
                
                    <tr id="0ac7fe3a033baa5062ebffee94a3054f3b9d6592">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ac7fe3a033baa5062ebffee94a3054f3b9d6592">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_Noise-Aware_Unsupervised_Deep_Lidar-Stereo_Fusion_CVPR_2019_paper.html">Noise-Aware Unsupervised Deep Lidar-Stereo Fusion</a></th>
                    </tr>
                
                    <tr id="7e094ee2be0e5ad3599566390217aa654097dc8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e094ee2be0e5ad3599566390217aa654097dc8f">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Learning_Transformation_Synchronization_CVPR_2019_paper.html">Learning Transformation Synchronization</a></th>
                    </tr>
                
                    <tr id="9e9e9da2cd3f4946570d19891a108a02b93611ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9e9e9da2cd3f4946570d19891a108a02b93611ad">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jin_Learning_to_Extract_Flawless_Slow_Motion_From_Blurry_Videos_CVPR_2019_paper.html">Learning to Extract Flawless Slow Motion From Blurry Videos</a></th>
                    </tr>
                
                    <tr id="a19241f718c76e15d36741d153a1a098069fb54b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a19241f718c76e15d36741d153a1a098069fb54b">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Deep_ChArUco_Dark_ChArUco_Marker_Pose_Estimation_CVPR_2019_paper.html">Deep ChArUco: Dark ChArUco Marker Pose Estimation</a></th>
                    </tr>
                
                    <tr id="9ee16987849ddc5ff661d1648325e03fa9b1e1d3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9ee16987849ddc5ff661d1648325e03fa9b1e1d3">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhussip_Training_Deep_Learning_Based_Image_Denoisers_From_Undersampled_Measurements_Without_CVPR_2019_paper.html">Training Deep Learning Based Image Denoisers From Undersampled Measurements Without Ground Truth and Without Image Prior</a></th>
                    </tr>
                
                    <tr id="6e0d8e47c76cc1f7c28908a1e4b8e01288f0d445">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6e0d8e47c76cc1f7c28908a1e4b8e01288f0d445">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Su_Unsupervised_Multi-Modal_Neural_Machine_Translation_CVPR_2019_paper.html">Unsupervised Multi-Modal Neural Machine Translation</a></th>
                    </tr>
                
                    <tr id="b57e695304e3d9cda4199eb9251e5091cdf8f522">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b57e695304e3d9cda4199eb9251e5091cdf8f522">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_QATM_Quality-Aware_Template_Matching_for_Deep_Learning_CVPR_2019_paper.html">QATM: Quality-Aware Template Matching for Deep Learning</a></th>
                    </tr>
                
                    <tr id="849679f4f79ed03e062e183f6aeee23916ea4019">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/849679f4f79ed03e062e183f6aeee23916ea4019">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Texture_Mixer_A_Network_for_Controllable_Synthesis_and_Interpolation_of_CVPR_2019_paper.html">Texture Mixer: A Network for Controllable Synthesis and Interpolation of Texture</a></th>
                    </tr>
                
                    <tr id="381c97b90d5c8ba40c38811a0b8a6c869ad3e36f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/381c97b90d5c8ba40c38811a0b8a6c869ad3e36f">34</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Scheerlinck_CED_Color_Event_Camera_Dataset_CVPRW_2019_paper.html">CED: Color Event Camera Dataset</a></th>
                    </tr>
                
                    <tr id="b5b36afbb1f97a21e8580d20b0acf07a57162bc7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b5b36afbb1f97a21e8580d20b0acf07a57162bc7">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Han_Deep_Reinforcement_Learning_of_Volume-Guided_Progressive_View_Inpainting_for_3D_CVPR_2019_paper.html">Deep Reinforcement Learning of Volume-Guided Progressive View Inpainting for 3D Point Scene Completion From a Single Depth Image</a></th>
                    </tr>
                
                    <tr id="c19659297ac67a29d7524fba60062558f2235f8a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c19659297ac67a29d7524fba60062558f2235f8a">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Feng_Spatio-Temporal_Video_Re-Localization_by_Warp_LSTM_CVPR_2019_paper.html">Spatio-Temporal Video Re-Localization by Warp LSTM</a></th>
                    </tr>
                
                    <tr id="f7456ccc664e3918c7f9f28c45edd497ce195bd8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7456ccc664e3918c7f9f28c45edd497ce195bd8">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Unsupervised_Visual_Domain_Adaptation_A_Deep_Max-Margin_Gaussian_Process_Approach_CVPR_2019_paper.html">Unsupervised Visual Domain Adaptation: A Deep Max-Margin Gaussian Process Approach</a></th>
                    </tr>
                
                    <tr id="661f5c55d8d210e798abfd8ed1a640435f2a455d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/661f5c55d8d210e798abfd8ed1a640435f2a455d">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Reasoning-RCNN_Unifying_Adaptive_Global_Reasoning_Into_Large-Scale_Object_Detection_CVPR_2019_paper.html">Reasoning-RCNN: Unifying Adaptive Global Reasoning Into Large-Scale Object Detection</a></th>
                    </tr>
                
                    <tr id="f2ae99b9253b4663176b7d7dc2897ec8923fd751">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f2ae99b9253b4663176b7d7dc2897ec8923fd751">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Steady-State_Non-Line-Of-Sight_Imaging_CVPR_2019_paper.html">Steady-State Non-Line-Of-Sight Imaging</a></th>
                    </tr>
                
                    <tr id="8f6f20c48a9e99fac227cb58570f6285cab8b730">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f6f20c48a9e99fac227cb58570f6285cab8b730">33</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MULA/Zhao_A_Large-Scale_Attribute_Dataset_for_Zero-Shot_Learning_CVPRW_2019_paper.html">A Large-Scale Attribute Dataset for Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="5cf1ef66977acd38c260da77b747c6aea2367201">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5cf1ef66977acd38c260da77b747c6aea2367201">33</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UAVision/Kyrkou_Deep-Learning-Based_Aerial_Image_Classification_for_Emergency_Response_Applications_Using_Unmanned_CVPRW_2019_paper.html">Deep-Learning-Based Aerial Image Classification for Emergency Response Applications Using Unmanned Aerial Vehicles</a></th>
                    </tr>
                
                    <tr id="eaff90799e71e3f1a03c4ace4af8864ada9b2693">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eaff90799e71e3f1a03c4ace4af8864ada9b2693">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Vongkulbhisal_Unifying_Heterogeneous_Classifiers_With_Distillation_CVPR_2019_paper.html">Unifying Heterogeneous Classifiers With Distillation</a></th>
                    </tr>
                
                    <tr id="81336b3474553bfc861d3c724f79ce52b579a5e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/81336b3474553bfc861d3c724f79ce52b579a5e3">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qiu_Adversarial_Defense_Through_Network_Profiling_Based_Path_Extraction_CVPR_2019_paper.html">Adversarial Defense Through Network Profiling Based Path Extraction</a></th>
                    </tr>
                
                    <tr id="24ffb2a7da600321a82be5f8be25dbde6ae0d3a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/24ffb2a7da600321a82be5f8be25dbde6ae0d3a2">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zeng_Reliable_and_Efficient_Image_Cropping_A_Grid_Anchor_Based_Approach_CVPR_2019_paper.html">Reliable and Efficient Image Cropping: A Grid Anchor Based Approach</a></th>
                    </tr>
                
                    <tr id="9c0ef3ad676e767e10852168c83e88efb1647a8b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c0ef3ad676e767e10852168c83e88efb1647a8b">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_OICSR_Out-In-Channel_Sparsity_Regularization_for_Compact_Deep_Neural_Networks_CVPR_2019_paper.html">OICSR: Out-In-Channel Sparsity Regularization for Compact Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="e7cdfcf3fd4fa5a8b019a0eaa5fc01888038d578">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e7cdfcf3fd4fa5a8b019a0eaa5fc01888038d578">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Conditional_Adversarial_Generative_Flow_for_Controllable_Image_Synthesis_CVPR_2019_paper.html">Conditional Adversarial Generative Flow for Controllable Image Synthesis</a></th>
                    </tr>
                
                    <tr id="c434d2ae7ea8fe0248e39a598a7b2ce6b6f3066c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c434d2ae7ea8fe0248e39a598a7b2ce6b6f3066c">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Toward_Realistic_Image_Compositing_With_Adversarial_Learning_CVPR_2019_paper.html">Toward Realistic Image Compositing With Adversarial Learning</a></th>
                    </tr>
                
                    <tr id="c4a948952c68cd6ae0024bc60bc12c642fb44fc3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c4a948952c68cd6ae0024bc60bc12c642fb44fc3">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kanehira_Learning_to_Explain_With_Complemental_Examples_CVPR_2019_paper.html">Learning to Explain With Complemental Examples</a></th>
                    </tr>
                
                    <tr id="e722e37748c487748db743d2d0cbe7868489738b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e722e37748c487748db743d2d0cbe7868489738b">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chaudhuri_Joint_Face_Detection_and_Facial_Motion_Retargeting_for_Multiple_Faces_CVPR_2019_paper.html">Joint Face Detection and Facial Motion Retargeting for Multiple Faces</a></th>
                    </tr>
                
                    <tr id="0ec8b88f8c900a6173ccf149a05295afa8880429">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ec8b88f8c900a6173ccf149a05295afa8880429">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_A_Parametric_Top-View_Representation_of_Complex_Road_Scenes_CVPR_2019_paper.html">A Parametric Top-View Representation of Complex Road Scenes</a></th>
                    </tr>
                
                    <tr id="98c1fcb072c9791beff24208538fad071104d83c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/98c1fcb072c9791beff24208538fad071104d83c">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Uittenbogaard_Privacy_Protection_in_Street-View_Panoramas_Using_Depth_and_Multi-View_Imagery_CVPR_2019_paper.html">Privacy Protection in Street-View Panoramas Using Depth and Multi-View Imagery</a></th>
                    </tr>
                
                    <tr id="2ccf2cbc169167628abaca8e69f480d6a3137ab8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ccf2cbc169167628abaca8e69f480d6a3137ab8">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mundt_Meta-Learning_Convolutional_Neural_Architectures_for_Multi-Target_Concrete_Defect_Classification_With_CVPR_2019_paper.html">Meta-Learning Convolutional Neural Architectures for Multi-Target Concrete Defect Classification With the COncrete DEfect BRidge IMage Dataset</a></th>
                    </tr>
                
                    <tr id="f193bb19860f49e3daa4f2ed684231926dc4e70c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f193bb19860f49e3daa4f2ed684231926dc4e70c">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Du_Translate-to-Recognize_Networks_for_RGB-D_Scene_Recognition_CVPR_2019_paper.html">Translate-to-Recognize Networks for RGB-D Scene Recognition</a></th>
                    </tr>
                
                    <tr id="77ea182ab73c1aa9cdee06491179d9928ee6e99f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/77ea182ab73c1aa9cdee06491179d9928ee6e99f">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lohit_Temporal_Transformer_Networks_Joint_Learning_of_Invariant_and_Discriminative_Time_CVPR_2019_paper.html">Temporal Transformer Networks: Joint Learning of Invariant and Discriminative Time Warping</a></th>
                    </tr>
                
                    <tr id="3749e7775f39868915cb047ca212b90f62f7e4af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3749e7775f39868915cb047ca212b90f62f7e4af">32</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Paigwar_Attentional_PointNet_for_3D-Object_Detection_in_Point_Clouds_CVPRW_2019_paper.html">Attentional PointNet for 3D-Object Detection in Point Clouds</a></th>
                    </tr>
                
                    <tr id="9f70dc35279fc2a30e29c29a30109abba69c5c2d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9f70dc35279fc2a30e29c29a30109abba69c5c2d">32</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Calabrese_DHP19_Dynamic_Vision_Sensor_3D_Human_Pose_Dataset_CVPRW_2019_paper.html">DHP19: Dynamic Vision Sensor 3D Human Pose Dataset</a></th>
                    </tr>
                
                    <tr id="61d3dccb4eca3acf43a46d5c294061ea8069e1e4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61d3dccb4eca3acf43a46d5c294061ea8069e1e4">32</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Aich_Global_Sum_Pooling_A_Generalization_Trick_for_Object_Counting_with_CVPRW_2019_paper.html">Global Sum Pooling: A Generalization Trick for Object Counting with Small Datasets of Large Images</a></th>
                    </tr>
                
                    <tr id="2ef83bb794d35765ca02c0fad4ba0781de0ede3a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ef83bb794d35765ca02c0fad4ba0781de0ede3a">32</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Verdoliva_Extracting_camera-based_fingerprints_for_video_forensics_CVPRW_2019_paper.html">Extracting camera-based fingerprints for video forensics</a></th>
                    </tr>
                
                    <tr id="3749e7775f39868915cb047ca212b90f62f7e4af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3749e7775f39868915cb047ca212b90f62f7e4af">32</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Paigwar_Attentional_PointNet_for_3D-Object_Detection_in_Point_Clouds_CVPRW_2019_paper.html">Attentional PointNet for 3D-Object Detection in Point Clouds</a></th>
                    </tr>
                
                    <tr id="a096aed889737167920e9f718702a5bda8b73fb3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a096aed889737167920e9f718702a5bda8b73fb3">32</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Bonafilia_Building_High_Resolution_Maps_for_Humanitarian_Aid_and_Development_with_CVPRW_2019_paper.html">Building High Resolution Maps for Humanitarian Aid and Development with Weakly- and Semi-Supervised Learning</a></th>
                    </tr>
                
                    <tr id="f5277643f5100e05fd77d2d757a7df40f5dbaf6c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f5277643f5100e05fd77d2d757a7df40f5dbaf6c">32</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Zhou_End-to-end_Optimized_Image_Compression_with_Attention_Mechanism_CVPRW_2019_paper.html">End-to-end Optimized Image Compression with Attention Mechanism</a></th>
                    </tr>
                
                    <tr id="afa35a5673354720c4e6f5997d0a5aec47a2150f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/afa35a5673354720c4e6f5997d0a5aec47a2150f">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_MHP-VOS_Multiple_Hypotheses_Propagation_for_Video_Object_Segmentation_CVPR_2019_paper.html">MHP-VOS: Multiple Hypotheses Propagation for Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="5cd3a3c746c0fdb26630c3ed483294e2daeffa38">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5cd3a3c746c0fdb26630c3ed483294e2daeffa38">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pang_Deep_RNN_Framework_for_Visual_Sequential_Applications_CVPR_2019_paper.html">Deep RNN Framework for Visual Sequential Applications</a></th>
                    </tr>
                
                    <tr id="68f0e876a38b7a6d624ab940770501ef57d520c7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/68f0e876a38b7a6d624ab940770501ef57d520c7">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhuang_Learning_Structure-And-Motion-Aware_Rolling_Shutter_Correction_CVPR_2019_paper.html">Learning Structure-And-Motion-Aware Rolling Shutter Correction</a></th>
                    </tr>
                
                    <tr id="9431bd6b37b3aced0b4bddaa1800a3341ccf47f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9431bd6b37b3aced0b4bddaa1800a3341ccf47f1">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_DeepFlux_for_Skeletons_in_the_Wild_CVPR_2019_paper.html">DeepFlux for Skeletons in the Wild</a></th>
                    </tr>
                
                    <tr id="eba62fe8050e475ffe533b9f70db538074d8d0d1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eba62fe8050e475ffe533b9f70db538074d8d0d1">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yin_Context_and_Attribute_Grounded_Dense_Captioning_CVPR_2019_paper.html">Context and Attribute Grounded Dense Captioning</a></th>
                    </tr>
                
                    <tr id="f3d5130277fd028c0c9e621c73a4782621b14bf2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f3d5130277fd028c0c9e621c73a4782621b14bf2">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Visual_Question_Answering_as_Reading_Comprehension_CVPR_2019_paper.html">Visual Question Answering as Reading Comprehension</a></th>
                    </tr>
                
                    <tr id="b8495b6f77dac227fd23b608f1ad44c338eaa679">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b8495b6f77dac227fd23b608f1ad44c338eaa679">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Georgiadis_Accelerating_Convolutional_Neural_Networks_via_Activation_Map_Compression_CVPR_2019_paper.html">Accelerating Convolutional Neural Networks via Activation Map Compression</a></th>
                    </tr>
                
                    <tr id="d2b1543ae156efcaedc780ddf41ae06c74497a7a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d2b1543ae156efcaedc780ddf41ae06c74497a7a">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Aziere_Ensemble_Deep_Manifold_Similarity_Learning_Using_Hard_Proxies_CVPR_2019_paper.html">Ensemble Deep Manifold Similarity Learning Using Hard Proxies</a></th>
                    </tr>
                
                    <tr id="5d9099bdcd88298777158567c3ae261193e0ad66">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5d9099bdcd88298777158567c3ae261193e0ad66">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Reddy_Occlusion-Net_2D3D_Occluded_Keypoint_Localization_Using_Graph_Networks_CVPR_2019_paper.html">Occlusion-Net: 2D/3D Occluded Keypoint Localization Using Graph Networks</a></th>
                    </tr>
                
                    <tr id="84cd491bfe2921e5376ca9143fb421685dfd4ca9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/84cd491bfe2921e5376ca9143fb421685dfd4ca9">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Depth_From_a_Polarisation__RGB_Stereo_Pair_CVPR_2019_paper.html">Depth From a Polarisation + RGB Stereo Pair</a></th>
                    </tr>
                
                    <tr id="79a9e466b3f494ac429bfa78935c8c1e64d880d0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/79a9e466b3f494ac429bfa78935c8c1e64d880d0">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_RGBD_Based_Dimensional_Decomposition_Residual_Network_for_3D_Semantic_Scene_CVPR_2019_paper.html">RGBD Based Dimensional Decomposition Residual Network for 3D Semantic Scene Completion</a></th>
                    </tr>
                
                    <tr id="58407e32eaf24c7a9cee6cff7d8a2b41fadaa92d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/58407e32eaf24c7a9cee6cff7d8a2b41fadaa92d">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Fast_Single_Image_Reflection_Suppression_via_Convex_Optimization_CVPR_2019_paper.html">Fast Single Image Reflection Suppression via Convex Optimization</a></th>
                    </tr>
                
                    <tr id="23e943809c131c50dc90c1d308373febc60b9029">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/23e943809c131c50dc90c1d308373febc60b9029">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Intention_Oriented_Image_Captions_With_Guiding_Objects_CVPR_2019_paper.html">Intention Oriented Image Captions With Guiding Objects</a></th>
                    </tr>
                
                    <tr id="cf072e469d82e71f0515f32b686fb084f4f31714">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cf072e469d82e71f0515f32b686fb084f4f31714">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Schwartz_A_Simple_Baseline_for_Audio-Visual_Scene-Aware_Dialog_CVPR_2019_paper.html">A Simple Baseline for Audio-Visual Scene-Aware Dialog</a></th>
                    </tr>
                
                    <tr id="9f764bb1403bab2c7bc80a2f8a75467bda305db1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9f764bb1403bab2c7bc80a2f8a75467bda305db1">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liao_Multiview_2D3D_Rigid_Registration_via_a_Point-Of-Interest_Network_for_Tracking_CVPR_2019_paper.html">Multiview 2D/3D Rigid Registration via a Point-Of-Interest Network for Tracking and Triangulation</a></th>
                    </tr>
                
                    <tr id="7534dfaaa049f59b4fb1582852d8012e4d8c0ab8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7534dfaaa049f59b4fb1582852d8012e4d8c0ab8">31</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/Majurski_Cell_Image_Segmentation_Using_Generative_Adversarial_Networks_Transfer_Learning_and_CVPRW_2019_paper.html">Cell Image Segmentation Using Generative Adversarial Networks, Transfer Learning, and Augmentations</a></th>
                    </tr>
                
                    <tr id="7c9f730a1b786b1d744bb1d6fdb20ee277428259">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c9f730a1b786b1d744bb1d6fdb20ee277428259">31</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Khorramshahi_Attention_Driven_Vehicle_Re-identification_and_Unsupervised_Anomaly_Detection_for_Traffic_CVPRW_2019_paper.html">Attention Driven Vehicle Re-identification and Unsupervised Anomaly Detection for Traffic Understanding</a></th>
                    </tr>
                
                    <tr id="c70949d4e07554c09f383b8621ecfcf17e4b1bf5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c70949d4e07554c09f383b8621ecfcf17e4b1bf5">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Adaptively_Connected_Neural_Networks_CVPR_2019_paper.html">Adaptively Connected Neural Networks</a></th>
                    </tr>
                
                    <tr id="54ac0938649d70d3ce4a45028475b07fcdc9cbd5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/54ac0938649d70d3ce4a45028475b07fcdc9cbd5">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tran_Gotta_Adapt_Em_All_Joint_Pixel_and_Feature-Level_Domain_Adaptation_CVPR_2019_paper.html">Gotta Adapt &#39;Em All: Joint Pixel and Feature-Level Domain Adaptation for Recognition in the Wild</a></th>
                    </tr>
                
                    <tr id="9eb3e5509b841ea842d73275eed1cab6bdd73cf6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9eb3e5509b841ea842d73275eed1cab6bdd73cf6">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_K-Nearest_Neighbors_Hashing_CVPR_2019_paper.html">K-Nearest Neighbors Hashing</a></th>
                    </tr>
                
                    <tr id="ede2b6e05c06c218fcc10a54bee93fe35568a72c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ede2b6e05c06c218fcc10a54bee93fe35568a72c">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Marin-Jimenez_LAEO-Net_Revisiting_People_Looking_at_Each_Other_in_Videos_CVPR_2019_paper.html">LAEO-Net: Revisiting People Looking at Each Other in Videos</a></th>
                    </tr>
                
                    <tr id="aacdfd9fd9bf59afdc6612678440581f229d270e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aacdfd9fd9bf59afdc6612678440581f229d270e">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Exact_Adversarial_Attack_to_Image_Captioning_via_Structured_Output_Learning_CVPR_2019_paper.html">Exact Adversarial Attack to Image Captioning via Structured Output Learning With Latent Variables</a></th>
                    </tr>
                
                    <tr id="41eff047825b7240626ca871bcc9d37aa12663e8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/41eff047825b7240626ca871bcc9d37aa12663e8">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/van_der_Ouderaa_Reversible_GANs_for_Memory-Efficient_Image-To-Image_Translation_CVPR_2019_paper.html">Reversible GANs for Memory-Efficient Image-To-Image Translation</a></th>
                    </tr>
                
                    <tr id="f4485eb029dd282722975ec449ff802d2ad685e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f4485eb029dd282722975ec449ff802d2ad685e6">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Camposeco_Hybrid_Scene_Compression_for_Visual_Localization_CVPR_2019_paper.html">Hybrid Scene Compression for Visual Localization</a></th>
                    </tr>
                
                    <tr id="ddf42cc17ccc1eebb8910115a44c9c381a915a03">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ddf42cc17ccc1eebb8910115a44c9c381a915a03">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Rhodin_Neural_Scene_Decomposition_for_Multi-Person_Motion_Capture_CVPR_2019_paper.html">Neural Scene Decomposition for Multi-Person Motion Capture</a></th>
                    </tr>
                
                    <tr id="cc2597d0e7824d8d2db28bf3859428d6f17e0b04">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cc2597d0e7824d8d2db28bf3859428d6f17e0b04">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Bayesian_Hierarchical_Dynamic_Model_for_Human_Action_Recognition_CVPR_2019_paper.html">Bayesian Hierarchical Dynamic Model for Human Action Recognition</a></th>
                    </tr>
                
                    <tr id="605d275acfff55996c672339f4a21ff639a3640f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/605d275acfff55996c672339f4a21ff639a3640f">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Griffin_BubbleNets_Learning_to_Select_the_Guidance_Frame_in_Video_Object_CVPR_2019_paper.html">BubbleNets: Learning to Select the Guidance Frame in Video Object Segmentation by Deep Sorting Frames</a></th>
                    </tr>
                
                    <tr id="f8be3ede4a63e67dc2cf0c5a03cf7e3005f78782">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f8be3ede4a63e67dc2cf0c5a03cf7e3005f78782">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Guo_IRLAS_Inverse_Reinforcement_Learning_for_Architecture_Search_CVPR_2019_paper.html">IRLAS: Inverse Reinforcement Learning for Architecture Search</a></th>
                    </tr>
                
                    <tr id="6815288af7e09914e2c21d213a14f154060398ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6815288af7e09914e2c21d213a14f154060398ad">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pandey_Volumetric_Capture_of_Humans_With_a_Single_RGBD_Camera_via_CVPR_2019_paper.html">Volumetric Capture of Humans With a Single RGBD Camera via Semi-Parametric Learning</a></th>
                    </tr>
                
                    <tr id="8842a793e10d35f917345f7290fc671edd8cc7bf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8842a793e10d35f917345f7290fc671edd8cc7bf">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Not_All_Frames_Are_Equal_Weakly-Supervised_Video_Grounding_With_Contextual_CVPR_2019_paper.html">Not All Frames Are Equal: Weakly-Supervised Video Grounding With Contextual Similarity and Visual Clustering Losses</a></th>
                    </tr>
                
                    <tr id="1d9ad3be01e07cdd71686e7814a56c6b1eb82af7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d9ad3be01e07cdd71686e7814a56c6b1eb82af7">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Biasetton_Unsupervised_Domain_Adaptation_for_Semantic_Segmentation_of_Urban_Scenes_CVPRW_2019_paper.html">Unsupervised Domain Adaptation for Semantic Segmentation of Urban Scenes</a></th>
                    </tr>
                
                    <tr id="b6f512431464d89b4d77782e4fe90c85fc63a754">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b6f512431464d89b4d77782e4fe90c85fc63a754">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BCMCVAI/Goel_DeepRing_Protecting_Deep_Neural_Network_With_Blockchain_CVPRW_2019_paper.html">DeepRing: Protecting Deep Neural Network With Blockchain</a></th>
                    </tr>
                
                    <tr id="875e648855b915cd7f559fe223ba2ef7c8d83e33">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/875e648855b915cd7f559fe223ba2ef7c8d83e33">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SAIAD/Bolte_Unsupervised_Domain_Adaptation_to_Improve_Image_Segmentation_Quality_Both_in_CVPRW_2019_paper.html">Unsupervised Domain Adaptation to Improve Image Segmentation Quality Both in the Source and Target Domain</a></th>
                    </tr>
                
                    <tr id="980e4cf80e09261232ab0489e455ff5eb64c0487">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/980e4cf80e09261232ab0489e455ff5eb64c0487">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UAVision/Fonder_Mid-Air_A_Multi-Modal_Dataset_for_Extremely_Low_Altitude_Drone_Flights_CVPRW_2019_paper.html">Mid-Air: A Multi-Modal Dataset for Extremely Low Altitude Drone Flights</a></th>
                    </tr>
                
                    <tr id="4a65bb760eb95ede811cc77b567a4377fe151fa6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4a65bb760eb95ede811cc77b567a4377fe151fa6">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CFS/Liu_Multi-Modal_Face_Anti-Spoofing_Attack_Detection_Challenge_at_CVPR2019_CVPRW_2019_paper.html">Multi-Modal Face Anti-Spoofing Attack Detection Challenge at CVPR2019</a></th>
                    </tr>
                
                    <tr id="6ad0126bbecc08f29d883ab2e29f02b211487797">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6ad0126bbecc08f29d883ab2e29f02b211487797">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CFS/Shen_FaceBagNet_Bag-Of-Local-Features_Model_for_Multi-Modal_Face_Anti-Spoofing_CVPRW_2019_paper.html">FaceBagNet: Bag-Of-Local-Features Model for Multi-Modal Face Anti-Spoofing</a></th>
                    </tr>
                
                    <tr id="f57bd24c962f9a06d5d3dfdd013e34cfa1d05307">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f57bd24c962f9a06d5d3dfdd013e34cfa1d05307">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Face_and_Gesture_Analysis_for_Health_Informatics/Ahad_Vision-based_Action_Understanding_for_Assistive_Healthcare_A_Short_Review_CVPRW_2019_paper.html">Vision-based Action Understanding for Assistive Healthcare: A Short Review</a></th>
                    </tr>
                
                    <tr id="54ac0938649d70d3ce4a45028475b07fcdc9cbd5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/54ac0938649d70d3ce4a45028475b07fcdc9cbd5">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Tran_Gotta_Adapt_Em_All_Joint_Pixel_and_Feature-Level_Domain_Adaptation_CVPRW_2019_paper.html">Gotta Adapt &#39;Em All: Joint Pixel and Feature-Level Domain Adaptation for Recognition in the Wild</a></th>
                    </tr>
                
                    <tr id="1d9ad3be01e07cdd71686e7814a56c6b1eb82af7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d9ad3be01e07cdd71686e7814a56c6b1eb82af7">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Biasetton_Unsupervised_Domain_Adaptation_for_Semantic_Segmentation_of_Urban_Scenes_CVPRW_2019_paper.html">Unsupervised Domain Adaptation for Semantic Segmentation of Urban Scenes</a></th>
                    </tr>
                
                    <tr id="8c5752b88f5c287e7b6c051f6df08cc80d9e39d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c5752b88f5c287e7b6c051f6df08cc80d9e39d4">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Robust_Video_Stabilization_by_Optimization_in_CNN_Weight_Space_CVPR_2019_paper.html">Robust Video Stabilization by Optimization in CNN Weight Space</a></th>
                    </tr>
                
                    <tr id="a112f58886d4c6a6ab0ef3b8c19d4966b7043e54">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a112f58886d4c6a6ab0ef3b8c19d4966b7043e54">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Blind_Geometric_Distortion_Correction_on_Images_Through_Deep_Learning_CVPR_2019_paper.html">Blind Geometric Distortion Correction on Images Through Deep Learning</a></th>
                    </tr>
                
                    <tr id="cfa44f8cc2cdccab6243046152221d3a884cafe5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cfa44f8cc2cdccab6243046152221d3a884cafe5">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ingle_High_Flux_Passive_Imaging_With_Single-Photon_Sensors_CVPR_2019_paper.html">High Flux Passive Imaging With Single-Photon Sensors</a></th>
                    </tr>
                
                    <tr id="25e48d96ddd3eece7a0efc1a64badb8a2df9efc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/25e48d96ddd3eece7a0efc1a64badb8a2df9efc1">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yi_MMFace_A_Multi-Metric_Regression_Network_for_Unconstrained_Face_Reconstruction_CVPR_2019_paper.html">MMFace: A Multi-Metric Regression Network for Unconstrained Face Reconstruction</a></th>
                    </tr>
                
                    <tr id="2d04e75d4bfd8055e545035dc4b6f9e70734e58c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d04e75d4bfd8055e545035dc4b6f9e70734e58c">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Najibi_FA-RPN_Floating_Region_Proposals_for_Face_Detection_CVPR_2019_paper.html">FA-RPN: Floating Region Proposals for Face Detection</a></th>
                    </tr>
                
                    <tr id="24fdb40c354599ee33a25530c3fa7b9ebc75e840">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/24fdb40c354599ee33a25530c3fa7b9ebc75e840">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dognin_Adversarial_Semantic_Alignment_for_Improved_Image_Captions_CVPR_2019_paper.html">Adversarial Semantic Alignment for Improved Image Captions</a></th>
                    </tr>
                
                    <tr id="dee86cf4ddab965169297960b55a4a2c0aee58d5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dee86cf4ddab965169297960b55a4a2c0aee58d5">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Grounding_Human-To-Vehicle_Advice_for_Self-Driving_Vehicles_CVPR_2019_paper.html">Grounding Human-To-Vehicle Advice for Self-Driving Vehicles</a></th>
                    </tr>
                
                    <tr id="a0e8f4348968195c80494b7a4245edb91a252c93">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a0e8f4348968195c80494b7a4245edb91a252c93">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Burlina_Wheres_Wally_Now_Deep_Generative_and_Discriminative_Embeddings_for_Novelty_CVPR_2019_paper.html">Where&#39;s Wally Now? Deep Generative and Discriminative Embeddings for Novelty Detection</a></th>
                    </tr>
                
                    <tr id="3f32b0b933e4b08e735240d95e099837bb05f679">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f32b0b933e4b08e735240d95e099837bb05f679">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zheng_Disentangling_Latent_Space_for_VAE_by_Label_RelevantIrrelevant_Dimensions_CVPR_2019_paper.html">Disentangling Latent Space for VAE by Label Relevant/Irrelevant Dimensions</a></th>
                    </tr>
                
                    <tr id="ba366e9754f5777d915484e23a9ed10d6275206a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ba366e9754f5777d915484e23a9ed10d6275206a">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Stoffregen_Event_Cameras_Contrast_Maximization_and_Reward_Functions_An_Analysis_CVPR_2019_paper.html">Event Cameras, Contrast Maximization and Reward Functions: An Analysis</a></th>
                    </tr>
                
                    <tr id="61490d49c034aafb2623e5dc06800f61cc227253">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61490d49c034aafb2623e5dc06800f61cc227253">29</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Liang_Three-Stream_Convolutional_Neural_Network_With_Multi-Task_and_Ensemble_Learning_for_CVPRW_2019_paper.html">Three-Stream Convolutional Neural Network With Multi-Task and Ensemble Learning for 3D Action Recognition</a></th>
                    </tr>
                
                    <tr id="603a98ffcc72eb3a313e9be4e1165284bdf8af6e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/603a98ffcc72eb3a313e9be4e1165284bdf8af6e">29</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/TRMTMCT/Zhai_In_Defense_of_the_Classification_Loss_for_Person_Re-Identification_CVPRW_2019_paper.html">In Defense of the Classification Loss for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="d390adcc0e8f37ee5ece14a47ee9e1769871d660">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d390adcc0e8f37ee5ece14a47ee9e1769871d660">29</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Kanaci_Multi-Task_Mutual_Learning_for_Vehicle_Re-Identification_CVPRW_2019_paper.html">Multi-Task Mutual Learning for Vehicle Re-Identification</a></th>
                    </tr>
                
                    <tr id="f149aa000fd35fa5f70d478ae0bfce81e55c9b9f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f149aa000fd35fa5f70d478ae0bfce81e55c9b9f">29</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Wang_Anomaly_Candidate_Identification_and_Starting_Time_Estimation_of_Vehicles_from_CVPRW_2019_paper.html">Anomaly Candidate Identification and Starting Time Estimation of Vehicles from Traffic Videos</a></th>
                    </tr>
                
                    <tr id="d96acd7c3e48dcaa987f896b5317dc052eedbe32">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d96acd7c3e48dcaa987f896b5317dc052eedbe32">29</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Campos_Content_Adaptive_Optimization_for_Neural_Image_Compression_CVPRW_2019_paper.html">Content Adaptive Optimization for Neural Image Compression</a></th>
                    </tr>
                
                    <tr id="5b7186cb31497c305ac029804642c699925aff61">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b7186cb31497c305ac029804642c699925aff61">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Meng_Weakly_Supervised_Person_Re-Identification_CVPR_2019_paper.html">Weakly Supervised Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="21c07304466328bafe0b493f9583641f5f745c48">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/21c07304466328bafe0b493f9583641f5f745c48">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Alharbi_Latent_Filter_Scaling_for_Multimodal_Unsupervised_Image-To-Image_Translation_CVPR_2019_paper.html">Latent Filter Scaling for Multimodal Unsupervised Image-To-Image Translation</a></th>
                    </tr>
                
                    <tr id="afa1b2e96cea3bedf6777fc698e372e79022a116">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/afa1b2e96cea3bedf6777fc698e372e79022a116">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ni_Elastic_Boundary_Projection_for_3D_Medical_Image_Segmentation_CVPR_2019_paper.html">Elastic Boundary Projection for 3D Medical Image Segmentation</a></th>
                    </tr>
                
                    <tr id="e223021ffafe07cdc3d9289d0d6392e522585e92">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e223021ffafe07cdc3d9289d0d6392e522585e92">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Collomosse_LiveSketch_Query_Perturbations_for_Guided_Sketch-Based_Visual_Search_CVPR_2019_paper.html">LiveSketch: Query Perturbations for Guided Sketch-Based Visual Search</a></th>
                    </tr>
                
                    <tr id="9880651bab516df46a0f24ba1e56697d9bb555ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9880651bab516df46a0f24ba1e56697d9bb555ff">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Layout-Graph_Reasoning_for_Fashion_Landmark_Detection_CVPR_2019_paper.html">Layout-Graph Reasoning for Fashion Landmark Detection</a></th>
                    </tr>
                
                    <tr id="50680fcdd9b22cb32080b0d2c49310ec3834c2e7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50680fcdd9b22cb32080b0d2c49310ec3834c2e7">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ming_Group_Sampling_for_Scale_Invariant_Face_Detection_CVPR_2019_paper.html">Group Sampling for Scale Invariant Face Detection</a></th>
                    </tr>
                
                    <tr id="f6b4f6da2ac6040091ed04d2037d0b76e7f499a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f6b4f6da2ac6040091ed04d2037d0b76e7f499a0">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qi_KE-GAN_Knowledge_Embedded_Generative_Adversarial_Networks_for_Semi-Supervised_Scene_Parsing_CVPR_2019_paper.html">KE-GAN: Knowledge Embedded Generative Adversarial Networks for Semi-Supervised Scene Parsing</a></th>
                    </tr>
                
                    <tr id="fcc609ea9b4491406977dabf17ff52f89f103805">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fcc609ea9b4491406977dabf17ff52f89f103805">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kumar_Jumping_Manifolds_Geometry_Aware_Dense_Non-Rigid_Structure_From_Motion_CVPR_2019_paper.html">Jumping Manifolds: Geometry Aware Dense Non-Rigid Structure From Motion</a></th>
                    </tr>
                
                    <tr id="6da9d2a8163e0ae336cc06a0c2caeba610ae87c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6da9d2a8163e0ae336cc06a0c2caeba610ae87c0">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Agresti_Unsupervised_Domain_Adaptation_for_ToF_Data_Denoising_With_Adversarial_Learning_CVPR_2019_paper.html">Unsupervised Domain Adaptation for ToF Data Denoising With Adversarial Learning</a></th>
                    </tr>
                
                    <tr id="8240e4dbe95d52ff437194946e6c283ea5420f5c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8240e4dbe95d52ff437194946e6c283ea5420f5c">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Semantic_Component_Decomposition_for_Face_Attribute_Manipulation_CVPR_2019_paper.html">Semantic Component Decomposition for Face Attribute Manipulation</a></th>
                    </tr>
                
                    <tr id="7133f2df88f307c54e9b4f2eae034aa956bd2445">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7133f2df88f307c54e9b4f2eae034aa956bd2445">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_ECC_Platform-Independent_Energy-Constrained_Deep_Neural_Network_Compression_via_a_Bilinear_CVPR_2019_paper.html">ECC: Platform-Independent Energy-Constrained Deep Neural Network Compression via a Bilinear Regression Model</a></th>
                    </tr>
                
                    <tr id="7ea42c7f029cf3bd0683754e4ea21625c1044d55">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ea42c7f029cf3bd0683754e4ea21625c1044d55">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tong_Hierarchical_Disentanglement_of_Discriminative_Latent_Features_for_Zero-Shot_Learning_CVPR_2019_paper.html">Hierarchical Disentanglement of Discriminative Latent Features for Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="883a659062b3412747ea9b2f72539cc63dfca709">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/883a659062b3412747ea9b2f72539cc63dfca709">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hosseini_Atlas_of_Digital_Pathology_A_Generalized_Hierarchical_Histological_Tissue_Type-Annotated_CVPR_2019_paper.html">Atlas of Digital Pathology: A Generalized Hierarchical Histological Tissue Type-Annotated Database for Deep Learning</a></th>
                    </tr>
                
                    <tr id="1a69fea9e3640c8a6aae4f0716df121ba1d65a0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a69fea9e3640c8a6aae4f0716df121ba1d65a0c">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_LBS_Autoencoder_Self-Supervised_Fitting_of_Articulated_Meshes_to_Point_Clouds_CVPR_2019_paper.html">LBS Autoencoder: Self-Supervised Fitting of Articulated Meshes to Point Clouds</a></th>
                    </tr>
                
                    <tr id="781cbe2c4f155533fd77cacac55f2cd5c9be7d7e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/781cbe2c4f155533fd77cacac55f2cd5c9be7d7e">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Semantic_Attribute_Matching_Networks_CVPR_2019_paper.html">Semantic Attribute Matching Networks</a></th>
                    </tr>
                
                    <tr id="1759f223b99e26adda2fceb54f02564e78189730">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1759f223b99e26adda2fceb54f02564e78189730">28</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Rostami_SAR_Image_Classification_Using_Few-Shot_Cross-Domain_Transfer_Learning_CVPRW_2019_paper.html">SAR Image Classification Using Few-Shot Cross-Domain Transfer Learning</a></th>
                    </tr>
                
                    <tr id="d32db8a5bf047d34b2ef76a8d6bb62bd9eefcd38">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d32db8a5bf047d34b2ef76a8d6bb62bd9eefcd38">28</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Zendel_RailSem19_A_Dataset_for_Semantic_Rail_Scene_Understanding_CVPRW_2019_paper.html">RailSem19: A Dataset for Semantic Rail Scene Understanding</a></th>
                    </tr>
                
                    <tr id="471980b10443d0e0c858bac74a9238a8993895ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/471980b10443d0e0c858bac74a9238a8993895ff">28</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Feng_Suppressing_Model_Overfitting_for_Image_Super-Resolution_Networks_CVPRW_2019_paper.html">Suppressing Model Overfitting for Image Super-Resolution Networks</a></th>
                    </tr>
                
                    <tr id="cd2d47db1c10be3db822d2bf4dc052ce417cbaa0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd2d47db1c10be3db822d2bf4dc052ce417cbaa0">28</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Guo_Dense_Scene_Information_Estimation_Network_for_Dehazing_CVPRW_2019_paper.html">Dense Scene Information Estimation Network for Dehazing</a></th>
                    </tr>
                
                    <tr id="819fa65d0c9bf56d763b5693b0f4b6a3875c0939">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/819fa65d0c9bf56d763b5693b0f4b6a3875c0939">28</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Ignatov_NTIRE_2019_Challenge_on_Image_Enhancement_Methods_and_Results_CVPRW_2019_paper.html">NTIRE 2019 Challenge on Image Enhancement: Methods and Results</a></th>
                    </tr>
                
                    <tr id="99e61ded1de05ad549cbd9eaa3e013f70cb87f29">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/99e61ded1de05ad549cbd9eaa3e013f70cb87f29">28</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Chen_Live_Demonstration_CeleX-V_A_1M_Pixel_Multi-Mode_Event-Based_Sensor_CVPRW_2019_paper.html">Live Demonstration: CeleX-V: A 1M Pixel Multi-Mode Event-Based Sensor</a></th>
                    </tr>
                
                    <tr id="125cb66b115662ff2eee6a87f83f7ae69244dc46">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/125cb66b115662ff2eee6a87f83f7ae69244dc46">28</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Rafi_Application_of_DenseNet_in_Camera_Model_Identification_and_Post-processing_Detection_CVPRW_2019_paper.html">Application of DenseNet in Camera Model Identification and Post-processing Detection</a></th>
                    </tr>
                
                    <tr id="d32db8a5bf047d34b2ef76a8d6bb62bd9eefcd38">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d32db8a5bf047d34b2ef76a8d6bb62bd9eefcd38">28</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Zendel_RailSem19_A_Dataset_for_Semantic_Rail_Scene_Understanding_CVPRW_2019_paper.html">RailSem19: A Dataset for Semantic Rail Scene Understanding</a></th>
                    </tr>
                
                    <tr id="1819e6380f2057f83039d2cda431823d2baba4fb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1819e6380f2057f83039d2cda431823d2baba4fb">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_P3SGD_Patient_Privacy_Preserving_SGD_for_Regularizing_Deep_CNNs_in_CVPR_2019_paper.html">P3SGD: Patient Privacy Preserving SGD for Regularizing Deep CNNs in Pathological Image Classification</a></th>
                    </tr>
                
                    <tr id="bc37923b78d2ff7decac0a1210afb29bd356ac0a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bc37923b78d2ff7decac0a1210afb29bd356ac0a">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Extreme_Relative_Pose_Estimation_for_RGB-D_Scans_via_Scene_Completion_CVPR_2019_paper.html">Extreme Relative Pose Estimation for RGB-D Scans via Scene Completion</a></th>
                    </tr>
                
                    <tr id="2cb5a88d314b0867c0481a93df9f0d345fe5a540">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2cb5a88d314b0867c0481a93df9f0d345fe5a540">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Guo_Dynamic_Recursive_Neural_Network_CVPR_2019_paper.html">Dynamic Recursive Neural Network</a></th>
                    </tr>
                
                    <tr id="25058f25bdb2a7f2e231dd36194a47b106b1442a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/25058f25bdb2a7f2e231dd36194a47b106b1442a">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Compressing_Unknown_Images_With_Product_Quantizer_for_Efficient_Zero-Shot_Classification_CVPR_2019_paper.html">Compressing Unknown Images With Product Quantizer for Efficient Zero-Shot Classification</a></th>
                    </tr>
                
                    <tr id="1d863e63bce21b8b9d1805ca199674823d07db5a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d863e63bce21b8b9d1805ca199674823d07db5a">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/He_GeoNet_Deep_Geodesic_Networks_for_Point_Cloud_Analysis_CVPR_2019_paper.html">GeoNet: Deep Geodesic Networks for Point Cloud Analysis</a></th>
                    </tr>
                
                    <tr id="ee70c574dc06f0e17b1eaef1c9326d8533517f4c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ee70c574dc06f0e17b1eaef1c9326d8533517f4c">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Stojanov_Incremental_Object_Learning_From_Contiguous_Views_CVPR_2019_paper.html">Incremental Object Learning From Contiguous Views</a></th>
                    </tr>
                
                    <tr id="a688ac0ca245868a4303378cc44f2c2bd5d796d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a688ac0ca245868a4303378cc44f2c2bd5d796d2">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xing_Unsupervised_Disentangling_of_Appearance_and_Geometry_by_Deformable_Generator_Network_CVPR_2019_paper.html">Unsupervised Disentangling of Appearance and Geometry by Deformable Generator Network</a></th>
                    </tr>
                
                    <tr id="9f9b21270c4b659a0dbf2f9a25c223bd97aedc99">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9f9b21270c4b659a0dbf2f9a25c223bd97aedc99">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Tangent-Normal_Adversarial_Regularization_for_Semi-Supervised_Learning_CVPR_2019_paper.html">Tangent-Normal Adversarial Regularization for Semi-Supervised Learning</a></th>
                    </tr>
                
                    <tr id="8ae7b09919b6afca2d87b5c4abacefb4e0ff151b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8ae7b09919b6afca2d87b5c4abacefb4e0ff151b">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Swoboda_A_Convex_Relaxation_for_Multi-Graph_Matching_CVPR_2019_paper.html">A Convex Relaxation for Multi-Graph Matching</a></th>
                    </tr>
                
                    <tr id="f8ef5caa179b0b2fc102678d82a27433bbf4a151">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f8ef5caa179b0b2fc102678d82a27433bbf4a151">27</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Fridman_Arguing_Machines_Human_Supervision_of_Black_Box_AI_Systems_That_CVPRW_2019_paper.html">Arguing Machines: Human Supervision of Black Box AI Systems That Make Life-Critical Decisions</a></th>
                    </tr>
                
                    <tr id="881dfa0f00945dc2d75992f13582f42250c3e693">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/881dfa0f00945dc2d75992f13582f42250c3e693">27</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/TRMTMCT/Martinel_Aggregating_Deep_Pyramidal_Representations_for_Person_Re-Identification_CVPRW_2019_paper.html">Aggregating Deep Pyramidal Representations for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="b812084698caa3a9be8ed454036c54998008f124">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b812084698caa3a9be8ed454036c54998008f124">27</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Albright_Source_Generator_Attribution_via_Inversion_CVPRW_2019_paper.html">Source Generator Attribution via Inversion</a></th>
                    </tr>
                
                    <tr id="246a91b1737bdcc777efb7d85e37c51476886785">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/246a91b1737bdcc777efb7d85e37c51476886785">27</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/AlBadawy_Detecting_AI-Synthesized_Speech_Using_Bispectral_Analysis_CVPRW_2019_paper.html">Detecting AI-Synthesized Speech Using Bispectral Analysis</a></th>
                    </tr>
                
                    <tr id="f8ef5caa179b0b2fc102678d82a27433bbf4a151">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f8ef5caa179b0b2fc102678d82a27433bbf4a151">27</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Fridman_Arguing_Machines_Human_Supervision_of_Black_Box_AI_Systems_That_CVPRW_2019_paper.html">Arguing Machines: Human Supervision of Black Box AI Systems That Make Life-Critical Decisions</a></th>
                    </tr>
                
                    <tr id="fd7c12e1eac960a4b4e7d72499c94b8eb747eefe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fd7c12e1eac960a4b4e7d72499c94b8eb747eefe">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zuo_CRAVES_Controlling_Robotic_Arm_With_a_Vision-Based_Economic_System_CVPR_2019_paper.html">CRAVES: Controlling Robotic Arm With a Vision-Based Economic System</a></th>
                    </tr>
                
                    <tr id="6a552ef06b5cec584d7b75f8c17a9420db78b246">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a552ef06b5cec584d7b75f8c17a9420db78b246">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Park_Sphere_Generative_Adversarial_Network_Based_on_Geometric_Moment_Matching_CVPR_2019_paper.html">Sphere Generative Adversarial Network Based on Geometric Moment Matching</a></th>
                    </tr>
                
                    <tr id="91179a1183126a401a208468111a8cc00191ea42">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/91179a1183126a401a208468111a8cc00191ea42">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Weinzaepfel_Visual_Localization_by_Learning_Objects-Of-Interest_Dense_Match_Regression_CVPR_2019_paper.html">Visual Localization by Learning Objects-Of-Interest Dense Match Regression</a></th>
                    </tr>
                
                    <tr id="14ac0575e30fe54c0fecf638d399a6f4b3e7dd5f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/14ac0575e30fe54c0fecf638d399a6f4b3e7dd5f">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sun_Deeply-Supervised_Knowledge_Synergy_CVPR_2019_paper.html">Deeply-Supervised Knowledge Synergy</a></th>
                    </tr>
                
                    <tr id="7b263024df041ba927ec0986cf400b8417c88b07">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b263024df041ba927ec0986cf400b8417c88b07">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Singh_You_Reap_What_You_Sow_Using_Videos_to_Generate_High_CVPR_2019_paper.html">You Reap What You Sow: Using Videos to Generate High Precision Object Proposals for Weakly-Supervised Object Detection</a></th>
                    </tr>
                
                    <tr id="c7ee1000ff197985553c9fb8d9cdc838d2858cff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c7ee1000ff197985553c9fb8d9cdc838d2858cff">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Moltisanti_Action_Recognition_From_Single_Timestamp_Supervision_in_Untrimmed_Videos_CVPR_2019_paper.html">Action Recognition From Single Timestamp Supervision in Untrimmed Videos</a></th>
                    </tr>
                
                    <tr id="96baeca69aabc6e51125be586e29c6580e2ba83f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96baeca69aabc6e51125be586e29c6580e2ba83f">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Analysis_of_Feature_Visibility_in_Non-Line-Of-Sight_Measurements_CVPR_2019_paper.html">Analysis of Feature Visibility in Non-Line-Of-Sight Measurements</a></th>
                    </tr>
                
                    <tr id="6978d365ccc2e3f9259f1cd09deed99a3384acbf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6978d365ccc2e3f9259f1cd09deed99a3384acbf">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Building_Efficient_Deep_Neural_Networks_With_Unitary_Group_Convolutions_CVPR_2019_paper.html">Building Efficient Deep Neural Networks With Unitary Group Convolutions</a></th>
                    </tr>
                
                    <tr id="a3510e8d198cac9ccac2c24476c3d0886bbcb682">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a3510e8d198cac9ccac2c24476c3d0886bbcb682">26</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Mardanisamani_Crop_Lodging_Prediction_From_UAV-Acquired_Images_of_Wheat_and_Canola_CVPRW_2019_paper.html">Crop Lodging Prediction From UAV-Acquired Images of Wheat and Canola Using a DCNN Augmented With Handcrafted Texture Features</a></th>
                    </tr>
                
                    <tr id="8939088c2d7dc0e2fa5c9fc986c7c7564b7ba47b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8939088c2d7dc0e2fa5c9fc986c7c7564b7ba47b">26</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Shao_Efficient_Deep_Palmprint_Recognition_via_Distilled_Hashing_Coding_CVPRW_2019_paper.html">Efficient Deep Palmprint Recognition via Distilled Hashing Coding</a></th>
                    </tr>
                
                    <tr id="d4dafcd3e0b03f68f8f031ea1bbc02d0d31b59d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d4dafcd3e0b03f68f8f031ea1bbc02d0d31b59d2">26</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Sim_A_Deep_Motion_Deblurring_Network_Based_on_Per-Pixel_Adaptive_Kernels_CVPRW_2019_paper.html">A Deep Motion Deblurring Network Based on Per-Pixel Adaptive Kernels With Residual Down-Up and Up-Down Modules</a></th>
                    </tr>
                
                    <tr id="aaef4dce3d3dbec49f70a29a96e889a19c162deb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aaef4dce3d3dbec49f70a29a96e889a19c162deb">26</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Chin_Star_Tracking_Using_an_Event_Camera_CVPRW_2019_paper.html">Star Tracking Using an Event Camera</a></th>
                    </tr>
                
                    <tr id="45980c404e3644c78c58e0eda4b8cda8869d6d27">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/45980c404e3644c78c58e0eda4b8cda8869d6d27">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhuo_Unsupervised_Open_Domain_Recognition_by_Semantic_Discrepancy_Minimization_CVPR_2019_paper.html">Unsupervised Open Domain Recognition by Semantic Discrepancy Minimization</a></th>
                    </tr>
                
                    <tr id="fbd8bd944f883f465679248493bc097a4b7ab4ef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fbd8bd944f883f465679248493bc097a4b7ab4ef">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_Activity_Driven_Weakly_Supervised_Object_Detection_CVPR_2019_paper.html">Activity Driven Weakly Supervised Object Detection</a></th>
                    </tr>
                
                    <tr id="22ed48a84b3227ff05bbc8770f7b6c823afa734a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/22ed48a84b3227ff05bbc8770f7b6c823afa734a">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hamaguchi_Rare_Event_Detection_Using_Disentangled_Representation_Learning_CVPR_2019_paper.html">Rare Event Detection Using Disentangled Representation Learning</a></th>
                    </tr>
                
                    <tr id="16765e83676f8caf4d1b6ef787af36bb2434908e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16765e83676f8caf4d1b6ef787af36bb2434908e">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dmitriev_Learning_Multi-Class_Segmentations_From_Single-Class_Datasets_CVPR_2019_paper.html">Learning Multi-Class Segmentations From Single-Class Datasets</a></th>
                    </tr>
                
                    <tr id="77501e770f6b45a949fd9ea41f8f1775da821bba">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/77501e770f6b45a949fd9ea41f8f1775da821bba">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Duong_Automatic_Face_Aging_in_Videos_via_Deep_Reinforcement_Learning_CVPR_2019_paper.html">Automatic Face Aging in Videos via Deep Reinforcement Learning</a></th>
                    </tr>
                
                    <tr id="14b29f371195e86f6ccbf5961919dc451ede7d8d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/14b29f371195e86f6ccbf5961919dc451ede7d8d">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Aljadaany_Douglas-Rachford_Networks_Learning_Both_the_Image_Prior_and_Data_Fidelity_CVPR_2019_paper.html">Douglas-Rachford Networks: Learning Both the Image Prior and Data Fidelity Terms for Blind Image Deconvolution</a></th>
                    </tr>
                
                    <tr id="b175cb122f04d690da586dff416bc819e6fc2d52">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b175cb122f04d690da586dff416bc819e6fc2d52">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gattupalli_Weakly_Supervised_Deep_Image_Hashing_Through_Tag_Embeddings_CVPR_2019_paper.html">Weakly Supervised Deep Image Hashing Through Tag Embeddings</a></th>
                    </tr>
                
                    <tr id="b1a3dc492c88427a0b6fa253f09c2b19fc6f0d48">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b1a3dc492c88427a0b6fa253f09c2b19fc6f0d48">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Taran_Defending_Against_Adversarial_Attacks_by_Randomized_Diversification_CVPR_2019_paper.html">Defending Against Adversarial Attacks by Randomized Diversification</a></th>
                    </tr>
                
                    <tr id="cdbb2e8efac0235fb289e8b28b4b02652b6c0a2f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cdbb2e8efac0235fb289e8b28b4b02652b6c0a2f">25</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PCV/Goldman_Learn_Stereo_Infer_Mono_Siamese_Networks_for_Self-Supervised_Monocular_Depth_CVPRW_2019_paper.html">Learn Stereo, Infer Mono: Siamese Networks for Self-Supervised, Monocular, Depth Estimation</a></th>
                    </tr>
                
                    <tr id="d0b8c5c4ded3345613b27c0a24eae0eaed173c07">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d0b8c5c4ded3345613b27c0a24eae0eaed173c07">25</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EarthVision/Leotta_Urban_Semantic_3D_Reconstruction_From_Multiview_Satellite_Imagery_CVPRW_2019_paper.html">Urban Semantic 3D Reconstruction From Multiview Satellite Imagery</a></th>
                    </tr>
                
                    <tr id="16607d56d6431038f8ce18656cc0736202f7d489">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16607d56d6431038f8ce18656cc0736202f7d489">25</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Skovsen_The_GrassClover_Image_Dataset_for_Semantic_and_Hierarchical_Species_Understanding_CVPRW_2019_paper.html">The GrassClover Image Dataset for Semantic and Hierarchical Species Understanding in Agriculture</a></th>
                    </tr>
                
                    <tr id="4df76da50affba2e4e9bdda6f105ab9c0d0234b6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4df76da50affba2e4e9bdda6f105ab9c0d0234b6">25</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Sidorov_Conditional_GANs_for_Multi-Illuminant_Color_Constancy_Revolution_or_yet_Another_CVPRW_2019_paper.html">Conditional GANs for Multi-Illuminant Color Constancy: Revolution or yet Another Approach?</a></th>
                    </tr>
                
                    <tr id="13bd21fb44696c9a556e222cbc540243fdc284ae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/13bd21fb44696c9a556e222cbc540243fdc284ae">25</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Nah_NTIRE_2019_Challenge_on_Video_Deblurring_Methods_and_Results_CVPRW_2019_paper.html">NTIRE 2019 Challenge on Video Deblurring: Methods and Results</a></th>
                    </tr>
                
                    <tr id="7196aa4490a1d6fd5caac144acd4710cb17046b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7196aa4490a1d6fd5caac144acd4710cb17046b5">25</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/TRMTMCT/Tang_Unsupervised_Person_Re-Identification_With_Iterative_Self-Supervised_Domain_Adaptation_CVPRW_2019_paper.html">Unsupervised Person Re-Identification With Iterative Self-Supervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="7fdd1b95b7a41abde5efa4d0cec93d75d152b925">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7fdd1b95b7a41abde5efa4d0cec93d75d152b925">25</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/TRMTMCT/Cai_Multi-Scale_Body-Part_Mask_Guided_Attention_for_Person_Re-Identification_CVPRW_2019_paper.html">Multi-Scale Body-Part Mask Guided Attention for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="8eca936f462712f3d67ebe564292857144f704f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8eca936f462712f3d67ebe564292857144f704f1">25</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Subedar_Uncertainty_aware_audiovisual_activity_recognition_using_deep_Bayesian_variational_inference_CVPRW_2019_paper.html">Uncertainty aware audiovisual activity recognition using deep Bayesian variational inference</a></th>
                    </tr>
                
                    <tr id="579da787acbe561b05beea60162488a15f82ceea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/579da787acbe561b05beea60162488a15f82ceea">25</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Bai_Traffic_Anomaly_Detection_via_Perspective_Map_based_on_Spatial-temporal_Information_CVPRW_2019_paper.html">Traffic Anomaly Detection via Perspective Map based on Spatial-temporal Information Matrix</a></th>
                    </tr>
                
                    <tr id="c37bc234a97099e15753f19feb6653d436a09368">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c37bc234a97099e15753f19feb6653d436a09368">25</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/He_Multi-Camera_Vehicle_Tracking_with_Powerful_Visual_Features_and_Spatial-Temporal_Cue_CVPRW_2019_paper.html">Multi-Camera Vehicle Tracking with Powerful Visual Features and Spatial-Temporal Cue</a></th>
                    </tr>
                
                    <tr id="2806b9dacd2773efdfb6571b5b1aed39c8975537">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2806b9dacd2773efdfb6571b5b1aed39c8975537">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yoon_Self-Supervised_Adaptation_of_High-Fidelity_Face_Models_for_Monocular_Performance_Tracking_CVPR_2019_paper.html">Self-Supervised Adaptation of High-Fidelity Face Models for Monocular Performance Tracking</a></th>
                    </tr>
                
                    <tr id="f2ea6dfc46da5c35c01d4e6e19b37ac24689018c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f2ea6dfc46da5c35c01d4e6e19b37ac24689018c">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Eghbal-zadeh_Mixture_Density_Generative_Adversarial_Networks_CVPR_2019_paper.html">Mixture Density Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="8ce73ec2619fc45dedd96e2c57e940d124265574">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8ce73ec2619fc45dedd96e2c57e940d124265574">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gupta_Photon-Flooded_Single-Photon_3D_Cameras_CVPR_2019_paper.html">Photon-Flooded Single-Photon 3D Cameras</a></th>
                    </tr>
                
                    <tr id="b7fd6e25c240f530ee179e38aac09d86c9bfa3f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b7fd6e25c240f530ee179e38aac09d86c9bfa3f5">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Theagarajan_ShieldNets_Defending_Against_Adversarial_Attacks_Using_Probabilistic_Adversarial_Robustness_CVPR_2019_paper.html">ShieldNets: Defending Against Adversarial Attacks Using Probabilistic Adversarial Robustness</a></th>
                    </tr>
                
                    <tr id="fcbeb31de1656b08bd46af5c04bbe9cc1ad9a535">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fcbeb31de1656b08bd46af5c04bbe9cc1ad9a535">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Peng_RES-PCA_A_Scalable_Approach_to_Recovering_Low-Rank_Matrices_CVPR_2019_paper.html">RES-PCA: A Scalable Approach to Recovering Low-Rank Matrices</a></th>
                    </tr>
                
                    <tr id="f680419331ff8279ecba86bccd605d7ded9d245a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f680419331ff8279ecba86bccd605d7ded9d245a">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zisselman_A_Local_Block_Coordinate_Descent_Algorithm_for_the_CSC_Model_CVPR_2019_paper.html">A Local Block Coordinate Descent Algorithm for the CSC Model</a></th>
                    </tr>
                
                    <tr id="bddad24bb44902680e03b586985c0966878946e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bddad24bb44902680e03b586985c0966878946e1">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Conditional_Single-View_Shape_Generation_for_Multi-View_Stereo_Reconstruction_CVPR_2019_paper.html">Conditional Single-View Shape Generation for Multi-View Stereo Reconstruction</a></th>
                    </tr>
                
                    <tr id="8b5564d59e8326700cd5a905c79a9b39c9564c28">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b5564d59e8326700cd5a905c79a9b39c9564c28">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Taghanaki_A_Kernelized_Manifold_Mapping_to_Diminish_the_Effect_of_Adversarial_CVPR_2019_paper.html">A Kernelized Manifold Mapping to Diminish the Effect of Adversarial Perturbations</a></th>
                    </tr>
                
                    <tr id="9b72ba4b044f1cb92880cb363fe987845e160a9c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9b72ba4b044f1cb92880cb363fe987845e160a9c">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Machine_Vision_Guided_3D_Medical_Image_Compression_for_Efficient_Transmission_CVPR_2019_paper.html">Machine Vision Guided 3D Medical Image Compression for Efficient Transmission and Accurate Segmentation in the Clouds</a></th>
                    </tr>
                
                    <tr id="504fd8a5eec03ec865f43cae9886004ac7b96d67">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/504fd8a5eec03ec865f43cae9886004ac7b96d67">24</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Precognition/Sun_SuperTML_Two-Dimensional_Word_Embedding_for_the_Precognition_on_Structured_Tabular_CVPRW_2019_paper.html">SuperTML: Two-Dimensional Word Embedding for the Precognition on Structured Tabular Data</a></th>
                    </tr>
                
                    <tr id="a88e2508599342a886648ab2e858e8f3a87d1620">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a88e2508599342a886648ab2e858e8f3a87d1620">24</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PCV/Shimada_IsMo-GAN_Adversarial_Learning_for_Monocular_Non-Rigid_3D_Reconstruction_CVPRW_2019_paper.html">IsMo-GAN: Adversarial Learning for Monocular Non-Rigid 3D Reconstruction</a></th>
                    </tr>
                
                    <tr id="8445fa2b66bd1669cdf303b6313b041d5da247a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8445fa2b66bd1669cdf303b6313b041d5da247a9">24</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Cai_Temporal_Hockey_Action_Recognition_via_Pose_and_Optical_Flows_CVPRW_2019_paper.html">Temporal Hockey Action Recognition via Pose and Optical Flows</a></th>
                    </tr>
                
                    <tr id="a5a79b85162e296113067995e3ba9ad850ccf280">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a5a79b85162e296113067995e3ba9ad850ccf280">24</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/McNally_GolfDB_A_Video_Database_for_Golf_Swing_Sequencing_CVPRW_2019_paper.html">GolfDB: A Video Database for Golf Swing Sequencing</a></th>
                    </tr>
                
                    <tr id="9c8e1ba701c9ce4949d519e50ffc140d15ea85be">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c8e1ba701c9ce4949d519e50ffc140d15ea85be">24</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SkelNetOn/Demir_SkelNetOn_2019_Dataset_and_Challenge_on_Deep_Learning_for_Geometric_CVPRW_2019_paper.html">SkelNetOn 2019: Dataset and Challenge on Deep Learning for Geometric Shape Understanding</a></th>
                    </tr>
                
                    <tr id="90e141948786833a14f6d10f16b93f3984dd7717">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/90e141948786833a14f6d10f16b93f3984dd7717">24</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Liu_Hierarchical_Back_Projection_Network_for_Image_Super-Resolution_CVPRW_2019_paper.html">Hierarchical Back Projection Network for Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="ccc815030ae34ffa219eb3a27d3338de9f759964">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ccc815030ae34ffa219eb3a27d3338de9f759964">24</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Weakly_Supervised_Learning_for_RealWorld_Computer_Vision_Applications/Xu_Missing_Labels_in_Object_Detection_CVPRW_2019_paper.html">Missing Labels in Object Detection</a></th>
                    </tr>
                
                    <tr id="f428019763e827d4dae85b13036f9382f05f7f54">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f428019763e827d4dae85b13036f9382f05f7f54">24</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Zheng_VehicleNet_Learning_Robust_Feature_Representation_for_Vehicle_Re-identification_CVPRW_2019_paper.html">VehicleNet: Learning Robust Feature Representation for Vehicle Re-identification</a></th>
                    </tr>
                
                    <tr id="aa8fafebfbfe43cc867280b0c8de2ce35ffb81b8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aa8fafebfbfe43cc867280b0c8de2ce35ffb81b8">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mehta_On_Implicit_Filter_Level_Sparsity_in_Convolutional_Neural_Networks_CVPR_2019_paper.html">On Implicit Filter Level Sparsity in Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="54efdd4c03e47a11db7ef710b8dc87c70d34e529">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/54efdd4c03e47a11db7ef710b8dc87c70d34e529">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Nam_End-To-End_Time-Lapse_Video_Synthesis_From_a_Single_Outdoor_Image_CVPR_2019_paper.html">End-To-End Time-Lapse Video Synthesis From a Single Outdoor Image</a></th>
                    </tr>
                
                    <tr id="39d42d359acd84b05397c4f68106851ef177d3f6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39d42d359acd84b05397c4f68106851ef177d3f6">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Pan_Spatially_Variant_Linear_Representation_Models_for_Joint_Filtering_CVPR_2019_paper.html">Spatially Variant Linear Representation Models for Joint Filtering</a></th>
                    </tr>
                
                    <tr id="a701f5f889eb9849474ce40042b077b6f4771102">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a701f5f889eb9849474ce40042b077b6f4771102">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Hierarchy_Denoising_Recursive_Autoencoders_for_3D_Scene_Layout_Prediction_CVPR_2019_paper.html">Hierarchy Denoising Recursive Autoencoders for 3D Scene Layout Prediction</a></th>
                    </tr>
                
                    <tr id="93d6898f72598473c8650cf0425ad8dbfb2237ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/93d6898f72598473c8650cf0425ad8dbfb2237ac">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Joint_Representation_and_Estimator_Learning_for_Facial_Action_Unit_Intensity_CVPR_2019_paper.html">Joint Representation and Estimator Learning for Facial Action Unit Intensity Estimation</a></th>
                    </tr>
                
                    <tr id="ae91f6bdb73413a1c233bb22cb85bf2146d327ef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae91f6bdb73413a1c233bb22cb85bf2146d327ef">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Deep_Asymmetric_Metric_Learning_via_Rich_Relationship_Mining_CVPR_2019_paper.html">Deep Asymmetric Metric Learning via Rich Relationship Mining</a></th>
                    </tr>
                
                    <tr id="6bee682edc649778e8482a138d92c5657d23ea09">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6bee682edc649778e8482a138d92c5657d23ea09">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Synthesizing_3D_Shapes_From_Silhouette_Image_Collections_Using_Multi-Projection_Generative_CVPR_2019_paper.html">Synthesizing 3D Shapes From Silhouette Image Collections Using Multi-Projection Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="92366e3c446c30e4c783c61dcf420edd17695c73">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/92366e3c446c30e4c783c61dcf420edd17695c73">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fang_Modularized_Textual_Grounding_for_Counterfactual_Resilience_CVPR_2019_paper.html">Modularized Textual Grounding for Counterfactual Resilience</a></th>
                    </tr>
                
                    <tr id="17faab87b74d42e02b407c149c398c33ef4cfc0a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/17faab87b74d42e02b407c149c398c33ef4cfc0a">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Papadopoulos_How_to_Make_a_Pizza_Learning_a_Compositional_Layer-Based_GAN_CVPR_2019_paper.html">How to Make a Pizza: Learning a Compositional Layer-Based GAN Model</a></th>
                    </tr>
                
                    <tr id="b016ff1148e8bf8ffa1beb5c8cd89c644825edf2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b016ff1148e8bf8ffa1beb5c8cd89c644825edf2">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kanehira_Multimodal_Explanations_by_Predicting_Counterfactuality_in_Videos_CVPR_2019_paper.html">Multimodal Explanations by Predicting Counterfactuality in Videos</a></th>
                    </tr>
                
                    <tr id="f8142bdf3a50be3f641f508fb41d7d21421d68af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f8142bdf3a50be3f641f508fb41d7d21421d68af">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_3D_Appearance_Super-Resolution_With_Deep_Learning_CVPR_2019_paper.html">3D Appearance Super-Resolution With Deep Learning</a></th>
                    </tr>
                
                    <tr id="e7da564afdf8162489cbace970f26b239913d1f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e7da564afdf8162489cbace970f26b239913d1f1">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_R3_Adversarial_Network_for_Cross_Model_Face_Recognition_CVPR_2019_paper.html">R³ Adversarial Network for Cross Model Face Recognition</a></th>
                    </tr>
                
                    <tr id="730e906ff2f3ce3da874435298b844f9a763cfe0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/730e906ff2f3ce3da874435298b844f9a763cfe0">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_P2SGrad_Refined_Gradients_for_Optimizing_Deep_Face_Models_CVPR_2019_paper.html">P2SGrad: Refined Gradients for Optimizing Deep Face Models</a></th>
                    </tr>
                
                    <tr id="3aeaf0c52d2dc9b09478f5598429c6be8ef3745e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3aeaf0c52d2dc9b09478f5598429c6be8ef3745e">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Neverova_Slim_DensePose_Thrifty_Learning_From_Sparse_Annotations_and_Motion_Cues_CVPR_2019_paper.html">Slim DensePose: Thrifty Learning From Sparse Annotations and Motion Cues</a></th>
                    </tr>
                
                    <tr id="badaab2798fbe4f5621280ea5f0705ea8ad56683">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/badaab2798fbe4f5621280ea5f0705ea8ad56683">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Eilertsen_Single-Frame_Regularization_for_Temporally_Stable_CNNs_CVPR_2019_paper.html">Single-Frame Regularization for Temporally Stable CNNs</a></th>
                    </tr>
                
                    <tr id="10e86b11162c3bf4e3cf3ae30f602ec070de8c4b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/10e86b11162c3bf4e3cf3ae30f602ec070de8c4b">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Geneva_An_Efficient_Schmidt-EKF_for_3D_Visual-Inertial_SLAM_CVPR_2019_paper.html">An Efficient Schmidt-EKF for 3D Visual-Inertial SLAM</a></th>
                    </tr>
                
                    <tr id="05cd8f648e8d9ddc22f5f7ed818d6d2ca9220212">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05cd8f648e8d9ddc22f5f7ed818d6d2ca9220212">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yedidia_Using_Unknown_Occluders_to_Recover_Hidden_Scenes_CVPR_2019_paper.html">Using Unknown Occluders to Recover Hidden Scenes</a></th>
                    </tr>
                
                    <tr id="96cce59a04ed03a4aeb1ca4f8306c6d193cab1e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96cce59a04ed03a4aeb1ca4f8306c6d193cab1e6">23</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Moosbauer_A_Benchmark_for_Deep_Learning_Based_Object_Detection_in_Maritime_CVPRW_2019_paper.html">A Benchmark for Deep Learning Based Object Detection in Maritime Environments</a></th>
                    </tr>
                
                    <tr id="5bdce72bb7a649a11e883fcf5d4c24902ce6a436">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5bdce72bb7a649a11e883fcf5d4c24902ce6a436">23</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Liu_Pose-Guided_R-CNN_for_Jersey_Number_Recognition_in_Sports_CVPRW_2019_paper.html">Pose-Guided R-CNN for Jersey Number Recognition in Sports</a></th>
                    </tr>
                
                    <tr id="1ef445433fa8653e0fa4d58a0cdc48535db16877">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ef445433fa8653e0fa4d58a0cdc48535db16877">23</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Dobrescu_Understanding_Deep_Neural_Networks_for_Regression_in_Leaf_Counting_CVPRW_2019_paper.html">Understanding Deep Neural Networks for Regression in Leaf Counting</a></th>
                    </tr>
                
                    <tr id="10d8c854a366b05433a41c59cc1efd13e8a93214">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/10d8c854a366b05433a41c59cc1efd13e8a93214">23</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MBCCV/Zelinsky_Benchmarking_Gaze_Prediction_for_Categorical_Visual_Search_CVPRW_2019_paper.html">Benchmarking Gaze Prediction for Categorical Visual Search</a></th>
                    </tr>
                
                    <tr id="371d69fc3cebd7c2d4544e706d129a57566d713e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/371d69fc3cebd7c2d4544e706d129a57566d713e">23</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/Rudovic_Personalized_Estimation_of_Engagement_From_Videos_Using_Active_Learning_With_CVPRW_2019_paper.html">Personalized Estimation of Engagement From Videos Using Active Learning With Deep Reinforcement Learning</a></th>
                    </tr>
                
                    <tr id="098d7a729c7df5a47e83179e056a00101d74b90f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/098d7a729c7df5a47e83179e056a00101d74b90f">23</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Nah_NTIRE_2019_Challenge_on_Video_Super-Resolution_Methods_and_Results_CVPRW_2019_paper.html">NTIRE 2019 Challenge on Video Super-Resolution: Methods and Results</a></th>
                    </tr>
                
                    <tr id="ffa0b4f49326015150c05d63146b9d8aaaf34609">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ffa0b4f49326015150c05d63146b9d8aaaf34609">23</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/Chidester_Enhanced_Rotation-Equivariant_U-Net_for_Nuclear_Segmentation_CVPRW_2019_paper.html">Enhanced Rotation-Equivariant U-Net for Nuclear Segmentation</a></th>
                    </tr>
                
                    <tr id="a99a52935ae8e480fa80f06e8e87e3de67649ed5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a99a52935ae8e480fa80f06e8e87e3de67649ed5">23</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CFS/Wang_Multi-Modal_Face_Presentation_Attack_Detection_via_Spatial_and_Channel_Attentions_CVPRW_2019_paper.html">Multi-Modal Face Presentation Attack Detection via Spatial and Channel Attentions</a></th>
                    </tr>
                
                    <tr id="0d185f5df8e252bac0e23d08d7083190a6e64c1c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0d185f5df8e252bac0e23d08d7083190a6e64c1c">23</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/DOAI/Li_Learning_Object-Wise_Semantic_Representation_for_Detection_in_Remote_Sensing_Imagery_CVPRW_2019_paper.html">Learning Object-Wise Semantic Representation for Detection in Remote Sensing Imagery</a></th>
                    </tr>
                
                    <tr id="6807c7e11880559183d8e04422cce7216f746802">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6807c7e11880559183d8e04422cce7216f746802">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Atapour-Abarghouei_Veritatem_Dies_Aperit_-_Temporally_Consistent_Depth_Prediction_Enabled_by_CVPR_2019_paper.html">Veritatem Dies Aperit - Temporally Consistent Depth Prediction Enabled by a Multi-Task Geometric and Semantic Scene Understanding Approach</a></th>
                    </tr>
                
                    <tr id="d79c26d99853590354dac3a991c530b27a6eff39">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d79c26d99853590354dac3a991c530b27a6eff39">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kokkinos_Iterative_Residual_CNNs_for_Burst_Photography_Applications_CVPR_2019_paper.html">Iterative Residual CNNs for Burst Photography Applications</a></th>
                    </tr>
                
                    <tr id="ab7498e6e64168533b33dd377065ff084835c720">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ab7498e6e64168533b33dd377065ff084835c720">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Meirovitch_Cross-Classification_Clustering_An_Efficient_Multi-Object_Tracking_Technique_for_3-D_Instance_CVPR_2019_paper.html">Cross-Classification Clustering: An Efficient Multi-Object Tracking Technique for 3-D Instance Segmentation in Connectomics</a></th>
                    </tr>
                
                    <tr id="4dbf9b8b1c2c7764d70444eb36a13133b557605f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4dbf9b8b1c2c7764d70444eb36a13133b557605f">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Khan_Unsupervised_Primitive_Discovery_for_Improved_3D_Generative_Modeling_CVPR_2019_paper.html">Unsupervised Primitive Discovery for Improved 3D Generative Modeling</a></th>
                    </tr>
                
                    <tr id="0204d7bdfeb131788f6da6202296124aea2f0c65">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0204d7bdfeb131788f6da6202296124aea2f0c65">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Birdal_Probabilistic_Permutation_Synchronization_Using_the_Riemannian_Structure_of_the_Birkhoff_CVPR_2019_paper.html">Probabilistic Permutation Synchronization Using the Riemannian Structure of the Birkhoff Polytope</a></th>
                    </tr>
                
                    <tr id="bb1a33064948bd81d23ec079900df4a24c7f0263">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bb1a33064948bd81d23ec079900df4a24c7f0263">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lin_Robustness_Verification_of_Classification_Deep_Neural_Networks_via_Linear_Programming_CVPR_2019_paper.html">Robustness Verification of Classification Deep Neural Networks via Linear Programming</a></th>
                    </tr>
                
                    <tr id="db30fce2fec76c17dfd7a65f8b739855d033255e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db30fce2fec76c17dfd7a65f8b739855d033255e">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_R2GAN_Cross-Modal_Recipe_Retrieval_With_Generative_Adversarial_Network_CVPR_2019_paper.html">R²GAN: Cross-Modal Recipe Retrieval With Generative Adversarial Network</a></th>
                    </tr>
                
                    <tr id="46be558348f397e1c4dc6f33a07b0c3bbbeaa8d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/46be558348f397e1c4dc6f33a07b0c3bbbeaa8d4">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gomez-Villa_Convolutional_Neural_Networks_Can_Be_Deceived_by_Visual_Illusions_CVPR_2019_paper.html">Convolutional Neural Networks Can Be Deceived by Visual Illusions</a></th>
                    </tr>
                
                    <tr id="96fd1e38f3469ad067501de20a59f930e2b08d52">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96fd1e38f3469ad067501de20a59f930e2b08d52">22</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Giuffrida_Leaf_Counting_Without_Annotations_Using_Adversarial_Unsupervised_Domain_Adaptation_CVPRW_2019_paper.html">Leaf Counting Without Annotations Using Adversarial Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="a04e62f1e80921211decdb3780eb2435e4b977cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a04e62f1e80921211decdb3780eb2435e4b977cd">22</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SAIAD/Rottmann_Uncertainty_Measures_and_Prediction_Quality_Rating_for_the_Semantic_Segmentation_CVPRW_2019_paper.html">Uncertainty Measures and Prediction Quality Rating for the Semantic Segmentation of Nested Multi Resolution Street Scene Images</a></th>
                    </tr>
                
                    <tr id="1aeb16afe52f278a60fcdef0b0af06499eabd640">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1aeb16afe52f278a60fcdef0b0af06499eabd640">22</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/TRMTMCT/Bao_Masked_Graph_Attention_Network_for_Person_Re-Identification_CVPRW_2019_paper.html">Masked Graph Attention Network for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="a44f701becad31366c2680d0f0feb3aaae7aa6d6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a44f701becad31366c2680d0f0feb3aaae7aa6d6">22</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Cheng_DET_A_High-Resolution_DVS_Dataset_for_Lane_Extraction_CVPRW_2019_paper.html">DET: A High-Resolution DVS Dataset for Lane Extraction</a></th>
                    </tr>
                
                    <tr id="0c6781f3d7be421e24e16f8ba24bf1e1f687cb23">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c6781f3d7be421e24e16f8ba24bf1e1f687cb23">22</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Ren_Deep_Robust_Single_Image_Depth_Estimation_Neural_Network_Using_Scene_CVPRW_2019_paper.html">Deep Robust Single Image Depth Estimation Neural Network Using Scene Understanding</a></th>
                    </tr>
                
                    <tr id="83a08ea76feee1db77e249b21a50cc1b2fbc30e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/83a08ea76feee1db77e249b21a50cc1b2fbc30e3">22</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Gundavarapu_Structured_Aleatoric_Uncertainty_in_Human_Pose_Estimation_CVPRW_2019_paper.html">Structured Aleatoric Uncertainty in Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="904e87016be6ba344e1d5df074e28dcfd4a48e8a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/904e87016be6ba344e1d5df074e28dcfd4a48e8a">22</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SUMO/Eder_Convolutions_on_Spherical_Images_CVPRW_2019_paper.html">Convolutions on Spherical Images</a></th>
                    </tr>
                
                    <tr id="7de447359f5d6083536f11f0bc466b9d4b82f8c6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7de447359f5d6083536f11f0bc466b9d4b82f8c6">22</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Piaggesi_Predicting_City_Poverty_Using_Satellite_Imagery_CVPRW_2019_paper.html">Predicting City Poverty Using Satellite Imagery</a></th>
                    </tr>
                
                    <tr id="b6b6e255cb68ed85e9b2ec23f38916ce6f236969">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b6b6e255cb68ed85e9b2ec23f38916ce6f236969">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Huh_Feedback_Adversarial_Learning_Spatial_Feedback_for_Improving_Generative_Adversarial_Networks_CVPR_2019_paper.html">Feedback Adversarial Learning: Spatial Feedback for Improving Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="a1018fd41aafd18f1536aee6c8dfd1fb85c32e67">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a1018fd41aafd18f1536aee6c8dfd1fb85c32e67">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Inverse_Discriminative_Networks_for_Handwritten_Signature_Verification_CVPR_2019_paper.html">Inverse Discriminative Networks for Handwritten Signature Verification</a></th>
                    </tr>
                
                    <tr id="e78901680fd7eddfcd6234f1890984ab073be90c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e78901680fd7eddfcd6234f1890984ab073be90c">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Donne_Learning_Non-Volumetric_Depth_Fusion_Using_Successive_Reprojections_CVPR_2019_paper.html">Learning Non-Volumetric Depth Fusion Using Successive Reprojections</a></th>
                    </tr>
                
                    <tr id="db3ebd7062b045ec61b4df15eace9a2b088adeae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db3ebd7062b045ec61b4df15eace9a2b088adeae">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chang_Explore-Exploit_Graph_Traversal_for_Image_Retrieval_CVPR_2019_paper.html">Explore-Exploit Graph Traversal for Image Retrieval</a></th>
                    </tr>
                
                    <tr id="9a5f24aa976ee008062a6676fce9a4a88e35b971">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9a5f24aa976ee008062a6676fce9a4a88e35b971">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Tightness-Aware_Evaluation_Protocol_for_Scene_Text_Detection_CVPR_2019_paper.html">Tightness-Aware Evaluation Protocol for Scene Text Detection</a></th>
                    </tr>
                
                    <tr id="0196e1969c6eb2f2de02a630a14385a825156a79">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0196e1969c6eb2f2de02a630a14385a825156a79">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yang_A_Variational_EM_Framework_With_Adaptive_Edge_Selection_for_Blind_CVPR_2019_paper.html">A Variational EM Framework With Adaptive Edge Selection for Blind Motion Deblurring</a></th>
                    </tr>
                
                    <tr id="9288d6996978d512b1199d3f84572e380f4620b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9288d6996978d512b1199d3f84572e380f4620b5">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Learning_to_Localize_Through_Compressed_Binary_Maps_CVPR_2019_paper.html">Learning to Localize Through Compressed Binary Maps</a></th>
                    </tr>
                
                    <tr id="be23cdcd2135a6f20b527fdba78d15da40e4653c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/be23cdcd2135a6f20b527fdba78d15da40e4653c">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Goel_An_End-To-End_Network_for_Generating_Social_Relationship_Graphs_CVPR_2019_paper.html">An End-To-End Network for Generating Social Relationship Graphs</a></th>
                    </tr>
                
                    <tr id="ee2ba264682d92a369d75b9a600948d314568e80">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ee2ba264682d92a369d75b9a600948d314568e80">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhu_Sim-Real_Joint_Reinforcement_Transfer_for_3D_Indoor_Navigation_CVPR_2019_paper.html">Sim-Real Joint Reinforcement Transfer for 3D Indoor Navigation</a></th>
                    </tr>
                
                    <tr id="2be5e50e966590dbd7317e4d3ecb89707439fa5a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2be5e50e966590dbd7317e4d3ecb89707439fa5a">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Data-Driven_Neuron_Allocation_for_Scale_Aggregation_Networks_CVPR_2019_paper.html">Data-Driven Neuron Allocation for Scale Aggregation Networks</a></th>
                    </tr>
                
                    <tr id="e449052350b9e5940c714a33ebf8e6c9575b05fd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e449052350b9e5940c714a33ebf8e6c9575b05fd">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Campbell_The_Alignment_of_the_Spheres_Globally-Optimal_Spherical_Mixture_Alignment_for_CVPR_2019_paper.html">The Alignment of the Spheres: Globally-Optimal Spherical Mixture Alignment for Camera Pose Estimation</a></th>
                    </tr>
                
                    <tr id="152c11700a6924e94955f6cf00b5a7522b406ec3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/152c11700a6924e94955f6cf00b5a7522b406ec3">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yuan_Zoom-In-To-Check_Boosting_Video_Interpolation_via_Instance-Level_Discrimination_CVPR_2019_paper.html">Zoom-In-To-Check: Boosting Video Interpolation via Instance-Level Discrimination</a></th>
                    </tr>
                
                    <tr id="0373d38906018c5dc704bc180575ddeeba4c7170">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0373d38906018c5dc704bc180575ddeeba4c7170">21</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/VOCVALC/Rashed_Motion_and_Depth_Augmented_Semantic_Segmentation_for_Autonomous_Navigation_CVPRW_2019_paper.html">Motion and Depth Augmented Semantic Segmentation for Autonomous Navigation</a></th>
                    </tr>
                
                    <tr id="db48fa731066c97714a5e48f48d0e9a526f547ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db48fa731066c97714a5e48f48d0e9a526f547ac">21</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Cioppa_ARTHuS_Adaptive_Real-Time_Human_Segmentation_in_Sports_Through_Online_Distillation_CVPRW_2019_paper.html">ARTHuS: Adaptive Real-Time Human Segmentation in Sports Through Online Distillation</a></th>
                    </tr>
                
                    <tr id="79dff8ec372f8fbb9c23fde41d71f76ea71732b6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/79dff8ec372f8fbb9c23fde41d71f76ea71732b6">21</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Zabawa_Detection_of_Single_Grapevine_Berries_in_Images_Using_Fully_Convolutional_CVPRW_2019_paper.html">Detection of Single Grapevine Berries in Images Using Fully Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="720ae451fc261331fdcb104a8b7e5ee6f4936181">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/720ae451fc261331fdcb104a8b7e5ee6f4936181">21</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Nellithimaru_ROLS__Robust_Object-Level_SLAM_for_Grape_Counting_CVPRW_2019_paper.html">ROLS : Robust Object-Level SLAM for Grape Counting</a></th>
                    </tr>
                
                    <tr id="a3b01e84a43a9ca9389b6e05fbc59922d8b485d9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a3b01e84a43a9ca9389b6e05fbc59922d8b485d9">21</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/Kumawat_LBVCNN_Local_Binary_Volume_Convolutional_Neural_Network_for_Facial_Expression_CVPRW_2019_paper.html">LBVCNN: Local Binary Volume Convolutional Neural Network for Facial Expression Recognition From Image Sequences</a></th>
                    </tr>
                
                    <tr id="61086a67cf29acff5cf64938ba3d45a3a5bda9f8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61086a67cf29acff5cf64938ba3d45a3a5bda9f8">21</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/Liu_Understanding_Beauty_via_Deep_Facial_Features_CVPRW_2019_paper.html">Understanding Beauty via Deep Facial Features</a></th>
                    </tr>
                
                    <tr id="7b1c6f0a6441f620717f7e2590b5771a33cd52f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b1c6f0a6441f620717f7e2590b5771a33cd52f9">21</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Wu_6D-VNet_End-To-End_6-DoF_Vehicle_Pose_Estimation_From_Monocular_RGB_Images_CVPRW_2019_paper.html">6D-VNet: End-To-End 6-DoF Vehicle Pose Estimation From Monocular RGB Images</a></th>
                    </tr>
                
                    <tr id="cd40da0e80d029574a1b4e88a3fe62122519f0d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd40da0e80d029574a1b4e88a3fe62122519f0d4">21</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Han_Unsupervised_Domain_Adaptation_via_Calibrating_Uncertainties_CVPRW_2019_paper.html">Unsupervised Domain Adaptation via Calibrating Uncertainties</a></th>
                    </tr>
                
                    <tr id="7b1c6f0a6441f620717f7e2590b5771a33cd52f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b1c6f0a6441f620717f7e2590b5771a33cd52f9">21</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Wu_6D-VNet_End-to-End_6-DoF_Vehicle_Pose_Estimation_From_Monocular_RGB_Images_CVPRW_2019_paper.html">6D-VNet: End-to-End 6-DoF Vehicle Pose Estimation From Monocular RGB Images</a></th>
                    </tr>
                
                    <tr id="ab823cbcc22216161f16f63264ee127bcb5a12f7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ab823cbcc22216161f16f63264ee127bcb5a12f7">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yu_Thinking_Outside_the_Pool_Active_Training_Image_Creation_for_Relative_CVPR_2019_paper.html">Thinking Outside the Pool: Active Training Image Creation for Relative Attributes</a></th>
                    </tr>
                
                    <tr id="4ec5fc8daf92dec2b086a98e34429f99ec716c94">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ec5fc8daf92dec2b086a98e34429f99ec716c94">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Deep_Sketch-Shape_Hashing_With_Segmented_3D_Stochastic_Viewing_CVPR_2019_paper.html">Deep Sketch-Shape Hashing With Segmented 3D Stochastic Viewing</a></th>
                    </tr>
                
                    <tr id="b27a78586893030a5b85ef53adc65a5127131f2b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b27a78586893030a5b85ef53adc65a5127131f2b">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Bansal_Shapes_and_Context_In-The-Wild_Image_Synthesis__Manipulation_CVPR_2019_paper.html">Shapes and Context: In-The-Wild Image Synthesis &amp; Manipulation</a></th>
                    </tr>
                
                    <tr id="83f500cc63c446a2c897122008e3d9295cad21bd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/83f500cc63c446a2c897122008e3d9295cad21bd">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Abolghasemi_Pay_Attention_-_Robustifying_a_Deep_Visuomotor_Policy_Through_Task-Focused_CVPR_2019_paper.html">Pay Attention! - Robustifying a Deep Visuomotor Policy Through Task-Focused Visual Attention</a></th>
                    </tr>
                
                    <tr id="f3c790ebb1458d2de7b453ce0ccf26c16be6e83c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f3c790ebb1458d2de7b453ce0ccf26c16be6e83c">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Thoma_Mapping_Localization_and_Path_Planning_for_Image-Based_Navigation_Using_Visual_CVPR_2019_paper.html">Mapping, Localization and Path Planning for Image-Based Navigation Using Visual Features and Map</a></th>
                    </tr>
                
                    <tr id="fd6e197b1f19db9db11bf99c2732fbc8bfb8018a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fd6e197b1f19db9db11bf99c2732fbc8bfb8018a">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Normalized_Diversification_CVPR_2019_paper.html">Normalized Diversification</a></th>
                    </tr>
                
                    <tr id="276bf57be32852f14958ec2d88633e9290faf609">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/276bf57be32852f14958ec2d88633e9290faf609">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jiang_Data_Representation_and_Learning_With_Graph_Diffusion-Embedding_Networks_CVPR_2019_paper.html">Data Representation and Learning With Graph Diffusion-Embedding Networks</a></th>
                    </tr>
                
                    <tr id="7993861b4be581e5c91e094fa991c7023dd07bb4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7993861b4be581e5c91e094fa991c7023dd07bb4">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Heim_Constrained_Generative_Adversarial_Networks_for_Interactive_Image_Generation_CVPR_2019_paper.html">Constrained Generative Adversarial Networks for Interactive Image Generation</a></th>
                    </tr>
                
                    <tr id="05d112c01cd7a71dbf6ef9d3a7c352cac69951ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05d112c01cd7a71dbf6ef9d3a7c352cac69951ce">20</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Majumdar_Evading_Face_Recognition_via_Partial_Tampering_of_Faces_CVPRW_2019_paper.html">Evading Face Recognition via Partial Tampering of Faces</a></th>
                    </tr>
                
                    <tr id="76a7f3e2e00b26747de645b422efd0b24634b771">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/76a7f3e2e00b26747de645b422efd0b24634b771">20</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Mazaheri_A_Skip_Connection_Architecture_for_Localization_of_Image_Manipulations_CVPRW_2019_paper.html">A Skip Connection Architecture for Localization of Image Manipulations</a></th>
                    </tr>
                
                    <tr id="860f080c6f671c40d8fca7c97bf7a892387138ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/860f080c6f671c40d8fca7c97bf7a892387138ad">20</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Nguyen_Vehicle_Re-identification_with_Learned_Representation_and_Spatial_Verification_and_Abnormality_CVPRW_2019_paper.html">Vehicle Re-identification with Learned Representation and Spatial Verification and Abnormality Detection with Multi-Adaptive Vehicle Detectors for Traffic Video Analysis</a></th>
                    </tr>
                
                    <tr id="3ba9fdcd0d10f2a130fcbd678cebcbb5e8c6bd5f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ba9fdcd0d10f2a130fcbd678cebcbb5e8c6bd5f">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qiao_Neural_Rejuvenation_Improving_Deep_Network_Training_by_Enhancing_Computational_Resource_CVPR_2019_paper.html">Neural Rejuvenation: Improving Deep Network Training by Enhancing Computational Resource Utilization</a></th>
                    </tr>
                
                    <tr id="43842c5f210c66d587fa959cd7fbd0a19a014228">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/43842c5f210c66d587fa959cd7fbd0a19a014228">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_AOGNets_Compositional_Grammatical_Architectures_for_Deep_Learning_CVPR_2019_paper.html">AOGNets: Compositional Grammatical Architectures for Deep Learning</a></th>
                    </tr>
                
                    <tr id="84f6aa9d4e2007de15e92a84a97387086e612b70">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/84f6aa9d4e2007de15e92a84a97387086e612b70">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Mutual_Learning_of_Complementary_Networks_via_Residual_Correction_for_Improving_CVPR_2019_paper.html">Mutual Learning of Complementary Networks via Residual Correction for Improving Semi-Supervised Classification</a></th>
                    </tr>
                
                    <tr id="537ae82c5e1ccc4f5118e7fbd7903f45d349dc5f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/537ae82c5e1ccc4f5118e7fbd7903f45d349dc5f">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fan_Online_High_Rank_Matrix_Completion_CVPR_2019_paper.html">Online High Rank Matrix Completion</a></th>
                    </tr>
                
                    <tr id="f9d5df0a7132892b7a0635ee7c73ad0acf2cda55">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f9d5df0a7132892b7a0635ee7c73ad0acf2cda55">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yokozuka_VITAMIN-E_VIsual_Tracking_and_MappINg_With_Extremely_Dense_Feature_Points_CVPR_2019_paper.html">VITAMIN-E: VIsual Tracking and MappINg With Extremely Dense Feature Points</a></th>
                    </tr>
                
                    <tr id="7285d08ccf70bab92156c9e79935bbcebdf1d92d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7285d08ccf70bab92156c9e79935bbcebdf1d92d">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EarthVision/Daudt_Guided_Anisotropic_Diffusion_and_Iterative_Learning_for_Weakly_Supervised_Change_CVPRW_2019_paper.html">Guided Anisotropic Diffusion and Iterative Learning for Weakly Supervised Change Detection</a></th>
                    </tr>
                
                    <tr id="8cd70c0d531a2155bc1f4bd36e1feaf254a09e1f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8cd70c0d531a2155bc1f4bd36e1feaf254a09e1f">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Sarkar_Generation_of_Ball_Possession_Statistics_in_Soccer_Using_Minimum-Cost_Flow_CVPRW_2019_paper.html">Generation of Ball Possession Statistics in Soccer Using Minimum-Cost Flow Network</a></th>
                    </tr>
                
                    <tr id="942942c74fb0230207ef1640144e885e5cfe76d3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/942942c74fb0230207ef1640144e885e5cfe76d3">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/Roitberg_Analysis_of_Deep_Fusion_Strategies_for_Multi-Modal_Gesture_Recognition_CVPRW_2019_paper.html">Analysis of Deep Fusion Strategies for Multi-Modal Gesture Recognition</a></th>
                    </tr>
                
                    <tr id="4aee76d44af0337b0f53a899ae747984288ee0d1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4aee76d44af0337b0f53a899ae747984288ee0d1">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Zeng_Deep_Graph_Laplacian_Regularization_for_Robust_Denoising_of_Real_Images_CVPRW_2019_paper.html">Deep Graph Laplacian Regularization for Robust Denoising of Real Images</a></th>
                    </tr>
                
                    <tr id="82e9f74b48422cd20c08d5f499299ffeb81e829f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/82e9f74b48422cd20c08d5f499299ffeb81e829f">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Morales_Feature_Forwarding_for_Efficient_Single_Image_Dehazing_CVPRW_2019_paper.html">Feature Forwarding for Efficient Single Image Dehazing</a></th>
                    </tr>
                
                    <tr id="9d8d85a473cc8887c004a7f39c4e5a54d7a46c17">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9d8d85a473cc8887c004a7f39c4e5a54d7a46c17">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Yadav_Detecting_Textured_Contact_Lens_in_Uncontrolled_Environment_Using_DensePAD_CVPRW_2019_paper.html">Detecting Textured Contact Lens in Uncontrolled Environment Using DensePAD</a></th>
                    </tr>
                
                    <tr id="71b35562df0977a8de9cd13b5bbd3ed553df612f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/71b35562df0977a8de9cd13b5bbd3ed553df612f">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Yaman_Multimodal_Age_and_Gender_Classification_Using_Ear_and_Profile_Face_CVPRW_2019_paper.html">Multimodal Age and Gender Classification Using Ear and Profile Face Images</a></th>
                    </tr>
                
                    <tr id="7b0a3a1c97468d23004d88544aa5abe6dfa5a7ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b0a3a1c97468d23004d88544aa5abe6dfa5a7ff">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Yadav_Synthesizing_Iris_Images_Using_RaSGAN_With_Application_in_Presentation_Attack_CVPRW_2019_paper.html">Synthesizing Iris Images Using RaSGAN With Application in Presentation Attack Detection</a></th>
                    </tr>
                
                    <tr id="a99cd6c2ff547c8c79e8d7a8745808f4a54cde93">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a99cd6c2ff547c8c79e8d7a8745808f4a54cde93">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Renner_Event-Based_Attention_and_Tracking_on_Neuromorphic_Hardware_CVPRW_2019_paper.html">Event-Based Attention and Tracking on Neuromorphic Hardware</a></th>
                    </tr>
                
                    <tr id="93782401659fe26faef7e5f3b84ff632a12da47f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/93782401659fe26faef7e5f3b84ff632a12da47f">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Long_A_Coarse-to-fine_Deep_Convolutional_Neural_Network_Framework_for_Frame_Duplication_CVPRW_2019_paper.html">A Coarse-to-fine Deep Convolutional Neural Network Framework for Frame Duplication Detection and Localization in Forged Videos</a></th>
                    </tr>
                
                    <tr id="7c25fe4436257d6dc95428c44ac2ad2cf3ef0bf0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c25fe4436257d6dc95428c44ac2ad2cf3ef0bf0">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Biradar_Challenges_in_Time-Stamp_Aware_Anomaly_Detection_in_Traffic_Videos_CVPRW_2019_paper.html">Challenges in Time-Stamp Aware Anomaly Detection in Traffic Videos</a></th>
                    </tr>
                
                    <tr id="7801e5e80c411a13bc034a97f75bb99f1e03555b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7801e5e80c411a13bc034a97f75bb99f1e03555b">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Zhou_Multi-scale_and_Context-adaptive_Entropy_Model_for_Image_Compression_CVPRW_2019_paper.html">Multi-scale and Context-adaptive Entropy Model for Image Compression</a></th>
                    </tr>
                
                    <tr id="fcfbbcbdb0e14c5ea84cce6799adcadeaec794f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fcfbbcbdb0e14c5ea84cce6799adcadeaec794f1">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Nam_Strand-Accurate_Multi-View_Hair_Capture_CVPR_2019_paper.html">Strand-Accurate Multi-View Hair Capture</a></th>
                    </tr>
                
                    <tr id="7155c0863cf5c5fc2a21571f8b8a4110248e0977">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7155c0863cf5c5fc2a21571f8b8a4110248e0977">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Morgado_NetTailor_Tuning_the_Architecture_Not_Just_the_Weights_CVPR_2019_paper.html">NetTailor: Tuning the Architecture, Not Just the Weights</a></th>
                    </tr>
                
                    <tr id="9f9642ad3b57c69ff98bbb9210dca0768be610d6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9f9642ad3b57c69ff98bbb9210dca0768be610d6">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Muralikrishnan_Shape_Unicode_A_Unified_Shape_Representation_CVPR_2019_paper.html">Shape Unicode: A Unified Shape Representation</a></th>
                    </tr>
                
                    <tr id="d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d61bd9bc9a09731bcdfb7c84ef57b71ebb06a1e3">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cordel_Emotion-Aware_Human_Attention_Prediction_CVPR_2019_paper.html">Emotion-Aware Human Attention Prediction</a></th>
                    </tr>
                
                    <tr id="12c244c6686523f06ec2aedc5bd6e9060512aefc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/12c244c6686523f06ec2aedc5bd6e9060512aefc">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Corneanu_What_Does_It_Mean_to_Learn_in_Deep_Networks_And_CVPR_2019_paper.html">What does it mean to learn in deep networks ? And , how does one detect adversarial attacks ?</a></th>
                    </tr>
                
                    <tr id="b95c5751e8b37b738cebec39b42e334b324f8fbe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b95c5751e8b37b738cebec39b42e334b324f8fbe">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Efficient_Multi-Domain_Learning_by_Covariance_Normalization_CVPR_2019_paper.html">Efficient Multi-Domain Learning by Covariance Normalization</a></th>
                    </tr>
                
                    <tr id="71eb9810c779b29c745a8c151449fd2d80adf8d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/71eb9810c779b29c745a8c151449fd2d80adf8d4">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cao_Learning_Independent_Object_Motion_From_Unlabelled_Stereoscopic_Videos_CVPR_2019_paper.html">Learning Independent Object Motion From Unlabelled Stereoscopic Videos</a></th>
                    </tr>
                
                    <tr id="a56065201159c33ab5bda585fd2286764eab15a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a56065201159c33ab5bda585fd2286764eab15a5">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mu_Led3D_A_Lightweight_and_Efficient_Deep_Approach_to_Recognizing_Low-Quality_CVPR_2019_paper.html">Led3D: A Lightweight and Efficient Deep Approach to Recognizing Low-Quality 3D Faces</a></th>
                    </tr>
                
                    <tr id="3a7ea7e87f92e517666ae2a87801b2464e8d50d8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3a7ea7e87f92e517666ae2a87801b2464e8d50d8">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Riegler_Connecting_the_Dots_Learning_Representations_for_Active_Monocular_Depth_Estimation_CVPR_2019_paper.html">Connecting the Dots: Learning Representations for Active Monocular Depth Estimation</a></th>
                    </tr>
                
                    <tr id="220ee8f3abbe035a11399a1e0c543dd94cd63f26">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/220ee8f3abbe035a11399a1e0c543dd94cd63f26">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Object_Detection_With_Location-Aware_Deformable_Convolution_and_Backward_Attention_Filtering_CVPR_2019_paper.html">Object Detection With Location-Aware Deformable Convolution and Backward Attention Filtering</a></th>
                    </tr>
                
                    <tr id="aa1114e99a0dc50bff7d85da45aa8b37ce2ab517">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aa1114e99a0dc50bff7d85da45aa8b37ce2ab517">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Neuro-Inspired_Eye_Tracking_With_Eye_Movement_Dynamics_CVPR_2019_paper.html">Neuro-Inspired Eye Tracking With Eye Movement Dynamics</a></th>
                    </tr>
                
                    <tr id="51dc431a81507f117eba433f72f05f08db479dcf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/51dc431a81507f117eba433f72f05f08db479dcf">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wu_Enhancing_TripleGAN_for_Semi-Supervised_Conditional_Instance_Synthesis_and_Classification_CVPR_2019_paper.html">Enhancing TripleGAN for Semi-Supervised Conditional Instance Synthesis and Classification</a></th>
                    </tr>
                
                    <tr id="73bbd0b53044e9f518a3596a3607521bbce12fc2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/73bbd0b53044e9f518a3596a3607521bbce12fc2">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Marin_Beyond_Gradient_Descent_for_Regularized_Segmentation_Losses_CVPR_2019_paper.html">Beyond Gradient Descent for Regularized Segmentation Losses</a></th>
                    </tr>
                
                    <tr id="88cb92934f9ba8a9e7052870b1dd8d0bd9ad7b3d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/88cb92934f9ba8a9e7052870b1dd8d0bd9ad7b3d">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Minnehan_Cascaded_Projection_End-To-End_Network_Compression_and_Acceleration_CVPR_2019_paper.html">Cascaded Projection: End-To-End Network Compression and Acceleration</a></th>
                    </tr>
                
                    <tr id="4eea7f5b0e1365eb7f7354626cc2acb3701e84d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4eea7f5b0e1365eb7f7354626cc2acb3701e84d2">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Precognition/Neumann_Future_Event_Prediction_If_and_When_CVPRW_2019_paper.html">Future Event Prediction: If and When</a></th>
                    </tr>
                
                    <tr id="8495faedf3da3b9f639fa97904931ecb96017101">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8495faedf3da3b9f639fa97904931ecb96017101">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Jalal_SIDOD_A_Synthetic_Image_Dataset_for_3D_Object_Pose_Recognition_CVPRW_2019_paper.html">SIDOD: A Synthetic Image Dataset for 3D Object Pose Recognition With Distractors</a></th>
                    </tr>
                
                    <tr id="cf362e7d3d2c4beb1f383ccb7fc96fe64bcd57cf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cf362e7d3d2c4beb1f383ccb7fc96fe64bcd57cf">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SkelNetOn/Panichev_U-Net_Based_Convolutional_Neural_Network_for_Skeleton_Extraction_CVPRW_2019_paper.html">U-Net Based Convolutional Neural Network for Skeleton Extraction</a></th>
                    </tr>
                
                    <tr id="b0943a3f7e755af18ad91a84798254a7df37ffae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b0943a3f7e755af18ad91a84798254a7df37ffae">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Guo_Dense_123_Color_Enhancement_Dehazing_Network_CVPRW_2019_paper.html">Dense `123&#39; Color Enhancement Dehazing Network</a></th>
                    </tr>
                
                    <tr id="fed376b4e253e08b6deeb43209cfbb89c985fc9f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fed376b4e253e08b6deeb43209cfbb89c985fc9f">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Ozbulak_Image_Colorization_by_Capsule_Networks_CVPRW_2019_paper.html">Image Colorization by Capsule Networks</a></th>
                    </tr>
                
                    <tr id="435b7354ae91c2737e768dc33d3af0b7d256936d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/435b7354ae91c2737e768dc33d3af0b7d256936d">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Ancuti_NTIRE_2019_Image_Dehazing_Challenge_Report_CVPRW_2019_paper.html">NTIRE 2019 Image Dehazing Challenge Report</a></th>
                    </tr>
                
                    <tr id="f0175da1a683811455239527e0019c88e706f05f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f0175da1a683811455239527e0019c88e706f05f">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Weakly_Supervised_Learning_for_RealWorld_Computer_Vision_Applications/Li_Semi-supervised_learning_based_on_generative_adversarial_network_a_comparison_between_CVPRW_2019_paper.html">Semi-supervised learning based on generative adversarial network: a comparison between good GAN and bad GAN approach</a></th>
                    </tr>
                
                    <tr id="bb9275a4b02850bb33baa1c5c28b221ed8a61568">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bb9275a4b02850bb33baa1c5c28b221ed8a61568">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Akula_Natural_Language_Interaction_with_Explainable_AI_Models_CVPRW_2019_paper.html">Natural Language Interaction with Explainable AI Models</a></th>
                    </tr>
                
                    <tr id="38268657b2aedf37adc7863aea2e8df0a39be4cb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38268657b2aedf37adc7863aea2e8df0a39be4cb">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Kohler_Uncertainty_Based_Detection_and_Relabeling_of_Noisy_Image_Labels_CVPRW_2019_paper.html">Uncertainty Based Detection and Relabeling of Noisy Image Labels</a></th>
                    </tr>
                
                    <tr id="96a46bb212343c010f0febf2f61cc1c0e0c10efc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96a46bb212343c010f0febf2f61cc1c0e0c10efc">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Li_Spatio-temporal_Consistency_and_Hierarchical_Matching_for_Multi-Target_Multi-Camera_Vehicle_Tracking_CVPRW_2019_paper.html">Spatio-temporal Consistency and Hierarchical Matching for Multi-Target Multi-Camera Vehicle Tracking</a></th>
                    </tr>
                
                    <tr id="67e733b987eb508fdaa60746bf0f5ed4ad192dbe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/67e733b987eb508fdaa60746bf0f5ed4ad192dbe">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Sight_and_Sound/Angie_W_Boggust_Grounding_Spoken_Words_in_Unlabeled_Video_CVPRW_2019_paper.html">Grounding Spoken Words in Unlabeled Video</a></th>
                    </tr>
                
                    <tr id="75ab4f41c28bddefbd997744617e3ec6e3b478dc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/75ab4f41c28bddefbd997744617e3ec6e3b478dc">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_GIF2Video_Color_Dequantization_and_Temporal_Interpolation_of_GIF_Images_CVPR_2019_paper.html">GIF2Video: Color Dequantization and Temporal Interpolation of GIF Images</a></th>
                    </tr>
                
                    <tr id="51932dc1148566040fdb0df6ed66d8d2a0712933">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/51932dc1148566040fdb0df6ed66d8d2a0712933">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Teney_Actively_Seeking_and_Learning_From_Live_Data_CVPR_2019_paper.html">Actively Seeking and Learning From Live Data</a></th>
                    </tr>
                
                    <tr id="3f292be01a51694a05f33cf1c54cbd90cca08d36">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f292be01a51694a05f33cf1c54cbd90cca08d36">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jia_Instance-Level_Meta_Normalization_CVPR_2019_paper.html">Instance-Level Meta Normalization</a></th>
                    </tr>
                
                    <tr id="ef274194c9f55f203b9b47a362d40aa530acbc78">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ef274194c9f55f203b9b47a362d40aa530acbc78">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wei_Building_Detail-Sensitive_Semantic_Segmentation_Networks_With_Polynomial_Pooling_CVPR_2019_paper.html">Building Detail-Sensitive Semantic Segmentation Networks With Polynomial Pooling</a></th>
                    </tr>
                
                    <tr id="9ae43e25b04f5c35173b0bf490612015bd86c08f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9ae43e25b04f5c35173b0bf490612015bd86c08f">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ding_Face-Focused_Cross-Stream_Network_for_Deception_Detection_in_Videos_CVPR_2019_paper.html">Face-Focused Cross-Stream Network for Deception Detection in Videos</a></th>
                    </tr>
                
                    <tr id="0442cde9215e0c038a05c5d1ed18e4fd10281eb7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0442cde9215e0c038a05c5d1ed18e4fd10281eb7">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mukundan_Explicit_Spatial_Encoding_for_Deep_Local_Descriptors_CVPR_2019_paper.html">Explicit Spatial Encoding for Deep Local Descriptors</a></th>
                    </tr>
                
                    <tr id="b8317bc29531d78942a75fa493a852535f40b2d6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b8317bc29531d78942a75fa493a852535f40b2d6">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Weakly_Supervised_Image_Classification_Through_Noise_Regularization_CVPR_2019_paper.html">Weakly Supervised Image Classification Through Noise Regularization</a></th>
                    </tr>
                
                    <tr id="a86f5d6b84f05c2f264eba4881094673279ed0de">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a86f5d6b84f05c2f264eba4881094673279ed0de">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Cascaded_Generative_and_Discriminative_Learning_for_Microcalcification_Detection_in_Breast_CVPR_2019_paper.html">Cascaded Generative and Discriminative Learning for Microcalcification Detection in Breast Mammograms</a></th>
                    </tr>
                
                    <tr id="a8a1b25826d1e798d886d9c3b28fad968353176b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a8a1b25826d1e798d886d9c3b28fad968353176b">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Bastidas_Channel_Attention_Networks_CVPRW_2019_paper.html">Channel Attention Networks</a></th>
                    </tr>
                
                    <tr id="dede7c0b4091d106967db2f3dbdf0c647c7aa2db">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dede7c0b4091d106967db2f3dbdf0c647c7aa2db">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Mehri_Colorizing_Near_Infrared_Images_Through_a_Cyclic_Adversarial_Approach_of_CVPRW_2019_paper.html">Colorizing Near Infrared Images Through a Cyclic Adversarial Approach of Unpaired Samples</a></th>
                    </tr>
                
                    <tr id="b525d3fe8c9b59b46b368007cd5f7b6b3ca9dd2d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b525d3fe8c9b59b46b368007cd5f7b6b3ca9dd2d">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BEFA/Muthukumar_Color-Theoretic_Experiments_to_Understand_Unequal_Gender_Classification_Accuracy_From_Face_CVPRW_2019_paper.html">Color-Theoretic Experiments to Understand Unequal Gender Classification Accuracy From Face Images</a></th>
                    </tr>
                
                    <tr id="b3fa23e685724461011d1ead66eb7270bf85b217">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b3fa23e685724461011d1ead66eb7270bf85b217">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Wang_Aspect-Ratio-Preserving_Multi-Patch_Image_Aesthetics_Score_Prediction_CVPRW_2019_paper.html">Aspect-Ratio-Preserving Multi-Patch Image Aesthetics Score Prediction</a></th>
                    </tr>
                
                    <tr id="d6ad681c55bfe720dc5f87db6b6f221d966dc0fc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d6ad681c55bfe720dc5f87db6b6f221d966dc0fc">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Bianco_High-Resolution_Single_Image_Dehazing_Using_Encoder-Decoder_Architecture_CVPRW_2019_paper.html">High-Resolution Single Image Dehazing Using Encoder-Decoder Architecture</a></th>
                    </tr>
                
                    <tr id="12a6633e3bc4f668285d5c88187494c6abb073a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/12a6633e3bc4f668285d5c88187494c6abb073a5">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Proenca_Segmentation-Less_and_Non-Holistic_Deep-Learning_Frameworks_for_Iris_Recognition_CVPRW_2019_paper.html">Segmentation-Less and Non-Holistic Deep-Learning Frameworks for Iris Recognition</a></th>
                    </tr>
                
                    <tr id="ae0a6c53c33e45fb18c8d78e6bd8f0ffd297f203">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae0a6c53c33e45fb18c8d78e6bd8f0ffd297f203">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UAVision/Ringwald_UAV-Net_A_Fast_Aerial_Vehicle_Detector_for_Mobile_Platforms_CVPRW_2019_paper.html">UAV-Net: A Fast Aerial Vehicle Detector for Mobile Platforms</a></th>
                    </tr>
                
                    <tr id="16bc01018618b1ed01942561e6c28a26547aa956">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16bc01018618b1ed01942561e6c28a26547aa956">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Bellver_Budget-aware_Semi-Supervised_Semantic_and_Instance_Segmentation_CVPRW_2019_paper.html">Budget-aware Semi-Supervised Semantic and Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="43b06764f687b52f1706905218aea14faef59b06">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/43b06764f687b52f1706905218aea14faef59b06">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Lin_Medical_Time_Series_Classification_with_Hierarchical_Attention-based_Temporal_Convolutional_Networks_CVPRW_2019_paper.html">Medical Time Series Classification with Hierarchical Attention-based Temporal Convolutional Networks: A Case Study of Myotonic Dystrophy Diagnosis</a></th>
                    </tr>
                
                    <tr id="796bab5389b976c8ffaed57e6140fb72dc5b4295">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/796bab5389b976c8ffaed57e6140fb72dc5b4295">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Face_and_Gesture_Analysis_for_Health_Informatics/Asgarian_Limitations_and_Biases_in_Facial_Landmark_Detection_D_An_Empirical_CVPRW_2019_paper.html">Limitations and Biases in Facial Landmark Detection D An Empirical Study on Older Adults with Dementia</a></th>
                    </tr>
                
                    <tr id="2b15154b94fcaf857d8da2ad5b6d583d166d4234">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b15154b94fcaf857d8da2ad5b6d583d166d4234">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Abbasnejad_Whats_to_Know_Uncertainty_as_a_Guide_to_Asking_Goal-Oriented_CVPR_2019_paper.html">What&#39;s to Know? Uncertainty as a Guide to Asking Goal-Oriented Questions</a></th>
                    </tr>
                
                    <tr id="f68e35cdd571c3cf66f071384725135191ebac4d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f68e35cdd571c3cf66f071384725135191ebac4d">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liao_Synthesizing_Environment-Aware_Activities_via_Activity_Sketches_CVPR_2019_paper.html">Synthesizing Environment-Aware Activities via Activity Sketches</a></th>
                    </tr>
                
                    <tr id="5f5b7f7ef269e270c43c21aefaf9c6dbad63d5f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f5b7f7ef269e270c43c21aefaf9c6dbad63d5f2">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Niitani_Sampling_Techniques_for_Large-Scale_Object_Detection_From_Sparsely_Annotated_Objects_CVPR_2019_paper.html">Sampling Techniques for Large-Scale Object Detection From Sparsely Annotated Objects</a></th>
                    </tr>
                
                    <tr id="c0bd29bc2ec789d31034f2e7e50551f4c8ce39f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c0bd29bc2ec789d31034f2e7e50551f4c8ce39f5">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Barnea_Exploring_the_Bounds_of_the_Utility_of_Context_for_Object_CVPR_2019_paper.html">Exploring the Bounds of the Utility of Context for Object Detection</a></th>
                    </tr>
                
                    <tr id="1d217d9234a3da82dc641a91ea5a1cfa0594a326">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d217d9234a3da82dc641a91ea5a1cfa0594a326">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qi_3D_Motion_Decomposition_for_RGBD_Future_Dynamic_Scene_Synthesis_CVPR_2019_paper.html">3D Motion Decomposition for RGBD Future Dynamic Scene Synthesis</a></th>
                    </tr>
                
                    <tr id="1aea7d20edfd40b0907249270a80842382d93964">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1aea7d20edfd40b0907249270a80842382d93964">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Perrett_DDLSTM_Dual-Domain_LSTM_for_Cross-Dataset_Action_Recognition_CVPR_2019_paper.html">DDLSTM: Dual-Domain LSTM for Cross-Dataset Action Recognition</a></th>
                    </tr>
                
                    <tr id="f7212d466852116f912378e3969b7cdd94a80285">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7212d466852116f912378e3969b7cdd94a80285">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Derakhshani_Assisted_Excitation_of_Activations_A_Learning_Technique_to_Improve_Object_CVPR_2019_paper.html">Assisted Excitation of Activations: A Learning Technique to Improve Object Detectors</a></th>
                    </tr>
                
                    <tr id="8f2923fe11e31e624e1393c32714725bfbb2eb52">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f2923fe11e31e624e1393c32714725bfbb2eb52">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Eghbali_Deep_Spherical_Quantization_for_Image_Search_CVPR_2019_paper.html">Deep Spherical Quantization for Image Search</a></th>
                    </tr>
                
                    <tr id="009019f67019320bb1da759f60ee24daa7f96f51">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/009019f67019320bb1da759f60ee24daa7f96f51">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BMTT/Henschel_Simultaneous_Identification_and_Tracking_of_Multiple_People_Using_Video_and_CVPRW_2019_paper.html">Simultaneous Identification and Tracking of Multiple People Using Video and IMUs</a></th>
                    </tr>
                
                    <tr id="eb7edbd51a55f0d4737732c2c546e5e7ec6e8935">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eb7edbd51a55f0d4737732c2c546e5e7ec6e8935">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/FFSS-USAD/Park_Study_on_Fashion_Image_Retrieval_Methods_for_Efficient_Fashion_Visual_CVPRW_2019_paper.html">Study on Fashion Image Retrieval Methods for Efficient Fashion Visual Search</a></th>
                    </tr>
                
                    <tr id="ca721f0db5168097048fa19371ab1bdd92ff15ef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ca721f0db5168097048fa19371ab1bdd92ff15ef">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Kanojia_Attentive_Spatio-Temporal_Representation_Learning_for_Diving_Classification_CVPRW_2019_paper.html">Attentive Spatio-Temporal Representation Learning for Diving Classification</a></th>
                    </tr>
                
                    <tr id="fcc2cb1641ae27c5885d46c395b47ea05b678c02">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fcc2cb1641ae27c5885d46c395b47ea05b678c02">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/ISIC/Barata_Deep_Attention_Model_for_the_Hierarchical_Diagnosis_of_Skin_Lesions_CVPRW_2019_paper.html">Deep Attention Model for the Hierarchical Diagnosis of Skin Lesions</a></th>
                    </tr>
                
                    <tr id="ddb9c5e96932f2a8abe2ef16f18d19c21456247f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ddb9c5e96932f2a8abe2ef16f18d19c21456247f">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Du_Orientation-Aware_Deep_Neural_Network_for_Real_Image_Super-Resolution_CVPRW_2019_paper.html">Orientation-Aware Deep Neural Network for Real Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="c062945f73906266c9b8b9d3eaea9967959add00">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c062945f73906266c9b8b9d3eaea9967959add00">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Gao_Multi-Scale_Deep_Neural_Networks_for_Real_Image_Super-Resolution_CVPRW_2019_paper.html">Multi-Scale Deep Neural Networks for Real Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="bda24b14d9ac47ec8a4133eef4748c057d0a3a47">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bda24b14d9ac47ec8a4133eef4748c057d0a3a47">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Cheng_Encoder-Decoder_Residual_Network_for_Real_Super-Resolution_CVPRW_2019_paper.html">Encoder-Decoder Residual Network for Real Super-Resolution</a></th>
                    </tr>
                
                    <tr id="73b20392e4f159e14b4664f27bd9c1f6cc9a32f7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/73b20392e4f159e14b4664f27bd9c1f6cc9a32f7">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Zhao_Unsupervised_Traffic_Anomaly_Detection_Using_Trajectories_CVPRW_2019_paper.html">Unsupervised Traffic Anomaly Detection Using Trajectories</a></th>
                    </tr>
                
                    <tr id="3127f421fb3a6375039f5880a5d31f562d2d2f22">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3127f421fb3a6375039f5880a5d31f562d2d2f22">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Spanhel_Vehicle_Re-Identifiation_and_Multi-Camera_Tracking_in_Challenging_City-Scale_Environment_CVPRW_2019_paper.html">Vehicle Re-Identifiation and Multi-Camera Tracking in Challenging City-Scale Environment</a></th>
                    </tr>
                
                    <tr id="c8f95b057097c9b781dde59c5d77e0498a1b3e35">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c8f95b057097c9b781dde59c5d77e0498a1b3e35">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Nachmany_Detecting_Roads_from_Satellite_Imagery_in_the_Developing_World_CVPRW_2019_paper.html">Detecting Roads from Satellite Imagery in the Developing World</a></th>
                    </tr>
                
                    <tr id="3ed21606032143f94f3a8da13d757a9288bc67ed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ed21606032143f94f3a8da13d757a9288bc67ed">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Matejek_Biologically-Constrained_Graphs_for_Global_Connectomics_Reconstruction_CVPR_2019_paper.html">Biologically-Constrained Graphs for Global Connectomics Reconstruction</a></th>
                    </tr>
                
                    <tr id="7031d3636a1f467306f8bc95da030086f9af9eac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7031d3636a1f467306f8bc95da030086f9af9eac">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Mind_Your_Neighbours_Image_Annotation_With_Metadata_Neighbourhood_Graph_Co-Attention_CVPR_2019_paper.html">Mind Your Neighbours: Image Annotation With Metadata Neighbourhood Graph Co-Attention Networks</a></th>
                    </tr>
                
                    <tr id="d155f18a7ecdaf07d787501c6c74487dd05c0e23">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d155f18a7ecdaf07d787501c6c74487dd05c0e23">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hwang_Adversarial_Structure_Matching_for_Structured_Prediction_Tasks_CVPR_2019_paper.html">Adversarial Structure Matching for Structured Prediction Tasks</a></th>
                    </tr>
                
                    <tr id="89dc509dd74f05cd3b20af80fe6385b9f2657c5c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/89dc509dd74f05cd3b20af80fe6385b9f2657c5c">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Learning_to_Learn_Relation_for_Important_People_Detection_in_Still_CVPR_2019_paper.html">Learning to Learn Relation for Important People Detection in Still Images</a></th>
                    </tr>
                
                    <tr id="7d4916d528e093374fc1e7fd6219c8711d5efaaa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7d4916d528e093374fc1e7fd6219c8711d5efaaa">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tan_Weakly_Supervised_Open-Set_Domain_Adaptation_by_Dual-Domain_Collaboration_CVPR_2019_paper.html">Weakly Supervised Open-Set Domain Adaptation by Dual-Domain Collaboration</a></th>
                    </tr>
                
                    <tr id="fcd925c50392fcab91e9e5dce08d3ad766859926">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fcd925c50392fcab91e9e5dce08d3ad766859926">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Polynomial_Representation_for_Persistence_Diagram_CVPR_2019_paper.html">Polynomial Representation for Persistence Diagram</a></th>
                    </tr>
                
                    <tr id="bcad284af2a484d508a695dc534b0363812b1993">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bcad284af2a484d508a695dc534b0363812b1993">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lee_Inserting_Videos_Into_Videos_CVPR_2019_paper.html">Inserting Videos Into Videos</a></th>
                    </tr>
                
                    <tr id="2587270fb2c80e6e827eb10221528c4f45dfb760">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2587270fb2c80e6e827eb10221528c4f45dfb760">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Abbasnejad_A_Generative_Adversarial_Density_Estimator_CVPR_2019_paper.html">A Generative Adversarial Density Estimator</a></th>
                    </tr>
                
                    <tr id="49b26a9cf0aca4d36396395d563900147d40b29a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/49b26a9cf0aca4d36396395d563900147d40b29a">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Bao_High-Quality_Face_Capture_Using_Anatomical_Muscles_CVPR_2019_paper.html">High-Quality Face Capture Using Anatomical Muscles</a></th>
                    </tr>
                
                    <tr id="31df0d731161699cb29e1c4e27a7934df8785eeb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/31df0d731161699cb29e1c4e27a7934df8785eeb">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Additive_Adversarial_Learning_for_Unbiased_Authentication_CVPR_2019_paper.html">Additive Adversarial Learning for Unbiased Authentication</a></th>
                    </tr>
                
                    <tr id="c1261221feca1930ea437f0e82cff1fde4e9ee6f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c1261221feca1930ea437f0e82cff1fde4e9ee6f">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Re-Identification_Supervised_Texture_Generation_CVPR_2019_paper.html">Re-Identification Supervised Texture Generation</a></th>
                    </tr>
                
                    <tr id="3ca4dc6fe0fc54dc7e254db0d259abd7186a1550">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ca4dc6fe0fc54dc7e254db0d259abd7186a1550">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Lore_Generative_Adversarial_Networks_for_Spectral_Super-Resolution_and_Bidirectional_RGB-To-Multispectral_Mapping_CVPRW_2019_paper.html">Generative Adversarial Networks for Spectral Super-Resolution and Bidirectional RGB-To-Multispectral Mapping</a></th>
                    </tr>
                
                    <tr id="2b27eee33586fc035852c1cc4abc83a562119e23">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b27eee33586fc035852c1cc4abc83a562119e23">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EarthVision/Kellenberger_When_a_Few_Clicks_Make_All_the_Difference_Improving_Weakly-Supervised_CVPRW_2019_paper.html">When a Few Clicks Make All the Difference: Improving Weakly-Supervised Wildlife Detection in UAV Images</a></th>
                    </tr>
                
                    <tr id="72d0b1f44a9bcc5fa2588df36c8e568190dc79d6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/72d0b1f44a9bcc5fa2588df36c8e568190dc79d6">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/ISIC/Mishra_Interpreting_Fine-Grained_Dermatological_Classification_by_Deep_Learning_CVPRW_2019_paper.html">Interpreting Fine-Grained Dermatological Classification by Deep Learning</a></th>
                    </tr>
                
                    <tr id="e330af2d061ade245622b9445d5be9717f66b60f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e330af2d061ade245622b9445d5be9717f66b60f">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MBCCV/Koutras_SUSiNet_See_Understand_and_Summarize_It_CVPRW_2019_paper.html">SUSiNet: See, Understand and Summarize It</a></th>
                    </tr>
                
                    <tr id="4bdf46dd422208f2bb83990e79cd1f2e4ca11f97">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4bdf46dd422208f2bb83990e79cd1f2e4ca11f97">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BCMCVAI/Li_Exploiting_Computation_Power_of_Blockchain_for_Biomedical_Image_Segmentation_CVPRW_2019_paper.html">Exploiting Computation Power of Blockchain for Biomedical Image Segmentation</a></th>
                    </tr>
                
                    <tr id="39dcab483fa37155506e0a02c252cee5ebf0e463">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39dcab483fa37155506e0a02c252cee5ebf0e463">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Verma_Generative_Model_for_Zero-Shot_Sketch-Based_Image_Retrieval_CVPRW_2019_paper.html">Generative Model for Zero-Shot Sketch-Based Image Retrieval</a></th>
                    </tr>
                
                    <tr id="e9997c90e61600fa65f33a28cdfc6e524373e714">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e9997c90e61600fa65f33a28cdfc6e524373e714">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Aghdam_Exploring_Factors_for_Improving_Low_Resolution_Face_Recognition_CVPRW_2019_paper.html">Exploring Factors for Improving Low Resolution Face Recognition</a></th>
                    </tr>
                
                    <tr id="bb1273416cc5929208717d973cb7052395198626">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bb1273416cc5929208717d973cb7052395198626">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/GV_Automatic_Classification_of_Whole_Slide_Pap_Smear_Images_Using_CNN_CVPRW_2019_paper.html">Automatic Classification of Whole Slide Pap Smear Images Using CNN With PCA Based Feature Interpretation</a></th>
                    </tr>
                
                    <tr id="478a0a0c9bc1c0d431b5fdbf8a5503b793194130">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/478a0a0c9bc1c0d431b5fdbf8a5503b793194130">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Akyazi_Learning-Based_Image_Compression_using_Convolutional_Autoencoder_and_Wavelet_Decomposition_CVPRW_2019_paper.html">Learning-Based Image Compression using Convolutional Autoencoder and Wavelet Decomposition</a></th>
                    </tr>
                
                    <tr id="32d3c14588a5a7f53faf961e28ef192b152208a3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/32d3c14588a5a7f53faf961e28ef192b152208a3">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Nousias_Large-Scale_Metric_Structure_From_Motion_for_Unordered_Light_Fields_CVPR_2019_paper.html">Large-Scale, Metric Structure From Motion for Unordered Light Fields</a></th>
                    </tr>
                
                    <tr id="9c6e8acd8db5a2fe0ff0711e54212a2152538ab7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c6e8acd8db5a2fe0ff0711e54212a2152538ab7">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Rezanejad_Scene_Categorization_From_Contours_Medial_Axis_Based_Salience_Measures_CVPR_2019_paper.html">Scene Categorization From Contours: Medial Axis Based Salience Measures</a></th>
                    </tr>
                
                    <tr id="d6671a8f5c5ed906501f9c441fda64942a682800">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d6671a8f5c5ed906501f9c441fda64942a682800">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Deep_Blind_Video_Decaptioning_by_Temporal_Aggregation_and_Recurrence_CVPR_2019_paper.html">Deep Blind Video Decaptioning by Temporal Aggregation and Recurrence</a></th>
                    </tr>
                
                    <tr id="af44fb4b9ff95bfcc26e099c20bd1e251951b989">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/af44fb4b9ff95bfcc26e099c20bd1e251951b989">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shugrina_Creative_Flow_Dataset_CVPR_2019_paper.html">Creative Flow+ Dataset</a></th>
                    </tr>
                
                    <tr id="cec1c425aee5ed41d0fd89e3096864c926789c4e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cec1c425aee5ed41d0fd89e3096864c926789c4e">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Tian_Versatile_Multiple_Choice_Learning_and_Its_Application_to_Vision_Computing_CVPR_2019_paper.html">Versatile Multiple Choice Learning and Its Application to Vision Computing</a></th>
                    </tr>
                
                    <tr id="26e4fa5343b95c36bfb6eba79c2e71cbe27ed01a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26e4fa5343b95c36bfb6eba79c2e71cbe27ed01a">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Compact_Feature_Learning_for_Multi-Domain_Image_Classification_CVPR_2019_paper.html">Compact Feature Learning for Multi-Domain Image Classification</a></th>
                    </tr>
                
                    <tr id="303aa6cb7a182d5437c86d07aff4fb9fdabc744e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/303aa6cb7a182d5437c86d07aff4fb9fdabc744e">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Deep_Dual_Relation_Modeling_for_Egocentric_Interaction_Recognition_CVPR_2019_paper.html">Deep Dual Relation Modeling for Egocentric Interaction Recognition</a></th>
                    </tr>
                
                    <tr id="b80f128830114896df94999b4104cb75408e657e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b80f128830114896df94999b4104cb75408e657e">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Noh_Transfer_Learning_via_Unsupervised_Task_Discovery_for_Visual_Question_Answering_CVPR_2019_paper.html">Transfer Learning via Unsupervised Task Discovery for Visual Question Answering</a></th>
                    </tr>
                
                    <tr id="bf016450f60ca0a8090599b0446a2fbe9f5bb6fd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bf016450f60ca0a8090599b0446a2fbe9f5bb6fd">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xue_Transferable_AutoML_by_Model_Sharing_Over_Grouped_Datasets_CVPR_2019_paper.html">Transferable AutoML by Model Sharing Over Grouped Datasets</a></th>
                    </tr>
                
                    <tr id="a7a90e3c9ea3f4325be65a57a7529553d8fd7768">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a7a90e3c9ea3f4325be65a57a7529553d8fd7768">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lei_Direct_Object_Recognition_Without_Line-Of-Sight_Using_Optical_Coherence_CVPR_2019_paper.html">Direct Object Recognition Without Line-Of-Sight Using Optical Coherence</a></th>
                    </tr>
                
                    <tr id="e59e9d8b361c7e66c8635f3a0795c81a38ae66bd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e59e9d8b361c7e66c8635f3a0795c81a38ae66bd">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Broome_Dynamics_Are_Important_for_the_Recognition_of_Equine_Pain_in_CVPR_2019_paper.html">Dynamics Are Important for the Recognition of Equine Pain in Video</a></th>
                    </tr>
                
                    <tr id="76e333e5941a91da1fc4c5ddf9a06d02fea01496">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/76e333e5941a91da1fc4c5ddf9a06d02fea01496">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BEFA/Vera-Rodriguez_FaceGenderID_Exploiting_Gender_Information_in_DCNNs_Face_Recognition_Systems_CVPRW_2019_paper.html">FaceGenderID: Exploiting Gender Information in DCNNs Face Recognition Systems</a></th>
                    </tr>
                
                    <tr id="61784d9bbd30caea8393d111872fe7ccccba23ea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61784d9bbd30caea8393d111872fe7ccccba23ea">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Zecha_Refining_Joint_Locations_for_Human_Pose_Tracking_in_Sports_Videos_CVPRW_2019_paper.html">Refining Joint Locations for Human Pose Tracking in Sports Videos</a></th>
                    </tr>
                
                    <tr id="71fddccd0e5023510b8467ad853deb18c5e9d02e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/71fddccd0e5023510b8467ad853deb18c5e9d02e">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SkelNetOn/Nathan_SkeletonNet_Shape_Pixel_to_Skeleton_Pixel_CVPRW_2019_paper.html">SkeletonNet: Shape Pixel to Skeleton Pixel</a></th>
                    </tr>
                
                    <tr id="6f86055e8ccab6ed368a3dac43a5a5fd3a6441c6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6f86055e8ccab6ed368a3dac43a5a5fd3a6441c6">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Lin_Real_Photographs_Denoising_With_Noise_Domain_Adaptation_and_Attentive_Generative_CVPRW_2019_paper.html">Real Photographs Denoising With Noise Domain Adaptation and Attentive Generative Adversarial Network</a></th>
                    </tr>
                
                    <tr id="488ceba57a625b89fdbd212cc962b0b538cceddb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/488ceba57a625b89fdbd212cc962b0b538cceddb">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Kwak_Fractal_Residual_Network_and_Solutions_for_Real_Super-Resolution_CVPRW_2019_paper.html">Fractal Residual Network and Solutions for Real Super-Resolution</a></th>
                    </tr>
                
                    <tr id="e0ffe0c31e9c75c1a92a9297d5c1125e43734993">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e0ffe0c31e9c75c1a92a9297d5c1125e43734993">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Gu_NTIRE_2019_Challenge_on_Image_Colorization_Report_CVPRW_2019_paper.html">NTIRE 2019 Challenge on Image Colorization: Report</a></th>
                    </tr>
                
                    <tr id="01d2216c2a90a7b2b1ee1b49923cd070ac4a7e9f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01d2216c2a90a7b2b1ee1b49923cd070ac4a7e9f">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Ayotte_Fast_Continuous_User_Authentication_Using_Distance_Metric_Fusion_of_Free-Text_CVPRW_2019_paper.html">Fast Continuous User Authentication Using Distance Metric Fusion of Free-Text Keystroke Data</a></th>
                    </tr>
                
                    <tr id="ac4a4fa5c3543ea1417bb8f4a85800b8099e72ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ac4a4fa5c3543ea1417bb8f4a85800b8099e72ab">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SAIAD/Bar_On_the_Robustness_of_Redundant_Teacher-Student_Frameworks_for_Semantic_Segmentation_CVPRW_2019_paper.html">On the Robustness of Redundant Teacher-Student Frameworks for Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="43270f621fc8ea87fbdffbed3b4c4dbbde5b3bce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/43270f621fc8ea87fbdffbed3b4c4dbbde5b3bce">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/TRMTMCT/Li_State-Aware_Re-Identification_Feature_for_Multi-Target_Multi-Camera_Tracking_CVPRW_2019_paper.html">State-Aware Re-Identification Feature for Multi-Target Multi-Camera Tracking</a></th>
                    </tr>
                
                    <tr id="f2570ce3531ef57b8c65305e128cdff132ce79b6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f2570ce3531ef57b8c65305e128cdff132ce79b6">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Hashimoto_Normal_Estimation_for_Accurate_3D_Mesh_Reconstruction_with_Point_Cloud_CVPRW_2019_paper.html">Normal Estimation for Accurate 3D Mesh Reconstruction with Point Cloud Model Incorporating Spatial Structure</a></th>
                    </tr>
                
                    <tr id="feee543cc5350a3983031cae8559f126124ffa2e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/feee543cc5350a3983031cae8559f126124ffa2e">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Chen_Multi-camera_Vehicle_Tracking_and_Re-identification_on_AI_City_Challenge_2019_CVPRW_2019_paper.html">Multi-camera Vehicle Tracking and Re-identification on AI City Challenge 2019</a></th>
                    </tr>
                
                    <tr id="e93972f4727ee2eed75dc365ae05de7b24ee65df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e93972f4727ee2eed75dc365ae05de7b24ee65df">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Khan_ProcSy_Procedural_Synthetic_Dataset_Generation_Towards_Influence_Factor_Studies_Of_CVPRW_2019_paper.html">ProcSy: Procedural Synthetic Dataset Generation Towards Influence Factor Studies Of Semantic Segmentation Networks</a></th>
                    </tr>
                
                    <tr id="991c36ca67afd966ef800f3b6d555bdb77571461">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/991c36ca67afd966ef800f3b6d555bdb77571461">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Liu_Practical_Stacked_Non-local_Attention_Modules_for_Image_Compression_CVPRW_2019_paper.html">Practical Stacked Non-local Attention Modules for Image Compression</a></th>
                    </tr>
                
                    <tr id="4913b1ed5ee4c68e31c121e85abb96f6006a3e5d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4913b1ed5ee4c68e31c121e85abb96f6006a3e5d">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Probst_Unsupervised_Learning_of_Consensus_Maximization_for_3D_Vision_Problems_CVPR_2019_paper.html">Unsupervised Learning of Consensus Maximization for 3D Vision Problems</a></th>
                    </tr>
                
                    <tr id="72c5b7237bc0c4b66f7cf5ba89fa1cacba8bb81d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/72c5b7237bc0c4b66f7cf5ba89fa1cacba8bb81d">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Deep_Virtual_Networks_for_Memory_Efficient_Inference_of_Multiple_Tasks_CVPR_2019_paper.html">Deep Virtual Networks for Memory Efficient Inference of Multiple Tasks</a></th>
                    </tr>
                
                    <tr id="ad8109640209239eee04a6ba0b4fa87a97576c21">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ad8109640209239eee04a6ba0b4fa87a97576c21">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Branchaud-Charron_Spectral_Metric_for_Dataset_Complexity_Assessment_CVPR_2019_paper.html">Spectral Metric for Dataset Complexity Assessment</a></th>
                    </tr>
                
                    <tr id="ab051bc04aba92a9c7094ddf5c1f659a0a6d4853">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ab051bc04aba92a9c7094ddf5c1f659a0a6d4853">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Learning_With_Batch-Wise_Optimal_Transport_Loss_for_3D_Shape_Recognition_CVPR_2019_paper.html">Learning With Batch-Wise Optimal Transport Loss for 3D Shape Recognition</a></th>
                    </tr>
                
                    <tr id="363c83a7338880dcb13294650ef35d9addcfedab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/363c83a7338880dcb13294650ef35d9addcfedab">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Local_Detection_of_Stereo_Occlusion_Boundaries_CVPR_2019_paper.html">Local Detection of Stereo Occlusion Boundaries</a></th>
                    </tr>
                
                    <tr id="ed54caa681742c73ef59adb6ce6ce3233a0d3e7a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ed54caa681742c73ef59adb6ce6ce3233a0d3e7a">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Melzi_GFrames_Gradient-Based_Local_Reference_Frame_for_3D_Shape_Matching_CVPR_2019_paper.html">GFrames: Gradient-Based Local Reference Frame for 3D Shape Matching</a></th>
                    </tr>
                
                    <tr id="40e8eea840c67b27ef5d92470ede34218819b99f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/40e8eea840c67b27ef5d92470ede34218819b99f">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jaiswal_AIRD_Adversarial_Learning_Framework_for_Image_Repurposing_Detection_CVPR_2019_paper.html">AIRD: Adversarial Learning Framework for Image Repurposing Detection</a></th>
                    </tr>
                
                    <tr id="428934f26e240aadeec86b40b23182455fb25c1a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/428934f26e240aadeec86b40b23182455fb25c1a">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Local_Temporal_Bilinear_Pooling_for_Fine-Grained_Action_Parsing_CVPR_2019_paper.html">Local Temporal Bilinear Pooling for Fine-Grained Action Parsing</a></th>
                    </tr>
                
                    <tr id="c3d445c883a396501acf3b5f2cd7680b2b953903">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c3d445c883a396501acf3b5f2cd7680b2b953903">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Su_Improving_Action_Localization_by_Progressive_Cross-Stream_Cooperation_CVPR_2019_paper.html">Improving Action Localization by Progressive Cross-Stream Cooperation</a></th>
                    </tr>
                
                    <tr id="c3b80d2ce5c778cce21f8443e59cc788b720ecfa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c3b80d2ce5c778cce21f8443e59cc788b720ecfa">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MULA/Guan_Unsupervised_Domain_Adaptation_for_Multispectral_Pedestrian_Detection_CVPRW_2019_paper.html">Unsupervised Domain Adaptation for Multispectral Pedestrian Detection</a></th>
                    </tr>
                
                    <tr id="6181fa807eed9da5e9f90f8f5f5ac40ffd053f98">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6181fa807eed9da5e9f90f8f5f5ac40ffd053f98">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/FFSS-USAD/Karessli_SizeNet_Weakly_Supervised_Learning_of_Visual_Size_and_Fit_in_CVPRW_2019_paper.html">SizeNet: Weakly Supervised Learning of Visual Size and Fit in Fashion Images</a></th>
                    </tr>
                
                    <tr id="69857aa9ea58f1a9bc523965cac470da2859c149">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/69857aa9ea58f1a9bc523965cac470da2859c149">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Nowruzi_In-Vehicle_Occupancy_Detection_With_Convolutional_Networks_on_Thermal_Images_CVPRW_2019_paper.html">In-Vehicle Occupancy Detection With Convolutional Networks on Thermal Images</a></th>
                    </tr>
                
                    <tr id="9da0c0fbb14cb68957a087a9f6f98608fd5096f7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9da0c0fbb14cb68957a087a9f6f98608fd5096f7">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Mazzini_Spatial_Sampling_Network_for_Fast_Scene_Understanding_CVPRW_2019_paper.html">Spatial Sampling Network for Fast Scene Understanding</a></th>
                    </tr>
                
                    <tr id="62c6c2efdc2de134a94e78e9a350db74b80ccd00">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/62c6c2efdc2de134a94e78e9a350db74b80ccd00">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Chang_VORNet_Spatio-Temporally_Consistent_Video_Inpainting_for_Object_Removal_CVPRW_2019_paper.html">VORNet: Spatio-Temporally Consistent Video Inpainting for Object Removal</a></th>
                    </tr>
                
                    <tr id="12b4d7b6c5cc61a57bb81433b5acf1ea6a4d5956">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/12b4d7b6c5cc61a57bb81433b5acf1ea6a4d5956">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Arias_Kalman_Filtering_of_Patches_for_Frame-Recursive_Video_Denoising_CVPRW_2019_paper.html">Kalman Filtering of Patches for Frame-Recursive Video Denoising</a></th>
                    </tr>
                
                    <tr id="56488c4bcd685e2e5ec0ce289cb97b0f258753c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/56488c4bcd685e2e5ec0ce289cb97b0f258753c0">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Weakly_Supervised_Learning_for_RealWorld_Computer_Vision_Applications/Liu_Utilizing_the_Instability_in_Weakly_Supervised_Object_Detection_CVPRW_2019_paper.html">Utilizing the Instability in Weakly Supervised Object Detection</a></th>
                    </tr>
                
                    <tr id="abb6ef0832a587b444a5033ea741b08c953862ef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/abb6ef0832a587b444a5033ea741b08c953862ef">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Nielsen_GAN_Data_Augmentation_Through_Active_Learning_Inspired_Sample_Acquisition_CVPRW_2019_paper.html">GAN Data Augmentation Through Active Learning Inspired Sample Acquisition</a></th>
                    </tr>
                
                    <tr id="2575a1b3ac4604345b49d84db949e6280aad0f8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2575a1b3ac4604345b49d84db949e6280aad0f8f">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AAMVEM/Jamadandi_Exemplar-based_Underwater_Image_Enhancement_Augmented_by_Wavelet_Corrected_Transforms_CVPRW_2019_paper.html">Exemplar-based Underwater Image Enhancement Augmented by Wavelet Corrected Transforms</a></th>
                    </tr>
                
                    <tr id="7ce831a605d62bf50d161cc23d4190c8cd9aba78">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ce831a605d62bf50d161cc23d4190c8cd9aba78">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Horvath_Anomaly-Based_Manipulation_Detection_in_Satellite_Images_CVPRW_2019_paper.html">Anomaly-Based Manipulation Detection in Satellite Images</a></th>
                    </tr>
                
                    <tr id="bd0e357ef2abd28498cccafbaacdfa307f50ad48">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bd0e357ef2abd28498cccafbaacdfa307f50ad48">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Liu_Supervised_Joint_Domain_Learning_for_Vehicle_Re-Identification_CVPRW_2019_paper.html">Supervised Joint Domain Learning for Vehicle Re-Identification</a></th>
                    </tr>
                
                    <tr id="602dddfcd859f39b5f7b6fe8a2034a295388f019">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/602dddfcd859f39b5f7b6fe8a2034a295388f019">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Shine_A_Comparative_Study_of_Faster_R-CNN_Models_for_Anomaly_Detection_CVPRW_2019_paper.html">A Comparative Study of Faster R-CNN Models for Anomaly Detection in 2019 AI City Challenge</a></th>
                    </tr>
                
                    <tr id="9da0c0fbb14cb68957a087a9f6f98608fd5096f7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9da0c0fbb14cb68957a087a9f6f98608fd5096f7">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Mazzini_Spatial_Sampling_Network_for_Fast_Scene_Understanding_CVPRW_2019_paper.html">Spatial Sampling Network for Fast Scene Understanding</a></th>
                    </tr>
                
                    <tr id="d91888262f321a6cc1b9b43ee901f61526e62e96">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d91888262f321a6cc1b9b43ee901f61526e62e96">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Shariati_Towards_Autonomous_Mining_via_Intelligent_Excavators_CVPRW_2019_paper.html">Towards Autonomous Mining via Intelligent Excavators</a></th>
                    </tr>
                
                    <tr id="c79d960466516b1ec5ea436688a4c826a318bd0e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c79d960466516b1ec5ea436688a4c826a318bd0e">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Nazir_Tiny-Inception-ResNet-v2_Using_Deep_Learning_for_Eliminating_Bonded_Labors_of_Brick_CVPRW_2019_paper.html">Tiny-Inception-ResNet-v2: Using Deep Learning for Eliminating Bonded Labors of Brick Kilns in South Asia</a></th>
                    </tr>
                
                    <tr id="50c68d557578c6a02a4efa34486fa716ef80cc32">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50c68d557578c6a02a4efa34486fa716ef80cc32">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gutierrez-Barragan_Practical_Coding_Function_Design_for_Time-Of-Flight_Imaging_CVPR_2019_paper.html">Practical Coding Function Design for Time-Of-Flight Imaging</a></th>
                    </tr>
                
                    <tr id="d790a79adc5edad26b8bd81c61235643e63a2238">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d790a79adc5edad26b8bd81c61235643e63a2238">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Towards_Visual_Feature_Translation_CVPR_2019_paper.html">Towards Visual Feature Translation</a></th>
                    </tr>
                
                    <tr id="a35dda4bf77f65c9879bc694b5afb6c605b22e19">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a35dda4bf77f65c9879bc694b5afb6c605b22e19">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kasten_GPSfM_Global_Projective_SFM_Using_Algebraic_Constraints_on_Multi-View_Fundamental_CVPR_2019_paper.html">GPSfM: Global Projective SFM Using Algebraic Constraints on Multi-View Fundamental Matrices</a></th>
                    </tr>
                
                    <tr id="2aa3c6992dd0ac96631e5c0a89104ca10beef739">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2aa3c6992dd0ac96631e5c0a89104ca10beef739">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Revaud_Did_It_Change_Learning_to_Detect_Point-Of-Interest_Changes_for_Proactive_CVPR_2019_paper.html">Did It Change? Learning to Detect Point-Of-Interest Changes for Proactive Map Updates</a></th>
                    </tr>
                
                    <tr id="f23a5c29f227c2653014450284b7aa15ad9f88eb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f23a5c29f227c2653014450284b7aa15ad9f88eb">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Murrugarra-Llerena_Cross-Modality_Personalization_for_Retrieval_CVPR_2019_paper.html">Cross-Modality Personalization for Retrieval</a></th>
                    </tr>
                
                    <tr id="8c0c2db0c8170f72d35132a4c30d3b6db3a8a784">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c0c2db0c8170f72d35132a4c30d3b6db3a8a784">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Huang_End-To-End_Projector_Photometric_Compensation_CVPR_2019_paper.html">End-To-End Projector Photometric Compensation</a></th>
                    </tr>
                
                    <tr id="03181dc1eee845e1461b3c6b2109c8782c10a4ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/03181dc1eee845e1461b3c6b2109c8782c10a4ad">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Magri_Fitting_Multiple_Heterogeneous_Models_by_Multi-Class_Cascaded_T-Linkage_CVPR_2019_paper.html">Fitting Multiple Heterogeneous Models by Multi-Class Cascaded T-Linkage</a></th>
                    </tr>
                
                    <tr id="6d9e326ff03bbaf6426bfb3a9331d49a24dc4e4c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6d9e326ff03bbaf6426bfb3a9331d49a24dc4e4c">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xiong_Visual_Query_Answering_by_Entity-Attribute_Graph_Matching_and_Reasoning_CVPR_2019_paper.html">Visual Query Answering by Entity-Attribute Graph Matching and Reasoning</a></th>
                    </tr>
                
                    <tr id="f14a0ea3e096ca72cb9485ddb77a94a5e492c32a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f14a0ea3e096ca72cb9485ddb77a94a5e492c32a">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cai_MaxpoolNMS_Getting_Rid_of_NMS_Bottlenecks_in_Two-Stage_Object_Detectors_CVPR_2019_paper.html">MaxpoolNMS: Getting Rid of NMS Bottlenecks in Two-Stage Object Detectors</a></th>
                    </tr>
                
                    <tr id="685151715b1ae90e2117ea7a3bff8dd011863611">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/685151715b1ae90e2117ea7a3bff8dd011863611">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Piao_Double_Nuclear_Norm_Based_Low_Rank_Representation_on_Grassmann_Manifolds_CVPR_2019_paper.html">Double Nuclear Norm Based Low Rank Representation on Grassmann Manifolds for Clustering</a></th>
                    </tr>
                
                    <tr id="d79c2fd6c912a71dd08d4c7ca7f7f12966113463">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d79c2fd6c912a71dd08d4c7ca7f7f12966113463">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cerrone_End-To-End_Learned_Random_Walker_for_Seeded_Image_Segmentation_CVPR_2019_paper.html">End-To-End Learned Random Walker for Seeded Image Segmentation</a></th>
                    </tr>
                
                    <tr id="7ed3ab6bde2f17488c7b85ffb6d3875916ba4629">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ed3ab6bde2f17488c7b85ffb6d3875916ba4629">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/S_Regularizer_to_Mitigate_Gradient_Masking_Effect_During_Single-Step_Adversarial_Training_CVPRW_2019_paper.html">Regularizer to Mitigate Gradient Masking Effect During Single-Step Adversarial Training</a></th>
                    </tr>
                
                    <tr id="d07b121d60cb24271f5d93a78cac975e7ae1de8c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d07b121d60cb24271f5d93a78cac975e7ae1de8c">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Gupta_Bag-Of-Lies_A_Multimodal_Dataset_for_Deception_Detection_CVPRW_2019_paper.html">Bag-Of-Lies: A Multimodal Dataset for Deception Detection</a></th>
                    </tr>
                
                    <tr id="f0d93601399ab53f965412754d6f77a078ca6c04">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f0d93601399ab53f965412754d6f77a078ca6c04">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/FFSS-USAD/Chopra_Powering_Robust_Fashion_Retrieval_With_Information_Rich_Feature_Embeddings_CVPRW_2019_paper.html">Powering Robust Fashion Retrieval With Information Rich Feature Embeddings</a></th>
                    </tr>
                
                    <tr id="cb027fb1d3322f5dd8d1327457cd1fae0efc0351">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cb027fb1d3322f5dd8d1327457cd1fae0efc0351">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Sapoukhina_Data_Augmentation_From_RGB_to_Chlorophyll_Fluorescence_Imaging_Application_to_CVPRW_2019_paper.html">Data Augmentation From RGB to Chlorophyll Fluorescence Imaging Application to Leaf Segmentation of Arabidopsis thaliana From Top View Images</a></th>
                    </tr>
                
                    <tr id="003500249f7d78317c00d9c9d97e0808715ecb56">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/003500249f7d78317c00d9c9d97e0808715ecb56">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SkelNetOn/Ghadai_Multi-Level_3D_CNN_for_Learning_Multi-Scale_Spatial_Features_CVPRW_2019_paper.html">Multi-Level 3D CNN for Learning Multi-Scale Spatial Features</a></th>
                    </tr>
                
                    <tr id="47eba61269b87595434619b69e67abd76dbc2232">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47eba61269b87595434619b69e67abd76dbc2232">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Diba_Weakly_Supervised_Object_Discovery_by_Generative_Adversarial__Ranking_Networks_CVPRW_2019_paper.html">Weakly Supervised Object Discovery by Generative Adversarial &amp; Ranking Networks</a></th>
                    </tr>
                
                    <tr id="ad20c60cd67e94841b63b1746b5dce42646dcb8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ad20c60cd67e94841b63b1746b5dce42646dcb8f">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Liu_Knowledge_Representing_Efficient_Sparse_Representation_of_Prior_Knowledge_for_Knowledge_CVPRW_2019_paper.html">Knowledge Representing: Efficient, Sparse Representation of Prior Knowledge for Knowledge Distillation</a></th>
                    </tr>
                
                    <tr id="87ef3c9400dbd51ef9993c40011865838e5064f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/87ef3c9400dbd51ef9993c40011865838e5064f9">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Cheng_Light_Field_Super-Resolution_A_Benchmark_CVPRW_2019_paper.html">Light Field Super-Resolution: A Benchmark</a></th>
                    </tr>
                
                    <tr id="756eb3cccce5ea43bc3073b3ae26d951bcd8547a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/756eb3cccce5ea43bc3073b3ae26d951bcd8547a">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SAIAD/Assion_The_Attack_Generator_A_Systematic_Approach_Towards_Constructing_Adversarial_Attacks_CVPRW_2019_paper.html">The Attack Generator: A Systematic Approach Towards Constructing Adversarial Attacks</a></th>
                    </tr>
                
                    <tr id="10a07f8708a0af821632bb585a7cc189e6ddac0b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/10a07f8708a0af821632bb585a7cc189e6ddac0b">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/Tsuda_Cell_Image_Segmentation_by_Integrating_Pix2pixs_for_Each_Class_CVPRW_2019_paper.html">Cell Image Segmentation by Integrating Pix2pixs for Each Class</a></th>
                    </tr>
                
                    <tr id="d483c5d90d47d9f843035fc97e84613020e4599b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d483c5d90d47d9f843035fc97e84613020e4599b">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CFS/Rill-Garcia_High-Level_Features_for_Multimodal_Deception_Detection_in_Videos_CVPRW_2019_paper.html">High-Level Features for Multimodal Deception Detection in Videos</a></th>
                    </tr>
                
                    <tr id="9c745b744b7413f23aa1a1b87221ef3c9eec87fd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c745b744b7413f23aa1a1b87221ef3c9eec87fd">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Weakly_Supervised_Learning_for_RealWorld_Computer_Vision_Applications/Olmschenk_Dense_Crowd_Counting_Convolutional_Neural_Networks_with_Minimal_Data_using_CVPRW_2019_paper.html">Dense Crowd Counting Convolutional Neural Networks with Minimal Data using Semi-Supervised Dual-Goal Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="684646326870721897b7ac9fa3393296c954b2c5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/684646326870721897b7ac9fa3393296c954b2c5">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Dong_Explainability_for_Content-Based_Image_Retrieval_CVPRW_2019_paper.html">Explainability for Content-Based Image Retrieval</a></th>
                    </tr>
                
                    <tr id="4436b841edba08eb264bcbd4460b32b4a3b347fa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4436b841edba08eb264bcbd4460b32b4a3b347fa">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Schonfeld_Generalized_Zero-Shot_Learning_via_Aligned_Variational_Autoencoders_CVPRW_2019_paper.html">Generalized Zero-Shot Learning via Aligned Variational Autoencoders</a></th>
                    </tr>
                
                    <tr id="69548a2f8a24bab46fc08dcf47bd79ed3fbbcbc5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/69548a2f8a24bab46fc08dcf47bd79ed3fbbcbc5">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Peretroukhin_Deep_Probabilistic_Regression_of_Elements_of_SO3_using_Quaternion_Averaging_CVPRW_2019_paper.html">Deep Probabilistic Regression of Elements of SO(3) using Quaternion Averaging and Uncertainty Injection</a></th>
                    </tr>
                
                    <tr id="c9492fcd60bf1f052d44241f0bc33dd0ef0982d7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c9492fcd60bf1f052d44241f0bc33dd0ef0982d7">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SUMO/Shin_Multi-layer_Depth_and_Epipolar_Feature_Transformers_for_3D_Scene_Reconstruction_CVPRW_2019_paper.html">Multi-layer Depth and Epipolar Feature Transformers for 3D Scene Reconstruction</a></th>
                    </tr>
                
                    <tr id="8265a358a85d8e43f9a4810d4e12fcc732d42a27">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8265a358a85d8e43f9a4810d4e12fcc732d42a27">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Huang_Deep_Feature_Fusion_with_Multiple_Granularity_for_Vehicle_Re-identification_CVPRW_2019_paper.html">Deep Feature Fusion with Multiple Granularity for Vehicle Re-identification</a></th>
                    </tr>
                
                    <tr id="9daae6a28b2cd86f006d3cc87609779d541b23c2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9daae6a28b2cd86f006d3cc87609779d541b23c2">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Chang_AI_City_Challenge_2019_--_City-Scale_Video_Analytics_for_Smart_CVPRW_2019_paper.html">AI City Challenge 2019 -- City-Scale Video Analytics for Smart Transportation</a></th>
                    </tr>
                
                    <tr id="3859990fc1d6c9efb818fb4c81340962dbb00029">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3859990fc1d6c9efb818fb4c81340962dbb00029">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Lv_Vehicle_Re-Identification_with_Location_and_Time_Stamps_CVPRW_2019_paper.html">Vehicle Re-Identification with Location and Time Stamps</a></th>
                    </tr>
                
                    <tr id="edb50a4410c6484fc0bcd9474c82038396ab27e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/edb50a4410c6484fc0bcd9474c82038396ab27e1">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Le_Weakly_Labeling_the_Antarctic_The_Penguin_Colony_Case_CVPRW_2019_paper.html">Weakly Labeling the Antarctic: The Penguin Colony Case</a></th>
                    </tr>
                
                    <tr id="a90b8751831c790f930815db846df37ae94f27f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a90b8751831c790f930815db846df37ae94f27f2">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Rehman_Deep_Landscape_Features_for_Improving_Vector-borne_Disease_Prediction_CVPRW_2019_paper.html">Deep Landscape Features for Improving Vector-borne Disease Prediction</a></th>
                    </tr>
                
                    <tr id="4a0a2fd89084ad8dabf8009765dc44d0530d4798">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4a0a2fd89084ad8dabf8009765dc44d0530d4798">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/3DWidDGET/K_L_Navaneet_DIFFER_Moving_Beyond_3D_Reconstruction_with_Differentiable_Feature_Rendering_CVPRW_2019_paper.html">DIFFER: Moving Beyond 3D Reconstruction with Differentiable Feature Rendering</a></th>
                    </tr>
                
                    <tr id="2c1ccf7b7d201fa53e555aa714b743144c059348">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c1ccf7b7d201fa53e555aa714b743144c059348">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/3DWidDGET/Amit_Raj_Learning_to_Generate_Textures_on_3D_Meshes_CVPRW_2019_paper.html">Learning to Generate Textures on 3D Meshes</a></th>
                    </tr>
                
                    <tr id="b22075a94a4ad5a6c612ddf6357fd9d1e5be27c1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b22075a94a4ad5a6c612ddf6357fd9d1e5be27c1">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Takeda_Video_Magnification_in_the_Wild_Using_Fractional_Anisotropy_in_Temporal_CVPR_2019_paper.html">Video Magnification in the Wild Using Fractional Anisotropy in Temporal Distribution</a></th>
                    </tr>
                
                    <tr id="6cdb91adf87f404cbbedecb0234eac6a78f5598c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6cdb91adf87f404cbbedecb0234eac6a78f5598c">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Learning_to_Film_From_Professional_Human_Motion_Videos_CVPR_2019_paper.html">Learning to Film From Professional Human Motion Videos</a></th>
                    </tr>
                
                    <tr id="e6ccd4369781ccc31bd6e08a837d4ab0d9ddda4c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e6ccd4369781ccc31bd6e08a837d4ab0d9ddda4c">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hu_Listen_to_the_Image_CVPR_2019_paper.html">Listen to the Image</a></th>
                    </tr>
                
                    <tr id="dde47480f7efd36903d3e554256f6f1d185d6415">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dde47480f7efd36903d3e554256f6f1d185d6415">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qiu_World_From_Blur_CVPR_2019_paper.html">World From Blur</a></th>
                    </tr>
                
                    <tr id="42f60c677dea8e7beb5e03713604c8246c5999c3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/42f60c677dea8e7beb5e03713604c8246c5999c3">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Korus_Content_Authentication_for_Neural_Imaging_Pipelines_End-To-End_Optimization_of_Photo_CVPR_2019_paper.html">Content Authentication for Neural Imaging Pipelines: End-To-End Optimization of Photo Provenance in Complex Distribution Channels</a></th>
                    </tr>
                
                    <tr id="50653a00db380cb5f6ad308538334062617a82e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50653a00db380cb5f6ad308538334062617a82e6">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Herath_Min-Max_Statistical_Alignment_for_Transfer_Learning_CVPR_2019_paper.html">Min-Max Statistical Alignment for Transfer Learning</a></th>
                    </tr>
                
                    <tr id="6a60daa8ca0453bdb2ce6a6b6b87a47b75392dfc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a60daa8ca0453bdb2ce6a6b6b87a47b75392dfc">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Hyperspectral_Imaging_With_Random_Printed_Mask_CVPR_2019_paper.html">Hyperspectral Imaging With Random Printed Mask</a></th>
                    </tr>
                
                    <tr id="5b57887fa29f69084975d09b900313a1f2e44551">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b57887fa29f69084975d09b900313a1f2e44551">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ho_PIEs_Pose_Invariant_Embeddings_CVPR_2019_paper.html">PIEs: Pose Invariant Embeddings</a></th>
                    </tr>
                
                    <tr id="dca97f65ddb1831e35ba0e1edff32d1fa8645e8d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dca97f65ddb1831e35ba0e1edff32d1fa8645e8d">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Context-Aware_Spatio-Recurrent_Curvilinear_Structure_Segmentation_CVPR_2019_paper.html">Context-Aware Spatio-Recurrent Curvilinear Structure Segmentation</a></th>
                    </tr>
                
                    <tr id="d96b37a9877dc7917c06b41db20e05d862ecde5c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d96b37a9877dc7917c06b41db20e05d862ecde5c">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/FFSS-USAD/Kucer_A_Detect-Then-Retrieve_Model_for_Multi-Domain_Fashion_Item_Retrieval_CVPRW_2019_paper.html">A Detect-Then-Retrieve Model for Multi-Domain Fashion Item Retrieval</a></th>
                    </tr>
                
                    <tr id="53d802737cd5975bf17dae741d0831142d75b162">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/53d802737cd5975bf17dae741d0831142d75b162">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Ali_Variational_Learning_of_Beta-Liouville_Hidden_Markov_Models_for_Infrared_Action_CVPRW_2019_paper.html">Variational Learning of Beta-Liouville Hidden Markov Models for Infrared Action Recognition</a></th>
                    </tr>
                
                    <tr id="e0147af8428442557dca587489ed0a86b649f8b4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e0147af8428442557dca587489ed0a86b649f8b4">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Istasse_Associative_Embedding_for_Team_Discrimination_CVPRW_2019_paper.html">Associative Embedding for Team Discrimination</a></th>
                    </tr>
                
                    <tr id="94ec689c3b2120585b882047ca947407b778c7d5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/94ec689c3b2120585b882047ca947407b778c7d5">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/ISIC/Phillips_Segmentation_of_Prognostic_Tissue_Structures_in_Cutaneous_Melanoma_Using_Whole_CVPRW_2019_paper.html">Segmentation of Prognostic Tissue Structures in Cutaneous Melanoma Using Whole Slide Images</a></th>
                    </tr>
                
                    <tr id="cf0aff9ef72cb7501b297cae88ec2cf3a00b5b71">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cf0aff9ef72cb7501b297cae88ec2cf3a00b5b71">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SkelNetOn/Jiang_Feature_Hourglass_Network_for_Skeleton_Detection_CVPRW_2019_paper.html">Feature Hourglass Network for Skeleton Detection</a></th>
                    </tr>
                
                    <tr id="dad716738c65b0bdada587e1f74486dd992d9a2a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dad716738c65b0bdada587e1f74486dd992d9a2a">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Pouyanfar_ROADS_Randomization_for_Obstacle_Avoidance_and_Driving_in_Simulation_CVPRW_2019_paper.html">ROADS: Randomization for Obstacle Avoidance and Driving in Simulation</a></th>
                    </tr>
                
                    <tr id="b525b9cc5a48cc5f485957edc65dce94207bb1d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b525b9cc5a48cc5f485957edc65dce94207bb1d4">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BCMCVAI/Jourdan_A_Probabilistic_Model_of_the_Bitcoin_Blockchain_CVPRW_2019_paper.html">A Probabilistic Model of the Bitcoin Blockchain</a></th>
                    </tr>
                
                    <tr id="fb9fb80dfea823ca565ddff77cdff74000ca66ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fb9fb80dfea823ca565ddff77cdff74000ca66ac">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BCMCVAI/Bui_ARCHANGEL_Tamper-Proofing_Video_Archives_Using_Temporal_Content_Hashes_on_the_CVPRW_2019_paper.html">ARCHANGEL: Tamper-Proofing Video Archives Using Temporal Content Hashes on the Blockchain</a></th>
                    </tr>
                
                    <tr id="dccec680a4bc285331705fa0c0ba38ac3a485c1c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dccec680a4bc285331705fa0c0ba38ac3a485c1c">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BCMCVAI/Delgado-Mohatar_Biometric_Template_Storage_With_Blockchain_A_First_Look_Into_Cost_CVPRW_2019_paper.html">Biometric Template Storage With Blockchain: A First Look Into Cost and Performance Tradeoffs</a></th>
                    </tr>
                
                    <tr id="edf126a5ff309dd1cbfc0c594e09f7063692338b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/edf126a5ff309dd1cbfc0c594e09f7063692338b">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Brummer_Natural_Image_Noise_Dataset_CVPRW_2019_paper.html">Natural Image Noise Dataset</a></th>
                    </tr>
                
                    <tr id="6700383c2197b08b79a88bb30ec6fec32ec7e322">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6700383c2197b08b79a88bb30ec6fec32ec7e322">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Chen_Multi-Scale_Adaptive_Dehazing_Network_CVPRW_2019_paper.html">Multi-Scale Adaptive Dehazing Network</a></th>
                    </tr>
                
                    <tr id="ef6fc1042d8ef51c5268799e33b64e9fd77c0d36">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ef6fc1042d8ef51c5268799e33b64e9fd77c0d36">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Pernici_Maximally_Compact_and_Separated_Features_with_Regular_Polytope_Networks_CVPRW_2019_paper.html">Maximally Compact and Separated Features with Regular Polytope Networks</a></th>
                    </tr>
                
                    <tr id="2f27d72cf2a40a7bff90d1450c9344fbb3cff30b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2f27d72cf2a40a7bff90d1450c9344fbb3cff30b">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Akula_Explainable_AI_as_Collaborative_Task_Solving_CVPRW_2019_paper.html">Explainable AI as Collaborative Task Solving</a></th>
                    </tr>
                
                    <tr id="1ff1fa52b0f69574bc956dcf6a99631eb91eb6ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ff1fa52b0f69574bc956dcf6a99631eb91eb6ab">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Miller_Benchmarking_Sampling-based_Probabilistic_Object_Detectors_CVPRW_2019_paper.html">Benchmarking Sampling-based Probabilistic Object Detectors</a></th>
                    </tr>
                
                    <tr id="823c0abb5a7a0b2503c3bc0d5629950cc78e1a4f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/823c0abb5a7a0b2503c3bc0d5629950cc78e1a4f">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Hou_A_Locality_Aware_City-Scale_Multi-Camera_Vehicle_Tracking_System_CVPRW_2019_paper.html">A Locality Aware City-Scale Multi-Camera Vehicle Tracking System</a></th>
                    </tr>
                
                    <tr id="dad716738c65b0bdada587e1f74486dd992d9a2a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dad716738c65b0bdada587e1f74486dd992d9a2a">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Pouyanfar_ROADS_Randomization_for_Obstacle_Avoidance_and_Driving_in_Simulation_CVPRW_2019_paper.html">ROADS: Randomization for Obstacle Avoidance and Driving in Simulation</a></th>
                    </tr>
                
                    <tr id="d2b1cf0f018d4eeca84236347cf25e1b66fbbc61">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d2b1cf0f018d4eeca84236347cf25e1b66fbbc61">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Sight_and_Sound/Naji_Khosravan_On_Attention_Modules_for_Audio-Visual_Synchronization_CVPRW_2019_paper.html">On Attention Modules for Audio-Visual Synchronization</a></th>
                    </tr>
                
                    <tr id="315184f8d685a333a486e4421cab8739c821aa39">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/315184f8d685a333a486e4421cab8739c821aa39">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MMLV/Bera_The_Emotionally_Intelligent_Robot_Improving_Socially-aware_Human_Prediction_in_Crowded_CVPRW_2019_paper.html">The Emotionally Intelligent Robot: Improving Socially-aware Human Prediction in Crowded Environments</a></th>
                    </tr>
                
                    <tr id="ef4f2ecb049b6438061d73173dd62454f8881098">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ef4f2ecb049b6438061d73173dd62454f8881098">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Lam_Compressing_Weight-updates_for_Image_Artifacts_Removal_Neural_Networks_CVPRW_2019_paper.html">Compressing Weight-updates for Image Artifacts Removal Neural Networks</a></th>
                    </tr>
                
                    <tr id="2c1136b2fe1c7b845dd2caa8389a81503f924fec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c1136b2fe1c7b845dd2caa8389a81503f924fec">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Deep_Global_Generalized_Gaussian_Networks_CVPR_2019_paper.html">Deep Global Generalized Gaussian Networks</a></th>
                    </tr>
                
                    <tr id="c095890a87c90db13e4d7c9311d223c5f2d96cac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c095890a87c90db13e4d7c9311d223c5f2d96cac">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hertz_Blind_Visual_Motif_Removal_From_a_Single_Image_CVPR_2019_paper.html">Blind Visual Motif Removal From a Single Image</a></th>
                    </tr>
                
                    <tr id="6dea6735e0d791ec34ab5bba8c0ef2d0c97bb505">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6dea6735e0d791ec34ab5bba8c0ef2d0c97bb505">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Variational_Bayesian_Dropout_With_a_Hierarchical_Prior_CVPR_2019_paper.html">Variational Bayesian Dropout With a Hierarchical Prior</a></th>
                    </tr>
                
                    <tr id="afa50f7f19f88348560b4d06d9e1360d05a92111">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/afa50f7f19f88348560b4d06d9e1360d05a92111">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_A_MainSubsidiary_Network_Framework_for_Simplifying_Binary_Neural_Networks_CVPR_2019_paper.html">A Main/Subsidiary Network Framework for Simplifying Binary Neural Networks</a></th>
                    </tr>
                
                    <tr id="c7b64eec2966cd477592f99e9d98579b5df4f11b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c7b64eec2966cd477592f99e9d98579b5df4f11b">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shakeri_Moving_Object_Detection_Under_Discontinuous_Change_in_Illumination_Using_Tensor_CVPR_2019_paper.html">Moving Object Detection Under Discontinuous Change in Illumination Using Tensor Low-Rank and Invariant Sparse Decomposition</a></th>
                    </tr>
                
                    <tr id="27caa718045d77444ba0a2b22598e7fc18801e91">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/27caa718045d77444ba0a2b22598e7fc18801e91">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Robust_Subspace_Clustering_With_Independent_and_Piecewise_Identically_Distributed_Noise_CVPR_2019_paper.html">Robust Subspace Clustering With Independent and Piecewise Identically Distributed Noise Modeling</a></th>
                    </tr>
                
                    <tr id="f02ea20eb2597ce4ffd6026713a1f804e9436f4d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f02ea20eb2597ce4ffd6026713a1f804e9436f4d">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Puy_A_Flexible_Convolutional_Solver_for_Fast_Style_Transfers_CVPR_2019_paper.html">A Flexible Convolutional Solver for Fast Style Transfers</a></th>
                    </tr>
                
                    <tr id="813a20cec12677579c1541de0a27885e7be41a92">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/813a20cec12677579c1541de0a27885e7be41a92">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Path-Invariant_Map_Networks_CVPR_2019_paper.html">Path-Invariant Map Networks</a></th>
                    </tr>
                
                    <tr id="559fde1e4e7b122c2f9f49d54e8bcbda60118cd4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/559fde1e4e7b122c2f9f49d54e8bcbda60118cd4">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Retrieval-Augmented_Convolutional_Neural_Networks_Against_Adversarial_Examples_CVPR_2019_paper.html">Retrieval-Augmented Convolutional Neural Networks Against Adversarial Examples</a></th>
                    </tr>
                
                    <tr id="fab3d8ca3b0ba22e2a0f31b22f0f8166b0fb8f05">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fab3d8ca3b0ba22e2a0f31b22f0f8166b0fb8f05">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Huang_Motion_Estimation_of_Non-Holonomic_Ground_Vehicles_From_a_Single_Feature_CVPR_2019_paper.html">Motion Estimation of Non-Holonomic Ground Vehicles From a Single Feature Correspondence Measured Over N Views</a></th>
                    </tr>
                
                    <tr id="992b79359884344d7b94192c6123404926d003ba">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/992b79359884344d7b94192c6123404926d003ba">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Shirai_Privacy-Preserving_Annotation_of_Face_Images_Through_Attribute-Preserving_Face_Synthesis_CVPRW_2019_paper.html">Privacy-Preserving Annotation of Face Images Through Attribute-Preserving Face Synthesis</a></th>
                    </tr>
                
                    <tr id="997b8460d87fb41a928e3e47b06ebbe2d1e2798d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/997b8460d87fb41a928e3e47b06ebbe2d1e2798d">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Hosseini_Dropping_Pixels_for_Adversarial_Robustness_CVPRW_2019_paper.html">Dropping Pixels for Adversarial Robustness</a></th>
                    </tr>
                
                    <tr id="29b562dba4a6333a3d1c917c4b99864c71d19ad7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/29b562dba4a6333a3d1c917c4b99864c71d19ad7">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/VOCVALC/Lee_CeMNet_Self-Supervised_Learning_for_Accurate_Continuous_Ego-Motion_Estimation_CVPRW_2019_paper.html">CeMNet: Self-Supervised Learning for Accurate Continuous Ego-Motion Estimation</a></th>
                    </tr>
                
                    <tr id="0e510bafa65f01f630934c525574e575a5ac386a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e510bafa65f01f630934c525574e575a5ac386a">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Chakraborty_Sur-Real_Frechet_Mean_and_Distance_Transform_for_Complex-Valued_Deep_Learning_CVPRW_2019_paper.html">Sur-Real: Frechet Mean and Distance Transform for Complex-Valued Deep Learning</a></th>
                    </tr>
                
                    <tr id="cb4931190972330aae00194f91e9ed6269cb8b59">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cb4931190972330aae00194f91e9ed6269cb8b59">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BIC/Hamad_Automated_Segmentation_of_the_Vocal_Folds_in_Laryngeal_Endoscopy_Videos_CVPRW_2019_paper.html">Automated Segmentation of the Vocal Folds in Laryngeal Endoscopy Videos Using Deep Convolutional Regression Networks</a></th>
                    </tr>
                
                    <tr id="565fadef83fd57163b91b9176a5d6da164f166d8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/565fadef83fd57163b91b9176a5d6da164f166d8">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Vit_Length_Phenotyping_With_Interest_Point_Detection_CVPRW_2019_paper.html">Length Phenotyping With Interest Point Detection</a></th>
                    </tr>
                
                    <tr id="69a46505f42b8b5ae46e3f11a837782d82ec94e4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/69a46505f42b8b5ae46e3f11a837782d82ec94e4">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Chen_Leaf_Segmentation_by_Functional_Modeling_CVPRW_2019_paper.html">Leaf Segmentation by Functional Modeling</a></th>
                    </tr>
                
                    <tr id="37cfe39ef473170e2404b0d05180ea36f702f5f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/37cfe39ef473170e2404b0d05180ea36f702f5f2">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SkelNetOn/Yang_A_Novel_Algorithm_for_Skeleton_Extraction_From_Images_Using_Topological_CVPRW_2019_paper.html">A Novel Algorithm for Skeleton Extraction From Images Using Topological Graph Analysis</a></th>
                    </tr>
                
                    <tr id="28670555051e6ce0cb2aa38e38a0d15737397ce4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/28670555051e6ce0cb2aa38e38a0d15737397ce4">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SkelNetOn/Liu_Parametric_Skeleton_Generation_via_Gaussian_Mixture_Models_CVPRW_2019_paper.html">Parametric Skeleton Generation via Gaussian Mixture Models</a></th>
                    </tr>
                
                    <tr id="27e7ceb2e21c2344bca2cadbe0feb391b50d851c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/27e7ceb2e21c2344bca2cadbe0feb391b50d851c">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Brosh_Accurate_Visual_Localization_for_Automotive_Applications_CVPRW_2019_paper.html">Accurate Visual Localization for Automotive Applications</a></th>
                    </tr>
                
                    <tr id="cee3af2e5b28aca09d97dabcbee1cc447f985cc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cee3af2e5b28aca09d97dabcbee1cc447f985cc1">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BCMCVAI/Sarpatwar_Blockchain_Enabled_AI_Marketplace_The_Price_You_Pay_for_Trust_CVPRW_2019_paper.html">Blockchain Enabled AI Marketplace: The Price You Pay for Trust</a></th>
                    </tr>
                
                    <tr id="1b6e1d5ca640a9e23cf0677d87befc58a9ea278d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1b6e1d5ca640a9e23cf0677d87befc58a9ea278d">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Tripathi_Compact_Scene_Graphs_for_Layout_Composition_and_Patch_Retrieval_CVPRW_2019_paper.html">Compact Scene Graphs for Layout Composition and Patch Retrieval</a></th>
                    </tr>
                
                    <tr id="b9814a336b50a7a81ca4cc3dd91059c0f7626489">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b9814a336b50a7a81ca4cc3dd91059c0f7626489">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Mastan_Multi-Level_Encoder-Decoder_Architectures_for_Image_Restoration_CVPRW_2019_paper.html">Multi-Level Encoder-Decoder Architectures for Image Restoration</a></th>
                    </tr>
                
                    <tr id="90376f8998fba32674ed9a04fa2a0d644a369c5d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/90376f8998fba32674ed9a04fa2a0d644a369c5d">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Jang_DenseNet_With_Deep_Residual_Channel-Attention_Blocks_for_Single_Image_Super_CVPRW_2019_paper.html">DenseNet With Deep Residual Channel-Attention Blocks for Single Image Super Resolution</a></th>
                    </tr>
                
                    <tr id="089da19ed3b0142c2de055579049789e1090f278">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/089da19ed3b0142c2de055579049789e1090f278">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Xu_SCAN_Spatial_Color_Attention_Networks_for_Real_Single_Image_Super-Resolution_CVPRW_2019_paper.html">SCAN: Spatial Color Attention Networks for Real Single Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="4d42f185bcad97d3bb37737d7e802799792b9723">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4d42f185bcad97d3bb37737d7e802799792b9723">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Carley_Person_Re-Identification_From_Gait_Using_an_Autocorrelation_Network_CVPRW_2019_paper.html">Person Re-Identification From Gait Using an Autocorrelation Network</a></th>
                    </tr>
                
                    <tr id="bbe1268f17a01b8197a31c1fbc998ebaf8139058">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bbe1268f17a01b8197a31c1fbc998ebaf8139058">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/Gupta_Partially-Independent_Framework_for_Breast_Cancer_Histopathological_Image_Classification_CVPRW_2019_paper.html">Partially-Independent Framework for Breast Cancer Histopathological Image Classification</a></th>
                    </tr>
                
                    <tr id="38aa1e6f83ad36024af7d7eb089ea5bafd6c1df2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38aa1e6f83ad36024af7d7eb089ea5bafd6c1df2">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UAVision/Muller_Learning_a_Controller_Fusion_Network_by_Online_Trajectory_Filtering_for_CVPRW_2019_paper.html">Learning a Controller Fusion Network by Online Trajectory Filtering for Vision-Based UAV Racing</a></th>
                    </tr>
                
                    <tr id="2e80c193ac87b01154eca530ba54bd00be3d9ddd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e80c193ac87b01154eca530ba54bd00be3d9ddd">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Augmented_Human_Humancentric_Understanding_and_2D3D_Synthesis/Zhang_Exploiting_Offset-guided_Network_for_Pose_Estimation_and_Tracking_CVPRW_2019_paper.html">Exploiting Offset-guided Network for Pose Estimation and Tracking</a></th>
                    </tr>
                
                    <tr id="27e7ceb2e21c2344bca2cadbe0feb391b50d851c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/27e7ceb2e21c2344bca2cadbe0feb391b50d851c">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Brosh_Accurate_Visual_Localization_for_Automotive_Applications_CVPRW_2019_paper.html">Accurate Visual Localization for Automotive Applications</a></th>
                    </tr>
                
                    <tr id="80bb60b737b53b23f5eb1f56cd145153d4581330">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/80bb60b737b53b23f5eb1f56cd145153d4581330">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Haurilet_Its_Not_About_the_Journey_Its_About_the_Destination_Following_CVPR_2019_paper.html">It&#39;s Not About the Journey; It&#39;s About the Destination: Following Soft Paths Under Question-Guidance for Visual Reasoning</a></th>
                    </tr>
                
                    <tr id="bbc9cb65aeb814de917fecab31843b95070c3cc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bbc9cb65aeb814de917fecab31843b95070c3cc1">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Suris_Learning_Words_by_Drawing_Images_CVPR_2019_paper.html">Learning Words by Drawing Images</a></th>
                    </tr>
                
                    <tr id="f72a1933f54ef6560ad39da0c4ac6a779135ab3d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f72a1933f54ef6560ad39da0c4ac6a779135ab3d">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Qiao_Tell_Me_Where_I_Am_Object-Level_Scene_Context_Prediction_CVPR_2019_paper.html">Tell Me Where I Am: Object-Level Scene Context Prediction</a></th>
                    </tr>
                
                    <tr id="1bb6657f6c8e629ebff9817d4b6d9b5d002b2b6b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1bb6657f6c8e629ebff9817d4b6d9b5d002b2b6b">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zaeemzadeh_Iterative_Projection_and_Matching_Finding_Structure-Preserving_Representatives_and_Its_Application_CVPR_2019_paper.html">Iterative Projection and Matching: Finding Structure-Preserving Representatives and Its Application to Computer Vision</a></th>
                    </tr>
                
                    <tr id="06e89127926108353b02fd64e60e80fc24412816">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/06e89127926108353b02fd64e60e80fc24412816">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Structure-Preserving_Stereoscopic_View_Synthesis_With_Multi-Scale_Adversarial_Correlation_Matching_CVPR_2019_paper.html">Structure-Preserving Stereoscopic View Synthesis With Multi-Scale Adversarial Correlation Matching</a></th>
                    </tr>
                
                    <tr id="415a163f29356c0c02ee6ad34cac40e42a58d969">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/415a163f29356c0c02ee6ad34cac40e42a58d969">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Araslanov_Actor-Critic_Instance_Segmentation_CVPR_2019_paper.html">Actor-Critic Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="6a2b5c5c9da708d13f855cad185cfe4bbf1567af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a2b5c5c9da708d13f855cad185cfe4bbf1567af">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Mollenhoff_Lifting_Vectorial_Variational_Problems_A_Natural_Formulation_Based_on_Geometric_CVPR_2019_paper.html">Lifting Vectorial Variational Problems: A Natural Formulation Based on Geometric Measure Theory and Discrete Exterior Calculus</a></th>
                    </tr>
                
                    <tr id="664539e42a9e5bc8f75745e8d40af72b4b40ccea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/664539e42a9e5bc8f75745e8d40af72b4b40ccea">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kortylewski_Greedy_Structure_Learning_of_Hierarchical_Compositional_Models_CVPR_2019_paper.html">Greedy Structure Learning of Hierarchical Compositional Models</a></th>
                    </tr>
                
                    <tr id="8bd5f5d4bc0aab144529fed262ba476f0926b543">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8bd5f5d4bc0aab144529fed262ba476f0926b543">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/da_Silveira_Perturbation_Analysis_of_the_8-Point_Algorithm_A_Case_Study_for_CVPR_2019_paper.html">Perturbation Analysis of the 8-Point Algorithm: A Case Study for Wide FoV Cameras</a></th>
                    </tr>
                
                    <tr id="66c483605f17111fbcd51ef4ab309103d129457d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/66c483605f17111fbcd51ef4ab309103d129457d">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Dong_Low-Rank_Laplacian-Uniform_Mixed_Model_for_Robust_Face_Recognition_CVPR_2019_paper.html">Low-Rank Laplacian-Uniform Mixed Model for Robust Face Recognition</a></th>
                    </tr>
                
                    <tr id="e30acee7999f534f5e364610eddfc983791ec899">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e30acee7999f534f5e364610eddfc983791ec899">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Retsinas_An_Alternative_Deep_Feature_Approach_to_Line_Level_Keyword_Spotting_CVPR_2019_paper.html">An Alternative Deep Feature Approach to Line Level Keyword Spotting</a></th>
                    </tr>
                
                    <tr id="51b02c4865bc1adc60f12de0830e6bda8249eb18">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/51b02c4865bc1adc60f12de0830e6bda8249eb18">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Precognition/Choi_Learning_to_Infer_Relations_for_Future_Trajectory_Forecast_CVPRW_2019_paper.html">Learning to Infer Relations for Future Trajectory Forecast</a></th>
                    </tr>
                
                    <tr id="0a6b1aa297a8448aeb6a3b9ede9e3272d81b3d03">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a6b1aa297a8448aeb6a3b9ede9e3272d81b3d03">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/FFSS-USAD/Kataoka_Ten-Million-Order_Human_Database_for_World-Wide_Fashion_Culture_Analysis_CVPRW_2019_paper.html">Ten-Million-Order Human Database for World-Wide Fashion Culture Analysis</a></th>
                    </tr>
                
                    <tr id="4357e752131594302ba91027762884e22d1d9253">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4357e752131594302ba91027762884e22d1d9253">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Poster_An_Examination_of_Deep-Learning_Based_Landmark_Detection_Methods_on_Thermal_CVPRW_2019_paper.html">An Examination of Deep-Learning Based Landmark Detection Methods on Thermal Face Imagery</a></th>
                    </tr>
                
                    <tr id="9f41b3500e556203de6659ed57a3d8fdd5496a4c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9f41b3500e556203de6659ed57a3d8fdd5496a4c">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Chen_Adversarial_Large-Scale_Root_Gap_Inpainting_CVPRW_2019_paper.html">Adversarial Large-Scale Root Gap Inpainting</a></th>
                    </tr>
                
                    <tr id="db9c047ae848713e04069c180caa31359e1d1e86">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db9c047ae848713e04069c180caa31359e1d1e86">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MBCCV/Sidorov_Changing_the_Image_Memorability_From_Basic_Photo_Editing_to_GANs_CVPRW_2019_paper.html">Changing the Image Memorability: From Basic Photo Editing to GANs</a></th>
                    </tr>
                
                    <tr id="3ca3a708d0b2e2b8cb1010c364e89de3c85adfe2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ca3a708d0b2e2b8cb1010c364e89de3c85adfe2">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MBCCV/Luo_Visual_Attention_in_Multi-Label_Image_Classification_CVPRW_2019_paper.html">Visual Attention in Multi-Label Image Classification</a></th>
                    </tr>
                
                    <tr id="3bb85b86fb731aef120d3e5211f2f49a19d90917">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3bb85b86fb731aef120d3e5211f2f49a19d90917">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BCMCVAI/Lopes_Robot_Workspace_Monitoring_Using_a_Blockchain-Based_3D_Vision_Approach_CVPRW_2019_paper.html">Robot Workspace Monitoring Using a Blockchain-Based 3D Vision Approach</a></th>
                    </tr>
                
                    <tr id="9c3921b8085c7f3c6227622735a19dee1abb1bb1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c3921b8085c7f3c6227622735a19dee1abb1bb1">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/He_Scan-Flood_FillSCAFF_An_Efficient_Automatic_Precise_Region_Filling_Algorithm_for_CVPRW_2019_paper.html">Scan-Flood Fill(SCAFF): An Efficient Automatic Precise Region Filling Algorithm for Complicated Regions</a></th>
                    </tr>
                
                    <tr id="7e616d422c05a9eae4eea346c6b9a8daca3b0ff2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e616d422c05a9eae4eea346c6b9a8daca3b0ff2">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Dube_Automatic_Labeling_of_Data_for_Transfer_Learning_CVPRW_2019_paper.html">Automatic Labeling of Data for Transfer Learning</a></th>
                    </tr>
                
                    <tr id="2c4a3e707c1dc6ee9fd45c91cbc981b509ce511f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c4a3e707c1dc6ee9fd45c91cbc981b509ce511f">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Zhang_Explaining_the_PointNet_What_Has_Been_Learned_Inside_the_PointNet_CVPRW_2019_paper.html">Explaining the PointNet: What Has Been Learned Inside the PointNet?</a></th>
                    </tr>
                
                    <tr id="d61610e001960d872bff489115fa59a7cc6a2aa0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d61610e001960d872bff489115fa59a7cc6a2aa0">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Face_and_Gesture_Analysis_for_Health_Informatics/Kumar_CLASSIFICATION_OF_FACIAL_MICRO-EXPRESSIONS_USING_MOTION_MAGNIFIED_EMOTION_AVATAR_IMAGES_CVPRW_2019_paper.html">CLASSIFICATION OF FACIAL MICRO-EXPRESSIONS USING MOTION MAGNIFIED EMOTION AVATAR IMAGES</a></th>
                    </tr>
                
                    <tr id="1ff027d262aeba829bc59f1fdf3550d83246b064">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ff027d262aeba829bc59f1fdf3550d83246b064">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Ghosh_SpliceRadar_A_Learned_Method_For_Blind_Image_Forensics_CVPRW_2019_paper.html">SpliceRadar: A Learned Method For Blind Image Forensics</a></th>
                    </tr>
                
                    <tr id="700831b6e7eaf17a00a4973bca167f31d115e01f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/700831b6e7eaf17a00a4973bca167f31d115e01f">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Shankar_Comparative_Study_on_various_Losses_for_Vehicle_Re-identification_CVPRW_2019_paper.html">Comparative Study on various Losses for Vehicle Re-identification</a></th>
                    </tr>
                
                    <tr id="a78637cecc6d21abf8c98583fdfc656efc0ce105">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a78637cecc6d21abf8c98583fdfc656efc0ce105">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Augmented_Human_Humancentric_Understanding_and_2D3D_Synthesis/Chen_Unpaired_Pose_Guided_Human_Image_Generation_CVPRW_2019_paper.html">Unpaired Pose Guided Human Image Generation</a></th>
                    </tr>
                
                    <tr id="26f0719ad274b304833a9b9c94235e3f3db694f3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26f0719ad274b304833a9b9c94235e3f3db694f3">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Wen_Variational_Autoencoder_based_Image_Compression_with_Pyramidal_Features_and_Context_CVPRW_2019_paper.html">Variational Autoencoder based Image Compression with Pyramidal Features and Context Entropy Model</a></th>
                    </tr>
                
                    <tr id="d5a39dde3426cf3c06ff5806c406f8ed3ced600b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d5a39dde3426cf3c06ff5806c406f8ed3ced600b">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/DOAI/Al-Shakarji_Multi-Cue_Vehicle_Detection_for_Semantic_Video_Compression_in_Georegistered_Aerial_CVPRW_2019_paper.html">Multi-Cue Vehicle Detection for Semantic Video Compression in Georegistered Aerial Videos</a></th>
                    </tr>
                
                    <tr id="8e77845685cb3efc6e3622e1cd3f63ab11743810">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e77845685cb3efc6e3622e1cd3f63ab11743810">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Cheng_Local_to_Global_Learning_Gradually_Adding_Classes_for_Training_Deep_CVPR_2019_paper.html">Local to Global Learning: Gradually Adding Classes for Training Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="7b08e87fa4a636fd84ca892720334fd545427733">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b08e87fa4a636fd84ca892720334fd545427733">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Surface_Reconstruction_From_Normals_A_Robust_DGP-Based_Discontinuity_Preservation_Approach_CVPR_2019_paper.html">Surface Reconstruction From Normals: A Robust DGP-Based Discontinuity Preservation Approach</a></th>
                    </tr>
                
                    <tr id="00f81a03f16366f0a838855c0398d94b540f71a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00f81a03f16366f0a838855c0398d94b540f71a9">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Blanchard_A_Neurobiological_Evaluation_Metric_for_Neural_Network_Model_Search_CVPR_2019_paper.html">A Neurobiological Evaluation Metric for Neural Network Model Search</a></th>
                    </tr>
                
                    <tr id="d245c87739c5339f60a67b440d72dccb547c7bcf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d245c87739c5339f60a67b440d72dccb547c7bcf">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ye_Predicting_Visible_Image_Differences_Under_Varying_Display_Brightness_and_Viewing_CVPR_2019_paper.html">Predicting Visible Image Differences Under Varying Display Brightness and Viewing Distance</a></th>
                    </tr>
                
                    <tr id="92ad5b4fdd762beea799fe248d1d79f427210e24">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/92ad5b4fdd762beea799fe248d1d79f427210e24">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lange_Combinatorial_Persistency_Criteria_for_Multicut_and_Max-Cut_CVPR_2019_paper.html">Combinatorial Persistency Criteria for Multicut and Max-Cut</a></th>
                    </tr>
                
                    <tr id="f8bd5ecc395f208d9b40488181979817fe148214">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f8bd5ecc395f208d9b40488181979817fe148214">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yuan_A_Decomposition_Algorithm_for_the_Sparse_Generalized_Eigenvalue_Problem_CVPR_2019_paper.html">A Decomposition Algorithm for the Sparse Generalized Eigenvalue Problem</a></th>
                    </tr>
                
                    <tr id="091b0ad82f3900ddd301b3a2098bccc5a9d75f0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/091b0ad82f3900ddd301b3a2098bccc5a9d75f0c">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Spencer_Scale-Adaptive_Neural_Dense_Features_Learning_via_Hierarchical_Context_Aggregation_CVPR_2019_paper.html">Scale-Adaptive Neural Dense Features: Learning via Hierarchical Context Aggregation</a></th>
                    </tr>
                
                    <tr id="f7b09a4815c62f1dfa66ac9c86c7efbb14d506fd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7b09a4815c62f1dfa66ac9c86c7efbb14d506fd">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Fan_Boosting_Local_Shape_Matching_for_Dense_3D_Face_Correspondence_CVPR_2019_paper.html">Boosting Local Shape Matching for Dense 3D Face Correspondence</a></th>
                    </tr>
                
                    <tr id="f14746ffe54b4e1af4f96ca65407d40ac58ea879">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f14746ffe54b4e1af4f96ca65407d40ac58ea879">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Swoboda_MAP_Inference_via_Block-Coordinate_Frank-Wolfe_Algorithm_CVPR_2019_paper.html">MAP Inference via Block-Coordinate Frank-Wolfe Algorithm</a></th>
                    </tr>
                
                    <tr id="27325b4b42a8c107cb53b93ab27f26dc080e5d63">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/27325b4b42a8c107cb53b93ab27f26dc080e5d63">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhou_Learning_to_Learn_Image_Classifiers_With_Visual_Analogy_CVPR_2019_paper.html">Learning to Learn Image Classifiers With Visual Analogy</a></th>
                    </tr>
                
                    <tr id="26ca67516452ef98808f3c4c388a3b9af9cbb283">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26ca67516452ef98808f3c4c388a3b9af9cbb283">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yoo_Dichromatic_Model_Based_Temporal_Color_Constancy_for_AC_Light_Sources_CVPR_2019_paper.html">Dichromatic Model Based Temporal Color Constancy for AC Light Sources</a></th>
                    </tr>
                
                    <tr id="71fbbbb5d0140f277ece5509dec93a4984a41012">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/71fbbbb5d0140f277ece5509dec93a4984a41012">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Precognition/Butepage_Predicting_the_What_and_How_-_a_Probabilistic_Semi-Supervised_Approach_CVPRW_2019_paper.html">Predicting the What and How - a Probabilistic Semi-Supervised Approach to Multi-Task Human Activity Modeling</a></th>
                    </tr>
                
                    <tr id="9f74d76deabce98d643daceb044df2bc4acdd0cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9f74d76deabce98d643daceb044df2bc4acdd0cc">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Suarez_Image_Vegetation_Index_Through_a_Cycle_Generative_Adversarial_Network_CVPRW_2019_paper.html">Image Vegetation Index Through a Cycle Generative Adversarial Network</a></th>
                    </tr>
                
                    <tr id="e585b9f3ec8ecdf9c86e87b156a1ba4c24b0e849">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e585b9f3ec8ecdf9c86e87b156a1ba4c24b0e849">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EarthVision/Bittner_Late_or_Earlier_Information_Fusion_From_Depth_and_Spectral_Data_CVPRW_2019_paper.html">Late or Earlier Information Fusion From Depth and Spectral Data? Large-Scale Digital Surface Model Refinement by Hybrid-CGAN</a></th>
                    </tr>
                
                    <tr id="865cd67e7ae6765fbc4f19f67e490d2c181dc5d3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/865cd67e7ae6765fbc4f19f67e490d2c181dc5d3">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EarthVision/Rafique_Weakly_Supervised_Fusion_of_Multiple_Overhead_Images_CVPRW_2019_paper.html">Weakly Supervised Fusion of Multiple Overhead Images</a></th>
                    </tr>
                
                    <tr id="714a0dd2477b2ed6469fdb5e9345f8b2df36dec2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/714a0dd2477b2ed6469fdb5e9345f8b2df36dec2">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/Nagpal_Expression_Classification_in_Children_Using_Mean_Supervised_Deep_Boltzmann_Machine_CVPRW_2019_paper.html">Expression Classification in Children Using Mean Supervised Deep Boltzmann Machine</a></th>
                    </tr>
                
                    <tr id="5add1a183d88a5153218ea92a0b9f2dcc14d9a04">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5add1a183d88a5153218ea92a0b9f2dcc14d9a04">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Tomasello_DSCnet_Replicating_Lidar_Point_Clouds_With_Deep_Sensor_Cloning_CVPRW_2019_paper.html">DSCnet: Replicating Lidar Point Clouds With Deep Sensor Cloning</a></th>
                    </tr>
                
                    <tr id="c5a16cfc6647e86dbaa61674bd71ba462976e475">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c5a16cfc6647e86dbaa61674bd71ba462976e475">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/van_Zwanenberg_Edge_Detection_Techniques_for_Quantifying_Spatial_Imaging_System_Performance_and_CVPRW_2019_paper.html">Edge Detection Techniques for Quantifying Spatial Imaging System Performance and Image Quality</a></th>
                    </tr>
                
                    <tr id="79d344c5705b3a54fc2af2c6783b0b4c65c706a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/79d344c5705b3a54fc2af2c6783b0b4c65c706a0">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Fan_An_Empirical_Investigation_of_Efficient_Spatio-Temporal_Modeling_in_Video_Restoration_CVPRW_2019_paper.html">An Empirical Investigation of Efficient Spatio-Temporal Modeling in Video Restoration</a></th>
                    </tr>
                
                    <tr id="4ef6edfc233bf6a47e44de5a570462e9bdecc2f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ef6edfc233bf6a47e44de5a570462e9bdecc2f5">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Grm_Face_Hallucination_Revisited_An_Exploratory_Study_on_Dataset_Bias_CVPRW_2019_paper.html">Face Hallucination Revisited: An Exploratory Study on Dataset Bias</a></th>
                    </tr>
                
                    <tr id="6b4070aa01aa0817f2004380359144b95b1f40fc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6b4070aa01aa0817f2004380359144b95b1f40fc">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SAIAD/Chan_The_Ethical_Dilemma_When_Not_Setting_up_Cost-Based_Decision_Rules_CVPRW_2019_paper.html">The Ethical Dilemma When (Not) Setting up Cost-Based Decision Rules in Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="49f5b2d329dea8d05654238027d2c80f4460fa62">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/49f5b2d329dea8d05654238027d2c80f4460fa62">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/Wang_Multiscale_Kernels_for_Enhanced_U-Shaped_Network_to_Improve_3D_Neuron_CVPRW_2019_paper.html">Multiscale Kernels for Enhanced U-Shaped Network to Improve 3D Neuron Tracing</a></th>
                    </tr>
                
                    <tr id="4b7dea0135e22b090d0b71cfa0297d59d0ad213f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4b7dea0135e22b090d0b71cfa0297d59d0ad213f">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Yang_Learn_To_Be_Uncertain_Leveraging_Uncertain_Labels_In_Chest_X-rays_CVPRW_2019_paper.html">Learn To Be Uncertain: Leveraging Uncertain Labels In Chest X-rays With Bayesian Neural Networks</a></th>
                    </tr>
                
                    <tr id="e0641f1d83bd66238de1c085cdbfa495e7154ad3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e0641f1d83bd66238de1c085cdbfa495e7154ad3">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Nikoukhah_JPEG_Grid_Detection_based_on_the_Number_of_DCT_Zeros_CVPRW_2019_paper.html">JPEG Grid Detection based on the Number of DCT Zeros and its Application to Automatic and Localized Forgery Detection</a></th>
                    </tr>
                
                    <tr id="526c4a4a60592770460f017c22500afd0b31a3ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/526c4a4a60592770460f017c22500afd0b31a3ac">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Tarianga_Classification_of_Computer_Generated_and_Natural_Images_based_on_Efficient_CVPRW_2019_paper.html">Classification of Computer Generated and Natural Images based on Efficient Deep Convolutional Recurrent Attention Model</a></th>
                    </tr>
                
                    <tr id="ea6f23397a0c101d934f885c6b10aef1967fcc12">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ea6f23397a0c101d934f885c6b10aef1967fcc12">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Bijelic_Recovering_the_Unseen_Benchmarking_the_Generalization_of_Enhancement_Methods_to_CVPRW_2019_paper.html">Recovering the Unseen: Benchmarking the Generalization of Enhancement Methods to Real World Data in Heavy Fog</a></th>
                    </tr>
                
                    <tr id="d41fa7f0e71b2cbdd11e67c07d29f7dd131d9e8a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d41fa7f0e71b2cbdd11e67c07d29f7dd131d9e8a">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Image_Matching_Local_Features_and_Beyond/Yang_Learning_Data-Adaptive_Interest_Points_through_Epipolar_Adaptation_CVPRW_2019_paper.html">Learning Data-Adaptive Interest Points through Epipolar Adaptation</a></th>
                    </tr>
                
                    <tr id="5add1a183d88a5153218ea92a0b9f2dcc14d9a04">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5add1a183d88a5153218ea92a0b9f2dcc14d9a04">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Tomasello_DSCnet_Replicating_Lidar_Point_Clouds_With_Deep_Sensor_Cloning_CVPRW_2019_paper.html">DSCnet: Replicating Lidar Point Clouds With Deep Sensor Cloning</a></th>
                    </tr>
                
                    <tr id="31302025327dfb17c1c199883d2d370f2fb69c60">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/31302025327dfb17c1c199883d2d370f2fb69c60">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Engelsma_Infant-Prints_Fingerprints_for_Reducing_Infant_Mortality_CVPRW_2019_paper.html">Infant-Prints: Fingerprints for Reducing Infant Mortality</a></th>
                    </tr>
                
                    <tr id="b0a52e04f2696528cf121b2118c138dfa2595fc9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b0a52e04f2696528cf121b2118c138dfa2595fc9">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Jahanian_See_the_E-Waste_Training_Visual_Intelligence_to_See_Dense_Circuit_CVPRW_2019_paper.html">See the E-Waste! Training Visual Intelligence to See Dense Circuit Boards for Recycling</a></th>
                    </tr>
                
                    <tr id="d124bd0f0a6f89880844a7da0e8cb79c9f5cd659">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d124bd0f0a6f89880844a7da0e8cb79c9f5cd659">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Sight_and_Sound/Yapeng_Tian_Audio-Visual_Interpretable_and_Controllable_Video_Captioning_CVPRW_2019_paper.html">Audio-Visual Interpretable and Controllable Video Captioning</a></th>
                    </tr>
                
                    <tr id="bea14cbd2ce369ef4cd062fedbb80a6ed8c0263b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bea14cbd2ce369ef4cd062fedbb80a6ed8c0263b">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Cho_Low_Bit-rate_Image_Compression_based_on_Post-processing_with_Grouped_Residual_CVPRW_2019_paper.html">Low Bit-rate Image Compression based on Post-processing with Grouped Residual Dense Network</a></th>
                    </tr>
                
                    <tr id="eb616132798816100d83e35130f3497a0aa56e20">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eb616132798816100d83e35130f3497a0aa56e20">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Lu_Learned_Image_Restoration_for_VVC_Intra_Coding_CVPRW_2019_paper.html">Learned Image Restoration for VVC Intra Coding</a></th>
                    </tr>
                
                    <tr id="ae8fe1ebef9b8984db04e304d90c54b6c04cfe2c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae8fe1ebef9b8984db04e304d90c54b6c04cfe2c">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hui_Learning_to_Separate_Multiple_Illuminants_in_a_Single_Image_CVPR_2019_paper.html">Learning to Separate Multiple Illuminants in a Single Image</a></th>
                    </tr>
                
                    <tr id="7cd78c72c45d5d4d155a535c763e5f46a993c3c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7cd78c72c45d5d4d155a535c763e5f46a993c3c0">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shen_3D_Shape_Reconstruction_From_Images_in_the_Frequency_Domain_CVPR_2019_paper.html">3D Shape Reconstruction From Images in the Frequency Domain</a></th>
                    </tr>
                
                    <tr id="c803dfb4a3f9efeb249c21d20897daa4bb6a86a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c803dfb4a3f9efeb249c21d20897daa4bb6a86a6">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shi_Scene_Parsing_via_Integrated_Classification_Model_and_Variance-Based_Regularization_CVPR_2019_paper.html">Scene Parsing via Integrated Classification Model and Variance-Based Regularization</a></th>
                    </tr>
                
                    <tr id="48ccdabdb3de9932602d6f40a4c63698d1efe7de">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/48ccdabdb3de9932602d6f40a4c63698d1efe7de">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Typography_With_Decor_Intelligent_Text_Style_Transfer_CVPR_2019_paper.html">Typography With Decor: Intelligent Text Style Transfer</a></th>
                    </tr>
                
                    <tr id="1febde5425b14742f7f5c718bd128f3883aa0cea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1febde5425b14742f7f5c718bd128f3883aa0cea">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Cross-Atlas_Convolution_for_Parameterization_Invariant_Learning_on_Textured_Mesh_Surface_CVPR_2019_paper.html">Cross-Atlas Convolution for Parameterization Invariant Learning on Textured Mesh Surface</a></th>
                    </tr>
                
                    <tr id="5722baf61523e2d6e0fb195eeaf3c45adcc4b1b3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5722baf61523e2d6e0fb195eeaf3c45adcc4b1b3">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_A_Robust_Local_Spectral_Descriptor_for_Matching_Non-Rigid_Shapes_With_CVPR_2019_paper.html">A Robust Local Spectral Descriptor for Matching Non-Rigid Shapes With Incompatible Shape Structures</a></th>
                    </tr>
                
                    <tr id="fba0a446d07bff1c81cc4f0b114cf07748ac369a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fba0a446d07bff1c81cc4f0b114cf07748ac369a">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yuan_Enhanced_Bayesian_Compression_via_Deep_Reinforcement_Learning_CVPR_2019_paper.html">Enhanced Bayesian Compression via Deep Reinforcement Learning</a></th>
                    </tr>
                
                    <tr id="e7b36024652d99cdf1f75a1daa891729ef0aa0cb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e7b36024652d99cdf1f75a1daa891729ef0aa0cb">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Sawatzky_What_Object_Should_I_Use_-_Task_Driven_Object_Detection_CVPR_2019_paper.html">What Object Should I Use? - Task Driven Object Detection</a></th>
                    </tr>
                
                    <tr id="3b9e1e10ddf8e0a7ee5abfcd2dfb3b67dc81e336">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3b9e1e10ddf8e0a7ee5abfcd2dfb3b67dc81e336">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xie_Topology_Reconstruction_of_Tree-Like_Structure_in_Images_via_Structural_Similarity_CVPR_2019_paper.html">Topology Reconstruction of Tree-Like Structure in Images via Structural Similarity Measure and Dominant Set Clustering</a></th>
                    </tr>
                
                    <tr id="e429528178fba3ec903029567bed73a8f96d5e71">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e429528178fba3ec903029567bed73a8f96d5e71">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhi_Multispectral_Imaging_for_Fine-Grained_Recognition_of_Powders_on_Complex_Backgrounds_CVPR_2019_paper.html">Multispectral Imaging for Fine-Grained Recognition of Powders on Complex Backgrounds</a></th>
                    </tr>
                
                    <tr id="9e7cdb434747c16c78a2dde86e2c43a8a75c8a14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9e7cdb434747c16c78a2dde86e2c43a8a75c8a14">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Hascoet_On_Zero-Shot_Recognition_of_Generic_Objects_CVPR_2019_paper.html">On Zero-Shot Recognition of Generic Objects</a></th>
                    </tr>
                
                    <tr id="0414b97fa6c8525c25e05e01c7674f4c96722ab8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0414b97fa6c8525c25e05e01c7674f4c96722ab8">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kukelova_Radial_Distortion_Triangulation_CVPR_2019_paper.html">Radial Distortion Triangulation</a></th>
                    </tr>
                
                    <tr id="8bc2013c3005a21979cc21c3a01dc16b513be7ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8bc2013c3005a21979cc21c3a01dc16b513be7ab">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Li_Guaranteed_Matrix_Completion_Under_Multiple_Linear_Transformations_CVPR_2019_paper.html">Guaranteed Matrix Completion Under Multiple Linear Transformations</a></th>
                    </tr>
                
                    <tr id="5b5c59d5ee264227a370ea68929bfcac0209b4e0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b5c59d5ee264227a370ea68929bfcac0209b4e0">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/You_Action4D_Online_Action_Recognition_in_the_Crowd_and_Clutter_CVPR_2019_paper.html">Action4D: Online Action Recognition in the Crowd and Clutter</a></th>
                    </tr>
                
                    <tr id="b82d07aa04d883efca35b3c73619d1d0cbd1e738">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b82d07aa04d883efca35b3c73619d1d0cbd1e738">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Uemori_Skin-Based_Identification_From_Multispectral_Image_Data_Using_CNNs_CVPR_2019_paper.html">Skin-Based Identification From Multispectral Image Data Using CNNs</a></th>
                    </tr>
                
                    <tr id="43f0bc4cfc27d2caa60378192d26fc893ff3962c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/43f0bc4cfc27d2caa60378192d26fc893ff3962c">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/FFSS-USAD/Ping_Fashion-AttGAN_Attribute-Aware_Fashion_Editing_With_Multi-Objective_GAN_CVPRW_2019_paper.html">Fashion-AttGAN: Attribute-Aware Fashion Editing With Multi-Objective GAN</a></th>
                    </tr>
                
                    <tr id="d03ffaff4045038cbe4b27ec685ba658a7aeaee8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d03ffaff4045038cbe4b27ec685ba658a7aeaee8">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Lannan_Filter_Guided_Manifold_Optimization_in_the_Autoencoder_Latent_Space_CVPRW_2019_paper.html">Filter Guided Manifold Optimization in the Autoencoder Latent Space</a></th>
                    </tr>
                
                    <tr id="6916242eac40e5ed376930fab5991dcfdcbf30a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6916242eac40e5ed376930fab5991dcfdcbf30a5">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EarthVision/Duan_Large-Scale_DTM_Generation_From_Satellite_Data_CVPRW_2019_paper.html">Large-Scale DTM Generation From Satellite Data</a></th>
                    </tr>
                
                    <tr id="de7cbc5737177ff89913a916e9bd6417836f520e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/de7cbc5737177ff89913a916e9bd6417836f520e">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Ogata_Temporal_Distance_Matrices_for_Squat_Classification_CVPRW_2019_paper.html">Temporal Distance Matrices for Squat Classification</a></th>
                    </tr>
                
                    <tr id="117a979d5235d99ec8a3304827fccdeb8c31bb9c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/117a979d5235d99ec8a3304827fccdeb8c31bb9c">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Higgs_ProTractor_A_Lightweight_Ground_Imaging_and_Analysis_System_for_Early-Season_CVPRW_2019_paper.html">ProTractor: A Lightweight Ground Imaging and Analysis System for Early-Season Field Phenotyping</a></th>
                    </tr>
                
                    <tr id="e6339fe2157e4ff79dff2b7ea062c4c209ed4268">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e6339fe2157e4ff79dff2b7ea062c4c209ed4268">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Krause_A_Guided_Multi-Scale_Categorization_of_Plant_Species_in_Natural_Images_CVPRW_2019_paper.html">A Guided Multi-Scale Categorization of Plant Species in Natural Images</a></th>
                    </tr>
                
                    <tr id="019a6752122c00d7ccb47d01c713d6ec7e27a65e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/019a6752122c00d7ccb47d01c713d6ec7e27a65e">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Masjedi_Prediction_of_Sorghum_Biomass_Using_Uav_Time_Series_Data_and_CVPRW_2019_paper.html">Prediction of Sorghum Biomass Using Uav Time Series Data and Recurrent Neural Networks</a></th>
                    </tr>
                
                    <tr id="2d24dcebd08652477350f4b2979d8b010e2d36ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d24dcebd08652477350f4b2979d8b010e2d36ff">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SkelNetOn/Atienza_Pyramid_U-Network_for_Skeleton_Extraction_From_Shape_Points_CVPRW_2019_paper.html">Pyramid U-Network for Skeleton Extraction From Shape Points</a></th>
                    </tr>
                
                    <tr id="e7fef44803d3feca02ff6d556a68d91c74a92dde">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e7fef44803d3feca02ff6d556a68d91c74a92dde">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Wong_AttoNets_Compact_and_Efficient_Deep_Neural_Networks_for_the_Edge_CVPRW_2019_paper.html">AttoNets: Compact and Efficient Deep Neural Networks for the Edge via Human-Machine Collaborative Design</a></th>
                    </tr>
                
                    <tr id="884ad46d2006302437c65941cf99b901277a7939">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/884ad46d2006302437c65941cf99b901277a7939">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Zhang_Pairwise_Teacher-Student_Network_for_Semi-Supervised_Hashing_CVPRW_2019_paper.html">Pairwise Teacher-Student Network for Semi-Supervised Hashing</a></th>
                    </tr>
                
                    <tr id="39ca7ea448d40093b459f73eeb709e96afa0f920">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39ca7ea448d40093b459f73eeb709e96afa0f920">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Bianco_Content-Preserving_Tone_Adjustment_for_Image_Enhancement_CVPRW_2019_paper.html">Content-Preserving Tone Adjustment for Image Enhancement</a></th>
                    </tr>
                
                    <tr id="da64561574dcdca2ff328813b51c46de78f7d3b7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/da64561574dcdca2ff328813b51c46de78f7d3b7">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Tolosana_MobileTouchDB_Mobile_Touch_Character_Database_in_the_Wild_and_Biometric_CVPRW_2019_paper.html">MobileTouchDB: Mobile Touch Character Database in the Wild and Biometric Benchmark</a></th>
                    </tr>
                
                    <tr id="1c3c99454908c532e3629b36eae38f716ab68721">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1c3c99454908c532e3629b36eae38f716ab68721">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SAIAD/Frickenstein_DSC_Dense-Sparse_Convolution_for_Vectorized_Inference_of_Convolutional_Neural_Networks_CVPRW_2019_paper.html">DSC: Dense-Sparse Convolution for Vectorized Inference of Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="d1578c04bd2c71ea34a0f775e0be48cca8480cae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d1578c04bd2c71ea34a0f775e0be48cca8480cae">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/El-Melegy_Identification_of_Tuberculosis_Bacilli_in_ZN-Stained_Sputum_Smear_Images_A_CVPRW_2019_paper.html">Identification of Tuberculosis Bacilli in ZN-Stained Sputum Smear Images: A Deep Learning Approach</a></th>
                    </tr>
                
                    <tr id="a85a4c07fb4b44dc87fb20a503d3b361071c496c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a85a4c07fb4b44dc87fb20a503d3b361071c496c">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UAVision/Saribas_A_Hybrid_Method_for_Tracking_of_Objects_by_UAVs_CVPRW_2019_paper.html">A Hybrid Method for Tracking of Objects by UAVs</a></th>
                    </tr>
                
                    <tr id="7037c37e7837e08fe1a58042e114940551d80f74">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7037c37e7837e08fe1a58042e114940551d80f74">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Liu_Live_Demonstration_Face_Recognition_on_an_Ultra-Low_Power_Event-Driven_Convolutional_CVPRW_2019_paper.html">Live Demonstration: Face Recognition on an Ultra-Low Power Event-Driven Convolutional Neural Network ASIC</a></th>
                    </tr>
                
                    <tr id="ae57cabb1a583cdd0547476f5e08c8021eb996f3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae57cabb1a583cdd0547476f5e08c8021eb996f3">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Weakly_Supervised_Learning_for_RealWorld_Computer_Vision_Applications/Zohrizadeh_Class_Subset_Selection_for_Partial_Domain_Adaptation_CVPRW_2019_paper.html">Class Subset Selection for Partial Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="acaa653a7f0b7a2909058a48efe824dee54cb72f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/acaa653a7f0b7a2909058a48efe824dee54cb72f">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Ivan_Convolutional_Neural_Networks_on_Randomized_Data_CVPRW_2019_paper.html">Convolutional Neural Networks on Randomized Data</a></th>
                    </tr>
                
                    <tr id="24f06f1c54d2924b2d40344abdc22dacdf70ce76">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/24f06f1c54d2924b2d40344abdc22dacdf70ce76">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Girish_Unsupervised_clustering_based_understanding_of_CNN_CVPRW_2019_paper.html">Unsupervised clustering based understanding of CNN</a></th>
                    </tr>
                
                    <tr id="957cc137b5fe5886073592507736ac44ac8f3caa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/957cc137b5fe5886073592507736ac44ac8f3caa">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Asai_Multi-Task_Learning_based_on_Separable_Formulation_of_Depth_Estimation_and_CVPRW_2019_paper.html">Multi-Task Learning based on Separable Formulation of Depth Estimation and its Uncertainty</a></th>
                    </tr>
                
                    <tr id="4ae525bb071593ed8004e7e03a5bf14dbd1361eb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ae525bb071593ed8004e7e03a5bf14dbd1361eb">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Speth_Automated_Label_Noise_Identification_for_Facial_Attribute_Recognition_CVPRW_2019_paper.html">Automated Label Noise Identification for Facial Attribute Recognition</a></th>
                    </tr>
                
                    <tr id="aee1d46829efa7f46dd3d6af90f3095173b316c2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aee1d46829efa7f46dd3d6af90f3095173b316c2">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Singh_Robust_Homomorphic_Image_Hashing_CVPRW_2019_paper.html">Robust Homomorphic Image Hashing</a></th>
                    </tr>
                
                    <tr id="c5df537661783190b64e10f7fedc88b69bad821c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c5df537661783190b64e10f7fedc88b69bad821c">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Wu_Multiview_Vehicle_Tracking_by_Graph_Matching_Model_CVPRW_2019_paper.html">Multiview Vehicle Tracking by Graph Matching Model</a></th>
                    </tr>
                
                    <tr id="fc60614e93b98dcc2870ee6f353ad9e2dbb17464">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc60614e93b98dcc2870ee6f353ad9e2dbb17464">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Augmented_Human_Humancentric_Understanding_and_2D3D_Synthesis/Jain_On_the_Robustness_of_Human_Pose_Estimation_CVPRW_2019_paper.html">On the Robustness of Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="608b0a495bbe5b312b7dfb8b4af07386fa8f50ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/608b0a495bbe5b312b7dfb8b4af07386fa8f50ab">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/3DWidDGET/Atienza_A_Conditional_Generative_Adversarial_Network_for_Rendering_Point_Clouds_CVPRW_2019_paper.html">A Conditional Generative Adversarial Network for Rendering Point Clouds</a></th>
                    </tr>
                
                    <tr id="0502e31fee3c6da0139b502d7214f757c7030dcd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0502e31fee3c6da0139b502d7214f757c7030dcd">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Xue_Attention_Based_Image_Compression_Post-Processing_Convlutional_Neural_Network_CVPRW_2019_paper.html">Attention Based Image Compression Post-Processing Convlutional Neural Network</a></th>
                    </tr>
                
                    <tr id="1a68528ca25203c8e6010d9aa3e7b6ae5f22f907">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a68528ca25203c8e6010d9aa3e7b6ae5f22f907">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Aytekin_A_Compression_Objective_and_a_Cycle_Loss_for_Neural_Image_CVPRW_2019_paper.html">A Compression Objective and a Cycle Loss for Neural Image Compression</a></th>
                    </tr>
                
                    <tr id="946769f0e55aedaeedaa5ce4863d4624770c068f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/946769f0e55aedaeedaa5ce4863d4624770c068f">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/DOAI/Yang_Multi-Scale_Weighted_Branch_Network_for_Remote_Sensing_Image_Classification_CVPRW_2019_paper.html">Multi-Scale Weighted Branch Network for Remote Sensing Image Classification</a></th>
                    </tr>
                
                    <tr id="3decdf571684bd79f55a52f62f58913e601ad7f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3decdf571684bd79f55a52f62f58913e601ad7f1">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ghosh_On_Learning_Density_Aware_Embeddings_CVPR_2019_paper.html">On Learning Density Aware Embeddings</a></th>
                    </tr>
                
                    <tr id="c84737c7cb2d099bf76e50ccd5f704037d81aa62">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c84737c7cb2d099bf76e50ccd5f704037d81aa62">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gygli_Fast_Object_Class_Labelling_via_Speech_CVPR_2019_paper.html">Fast Object Class Labelling via Speech</a></th>
                    </tr>
                
                    <tr id="9412a443ff29a472b4783d8dcd60416e102ec8ef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9412a443ff29a472b4783d8dcd60416e102ec8ef">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Men_DynTypo_Example-Based_Dynamic_Text_Effects_Transfer_CVPR_2019_paper.html">DynTypo: Example-Based Dynamic Text Effects Transfer</a></th>
                    </tr>
                
                    <tr id="ccb898e02fb7cf248f533d6ca6cd1c1a69746c9e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ccb898e02fb7cf248f533d6ca6cd1c1a69746c9e">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jack_IGE-Net_Inverse_Graphics_Energy_Networks_for_Human_Pose_Estimation_and_CVPR_2019_paper.html">IGE-Net: Inverse Graphics Energy Networks for Human Pose Estimation and Single-View Reconstruction</a></th>
                    </tr>
                
                    <tr id="39686387102c043194b0166df033580395c4be3c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39686387102c043194b0166df033580395c4be3c">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ho_Catastrophic_Childs_Play_Easy_to_Perform_Hard_to_Defend_Adversarial_CVPR_2019_paper.html">Catastrophic Child&#39;s Play: Easy to Perform, Hard to Defend Adversarial Attacks</a></th>
                    </tr>
                
                    <tr id="36c6e907cbf0c3a2d5b8d745a93e99c655160265">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/36c6e907cbf0c3a2d5b8d745a93e99c655160265">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Chen_Embedding_Complementary_Deep_Networks_for_Image_Classification_CVPR_2019_paper.html">Embedding Complementary Deep Networks for Image Classification</a></th>
                    </tr>
                
                    <tr id="8c08eec4ec339c10c12a8de40924444530e59e0d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c08eec4ec339c10c12a8de40924444530e59e0d">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lan_Robust_Point_Cloud_Based_Reconstruction_of_Large-Scale_Outdoor_Scenes_CVPR_2019_paper.html">Robust Point Cloud Based Reconstruction of Large-Scale Outdoor Scenes</a></th>
                    </tr>
                
                    <tr id="796676a8921c719839029b1d0bf5ad8bbcfee016">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/796676a8921c719839029b1d0bf5ad8bbcfee016">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Martinez_Segmentation_Certainty_Through_Uncertainty_Uncertainty-Refined_Binary_Volumetric_Segmentation_Under_Multifactor_CVPRW_2019_paper.html">Segmentation Certainty Through Uncertainty: Uncertainty-Refined Binary Volumetric Segmentation Under Multifactor Domain Shift</a></th>
                    </tr>
                
                    <tr id="d01ab57ef1a75ef7d96386a3115f3fa8ec9cbb07">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d01ab57ef1a75ef7d96386a3115f3fa8ec9cbb07">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/FFSS-USAD/Liu_Modeling_Image_Composition_for_Visual_Aesthetic_Assessment_CVPRW_2019_paper.html">Modeling Image Composition for Visual Aesthetic Assessment</a></th>
                    </tr>
                
                    <tr id="4717e5ce7250cf8466b9987aadccd70f1eacf581">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4717e5ce7250cf8466b9987aadccd70f1eacf581">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Li_Fine-Grained_Visual_Dribbling_Style_Analysis_for_Soccer_Videos_With_Augmented_CVPRW_2019_paper.html">Fine-Grained Visual Dribbling Style Analysis for Soccer Videos With Augmented Dribble Energy Image</a></th>
                    </tr>
                
                    <tr id="4953374ae658f86d0ba56ba7cb2f93798199c991">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4953374ae658f86d0ba56ba7cb2f93798199c991">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/Su_Efficient_and_Accurate_Face_Alignment_by_Global_Regression_and_Cascaded_CVPRW_2019_paper.html">Efficient and Accurate Face Alignment by Global Regression and Cascaded Local Refinement</a></th>
                    </tr>
                
                    <tr id="cd54e48acab87f2b1cdb1ce361d88e0f886297bf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd54e48acab87f2b1cdb1ce361d88e0f886297bf">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BCMCVAI/Bathen_SelfIs_Self-Sovereign_Biometric_IDs_CVPRW_2019_paper.html">SelfIs: Self-Sovereign Biometric IDs</a></th>
                    </tr>
                
                    <tr id="2b25e532b94bf679375cdf551be86e321158a72d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b25e532b94bf679375cdf551be86e321158a72d">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Yang_Adaptive_Labeling_for_Deep_Learning_to_Hash_CVPRW_2019_paper.html">Adaptive Labeling for Deep Learning to Hash</a></th>
                    </tr>
                
                    <tr id="0a27bf8ab75fd7c833a4f52870b24f4d203f9d79">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a27bf8ab75fd7c833a4f52870b24f4d203f9d79">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Mu_Salient_Object_Detection_in_Low_Contrast_Images_via_Global_Convolution_CVPRW_2019_paper.html">Salient Object Detection in Low Contrast Images via Global Convolution and Boundary Refinement</a></th>
                    </tr>
                
                    <tr id="f530bba1f93c2ab4d01a2f80728798d238a9f2eb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f530bba1f93c2ab4d01a2f80728798d238a9f2eb">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Xiao_Histogram_Learning_in_Image_Contrast_Enhancement_CVPRW_2019_paper.html">Histogram Learning in Image Contrast Enhancement</a></th>
                    </tr>
                
                    <tr id="3f15295038dac67d74d37edfd1acd5cb1db87b70">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f15295038dac67d74d37edfd1acd5cb1db87b70">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Vasileiadis_Facial_Soft_Biometrics_Detection_on_Low_Power_Devices_CVPRW_2019_paper.html">Facial Soft Biometrics Detection on Low Power Devices</a></th>
                    </tr>
                
                    <tr id="29a1b2395f38626e3225d214649221f6e599484c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/29a1b2395f38626e3225d214649221f6e599484c">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Mohan_Significant_Feature_Based_Representation_for_Template_Protection_CVPRW_2019_paper.html">Significant Feature Based Representation for Template Protection</a></th>
                    </tr>
                
                    <tr id="233a7fed7fbefeaee955485b174e776449187fc3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/233a7fed7fbefeaee955485b174e776449187fc3">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/Dastidar_Automated_Focus_Distance_Estimation_for_Digital_Microscopy_Using_Deep_Convolutional_CVPRW_2019_paper.html">Automated Focus Distance Estimation for Digital Microscopy Using Deep Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="d6c426f44d690567296e240b239174dc81057677">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d6c426f44d690567296e240b239174dc81057677">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/Gupta_Deep_Metric_Learning_for_Identification_of_Mitotic_Patterns_of_HEp-2_CVPRW_2019_paper.html">Deep Metric Learning for Identification of Mitotic Patterns of HEp-2 Cell Images</a></th>
                    </tr>
                
                    <tr id="d4b3deabf085ec5a56a87994c97cf2e5ffff4638">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d4b3deabf085ec5a56a87994c97cf2e5ffff4638">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Cevikalp_Semi-Supervised_Robust_Deep_Neural_Networks_for_Multi-Label_Classification_CVPRW_2019_paper.html">Semi-Supervised Robust Deep Neural Networks for Multi-Label Classification</a></th>
                    </tr>
                
                    <tr id="3c94d65889711a3eaf8ce13ed9f5b73ed1c9e10b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3c94d65889711a3eaf8ce13ed9f5b73ed1c9e10b">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Kim_Deep_Coupling_of_Random_Ferns_CVPRW_2019_paper.html">Deep Coupling of Random Ferns</a></th>
                    </tr>
                
                    <tr id="3780d0c847a93b511ba3cbfa0e4face27dd5fbad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3780d0c847a93b511ba3cbfa0e4face27dd5fbad">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Zhang_Building_Explainable_AI_Evaluation_for_Autonomous_Perception_CVPRW_2019_paper.html">Building Explainable AI Evaluation for Autonomous Perception</a></th>
                    </tr>
                
                    <tr id="7610c3c73a06303a314e38fdf6992a2330e09270">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7610c3c73a06303a314e38fdf6992a2330e09270">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Li_Visualizing_the_Decision-making_Process_in_Deep_Neural_Decision_Forest_CVPRW_2019_paper.html">Visualizing the Decision-making Process in Deep Neural Decision Forest</a></th>
                    </tr>
                
                    <tr id="ccefdb9f530c3652d37f9f852f58e4da15efc926">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ccefdb9f530c3652d37f9f852f58e4da15efc926">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Lee_Incremental_Learning_with_Unlabeled_Data_in_the_Wild_CVPRW_2019_paper.html">Incremental Learning with Unlabeled Data in the Wild</a></th>
                    </tr>
                
                    <tr id="4c1139695792befd2073186987d21a8f8d2d0c51">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c1139695792befd2073186987d21a8f8d2d0c51">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AAMVEM/King_Deep_Learning_for_Semantic_Segmentation_of_Coral_Reef_Images_Using_CVPRW_2019_paper.html">Deep Learning for Semantic Segmentation of Coral Reef Images Using Multi-View Information</a></th>
                    </tr>
                
                    <tr id="b0a01929325d71a495502503cf866cfe42790338">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b0a01929325d71a495502503cf866cfe42790338">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Kim_Bidirectional_Deep_Residual_learning_for_Haze_Removal_CVPRW_2019_paper.html">Bidirectional Deep Residual learning for Haze Removal</a></th>
                    </tr>
                
                    <tr id="192e2f21a36729bf9de4e44c1001c9aa34a839fb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/192e2f21a36729bf9de4e44c1001c9aa34a839fb">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Avraham_Parallel_Optimal_Transport_GAN_CVPR_2019_paper.html">Parallel Optimal Transport GAN</a></th>
                    </tr>
                
                    <tr id="a5cf10eb80e6086202d7dc4a3fc11aa2288738a3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a5cf10eb80e6086202d7dc4a3fc11aa2288738a3">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Causes_and_Corrections_for_Bimodal_Multi-Path_Scanning_With_Structured_Light_CVPR_2019_paper.html">Causes and Corrections for Bimodal Multi-Path Scanning With Structured Light</a></th>
                    </tr>
                
                    <tr id="3ffa6d47aeafdd03f99ae2aa94625887728295b6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ffa6d47aeafdd03f99ae2aa94625887728295b6">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liu_Orthogonal_Decomposition_Network_for_Pixel-Wise_Binary_Classification_CVPR_2019_paper.html">Orthogonal Decomposition Network for Pixel-Wise Binary Classification</a></th>
                    </tr>
                
                    <tr id="0868e54f5e3d0c3ccf70ec05d30ccf163581cdfd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0868e54f5e3d0c3ccf70ec05d30ccf163581cdfd">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Korhonen_Assessing_Personally_Perceived_Image_Quality_via_Image_Features_and_Collaborative_CVPR_2019_paper.html">Assessing Personally Perceived Image Quality via Image Features and Collaborative Filtering</a></th>
                    </tr>
                
                    <tr id="65b241a7a481fe5df5346f00d3b56cb9a8d2c228">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/65b241a7a481fe5df5346f00d3b56cb9a8d2c228">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Ren_EIGEN_Ecologically-Inspired_GENetic_Approach_for_Neural_Network_Structure_Searching_From_CVPR_2019_paper.html">EIGEN: Ecologically-Inspired GENetic Approach for Neural Network Structure Searching From Scratch</a></th>
                    </tr>
                
                    <tr id="b2cf3ff8a900c04a4a55ae3bd54d93848c03008e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b2cf3ff8a900c04a4a55ae3bd54d93848c03008e">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Miraldo_Minimal_Solvers_for_Mini-Loop_Closures_in_3D_Multi-Scan_Alignment_CVPR_2019_paper.html">Minimal Solvers for Mini-Loop Closures in 3D Multi-Scan Alignment</a></th>
                    </tr>
                
                    <tr id="273ebb14fc10d578a88a2c6cfea997e1c1b91009">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/273ebb14fc10d578a88a2c6cfea997e1c1b91009">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Learning_to_Explore_Intrinsic_Saliency_for_Stereoscopic_Video_CVPR_2019_paper.html">Learning to Explore Intrinsic Saliency for Stereoscopic Video</a></th>
                    </tr>
                
                    <tr id="1393aa0f0b392b861d90811585690ea8e976719d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1393aa0f0b392b861d90811585690ea8e976719d">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Ray-Space_Projection_Model_for_Light_Field_Camera_CVPR_2019_paper.html">Ray-Space Projection Model for Light Field Camera</a></th>
                    </tr>
                
                    <tr id="59b439bde73d80dccf367d414e209d08d312c059">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/59b439bde73d80dccf367d414e209d08d312c059">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Knowing_When_to_Stop_Evaluation_and_Verification_of_Conformity_to_CVPR_2019_paper.html">Knowing When to Stop: Evaluation and Verification of Conformity to Output-Size Specifications</a></th>
                    </tr>
                
                    <tr id="da3a14c1ab15f887ea56daec14f26460bfa96c56">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/da3a14c1ab15f887ea56daec14f26460bfa96c56">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Ding_Defending_Against_Adversarial_Attacks_Using_Random_Forest_CVPRW_2019_paper.html">Defending Against Adversarial Attacks Using Random Forest</a></th>
                    </tr>
                
                    <tr id="3e9285552fc3c1402a09e3d29ee09c130cf2d419">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3e9285552fc3c1402a09e3d29ee09c130cf2d419">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MULA/Pan_Cross-Stream_Selective_Networks_for_Action_Recognition_CVPRW_2019_paper.html">Cross-Stream Selective Networks for Action Recognition</a></th>
                    </tr>
                
                    <tr id="37a49460aef16ea245f4ac9cd8ffd447d81961ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/37a49460aef16ea245f4ac9cd8ffd447d81961ce">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Schroeder_Using_a_Priori_Knowledge_to_Improve_Scene_Understanding_CVPRW_2019_paper.html">Using a Priori Knowledge to Improve Scene Understanding</a></th>
                    </tr>
                
                    <tr id="3f4cc36f6ad57d2abe7ea07d583a416b34efa9cb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f4cc36f6ad57d2abe7ea07d583a416b34efa9cb">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Mittel_Visual_Transfer_Between_Atari_Games_Using_Competitive_Reinforcement_Learning_CVPRW_2019_paper.html">Visual Transfer Between Atari Games Using Competitive Reinforcement Learning</a></th>
                    </tr>
                
                    <tr id="04c741d3cec4c8dfa777fa31081d79d2e5124014">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/04c741d3cec4c8dfa777fa31081d79d2e5124014">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/FFSS-USAD/Lin_Learning_Personal_Tastes_in_Choosing_Fashion_Outfits_CVPRW_2019_paper.html">Learning Personal Tastes in Choosing Fashion Outfits</a></th>
                    </tr>
                
                    <tr id="077346a4336f2c1d8cb1f5edb42c6d4bcbedb850">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/077346a4336f2c1d8cb1f5edb42c6d4bcbedb850">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Piergiovanni_Early_Detection_of_Injuries_in_MLB_Pitchers_From_Video_CVPRW_2019_paper.html">Early Detection of Injuries in MLB Pitchers From Video</a></th>
                    </tr>
                
                    <tr id="345fc3589ff6ee6cd4802de4cd1e693b3591c62f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/345fc3589ff6ee6cd4802de4cd1e693b3591c62f">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Long_Bean_Split_Ratio_for_Dry_Bean_Canning_Quality_and_Variety_CVPRW_2019_paper.html">Bean Split Ratio for Dry Bean Canning Quality and Variety Analysis</a></th>
                    </tr>
                
                    <tr id="8182a64c88ff3c798dd7af49be3882e984fd0b81">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8182a64c88ff3c798dd7af49be3882e984fd0b81">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MBCCV/Perera_Is_Image_Memorability_Prediction_Solved_CVPRW_2019_paper.html">Is Image Memorability Prediction Solved?</a></th>
                    </tr>
                
                    <tr id="418d6561612505e579731c3edf4db6f5fd56d35d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/418d6561612505e579731c3edf4db6f5fd56d35d">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/Bera_Modelling_Multi-Channel_Emotions_Using_Facial_Expression_and_Trajectory_Cues_for_CVPRW_2019_paper.html">Modelling Multi-Channel Emotions Using Facial Expression and Trajectory Cues for Improving Socially-Aware Robot Navigation</a></th>
                    </tr>
                
                    <tr id="3ee8b79a04760812c66dd2a6c8630e48ea4ac7b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ee8b79a04760812c66dd2a6c8630e48ea4ac7b5">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Kreuzig_DistanceNet_Estimating_Traveled_Distance_From_Monocular_Images_Using_a_Recurrent_CVPRW_2019_paper.html">DistanceNet: Estimating Traveled Distance From Monocular Images Using a Recurrent Convolutional Neural Network</a></th>
                    </tr>
                
                    <tr id="80d1dcf9c8ee9f492effdedce4a6de7e825a93be">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/80d1dcf9c8ee9f492effdedce4a6de7e825a93be">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Zhu_An_Epipolar_Volume_Autoencoder_With_Adversarial_Loss_for_Deep_Light_CVPRW_2019_paper.html">An Epipolar Volume Autoencoder With Adversarial Loss for Deep Light Field Super-Resolution</a></th>
                    </tr>
                
                    <tr id="da4f013f8b423e024ad668c7ebe493c0825465e7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/da4f013f8b423e024ad668c7ebe493c0825465e7">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/G._Low_Rank_Poisson_Denoising_LRPD_A_Low_Rank_Approach_Using_CVPRW_2019_paper.html">Low Rank Poisson Denoising (LRPD): A Low Rank Approach Using Split Bregman Algorithm for Poisson Noise Removal From Images</a></th>
                    </tr>
                
                    <tr id="414509ab6f755a63d02e442a7824535c65d5134b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/414509ab6f755a63d02e442a7824535c65d5134b">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Chaney_Learning_Event-Based_Height_From_Plane_and_Parallax_CVPRW_2019_paper.html">Learning Event-Based Height From Plane and Parallax</a></th>
                    </tr>
                
                    <tr id="23da436f3bd41c372ce7548d6295c3bb1473ced6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/23da436f3bd41c372ce7548d6295c3bb1473ced6">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Pahuja_Enhancing_Salient_Object_Segmentation_Through_Attention_CVPRW_2019_paper.html">Enhancing Salient Object Segmentation Through Attention</a></th>
                    </tr>
                
                    <tr id="47a55ae665f61d249f41cfd6747df1fc069aea35">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47a55ae665f61d249f41cfd6747df1fc069aea35">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Li_Localizing_Common_Objects_Using_Common_Component_Activation_Map_CVPRW_2019_paper.html">Localizing Common Objects Using Common Component Activation Map</a></th>
                    </tr>
                
                    <tr id="6043a4ce282dc0fbbd8270867c54c0b1819b0b8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6043a4ce282dc0fbbd8270867c54c0b1819b0b8f">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Robertson_Manipulation_Data_Collection_and_Annotation_Tool_for_Media_Forensics_CVPRW_2019_paper.html">Manipulation Data Collection and Annotation Tool for Media Forensics</a></th>
                    </tr>
                
                    <tr id="24bee4535039570f3a0f7eb1c3e75e689ec202cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/24bee4535039570f3a0f7eb1c3e75e689ec202cd">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Ayala-Acevedo_Vehicle_Re-Identification_Pushing_the_limits_of_re-identification_CVPRW_2019_paper.html">Vehicle Re-Identification: Pushing the limits of re-identification</a></th>
                    </tr>
                
                    <tr id="d00c0531540eace46c1b5a0a43fdd2199359e013">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d00c0531540eace46c1b5a0a43fdd2199359e013">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Mukherjee_Attribute-Controlled_Traffic_Data_Augmentation_Using_Conditional_Generative_Models_CVPRW_2019_paper.html">Attribute-Controlled Traffic Data Augmentation Using Conditional Generative Models</a></th>
                    </tr>
                
                    <tr id="e9616ea7ebb48c1f005b95e7c955ad4a93f10df9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e9616ea7ebb48c1f005b95e7c955ad4a93f10df9">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Augmented_Human_Humancentric_Understanding_and_2D3D_Synthesis/Wan_Patch-based_3D_Human_Pose_Refinement_CVPRW_2019_paper.html">Patch-based 3D Human Pose Refinement</a></th>
                    </tr>
                
                    <tr id="3ee8b79a04760812c66dd2a6c8630e48ea4ac7b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ee8b79a04760812c66dd2a6c8630e48ea4ac7b5">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Kreuzig_DistanceNet_Estimating_Traveled_Distance_From_Monocular_Images_Using_a_Recurrent_CVPRW_2019_paper.html">DistanceNet: Estimating Traveled Distance From Monocular Images Using a Recurrent Convolutional Neural Network</a></th>
                    </tr>
                
                    <tr id="8b4d15707bbf154e9c1bab0c30c33f74e8f2e158">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b4d15707bbf154e9c1bab0c30c33f74e8f2e158">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Akutsu_End-to-End_Learned_ROI_Image_Compression_CVPRW_2019_paper.html">End-to-End Learned ROI Image Compression</a></th>
                    </tr>
                
                    <tr id="e58c7ebea2fa8c0d9bde125b933d70a775e47f78">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e58c7ebea2fa8c0d9bde125b933d70a775e47f78">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/DOAI/Naude_The_Aerial_Elephant_Dataset_A_New_Public_Benchmark_for_Aerial_CVPRW_2019_paper.html">The Aerial Elephant Dataset: A New Public Benchmark for Aerial Object Detection.</a></th>
                    </tr>
                
                    <tr id="7cd3e90b1829ae6e11e900a64ced0da01f6281de">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7cd3e90b1829ae6e11e900a64ced0da01f6281de">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Deza_Assessment_of_Faster_R-CNN_in_Man-Machine_Collaborative_Search_CVPR_2019_paper.html">Assessment of Faster R-CNN in Man-Machine Collaborative Search</a></th>
                    </tr>
                
                    <tr id="de5d50ad1522f5c36491d5a97337dbeebeb0ead6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/de5d50ad1522f5c36491d5a97337dbeebeb0ead6">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Shevlev_Co-Occurrence_Neural_Network_CVPR_2019_paper.html">Co-Occurrence Neural Network</a></th>
                    </tr>
                
                    <tr id="99dddd2cf230c80e3a315e4c110af9b731fd4b6b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/99dddd2cf230c80e3a315e4c110af9b731fd4b6b">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Bapat_The_Domain_Transform_Solver_CVPR_2019_paper.html">The Domain Transform Solver</a></th>
                    </tr>
                
                    <tr id="22ec6f066fefdbb58a8b1847186d87406d9aee14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/22ec6f066fefdbb58a8b1847186d87406d9aee14">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Propagation_Mechanism_for_Deep_and_Wide_Neural_Networks_CVPR_2019_paper.html">Propagation Mechanism for Deep and Wide Neural Networks</a></th>
                    </tr>
                
                    <tr id="0cfa70687f1cef0305c8336c086c4f2e8c051ed4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0cfa70687f1cef0305c8336c086c4f2e8c051ed4">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CV-COPS/Gheisari_Privacy_Preserving_Group_Membership_Verification_and_Identification_CVPRW_2019_paper.html">Privacy Preserving Group Membership Verification and Identification</a></th>
                    </tr>
                
                    <tr id="b6539443f5e6b52de3436518abc44ab0793b4dc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b6539443f5e6b52de3436518abc44ab0793b4dc1">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/VOCVALC/Yang_Visual-GPS_Ego-Downward_and_Ambient_Video_Based_Person_Location_Association_CVPRW_2019_paper.html">Visual-GPS: Ego-Downward and Ambient Video Based Person Location Association</a></th>
                    </tr>
                
                    <tr id="fa939844685c069e5efdf4b4a51302b28bb708d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fa939844685c069e5efdf4b4a51302b28bb708d4">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Precognition/Ly_Multimodal_2D_and_3D_for_In-The-Wild_Facial_Expression_Recognition_CVPRW_2019_paper.html">Multimodal 2D and 3D for In-The-Wild Facial Expression Recognition</a></th>
                    </tr>
                
                    <tr id="a79076fcea549baca1b1b55b69b77e22cab5c001">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a79076fcea549baca1b1b55b69b77e22cab5c001">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MULA/Santolini_Cut_Quality_Estimation_in_Industrial_Laser_Cutting_Machines_A_Machine_CVPRW_2019_paper.html">Cut Quality Estimation in Industrial Laser Cutting Machines: A Machine Learning Approach</a></th>
                    </tr>
                
                    <tr id="10ac46c67ea33b278e830f97470deab50e0a47bb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/10ac46c67ea33b278e830f97470deab50e0a47bb">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PCV/Wang_Robustifying_Relative_Orientations_With_Respect_to_Repetitive_Structures_and_Very_CVPRW_2019_paper.html">Robustifying Relative Orientations With Respect to Repetitive Structures and Very Short Baselines for Global SfM</a></th>
                    </tr>
                
                    <tr id="db16e0b6eadce6cbf507ad1cd1c72555cd8196ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db16e0b6eadce6cbf507ad1cd1c72555cd8196ab">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PCV/Bielova_A_Digital_Image_Processing_Pipeline_for_Modelling_of_Realistic_Noise_CVPRW_2019_paper.html">A Digital Image Processing Pipeline for Modelling of Realistic Noise in Synthetic Images</a></th>
                    </tr>
                
                    <tr id="3a9ae06cf6a3fb161a4e10304f323669118c61cb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3a9ae06cf6a3fb161a4e10304f323669118c61cb">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Gupta_Post_Disaster_Mapping_With_Semantic_Change_Detection_in_Satellite_Imagery_CVPRW_2019_paper.html">Post Disaster Mapping With Semantic Change Detection in Satellite Imagery</a></th>
                    </tr>
                
                    <tr id="d525135ab3783365001cfa6c06f05fd323710d95">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d525135ab3783365001cfa6c06f05fd323710d95">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Antensteiner_Single_Image_Multi-Spectral_Photometric_Stereo_Using_a_Split_U-Shaped_CNN_CVPRW_2019_paper.html">Single Image Multi-Spectral Photometric Stereo Using a Split U-Shaped CNN</a></th>
                    </tr>
                
                    <tr id="b8950d2dfa4975347b3f5559713e78032671885e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b8950d2dfa4975347b3f5559713e78032671885e">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Mu_Riemannian_Loss_for_Image_Restoration_CVPRW_2019_paper.html">Riemannian Loss for Image Restoration</a></th>
                    </tr>
                
                    <tr id="0de1c351109113b3fa69fa8e7724d7f1bd0b9234">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0de1c351109113b3fa69fa8e7724d7f1bd0b9234">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Parameshwaran_Transfer_Learning_for_Classifying_Single_Hand_Gestures_on_Comprehensive_Bharatanatyam_CVPRW_2019_paper.html">Transfer Learning for Classifying Single Hand Gestures on Comprehensive Bharatanatyam Mudra Dataset</a></th>
                    </tr>
                
                    <tr id="dce0dd4be8a0a1d0f08dbcbe9820b3e665ba9cf6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dce0dd4be8a0a1d0f08dbcbe9820b3e665ba9cf6">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Wang_Improved_Automating_Seismic_Facies_Analysis_Using_Deep_Dilated_Attention_Autoencoders_CVPRW_2019_paper.html">Improved Automating Seismic Facies Analysis Using Deep Dilated Attention Autoencoders</a></th>
                    </tr>
                
                    <tr id="d06ab5742c2d4945050730568ca89eacff5f1bcf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d06ab5742c2d4945050730568ca89eacff5f1bcf">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Kalavakonda_Autonomous_Neurosurgical_Instrument_Segmentation_Using_End-To-End_Learning_CVPRW_2019_paper.html">Autonomous Neurosurgical Instrument Segmentation Using End-To-End Learning</a></th>
                    </tr>
                
                    <tr id="442e16aa5ea35f4646e467b0885358ba86e3dc12">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/442e16aa5ea35f4646e467b0885358ba86e3dc12">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EVW/Tosi_Leveraging_Confident_Points_for_Accurate_Depth_Refinement_on_Embedded_Systems_CVPRW_2019_paper.html">Leveraging Confident Points for Accurate Depth Refinement on Embedded Systems</a></th>
                    </tr>
                
                    <tr id="0b14577c413d1d2d447e77773ba0808a1f586fa1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0b14577c413d1d2d447e77773ba0808a1f586fa1">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Mortensen_The_Oil_Radish_Growth_Dataset_for_Semantic_Segmentation_and_Yield_CVPRW_2019_paper.html">The Oil Radish Growth Dataset for Semantic Segmentation and Yield Estimation</a></th>
                    </tr>
                
                    <tr id="419251a82508758a5d506584065dc70a065f5043">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/419251a82508758a5d506584065dc70a065f5043">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/An_APA_Adaptive_Pose_Alignment_for_Robust_Face_Recognition_CVPRW_2019_paper.html">APA: Adaptive Pose Alignment for Robust Face Recognition</a></th>
                    </tr>
                
                    <tr id="1a42fbbb6aaa810128576bd615fe5e0977b06251">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a42fbbb6aaa810128576bd615fe5e0977b06251">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Maxwell_Real-Time_Physics-Based_Removal_of_Shadows_and_Shading_From_Road_Surfaces_CVPRW_2019_paper.html">Real-Time Physics-Based Removal of Shadows and Shading From Road Surfaces</a></th>
                    </tr>
                
                    <tr id="adbe9b600bb5bf0505086299c4aae59512aab727">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/adbe9b600bb5bf0505086299c4aae59512aab727">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Rakshit_Class_Consistency_Driven_Unsupervised_Deep_Adversarial_Domain_Adaptation_CVPRW_2019_paper.html">Class Consistency Driven Unsupervised Deep Adversarial Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="b8cb76a91d17451652e0e867a65ac1634acea21d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b8cb76a91d17451652e0e867a65ac1634acea21d">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Hou_Learning_Deep_Image_Priors_for_Blind_Image_Denoising_CVPRW_2019_paper.html">Learning Deep Image Priors for Blind Image Denoising</a></th>
                    </tr>
                
                    <tr id="4495aecd4f02155822fc09ffea2c23ad3a2526c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4495aecd4f02155822fc09ffea2c23ad3a2526c4">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Kalarot_MultiBoot_Vsr_Multi-Stage_Multi-Reference_Bootstrapping_for_Video_Super-Resolution_CVPRW_2019_paper.html">MultiBoot Vsr: Multi-Stage Multi-Reference Bootstrapping for Video Super-Resolution</a></th>
                    </tr>
                
                    <tr id="4ef6dcbb02d84faded04c070be5df9cea2f10682">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ef6dcbb02d84faded04c070be5df9cea2f10682">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Chong_GANmera_Reproducing_Aesthetically_Pleasing_Photographs_Using_Deep_Adversarial_Networks_CVPRW_2019_paper.html">GANmera: Reproducing Aesthetically Pleasing Photographs Using Deep Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="c3dc2980ec90dc5f6d8e2440f799e37fde04fe81">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c3dc2980ec90dc5f6d8e2440f799e37fde04fe81">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Hu_Revisiting_Depth-Based_Face_Recognition_From_a_Quality_Perspective_CVPRW_2019_paper.html">Revisiting Depth-Based Face Recognition From a Quality Perspective</a></th>
                    </tr>
                
                    <tr id="71df94e8546baa72b84903a774a2fd685bd7e615">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/71df94e8546baa72b84903a774a2fd685bd7e615">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/TRMTMCT/Chung_Camera-Aware_Image-To-Image_Translation_Using_Similarity_Preserving_StarGAN_for_Person_Re-Identification_CVPRW_2019_paper.html">Camera-Aware Image-To-Image Translation Using Similarity Preserving StarGAN for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="99ceb71bf4114d25b5064b35a980c2449bea4ac2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/99ceb71bf4114d25b5064b35a980c2449bea4ac2">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UAVision/Akhauri_HadaNets_Flexible_Quantization_Strategies_for_Neural_Networks_CVPRW_2019_paper.html">HadaNets: Flexible Quantization Strategies for Neural Networks</a></th>
                    </tr>
                
                    <tr id="a3577fc002714752da5bd5dc74be3e120f0edce2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a3577fc002714752da5bd5dc74be3e120f0edce2">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Zhu_Live_Demonstration_Unsupervised_Event-Based_Learning_of_Optical_Flow_Depth_and_CVPRW_2019_paper.html">Live Demonstration: Unsupervised Event-Based Learning of Optical Flow, Depth and Egomotion</a></th>
                    </tr>
                
                    <tr id="6df2cdf1d3319fc2b06845266339511a79e4208a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6df2cdf1d3319fc2b06845266339511a79e4208a">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Jindal_A_Nonlinear_Noise-aware_Quasi-clustering_Approach_to_Learning_Deep_CNNs_from_CVPRW_2019_paper.html">A Nonlinear, Noise-aware, Quasi-clustering Approach to Learning Deep CNNs from Noisy Labels</a></th>
                    </tr>
                
                    <tr id="0e8ae56440a967411473c3732f22a44192d4975d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e8ae56440a967411473c3732f22a44192d4975d">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Shi_Deep_Visual_City_Recognition_Visualization_CVPRW_2019_paper.html">Deep Visual City Recognition Visualization</a></th>
                    </tr>
                
                    <tr id="9796af327dcb7052d45df017bc8f9f2f996d8bac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9796af327dcb7052d45df017bc8f9f2f996d8bac">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Shen_Explainable_Hierarchical_Semantic_Convolutional_Neural_Network_for_Lung_Cancer_Diagnosis_CVPRW_2019_paper.html">Explainable Hierarchical Semantic Convolutional Neural Network for Lung Cancer Diagnosis</a></th>
                    </tr>
                
                    <tr id="e62286276fa90ac9bacb86965afe66b81eb47d4a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e62286276fa90ac9bacb86965afe66b81eb47d4a">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Kiritoshi_L1-Norm_Gradient_Penalty_for_Noise_Reduction_of_Attribution_Maps_CVPRW_2019_paper.html">L1-Norm Gradient Penalty for Noise Reduction of Attribution Maps</a></th>
                    </tr>
                
                    <tr id="bff8ca3992a2adb723d27011096e05a46fb50f6f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bff8ca3992a2adb723d27011096e05a46fb50f6f">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Butepage_Modeling_assumptions_and_evaluation_schemes_On_the_assessment_of_deep_CVPRW_2019_paper.html">Modeling assumptions and evaluation schemes: On the assessment of deep latent variable models</a></th>
                    </tr>
                
                    <tr id="1484af0b0faf4240d24db4422f393d6a6861f7df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1484af0b0faf4240d24db4422f393d6a6861f7df">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SUMO/Kim_Multi-planar_Monocular_Reconstruction_of_Manhattan_Indoor_Scenes_CVPRW_2019_paper.html">Multi-planar Monocular Reconstruction of Manhattan Indoor Scenes</a></th>
                    </tr>
                
                    <tr id="47923863c2393eb107e3051f505f0cb0b6c79036">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47923863c2393eb107e3051f505f0cb0b6c79036">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Sekhar_Online_Signature_Verification_Based_on_Writer_Specific_Feature_Selection_and_CVPRW_2019_paper.html">Online Signature Verification Based on Writer Specific Feature Selection and Fuzzy Similarity Measure</a></th>
                    </tr>
                
                    <tr id="fcce76a9ccba8bcb077077b206724b9ef2379bb9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fcce76a9ccba8bcb077077b206724b9ef2379bb9">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_Meets_Cognition_Camera_Ready/Gokhale_Cooking_With_Blocks__A_Recipe_for_Visual_Reasoning_on_CVPRW_2019_paper.html">Cooking With Blocks : A Recipe for Visual Reasoning on Image-Pairs</a></th>
                    </tr>
                
                    <tr id="4c5d5af22bc1e99fd5d3167659440b17edb0c9cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c5d5af22bc1e99fd5d3167659440b17edb0c9cd">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_Meets_Cognition_Camera_Ready/Ho_On_Human-like_Performance_Artificial_Intelligence_A_Demonstration_Using_an_Atari_CVPRW_2019_paper.html">On Human-like Performance Artificial Intelligence: A Demonstration Using an Atari Game</a></th>
                    </tr>
                
                    <tr id="5c6c267932b2efc7eadc717cf81ba1ad73dd2e91">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c6c267932b2efc7eadc717cf81ba1ad73dd2e91">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Augmented_Human_Humancentric_Understanding_and_2D3D_Synthesis/Moon_Multi-scale_Aggregation_R-CNN_for_2D_Multi-person_Pose_Estimation_CVPRW_2019_paper.html">Multi-scale Aggregation R-CNN for 2D Multi-person Pose Estimation</a></th>
                    </tr>
                
                    <tr id="9d02a5b52bb47ecf594710ede66c12f1eb660c39">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9d02a5b52bb47ecf594710ede66c12f1eb660c39">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Augmented_Human_Humancentric_Understanding_and_2D3D_Synthesis/Li_What_Elements_are_Essential_to_Recognize_Human_Actions_CVPRW_2019_paper.html">What Elements are Essential to Recognize Human Actions?</a></th>
                    </tr>
                
                    <tr id="0d5d183873de67a93520681be8dbc4abadc329b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0d5d183873de67a93520681be8dbc4abadc329b1">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Augmented_Human_Humancentric_Understanding_and_2D3D_Synthesis/Sabyrov_Towards_Real-time_Sign_Language_Interpreting_Robot_Evaluation_of_Non-manual_Components_CVPRW_2019_paper.html">Towards Real-time Sign Language Interpreting Robot: Evaluation of Non-manual Components on Recognition Accuracy</a></th>
                    </tr>
                
                    <tr id="1a42fbbb6aaa810128576bd615fe5e0977b06251">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a42fbbb6aaa810128576bd615fe5e0977b06251">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Maxwell_Real-Time_Physics-Based_Removal_of_Shadows_and_Shading_From_Road_Surfaces_CVPRW_2019_paper.html">Real-Time Physics-Based Removal of Shadows and Shading From Road Surfaces</a></th>
                    </tr>
                
                    <tr id="c270f87118b0899c8836ea274997a121974d92cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c270f87118b0899c8836ea274997a121974d92cc">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Kalliatakis_DisplaceNet_Recognising_Displaced_People_from_Images_by_Exploiting_Dominance_Level_CVPRW_2019_paper.html">DisplaceNet: Recognising Displaced People from Images by Exploiting Dominance Level</a></th>
                    </tr>
                
                    <tr id="6b9d765269867fb2e89df6cb2fa145b1b6117c99">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6b9d765269867fb2e89df6cb2fa145b1b6117c99">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Sight_and_Sound/Yapeng_Tian_Audio-Visual_Event_Localization_in_the_Wild_CVPRW_2019_paper.html">Audio-Visual Event Localization in the Wild</a></th>
                    </tr>
                
                    <tr id="899da796bd1f78416d8fc4a6ea793b0fe9930e4d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/899da796bd1f78416d8fc4a6ea793b0fe9930e4d">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Lee_Extended_End-to-End_optimized_Image_Compression_Method_based_on_a_Context-Adaptive_CVPRW_2019_paper.html">Extended End-to-End optimized Image Compression Method based on a Context-Adaptive Entropy Model</a></th>
                    </tr>
                
                    <tr id="4b01de80eb3019c69a3671f54544ec7354e01935">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4b01de80eb3019c69a3671f54544ec7354e01935">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UG2_Prize_Challenge/Li_Depth_Image_Quality_Assessment_for_View_Synthesis_Based_on_Weighted_CVPRW_2019_paper.html">Depth Image Quality Assessment for View Synthesis Based on Weighted Edge Similarity</a></th>
                    </tr>
                
                    <tr id="5dc0f1b550aeb276d1442630844b617b3948003f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5dc0f1b550aeb276d1442630844b617b3948003f">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UG2_Prize_Challenge/Arief_Density-Adaptive_Sampling_for_Heterogeneous_Point_Cloud_Object_Segmentation_in_Autonomous_CVPRW_2019_paper.html">Density-Adaptive Sampling for Heterogeneous Point Cloud Object Segmentation in Autonomous Vehicle Applications</a></th>
                    </tr>
                
                    <tr id="d85b859f22a0b7210156504931982d0fcc96667f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d85b859f22a0b7210156504931982d0fcc96667f">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Trager_Coordinate-Free_Carlsson-Weinshall_Duality_and_Relative_Multi-View_Geometry_CVPR_2019_paper.html">Coordinate-Free Carlsson-Weinshall Duality and Relative Multi-View Geometry</a></th>
                    </tr>
                
                    <tr id="7f382a645796107539e3e984c4bb70507a5a4160">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7f382a645796107539e3e984c4bb70507a5a4160">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Polarimetric_Camera_Calibration_Using_an_LCD_Monitor_CVPR_2019_paper.html">Polarimetric Camera Calibration Using an LCD Monitor</a></th>
                    </tr>
                
                    <tr id="b8cb3c0830b4b0124f469fbde434f501a3d9f654">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b8cb3c0830b4b0124f469fbde434f501a3d9f654">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lv_Turn_a_Silicon_Camera_Into_an_InGaAs_Camera_CVPR_2019_paper.html">Turn a Silicon Camera Into an InGaAs Camera</a></th>
                    </tr>
                
                    <tr id="1ebadc92701734028f76e22d71f5339eac166f1f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ebadc92701734028f76e22d71f5339eac166f1f">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Kim_Joint_Manifold_Diffusion_for_Combining_Predictions_on_Decoupled_Observations_CVPR_2019_paper.html">Joint Manifold Diffusion for Combining Predictions on Decoupled Observations</a></th>
                    </tr>
                
                    <tr id="8cf96e367622216a71a6d197667e26d2de90bcc3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8cf96e367622216a71a6d197667e26d2de90bcc3">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Trunz_Inverse_Procedural_Modeling_of_Knitwear_CVPR_2019_paper.html">Inverse Procedural Modeling of Knitwear</a></th>
                    </tr>
                
                    <tr id="a33987cfd9e61e0af16f4aa792021ac4e80aca94">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a33987cfd9e61e0af16f4aa792021ac4e80aca94">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Lin_MBS_Macroblock_Scaling_for_CNN_Model_Reduction_CVPR_2019_paper.html">MBS: Macroblock Scaling for CNN Model Reduction</a></th>
                    </tr>
                
                    <tr id="fedc389f32d609f5fafd5f44f7bf5a94e8ec587d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fedc389f32d609f5fafd5f44f7bf5a94e8ec587d">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhao_Spectral_Reconstruction_From_Dispersive_Blur_A_Novel_Light_Efficient_Spectral_CVPR_2019_paper.html">Spectral Reconstruction From Dispersive Blur: A Novel Light Efficient Spectral Imager</a></th>
                    </tr>
                
                    <tr id="6431621ac59f02942e7de9b8571c18872f07e869">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6431621ac59f02942e7de9b8571c18872f07e869">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Yezzi_PDE_Acceleration_for_Active_Contours_CVPR_2019_paper.html">PDE Acceleration for Active Contours</a></th>
                    </tr>
                
                    <tr id="430196b43a2960eedc46ceb7f463072542b54799">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/430196b43a2960eedc46ceb7f463072542b54799">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MULA/Giannone_Learning_Common_Representation_From_RGB_and_Depth_Images_CVPRW_2019_paper.html">Learning Common Representation From RGB and Depth Images</a></th>
                    </tr>
                
                    <tr id="8bb8cf57b1403ef18b03cba9fb746f57cda22167">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8bb8cf57b1403ef18b03cba9fb746f57cda22167">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Beaupre_Siamese_CNNs_for_RGB-LWIR_Disparity_Estimation_CVPRW_2019_paper.html">Siamese CNNs for RGB-LWIR Disparity Estimation</a></th>
                    </tr>
                
                    <tr id="89348bede5f72f6fc04c51a9b9dae3dafc3131e5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/89348bede5f72f6fc04c51a9b9dae3dafc3131e5">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SkelNetOn/Ozer_Parametric_Shape_Modeling_and_Skeleton_Extraction_With_Radial_Basis_Functions_CVPRW_2019_paper.html">Parametric Shape Modeling and Skeleton Extraction With Radial Basis Functions Using Similarity Domains Network</a></th>
                    </tr>
                
                    <tr id="c6069f189da1b3f0301da1b6014a6bbe5b8b568c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c6069f189da1b3f0301da1b6014a6bbe5b8b568c">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WAD/Guclu_RGB-D_Indoor_Mapping_Using_Deep_Features_CVPRW_2019_paper.html">RGB-D Indoor Mapping Using Deep Features</a></th>
                    </tr>
                
                    <tr id="38402793cabf5e60de6acfeb155fa7597be3df8b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38402793cabf5e60de6acfeb155fa7597be3df8b">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Dai_Video-Based_Action_Recognition_Using_Dimension_Reduction_of_Deep_Covariance_Trajectories_CVPRW_2019_paper.html">Video-Based Action Recognition Using Dimension Reduction of Deep Covariance Trajectories</a></th>
                    </tr>
                
                    <tr id="cde73a42d4dea6431c876b00245d462bad4b0f78">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cde73a42d4dea6431c876b00245d462bad4b0f78">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Shafiee_Dynamic_Representations_Toward_Efficient_Inference_on_Deep_Neural_Networks_by_CVPRW_2019_paper.html">Dynamic Representations Toward Efficient Inference on Deep Neural Networks by Decision Gates</a></th>
                    </tr>
                
                    <tr id="2a9ed0907776b404b3905264ac9e18497a4158c3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2a9ed0907776b404b3905264ac9e18497a4158c3">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Du_Recursive_Image_Dehazing_via_Perceptually_Optimized_Generative_Adversarial_Network_POGAN_CVPRW_2019_paper.html">Recursive Image Dehazing via Perceptually Optimized Generative Adversarial Network (POGAN)</a></th>
                    </tr>
                
                    <tr id="e0fb007a34943c0cd19d1b982186cba9e978f495">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e0fb007a34943c0cd19d1b982186cba9e978f495">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Kim_Evaluating_Parameterization_Methods_for_Convolutional_Neural_Network_CNN-Based_Image_Operators_CVPRW_2019_paper.html">Evaluating Parameterization Methods for Convolutional Neural Network (CNN)-Based Image Operators</a></th>
                    </tr>
                
                    <tr id="936b8ba15481793d180004b088f011944b2ec263">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/936b8ba15481793d180004b088f011944b2ec263">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Omiya_Optimization-Based_Data_Generation_for_Photo_Enhancement_CVPRW_2019_paper.html">Optimization-Based Data Generation for Photo Enhancement</a></th>
                    </tr>
                
                    <tr id="96ba1c68ad4f37b23aa7c629ee0932f631f2fd9b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96ba1c68ad4f37b23aa7c629ee0932f631f2fd9b">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Li_Adapting_Image_Super-Resolution_State-Of-The-Arts_and_Learning_Multi-Model_Ensemble_for_Video_CVPRW_2019_paper.html">Adapting Image Super-Resolution State-Of-The-Arts and Learning Multi-Model Ensemble for Video Super-Resolution</a></th>
                    </tr>
                
                    <tr id="90fb5bab23765024093e8e8f0f4fd3c94546710c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/90fb5bab23765024093e8e8f0f4fd3c94546710c">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Hsu_Face_Synthesis_and_Recognition_Using_Disentangled_Representation-Learning_Wasserstein_GAN_CVPRW_2019_paper.html">Face Synthesis and Recognition Using Disentangled Representation-Learning Wasserstein GAN</a></th>
                    </tr>
                
                    <tr id="88544e93eb859b8152fee2bee1fc3ff0f8dd01bf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/88544e93eb859b8152fee2bee1fc3ff0f8dd01bf">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Liu_Live_Demonstration_A_Real-Time_Event-Based_Fast_Corner_Detection_Demo_Based_CVPRW_2019_paper.html">Live Demonstration: A Real-Time Event-Based Fast Corner Detection Demo Based on FPGA</a></th>
                    </tr>
                
                    <tr id="aedd79f0e5eb09c2e38dddd3bf0e358d206ffbce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aedd79f0e5eb09c2e38dddd3bf0e358d206ffbce">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Weakly_Supervised_Learning_for_RealWorld_Computer_Vision_Applications/Xu_Semantic_Part_RCNN_for_Real-World_Pedestrian_Detection_CVPRW_2019_paper.html">Semantic Part RCNN for Real-World Pedestrian Detection</a></th>
                    </tr>
                
                    <tr id="fbb209f1ef344a0599db2f9a2c3ca947c57bef6c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fbb209f1ef344a0599db2f9a2c3ca947c57bef6c">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Lin_Learning_Semantically_Meaningful_Embeddings_Using_Linear_Constraints_CVPRW_2019_paper.html">Learning Semantically Meaningful Embeddings Using Linear Constraints</a></th>
                    </tr>
                
                    <tr id="e06539f4ba588cd473ba9b19e6c752f7d180247e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e06539f4ba588cd473ba9b19e6c752f7d180247e">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Lee_Analysis_of_the_contribution_and_temporal_dependency_of_LSTM_layers_CVPRW_2019_paper.html">Analysis of the contribution and temporal dependency of LSTM layers for reinforcement learning tasks</a></th>
                    </tr>
                
                    <tr id="d24d20bd5371856462b0e82df4ae1451584a52d9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d24d20bd5371856462b0e82df4ae1451584a52d9">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Yang_Directing_DNNs_Attention_for_Facial_Attribution_Classification_using_Gradient-weighted_Class_CVPRW_2019_paper.html">Directing DNNs Attention for Facial Attribution Classification using Gradient-weighted Class Activation Mapping</a></th>
                    </tr>
                
                    <tr id="7fcf083ff6a09da3308e591cb5f62254036cafb2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7fcf083ff6a09da3308e591cb5f62254036cafb2">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Dhamija_Improving_Deep_Network_Robustness_to_Unknown_Inputs_with_Objectosphere_CVPRW_2019_paper.html">Improving Deep Network Robustness to Unknown Inputs with Objectosphere</a></th>
                    </tr>
                
                    <tr id="8488ae768c796a413ff685843822ddbafd5446f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8488ae768c796a413ff685843822ddbafd5446f5">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Verma_CNN-based_System_for_Speaker_Independent_Cell-Phone_Identification_from_Recorded_Audio_CVPRW_2019_paper.html">CNN-based System for Speaker Independent Cell-Phone Identification from Recorded Audio</a></th>
                    </tr>
                
                    <tr id="3869cce163084179e2488b00370b4dee6c8dcce0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3869cce163084179e2488b00370b4dee6c8dcce0">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_Meets_Cognition_Camera_Ready/Hornauer_Driving_Scene_Retrieval_by_Example_from_Large-Scale_Data_CVPRW_2019_paper.html">Driving Scene Retrieval by Example from Large-Scale Data</a></th>
                    </tr>
                
                    <tr id="5093077647cbffad7a10d6aa8fee2cb7eb8a1d46">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5093077647cbffad7a10d6aa8fee2cb7eb8a1d46">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Porav_Reducing_Steganography_In_Cycle-consistency_GANs_CVPRW_2019_paper.html">Reducing Steganography In Cycle-consistency GANs</a></th>
                    </tr>
                
                    <tr id="c6069f189da1b3f0301da1b6014a6bbe5b8b568c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c6069f189da1b3f0301da1b6014a6bbe5b8b568c">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Autonomous_Driving/Guclu_RGB-D_Indoor_Mapping_Using_Deep_Features_CVPRW_2019_paper.html">RGB-D Indoor Mapping Using Deep Features</a></th>
                    </tr>
                
                    <tr id="7fe857af3910aaee6f9bb44a89c0ed560a7b50da">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7fe857af3910aaee6f9bb44a89c0ed560a7b50da">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/DynaVis/Shere_3D_Human_Pose_Estimation_From_Multi_Person_Stereo_360_Scenes_CVPRW_2019_paper.html">3D Human Pose Estimation From Multi Person Stereo 360 Scenes</a></th>
                    </tr>
                
                    <tr id="66da23d7b80bdb06dfebe80d16a940b9c2196643">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/66da23d7b80bdb06dfebe80d16a940b9c2196643">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/DynaVis/Miksik_Live_Reconstruction_of_Large-Scale_Dynamic_Outdoor_Worlds_CVPRW_2019_paper.html">Live Reconstruction of Large-Scale Dynamic Outdoor Worlds</a></th>
                    </tr>
                
                    <tr id="b2777d890103d7eaf465635fa2e6b0b66486f0a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b2777d890103d7eaf465635fa2e6b0b66486f0a9">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Li_A_Better_Color_Space_Conversion_Based_on_Learned_Variances_For_CVPRW_2019_paper.html">A Better Color Space Conversion Based on Learned Variances For Image Compression</a></th>
                    </tr>
                
                    <tr id="afb1c5bf5dab578ea310616c2aa8040e26ddf6eb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/afb1c5bf5dab578ea310616c2aa8040e26ddf6eb">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Cui_Decoder_Side_Color_Image_Quality_Enhancement_using_a_Wavelet_Transform_CVPRW_2019_paper.html">Decoder Side Color Image Quality Enhancement using a Wavelet Transform based 3-stage Convolutional Neural Network</a></th>
                    </tr>
                
                    <tr id="3ad241a9a9d6b500168e46c08497c9f91bd2a4e0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ad241a9a9d6b500168e46c08497c9f91bd2a4e0">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Li_VimicroABCnet_An_Image_Coder_Combining_A_Better_Color_Space_Conversion_CVPRW_2019_paper.html">VimicroABCnet: An Image Coder Combining A Better Color Space Conversion Algorithm and A Post Enhancing Network</a></th>
                    </tr>
                
                    <tr id="deceaa2b4c8ec86f43d73d409f8444c7f24d223a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/deceaa2b4c8ec86f43d73d409f8444c7f24d223a">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Cai_Efficient_Learning_Based_Sub-pixel_Image_Compression_CVPRW_2019_paper.html">Efficient Learning Based Sub-pixel Image Compression</a></th>
                    </tr>
                
                    <tr id="61ff748bfe6cfd6bce42f42e126892b092bbbffc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61ff748bfe6cfd6bce42f42e126892b092bbbffc">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Koyamatsu_Reflective_and_Fluorescent_Separation_Under_Narrow-Band_Illumination_CVPR_2019_paper.html">Reflective and Fluorescent Separation Under Narrow-Band Illumination</a></th>
                    </tr>
                
                    <tr id="e5ea38b9d211e1d3d9fd5182150ee1bc7ed2a435">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5ea38b9d211e1d3d9fd5182150ee1bc7ed2a435">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Liang_Learning_Personalized_Modular_Network_Guided_by_Structured_Knowledge_CVPR_2019_paper.html">Learning Personalized Modular Network Guided by Structured Knowledge</a></th>
                    </tr>
                
                    <tr id="d80b8ddc5711a31a4ae82f6ad6d29e528d5e82c3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d80b8ddc5711a31a4ae82f6ad6d29e528d5e82c3">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Gao_Cross_Domain_Model_Compression_by_Structurally_Weight_Sharing_CVPR_2019_paper.html">Cross Domain Model Compression by Structurally Weight Sharing</a></th>
                    </tr>
                
                    <tr id="d84a8dff940e6949469ca92aa00c7692c43da99a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d84a8dff940e6949469ca92aa00c7692c43da99a">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Xu_Deep_Robust_Subjective_Visual_Property_Prediction_in_Crowdsourcing_CVPR_2019_paper.html">Deep Robust Subjective Visual Property Prediction in Crowdsourcing</a></th>
                    </tr>
                
                    <tr id="4f7bbcef3d40cafad17936fdf562a121667af1e8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f7bbcef3d40cafad17936fdf562a121667af1e8">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Zhang_Divergence_Prior_and_Vessel-Tree_Reconstruction_CVPR_2019_paper.html">Divergence Prior and Vessel-Tree Reconstruction</a></th>
                    </tr>
                
                    <tr id="91767fd21ffa35b162e6498b0079143321e69264">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/91767fd21ffa35b162e6498b0079143321e69264">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Precognition/Hudnell_Robust_Aleatoric_Modeling_for_Future_Vehicle_Localization_CVPRW_2019_paper.html">Robust Aleatoric Modeling for Future Vehicle Localization</a></th>
                    </tr>
                
                    <tr id="0ea869fcb96d5a0e0a59b27eeae0234938fe1fca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ea869fcb96d5a0e0a59b27eeae0234938fe1fca">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MULA/Wan_Co-Compressing_and_Unifying_Deep_CNN_Models_for_Efficient_Human_Face_CVPRW_2019_paper.html">Co-Compressing and Unifying Deep CNN Models for Efficient Human Face and Speaker Recognition</a></th>
                    </tr>
                
                    <tr id="d3bebb7c790fa4c033a30fab6b846a845c2d0487">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d3bebb7c790fa4c033a30fab6b846a845c2d0487">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Amerini_WiCV_2019_The_Sixth_Women_In_Computer_Vision_Workshop_CVPRW_2019_paper.html">WiCV 2019: The Sixth Women In Computer Vision Workshop</a></th>
                    </tr>
                
                    <tr id="45293b8428be256faf29c14be524c2c68110dadd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/45293b8428be256faf29c14be524c2c68110dadd">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Pouyanfar_Residual_Attention-Based_Fusion_for_Video_Classification_CVPRW_2019_paper.html">Residual Attention-Based Fusion for Video Classification</a></th>
                    </tr>
                
                    <tr id="30f537ec1d2d688894defbc7fb366cf274fd4bea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/30f537ec1d2d688894defbc7fb366cf274fd4bea">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Gharibbafghi_Superpixel-Based_3D_Building_Model_Refinement_and_Change_Detection_Using_VHR_CVPRW_2019_paper.html">Superpixel-Based 3D Building Model Refinement and Change Detection, Using VHR Stereo Satellite Imagery</a></th>
                    </tr>
                
                    <tr id="29748c47bd7b4d827092d5207530627e2d862e77">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/29748c47bd7b4d827092d5207530627e2d862e77">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Yazdanpour_Online_Reconstruction_of_Indoor_Scenes_With_Local_Manhattan_Frame_Growing_CVPRW_2019_paper.html">Online Reconstruction of Indoor Scenes With Local Manhattan Frame Growing</a></th>
                    </tr>
                
                    <tr id="5de538f74fd1a9a953505929e257e89c0ac64518">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5de538f74fd1a9a953505929e257e89c0ac64518">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Guo_Dual_Graphical_Models_for_Relational_Modeling_of_Indoor_Object_Categories_CVPRW_2019_paper.html">Dual Graphical Models for Relational Modeling of Indoor Object Categories</a></th>
                    </tr>
                
                    <tr id="ee575ae5f44b7e625615ce7c4cb9cdd220081b7b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ee575ae5f44b7e625615ce7c4cb9cdd220081b7b">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Iwashita_MU-Net_Deep_Learning-Based_Thermal_IR_Image_Estimation_From_RGB_Image_CVPRW_2019_paper.html">MU-Net: Deep Learning-Based Thermal IR Image Estimation From RGB Image</a></th>
                    </tr>
                
                    <tr id="0881d8beaabfe1a41f29ca7d9cc14982139bef9a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0881d8beaabfe1a41f29ca7d9cc14982139bef9a">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EVW/Chen_Condensation-Net_Memory-Efficient_Network_Architecture_With_Cross-Channel_Pooling_Layers_and_Virtual_CVPRW_2019_paper.html">Condensation-Net: Memory-Efficient Network Architecture With Cross-Channel Pooling Layers and Virtual Feature Maps</a></th>
                    </tr>
                
                    <tr id="c9d612cdd8ba4b9bce669f33072caaed39d3176a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c9d612cdd8ba4b9bce669f33072caaed39d3176a">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EVW/Gao_DupNet_Towards_Very_Tiny_Quantized_CNN_With_Improved_Accuracy_for_CVPRW_2019_paper.html">DupNet: Towards Very Tiny Quantized CNN With Improved Accuracy for Face Detection</a></th>
                    </tr>
                
                    <tr id="c3cb343fe2cac7c6e83a9f2c661cb0f8a3ed27ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c3cb343fe2cac7c6e83a9f2c661cb0f8a3ed27ce">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EarthVision/Jin_Intrinsic_Scene_Properties_From_Hyperspectral_Images_and_LiDAR_CVPRW_2019_paper.html">Intrinsic Scene Properties From Hyperspectral Images and LiDAR</a></th>
                    </tr>
                
                    <tr id="48dc1bdbac70bd1abe89a284f4f10807f63dd884">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/48dc1bdbac70bd1abe89a284f4f10807f63dd884">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVSports/Schlosser_Investigation_on_Combining_3D_Convolution_of_Image_Data_and_Optical_CVPRW_2019_paper.html">Investigation on Combining 3D Convolution of Image Data and Optical Flow to Generate Temporal Action Proposals</a></th>
                    </tr>
                
                    <tr id="281c48f743500f6802477e7fdc4b19db59915f87">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/281c48f743500f6802477e7fdc4b19db59915f87">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Chen_Single_Image_Based_Metric_Learning_via_Overlapping_Blocks_Model_for_CVPRW_2019_paper.html">Single Image Based Metric Learning via Overlapping Blocks Model for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="3d17bd832ca3e3f1fc84624a3093ae84d2bce041">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3d17bd832ca3e3f1fc84624a3093ae84d2bce041">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Kang_Hierarchical_Feature-Pair_Relation_Networks_for_Face_Recognition_CVPRW_2019_paper.html">Hierarchical Feature-Pair Relation Networks for Face Recognition</a></th>
                    </tr>
                
                    <tr id="468075ccc6b662cd458c1a714fce2d9e60407ec4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/468075ccc6b662cd458c1a714fce2d9e60407ec4">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SAIAD/Schuster_An_Empirical_Evaluation_Study_on_the_Training_of_SDC_Features_CVPRW_2019_paper.html">An Empirical Evaluation Study on the Training of SDC Features for Dense Pixel Matching</a></th>
                    </tr>
                
                    <tr id="955704cebc220bebe9661b110a22ed17604ebe0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/955704cebc220bebe9661b110a22ed17604ebe0c">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SAIAD/Brunner_Leveraging_Semantic_Embeddings_for_Safety-Critical_Applications_CVPRW_2019_paper.html">Leveraging Semantic Embeddings for Safety-Critical Applications</a></th>
                    </tr>
                
                    <tr id="cc2f59510caf0fffe3a426dd70304b471a418e37">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cc2f59510caf0fffe3a426dd70304b471a418e37">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Zhang_Joint_Learning_of_Neural_Networks_via_Iterative_Reweighted_Least_Squares_CVPRW_2019_paper.html">Joint Learning of Neural Networks via Iterative Reweighted Least Squares</a></th>
                    </tr>
                
                    <tr id="5a4fdb22bc22a68986f207ee15fcff0fbb3a00bd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5a4fdb22bc22a68986f207ee15fcff0fbb3a00bd">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Kimura_Interpretation_of_Feature_Space_using_Multi-Channel_Attentional_Sub-Networks_CVPRW_2019_paper.html">Interpretation of Feature Space using Multi-Channel Attentional Sub-Networks</a></th>
                    </tr>
                
                    <tr id="98b28849c88b86120bfd4fa390944468fa09832e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/98b28849c88b86120bfd4fa390944468fa09832e">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Yoo_Relevance_Regularization_of_Convolutional_Neural_Network_for_Interpretable_Classification_CVPRW_2019_paper.html">Relevance Regularization of Convolutional Neural Network for Interpretable Classification</a></th>
                    </tr>
                
                    <tr id="c95b12d9a2831a0e9b11a89ed21cd7a2628600c2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c95b12d9a2831a0e9b11a89ed21cd7a2628600c2">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Fan_Towards_an_Understanding_of_Neural_Networks_in_Natural-Image_Spaces_CVPRW_2019_paper.html">Towards an Understanding of Neural Networks in Natural-Image Spaces</a></th>
                    </tr>
                
                    <tr id="fbdcd3ad1ac5bd1a13a49163e568d0d85b59b2c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fbdcd3ad1ac5bd1a13a49163e568d0d85b59b2c4">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Li_Beauty_Learning_and_Counterfactual_Inference_CVPRW_2019_paper.html">Beauty Learning and Counterfactual Inference</a></th>
                    </tr>
                
                    <tr id="376ee44dc2e36199209b86cfef784533a96c55ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/376ee44dc2e36199209b86cfef784533a96c55ac">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Kennamer_Empirical_Study_of_MC-Dropout_in_Various_Astronomical_Observing_Conditions_CVPRW_2019_paper.html">Empirical Study of MC-Dropout in Various Astronomical Observing Conditions</a></th>
                    </tr>
                
                    <tr id="b4321bb30d7d49805391bb47864119fbcdefa744">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b4321bb30d7d49805391bb47864119fbcdefa744">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Face_and_Gesture_Analysis_for_Health_Informatics/Bera_Improving_Socially-aware_Multi-channel_Human_Emotion_Prediction_for_Robot_Navigation_CVPRW_2019_paper.html">Improving Socially-aware Multi-channel Human Emotion Prediction for Robot Navigation</a></th>
                    </tr>
                
                    <tr id="18befbc1ddb5f66ec90fe0d02ff94e5aa54d5b74">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/18befbc1ddb5f66ec90fe0d02ff94e5aa54d5b74">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Face_and_Gesture_Analysis_for_Health_Informatics/Ogihara_Categorical_Timeline_Allocation_and_Alignment_for_Diagnostic_Head_Movement_Tracking_CVPRW_2019_paper.html">Categorical Timeline Allocation and Alignment for Diagnostic Head Movement Tracking Feature Analysis</a></th>
                    </tr>
                
                    <tr id="240ced5ef660759830b388efa1ff50e44446d0a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/240ced5ef660759830b388efa1ff50e44446d0a0">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AI_City/Luna_VPULab_participation_at_AI_City_Challenge_2019_CVPRW_2019_paper.html">VPULab participation at AI City Challenge 2019</a></th>
                    </tr>
                
                    <tr id="dce4fcba1f78d1aebfdbee4f5e1375acd0fba87e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dce4fcba1f78d1aebfdbee4f5e1375acd0fba87e">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_Meets_Cognition_Camera_Ready/Rempe_Learning_Generalizable_Final-State_Dynamics_of_3D_Rigid_Objects_CVPRW_2019_paper.html">Learning Generalizable Final-State Dynamics of 3D Rigid Objects</a></th>
                    </tr>
                
                    <tr id="9c25288c124638696491c9b1f3b8282910a901bd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c25288c124638696491c9b1f3b8282910a901bd">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Treible_CATS_2_Color_And_Thermal_Stereo_Scenes_with_Semantic_Labels_CVPRW_2019_paper.html">CATS 2: Color And Thermal Stereo Scenes with Semantic Labels</a></th>
                    </tr>
                
                    <tr id="fa1185dbf0372e55a1c0200262157b9b2876d917">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fa1185dbf0372e55a1c0200262157b9b2876d917">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/cv4gc/Yi_Towards_equitable_access_to_information_and_opportunity_for_all_mapping_CVPRW_2019_paper.html">Towards equitable access to information and opportunity for all: mapping schools with high-resolution Satellite Imagery and Machine Learning</a></th>
                    </tr>
                
                    <tr id="c1fb788324287f7e7d84606f32f1878196764b36">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c1fb788324287f7e7d84606f32f1878196764b36">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Sight_and_Sound/Yukitaka_Tsuchiya_Generating_Video_from_Single_Image_and_Sound_CVPRW_2019_paper.html">Generating Video from Single Image and Sound</a></th>
                    </tr>
                
                    <tr id="4aa2a2aeb5cbe8070c47cbc912f8a6057ace4a0f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4aa2a2aeb5cbe8070c47cbc912f8a6057ace4a0f">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/3DWidDGET/Leonardo_Galteri_Coarse-to-Fine_3D_Face_Reconstruction_CVPRW_2019_paper.html">Coarse-to-Fine 3D Face Reconstruction</a></th>
                    </tr>
                
                    <tr id="4841e9911a234e66e538cfbafb27aac8b2b1c59c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4841e9911a234e66e538cfbafb27aac8b2b1c59c">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/MMLV/Rouditchenko_Self-Supervised_Segmentation_and_Source_Separation_on_Videos_CVPRW_2019_paper.html">Self-Supervised Segmentation and Source Separation on Videos</a></th>
                    </tr>
                
                    <tr id="3d1a3249a8ba282293c43338690deef9079c115f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3d1a3249a8ba282293c43338690deef9079c115f">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Savioli_A_Hybrid_Approach_Between_Adversarial_Generative_Networks_and_Actor-Critic_Policy_CVPRW_2019_paper.html">A Hybrid Approach Between Adversarial Generative Networks and Actor-Critic Policy Gradient for Low Rate High-Resolution Image Compression</a></th>
                    </tr>
                
                    <tr id="9aa92379544be3adc00a4bfdc6ee0f89163daf14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9aa92379544be3adc00a4bfdc6ee0f89163daf14">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UG2_Prize_Challenge/Yang_Preselection_Based_Subjective_Preference_Evaluation_for_the_Quality_of_Underwater_CVPRW_2019_paper.html">Preselection Based Subjective Preference Evaluation for the Quality of Underwater Images</a></th>
                    </tr>
                
                    <tr id="8ba2f12bc2b1ae01913d5e79a89c47bb69cc464c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8ba2f12bc2b1ae01913d5e79a89c47bb69cc464c">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Wang_Joint_Representative_Selection_and_Feature_Learning_A_Semi-Supervised_Approach_CVPR_2019_paper.html">Joint Representative Selection and Feature Learning: A Semi-Supervised Approach</a></th>
                    </tr>
                
                    <tr id="810c3412a1f5997219a0d4b3365ea94a7bcda6d9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/810c3412a1f5997219a0d4b3365ea94a7bcda6d9">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Jeong_End-To-End_Efficient_Representation_Learning_via_Cascading_Combinatorial_Optimization_CVPR_2019_paper.html">End-To-End Efficient Representation Learning via Cascading Combinatorial Optimization</a></th>
                    </tr>
                
                    <tr id="36d136f12388b8bda1b2db1a06c1981b94f8b48f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/36d136f12388b8bda1b2db1a06c1981b94f8b48f">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Bracha_Informative_Object_Annotations_Tell_Me_Something_I_Dont_Know_CVPR_2019_paper.html">Informative Object Annotations: Tell Me Something I Don&#39;t Know</a></th>
                    </tr>
                
                    <tr id="73a006022a64a7de18cd99ba7c7cb570e0566e38">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/73a006022a64a7de18cd99ba7c7cb570e0566e38">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Precognition/Agethen_Anticipation_of_Human_Actions_With_Pose-Based_Fine-Grained_Representations_CVPRW_2019_paper.html">Anticipation of Human Actions With Pose-Based Fine-Grained Representations</a></th>
                    </tr>
                
                    <tr id="34b09024e25c73500a3a9bf79e7eec48e8fd45aa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/34b09024e25c73500a3a9bf79e7eec48e8fd45aa">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PCV/Tsekourakis_Measuring_the_Effects_of_Temporal_Coherence_in_Depth_Estimation_for_CVPRW_2019_paper.html">Measuring the Effects of Temporal Coherence in Depth Estimation for Dynamic Scenes</a></th>
                    </tr>
                
                    <tr id="87a132a6670416cd4d3f1f61af2ea30986322187">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/87a132a6670416cd4d3f1f61af2ea30986322187">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Chung_Assessing_Architectural_Similarity_in_Populations_of_Deep_Neural_Networks_CVPRW_2019_paper.html">Assessing Architectural Similarity in Populations of Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="969b04f58a2bf4a1658de0af544de590cd99ead2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/969b04f58a2bf4a1658de0af544de590cd99ead2">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Bhatt_Segmentation_of_Low-Level_Temporal_Plume_Patterns_From_IR_Video_CVPRW_2019_paper.html">Segmentation of Low-Level Temporal Plume Patterns From IR Video</a></th>
                    </tr>
                
                    <tr id="98bdf59ba97b3c0260c9fcc06ce1f592c9c7a3e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/98bdf59ba97b3c0260c9fcc06ce1f592c9c7a3e3">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Mullen_Comparing_the_Effects_of_Annotation_Type_on_Machine_Learning_Detection_CVPRW_2019_paper.html">Comparing the Effects of Annotation Type on Machine Learning Detection Performance</a></th>
                    </tr>
                
                    <tr id="47ec6a4f708d6e8805b6e2731e27e258ab0ba11a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47ec6a4f708d6e8805b6e2731e27e258ab0ba11a">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Ozkan_Hyperspectral_Data_to_Relative_Lidar_Depth_An_Inverse_Problem_for_CVPRW_2019_paper.html">Hyperspectral Data to Relative Lidar Depth: An Inverse Problem for Remote Sensing</a></th>
                    </tr>
                
                    <tr id="6b73aac2bb3b39065642af1313f411a8eaee9623">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6b73aac2bb3b39065642af1313f411a8eaee9623">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BIC/Liu_Intersection_to_Overpass_Instance_Segmentation_on_Filamentous_Structures_With_an_CVPRW_2019_paper.html">Intersection to Overpass: Instance Segmentation on Filamentous Structures With an Orientation-Aware Neural Network and Terminus Pairing Algorithm</a></th>
                    </tr>
                
                    <tr id="3dd7732b2aa037cd5da66e0018d24fb03c077df2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3dd7732b2aa037cd5da66e0018d24fb03c077df2">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVPPP/Shafiekhani_VisND_A_Visualization_Tool_for_Multidimensional_Model_of_Canopy_CVPRW_2019_paper.html">VisND: A Visualization Tool for Multidimensional Model of Canopy</a></th>
                    </tr>
                
                    <tr id="d3de168422b1440c9a367cb9a121759869ea3834">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d3de168422b1440c9a367cb9a121759869ea3834">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BCMCVAI/Amar_Incentive-Based_Ledger_Protocols_for_Solving_Machine_Learning_Tasks_and_Optimization_CVPRW_2019_paper.html">Incentive-Based Ledger Protocols for Solving Machine Learning Tasks and Optimization Problems via Competitions</a></th>
                    </tr>
                
                    <tr id="70cd3d0dd222e45b3ff7a628181de80fc1b5fdca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70cd3d0dd222e45b3ff7a628181de80fc1b5fdca">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Huang_Deep_Anchored_Convolutional_Neural_Networks_CVPRW_2019_paper.html">Deep Anchored Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="a15a277af50a6fd02efbb7ef8f63593a1c9e54f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a15a277af50a6fd02efbb7ef8f63593a1c9e54f1">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Yang_Multi-Stage_Optimization_for_Photorealistic_Neural_Style_Transfer_CVPRW_2019_paper.html">Multi-Stage Optimization for Photorealistic Neural Style Transfer</a></th>
                    </tr>
                
                    <tr id="1aae75f470c6268769911bb503ce3757220ee48e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1aae75f470c6268769911bb503ce3757220ee48e">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/Yi_Online_Neural_Cell_Tracking_Using_Blob-Seed_Segmentation_and_Optical_Flow_CVPRW_2019_paper.html">Online Neural Cell Tracking Using Blob-Seed Segmentation and Optical Flow</a></th>
                    </tr>
                
                    <tr id="326968b0f38fee62805233a931299aa93868efb6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/326968b0f38fee62805233a931299aa93868efb6">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Bose_Live_Demonstration_Digit_Recognition_on_Pixel_Processor_Arrays_CVPRW_2019_paper.html">Live Demonstration: Digit Recognition on Pixel Processor Arrays</a></th>
                    </tr>
                
                    <tr id="b26f53ec1d8262d6dcf39e28c02ccfe214bef5af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b26f53ec1d8262d6dcf39e28c02ccfe214bef5af">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Weakly_Supervised_Learning_for_RealWorld_Computer_Vision_Applications/Zhang_A_pairwise_learning_strategy_for_video-based_face_recognition_CVPRW_2019_paper.html">A pairwise learning strategy for video-based face recognition</a></th>
                    </tr>
                
                    <tr id="f652cebe85d2b1f76493da2668dc6fe15b84a103">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f652cebe85d2b1f76493da2668dc6fe15b84a103">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Weakly_Supervised_Learning_for_RealWorld_Computer_Vision_Applications/Shimoda_Self-supervised_Difference_Detection_for_Refinement_CRF_and_Seed_Interpolation_CVPRW_2019_paper.html">Self-supervised Difference Detection for Refinement CRF and Seed Interpolation</a></th>
                    </tr>
                
                    <tr id="4628dc86d6ee97964a7819d01a221cd84e170add">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4628dc86d6ee97964a7819d01a221cd84e170add">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Motiian_Unsupervised_Learning_of_Paired_Style_Statistics_for_Unpaired_Image_Translation_CVPRW_2019_paper.html">Unsupervised Learning of Paired Style Statistics for Unpaired Image Translation</a></th>
                    </tr>
                
                    <tr id="b498ce6c001507c55f976f68c4ec9702720e7425">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b498ce6c001507c55f976f68c4ec9702720e7425">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Ramakrishnan_Identifying_Interpretable_Action_Concepts_in_Deep_Networks_CVPRW_2019_paper.html">Identifying Interpretable Action Concepts in Deep Networks</a></th>
                    </tr>
                
                    <tr id="2e8eb3d8b0c67f593a1a64d28624aeeaa7c736f8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e8eb3d8b0c67f593a1a64d28624aeeaa7c736f8">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Daya_Beyond_Explainability_Leveraging_Interpretability_for_Improved_Adversarial_Learning_CVPRW_2019_paper.html">Beyond Explainability: Leveraging Interpretability for Improved Adversarial Learning</a></th>
                    </tr>
                
                    <tr id="86bc9524de32805ba2f133cda58e456fb552bfcb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/86bc9524de32805ba2f133cda58e456fb552bfcb">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Sathish_Unit_Impulse_Response_as_an_Explainer_of_Redundancy_in_a_CVPRW_2019_paper.html">Unit Impulse Response as an Explainer of Redundancy in a Deep Convolutional Neural Network</a></th>
                    </tr>
                
                    <tr id="7b48129aa32395624e66a0fc54bafc4d7001e03f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b48129aa32395624e66a0fc54bafc4d7001e03f">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Alyuz_Interpretable_Machine_Learning_for_Generating_Semantically_Meaningful_Formative_Feedback_CVPRW_2019_paper.html">Interpretable Machine Learning for Generating Semantically Meaningful Formative Feedback</a></th>
                    </tr>
                
                    <tr id="3adfc25912348a1b0a23a00777853849815986ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3adfc25912348a1b0a23a00777853849815986ab">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Chen_To_believe_or_not_to_believe_Validating_explanation_fidelity_for_CVPRW_2019_paper.html">To believe or not to believe: Validating explanation fidelity for dynamic malware analysis</a></th>
                    </tr>
                
                    <tr id="ec7e51559fc88c97718bda0a5cc9dda5099c739b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ec7e51559fc88c97718bda0a5cc9dda5099c739b">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Bargal_Are_CNN_Predictions_based_on_Reasonable_Evidence_CVPRW_2019_paper.html">Are CNN Predictions based on Reasonable Evidence?</a></th>
                    </tr>
                
                    <tr id="f880ebd2ab08872bb6f79c12fa94b4b4d8043f97">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f880ebd2ab08872bb6f79c12fa94b4b4d8043f97">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/de_la_Calle_Geometric_interpretation_of_a_CNNs_last_layer_CVPRW_2019_paper.html">Geometric interpretation of a CNN&#39;s last layer</a></th>
                    </tr>
                
                    <tr id="11cb2042a31f4447cdd1b752f7d7586938bb327c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/11cb2042a31f4447cdd1b752f7d7586938bb327c">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Vasu_Visualizing_the_Resilience_of_Deep_Convolutional_Network_Interpretations_CVPRW_2019_paper.html">Visualizing the Resilience of Deep Convolutional Network Interpretations</a></th>
                    </tr>
                
                    <tr id="2d7b3390f623bd5c7bf4d1c41c9bff887baf4bf2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d7b3390f623bd5c7bf4d1c41c9bff887baf4bf2">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Dupre_Iterative_Self-Learning_Semi-Supervised_Improvement_to_Dataset_Volumes_and_Model_Accuracy_CVPRW_2019_paper.html">Iterative Self-Learning: Semi-Supervised Improvement to Dataset Volumes and Model Accuracy</a></th>
                    </tr>
                
                    <tr id="c9c44aea7cac6addce6e396dcdcfa6425282b143">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c9c44aea7cac6addce6e396dcdcfa6425282b143">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Media_Forensics/Stanton_Detecting_Image_Forgery_Based_On_Color_Phenomenology_CVPRW_2019_paper.html">Detecting Image Forgery Based On Color Phenomenology</a></th>
                    </tr>
                
                    <tr id="20171a7296197ba0ba9d63fe843fee32d67c9bed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/20171a7296197ba0ba9d63fe843fee32d67c9bed">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_Meets_Cognition_Camera_Ready/Singh_HalfHalf_New_Tasks_and_Benchmarks_for_Studying_Visual_Common_Sense_CVPRW_2019_paper.html">Half&amp;Half: New Tasks and Benchmarks for Studying Visual Common Sense</a></th>
                    </tr>
                
                    <tr id="cbfc46198306201da2d00a1e76e80c62b1c6080b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cbfc46198306201da2d00a1e76e80c62b1c6080b">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_for_All_Seasons_Bad_Weather_and_Nighttime/Haurum_Is_it_Raining_Outside__Detection_of_Rainfall_using_General-Purpose_CVPRW_2019_paper.html">Is it Raining Outside?  Detection of Rainfall using General-Purpose Surveillance Cameras</a></th>
                    </tr>
                
                    <tr id="5a0a08ba1b13ef2b329cb320dd8b834edb426232">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5a0a08ba1b13ef2b329cb320dd8b834edb426232">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Augmented_Human_Humancentric_Understanding_and_2D3D_Synthesis/Huang_Infant_Contact-less_Non-Nutritive_Sucking_Pattern_Quantification_via_Facial_Gesture_Analysis_CVPRW_2019_paper.html">Infant Contact-less Non-Nutritive Sucking Pattern Quantification via Facial Gesture Analysis</a></th>
                    </tr>
                
                    <tr id="9004b113d09b79a83657a79d60ad2cafecddf7cf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9004b113d09b79a83657a79d60ad2cafecddf7cf">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Sight_and_Sound/Lele_Chen_Sound_to_Visual_Hierarchical_Cross-Modal_Talking_Face_Generation_CVPRW_2019_paper.html">Sound to Visual: Hierarchical Cross-Modal Talking Face Generation</a></th>
                    </tr>
                
                    <tr id="670a5d08910b93cf20e58543be182d7a2fbfb1bd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/670a5d08910b93cf20e58543be182d7a2fbfb1bd">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Sight_and_Sound/Inkyu_An_Reflection_and_Diffraction-Aware_Sound_Source_Localization_CVPRW_2019_paper.html">Reflection and Diffraction-Aware Sound Source Localization</a></th>
                    </tr>
                
                    <tr id="01badbdee472872164ec7272f7f3c2541558d4d7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01badbdee472872164ec7272f7f3c2541558d4d7">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Lee_Learned_Image_Compression_with_Residual_Coding_CVPRW_2019_paper.html">Learned Image Compression with Residual Coding</a></th>
                    </tr>
                
                    <tr id="64246e99daefcb6de0d06219835d48828962110b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/64246e99daefcb6de0d06219835d48828962110b">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Chun_Learned_Prior_Information_for_Image_Compression_CVPRW_2019_paper.html">Learned Prior Information for Image Compression</a></th>
                    </tr>
                
                    <tr id="247e5c881797ea80ec850bd531324ff4bbfc6f6f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/247e5c881797ea80ec850bd531324ff4bbfc6f6f">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/UG2_Prize_Challenge/Zhao_Pyramid_Convolutional_Network_for_Single_Image_Deraining_CVPRW_2019_paper.html">Pyramid Convolutional Network for Single Image Deraining</a></th>
                    </tr>
                
                    <tr id="7de24fc3ddb41ba4131ffd7eb76ae91c607d82f3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7de24fc3ddb41ba4131ffd7eb76ae91c607d82f3">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/DOAI/Jiang_ArcticNet_A_Deep_Learning_Solution_to_Classify_the_Arctic_Area_CVPRW_2019_paper.html">ArcticNet: A Deep Learning Solution to Classify the Arctic Area</a></th>
                    </tr>
                
                    <tr id="5bc582764f971918fc5fc4a8c222fb24c4a6f511">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5bc582764f971918fc5fc4a8c222fb24c4a6f511">0</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content_CVPR_2019/html/Probst_What_Correspondences_Reveal_About_Unknown_Camera_and_Motion_Models_CVPR_2019_paper.html">What Correspondences Reveal About Unknown Camera and Motion Models?</a></th>
                    </tr>
                
                    <tr id="18ada72f92ea8d0c0eed6f9fbb46b1d37ee95809">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/18ada72f92ea8d0c0eed6f9fbb46b1d37ee95809">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/WiCV/Pfisterer_Towards_Computer_Vision_Powered_Color-Nutrient_Assessment_of_Pureed_Food_CVPRW_2019_paper.html">Towards Computer Vision Powered Color-Nutrient Assessment of Pureed Food</a></th>
                    </tr>
                
                    <tr id="4eee1d62e4349293a78d0b16bae16c26096aea74">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4eee1d62e4349293a78d0b16bae16c26096aea74">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Emerson_Image_Recovery_in_the_Infrared_Domain_via_Path-Augmented_Compressive_Sampling_CVPRW_2019_paper.html">Image Recovery in the Infrared Domain via Path-Augmented Compressive Sampling Matching Pursuit</a></th>
                    </tr>
                
                    <tr id="7f09dee8545f946a7831410f532d6105ef4e5845">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7f09dee8545f946a7831410f532d6105ef4e5845">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/PBVS/Bernal_Surrogate_Contrastive_Network_for_Supervised_Band_Selection_in_Multispectral_Computer_CVPRW_2019_paper.html">Surrogate Contrastive Network for Supervised Band Selection in Multispectral Computer Vision Tasks</a></th>
                    </tr>
                
                    <tr id="6952b5f1e891632985fe32c287aaa38b768b7588">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6952b5f1e891632985fe32c287aaa38b768b7588">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/BIC/Selka_Surface_Parameterization_and_Registration_for_Statistical_Multiscale_Atlasing_of_Organ_CVPRW_2019_paper.html">Surface Parameterization and Registration for Statistical Multiscale Atlasing of Organ Development</a></th>
                    </tr>
                
                    <tr id="9bb7e13d76bc4404ff034eb0759823138c7b6112">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9bb7e13d76bc4404ff034eb0759823138c7b6112">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/ISIC/Karaimer_A_Customized_Camera_Imaging_Pipeline_for_Dermatological_Imaging_CVPRW_2019_paper.html">A Customized Camera Imaging Pipeline for Dermatological Imaging</a></th>
                    </tr>
                
                    <tr id="0298643ab4e942668832c231706f6732bd33f4fc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0298643ab4e942668832c231706f6732bd33f4fc">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SkelNetOn/Gui_Invariance_to_Affine-Permutation_Distortions_CVPRW_2019_paper.html">Invariance to Affine-Permutation Distortions</a></th>
                    </tr>
                
                    <tr id="918996bac4632a1673e69e2907b145dabc20dda4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/918996bac4632a1673e69e2907b145dabc20dda4">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/Yang_Stacked_Multi-Target_Network_for_Robust_Facial_Landmark_Localisation_CVPRW_2019_paper.html">Stacked Multi-Target Network for Robust Facial Landmark Localisation</a></th>
                    </tr>
                
                    <tr id="b77d6d31a10061bac5bc2e500b6f83d9b33e8be6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b77d6d31a10061bac5bc2e500b6f83d9b33e8be6">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/AMFG/Zheng_2D-3D_Heterogeneous_Face_Recognition_Based_on_Deep_Coupled_Spectral_Regression_CVPRW_2019_paper.html">2D-3D Heterogeneous Face Recognition Based on Deep Coupled Spectral Regression</a></th>
                    </tr>
                
                    <tr id="96fbeb60b2d8944fb8e0c1bd54c7b823a80c8136">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96fbeb60b2d8944fb8e0c1bd54c7b823a80c8136">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Li_Robust_Visual_Tracking_via_Collaborative_and_Reinforced_Convolutional_Feature_Learning_CVPRW_2019_paper.html">Robust Visual Tracking via Collaborative and Reinforced Convolutional Feature Learning</a></th>
                    </tr>
                
                    <tr id="6185073ff219ac540895161e37941f5b582e4f77">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6185073ff219ac540895161e37941f5b582e4f77">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Wang_Image_Denoising_Using_Deep_CGAN_With_Bi-Skip_Connections_CVPRW_2019_paper.html">Image Denoising Using Deep CGAN With Bi-Skip Connections</a></th>
                    </tr>
                
                    <tr id="1914c76fef174753ad60bbe5642e16224a4570f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1914c76fef174753ad60bbe5642e16224a4570f9">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CEFRL/Wang_A_Site_Model_Based_Change_Detection_Method_for_SAR_Images_CVPRW_2019_paper.html">A Site Model Based Change Detection Method for SAR Images</a></th>
                    </tr>
                
                    <tr id="3a89177065bdbbec199f36194860c74b6fbeb950">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3a89177065bdbbec199f36194860c74b6fbeb950">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/NTIRE/Post_FRESCO_Fast_Radiometric_Egocentric_Screen_Compensation_CVPRW_2019_paper.html">FRESCO: Fast Radiometric Egocentric Screen Compensation</a></th>
                    </tr>
                
                    <tr id="26382b23c3cf177040a8bcc908d639d49524d6f3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26382b23c3cf177040a8bcc908d639d49524d6f3">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Biometrics/Raja_Subsurface_and_Layer_Intertwined_Template_Protection_Using_Inherent_Properties_of_CVPRW_2019_paper.html">Subsurface and Layer Intertwined Template Protection Using Inherent Properties of Full-Field Optical Coherence Tomography Fingerprint Imaging</a></th>
                    </tr>
                
                    <tr id="f26d39ad3dee51f93abae38b2d2ef550ffda1bce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f26d39ad3dee51f93abae38b2d2ef550ffda1bce">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CVMI/Jiao_Multi-Object_Portion_Tracking_in_4D_Fluorescence_Microscopy_Imagery_With_Deep_CVPRW_2019_paper.html">Multi-Object Portion Tracking in 4D Fluorescence Microscopy Imagery With Deep Feature Maps</a></th>
                    </tr>
                
                    <tr id="6df884dbabac338df0f927e9762110f0a8c27e1e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6df884dbabac338df0f927e9762110f0a8c27e1e">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Shedligeri_Live_Demonstration_Joint_Estimation_of_Optical_Flow_and_Intensity_Image_CVPRW_2019_paper.html">Live Demonstration: Joint Estimation of Optical Flow and Intensity Image From Event Sensors</a></th>
                    </tr>
                
                    <tr id="bfcf748509c2d2ba2ca3d305b450c08930754241">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bfcf748509c2d2ba2ca3d305b450c08930754241">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/EventVision/Yang_Live_Demonstration_Real-Time_Vi-SLAM_With_High-Resolution_Event_Camera_CVPRW_2019_paper.html">Live Demonstration: Real-Time Vi-SLAM With High-Resolution Event Camera</a></th>
                    </tr>
                
                    <tr id="c4e7701bb59e075fcaf850305da6cd4773d9b8ed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c4e7701bb59e075fcaf850305da6cd4773d9b8ed">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Deep_Vision_Workshop/Daya_SANE_Towards_Improved_Prediction_Robustness_via_Stochastically_Activated_Network_Ensembles_CVPRW_2019_paper.html">SANE: Towards Improved Prediction Robustness via Stochastically Activated Network Ensembles</a></th>
                    </tr>
                
                    <tr id="e8a80c981a1f5ace33687e0e1bfc91f97c35e54e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e8a80c981a1f5ace33687e0e1bfc91f97c35e54e">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Explainable_AI/Lee_Interpretation_of_Deep_CNN_Recognition_with_Filter_Space_Clustering_in_CVPRW_2019_paper.html">Interpretation of Deep CNN Recognition with Filter Space Clustering in Feature Extraction and Reconstruction</a></th>
                    </tr>
                
                    <tr id="6c0e3b3e8820a2bb4c72e8a23601d9e3598dadb0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c0e3b3e8820a2bb4c72e8a23601d9e3598dadb0">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Ebrahimi_Uncertainty-Guided_Continual_Learning_in_Bayesian_Neural_Networks_-_Extended_Abstract_CVPRW_2019_paper.html">Uncertainty-Guided Continual Learning in Bayesian Neural Networks - Extended Abstract</a></th>
                    </tr>
                
                    <tr id="c8f0c15207ef4236755b869f2b06234c9b2e41a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c8f0c15207ef4236755b869f2b06234c9b2e41a5">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Shrivastava_Learning_Conditional_Error_Model_for_Simulated_Time-Series_Data_CVPRW_2019_paper.html">Learning Conditional Error Model for Simulated Time-Series Data</a></th>
                    </tr>
                
                    <tr id="f2fe1a2e9d99d937387d2fda0842c29281ec978c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f2fe1a2e9d99d937387d2fda0842c29281ec978c">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Uncertainty_and_Robustness_in_Deep_Visual_Learning/Daya_SANE_Exploring_Adversarial_Robustness_With_Stochastically_Activated_Network_Ensembles_CVPRW_2019_paper.html">SANE: Exploring Adversarial Robustness With Stochastically Activated Network Ensembles</a></th>
                    </tr>
                
                    <tr id="9b9a2f1adb3dcb8f7fac774523e1b7ce537723a7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9b9a2f1adb3dcb8f7fac774523e1b7ce537723a7">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/LowPower_Image_Recognition_Challenge/Heath_Are_You_Paying_Attention_Classifying_Attention_in_Pivotal_Response_Treatment_CVPRW_2019_paper.html">Are You Paying Attention? Classifying Attention in Pivotal Response Treatment Videos</a></th>
                    </tr>
                
                    <tr id="ec64238ab45836fd4e34040326d3ef008e07dcd6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ec64238ab45836fd4e34040326d3ef008e07dcd6">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/LowPower_Image_Recognition_Challenge/Goncharenko_Winning_Solution_on_LPIRC-ll_Competition_CVPRW_2019_paper.html">Winning Solution on LPIRC-ll Competition</a></th>
                    </tr>
                
                    <tr id="8367db470280bd66a65a162fbbf7fa71821ee095">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8367db470280bd66a65a162fbbf7fa71821ee095">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Face_and_Gesture_Analysis_for_Health_Informatics/Xiang_Beyond_Deep_Feature_Averaging_Sampling_Videos_Towards_Practical_Facial_Pain_CVPRW_2019_paper.html">Beyond Deep Feature Averaging: Sampling Videos Towards Practical Facial Pain Recognition</a></th>
                    </tr>
                
                    <tr id="f513d43e346648846990339476fddd385527d1d5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f513d43e346648846990339476fddd385527d1d5">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/SUMO/Wang_Efficient_Plane-Based_Optimization_of_Geometry_and_Texture_for_Indoor_RGB-D_CVPRW_2019_paper.html">Efficient Plane-Based Optimization of Geometry and Texture for Indoor RGB-D Reconstruction</a></th>
                    </tr>
                
                    <tr id="e01b2a92912db8d44fe58eac236cc417addce6f3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e01b2a92912db8d44fe58eac236cc417addce6f3">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_Meets_Cognition_Camera_Ready/Pan_Visual_Similarity_from_Optimizing_Feature_and_Memory_On_A_Hypersphere_CVPRW_2019_paper.html">Visual Similarity from Optimizing Feature and Memory On A Hypersphere</a></th>
                    </tr>
                
                    <tr id="f73fdb956aee88cef429e12ea4fa0807b4c8ded7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f73fdb956aee88cef429e12ea4fa0807b4c8ded7">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Vision_Meets_Cognition_Camera_Ready/Takmaz_Learning_Feature_Representations_for_Look-Alike_Images_CVPRW_2019_paper.html">Learning Feature Representations for Look-Alike Images</a></th>
                    </tr>
                
                    <tr id="c2bd8421d496ff7ab0776fa7aa0c1613f9bf0a6b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c2bd8421d496ff7ab0776fa7aa0c1613f9bf0a6b">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Image_Matching_Local_Features_and_Beyond/Farhan_Boosting_Local_Matches_with_Convolutional_Co-Segmentation_CVPRW_2019_paper.html">Boosting Local Matches with Convolutional Co-Segmentation</a></th>
                    </tr>
                
                    <tr id="37f1329b748f0bcdfb5724f0a6b2d7d0c181b1b6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/37f1329b748f0bcdfb5724f0a6b2d7d0c181b1b6">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Image_Matching_Local_Features_and_Beyond/Ha_An_End-to-end_Deep_Convolutional_Neural_Network_for_a_Multi-scale_Image_CVPRW_2019_paper.html">An End-to-end Deep Convolutional Neural Network for a Multi-scale Image Matching and Localization Problem</a></th>
                    </tr>
                
                    <tr id="42d8d6c2d175d1fcf6a863729ac2044ea74d018e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/42d8d6c2d175d1fcf6a863729ac2044ea74d018e">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/Sight_and_Sound/German_Parisi_A_Neurorobotic_Experiment_for_Crossmodal_Conflict_Resolution_CVPRW_2019_paper.html">A Neurorobotic Experiment for Crossmodal Conflict Resolution</a></th>
                    </tr>
                
                    <tr id="27cea3e4b1546fe6f743f96bbbf53ea77802d378">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/27cea3e4b1546fe6f743f96bbbf53ea77802d378">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/3DWidDGET/Yu_Semi-supervised_Three-dimensional_Reconstruction_Framework_with_Generative_Adversarial_Networks_CVPRW_2019_paper.html">Semi-supervised Three-dimensional Reconstruction Framework with Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="75e30579b0c784ac6cf3b38246bad42f222b2294">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/75e30579b0c784ac6cf3b38246bad42f222b2294">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Eghbali_Discriminative_Quantization_for_Fast_Similarity_Search_CVPRW_2019_paper.html">Discriminative Quantization for Fast Similarity Search</a></th>
                    </tr>
                
                    <tr id="4febc3c81240f7e532768251e3dcecf2eada91d1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4febc3c81240f7e532768251e3dcecf2eada91d1">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Chen_Learning_Patterns_of_Latent_Residual_for_Improving_Video_Compression_CVPRW_2019_paper.html">Learning Patterns of Latent Residual for Improving Video Compression</a></th>
                    </tr>
                
                    <tr id="457994ceaab9ee91f4cfca0e988d6dc6e9be6aaa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/457994ceaab9ee91f4cfca0e988d6dc6e9be6aaa">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Jianhua_An_Image_Coder_With_CNN_Optimizations_CVPRW_2019_paper.html">An Image Coder With CNN Optimizations</a></th>
                    </tr>
                
                    <tr id="6269ac83d5f0ae6d1e4094c609801f78828bb6b6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6269ac83d5f0ae6d1e4094c609801f78828bb6b6">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Wang_RDO-based_Secondary_Prediction_Scheme_for_Image_Compression_CVPRW_2019_paper.html">RDO-based Secondary Prediction Scheme for Image Compression</a></th>
                    </tr>
                
                    <tr id="8470141280f1ac3a7fded450193d0215e21decfb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8470141280f1ac3a7fded450193d0215e21decfb">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Wang_Joint_learned_and_traditional_image_compression_for_transparent_coding_CVPRW_2019_paper.html">Joint learned and traditional image compression for transparent coding</a></th>
                    </tr>
                
                    <tr id="fa6fd378afa03360238df29cd6a9523ef11b2fb7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fa6fd378afa03360238df29cd6a9523ef11b2fb7">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/CLIC_2019/Chang_Description_of_Challenge_Proposal_by_NCTU_An_Autoencoder-based_Image_Compressor_CVPRW_2019_paper.html">Description of Challenge Proposal by NCTU: An Autoencoder-based Image Compressor with Principle Component Analysis and Soft-Bit Rate Estimation</a></th>
                    </tr>
                
                    <tr id="bf08621db183f80b0363e87103abdc060bad4ab4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bf08621db183f80b0363e87103abdc060bad4ab4">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/../content_CVPRW_2019/html/DOAI/Lippoldt_Window_Detection_in_Facades_for_Aerial_Texture_Files_of_3D_CVPRW_2019_paper.html">Window Detection in Facades for Aerial Texture Files of 3D CityGML Models</a></th>
                    </tr>
                

                </tbody>
            </table>
        </div>
    </section>

</main>

<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"
        integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.min.js"
        integrity="sha384-+sLIOodYLS7CIrQpBjl+C7nPvqq+FbNUBDunl/OZv93DB7Ln/533i8e/mZXLi/P+"
        crossorigin="anonymous"></script>

</body>
</html>
