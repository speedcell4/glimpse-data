{
  "https://aclanthology.org/2022.emnlp-main.1": {
    "title": "Generative Knowledge Graph Construction: A Review",
    "volume": "main",
    "abstract": "Generative Knowledge Graph Construction (KGC) refers to those methods that leverage the sequence-to-sequence framework for building knowledge graphs, which is flexible and can be adapted to widespread tasks. In this study, we summarize the recent compelling progress in generative knowledge graph construction. We present the advantages and weaknesses of each paradigm in terms of different generation targets and provide theoretical insight and empirical analysis. Based on the review, we suggest promising research directions for the future. Our contributions are threefold: (1) We present a detailed, complete taxonomy for the generative KGC methods; (2) We provide a theoretical and empirical analysis of the generative KGC methods; (3) We propose several research directions that can be developed in the future",
    "checked": true,
    "id": "4993af5937aa4074072d802a656e833a08bbeca5",
    "semantic_title": "generative knowledge graph construction: a review",
    "citation_count": 50,
    "authors": [
      "Hongbin Ye",
      "Ningyu Zhang",
      "Hui Chen",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.2": {
    "title": "CDConv: A Benchmark for Contradiction Detection in Chinese Conversations",
    "volume": "main",
    "abstract": "Dialogue contradiction is a critical issue in open-domain dialogue systems. The contextualization nature of conversations makes dialogue contradiction detection rather challenging. In this work, we propose a benchmark for Contradiction Detection in Chinese Conversations, namely CDConv. It contains 12K multi-turn conversations annotated with three typical contradiction categories: Intra-sentence Contradiction, Role Confusion, and History Contradiction. To efficiently construct the CDConv conversations, we devise a series of methods for automatic conversation generation, which simulate common user behaviors that trigger chatbots to make contradictions. We conduct careful manual quality screening of the constructed conversations and show that state-of-the-art Chinese chatbots can be easily goaded into making contradictions. Experiments on CDConv show that properly modeling contextual information is critical for dialogue contradiction detection, but there are still unresolved challenges that require future research",
    "checked": true,
    "id": "577682d6df0da548dfb58d93dfd623b973bdf34a",
    "semantic_title": "cdconv: a benchmark for contradiction detection in chinese conversations",
    "citation_count": 12,
    "authors": [
      "Chujie Zheng",
      "Jinfeng Zhou",
      "Yinhe Zheng",
      "Libiao Peng",
      "Zhen Guo",
      "Wenquan Wu",
      "Zheng-Yu Niu",
      "Hua Wu",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.3": {
    "title": "Transformer Feed-Forward Layers Build Predictions by Promoting Concepts in the Vocabulary Space",
    "volume": "main",
    "abstract": "Transformer-based language models (LMs) are at the core of modern NLP, but their internal prediction construction process is opaque and largely not understood. In this work, we make a substantial step towards unveiling this underlying prediction process, by reverse-engineering the operation of the feed-forward network (FFN) layers, one of the building blocks of transformer models. We view the token representation as a changing distribution over the vocabulary, and the output from each FFN layer as an additive update to that distribution. Then, we analyze the FFN updates in the vocabulary space, showing that each update can be decomposed to sub-updates corresponding to single FFN parameter vectors, each promoting concepts that are often human-interpretable. We then leverage these findings for controlling LM predictions, where we reduce the toxicity of GPT2 by almost 50%, and for improving computation efficiency with a simple early exit rule, saving 20% of computation on average",
    "checked": true,
    "id": "cf36236015c9f93f15bfafbf282f69e08bdc9c16",
    "semantic_title": "transformer feed-forward layers build predictions by promoting concepts in the vocabulary space",
    "citation_count": 211,
    "authors": [
      "Mor Geva",
      "Avi Caciularu",
      "Kevin Wang",
      "Yoav Goldberg"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.4": {
    "title": "Learning to Generate Question by Asking Question: A Primal-Dual Approach with Uncommon Word Generation",
    "volume": "main",
    "abstract": "Automatic question generation (AQG) is the task of generating a question from a given passage and an answer. Most existing AQG methods aim at encoding the passage and the answer to generate the question. However, limited work has focused on modeling the correlation between the target answer and the generated question. Moreover, unseen or rare word generation has not been studied in previous works. In this paper, we propose a novel approach which incorporates question generation with its dual problem, question answering, into a unified primal-dual framework. Specifically, the question generation component consists of an encoder that jointly encodes the answer with the passage, and a decoder that produces the question. The question answering component then re-asks the generated question on the passage to ensure that the target answer is obtained. We further introduce a knowledge distillation module to improve the model generalization ability. We conduct an extensive set of experiments on SQuAD and HotpotQA benchmarks. Experimental results demonstrate the superior performance of the proposed approach over several state-of-the-art methods",
    "checked": true,
    "id": "cf4570cd3976da8424dd93d29f47f30098b0c186",
    "semantic_title": "learning to generate question by asking question: a primal-dual approach with uncommon word generation",
    "citation_count": 6,
    "authors": [
      "Qifan Wang",
      "Li Yang",
      "Xiaojun Quan",
      "Fuli Feng",
      "Dongfang Liu",
      "Zenglin Xu",
      "Sinong Wang",
      "Hao Ma"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.5": {
    "title": "Graph-based Model Generation for Few-Shot Relation Extraction",
    "volume": "main",
    "abstract": "Few-shot relation extraction (FSRE) has been a challenging problem since it only has a handful of training instances. Existing models follow a ‘one-for-all' scheme where one general large model performs all individual N-way-K-shot tasks in FSRE, which prevents the model from achieving the optimal point on each task. In view of this, we propose a model generation framework that consists of one general model for all tasks and many tiny task-specific models for each individual task. The general model generates and passes the universal knowledge to the tiny models which will be further fine-tuned when performing specific tasks. In this way, we decouple the complexity of the entire task space from that of all individual tasks while absorbing the universal knowledge.Extensive experimental results on two public datasets demonstrate that our framework reaches a new state-of-the-art performance for FRSE tasks. Our code is available at: https://github.com/NLPWM-WHU/GM_GEN",
    "checked": true,
    "id": "2576ac446b828b229262bd09d10ac2c19f498f9d",
    "semantic_title": "graph-based model generation for few-shot relation extraction",
    "citation_count": 10,
    "authors": [
      "Wanli Li",
      "Tieyun Qian"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.6": {
    "title": "Backdoor Attacks in Federated Learning by Rare Embeddings and Gradient Ensembling",
    "volume": "main",
    "abstract": "Recent advances in federated learning have demonstrated its promising capability to learn on decentralized datasets. However, a considerable amount of work has raised concerns due to the potential risks of adversaries participating in the framework to poison the global model for an adversarial purpose. This paper investigates the feasibility of model poisoning for backdoor attacks through rare word embeddings of NLP models. In text classification, less than 1% of adversary clients suffices to manipulate the model output without any drop in the performance of clean sentences. For a less complex dataset, a mere 0.1% of adversary clients is enough to poison the global model effectively. We also propose a technique specialized in the federated learning scheme called gradient ensemble, which enhances the backdoor performance in all experimental settings",
    "checked": true,
    "id": "2b8d483b94cceefe10d804579f09891ddb53f836",
    "semantic_title": "backdoor attacks in federated learning by rare embeddings and gradient ensembling",
    "citation_count": 10,
    "authors": [
      "Ki Yoon Yoo",
      "Nojun Kwak"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.7": {
    "title": "Generating Natural Language Proofs with Verifier-Guided Search",
    "volume": "main",
    "abstract": "Reasoning over natural language is a challenging problem in NLP. In this work, we focus on proof generation: Given a hypothesis and a set of supporting facts, the model generates a proof tree indicating how to derive the hypothesis from supporting facts. Compared to generating the entire proof in one shot, stepwise generation can better exploit the compositionality and generalize to longer proofs but has achieved limited success on real-world data. Existing stepwise methods struggle to generate proof steps that are both logically valid and relevant to the hypothesis. Instead, they tend to hallucinate invalid steps given the hypothesis. In this paper, we present a novel stepwise method, NLProofS (Natural Language Proof Search), which learns to generate relevant steps conditioning on the hypothesis. At the core of our approach, we train an independent verifier to check the validity of the proof steps to prevent hallucination. Instead of generating steps greedily, we search for proofs maximizing a global proof score judged by the verifier. NLProofS achieves state-of-the-art performance on EntailmentBank and RuleTaker. Specifically, it improves the correctness of predicted proofs from 27.7% to 33.3% in the distractor setting of EntailmentBank, demonstrating the effectiveness of NLProofS in generating challenging human-authored proofs",
    "checked": true,
    "id": "196cc546041cb6db167784f632037f0a1dcf4a79",
    "semantic_title": "generating natural language proofs with verifier-guided search",
    "citation_count": 51,
    "authors": [
      "Kaiyu Yang",
      "Jia Deng",
      "Danqi Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.8": {
    "title": "Toward Unifying Text Segmentation and Long Document Summarization",
    "volume": "main",
    "abstract": "Text segmentation is important for signaling a document's structure. Without segmenting a long document into topically coherent sections, it is difficult for readers to comprehend the text, let alone find important information. The problem is only exacerbated by a lack of segmentation in transcripts of audio/video recordings. In this paper, we explore the role that section segmentation plays in extractive summarization of written and spoken documents. Our approach learns robust sentence representations by performing summarization and segmentation simultaneously, which is further enhanced by an optimization-based regularizer to promote selection of diverse summary sentences. We conduct experiments on multiple datasets ranging from scientific articles to spoken transcripts to evaluate the model's performance. Our findings suggest that the model can not only achieve state-of-the-art performance on publicly available benchmarks, but demonstrate better cross-genre transferability when equipped with text segmentation. We perform a series of analyses to quantify the impact of section segmentation on summarizing written and spoken documents of substantial length and complexity",
    "checked": true,
    "id": "3bcea238b0c323d8f891829714bbe6e8a3de894c",
    "semantic_title": "toward unifying text segmentation and long document summarization",
    "citation_count": 20,
    "authors": [
      "Sangwoo Cho",
      "Kaiqiang Song",
      "Xiaoyang Wang",
      "Fei Liu",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.9": {
    "title": "The Geometry of Multilingual Language Model Representations",
    "volume": "main",
    "abstract": "We assess how multilingual language models maintain a shared multilingual representation space while still encoding language-sensitive information in each language. Using XLM-R as a case study, we show that languages occupy similar linear subspaces after mean-centering, evaluated based on causal effects on language modeling performance and direct comparisons between subspaces for 88 languages. The subspace means differ along language-sensitive axes that are relatively stable throughout middle layers, and these axes encode information such as token vocabularies. Shifting representations by language means is sufficient to induce token predictions in different languages. However, we also identify stable language-neutral axes that encode information such as token positions and part-of-speech. We visualize representations projected onto language-sensitive and language-neutral axes, identifying language family and part-of-speech clusters, along with spirals, toruses, and curves representing token position information. These results demonstrate that multilingual language models encode information along orthogonal language-sensitive and language-neutral axes, allowing the models to extract a variety of features for downstream tasks and cross-lingual transfer learning",
    "checked": true,
    "id": "24a4657b614a4a3037bf045cc1ded0548771c148",
    "semantic_title": "the geometry of multilingual language model representations",
    "citation_count": 40,
    "authors": [
      "Tyler Chang",
      "Zhuowen Tu",
      "Benjamin Bergen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.10": {
    "title": "Improving Complex Knowledge Base Question Answering via Question-to-Action and Question-to-Question Alignment",
    "volume": "main",
    "abstract": "Complex knowledge base question answering can be achieved by converting questions into sequences of predefined actions. However, there is a significant semantic and structural gap between natural language and action sequences, which makes this conversion difficult. In this paper, we introduce an alignment-enhanced complex question answering framework, called ALCQA, which mitigates this gap through question-to-action alignment and question-to-question alignment. We train a question rewriting model to align the question and each action, and utilize a pretrained language model to implicitly align the question and KG artifacts. Moreover, considering that similar questions correspond to similar action sequences, we retrieve top-k similar question-answer pairs at the inference stage through question-to-question alignment and propose a novel reward-guided action sequence selection strategy to select from candidate action sequences. We conduct experiments on CQA and WQSP datasets, and the results show that our approach outperforms state-of-the-art methods and obtains a 9.88% improvements in the F1 metric on CQA dataset. Our source code is available at https://github.com/TTTTTTTTy/ALCQA",
    "checked": true,
    "id": "313e22afb1e33af6f950e2f2cb3671555aa1e3d8",
    "semantic_title": "improving complex knowledge base question answering via question-to-action and question-to-question alignment",
    "citation_count": 4,
    "authors": [
      "Yechun Tang",
      "Xiaoxia Cheng",
      "Weiming Lu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.11": {
    "title": "PAIR: Prompt-Aware margIn Ranking for Counselor Reflection Scoring in Motivational Interviewing",
    "volume": "main",
    "abstract": "Counselor reflection is a core verbal skill used by mental health counselors to express understanding and affirmation of the client's experience and concerns. In this paper, we propose a system for the analysis of counselor reflections. Specifically, our system takes as input one dialog turn containing a client prompt and a counselor response, and outputs a score indicating the level of reflection in the counselor response. We compile a dataset consisting of different levels of reflective listening skills, and propose the Prompt-Aware margIn Ranking (PAIR) framework that contrasts positive and negative prompt and response pairs using specially designed multi-gap and prompt-aware margin ranking losses. Through empirical evaluations and deployment of our system in a real-life educational environment, we show that our analysis model outperforms several baselines on different metrics, and can be used to provide useful feedback to counseling trainees",
    "checked": true,
    "id": "56a8004bd689939e80493d1409aee7261345e808",
    "semantic_title": "pair: prompt-aware margin ranking for counselor reflection scoring in motivational interviewing",
    "citation_count": 12,
    "authors": [
      "Do June Min",
      "Verónica Pérez-Rosas",
      "Kenneth Resnicow",
      "Rada Mihalcea"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.12": {
    "title": "Co-guiding Net: Achieving Mutual Guidances between Multiple Intent Detection and Slot Filling via Heterogeneous Semantics-Label Graphs",
    "volume": "main",
    "abstract": "Recent graph-based models for joint multiple intent detection and slot filling have obtained promising results through modeling the guidance from the prediction of intents to the decoding of slot filling.However, existing methods (1) only model the unidirectional guidance from intent to slot; (2) adopt homogeneous graphs to model the interactions between the slot semantics nodes and intent label nodes, which limit the performance.In this paper, we propose a novel model termed Co-guiding Net, which implements a two-stage framework achieving the mutual guidances between the two tasks.In the first stage, the initial estimated labels of both tasks are produced, and then they are leveraged in the second stage to model the mutual guidances.Specifically, we propose two heterogeneous graph attention networks working on the proposed two heterogeneous semantics-label graphs, which effectively represent the relations among the semantics nodes and label nodes.Experiment results show that our model outperforms existing models by a large margin, obtaining a relative improvement of 19.3% over the previous best model on MixATIS dataset in overall accuracy",
    "checked": true,
    "id": "b3aec6ba3bba8183230db45ea5ddfec7685900a0",
    "semantic_title": "co-guiding net: achieving mutual guidances between multiple intent detection and slot filling via heterogeneous semantics-label graphs",
    "citation_count": 27,
    "authors": [
      "Bowen Xing",
      "Ivor Tsang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.13": {
    "title": "The Importance of Being Parameters: An Intra-Distillation Method for Serious Gains",
    "volume": "main",
    "abstract": "Recent model pruning methods have demonstrated the ability to remove redundant parameters without sacrificing model performance. Common methods remove redundant parameters according to the parameter sensitivity, a gradient-based measure reflecting the contribution of the parameters. In this paper, however, we argue that redundant parameters can be trained to make beneficial contributions. We first highlight the large sensitivity (contribution) gap among high-sensitivity and low-sensitivity parameters and show that the model generalization performance can be significantly improved after balancing the contribution of all parameters. Our goal is to balance the sensitivity of all parameters and encourage all of them to contribute equally. We propose a general task-agnostic method, namely intra-distillation, appended to the regular training loss to balance parameter sensitivity. Moreover, we also design a novel adaptive learning method to control the strength of intra-distillation loss for faster convergence. Our experiments show the strong effectiveness of our methods on machine translation, natural language understanding, and zero-shot cross-lingual transfer across up to 48 languages, e.g., a gain of 3.54 BLEU on average across 8 language pairs from the IWSLT'14 dataset",
    "checked": true,
    "id": "190b53f18d238f56a5164ee152431afc2fd142c3",
    "semantic_title": "the importance of being parameters: an intra-distillation method for serious gains",
    "citation_count": 4,
    "authors": [
      "Haoran Xu",
      "Philipp Koehn",
      "Kenton Murray"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.14": {
    "title": "Interpreting Language Models with Contrastive Explanations",
    "volume": "main",
    "abstract": "Model interpretability methods are often used to explain NLP model decisions on tasks such as text classification, where the output space is relatively small. However, when applied to language generation, where the output space often consists of tens of thousands of tokens, these methods are unable to provide informative explanations. Language models must consider various features to predict a token, such as its part of speech, number, tense, or semantics.Existing explanation methods conflate evidence for all these features into a single explanation, which is less interpretable for human understanding.To disentangle the different decisions in language modeling, we focus on explaining language models contrastively: we look for salient input tokens that explain why the model predicted one token instead of another. We demonstrate that contrastive explanations are quantifiably better than non-contrastive explanations in verifying major grammatical phenomena, and that they significantly improve contrastive model simulatability for human observers. We also identify groups of contrastive decisions where the model uses similar evidence, and we are able to characterize what input tokens models use during various language generation decisions",
    "checked": true,
    "id": "1ec16018e9152c50bbaed1d49c3077b9fb6d2838",
    "semantic_title": "interpreting language models with contrastive explanations",
    "citation_count": 52,
    "authors": [
      "Kayo Yin",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.15": {
    "title": "RankGen: Improving Text Generation with Large Ranking Models",
    "volume": "main",
    "abstract": "Given an input sequence (or prefix), modern language models often assign high probabilities to output sequences that are repetitive, incoherent, or irrelevant to the prefix; as such, model-generated text also contains such artifacts. To address these issues we present RankGen, a 1.2B parameter encoder model for English that scores model generations given a prefix. RankGen can be flexibly incorporated as a scoring function in beam search and used to decode from any pretrained language model. We train RankGen using large-scale contrastive learning to map a prefix close to the ground-truth sequence that follows it and far away from two types of negatives: (1) random sequences from the same document as the prefix, and (2) sequences generated from a large language model conditioned on the prefix. Experiments across four different language models (345M-11B parameters) and two domains show that RankGen significantly outperforms decoding algorithms like nucleus, top-k, and typical sampling on both automatic metrics (85.0 vs 77.3 MAUVE) as well as human evaluations with English writers (74.5% human preference over nucleus sampling). Analysis reveals that RankGen outputs are more relevant to the prefix and improve continuity and coherence compared to baselines. We release our model checkpoints, code, and human preference data with explanations to facilitate future research",
    "checked": true,
    "id": "23447f473cd240494b0a20ea008038aaef7e3391",
    "semantic_title": "rankgen: improving text generation with large ranking models",
    "citation_count": 59,
    "authors": [
      "Kalpesh Krishna",
      "Yapei Chang",
      "John Wieting",
      "Mohit Iyyer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.16": {
    "title": "Learning a Grammar Inducer from Massive Uncurated Instructional Videos",
    "volume": "main",
    "abstract": "Video-aided grammar induction aims to leverage video information for finding more accurate syntactic grammars for accompanying text. While previous work focuses on building systems for inducing grammars on text that are well-aligned with video content, we investigate the scenario, in which text and video are only in loose correspondence. Such data can be found in abundance online, and the weak correspondence is similar to the indeterminacy problem studied in language acquisition. Furthermore, we build a new model that can better learn video-span correlation without manually designed features adopted by previous work. Experiments show that our model trained only on large-scale YouTube data with no text-video alignment reports strong and robust performances across three unseen datasets, despite domain shift and noisy label issues. Furthermore our model yields higher F1 scores than the previous state-of-the-art systems trained on in-domain data",
    "checked": true,
    "id": "633cc9f824aafdf4f3c1c51fc4957a44a4936cc1",
    "semantic_title": "learning a grammar inducer from massive uncurated instructional videos",
    "citation_count": 3,
    "authors": [
      "Songyang Zhang",
      "Linfeng Song",
      "Lifeng Jin",
      "Haitao Mi",
      "Kun Xu",
      "Dong Yu",
      "Jiebo Luo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.17": {
    "title": "Normalized Contrastive Learning for Text-Video Retrieval",
    "volume": "main",
    "abstract": "Cross-modal contrastive learning has led the recent advances in multimodal retrieval with its simplicity and effectiveness. In this work, however, we reveal that cross-modal contrastive learning suffers from incorrect normalization of the sum retrieval probabilities of each text or video instance. Specifically, we show that many test instances are either over- or under-represented during retrieval, significantly hurting the retrieval performance. To address this problem, we propose Normalized Contrastive Learning (NCL) which utilizes the Sinkhorn-Knopp algorithm to compute the instance-wise biases that properly normalize the sum retrieval probabilities of each instance so that every text and video instance is fairly represented during cross-modal retrieval. Empirical study shows that NCL brings consistent and significant gains in text-video retrieval on different model architectures, with new state-of-the-art multimodal retrieval metrics on the ActivityNet, MSVD, and MSR-VTT datasets without any architecture engineering",
    "checked": true,
    "id": "d6fa5acf4aa2ccee622504c3925d164f8b72f825",
    "semantic_title": "normalized contrastive learning for text-video retrieval",
    "citation_count": 7,
    "authors": [
      "Yookoon Park",
      "Mahmoud Azab",
      "Seungwhan Moon",
      "Bo Xiong",
      "Florian Metze",
      "Gourab Kundu",
      "Kirmani Ahmed"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.18": {
    "title": "Estimating Soft Labels for Out-of-Domain Intent Detection",
    "volume": "main",
    "abstract": "Out-of-Domain (OOD) intent detection is important for practical dialog systems. To alleviate the issue of lacking OOD training samples, some works propose synthesizing pseudo OOD samples and directly assigning one-hot OOD labels to these pseudo samples. However, these one-hot labels introduce noises to the training process because some \"hard\" pseudo OOD samples may coincide with In-Domain (IND) intents. In this paper, we propose an adaptive soft pseudo labeling (ASoul) method that can estimate soft labels for pseudo OOD samples when training OOD detectors. Semantic connections between pseudo OOD samples and IND intents are captured using an embedding graph. A co-training framework is further introduced to produce resulting soft labels following the smoothness assumption, i.e., close samples are likely to have similar labels. Extensive experiments on three benchmark datasets show that ASoul consistently improves the OOD detection performance and outperforms various competitive baselines",
    "checked": true,
    "id": "fa8d5b09c405416d6343261739ecb3862cac0d6b",
    "semantic_title": "estimating soft labels for out-of-domain intent detection",
    "citation_count": 13,
    "authors": [
      "Hao Lang",
      "Yinhe Zheng",
      "Jian Sun",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.19": {
    "title": "Multi-VQG: Generating Engaging Questions for Multiple Images",
    "volume": "main",
    "abstract": "Generating engaging content has drawn much recent attention in the NLP community. Asking questions is a natural way to respond to photos and promote awareness. However, most answers to questions in traditional question-answering (QA) datasets are factoids, which reduce individuals' willingness to answer. Furthermore, traditional visual question generation (VQG) confines the source data for question generation to single images, resulting in a limited ability to comprehend time-series information of the underlying event. In this paper, we propose generating engaging questions from multiple images. We present MVQG, a new dataset, and establish a series of baselines, including both end-to-end and dual-stage architectures. Results show that building stories behind the image sequence enables models togenerate engaging questions, which confirms our assumption that people typically construct a picture of the event in their minds before asking questions. These results open up an exciting challenge for visual-and-language models to implicitly construct a story behind a series of photos to allow for creativity and experience sharing and hence draw attention to downstream applications",
    "checked": true,
    "id": "90a54e732da2dab5bf0873d8bec1a742b2160d48",
    "semantic_title": "multi-vqg: generating engaging questions for multiple images",
    "citation_count": 2,
    "authors": [
      "Min-Hsuan Yeh",
      "Vincent Chen",
      "Ting-Hao Huang",
      "Lun-Wei Ku"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.20": {
    "title": "Tomayto, Tomahto. Beyond Token-level Answer Equivalence for Question Answering Evaluation",
    "volume": "main",
    "abstract": "The predictions of question answering (QA) systems are typically evaluated against manually annotated finite sets of one or more answers. This leads to a coverage limitation that results in underestimating the true performance of systems, and is typically addressed by extending over exact match (EM) with predefined rules or with the token-level F1 measure.In this paper, we present the first systematic conceptual and data-driven analysis to examine the shortcomings of token-level equivalence measures.To this end, we define the asymmetric notion of answer equivalence (AE), accepting answers that are equivalent to or improve over the reference, and publish over 23k human judgements for candidates produced by multiple QA systems on SQuAD.Through a careful analysis of this data, we reveal and quantify several concrete limitations of the F1 measure, such as a false impression of graduality, or missing dependence on the question.Since collecting AE annotations for each evaluated model is expensive, we learn a BERT matching (BEM) measure to approximate this task. Being a simpler task than QA, we find BEM to provide significantly better AE approximations than F1, and to more accurately reflect the performance of systems.Finally, we demonstrate the practical utility of AE and BEM on the concrete application of minimal accurate prediction sets, reducing the number of required answers by up to X2.6",
    "checked": true,
    "id": "8324cc3fb32246f57d18ea8f81eaeae50de60079",
    "semantic_title": "tomayto, tomahto. beyond token-level answer equivalence for question answering evaluation",
    "citation_count": 34,
    "authors": [
      "Jannis Bulian",
      "Christian Buck",
      "Wojciech Gajewski",
      "Benjamin Börschinger",
      "Tal Schuster"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.21": {
    "title": "Non-Parametric Domain Adaptation for End-to-End Speech Translation",
    "volume": "main",
    "abstract": "The end-to-end speech translation (E2E-ST) has received increasing attention due to the potential of its less error propagation, lower latency and fewer parameters. However, the effectiveness of neural-based approaches to this task is severely limited by the available training corpus, especially for domain adaptation where in-domain triplet data is scarce or nonexistent. In this paper, we propose a novel non-parametric method that leverages in-domain text translation corpus to achieve domain adaptation for E2E-ST systems. To this end, we first incorporate an additional encoder into the pre-trained E2E-ST model to realize text translation modeling, based on which the decoder's output representations for text and speech translation tasks are unified by reducing the correspondent representation mismatch in available triplet training data. During domain adaptation, a k-nearest-neighbor (kNN) classifier is introduced to produce the final translation distribution using the external datastore built by the domain-specific text translation corpus, while the universal output representation is adopted to perform a similarity search. Experiments on the Europarl-ST benchmark demonstrate that when in-domain text translation data is involved only, our proposed approach significantly improves baseline by 12.82 BLEU on average in all translation directions, even outperforming the strong in-domain fine-tuning strategy",
    "checked": true,
    "id": "e03fbb4c3ef5203ad12dc659707423fd95b78f16",
    "semantic_title": "non-parametric domain adaptation for end-to-end speech translation",
    "citation_count": 15,
    "authors": [
      "Yichao Du",
      "Weizhi Wang",
      "Zhirui Zhang",
      "Boxing Chen",
      "Tong Xu",
      "Jun Xie",
      "Enhong Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.22": {
    "title": "Prompting for Multimodal Hateful Meme Classification",
    "volume": "main",
    "abstract": "Hateful meme classification is a challenging multimodal task that requires complex reasoning and contextual background knowledge. Ideally, we could leverage an explicit external knowledge base to supplement contextual and cultural information in hateful memes. However, there is no known explicit external knowledge base that could provide such hate speech contextual information. To address this gap, we propose PromptHate, a simple yet effective prompt-based model that prompts pre-trained language models (PLMs) for hateful meme classification. Specifically, we construct simple prompts and provide a few in-context examples to exploit the implicit knowledge in the pre-trained RoBERTa language model for hateful meme classification. We conduct extensive experiments on two publicly available hateful and offensive meme datasets. Our experiment results show that PromptHate is able to achieve a high AUC of 90.96, outperforming state-of-the-art baselines on the hateful meme classification task. We also perform fine-grain analyses and case studies on various prompt settings and demonstrate the effectiveness of the prompts on hateful meme classification",
    "checked": true,
    "id": "ae766548699f27e669932de14e1c0f47b2828536",
    "semantic_title": "prompting for multimodal hateful meme classification",
    "citation_count": 47,
    "authors": [
      "Rui Cao",
      "Roy Ka-Wei Lee",
      "Wen-Haw Chong",
      "Jing Jiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.23": {
    "title": "Certified Error Control of Candidate Set Pruning for Two-Stage Relevance Ranking",
    "volume": "main",
    "abstract": "In information retrieval (IR), candidate set pruning has been commonly used to speed up two-stage relevance ranking. However, such an approach lacks accurate error control and often trades accuracy against computational efficiency in an empirical fashion, missing theoretical guarantees. In this paper, we propose the concept of certified error control of candidate set pruning for relevance ranking, which means that the test error after pruning is guaranteed to be controlled under a user-specified threshold with high probability. Both in-domain and out-of-domain experiments show that our method successfully prunes the first-stage retrieved candidate sets to improve the second-stage reranking speed while satisfying the pre-specified accuracy constraints in both settings. For example, on MS MARCO Passage v1, our method reduces the average candidate set size from 1000 to 27, increasing reranking speed by about 37 times, while keeping MRR@10 greater than a pre-specified value of 0.38 with about 90% empirical coverage. In contrast, empirical baselines fail to meet such requirements. Code and data are available at: https://github.com/alexlimh/CEC-Ranking",
    "checked": true,
    "id": "0c430ea48e37ff43d3ab373ea1441468aa923653",
    "semantic_title": "certified error control of candidate set pruning for two-stage relevance ranking",
    "citation_count": 5,
    "authors": [
      "Minghan Li",
      "Xinyu Zhang",
      "Ji Xin",
      "Hongyang Zhang",
      "Jimmy Lin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.24": {
    "title": "Linearizing Transformer with Key-Value Memory",
    "volume": "main",
    "abstract": "Efficient transformer variants with linear time complexity have been developed to mitigate the quadratic computational overhead of the vanilla transformer. Among them are low-rank projection methods such as Linformer and kernel-based Transformers. Despite their unique merits, they usually suffer from a performance drop comparing with the vanilla transformer on many sequence generation tasks, and often fail to obtain computation gain when the generation is short. We propose Memsizer, an approach towards closing the performance gap while improving the efficiency even with short generation. It projects the source sequences into lower dimension representations like Linformer, while enjoying efficient recurrent-style incremental computation similar to kernel-based transformers. This yields linear computation time and constant memory complexity at inference time. Memsizer also employs a lightweight multi-head mechanism which renders the computation as light as a single-head model. We demonstrate that Memsizer provides an improved balance between efficiency and accuracy over the vanilla transformer and other efficient transformer variants in three typical sequence generation tasks, including machine translation, abstractive text summarization, and language modeling",
    "checked": true,
    "id": "e2ee883fca5f8f32a1dfa2dc06c742d57f2c38b9",
    "semantic_title": "linearizing transformer with key-value memory",
    "citation_count": 4,
    "authors": [
      "Yizhe Zhang",
      "Deng Cai"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.25": {
    "title": "Robustness of Fusion-based Multimodal Classifiers to Cross-Modal Content Dilutions",
    "volume": "main",
    "abstract": "As multimodal learning finds applications in a wide variety of high-stakes societal tasks, investigating their robustness becomes important. Existing work has focused on understanding the robustness of vision-and-language models to imperceptible variations on benchmark tasks. In this work, we investigate the robustness of multimodal classifiers to cross-modal dilutions – a plausible variation. We develop a model that, given a multimodal (image + text) input, generates additional dilution text that (a) maintains relevance and topical coherence with the image and existing text, and (b) when added to the original text, leads to misclassification of the multimodal input. Via experiments on Crisis Humanitarianism and Sentiment Detection tasks, we find that the performance of task-specific fusion-based multimodal classifiers drops by 23.3% and 22.5%, respectively, in the presence of dilutions generated by our model. Metric-based comparisons with several baselines and human evaluations indicate that our dilutions show higher relevance and topical coherence, while simultaneously being more effective at demonstrating the brittleness of the multimodal classifiers. Our work aims to highlight and encourage further research on the robustness of deep multimodal models to realistic variations, especially in human-facing societal applications",
    "checked": true,
    "id": "cafb98bf7b40acd5e9599120b151aa24594cb90e",
    "semantic_title": "robustness of fusion-based multimodal classifiers to cross-modal content dilutions",
    "citation_count": 6,
    "authors": [
      "Gaurav Verma",
      "Vishwa Vinay",
      "Ryan Rossi",
      "Srijan Kumar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.26": {
    "title": "Translation between Molecules and Natural Language",
    "volume": "main",
    "abstract": "We present MolT5 - a self-supervised learning framework for pretraining models on a vast amount of unlabeled natural language text and molecule strings. MolT5 allows for new, useful, and challenging analogs of traditional vision-language tasks, such as molecule captioning and text-based de novo molecule generation (altogether: translation between molecules and language), which we explore for the first time. Since MolT5 pretrains models on single-modal data, it helps overcome the chemistry domain shortcoming of data scarcity. Furthermore, we consider several metrics, including a new cross-modal embedding-based metric, to evaluate the tasks of molecule captioning and text-based molecule generation. Our results show that MolT5-based models are able to generate outputs, both molecules and captions, which in many cases are high quality",
    "checked": true,
    "id": "3b9b1aba877ecd3f7e508cbc78a41b623349902b",
    "semantic_title": "translation between molecules and natural language",
    "citation_count": 102,
    "authors": [
      "Carl Edwards",
      "Tuan Lai",
      "Kevin Ros",
      "Garrett Honke",
      "Kyunghyun Cho",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.27": {
    "title": "What Makes Instruction Learning Hard? An Investigation and a New Challenge in a Synthetic Environment",
    "volume": "main",
    "abstract": "The instruction learning paradigm—where a model learns to perform new tasks from task descriptions alone—has become popular in research on general-purpose models. The capabilities of large transformer models as instruction learners, however, remain poorly understood. We use a controlled synthetic environment to characterize such capabilities. Specifically, we use the task of deciding whether a given string matches a regular expression (viewed as an instruction) to identify properties of tasks, instructions, and instances that make instruction learning challenging. For instance, we find that our model, a fine-tuned T5-based text2text transformer, struggles with large regular languages, suggesting that less precise instructions are challenging for models. Instruction executions that require tracking longer contexts of prior steps are also difficult. We use our findings to systematically construct a challenging instruction learning dataset, which we call Hard RegSet. Fine-tuning on Hard RegSet, our large transformer learns to correctly interpret (with at least 90% accuracy) only 65.6% of test instructions, and 11%-24% of the instructions in out-of-distribution generalization settings. We thus propose Hard RegSet as a challenging instruction learning dataset, and a controlled environment for studying instruction learning",
    "checked": true,
    "id": "cb16b85891172572cd856142880b503db0c2bc61",
    "semantic_title": "what makes instruction learning hard? an investigation and a new challenge in a synthetic environment",
    "citation_count": 11,
    "authors": [
      "Matthew Finlayson",
      "Kyle Richardson",
      "Ashish Sabharwal",
      "Peter Clark"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.28": {
    "title": "Sentence-Incremental Neural Coreference Resolution",
    "volume": "main",
    "abstract": "We propose a sentence-incremental neural coreference resolution system which incrementally builds clusters after marking mention boundaries in a shift-reduce method. The system is aimed at bridging two recent approaches at coreference resolution: (1) state-of-the-art non-incremental models that incur quadratic complexity in document length with high computational cost, and (2) memory network-based models which operate incrementally but do not generalize beyond pronouns. For comparison, we simulate an incremental setting by constraining non-incremental systems to form partial coreference chains before observing new sentences. In this setting, our system outperforms comparable state-of-the-art methods by 2 F1 on OntoNotes and 6.8 F1 on the CODI-CRAC 2021 corpus. In a conventional coreference setup, our system achieves 76.3 F1 on OntoNotes and 45.5 F1 on CODI-CRAC 2021, which is comparable to state-of-the-art baselines. We also analyze variations of our system and show that the degree of incrementality in the encoder has a surprisingly large effect on the resulting performance",
    "checked": true,
    "id": "29648751743f0b44d85096ac22358eaaf25c24c9",
    "semantic_title": "sentence-incremental neural coreference resolution",
    "citation_count": 3,
    "authors": [
      "Matt Grenander",
      "Shay B. Cohen",
      "Mark Steedman"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.29": {
    "title": "SNaC: Coherence Error Detection for Narrative Summarization",
    "volume": "main",
    "abstract": "Progress in summarizing long texts is inhibited by the lack of appropriate evaluation frameworks. A long summary that appropriately covers the facets of that text must also present a coherent narrative, but current automatic and human evaluation methods fail to identify gaps in coherence. In this work, we introduce SNaC, a narrative coherence evaluation framework for fine-grained annotations of long summaries. We develop a taxonomy of coherence errors in generated narrative summaries and collect span-level annotations for 6.6k sentences across 150 book and movie summaries. Our work provides the first characterization of coherence errors generated by state-of-the-art summarization models and a protocol for eliciting coherence judgments from crowdworkers. Furthermore, we show that the collected annotations allow us to benchmark past work in coherence modeling and train a strong classifier for automatically localizing coherence errors in generated summaries. Finally, our SNaC framework can support future work in long document summarization and coherence evaluation, including improved summarization modeling and post-hoc summary correction",
    "checked": true,
    "id": "37cef4df24447b012f0671f0baabe6b9ffe38bf2",
    "semantic_title": "snac: coherence error detection for narrative summarization",
    "citation_count": 25,
    "authors": [
      "Tanya Goyal",
      "Junyi Jessy Li",
      "Greg Durrett"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.30": {
    "title": "HydraSum: Disentangling Style Features in Text Summarization with Multi-Decoder Models",
    "volume": "main",
    "abstract": "Summarization systems make numerous \"decisions\" about summary properties during inference, e.g. degree of copying, specificity and length of outputs, etc. However, these are implicitly encoded within model parameters and specific styles cannot be enforced. To address this, we introduce HydraSum, a new summarization architecture that extends the single decoder framework of current models to a mixture-of-experts version with multiple decoders. We show that HydraSum's multiple decoders automatically learn contrasting summary styles when trained under the standard training objective without any extra supervision. Through experiments on three summarization datasets (CNN, Newsroom and XSum), we show that HydraSum provides a simple mechanism to obtain stylistically-diverse summaries by sampling from either individual decoders or their mixtures, outperforming baseline models. Finally, we demonstrate that a small modification to the gating strategy during training can enforce an even stricter style partitioning, e.g. high- vs low-abstractiveness or high- vs low-specificity, allowing users to sample from a larger area in the generation space and vary summary styles along multiple dimensions",
    "checked": true,
    "id": "6e5316847e9278980de79539e2ff417016566fd2",
    "semantic_title": "hydrasum: disentangling style features in text summarization with multi-decoder models",
    "citation_count": 9,
    "authors": [
      "Tanya Goyal",
      "Nazneen Rajani",
      "Wenhao Liu",
      "Wojciech Kryscinski"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.31": {
    "title": "A Good Neighbor, A Found Treasure: Mining Treasured Neighbors for Knowledge Graph Entity Typing",
    "volume": "main",
    "abstract": "The task of knowledge graph entity typing (KGET) aims to infer the missing types for entities in knowledge graphs. Some pioneering work has proved that neighbor information is very important for the task. However, existing methods only leverage the one-hop neighbor information of the central entity, ignoring the multi-hop neighbor information that can provide valuable clues for inference. Besides, we also observe that there are co-occurrence relations between types, which is very helpful to alleviate false-negative problem. In this paper, we propose a novel method called Mining Treasured Neighbors (MiNer) to make use of these two characteristics. Firstly, we devise a Neighbor Information Aggregation module to aggregate the neighbor information. Then, we propose an Entity Type Inference module to mitigate the adverse impact of the irrelevant neighbor information. Finally, a Type Co-occurrence Regularization module is designed to prevent the model from overfitting the false negative examples caused by missing types. Experimental results on two widely used datasets indicate that our approach significantly outperforms previous state-of-the-art methods",
    "checked": true,
    "id": "f99f62ae81fd3ae0d9e2327f8c71ac172dbfec0e",
    "semantic_title": "a good neighbor, a found treasure: mining treasured neighbors for knowledge graph entity typing",
    "citation_count": 5,
    "authors": [
      "Zhuoran Jin",
      "Pengfei Cao",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.32": {
    "title": "Guiding Neural Entity Alignment with Compatibility",
    "volume": "main",
    "abstract": "Entity Alignment (EA) aims to find equivalent entities between two Knowledge Graphs (KGs). While numerous neural EA models have been devised, they are mainly learned using labelled data only. In this work, we argue that different entities within one KG should have compatible counterparts in the other KG due to the potential dependencies among the entities. Making compatible predictions thus should be one of the goals of training an EA model along with fitting the labelled data: this aspect however is neglected in current methods. To power neural EA models with compatibility, we devise a training framework by addressing three problems: (1) how to measure the compatibility of an EA model; (2) how to inject the property of being compatible into an EA model; (3) how to optimise parameters of the compatibility model. Extensive experiments on widely-used datasets demonstrate the advantages of integrating compatibility within EA models. In fact, state-of-the-art neural EA models trained within our framework using just 5% of the labelled data can achieve comparable effectiveness with supervised training using 20% of the labelled data",
    "checked": true,
    "id": "269099ac594f0149bae7b8b6403ad5a8c6e3a054",
    "semantic_title": "guiding neural entity alignment with compatibility",
    "citation_count": 2,
    "authors": [
      "Bing Liu",
      "Harrisen Scells",
      "Wen Hua",
      "Guido Zuccon",
      "Genghong Zhao",
      "Xia Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.33": {
    "title": "InstructDial: Improving Zero and Few-shot Generalization in Dialogue through Instruction Tuning",
    "volume": "main",
    "abstract": "Instruction tuning is an emergent paradigm in NLP wherein natural language instructions are leveraged with language models to induce zero-shot performance on unseen tasks. Dialogue is an especially interesting area in which to explore instruction tuning because dialogue systems perform multiple kinds of tasks related to language (e.g., natural language understanding and generation, domain-specific interaction), yet instruction tuning has not been systematically explored for dialogue-related tasks. We introduce InstructDial, an instruction tuning framework for dialogue, which consists of a repository of 48 diverse dialogue tasks in a unified text-to-text format created from 59 openly available dialogue datasets. We explore cross-task generalization ability on models tuned on InstructDial across diverse dialogue tasks. Our analysis reveals that InstructDial enables good zero-shot performance on unseen datasets and tasks such as dialogue evaluation and intent detection, and even better performance in a few-shot setting. To ensure that models adhere to instructions, we introduce novel meta-tasks. We establish benchmark zero-shot and few-shot performance of models trained using the proposed framework on multiple dialogue tasks",
    "checked": true,
    "id": "8f926c0c3f1557a9241b7e75609082a1f207a75e",
    "semantic_title": "instructdial: improving zero and few-shot generalization in dialogue through instruction tuning",
    "citation_count": 33,
    "authors": [
      "Prakhar Gupta",
      "Cathy Jiao",
      "Yi-Ting Yeh",
      "Shikib Mehri",
      "Maxine Eskenazi",
      "Jeffrey Bigham"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.34": {
    "title": "Unsupervised Boundary-Aware Language Model Pretraining for Chinese Sequence Labeling",
    "volume": "main",
    "abstract": "Boundary information is critical for various Chinese language processing tasks, such as word segmentation, part-of-speech tagging, and named entity recognition. Previous studies usually resorted to the use of a high-quality external lexicon, where lexicon items can offer explicit boundary information. However, to ensure the quality of the lexicon, great human effort is always necessary, which has been generally ignored. In this work, we suggest unsupervised statistical boundary information instead, and propose an architecture to encode the information directly into pre-trained language models, resulting in Boundary-Aware BERT (BABERT). We apply BABERT for feature induction of Chinese sequence labeling tasks. Experimental results on ten benchmarks of Chinese sequence labeling demonstrate that BABERT can provide consistent improvements on all datasets. In addition, our method can complement previous supervised lexicon exploration, where further improvements can be achieved when integrated with external lexicon information",
    "checked": true,
    "id": "beb40cc99a6ab931aa8ea1758c1a0397ecd32847",
    "semantic_title": "unsupervised boundary-aware language model pretraining for chinese sequence labeling",
    "citation_count": 4,
    "authors": [
      "Peijie Jiang",
      "Dingkun Long",
      "Yanzhao Zhang",
      "Pengjun Xie",
      "Meishan Zhang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.35": {
    "title": "RetroMAE: Pre-Training Retrieval-oriented Language Models Via Masked Auto-Encoder",
    "volume": "main",
    "abstract": "Despite pre-training's progress in many important NLP tasks, it remains to explore effective pre-training strategies for dense retrieval. In this paper, we propose RetroMAE, a new retrieval oriented pre-training paradigm based on Masked Auto-Encoder (MAE). RetroMAE is highlighted by three critical designs. 1) A novel MAE workflow, where the input sentence is polluted for encoder and decoder with different masks. The sentence embedding is generated from the encoder's masked input; then, the original sentence is recovered based on the sentence embedding and the decoder's masked input via masked language modeling. 2) Asymmetric model structure, with a full-scale BERT like transformer as encoder, and a one-layer transformer as decoder. 3) Asymmetric masking ratios, with a moderate ratio for encoder: 15 30%, and an aggressive ratio for decoder: 50 70%. Our framework is simple to realize and empirically competitive: the pre-trained models dramatically improve the SOTA performances on a wide range of dense retrieval benchmarks, like BEIR and MS MARCO. The source code and pre-trained models are made publicly available at https://github.com/staoxiao/RetroMAE so as to inspire more interesting research",
    "checked": true,
    "id": "103ffc0879fbed73e7a51b52268fb6744fe0c284",
    "semantic_title": "retromae: pre-training retrieval-oriented language models via masked auto-encoder",
    "citation_count": 59,
    "authors": [
      "Shitao Xiao",
      "Zheng Liu",
      "Yingxia Shao",
      "Zhao Cao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.36": {
    "title": "Aligning Recommendation and Conversation via Dual Imitation",
    "volume": "main",
    "abstract": "Human conversations of recommendation naturally involve the shift of interests which can align the recommendation actions and conversation process to make accurate recommendations with rich explanations. However, existing conversational recommendation systems (CRS) ignore the advantage of user interest shift in connecting recommendation and conversation, which leads to an ineffective loose coupling structure of CRS. To address this issue, by modeling the recommendation actions as recommendation paths in a knowledge graph (KG), we propose DICR (Dual Imitation for Conversational Recommendation), which designs a dual imitation to explicitly align the recommendation paths and user interest shift paths in a recommendation module and a conversation module, respectively. By exchanging alignment signals, DICR achieves bidirectional promotion between recommendation and conversation modules and generates high-quality responses with accurate recommendations and coherent explanations. Experiments demonstrate that DICR outperforms the state-of-the-art models on recommendation and conversation performance with automatic, human, and novel explainability metrics",
    "checked": true,
    "id": "5b1a4ad14662be9e48e3b4cf67a4b43adbe9eee1",
    "semantic_title": "aligning recommendation and conversation via dual imitation",
    "citation_count": 6,
    "authors": [
      "Jinfeng Zhou",
      "Bo Wang",
      "Minlie Huang",
      "Dongming Zhao",
      "Kun Huang",
      "Ruifang He",
      "Yuexian Hou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.37": {
    "title": "QRelScore: Better Evaluating Generated Questions with Deeper Understanding of Context-aware Relevance",
    "volume": "main",
    "abstract": "Existing metrics for assessing question generation not only require costly human reference but also fail to take into account the input context of generation, rendering the lack of deep understanding of the relevance between the generated questions and input contexts. As a result, they may wrongly penalize a legitimate and reasonable candidate question when it (1) involves complicated reasoning with the context or (2) can be grounded by multiple evidences in the context.In this paper, we propose QRelScore, a context-aware Relevance evaluation metric for Question Generation.Based on off-the-shelf language models such as BERT and GPT2, QRelScore employs both word-level hierarchical matching and sentence-level prompt-based generation to cope with the complicated reasoning and diverse generation from multiple evidences, respectively.Compared with existing metrics, our experiments demonstrate that QRelScore is able to achieve a higher correlation with human judgments while being much more robust to adversarial samples",
    "checked": true,
    "id": "e6f44759d5d03d7018319d507ee5ac19485596a5",
    "semantic_title": "qrelscore: better evaluating generated questions with deeper understanding of context-aware relevance",
    "citation_count": 8,
    "authors": [
      "Xiaoqiang Wang",
      "Bang Liu",
      "Siliang Tang",
      "Lingfei Wu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.38": {
    "title": "Abstract Visual Reasoning with Tangram Shapes",
    "volume": "main",
    "abstract": "We introduce KiloGram, a resource for studying abstract visual reasoning in humans and machines. Drawing on the history of tangram puzzles as stimuli in cognitive science, we build a richly annotated dataset that, with >1k distinct stimuli, is orders of magnitude larger and more diverse than prior resources. It is both visually and linguistically richer, moving beyond whole shape descriptions to include segmentation maps and part labels. We use this resource to evaluate the abstract visual reasoning capacities of recent multi-modal models. We observe that pre-trained weights demonstrate limited abstract reasoning, which dramatically improves with fine-tuning. We also observe that explicitly describing parts aids abstract reasoning for both humans and models, especially when jointly encoding the linguistic and visual inputs",
    "checked": true,
    "id": "cdef738dd79364d7f12ccad4eef0f38e2d37dd1c",
    "semantic_title": "abstract visual reasoning with tangram shapes",
    "citation_count": 25,
    "authors": [
      "Anya Ji",
      "Noriyuki Kojima",
      "Noah Rush",
      "Alane Suhr",
      "Wai Keen Vong",
      "Robert Hawkins",
      "Yoav Artzi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.39": {
    "title": "UnifiedSKG: Unifying and Multi-Tasking Structured Knowledge Grounding with Text-to-Text Language Models",
    "volume": "main",
    "abstract": "Structured knowledge grounding (SKG) leverages structured knowledge to complete user requests, such as semantic parsing over databases and question answering over knowledge bases. Since the inputs and outputs of SKG tasks are heterogeneous, they have been studied separately by different communities, which limits systematic and compatible research on SKG. In this paper, we overcome this limitation by proposing the UnifiedSKG framework, which unifies 21 SKG tasks into a text-to-text format, aiming to promote systematic SKG research, instead of being exclusive to a single task, domain, or dataset. We use UnifiedSKG to benchmark T5 with different sizes and show that T5, with simple modifications when necessary, achieves state-of-the-art performance on almost all of the 21 tasks. We further demonstrate that multi-task prefix-tuning improves the performance on most tasks, largely improving the overall performance. UnifiedSKG also facilitates the investigation of zero-shot and few-shot learning, and we show that T0, GPT-3, and Codex struggle in zero-shot and few-shot learning for SKG. We also use UnifiedSKG to conduct a series of controlled experiments on structured knowledge encoding variants across SKG tasks. UnifiedSKG is easily extensible to more tasks, and it is open-sourced at https://github.com/hkunlp/unifiedskg",
    "checked": true,
    "id": "79950179d60ba39a74d5fe2aedc47a57c0bf4c03",
    "semantic_title": "unifiedskg: unifying and multi-tasking structured knowledge grounding with text-to-text language models",
    "citation_count": 253,
    "authors": [
      "Tianbao Xie",
      "Chen Henry Wu",
      "Peng Shi",
      "Ruiqi Zhong",
      "Torsten Scholak",
      "Michihiro Yasunaga",
      "Chien-Sheng Wu",
      "Ming Zhong",
      "Pengcheng Yin",
      "Sida I. Wang",
      "Victor Zhong",
      "Bailin Wang",
      "Chengzu Li",
      "Connor Boyle",
      "Ansong Ni",
      "Ziyu Yao",
      "Dragomir Radev",
      "Caiming Xiong",
      "Lingpeng Kong",
      "Rui Zhang",
      "Noah A. Smith",
      "Luke Zettlemoyer",
      "Tao Yu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.40": {
    "title": "Balanced Adversarial Training: Balancing Tradeoffs between Fickleness and Obstinacy in NLP Models",
    "volume": "main",
    "abstract": "Traditional (fickle) adversarial examples involve finding a small perturbation that does not change an input's true label but confuses the classifier into outputting a different prediction. Conversely, obstinate adversarial examples occur when an adversary finds a small perturbation that preserves the classifier's prediction but changes the true label of an input.Adversarial training and certified robust training have shown some effectiveness in improving the robustness of machine learnt models to fickle adversarial examples. We show that standard adversarial training methods focused on reducing vulnerability to fickle adversarial examples may make a model more vulnerable to obstinate adversarial examples, with experiments for both natural language inference and paraphrase identification tasks. To counter this phenomenon, we introduce Balanced Adversarial Training, which incorporates contrastive learning to increase robustness against both fickle and obstinate adversarial examples",
    "checked": true,
    "id": "5f0d93bc4aa4d93e3ec34c3111eace23548225df",
    "semantic_title": "balanced adversarial training: balancing tradeoffs between fickleness and obstinacy in nlp models",
    "citation_count": 2,
    "authors": [
      "Hannah Chen",
      "Yangfeng Ji",
      "David Evans"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.41": {
    "title": "When Can Transformers Ground and Compose: Insights from Compositional Generalization Benchmarks",
    "volume": "main",
    "abstract": "Humans can reason compositionally whilst grounding language utterances to the real world. Recent benchmarks like ReaSCAN (Wu et al., 2021) use navigation tasks grounded in a grid world to assess whether neural models exhibit similar capabilities. In this work, we present a simple transformer-based model that outperforms specialized architectures on ReaSCAN and a modified version (Qiu et al., 2021) of gSCAN (Ruis et al., 2020). On analyzing the task, we find that identifying the target location in the grid world is the main challenge for the models. Furthermore, we show that a particular split in ReaSCAN, which tests depth generalization, is unfair. On an amended version of this split, we show that transformers can generalize to deeper input structures. Finally, we design a simpler grounded compositional generalization task, RefEx, to investigate how transformers reason compositionally. We show that a single self-attention layer with a single head generalizes to novel combinations of object attributes. Moreover, we derive a precise mathematical construction of the transformer's computations from the learned network. Overall, we provide valuable insights about the grounded compositional generalization task and the behaviour of transformers on it, which would be useful for researchers working in this area",
    "checked": true,
    "id": "dae5c4660dab4c2b0a0be586f8537db980925d4a",
    "semantic_title": "when can transformers ground and compose: insights from compositional generalization benchmarks",
    "citation_count": 9,
    "authors": [
      "Ankur Sikarwar",
      "Arkil Patel",
      "Navin Goyal"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.42": {
    "title": "Generative Language Models for Paragraph-Level Question Generation",
    "volume": "main",
    "abstract": "Powerful generative models have led to recent progress in question generation (QG). However, it is difficult to measure advances in QG research since there are no standardized resources that allow a uniform comparison among approaches. In this paper, we introduce QG-Bench, a multilingual and multidomain benchmark for QG that unifies existing question answering datasets by converting them to a standard QG setting. It includes general-purpose datasets such as SQuAD for English, datasets from ten domains and two styles, as well as datasets in eight different languages. Using QG-Bench as a reference, we perform an extensive analysis of the capabilities of language models for the task. First, we propose robust QG baselines based on fine-tuning generative language models. Then, we complement automatic evaluation based on standard metrics with an extensive manual evaluation, which in turn sheds light on the difficulty of evaluating QG models. Finally, we analyse both the domain adaptability of these models as well as the effectiveness of multilingual models in languages other than English.QG-Bench is released along with the fine-tuned models presented in the paper (https://github.com/asahi417/lm-question-generation), which are also available as a demo (https://autoqg.net/)",
    "checked": true,
    "id": "ec0ef1cd3d177e3f13598a74753e62a64dfb7527",
    "semantic_title": "generative language models for paragraph-level question generation",
    "citation_count": 30,
    "authors": [
      "Asahi Ushio",
      "Fernando Alva-Manchego",
      "Jose Camacho-Collados"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.43": {
    "title": "A Unified Encoder-Decoder Framework with Entity Memory",
    "volume": "main",
    "abstract": "Entities, as important carriers of real-world knowledge, play a key role in many NLP tasks.We focus on incorporating entity knowledge into an encoder-decoder framework for informative text generation. Existing approaches tried to index, retrieve, and read external documents as evidence, but they suffered from a large computational overhead. In this work, we propose an encoder-decoder framework with an entity memory, namely EDMem. The entity knowledge is stored in the memory as latent representations, and the memory is pre-trained on Wikipedia along with encoder-decoder parameters. To precisely generate entity names, we design three decoding methods to constrain entity generation by linking entities in the memory. EDMem is a unified framework that can be used on various entity-intensive question answering and generation tasks. Extensive experimental results show that EDMem outperforms both memory-based auto-encoder models and non-memory encoder-decoder models",
    "checked": true,
    "id": "1fa54643f8a43ec7dc70628d960dc8bbd3045884",
    "semantic_title": "a unified encoder-decoder framework with entity memory",
    "citation_count": 11,
    "authors": [
      "Zhihan Zhang",
      "Wenhao Yu",
      "Chenguang Zhu",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.44": {
    "title": "Segmenting Numerical Substitution Ciphers",
    "volume": "main",
    "abstract": "Deciphering historical substitution ciphers is a challenging problem. Example problems that have been previously studied include detecting cipher type, detecting plaintext language, and acquiring the substitution key for segmented ciphers. However, attacking unsegmented ciphers is still a challenging task. Segmentation (i.e. finding substitution units) is essential for cracking those ciphers. In this work, we propose the first automatic methods to segment those ciphers using Byte Pair Encoding (BPE) and unigram language models. Our methods achieve an average segmentation error of 2% on 100 randomly-generated monoalphabetic ciphers and 27% on 3 real historical homophonic ciphers. We also propose a method for solving non-deterministic ciphers with existing keys using a lattice and a pretrained language model. Our method leads to the full solution of the IA cipher; a real historical cipher that has not been fully solved until this work",
    "checked": true,
    "id": "16c9eea3abc67873de0c59ba106f7db92bd36f8c",
    "semantic_title": "segmenting numerical substitution ciphers",
    "citation_count": 1,
    "authors": [
      "Nada Aldarrab",
      "Jonathan May"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.45": {
    "title": "Crossmodal-3600: A Massively Multilingual Multimodal Evaluation Dataset",
    "volume": "main",
    "abstract": "Research in massively multilingual image captioning has been severely hampered by a lack of high-quality evaluation datasets. In this paper we present the Crossmodal-3600 dataset (XM3600 in short), a geographically diverse set of 3600 images annotated with human-generated reference captions in 36 languages. The images were selected from across the world, covering regions where the 36 languages are spoken, and annotated with captions that achieve consistency in terms of style across all languages, while avoiding annotation artifacts due to direct translation. We apply this benchmark to model selection for massively multilingual image captioning models, and show superior correlation results with human evaluations when using XM3600 as golden references for automatic metrics",
    "checked": true,
    "id": "a8260077135246476a0b0601495ef08e56c21a50",
    "semantic_title": "crossmodal-3600: a massively multilingual multimodal evaluation dataset",
    "citation_count": 41,
    "authors": [
      "Ashish V. Thapliyal",
      "Jordi Pont Tuset",
      "Xi Chen",
      "Radu Soricut"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.46": {
    "title": "ReSel: N-ary Relation Extraction from Scientific Text and Tables by Learning to Retrieve and Select",
    "volume": "main",
    "abstract": "We study the problem of extracting N-ary relation tuples from scientific articles. This task is challenging because the target knowledge tuples can reside in multiple parts and modalities of the document. Our proposed method ReSel decomposes this task into a two-stage procedure that first retrieves the most relevant paragraph/table and then selects the target entity from the retrieved component. For the high-level retrieval stage, ReSel designs a simple and effective feature set, which captures multi-level lexical and semantic similarities between the query and components. For the low-level selection stage, ReSel designs a cross-modal entity correlation graph along with a multi-view architecture, which models both semantic and document-structural relations between entities. Our experiments on three scientific information extraction datasets show that ReSel outperforms state-of-the-art baselines significantly",
    "checked": true,
    "id": "5f5cb6a74f6971f022d6c8b3b70146f28b606ad1",
    "semantic_title": "resel: n-ary relation extraction from scientific text and tables by learning to retrieve and select",
    "citation_count": 18,
    "authors": [
      "Yuchen Zhuang",
      "Yinghao Li",
      "Junyang Zhang",
      "Yue Yu",
      "Yingjun Mou",
      "Xiang Chen",
      "Le Song",
      "Chao Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.47": {
    "title": "GammaE: Gamma Embeddings for Logical Queries on Knowledge Graphs",
    "volume": "main",
    "abstract": "Embedding knowledge graphs (KGs) for multi-hop logical reasoning is a challenging problem due to massive and complicated structures in many KGs. Recently, many promising works projected entities and queries into a geometric space to efficiently find answers. However, it remains challenging to model the negation and union operator. The negation operator has no strict boundaries, which generates overlapped embeddings and leads to obtaining ambiguous answers. An additional limitation is that the union operator is non-closure, which undermines the model to handle a series of union operators. To address these problems, we propose a novel probabilistic embedding model, namely Gamma Embeddings (GammaE), for encoding entities and queries to answer different types of FOL queries on KGs. We utilize the linear property and strong boundary support of the Gamma distribution to capture more features of entities and queries, which dramatically reduces model uncertainty. Furthermore, GammaE implements the Gamma mixture method to design the closed union operator. The performance of GammaE is validated on three large logical query datasets. Experimental results show that GammaE significantly outperforms state-of-the-art models on public benchmarks",
    "checked": true,
    "id": "12f7273cdcb8fde49b4c84d16ba41d6c7da55ba5",
    "semantic_title": "gammae: gamma embeddings for logical queries on knowledge graphs",
    "citation_count": 25,
    "authors": [
      "Dong Yang",
      "Peijun Qing",
      "Yang Li",
      "Haonan Lu",
      "Xiaodong Lin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.48": {
    "title": "Reasoning Like Program Executors",
    "volume": "main",
    "abstract": "Reasoning over natural language is a long-standing goal for the research community. However, studies have shown that existing language models are inadequate in reasoning. To address the issue, we present POET, a novel reasoning pre-training paradigm. Through pre-training language models with programs and their execution results, POET empowers language models to harvest the reasoning knowledge possessed by program executors via a data-driven approach. POET is conceptually simple and can be instantiated by different kinds of program executors. In this paper, we showcase two simple instances POET-Math and POET-Logic, in addition to a complex instance, POET-SQL. Experimental results on six benchmarks demonstrate that POET can significantly boost model performance in natural language reasoning, such as numerical reasoning, logical reasoning, and multi-hop reasoning. POET opens a new gate on reasoning-enhancement pre-training, and we hope our analysis would shed light on the future research of reasoning like program executors",
    "checked": true,
    "id": "03488f1a193066b5ea8b9b800e119f07df5c1d9e",
    "semantic_title": "reasoning like program executors",
    "citation_count": 49,
    "authors": [
      "Xinyu Pi",
      "Qian Liu",
      "Bei Chen",
      "Morteza Ziyadi",
      "Zeqi Lin",
      "Qiang Fu",
      "Yan Gao",
      "Jian-Guang Lou",
      "Weizhu Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.49": {
    "title": "SEM-F1: an Automatic Way for Semantic Evaluation of Multi-Narrative Overlap Summaries at Scale",
    "volume": "main",
    "abstract": "Recent work has introduced an important yet relatively under-explored NLP task called Semantic Overlap Summarization (SOS) that entails generating a summary from multiple alternative narratives which conveys the common information provided by those narratives. Previous work also published a benchmark dataset for this task by collecting 2,925 alternative narrative pairs from the web and manually annotating 411 different reference summaries by engaging human annotators. In this paper, we exclusively focus on the automated evaluation of the SOS task using the benchmark dataset. More specifically, we first use the popular ROUGE metric from text-summarization literature and conduct a systematic study to evaluate the SOS task. Our experiments discover that ROUGE is not suitable for this novel task and therefore, we propose a new sentence-level precision-recall style automated evaluation metric, called SEM-F1 (Semantic F1). It is inspired by the benefits of the sentence-wise annotation technique using overlap labels reported by the previous work. Our experiments show that the proposed SEM-F1 metric yields a higher correlation with human judgment and higher inter-rater agreement compared to the ROUGE metric",
    "checked": true,
    "id": "575f4af34c00ca5f92480a7e402e36ee02d87217",
    "semantic_title": "sem-f1: an automatic way for semantic evaluation of multi-narrative overlap summaries at scale",
    "citation_count": 5,
    "authors": [
      "Naman Bansal",
      "Mousumi Akter",
      "Shubhra Kanti Karmaker Santu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.50": {
    "title": "Inducer-tuning: Connecting Prefix-tuning and Adapter-tuning",
    "volume": "main",
    "abstract": "Prefix-tuning, or more generally continuous prompt tuning, has become an essential paradigm of parameter-efficient transfer learning. Using a large pre-trained language model (PLM), prefix-tuning can obtain strong performance by training only a small portion of parameters. In this paper, we propose to understand and further develop prefix-tuning through the kernel lens. Specifically, we make an analogy between prefixes and inducing variables in kernel methods and hypothesize that prefixes serving as inducing variables would improve their overall mechanism. From the kernel estimator perspective, we suggest a new variant of prefix-tuning—inducer-tuning, which shares the exact mechanism as prefix-tuning while leveraging the residual form found in adapter-tuning. This mitigates the initialization issue in prefix-tuning. Through comprehensive empirical experiments on natural language understanding and generation tasks, we demonstrate that inducer-tuning can close the performance gap between prefix-tuning and fine-tuning",
    "checked": true,
    "id": "289700f4570733b612147883ad29b963bbffe31a",
    "semantic_title": "inducer-tuning: connecting prefix-tuning and adapter-tuning",
    "citation_count": 2,
    "authors": [
      "Yifan Chen",
      "Devamanyu Hazarika",
      "Mahdi Namazifar",
      "Yang Liu",
      "Di Jin",
      "Dilek Hakkani-Tur"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.51": {
    "title": "DocInfer: Document-level Natural Language Inference using Optimal Evidence Selection",
    "volume": "main",
    "abstract": "We present DocInfer - a novel, end-to-end Document-level Natural Language Inference model that builds a hierarchical document graph enriched through inter-sentence relations (topical, entity-based, concept-based), performs paragraph pruning using the novel SubGraph Pooling layer, followed by optimal evidence selection based on REINFORCE algorithm to identify the most important context sentences for a given hypothesis. Our evidence selection mechanism allows it to transcend the input length limitation of modern BERT-like Transformer models while presenting the entire evidence together for inferential reasoning. We show this is an important property needed to reason on large documents where the evidence may be fragmented and located arbitrarily far from each other. Extensive experiments on popular corpora - DocNLI, ContractNLI, and ConTRoL datasets, and our new proposed dataset called CaseHoldNLI on the task of legal judicial reasoning, demonstrate significant performance gains of 8-12% over SOTA methods. Our ablation studies validate the impact of our model. Performance improvement of 3-6% on annotation-scarce downstream tasks of fact verification, multiple-choice QA, and contract clause retrieval demonstrates the usefulness of DocInfer beyond primary NLI tasks",
    "checked": true,
    "id": "4430cb7ddb3c4a9860ddabf4f92568a8a03c2b18",
    "semantic_title": "docinfer: document-level natural language inference using optimal evidence selection",
    "citation_count": 7,
    "authors": [
      "Puneet Mathur",
      "Gautam Kunapuli",
      "Riyaz Bhat",
      "Manish Shrivastava",
      "Dinesh Manocha",
      "Maneesh Singh"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.52": {
    "title": "LightEA: A Scalable, Robust, and Interpretable Entity Alignment Framework via Three-view Label Propagation",
    "volume": "main",
    "abstract": "Entity Alignment (EA) aims to find equivalent entity pairs between KGs, which is the core step to bridging and integrating multi-source KGs. In this paper, we argue that existing complex EA methods inevitably inherit the inborn defects from their neural network lineage: poor interpretability and weak scalability. Inspired by recent studies, we reinvent the classical Label Propagation algorithm to effectively run on KGs and propose a neural-free EA framework — LightEA, consisting of three efficient components: (i) Random Orthogonal Label Generation, (ii) Three-view Label Propagation, and (iii) Sparse Sinkhorn Operation.According to the extensive experiments on public datasets, LightEA has impressive scalability, robustness, and interpretability. With a mere tenth of time consumption, LightEA achieves comparable results to state-of-the-art methods across all datasets and even surpasses them on many. Besides, due to the computational process of LightEA being entirely linear, we could trace the propagation process at each step and clearly explain how the entities are aligned",
    "checked": true,
    "id": "c1519ab70e030e038919983b15b1db659cebb935",
    "semantic_title": "lightea: a scalable, robust, and interpretable entity alignment framework via three-view label propagation",
    "citation_count": 19,
    "authors": [
      "Xin Mao",
      "Wenting Wang",
      "Yuanbin Wu",
      "Man Lan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.53": {
    "title": "Metric-guided Distillation: Distilling Knowledge from the Metric to Ranker and Retriever for Generative Commonsense Reasoning",
    "volume": "main",
    "abstract": "Commonsense generation aims to generate a realistic sentence describing a daily scene under the given concepts, which is very challenging, since it requires models to have relational reasoning and compositional generalization capabilities. Previous work focuses on retrieving prototype sentences for the provided concepts to assist generation. They first use a sparse retriever to retrieve candidate sentences, then re-rank the candidates with a ranker. However, the candidates returned by their ranker may not be the most relevant sentences, since the ranker treats all candidates equally without considering their relevance to the reference sentences of the given concepts. Another problem is that re-ranking is very expensive, but only using retrievers will seriously degrade the performance of their generation models. To solve these problems, we propose the metric distillation rule to distill knowledge from the metric (e.g., BLEU) to the ranker. We further transfer the critical knowledge summarized by the distilled ranker to the retriever. In this way, the relevance scores of candidate sentences predicted by the ranker and retriever will be more consistent with their quality measured by the metric. Experimental results on the CommonGen benchmark verify the effectiveness of our proposed method: (1) Our generation model with the distilled ranker achieves a new state-of-the-art result. (2) Our generation model with the distilled retriever even surpasses the previous SOTA",
    "checked": true,
    "id": "7de0d0800fa2046ce74fff0bf60ff63a966e166d",
    "semantic_title": "metric-guided distillation: distilling knowledge from the metric to ranker and retriever for generative commonsense reasoning",
    "citation_count": 10,
    "authors": [
      "Xingwei He",
      "Yeyun Gong",
      "A-Long Jin",
      "Weizhen Qi",
      "Hang Zhang",
      "Jian Jiao",
      "Bartuer Zhou",
      "Biao Cheng",
      "Sm Yiu",
      "Nan Duan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.54": {
    "title": "Efficient Document Retrieval by End-to-End Refining and Quantizing BERT Embedding with Contrastive Product Quantization",
    "volume": "main",
    "abstract": "Efficient document retrieval heavily relies on the technique of semantic hashing, which learns a binary code for every document and employs Hamming distance to evaluate document distances. However, existing semantic hashing methods are mostly established on outdated TFIDF features, which obviously do not contain lots of important semantic information about documents. Furthermore, the Hamming distance can only be equal to one of several integer values, significantly limiting its representational ability for document distances. To address these issues, in this paper, we propose to leverage BERT embeddings to perform efficient retrieval based on the product quantization technique, which will assign for every document a real-valued codeword from the codebook, instead of a binary code as in semantic hashing. Specifically, we first transform the original BERT embeddings via a learnable mapping and feed the transformed embedding into a probabilistic product quantization module to output the assigned codeword. The refining and quantizing modules can be optimized in an end-to-end manner by minimizing the probabilistic contrastive loss. A mutual information maximization based method is further proposed to improve the representativeness of codewords, so that documents can be quantized more accurately. Extensive experiments conducted on three benchmarks demonstrate that our proposed method significantly outperforms current state-of-the-art baselines",
    "checked": true,
    "id": "67229d3394ba916516c8ce12be5e874061588eb6",
    "semantic_title": "efficient document retrieval by end-to-end refining and quantizing bert embedding with contrastive product quantization",
    "citation_count": 3,
    "authors": [
      "Zexuan Qiu",
      "Qinliang Su",
      "Jianxing Yu",
      "Shijing Si"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.55": {
    "title": "Curriculum Knowledge Distillation for Emoji-supervised Cross-lingual Sentiment Analysis",
    "volume": "main",
    "abstract": "Existing sentiment analysis models have achieved great advances with the help of sufficient sentiment annotations. Unfortunately, many languages do not have sufficient sentiment corpus. To this end, recent studies have proposed cross-lingual sentiment analysis to transfer sentiment analysis models from resource-rich languages to low-resource languages. However, these studies either rely on external cross-lingual supervision (e.g., parallel corpora and translation model), or are limited by the cross-lingual gaps. In this work, based on the intuitive assumption that the relationships between emojis and sentiments are consistent across different languages, we investigate transferring sentiment knowledge across languages with the help of emojis. To this end, we propose a novel cross-lingual sentiment analysis approach dubbed Curriculum Knowledge Distiller (CKD). The core idea of CKD is to use emojis to bridge the source and target languages. Note that, compared with texts, emojis are more transferable, but cannot reveal the precise sentiment. Thus, we distill multiple Intermediate Sentiment Classifiers (ISC) on source language corpus with emojis to get ISCs with different attention weights of texts. To transfer them into the target language, we distill ISCs into the Target Language Sentiment Classifier (TSC) following the curriculum learning mechanism. In this way, TSC can learn delicate sentiment knowledge, meanwhile, avoid being affected by cross-lingual gaps. Experimental results on five cross-lingual benchmarks clearly verify the effectiveness of our approach",
    "checked": true,
    "id": "df9064503962fa9dc394003b06f43e9d6523959a",
    "semantic_title": "curriculum knowledge distillation for emoji-supervised cross-lingual sentiment analysis",
    "citation_count": 3,
    "authors": [
      "Jianyang Zhang",
      "Tao Liang",
      "Mingyang Wan",
      "Guowu Yang",
      "Fengmao Lv"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.56": {
    "title": "Correctable-DST: Mitigating Historical Context Mismatch between Training and Inference for Improved Dialogue State Tracking",
    "volume": "main",
    "abstract": "Recently proposed dialogue state tracking (DST) approaches predict the dialogue state of a target turn sequentially based on the previous dialogue state. During the training time, the ground-truth previous dialogue state is utilized as the historical context. However, only the previously predicted dialogue state can be used in inference. This discrepancy might lead to error propagation, i.e., mistakes made by the model in the current turn are likely to be carried over to the following turns.To solve this problem, we propose Correctable Dialogue State Tracking (Correctable-DST). Specifically, it consists of three stages: (1) a Predictive State Simulator is exploited to generate a previously \"predicted\" dialogue state based on the ground-truth previous dialogue state during training; (2) a Slot Detector is proposed to determine the slots with an incorrect value in the previously \"predicted\" state and the slots whose values are to be updated in the current turn; (3) a State Generator takes the name of the above-selected slots as a prompt to generate the current state.Empirical results show that our approach achieves 67.51%, 68.24%, 70.30%, 71.38%, and 81.27% joint goal accuracy on MultiWOZ 2.0-2.4 datasets, respectively, and achieves a new state-of-the-art performance with significant improvements",
    "checked": true,
    "id": "8e64f8ec1360f2061ff10d7ac6020806a3ddcce3",
    "semantic_title": "correctable-dst: mitigating historical context mismatch between training and inference for improved dialogue state tracking",
    "citation_count": 2,
    "authors": [
      "Hongyan Xie",
      "Haoxiang Su",
      "Shuangyong Song",
      "Hao Huang",
      "Bo Zou",
      "Kun Deng",
      "Jianghua Lin",
      "Zhihui Zhang",
      "Xiaodong He"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.57": {
    "title": "DropMix: A Textual Data Augmentation Combining Dropout with Mixup",
    "volume": "main",
    "abstract": "Overfitting is a notorious problem when there is insufficient data to train deep neural networks in machine learning tasks. Data augmentation regularization methods such as Dropout, Mixup, and their enhanced variants are effective and prevalent, and achieve promising performance to overcome overfitting. However, in text learning, most of the existing regularization approaches merely adopt ideas from computer vision without considering the importance of dimensionality in natural language processing. In this paper, we argue that the property is essential to overcome overfitting in text learning. Accordingly, we present a saliency map informed textual data augmentation and regularization framework, which combines Dropout and Mixup, namely DropMix, to mitigate the overfitting problem in text learning. In addition, we design a procedure that drops and patches fine grained shapes of the saliency map under the DropMix framework to enhance regularization. Empirical studies confirm the effectiveness of the proposed approach on 12 text classification tasks",
    "checked": true,
    "id": "e6e3f6476dd6706c78a2a5bdb5102bc26b96de93",
    "semantic_title": "dropmix: a textual data augmentation combining dropout with mixup",
    "citation_count": 5,
    "authors": [
      "Fanshuang Kong",
      "Richong Zhang",
      "Xiaohui Guo",
      "Samuel Mensah",
      "Yongyi Mao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.58": {
    "title": "Cross-document Event Coreference Search: Task, Dataset and Modeling",
    "volume": "main",
    "abstract": "The task of Cross-document Coreference Resolution has been traditionally formulated as requiring to identify all coreference links across a given set of documents. We propose an appealing, and often more applicable, complementary set up for the task – Cross-document Coreference Search, focusing in this paper on event coreference. Concretely, given a mention in context of an event of interest, considered as a query, the task is to find all coreferring mentions for the query event in a large document collection. To support research on this task, we create a corresponding dataset, which is derived from Wikipedia while leveraging annotations in the available Wikipedia Event Coreferecene dataset (WEC-Eng). Observing that the coreference search setup is largely analogous to the setting of Open Domain Question Answering, we adapt the prominent Deep Passage Retrieval (DPR) model to our setting, as an appealing baseline. Finally, we present a novel model that integrates a powerful coreference scoring scheme into the DPR architecture, yielding improved performance",
    "checked": true,
    "id": "f4d587be83b5da1e35592d5662a05398c9e9b720",
    "semantic_title": "cross-document event coreference search: task, dataset and modeling",
    "citation_count": 8,
    "authors": [
      "Alon Eirew",
      "Avi Caciularu",
      "Ido Dagan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.59": {
    "title": "VIRT: Improving Representation-based Text Matching via Virtual Interaction",
    "volume": "main",
    "abstract": "Text matching is a fundamental research problem in natural language understanding. Interaction-based approaches treat the text pair as a single sequence and encode it through cross encoders, while representation-based models encode the text pair independently with siamese or dual encoders. Interaction-based models require dense computations and thus are impractical in real-world applications. Representation-based models have become the mainstream paradigm for efficient text matching. However, these models suffer from severe performance degradation due to the lack of interactions between the pair of texts. To remedy this, we propose a Virtual InteRacTion mechanism (VIRT) for improving representation-based text matching while maintaining its efficiency. In particular, we introduce an interactive knowledge distillation module that is only applied during training. It enables deep interaction between texts by effectively transferring knowledge from the interaction-based model. A light interaction strategy is designed to fully leverage the learned interactive knowledge. Experimental results on six text matching benchmarks demonstrate the superior performance of our method over several state-of-the-art representation-based models. We further show that VIRT can be integrated into existing methods as plugins to lift their performances",
    "checked": true,
    "id": "eb7c9316c7c26220483cb9315058ceb129b5c167",
    "semantic_title": "virt: improving representation-based text matching via virtual interaction",
    "citation_count": 6,
    "authors": [
      "Dan Li",
      "Yang Yang",
      "Hongyin Tang",
      "Jiahao Liu",
      "Qifan Wang",
      "Jingang Wang",
      "Tong Xu",
      "Wei Wu",
      "Enhong Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.60": {
    "title": "MAVEN-ERE: A Unified Large-scale Dataset for Event Coreference, Temporal, Causal, and Subevent Relation Extraction",
    "volume": "main",
    "abstract": "The diverse relationships among real-world events, including coreference, temporal, causal, and subevent relations, are fundamental to understanding natural languages. However, two drawbacks of existing datasets limit event relation extraction (ERE) tasks: (1) Small scale. Due to the annotation complexity, the data scale of existing datasets is limited, which cannot well train and evaluate data-hungry models. (2) Absence of unified annotation. Different types of event relations naturally interact with each other, but existing datasets only cover limited relation types at once, which prevents models from taking full advantage of relation interactions. To address these issues, we construct a unified large-scale human-annotated ERE dataset MAVEN-ERE with improved annotation schemes. It contains 103,193 event coreference chains, 1,216,217 temporal relations, 57,992 causal relations, and 15,841 subevent relations, which is larger than existing datasets of all the ERE tasks by at least an order of magnitude. Experiments show that ERE on MAVEN-ERE is quite challenging, and considering relation interactions with joint learning can improve performances. The dataset and source codes can be obtained from https://github.com/THU-KEG/MAVEN-ERE",
    "checked": true,
    "id": "4b68322883f83fdfaf07344dff47a73b5cee9ce7",
    "semantic_title": "maven-ere: a unified large-scale dataset for event coreference, temporal, causal, and subevent relation extraction",
    "citation_count": 38,
    "authors": [
      "Xiaozhi Wang",
      "Yulin Chen",
      "Ning Ding",
      "Hao Peng",
      "Zimu Wang",
      "Yankai Lin",
      "Xu Han",
      "Lei Hou",
      "Juanzi Li",
      "Zhiyuan Liu",
      "Peng Li",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.61": {
    "title": "Entity Extraction in Low Resource Domains with Selective Pre-training of Large Language Models",
    "volume": "main",
    "abstract": "Transformer-based language models trained on large natural language corpora have been very useful in downstream entity extraction tasks. However, they often result in poor performances when applied to domains that are different from those they are pretrained on. Continued pretraining using unlabeled data from target domains can help improve the performances of these language models on the downstream tasks. However, using all of the available unlabeled data for pretraining can be time-intensive; also, it can be detrimental to the performance of the downstream tasks, if the unlabeled data is not aligned with the data distribution for the target tasks. Previous works employed external supervision in the form of ontologies for selecting appropriate data samples for pretraining, but external supervision can be quite hard to obtain in low-resource domains. In this paper, we introduce effective ways to select data from unlabeled corpora of target domains for language model pretraining to improve the performances in target entity extraction tasks. Our data selection strategies do not require any external supervision. We conduct extensive experiments for the task of named entity recognition (NER) on seven different domains and show that language models pretrained on target domain unlabeled data obtained using our data selection strategies achieve better performances compared to those using data selection strategies in previous works that use external supervision. We also show that these pretrained language models using our data selection strategies outperform those pretrained on all of the available unlabeled target domain data",
    "checked": true,
    "id": "2ee0f11f7df4de9120bcb6520deddf579597a108",
    "semantic_title": "entity extraction in low resource domains with selective pre-training of large language models",
    "citation_count": 0,
    "authors": [
      "Aniruddha Mahapatra",
      "Sharmila Reddy Nangi",
      "Aparna Garimella",
      "Anandhavelu N"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.62": {
    "title": "How Large Language Models are Transforming Machine-Paraphrase Plagiarism",
    "volume": "main",
    "abstract": "The recent success of large language models for text generation poses a severe threat to academic integrity, as plagiarists can generate realistic paraphrases indistinguishable from original work.However, the role of large autoregressive models in generating machine-paraphrased plagiarism and their detection is still incipient in the literature.This work explores T5 and GPT3 for machine-paraphrase generation on scientific articles from arXiv, student theses, and Wikipedia.We evaluate the detection performance of six automated solutions and one commercial plagiarism detection software and perform a human study with 105 participants regarding their detection performance and the quality of generated examples.Our results suggest that large language models can rewrite text humans have difficulty identifying as machine-paraphrased (53% mean acc.).Human experts rate the quality of paraphrases generated by GPT-3 as high as original texts (clarity 4.0/5, fluency 4.2/5, coherence 3.8/5).The best-performing detection model (GPT-3) achieves 66% F1-score in detecting paraphrases.We make our code, data, and findings publicly available to facilitate the development of detection solutions",
    "checked": true,
    "id": "f158e70e9ead719e8a524eaf8ec79270574f2eda",
    "semantic_title": "how large language models are transforming machine-paraphrase plagiarism",
    "citation_count": 24,
    "authors": [
      "Jan Philip Wahle",
      "Terry Ruas",
      "Frederic Kirstein",
      "Bela Gipp"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.63": {
    "title": "M2D2: A Massively Multi-Domain Language Modeling Dataset",
    "volume": "main",
    "abstract": "We present M2D2, a fine-grained, massively multi-domain corpus for studying domain adaptation in language models (LMs). M2D2 consists of 8.5B tokens and spans 145 domains extracted from Wikipedia and Semantic Scholar. Using ontologies derived from Wikipedia and ArXiv categories, we organize the domains in each data source into 22 groups. This two-level hierarchy enables the study of relationships between domains and their effects on in- and out-of-domain performance after adaptation. We also present a number of insights into the nature of effective domain adaptation in LMs, as examples of the new types of studies M2D2 enables. To improve in-domain performance, we show the benefits of adapting the LM along a domain hierarchy; adapting to smaller amounts of fine-grained domain-specific data can lead to larger in-domain performance gains than larger amounts of weakly relevant data. We further demonstrate a trade-off between in-domain specialization and out-of-domain generalization within and across ontologies, as well as a strong correlation between out-of-domain performance and lexical overlap between domains",
    "checked": true,
    "id": "7c3a735c7567b5b54581ba09612db4d18a5dacac",
    "semantic_title": "m2d2: a massively multi-domain language modeling dataset",
    "citation_count": 14,
    "authors": [
      "Machel Reid",
      "Victor Zhong",
      "Suchin Gururangan",
      "Luke Zettlemoyer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.64": {
    "title": "Will You Find These Shortcuts?\" A Protocol for Evaluating the Faithfulness of Input Salience Methods for Text Classification",
    "volume": "main",
    "abstract": "Feature attribution a.k.a. input salience methods which assign an importance score to a feature are abundant but may produce surprisingly different results for the same model on the same input. While differences are expected if disparate definitions of importance are assumed, most methods claim to provide faithful attributions and point at the features most relevant for a model's prediction. Existing work on faithfulness evaluation is not conclusive and does not provide a clear answer as to how different methods are to be compared.Focusing on text classification and the model debugging scenario, our main contribution is a protocol for faithfulness evaluation that makes use of partially synthetic data to obtain ground truth for feature importance ranking. Following the protocol, we do an in-depth analysis of four standard salience method classes on a range of datasets and lexical shortcuts for BERT and LSTM models. We demonstrate that some of the most popular method configurations provide poor results even for simple shortcuts while a method judged to be too simplistic works remarkably well for BERT",
    "checked": true,
    "id": "1818e24137383ece9b2f379a63674b2632e16d04",
    "semantic_title": "will you find these shortcuts?\" a protocol for evaluating the faithfulness of input salience methods for text classification",
    "citation_count": 59,
    "authors": [
      "Jasmijn Bastings",
      "Sebastian Ebert",
      "Polina Zablotskaia",
      "Anders Sandholm",
      "Katja Filippova"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.65": {
    "title": "Information-Transport-based Policy for Simultaneous Translation",
    "volume": "main",
    "abstract": "Simultaneous translation (ST) outputs translation while receiving the source inputs, and hence requires a policy to determine whether to translate a target token or wait for the next source token. The major challenge of ST is that each target token can only be translated based on the current received source tokens, where the received source information will directly affect the translation quality. So naturally, how much source information is received for the translation of the current target token is supposed to be the pivotal evidence for the ST policy to decide between translating and waiting. In this paper, we treat the translation as information transport from source to target and accordingly propose an Information-Transport-based Simultaneous Translation (ITST). ITST quantifies the transported information weight from each source token to the current target token, and then decides whether to translate the target token according to its accumulated received information. Experiments on both text-to-text ST and speech-to-text ST (a.k.a., streaming speech translation) tasks show that ITST outperforms strong baselines and achieves state-of-the-art performance",
    "checked": true,
    "id": "7dc02a2ecbcd2c5f22595b736e2c7a1b35ac9267",
    "semantic_title": "information-transport-based policy for simultaneous translation",
    "citation_count": 36,
    "authors": [
      "Shaolei Zhang",
      "Yang Feng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.66": {
    "title": "Learning to Adapt to Low-Resource Paraphrase Generation",
    "volume": "main",
    "abstract": "Paraphrase generation is a longstanding NLP task and achieves great success with the aid of large corpora. However, transferring a paraphrasing model to another domain encounters the problem of domain shifting especially when the data is sparse. At the same time, widely using large pre-trained language models (PLMs) faces the overfitting problem when training on scarce labeled data. To mitigate these two issues, we propose, LAPA, an effective adapter for PLMs optimized by meta-learning. LAPA has three-stage training on three types of related resources to solve this problem: 1. pre-training PLMs on unsupervised corpora, 2. inserting an adapter layer and meta-training on source domain labeled data, and 3. fine-tuning adapters on a small amount of target domain labeled data. This method enables paraphrase generation models to learn basic language knowledge first, then learn the paraphrasing task itself later, and finally adapt to the target task. Our experimental results demonstrate that LAPA achieves state-of-the-art in supervised, unsupervised, and low-resource settings on three benchmark datasets. With only 2% of trainable parameters and 1% labeled data of the target task, our approach can achieve a competitive performance with previous work",
    "checked": true,
    "id": "20d2d10b0a6fabdfb89735a23c519db5811504bc",
    "semantic_title": "learning to adapt to low-resource paraphrase generation",
    "citation_count": 2,
    "authors": [
      "Zhigen Li",
      "Yanmeng Wang",
      "Rizhao Fan",
      "Ye Wang",
      "Jianfeng Li",
      "Shaojun Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.67": {
    "title": "A Distributional Lens for Multi-Aspect Controllable Text Generation",
    "volume": "main",
    "abstract": "Multi-aspect controllable text generation is a more challenging and practical task than single-aspect control. Existing methods achieve complex multi-aspect control by fusing multiple controllers learned from single-aspect, but suffer from attribute degeneration caused by the mutual interference of these controllers. To address this, we provide observations on attribute fusion from a distributional perspective and propose to directly search for the intersection areas of multiple attribute distributions as their combination for generation. Our method first estimates the attribute space with an autoencoder structure. Afterward, we iteratively approach the intersections by jointly minimizing distances to points representing different attributes. Finally, we map them to attribute-relevant sentences with a prefix-tuning-based decoder. Experiments on the three-aspect control task, including sentiment, topic, and detoxification aspects, reveal that our method outperforms several strong baselines on attribute relevance and text quality and achieves the SOTA. Further analysis also supplies some explanatory support for the effectiveness of our approach",
    "checked": true,
    "id": "2383140a30cbd5e66db3f73e488ebfdc7a7fbb56",
    "semantic_title": "a distributional lens for multi-aspect controllable text generation",
    "citation_count": 28,
    "authors": [
      "Yuxuan Gu",
      "Xiaocheng Feng",
      "Sicheng Ma",
      "Lingyuan Zhang",
      "Heng Gong",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.68": {
    "title": "ELMER: A Non-Autoregressive Pre-trained Language Model for Efficient and Effective Text Generation",
    "volume": "main",
    "abstract": "We study the text generation task under the approach of pre-trained language models (PLMs). Typically, an auto-regressive (AR) method is adopted for generating texts in a token-by-token manner. Despite many advantages of AR generation, it usually suffers from inefficient inference. Therefore, non-autoregressive (NAR) models are proposed to generate all target tokens simultaneously. However, NAR models usually generate texts of lower quality due to the absence of token dependency in the output text. In this paper, we propose ELMER: an efficient and effective PLM for NAR text generation to explicitly model the token dependency during NAR generation. By leveraging the early exit technique, ELMER enables the token generations at different layers, according to their prediction confidence (a more confident token will exit at a lower layer). Besides, we propose a novel pre-training objective, Layer Permutation Language Modeling, to pre-train ELMER by permuting the exit layer for each token in sequences. Experiments on three text generation tasks show that ELMER significantly outperforms NAR models and further narrows the performance gap with AR PLMs (ELMER (29.92) vs BART (30.61) ROUGE-L in XSUM) while achieving over 10 times inference speedup",
    "checked": true,
    "id": "764a616937a5923aaf22288b35f6b991ae41521d",
    "semantic_title": "elmer: a non-autoregressive pre-trained language model for efficient and effective text generation",
    "citation_count": 14,
    "authors": [
      "Junyi Li",
      "Tianyi Tang",
      "Wayne Xin Zhao",
      "Jian-Yun Nie",
      "Ji-Rong Wen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.69": {
    "title": "Multilingual Relation Classification via Efficient and Effective Prompting",
    "volume": "main",
    "abstract": "Prompting pre-trained language models has achieved impressive performance on various NLP tasks, especially in low data regimes. Despite the success of prompting in monolingual settings, applying prompt-based methods in multilingual scenarios has been limited to a narrow set of tasks, due to the high cost of handcrafting multilingual prompts. In this paper, we present the first work on prompt-based multilingual relation classification (RC), by introducing an efficient and effective method that constructs prompts from relation triples and involves only minimal translation for the class labels. We evaluate its performance in fully supervised, few-shot and zero-shot scenarios, and analyze its effectiveness across 14 languages, prompt variants, and English-task training in cross-lingual settings. We find that in both fully supervised and few-shot scenarios, our prompt method beats competitive baselines: fine-tuning XLM-R_EM and null prompts. It also outperforms the random baseline by a large margin in zero-shot experiments. Our method requires little in-language knowledge and can be used as a strong baseline for similar multilingual classification tasks",
    "checked": true,
    "id": "32635a3daba6cbd7f0dd930aa325254b191c1343",
    "semantic_title": "multilingual relation classification via efficient and effective prompting",
    "citation_count": 11,
    "authors": [
      "Yuxuan Chen",
      "David Harbecke",
      "Leonhard Hennig"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.70": {
    "title": "Topic-Regularized Authorship Representation Learning",
    "volume": "main",
    "abstract": "Authorship attribution is a task that aims to identify the author of a given piece of writing. We aim to develop a generalized solution that can handle a large number of texts from authors and topics unavailable in training data. Previous studies have proposed strategies to address only either unseen authors or unseen topics. Authorship representation learning has been shown to work in open-set environments with a large number of unseen authors but has not been explicitly designed for cross-topic environments at the same time. To handle a large number of unseen authors and topics, we propose Authorship Representation Regularization (ARR), a distillation framework that creates authorship representation with reduced reliance on topic-specific information. To assess the performance of our framework, we also propose a cross-topic-open-set evaluation method. Our proposed method has improved performances in the cross-topic-open set setup over baselines in 4 out of 6 cases",
    "checked": true,
    "id": "9751274d247da029a7812f98bda13e87beb43ed2",
    "semantic_title": "topic-regularized authorship representation learning",
    "citation_count": 1,
    "authors": [
      "Jitkapat Sawatphol",
      "Nonthakit Chaiwong",
      "Can Udomcharoenchaikit",
      "Sarana Nutanong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.71": {
    "title": "Fine-grained Contrastive Learning for Relation Extraction",
    "volume": "main",
    "abstract": "Recent relation extraction (RE) works have shown encouraging improvements by conducting contrastive learning on silver labels generated by distant supervision before fine-tuning on gold labels. Existing methods typically assume all these silver labels are accurate and treat them equally; however, distant supervision is inevitably noisy–some silver labels are more reliable than others. In this paper, we propose fine-grained contrastive learning (FineCL) for RE, which leverages fine-grained information about which silver labels are and are not noisy to improve the quality of learned relationship representations for RE. We first assess the quality of silver labels via a simple and automatic approach we call \"learning order denoising,\" where we train a language model to learn these relations and record the order of learned training instances. We show that learning order largely corresponds to label accuracy–early-learned silver labels have, on average, more accurate labels than later-learned silver labels. Then, during pre-training, we increase the weights of accurate labels within a novel contrastive learning objective. Experiments on several RE benchmarks show that FineCL makes consistent and significant performance gains over state-of-the-art methods",
    "checked": true,
    "id": "1242ee5c52464a5ac58d68a5f93449e334e00dfa",
    "semantic_title": "fine-grained contrastive learning for relation extraction",
    "citation_count": 10,
    "authors": [
      "William Hogan",
      "Jiacheng Li",
      "Jingbo Shang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.72": {
    "title": "Curriculum Prompt Learning with Self-Training for Abstractive Dialogue Summarization",
    "volume": "main",
    "abstract": "Succinctly summarizing dialogue is a task of growing interest, but inherent challenges, such as insufficient training data and low information density impede our ability to train abstractive models. In this work, we propose a novel curriculum-based prompt learning method with self-training to address these problems. Specifically, prompts are learned using a curriculum learning strategy that gradually increases the degree of prompt perturbation, thereby improving the dialogue understanding and modeling capabilities of our model. Unlabeled dialogue is incorporated by means of self-training so as to reduce the dependency on labeled data. We further investigate topic-aware prompts to better plan for the generation of summaries. Experiments confirm that our model substantially outperforms strong baselines and achieves new state-of-the-art results on the AMI and ICSI datasets. Human evaluations also show the superiority of our model with regard to the summary generation quality",
    "checked": true,
    "id": "86dac3ff83a0022ed10350690b970b7415e654d6",
    "semantic_title": "curriculum prompt learning with self-training for abstractive dialogue summarization",
    "citation_count": 5,
    "authors": [
      "Changqun Li",
      "Linlin Wang",
      "Xin Lin",
      "Gerard de Melo",
      "Liang He"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.73": {
    "title": "Zero-Shot Text Classification with Self-Training",
    "volume": "main",
    "abstract": "Recent advances in large pretrained language models have increased attention to zero-shot text classification. In particular, models finetuned on natural language inference datasets have been widely adopted as zero-shot classifiers due to their promising results and off-the-shelf availability. However, the fact that such models are unfamiliar with the target task can lead to instability and performance issues. We propose a plug-and-play method to bridge this gap using a simple self-training approach, requiring only the class names along with an unlabeled dataset, and without the need for domain expertise or trial and error. We show that fine-tuning the zero-shot classifier on its most confident predictions leads to significant performance gains across a wide range of text classification tasks, presumably since self-training adapts the zero-shot model to the task at hand",
    "checked": true,
    "id": "82cf46b592f499a2957a70a53947b2bbd5ca7cce",
    "semantic_title": "zero-shot text classification with self-training",
    "citation_count": 38,
    "authors": [
      "Ariel Gera",
      "Alon Halfon",
      "Eyal Shnarch",
      "Yotam Perlitz",
      "Liat Ein-Dor",
      "Noam Slonim"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.74": {
    "title": "Deconfounding Legal Judgment Prediction for European Court of Human Rights Cases Towards Better Alignment with Experts",
    "volume": "main",
    "abstract": "This work demonstrates that Legal Judgement Prediction systems without expert-informed adjustments can be vulnerable to shallow, distracting surface signals that arise from corpus construction, case distribution, and confounding factors. To mitigate this, we use domain expertise to strategically identify statistically predictive but legally irrelevant information. We adopt adversarial training to prevent the system from relying on it. We evaluate our deconfounded models by employing interpretability techniques and comparing to expert annotations. Quantitative experiments and qualitative analysis show that our deconfounded model consistently aligns better with expert rationales than baselines trained for prediction only. We further contribute a set of reference expert annotations to the validation and testing partitions of an existing benchmark dataset of European Court of Human Rights cases",
    "checked": true,
    "id": "0476fe2b42398f3482946fff2d5392e22662a248",
    "semantic_title": "deconfounding legal judgment prediction for european court of human rights cases towards better alignment with experts",
    "citation_count": 18,
    "authors": [
      "Santosh T.y.s.s",
      "Shanshan Xu",
      "Oana Ichim",
      "Matthias Grabmair"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.75": {
    "title": "SQuALITY: Building a Long-Document Summarization Dataset the Hard Way",
    "volume": "main",
    "abstract": "Summarization datasets are often assembled either by scraping naturally occurring public-domain summaries—which are nearly always in difficult-to-work-with technical domains—or by using approximate heuristics to extract them from everyday text—which frequently yields unfaithful summaries. In this work, we turn to a slower but more straightforward approach to developing summarization benchmark data: We hire highly-qualified contractors to read stories and write original summaries from scratch. To amortize reading time, we collect five summaries per document, with the first giving an overview and the subsequent four addressing specific questions. We use this protocol to collect SQuALITY, a dataset of question-focused summaries built on the same public-domain short stories as the multiple-choice dataset QuALITY (Pang et al., 2021). Experiments with state-of-the-art summarization systems show that our dataset is challenging and that existing automatic evaluation metrics are weak indicators of quality",
    "checked": true,
    "id": "b7422b7a7830cd899b47b03e514d8151ffb74c03",
    "semantic_title": "squality: building a long-document summarization dataset the hard way",
    "citation_count": 31,
    "authors": [
      "Alex Wang",
      "Richard Yuanzhe Pang",
      "Angelica Chen",
      "Jason Phang",
      "Samuel R. Bowman"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.76": {
    "title": "MetaASSIST: Robust Dialogue State Tracking with Meta Learning",
    "volume": "main",
    "abstract": "Existing dialogue datasets contain lots of noise in their state annotations. Such noise can hurt model training and ultimately lead to poor generalization performance. A general framework named ASSIST has recently been proposed to train robust dialogue state tracking (DST) models. It introduces an auxiliary model to generate pseudo labels for the noisy training set. These pseudo labels are combined with vanilla labels by a common fixed weighting parameter to train the primary DST model. Notwithstanding the improvements of ASSIST on DST, tuning the weighting parameter is challenging. Moreover, a single parameter shared by all slots and all instances may be suboptimal. To overcome these limitations, we propose a meta learning-based framework MetaASSIST to adaptively learn the weighting parameter. Specifically, we propose three schemes with varying degrees of flexibility, ranging from slot-wise to both slot-wise and instance-wise, to convert the weighting parameter into learnable functions. These functions are trained in a meta-learning manner by taking the validation set as meta data. Experimental results demonstrate that all three schemes can achieve competitive performance. Most impressively, we achieve a state-of-the-art joint goal accuracy of 80.10% on MultiWOZ 2.4",
    "checked": true,
    "id": "c3e66dd40810d888d3b7180ec7014fc62c5516bd",
    "semantic_title": "metaassist: robust dialogue state tracking with meta learning",
    "citation_count": 6,
    "authors": [
      "Fanghua Ye",
      "Xi Wang",
      "Jie Huang",
      "Shenghui Li",
      "Samuel Stern",
      "Emine Yilmaz"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.77": {
    "title": "Multilingual Machine Translation with Hyper-Adapters",
    "volume": "main",
    "abstract": "Multilingual machine translation suffers from negative interference across languages. A common solution is to relax parameter sharing with language-specific modules like adapters. However, adapters of related languages are unable to transfer information, and their total number of parameters becomes prohibitively expensive as the number of languages grows. In this work, we overcome these drawbacks using hyper-adapters – hyper-networks that generate adapters from language and layer embeddings. While past work had poor results when scaling hyper-networks, we propose a rescaling fix that significantly improves convergence and enables training larger hyper-networks. We find that hyper-adapters are more parameter efficient than regular adapters, reaching the same performance with up to 12 times less parameters. When using the same number of parameters and FLOPS, our approach consistently outperforms regular adapters. Also, hyper-adapters converge faster than alternative approaches and scale better than regular dense networks. Our analysis shows that hyper-adapters learn to encode language relatedness, enabling positive transfer across languages",
    "checked": true,
    "id": "a97a7c6040b030157efc239db9cd79ac738badac",
    "semantic_title": "multilingual machine translation with hyper-adapters",
    "citation_count": 19,
    "authors": [
      "Christos Baziotis",
      "Mikel Artetxe",
      "James Cross",
      "Shruti Bhosale"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.78": {
    "title": "Z-LaVI: Zero-Shot Language Solver Fueled by Visual Imagination",
    "volume": "main",
    "abstract": "Large-scale pretrained language models have made significant advances in solving downstream language understanding tasks. However, they generally suffer from reporting bias, the phenomenon describing the lack of explicit commonsense knowledge in written text, e.g., \"an orange is orange\". To overcome this limitation, we develop a novel approach, Z-LaVI, to endow language models with visual imagination capabilities. Specifically, we leverage two complementary types of \"imaginations\": (i) recalling existing images through retrieval and (ii) synthesizing nonexistent images via text-to-image generation. Jointly exploiting the language inputs and the imagination, a pretrained vision-language model (e.g., CLIP) eventually composes a zero-shot solution to the original language tasks. Notably, fueling language models with imagination can effectively leverage visual knowledge to solve plain language tasks. In consequence, Z-LaVI consistently improves the zero-shot performance of existing language models across a diverse set of language tasks",
    "checked": true,
    "id": "c2a2b801e9091c33d50efd8758d3bcc2b05368ff",
    "semantic_title": "z-lavi: zero-shot language solver fueled by visual imagination",
    "citation_count": 14,
    "authors": [
      "Yue Yang",
      "Wenlin Yao",
      "Hongming Zhang",
      "Xiaoyang Wang",
      "Dong Yu",
      "Jianshu Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.79": {
    "title": "Using Commonsense Knowledge to Answer Why-Questions",
    "volume": "main",
    "abstract": "Answering questions in narratives about why events happened often requires commonsense knowledge external to the text. What aspects of this knowledge are available in large language models? What aspects can be made accessible via external commonsense resources? We study these questions in the context of answering questions in the TellMeWhy dataset using COMET as a source of relevant commonsense relations. We analyze the effects of model size (T5 and GPT3) along with methods of injecting knowledge (COMET) into these models. Results show that the largest models, as expected, yield substantial improvements over base models. Injecting external knowledge helps models of various sizes, but the amount of improvement decreases with larger model size. We also find that the format in which knowledge is provided is critical, and that smaller models benefit more from larger amounts of knowledge. Finally, we develop an ontology of knowledge types and analyze the relative coverage of the models across these categories",
    "checked": true,
    "id": "7bb907e754942b832bacf7889ba1d6bd72945ca0",
    "semantic_title": "using commonsense knowledge to answer why-questions",
    "citation_count": 8,
    "authors": [
      "Yash Kumar Lal",
      "Niket Tandon",
      "Tanvi Aggarwal",
      "Horace Liu",
      "Nathanael Chambers",
      "Raymond Mooney",
      "Niranjan Balasubramanian"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.80": {
    "title": "Affective Idiosyncratic Responses to Music",
    "volume": "main",
    "abstract": "Affective responses to music are highly personal. Despite consensus that idiosyncratic factors play a key role in regulating how listeners emotionally respond to music, precisely measuring the marginal effects of these variables has proved challenging. To address this gap, we develop computational methods to measure affective responses to music from over 403M listener comments on a Chinese social music platform. Building on studies from music psychology in systematic and quasi-causal analyses, we test for musical, lyrical, contextual, demographic, and mental health effects that drive listener affective responses. Finally, motivated by the social phenomenon known as 网抑云 (wǎng-yì-yún), we identify influencing factors of platform user self-disclosures, the social support they receive, and notable differences in discloser user activity",
    "checked": true,
    "id": "d8013589c4e260e45f76426fd7e2beb7d5cf7d4a",
    "semantic_title": "affective idiosyncratic responses to music",
    "citation_count": 1,
    "authors": [
      "Sky CH-Wang",
      "Evan Li",
      "Oliver Li",
      "Smaranda Muresan",
      "Zhou Yu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.81": {
    "title": "Successive Prompting for Decomposing Complex Questions",
    "volume": "main",
    "abstract": "Answering complex questions that require making latent decisions is a challenging task, especially when limited supervision is available. Recent works leverage the capabilities of large language models (LMs) to perform complex question answering in a few-shot setting by demonstrating how to output intermediate rationalizations while solving the complex question in a single pass. We introduce \"Successive Prompting\" where, we iteratively break down a complex task into a simple task, solve it, and then repeat the process until we get the final solution. Successive prompting decouples the supervision for decomposing complex questions from the supervision for answering simple questions, allowing us to (1) have multiple opportunities to query in-context examples at each reasoning step (2) learn question decomposition separately from question answering, including using synthetic data, and (3) use bespoke (fine-tuned) components for reasoning steps where a large LM does not perform well. The intermediate supervision is typically manually written, which can be expensive to collect. We introduce a way to generate synthetic dataset which can be used to bootstrap model's ability to decompose and answer intermediate questions. Our best model (with successive prompting) achieves an improvement in F1 of ~5% when compared with a state-of-the-art model with synthetic augmentations and few-shot version of the DROP dataset",
    "checked": true,
    "id": "c90151f00b1ac4abf1cc353849b453aa21cc2df3",
    "semantic_title": "successive prompting for decomposing complex questions",
    "citation_count": 82,
    "authors": [
      "Dheeru Dua",
      "Shivanshu Gupta",
      "Sameer Singh",
      "Matt Gardner"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.82": {
    "title": "Maieutic Prompting: Logically Consistent Reasoning with Recursive Explanations",
    "volume": "main",
    "abstract": "Pre-trained language models (LMs) struggle with consistent reasoning; recently, prompting LMs to generate explanations that self-guide the inference has emerged as a promising direction to amend this. However, these approaches are fundamentally bounded by the correctness of explanations, which themselves are often noisy and inconsistent. In this work, we develop Maieutic Prompting, which aims to infer a correct answer to a question even from the unreliable generations of LM. Maieutic Prompting induces a tree of explanations abductively (e.g. X is true, because ...) and recursively, then frames the inference as a satisfiability problem over these explanations and their logical relations. We test Maieutic Prompting for true/false QA on three challenging benchmarks that require complex commonsense reasoning. Maieutic Prompting achieves up to 20% better accuracy than state-of-the-art prompting methods, and as a fully unsupervised approach, performs competitively with supervised models. We also show that Maieutic Prompting improves robustness in inference while providing interpretable rationales",
    "checked": true,
    "id": "50b0c6ee2b3d53ba5af69d6c00b5d60888a9026f",
    "semantic_title": "maieutic prompting: logically consistent reasoning with recursive explanations",
    "citation_count": 155,
    "authors": [
      "Jaehun Jung",
      "Lianhui Qin",
      "Sean Welleck",
      "Faeze Brahman",
      "Chandra Bhagavatula",
      "Ronan Le Bras",
      "Yejin Choi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.83": {
    "title": "DANLI: Deliberative Agent for Following Natural Language Instructions",
    "volume": "main",
    "abstract": "Recent years have seen an increasing amount of work on embodied AI agents that can perform tasks by following human language instructions. However, most of these agents are reactive, meaning that they simply learn and imitate behaviors encountered in the training data. These reactive agents are insufficient for long-horizon complex tasks. To address this limitation, we propose a neuro-symbolic deliberative agent that, while following language instructions, proactively applies reasoning and planning based on its neural and symbolic representations acquired from past experience (e.g., natural language and egocentric vision). We show that our deliberative agent achieves greater than 70% improvement over reactive baselines on the challenging TEACh benchmark. Moreover, the underlying reasoning and planning processes, together with our modular framework, offer impressive transparency and explainability to the behaviors of the agent. This enables an in-depth understanding of the agent's capabilities, which shed light on challenges and opportunities for future embodied agents for instruction following. The code is available at https://github.com/sled-group/DANLI",
    "checked": true,
    "id": "fc5631cdd08722f51e0ce4b718de0f081ae73603",
    "semantic_title": "danli: deliberative agent for following natural language instructions",
    "citation_count": 10,
    "authors": [
      "Yichi Zhang",
      "Jianing Yang",
      "Jiayi Pan",
      "Shane Storks",
      "Nikhil Devraj",
      "Ziqiao Ma",
      "Keunwoo Yu",
      "Yuwei Bao",
      "Joyce Chai"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.84": {
    "title": "Tracing Semantic Variation in Slang",
    "volume": "main",
    "abstract": "The meaning of a slang term can vary in different communities. However, slang semantic variation is not well understood and under-explored in the natural language processing of slang. One existing view argues that slang semantic variation is driven by culture-dependent communicative needs. An alternative view focuses on slang's social functions suggesting that the desire to foster semantic distinction may have led to the historical emergence of community-specific slang senses. We explore these theories using computational models and test them against historical slang dictionary entries, with a focus on characterizing regularity in the geographical variation of slang usages attested in the US and the UK over the past two centuries. We show that our models are able to predict the regional identity of emerging slang word meanings from historical slang records. We offer empirical evidence that both communicative need and semantic distinction play a role in the variation of slang meaning yet their relative importance fluctuates over the course of history. Our work offers an opportunity for incorporating historical cultural elements into the natural language processing of slang",
    "checked": true,
    "id": "6243c8f4d426e368b8ccbc8a7fb396438488dc99",
    "semantic_title": "tracing semantic variation in slang",
    "citation_count": 0,
    "authors": [
      "Zhewei Sun",
      "Yang Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.85": {
    "title": "Fine-grained Category Discovery under Coarse-grained supervision with Hierarchical Weighted Self-contrastive Learning",
    "volume": "main",
    "abstract": "Novel category discovery aims at adapting models trained on known categories to novel categories. Previous works only focus on the scenario where known and novel categories are of the same granularity.In this paper, we investigate a new practical scenario called Fine-grained Category Discovery under Coarse-grained supervision (FCDC). FCDC aims at discovering fine-grained categories with only coarse-grained labeled data, which can adapt models to categories of different granularity from known ones and reduce significant labeling cost. It is also a challenging task since supervised training on coarse-grained categories tends to focus on inter-class distance (distance between coarse-grained classes) but ignore intra-class distance (distance between fine-grained sub-classes) which is essential for separating fine-grained categories.Considering most current methods cannot transfer knowledge from coarse-grained level to fine-grained level, we propose a hierarchical weighted self-contrastive network by building a novel weighted self-contrastive module and combining it with supervised learning in a hierarchical manner.Extensive experiments on public datasets show both effectiveness and efficiency of our model over compared methods",
    "checked": true,
    "id": "d078a0fb395c4c964123790873c8c748a2a73463",
    "semantic_title": "fine-grained category discovery under coarse-grained supervision with hierarchical weighted self-contrastive learning",
    "citation_count": 13,
    "authors": [
      "Wenbin An",
      "Feng Tian",
      "Ping Chen",
      "Siliang Tang",
      "Qinghua Zheng",
      "QianYing Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.86": {
    "title": "PLM-based World Models for Text-based Games",
    "volume": "main",
    "abstract": "World models have improved the ability of reinforcement learning agents to operate in a sample efficient manner, by being trained to predict plausible changes in the underlying environment. As the core tasks of world models are future prediction and commonsense understanding, our claim is that pre-trained language models (PLMs) already provide a strong base upon which to build world models. Worldformer is a recently proposed world model for text-based game environments, based only partially on PLM and transformers. Our distinction is to fully leverage PLMs as actionable world models in text-based game environments, by reformulating generation as constrained decoding which decomposes actions into verb templates and objects. We show that our model improves future valid action prediction and graph change prediction. Additionally, we show that our model better reflects commonsense than standard PLM",
    "checked": true,
    "id": "f65e11bae859d318f286b36caaab8ff6ac11a771",
    "semantic_title": "plm-based world models for text-based games",
    "citation_count": 4,
    "authors": [
      "Minsoo Kim",
      "Yeonjoon Jung",
      "Dohyeon Lee",
      "Seung-won Hwang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.87": {
    "title": "Prompt-Based Meta-Learning For Few-shot Text Classification",
    "volume": "main",
    "abstract": "Few-shot Text Classification predicts the semantic label of a given text with a handful of supporting instances. Current meta-learning methods have achieved satisfying results in various few-shot situations. Still, they often require a large amount of data to construct many few-shot tasks for meta-training, which is not practical in real-world few-shot scenarios. Prompt-tuning has recently proved to be another effective few-shot learner by bridging the gap between pre-train and downstream tasks. In this work, we closely combine the two promising few-shot learning methodologies in structure and propose a Prompt-Based Meta-Learning (PBML) model to overcome the above meta-learning problem by adding the prompting mechanism. PBML assigns label word learning to base-learners and template learning to meta-learner, respectively. Experimental results show state-of-the-art performance on four text classification datasets under few-shot settings, with higher accuracy and good robustness. We demonstrate through low-resource experiments that our method alleviates the shortcoming that meta-learning requires too much data for meta-training. In the end, we use the visualization to interpret and verify that the meta-learning framework can help the prompting method converge better. We release our code to reproduce our experiments",
    "checked": true,
    "id": "bdf563cfb1168d44262646680cee1423d5b84674",
    "semantic_title": "prompt-based meta-learning for few-shot text classification",
    "citation_count": 15,
    "authors": [
      "Haoxing Zhang",
      "Xiaofeng Zhang",
      "Haibo Huang",
      "Lei Yu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.88": {
    "title": "How well can Text-to-Image Generative Models understand Ethical Natural Language Interventions?",
    "volume": "main",
    "abstract": "Text-to-image generative models have achieved unprecedented success in generating high-quality images based on natural language descriptions. However, it is shown that these models tend to favor specific social groups when prompted with neutral text descriptions (e.g., ‘a photo of a lawyer'). Following Zhao et al. (2021), we study the effect on the diversity of the generated images when adding ethical intervention that supports equitable judgment (e.g., ‘if all individuals can be a lawyer irrespective of their gender') in the input prompts. To this end, we introduce an Ethical NaTural Language Interventions in Text-to-Image GENeration (ENTIGEN) benchmark dataset to evaluate the change in image generations conditional on ethical interventions across three social axes – gender, skin color, and culture. Through CLIP-based and human evaluation on minDALL.E, DALL.E-mini and Stable Diffusion, we find that the model generations cover diverse social groups while preserving the image quality. In some cases, the generations would be anti-stereotypical (e.g., models tend to create images with individuals that are perceived as man when fed with prompts about makeup) in the presence of ethical intervention. Preliminary studies indicate that a large change in the model predictions is triggered by certain phrases such as ‘irrespective of gender' in the context of gender bias in the ethical interventions. We release code and annotated data at https://github.com/Hritikbansal/entigen_emnlp",
    "checked": true,
    "id": "23c818b5df6a2c8f8837f0e69741164f01946fef",
    "semantic_title": "how well can text-to-image generative models understand ethical natural language interventions?",
    "citation_count": 70,
    "authors": [
      "Hritik Bansal",
      "Da Yin",
      "Masoud Monajatipoor",
      "Kai-Wei Chang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.89": {
    "title": "Geographic Citation Gaps in NLP Research",
    "volume": "main",
    "abstract": "In a fair world, people have equitable opportunities to education, to conduct scientific research, to publish, and to get credit for their work, regardless of where they live. However, it is common knowledge among researchers that a vast number of papers accepted at top NLP venues come from a handful of western countries and (lately) China; whereas, very few papers from Africa and South America get published. Similar disparities are also believed to exist for paper citation counts. In the spirit of \"what we do not measure, we cannot improve\", this work asks a series of questions on the relationship between geographical location and publication success (acceptance in top NLP venues and citation impact). We first created a dataset of 70,000 papers from the ACL Anthology, extracted their meta-information, andgenerated their citation network. We then show that not only are there substantial geographical disparities in paper acceptance and citation but also that these disparities persist even when controlling for a number of variables such as venue of publication and sub-field of NLP. Further, despite some steps taken by the NLP community to improve geographical diversity, we show that the disparity in publication metrics across locations is still on an increasing trend since the early 2000s. We release our code and dataset here: https://github.com/iamjanvijay/acl-cite-net",
    "checked": true,
    "id": "6f8ab0fa15c87cee55b2ca5b8877e6784887ddbf",
    "semantic_title": "geographic citation gaps in nlp research",
    "citation_count": 15,
    "authors": [
      "Mukund Rungta",
      "Janvijay Singh",
      "Saif M. Mohammad",
      "Diyi Yang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.90": {
    "title": "Language Models of Code are Few-Shot Commonsense Learners",
    "volume": "main",
    "abstract": "We address the general task of structured commonsense reasoning: given a natural language input, the goal is to generate a graph such as an event or a reasoning-graph.To employ large language models (LMs) for this task, existing approaches ‘serialize' the output graph as a flat list of nodes and edges.Although feasible, these serialized graphs strongly deviate from the natural language corpora that LMs were pre-trained on, hindering LMs from generating them correctly. In this paper, we show that when we instead frame structured commonsense reasoning tasks as code generation tasks, pre-trained LMs of code are better structured commonsense reasoners than LMs of natural language, even when the downstream task does not involve source code at all.We demonstrate our approach across three diverse structured commonsense reasoning tasks. In all these natural language tasks, we show that using our approach, a code generation LM (codex) outperforms natural-LMs that are fine-tuned on the target task (T5) and other strong LMs such as GPT-3 in the few-shot setting",
    "checked": true,
    "id": "39e40821b7207125e54e6ed7112e55cd38c6f0c3",
    "semantic_title": "language models of code are few-shot commonsense learners",
    "citation_count": 137,
    "authors": [
      "Aman Madaan",
      "Shuyan Zhou",
      "Uri Alon",
      "Yiming Yang",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.91": {
    "title": "Numerical Optimizations for Weighted Low-rank Estimation on Language Models",
    "volume": "main",
    "abstract": "Singular value decomposition (SVD) is one of the most popular compression methods that approximate a target matrix with smaller matrices. However, standard SVD treats the parameters within the matrix with equal importance, which is a simple but unrealistic assumption. The parameters of a trained neural network model may affect the task performance unevenly, which suggests non-equal importance among the parameters. Compared to SVD, the decomposition method aware of parameter importance is the more practical choice in real cases. Unlike standard SVD, weighed value decomposition is a non-convex optimization problem that lacks a closed-form solution. We systematically investigated multiple optimization strategies to tackle the problem and examined our method by compressing Transformer-based language models.Further, we designed a metric to predict when the SVD may introduce a significant performance drop, for which our method can be a rescue strategy.The extensive evaluations demonstrate that our method can perform better than current SOTA methods in compressing Transformer-based language models",
    "checked": true,
    "id": "a18eab311e4d6a115bbca835885704cc74e3e687",
    "semantic_title": "numerical optimizations for weighted low-rank estimation on language models",
    "citation_count": 9,
    "authors": [
      "Ting Hua",
      "Yen-Chang Hsu",
      "Felicity Wang",
      "Qian Lou",
      "Yilin Shen",
      "Hongxia Jin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.92": {
    "title": "Generative Multi-hop Retrieval",
    "volume": "main",
    "abstract": "A common practice for text retrieval is to use an encoder to map the documents and the query to a common vector space and perform a nearest neighbor search (NNS); multi-hop retrieval also often adopts the same paradigm, usually with a modification of iteratively reformulating the query vector so that it can retrieve different documents at each hop. However, such a bi-encoder approach has limitations in multi-hop settings; (1) the reformulated query gets longer as the number of hops increases, which further tightens the embedding bottleneck of the query vector, and (2) it is prone to error propagation. In this paper, we focus on alleviating these limitations in multi-hop settings by formulating the problem in a fully generative way. We propose an encoder-decoder model that performs multi-hop retrieval by simply generating the entire text sequences of the retrieval targets, which means the query and the documents interact in the language model's parametric space rather than L2 or inner product space as in the bi-encoder approach. Our approach, Generative Multi-hop Retrieval (GMR), consistently achieves comparable or higher performance than bi-encoder models in five datasets while demonstrating superior GPU memory and storage footprint",
    "checked": true,
    "id": "896e3e1bfe1f89e790b178980c0d44558e6c3bb7",
    "semantic_title": "generative multi-hop retrieval",
    "citation_count": 10,
    "authors": [
      "Hyunji Lee",
      "Sohee Yang",
      "Hanseok Oh",
      "Minjoon Seo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.93": {
    "title": "Visual Spatial Description: Controlled Spatial-Oriented Image-to-Text Generation",
    "volume": "main",
    "abstract": "Image-to-text tasks such as open-ended image captioning and controllable image description have received extensive attention for decades. Here we advance this line of work further, presenting Visual Spatial Description (VSD), a new perspective for image-to-text toward spatial semantics. Given an image and two objects inside it, VSD aims to produce one description focusing on the spatial perspective between the two objects. Accordingly, we annotate a dataset manually to facilitate the investigation of the newly-introduced task, and then build several benchmark encoder-decoder models by using VL-BART and VL-T5 as backbones. In addition, we investigate visual spatial relationship classification (VSRC) information into our model by pipeline and end-to-end architectures. Finally, we conduct experiments on our benchmark dataset to evaluate all our models. Results show that our models are awe-inspiring, offering accurate and human-like spatial-oriented text descriptions. Besides, VSRC has great potential for VSD, and the joint end-to-end architecture is the better choice for their integration. We will make the dataset and codes publicly available for research purposes",
    "checked": true,
    "id": "0b574244f2ecea75a536106789f08d3c3c2590e0",
    "semantic_title": "visual spatial description: controlled spatial-oriented image-to-text generation",
    "citation_count": 9,
    "authors": [
      "Yu Zhao",
      "Jianguo Wei",
      "ZhiChao Lin",
      "Yueheng Sun",
      "Meishan Zhang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.94": {
    "title": "M3: A Multi-View Fusion and Multi-Decoding Network for Multi-Document Reading Comprehension",
    "volume": "main",
    "abstract": "Multi-document reading comprehension task requires collecting evidences from different documents for answering questions. Previous research works either use the extractive modeling method to naively integrate the scores from different documents on the encoder side or use the generative modeling method to collect the clues from different documents on the decoder side individually. However, any single modeling method cannot make full of the advantages of both. In this work, we propose a novel method that tries to employ a multi-view fusion and multi-decoding mechanism to achieve it. For one thing, our approach leverages question-centered fusion mechanism and cross-attention mechanism to gather fine-grained fusion of evidence clues from different documents in the encoder and decoder concurrently. For another, our method simultaneously employs both the extractive decoding approach and the generative decoding method to effectively guide the training process. Compared with existing methods, our method can perform both extractive decoding and generative decoding independently and optionally. Our experiments on two mainstream multi-document reading comprehension datasets (Natural Questions and TriviaQA) demonstrate that our method can provide consistent improvements over previous state-of-the-art methods",
    "checked": true,
    "id": "60dfb269f6ec44ccf993c52ba688481bc32f2b31",
    "semantic_title": "m3: a multi-view fusion and multi-decoding network for multi-document reading comprehension",
    "citation_count": 4,
    "authors": [
      "Liang Wen",
      "Houfeng Wang",
      "Yingwei Luo",
      "Xiaolin Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.95": {
    "title": "COCO-DR: Combating the Distribution Shift in Zero-Shot Dense Retrieval with Contrastive and Distributionally Robust Learning",
    "volume": "main",
    "abstract": "We present a new zero-shot dense retrieval (ZeroDR) method, COCO-DR, to improve the generalization ability of dense retrieval by combating the distribution shifts between source training tasks and target scenarios. To mitigate the impact of document differences, COCO-DR continues pretraining the language model on the target corpora to adapt the model to target distributions via COtinuous COtrastive learning. To prepare for unseen target queries, COCO-DR leverages implicit Distributionally Robust Optimization (iDRO) to reweight samples from different source query clusters for improving model robustness over rare queries during fine-tuning. COCO-DR achieves superior average performance on BEIR, the zero-shot retrieval benchmark. At BERT_Base scale, COCO-DR Base outperforms other ZeroDR models with 60x larger size. At BERT_Large scale, COCO-DR Large outperforms the giant GPT-3 embedding model which has 500x more parameters. Our analysis shows the correlation between COCO-DR's effectiveness in combating distribution shifts and improving zero-shot accuracy. Our code and model can be found at https://github.com/OpenMatch/COCO-DR",
    "checked": true,
    "id": "a2d28fb66dda5001b58d1529d1a82f768bdc9918",
    "semantic_title": "coco-dr: combating distribution shift in zero-shot dense retrieval with contrastive and distributionally robust learning",
    "citation_count": 34,
    "authors": [
      "Yue Yu",
      "Chenyan Xiong",
      "Si Sun",
      "Chao Zhang",
      "Arnold Overwijk"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.96": {
    "title": "Language Model Pre-Training with Sparse Latent Typing",
    "volume": "main",
    "abstract": "Modern large-scale Pre-trained Language Models (PLMs) have achieved tremendous success on a wide range of downstream tasks. However, most of the LM pre-training objectives only focus on text reconstruction, but have not sought to learn latent-level interpretable representations of sentences. In this paper, we manage to push the language models to obtain a deeper understanding of sentences by proposing a new pre-training objective, Sparse Latent Typing, which enables the model to sparsely extract sentence-level keywords with diverse latent types. Experimental results show that our model is able to learn interpretable latent type categories in a self-supervised manner without using any external knowledge. Besides, the language model pre-trained with such an objective also significantly improves Information Extraction related downstream tasks in both supervised and few-shot settings. Our code is publicly available at https://github.com/renll/SparseLT",
    "checked": true,
    "id": "cd16a961b16482d4aede6227acaa95183c5c555c",
    "semantic_title": "language model pre-training with sparse latent typing",
    "citation_count": 3,
    "authors": [
      "Liliang Ren",
      "Zixuan Zhang",
      "Han Wang",
      "Clare Voss",
      "ChengXiang Zhai",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.97": {
    "title": "On the Transformation of Latent Space in Fine-Tuned NLP Models",
    "volume": "main",
    "abstract": "We study the evolution of latent space in fine-tuned NLP models. Different from the commonly used probing-framework, we opt for an unsupervised method to analyze representations. More specifically, we discover latent concepts in the representational space using hierarchical clustering. We then use an alignment function to gauge the similarity between the latent space of a pre-trained model and its fine-tuned version. We use traditional linguistic concepts to facilitate our understanding and also study how the model space transforms towards task-specific information. We perform a thorough analysis, comparing pre-trained and fine-tuned models across three models and three downstream tasks. The notable findings of our work are: i) the latent space of the higher layers evolve towards task-specific concepts, ii) whereas the lower layers retain generic concepts acquired in the pre-trained model, iii) we discovered that some concepts in the higher layers acquire polarity towards the output class, and iv) that these concepts can be used for generating adversarial triggers",
    "checked": true,
    "id": "94d931a253fb44b9d2f93d9287aec1bf8bdf0a4b",
    "semantic_title": "on the transformation of latent space in fine-tuned nlp models",
    "citation_count": 13,
    "authors": [
      "Nadir Durrani",
      "Hassan Sajjad",
      "Fahim Dalvi",
      "Firoj Alam"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.98": {
    "title": "Watch the Neighbors: A Unified K-Nearest Neighbor Contrastive Learning Framework for OOD Intent Discovery",
    "volume": "main",
    "abstract": "Discovering out-of-domain (OOD) intent is important for developing new skills in task-oriented dialogue systems. The key challenges lie in how to transfer prior in-domain (IND) knowledge to OOD clustering, as well as jointly learn OOD representations and cluster assignments. Previous methods suffer from in-domain overfitting problem, and there is a natural gap between representation learning and clustering objectives. In this paper, we propose a unified K-nearest neighbor contrastive learning framework to discover OOD intents. Specifically, for IND pre-training stage, we propose a KCL objective to learn inter-class discriminative features, while maintaining intra-class diversity, which alleviates the in-domain overfitting problem. For OOD clustering stage, we propose a KCC method to form compact clusters by mining true hard negative samples, which bridges the gap between clustering and representation learning. Extensive experiments on three benchmark datasets show that our method achieves substantial improvements over the state-of-the-art methods",
    "checked": true,
    "id": "f567ebbfac14034f8be570ed90164ddf531726e3",
    "semantic_title": "watch the neighbors: a unified k-nearest neighbor contrastive learning framework for ood intent discovery",
    "citation_count": 9,
    "authors": [
      "Yutao Mou",
      "Keqing He",
      "Pei Wang",
      "Yanan Wu",
      "Jingang Wang",
      "Wei Wu",
      "Weiran Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.99": {
    "title": "Extracted BERT Model Leaks More Information than You Think!",
    "volume": "main",
    "abstract": "The collection and availability of big data, combined with advances in pre-trained models (e.g. BERT), have revolutionized the predictive performance of natural language processing tasks. This allows corporations to provide machine learning as a service (MLaaS) by encapsulating fine-tuned BERT-based models as APIs. Due to significant commercial interest, there has been a surge of attempts to steal remote services via model extraction. Although previous works have made progress in defending against model extraction attacks, there has been little discussion on their performance in preventing privacy leakage. This work bridges this gap by launching an attribute inference attack against the extracted BERT model. Our extensive experiments reveal that model extraction can cause severe privacy leakage even when victim models are facilitated with state-of-the-art defensive strategies",
    "checked": true,
    "id": "eb39dda2df56270599f2a28bc6433c84c1704949",
    "semantic_title": "extracted bert model leaks more information than you think!",
    "citation_count": 4,
    "authors": [
      "Xuanli He",
      "Lingjuan Lyu",
      "Chen Chen",
      "Qiongkai Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.100": {
    "title": "Do Vision-and-Language Transformers Learn Grounded Predicate-Noun Dependencies?",
    "volume": "main",
    "abstract": "Recent advances in vision-and-language modeling have seen the development of Transformer architectures that achieve remarkable performance on multimodal reasoning tasks.Yet, the exact capabilities of these black-box models are still poorly understood. While much of previous work has focused on studying their ability to learn meaning at the word-level, their ability to track syntactic dependencies between words has received less attention.We take a first step in closing this gap by creating a new multimodal task targeted at evaluating understanding of predicate-noun dependencies in a controlled setup.We evaluate a range of state-of-the-art models and find that their performance on the task varies considerably, with some models performing relatively well and others at chance level. In an effort to explain this variability, our analyses indicate that the quality (and not only sheer quantity) of pretraining data is essential. Additionally, the best performing models leverage fine-grained multimodal pretraining objectives in addition to the standard image-text matching objectives.This study highlights that targeted and controlled evaluations are a crucial step for a precise and rigorous test of the multimodal knowledge of vision-and-language models",
    "checked": true,
    "id": "4c43063804ee1fac639c0b68e75745ccde0e5649",
    "semantic_title": "do vision-and-language transformers learn grounded predicate-noun dependencies?",
    "citation_count": 10,
    "authors": [
      "Mitja Nikolaus",
      "Emmanuelle Salin",
      "Stephane Ayache",
      "Abdellah Fourtassi",
      "Benoit Favre"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.101": {
    "title": "A Multilingual Perspective Towards the Evaluation of Attribution Methods in Natural Language Inference",
    "volume": "main",
    "abstract": "Most evaluations of attribution methods focus on the English language. In this work, we present a multilingual approach for evaluating attribution methods for the Natural Language Inference (NLI) task in terms of faithfulness and plausibility.First, we introduce a novel cross-lingual strategy to measure faithfulness based on word alignments, which eliminates the drawbacks of erasure-based evaluations.We then perform a comprehensive evaluation of attribution methods, considering different output mechanisms and aggregation methods.Finally, we augment the XNLI dataset with highlight-based explanations, providing a multilingual NLI dataset with highlights, to support future exNLP studies. Our results show that attribution methods performing best for plausibility and faithfulness are different",
    "checked": true,
    "id": "e84d8a318393c1eeed7a35a44a5e59a66eaccd5c",
    "semantic_title": "a multilingual perspective towards the evaluation of attribution methods in natural language inference",
    "citation_count": 7,
    "authors": [
      "Kerem Zaman",
      "Yonatan Belinkov"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.102": {
    "title": "Graph-Based Multilingual Label Propagation for Low-Resource Part-of-Speech Tagging",
    "volume": "main",
    "abstract": "Part-of-Speech (POS) tagging is an important component of the NLP pipeline, but many low-resource languages lack labeled data for training. An established method for training a POS tagger in such a scenario is to create a labeled training set by transferring from high-resource languages. In this paper, we propose a novel method for transferring labels from multiple high-resource source to low-resource target languages. We formalize POS tag projection as graph-based label propagation. Given translations of a sentence in multiple languages, we create a graph with words as nodes and alignment links as edges by aligning words for all language pairs. We then propagate node labels from source to target using a Graph Neural Network augmented with transformer layers. We show that our propagation creates training sets that allow us to train POS taggers for a diverse set of languages. When combined with enhanced contextualized embeddings, our method achieves a new state-of-the-art for unsupervised POS tagging of low-resource languages",
    "checked": true,
    "id": "1e1dbf6b8c2787373d18c319af0414eb8b4977d1",
    "semantic_title": "graph-based multilingual label propagation for low-resource part-of-speech tagging",
    "citation_count": 4,
    "authors": [
      "Ayyoob ImaniGooghari",
      "Silvia Severini",
      "Masoud Jalili Sabet",
      "François Yvon",
      "Hinrich Schütze"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.103": {
    "title": "SubeventWriter: Iterative Sub-event Sequence Generation with Coherence Controller",
    "volume": "main",
    "abstract": "In this paper, we propose a new task of sub-event generation for an unseen process to evaluate the understanding of the coherence of sub-event actions and objects. To solve the problem, we design SubeventWriter, a sub-event sequence generation framework with a coherence controller. Given an unseen process, the framework can iteratively construct the sub-event sequence by generating one sub-event at each iteration. We also design a very effective coherence controller to decode more coherent sub-events. As our extensive experiments and analysis indicate, SubeventWriter can generate more reliable and meaningful sub-event sequences for unseen processes",
    "checked": true,
    "id": "3d7dccc8fcc7dc26fea7a44df428e1c2b96c988f",
    "semantic_title": "subeventwriter: iterative sub-event sequence generation with coherence controller",
    "citation_count": 9,
    "authors": [
      "Zhaowei Wang",
      "Hongming Zhang",
      "Tianqing Fang",
      "Yangqiu Song",
      "Ginny Wong",
      "Simon See"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.104": {
    "title": "Infinite SCAN: An Infinite Model of Diachronic Semantic Change",
    "volume": "main",
    "abstract": "In this study, we propose a Bayesian model that can jointly estimate the number of senses of words and their changes through time.The model combines a dynamic topic model on Gaussian Markov random fields with a logistic stick-breaking process that realizes Dirichlet process. In the experiments, we evaluated the proposed model in terms of interpretability, accuracy in estimating the number of senses, and tracking their changes using both artificial data and real data.We quantitatively verified that the model behaves as expected through evaluation using artificial data.Using the CCOHA corpus, we showed that our model outperforms the baseline model and investigated the semantic changes of several well-known target words",
    "checked": true,
    "id": "e2b4c7c08725bfbd528a0edc2d25a0d2b286ca51",
    "semantic_title": "infinite scan: an infinite model of diachronic semantic change",
    "citation_count": 0,
    "authors": [
      "Seiichi Inoue",
      "Mamoru Komachi",
      "Toshinobu Ogiso",
      "Hiroya Takamura",
      "Daichi Mochihashi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.105": {
    "title": "Learning Instructions with Unlabeled Data for Zero-Shot Cross-Task Generalization",
    "volume": "main",
    "abstract": "Training language models to learn from human instructions for zero-shot cross-task generalization has attracted much attention in NLP communities. Recently, instruction tuning (IT), which fine-tunes a pre-trained language model on a massive collection of tasks described via human-craft instructions, has been shown effective in instruction learning for unseen tasks. However, IT relies on a large amount of human-annotated samples, which restricts its generalization. Unlike labeled data, unlabeled data are often massive and cheap to obtain. In this work, we study how IT can be improved with unlabeled data. We first empirically explore the IT performance trends versus the number of labeled data, instructions, and training tasks. We find it critical to enlarge the number of training instructions, and the instructions can be underutilized due to the scarcity of labeled data. Then, we propose Unlabeled Data Augmented Instruction Tuning (UDIT) to take better advantage of the instructions during IT by constructing pseudo-labeled data from unlabeled plain texts. We conduct extensive experiments to show UDIT's effectiveness in various scenarios of tasks and datasets. We also comprehensively analyze the key factors of UDIT to investigate how to better improve IT with unlabeled data. The code is publicly available at https://github.com/thu-coai/UDIT",
    "checked": true,
    "id": "82cd40e926300b6b18c34ced2edeb07e84d9d6c7",
    "semantic_title": "learning instructions with unlabeled data for zero-shot cross-task generalization",
    "citation_count": 13,
    "authors": [
      "Yuxian Gu",
      "Pei Ke",
      "Xiaoyan Zhu",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.106": {
    "title": "Counterfactual Data Augmentation via Perspective Transition for Open-Domain Dialogues",
    "volume": "main",
    "abstract": "The construction of open-domain dialogue systems requires high-quality dialogue datasets. The dialogue data admits a wide variety of responses for a given dialogue history, especially responses with different semantics. However, collecting high-quality such a dataset in most scenarios is labor-intensive and time-consuming. In this paper, we propose a data augmentation method to automatically augment high-quality responses with different semantics by counterfactual inference. Specifically, given an observed dialogue, our counterfactual generation model first infers semantically different responses by replacing the observed reply perspective with substituted ones. Furthermore, our data selection method filters out detrimental augmented responses. Experimental results show that our data augmentation method can augment high-quality responses with different semantics for a given dialogue history, and can outperform competitive baselines on multiple downstream tasks",
    "checked": true,
    "id": "441cf3eed469ee58af1f036f4cfae938a0c6023e",
    "semantic_title": "counterfactual data augmentation via perspective transition for open-domain dialogues",
    "citation_count": 11,
    "authors": [
      "Jiao Ou",
      "Jinchao Zhang",
      "Yang Feng",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.107": {
    "title": "SQUIRE: A Sequence-to-sequence Framework for Multi-hop Knowledge Graph Reasoning",
    "volume": "main",
    "abstract": "Multi-hop knowledge graph (KG) reasoning has been widely studied in recent years to provide interpretable predictions on missing links with evidential paths. Most previous works use reinforcement learning (RL) based methods that learn to navigate the path towards the target entity. However, these methods suffer from slow and poor convergence, and they may fail to infer a certain path when there is a missing edge along the path. Here we present SQUIRE, the first Sequence-to-sequence based multi-hop reasoning framework, which utilizes an encoder-decoder Transformer structure to translate the query to a path. Our framework brings about two benefits: (1) It can learn and predict in an end-to-end fashion, which gives better and faster convergence; (2) Our transformer model does not rely on existing edges to generate the path, and has the flexibility to complete missing edges along the path, especially in sparse KGs. Experiments on standard and sparse KGs show that our approach yields significant improvement over prior methods, while converging 4x-7x faster",
    "checked": true,
    "id": "412bc1caf92614838749dcfce104776a36fdb7d7",
    "semantic_title": "squire: a sequence-to-sequence framework for multi-hop knowledge graph reasoning",
    "citation_count": 9,
    "authors": [
      "Yushi Bai",
      "Xin Lv",
      "Juanzi Li",
      "Lei Hou",
      "Yincen Qu",
      "Zelin Dai",
      "Feiyu Xiong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.108": {
    "title": "SpeechUT: Bridging Speech and Text with Hidden-Unit for Encoder-Decoder Based Speech-Text Pre-training",
    "volume": "main",
    "abstract": "The rapid development of single-modal pre-training has prompted researchers to pay more attention to cross-modal pre-training methods. In this paper, we propose a unified-modal speech-unit-text pre-training model, SpeechUT, to connect the representations of a speech encoder and a text decoder with a shared unit encoder. Leveraging hidden-unit as an interface to align speech and text, we can decompose the speech-to-text model into a speech-to-unit model and a unit-to-text model, which can be jointly pre-trained with unpaired speech and text data respectively. Our proposed SpeechUT is fine-tuned and evaluated on automatic speech recognition (ASR) and speech translation (ST) tasks. Experimental results show that SpeechUT gets substantial improvements over strong baselines, and achieves state-of-the-art performance on both the LibriSpeech ASR and MuST-C ST tasks. To better understand the proposed SpeechUT, detailed analyses are conducted. The code and pre-trained models are available at https://aka.ms/SpeechUT",
    "checked": true,
    "id": "628fb0736c5484f7a0006d0bb2d4a7a2ef9ae6b3",
    "semantic_title": "speechut: bridging speech and text with hidden-unit for encoder-decoder based speech-text pre-training",
    "citation_count": 46,
    "authors": [
      "Ziqiang Zhang",
      "Long Zhou",
      "Junyi Ao",
      "Shujie Liu",
      "Lirong Dai",
      "Jinyu Li",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.109": {
    "title": "Learning Label Modular Prompts for Text Classification in the Wild",
    "volume": "main",
    "abstract": "Machine learning models usually assume i.i.d data during training and testing, but data and tasks in real world often change over time. To emulate the transient nature of real world, we propose a challenging but practical task: text classification in-the-wild, which introduces different non-stationary training/testing stages. Decomposing a complex task into modular components can enable robust generalisation under such non-stationary environment. However, current modular approaches in NLP do not take advantage of recent advances in parameter efficient tuning of pretrained language models. To close this gap, we propose ModularPrompt, a label-modular prompt tuning framework for text classification tasks. In ModularPrompt, the input prompt consists of a sequence of soft label prompts, each encoding modular knowledge related to the corresponding class label. In two of most formidable settings, ModularPrompt outperforms relevant baselines by a large margin demonstrating strong generalisation ability. We also conduct comprehensive analysis to validate whether the learned prompts satisfy properties of a modular representation",
    "checked": true,
    "id": "082c3b929eef0a1e31389c0239d1b110c88de3f4",
    "semantic_title": "learning label modular prompts for text classification in the wild",
    "citation_count": 5,
    "authors": [
      "Hailin Chen",
      "Amrita Saha",
      "Shafiq Joty",
      "Steven C.H. Hoi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.110": {
    "title": "Unbiased and Efficient Sampling of Dependency Trees",
    "volume": "main",
    "abstract": "Most computational models of dependency syntax consist of distributions over spanning trees. However, the majority of dependency treebanks require that every valid dependency tree has a single edge coming out of the ROOT node, a constraint that is not part of the definition of spanning trees. For this reason all standard inference algorithms for spanning trees are sub-optimal for inference over dependency trees.Zmigrod et al (2021) proposed algorithms for sampling with and without replacement from the dependency tree distribution that incorporate the single-root constraint. In this paper we show that their fastest algorithm for sampling with replacement, Wilson-RC, is in fact producing biased samples and we provide two alternatives that are unbiased. Additionally, we propose two algorithms (one incremental, one parallel) that reduce the asymptotic runtime of algorithm for sampling k trees without replacement to O(kn^3). These algorithms are both asymptotically and practically more efficient",
    "checked": true,
    "id": "49457ad0eb4159a0186f59a11c7bc891cb8d29b2",
    "semantic_title": "unbiased and efficient sampling of dependency trees",
    "citation_count": 3,
    "authors": [
      "Miloš Stanojević"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.111": {
    "title": "Continual Learning of Neural Machine Translation within Low Forgetting Risk Regions",
    "volume": "main",
    "abstract": "This paper considers continual learning of large-scale pretrained neural machine translation model without accessing the previous training data or introducing model separation. We argue that the widely used regularization-based methods, which perform multi-objective learning with an auxiliary loss, suffer from the misestimate problem and cannot always achieve a good balance between the previous and new tasks. To solve the problem, we propose a two-stage training method based on the local features of the real loss. We first search low forgetting risk regions, where the model can retain the performance on the previous task as the parameters are updated, to avoid the catastrophic forgetting problem. Then we can continually train the model within this region only with the new training data to fit the new task. Specifically, we propose two methods to search the low forgetting risk regions, which are based on the curvature of loss and the impacts of the parameters on the model output, respectively. We conduct experiments on domain adaptation and more challenging language adaptation tasks, and the experimental results show that our method can achieve significant improvements compared with several strong baselines",
    "checked": true,
    "id": "b6ea823efc131c8a061ccaab9df7ee9aec746c21",
    "semantic_title": "continual learning of neural machine translation within low forgetting risk regions",
    "citation_count": 5,
    "authors": [
      "Shuhao Gu",
      "Bojie Hu",
      "Yang Feng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.112": {
    "title": "COST-EFF: Collaborative Optimization of Spatial and Temporal Efficiency with Slenderized Multi-exit Language Models",
    "volume": "main",
    "abstract": "Transformer-based pre-trained language models (PLMs) mostly suffer from excessive overhead despite their advanced capacity. For resource-constrained devices, there is an urgent need for a spatially and temporally efficient model which retains the major capacity of PLMs. However, existing statically compressed models are unaware of the diverse complexities between input instances, potentially resulting in redundancy and inadequacy for simple and complex inputs. Also, miniature models with early exiting encounter challenges in the trade-off between making predictions and serving the deeper layers. Motivated by such considerations, we propose a collaborative optimization for PLMs that integrates static model compression and dynamic inference acceleration. Specifically, the PLM is slenderized in width while the depth remains intact, complementing layer-wise early exiting to speed up inference dynamically. To address the trade-off of early exiting, we propose a joint training approach that calibrates slenderization and preserves contributive structures to each exit instead of only the final layer. Experiments are conducted on GLUE benchmark and the results verify the Pareto optimality of our approach at high compression and acceleration rate with 1/8 parameters and 1/19 FLOPs of BERT",
    "checked": true,
    "id": "7d0cda80884e1408e50e07ecae8001883eaf52c7",
    "semantic_title": "cost-eff: collaborative optimization of spatial and temporal efficiency with slenderized multi-exit language models",
    "citation_count": 3,
    "authors": [
      "Bowen Shen",
      "Zheng Lin",
      "Yuanxin Liu",
      "Zhengxiao Liu",
      "Lei Wang",
      "Weiping Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.113": {
    "title": "Rescue Implicit and Long-tail Cases: Nearest Neighbor Relation Extraction",
    "volume": "main",
    "abstract": "Relation extraction (RE) has achieved remarkable progress with the help of pre-trained language models. However, existing RE models are usually incapable of handling two situations: implicit expressions and long-tail relation types, caused by language complexity and data sparsity. In this paper, we introduce a simple enhancement of RE using k nearest neighbors (kNN-RE). kNN-RE allows the model to consult training relations at test time through a nearest-neighbor search and provides a simple yet effective means to tackle the two issues above. Additionally, we observe that kNN-RE serves as an effective way to leverage distant supervision (DS) data for RE. Experimental results show that the proposed kNN-RE achieves state-of-the-art performances on a variety of supervised RE datasets, i.e., ACE05, SciERC, and Wiki80, along with outperforming the best model to date on the i2b2 and Wiki80 datasets in the setting of allowing using DS. Our code and models are available at: https://github.com/YukinoWan/kNN-RE",
    "checked": true,
    "id": "c556fe9ffabd1138c4ac141254e6f16a082f8f4b",
    "semantic_title": "rescue implicit and long-tail cases: nearest neighbor relation extraction",
    "citation_count": 6,
    "authors": [
      "Zhen Wan",
      "Qianying Liu",
      "Zhuoyuan Mao",
      "Fei Cheng",
      "Sadao Kurohashi",
      "Jiwei Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.114": {
    "title": "StoryER: Automatic Story Evaluation via Ranking, Rating and Reasoning",
    "volume": "main",
    "abstract": "Existing automatic story evaluation methods place a premium on story lexical level coherence, deviating from human preference.We go beyond this limitation by considering a novel Story Evaluation method that mimics human preference when judging a story, namely StoryER, which consists of three sub-tasks: Ranking, Rating and Reasoning.Given either a machine-generated or a human-written story, StoryER requires the machine to output 1) a preference score that corresponds to human preference, 2) specific ratings and their corresponding confidences and 3) comments for various aspects (e.g., opening, character-shaping).To support these tasks, we introduce a well-annotated dataset comprising (i) 100k ranked story pairs; and (ii) a set of 46k ratings and comments on various aspects of the story.We finetune Longformer-Encoder-Decoder (LED) on the collected dataset, with the encoder responsible for preference score and aspect prediction and the decoder for comment generation.Our comprehensive experiments result a competitive benchmark for each task, showing the high correlation to human preference.In addition, we have witnessed the joint learning of the preference scores, the aspect ratings, and the comments brings gain each single task.Our dataset and benchmarks are publicly available to advance the research of story evaluation tasks",
    "checked": true,
    "id": "e20a151db8101c17b7c574ee471ddf171999864e",
    "semantic_title": "storyer: automatic story evaluation via ranking, rating and reasoning",
    "citation_count": 14,
    "authors": [
      "Hong Chen",
      "Duc Vo",
      "Hiroya Takamura",
      "Yusuke Miyao",
      "Hideki Nakayama"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.115": {
    "title": "Enhancing Self-Consistency and Performance of Pre-Trained Language Models through Natural Language Inference",
    "volume": "main",
    "abstract": "While large pre-trained language models are powerful, their predictions often lack logical consistency across test inputs. For example, a state-of-the-art Macaw question-answering (QA) model answers <i>Yes</i> to <i>Is a sparrow a bird?</i> and <i>Does a bird have feet?</i> but answers <i>No</i> to <i>Does a sparrow have feet?</i>. To address this failure mode, we propose a framework, Consistency Correction through Relation Detection, or <b>ConCoRD</b>, for boosting the consistency and accuracy of pre-trained NLP models using pre-trained natural language inference (NLI) models without fine-tuning or re-training. Given a batch of test inputs, ConCoRD samples several candidate outputs for each input and instantiates a factor graph that accounts for both the model's belief about the likelihood of each answer choice in isolation and the NLI model's beliefs about pair-wise answer choice compatibility. We show that a weighted MaxSAT solver can efficiently compute high-quality answer choices under this factor graph, improving over the raw model's predictions. Our experiments demonstrate that ConCoRD consistently boosts accuracy and consistency of off-the-shelf closed-book QA and VQA models using off-the-shelf NLI models, notably increasing accuracy of LXMERT on ConVQA by 5% absolute. See the project website (https://ericmitchell.ai/emnlp-2022-concord/) for code and data",
    "checked": true,
    "id": "529e997e0d9730c25ad4347502da7e5a753274b8",
    "semantic_title": "enhancing self-consistency and performance of pre-trained language models through natural language inference",
    "citation_count": 22,
    "authors": [
      "Eric Mitchell",
      "Joseph Noh",
      "Siyan Li",
      "Will Armstrong",
      "Ananth Agarwal",
      "Patrick Liu",
      "Chelsea Finn",
      "Christopher Manning"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.116": {
    "title": "Robustness of Demonstration-based Learning Under Limited Data Scenario",
    "volume": "main",
    "abstract": "Demonstration-based learning has shown great potential in stimulating pretrained language models' ability under limited data scenario. Simply augmenting the input with some demonstrations can significantly improve performance on few-shot NER. However, why such demonstrations are beneficial for the learning process remains unclear since there is no explicit alignment between the demonstrations and the predictions. In this paper, we design pathological demonstrations by gradually removing intuitively useful information from the standard ones to take a deep dive of the robustness of demonstration-based sequence labeling and show that (1) demonstrations composed of random tokens still make the model a better few-shot learner; (2) the length of random demonstrations and the relevance of random tokens are the main factors affecting the performance; (3) demonstrations increase the confidence of model predictions on captured superficial patterns. We have publicly released our code at https://github.com/SALT-NLP/RobustDemo",
    "checked": true,
    "id": "9a523de464d0096a4f2f722ecda5ef11a42bc6eb",
    "semantic_title": "robustness of demonstration-based learning under limited data scenario",
    "citation_count": 11,
    "authors": [
      "Hongxin Zhang",
      "Yanzhe Zhang",
      "Ruiyi Zhang",
      "Diyi Yang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.117": {
    "title": "Modeling Information Change in Science Communication with Semantically Matched Paraphrases",
    "volume": "main",
    "abstract": "Whether the media faithfully communicate scientific information has long been a core issue to the science community. Automatically identifying paraphrased scientific findings could enable large-scale tracking and analysis of information changes in the science communication process, but this requires systems to understand the similarity between scientific information across multiple domains. To this end, we present the SCIENTIFIC PARAPHRASE AND INFORMATION CHANGE DATASET (SPICED), the first paraphrase dataset of scientific findings annotated for degree of information change. SPICED contains 6,000 scientific finding pairs extracted from news stories, social media discussions, and full texts of original papers. We demonstrate that SPICED poses a challenging task and that models trained on SPICED improve downstream performance on evidence retrieval for fact checking of real-world scientific claims. Finally, we show that models trained on SPICED can reveal large-scale trends in the degrees to which people and organizations faithfully communicate new scientific findings. Data, code, and pre-trained models are available at http://www.copenlu.com/publication/2022_emnlp_wright/",
    "checked": true,
    "id": "0b7cc0e510ef05ad394a36d9cee9ddf5f2ae912f",
    "semantic_title": "modeling information change in science communication with semantically matched paraphrases",
    "citation_count": 13,
    "authors": [
      "Dustin Wright",
      "Jiaxin Pei",
      "David Jurgens",
      "Isabelle Augenstein"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.118": {
    "title": "Word Order Matters When You Increase Masking",
    "volume": "main",
    "abstract": "Word order, an essential property of natural languages, is injected in Transformer-based neural language models using position encoding. However, recent experiments have shown that explicit position encoding is not always useful, since some models without such feature managed to achieve state-of-the art performance on some tasks. To understand better this phenomenon, we examine the effect of removing position encodings on the pre-training objective itself (i.e., masked language modelling), to test whether models can reconstruct position information from co-occurrences alone. We do so by controlling the amount of masked tokens in the input sentence, as a proxy to affect the importance of position information for the task. We find that the necessity of position information increases with the amount of masking, and that masked language models without position encodings are not able to reconstruct this information on the task. These findings point towards a direct relationship between the amount of masking and the ability of Transformers to capture order-sensitive aspects of language using position encoding",
    "checked": true,
    "id": "ca0f43ae0e80deeac39b71822e63928b56031132",
    "semantic_title": "word order matters when you increase masking",
    "citation_count": 5,
    "authors": [
      "Karim Lasri",
      "Alessandro Lenci",
      "Thierry Poibeau"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.119": {
    "title": "An Empirical Analysis of Memorization in Fine-tuned Autoregressive Language Models",
    "volume": "main",
    "abstract": "Large language models are shown to present privacy risks through memorization of training data, andseveral recent works have studied such risks for the pre-training phase. Little attention, however, has been given to the fine-tuning phase and it is not well understood how different fine-tuning methods (such as fine-tuning the full model, the model head, and adapter) compare in terms of memorization risk. This presents increasing concern as the \"pre-train and fine-tune\" paradigm proliferates. In this paper, we empirically study memorization of fine-tuning methods using membership inference and extraction attacks, and show that their susceptibility to attacks is very different. We observe that fine-tuning the head of the model has the highest susceptibility to attacks, whereas fine-tuning smaller adapters appears to be less vulnerable to known extraction attacks",
    "checked": true,
    "id": "51256ee5425d5c425b84e7fac011775d8eff0d1c",
    "semantic_title": "an empirical analysis of memorization in fine-tuned autoregressive language models",
    "citation_count": 37,
    "authors": [
      "Fatemehsadat Mireshghallah",
      "Archit Uniyal",
      "Tianhao Wang",
      "David Evans",
      "Taylor Berg-Kirkpatrick"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.120": {
    "title": "Style Transfer as Data Augmentation: A Case Study on Named Entity Recognition",
    "volume": "main",
    "abstract": "In this work, we take the named entity recognition task in the English language as a case study and explore style transfer as a data augmentation method to increase the size and diversity of training data in low-resource scenarios. We propose a new method to effectively transform the text from a high-resource domain to a low-resource domain by changing its style-related attributes to generate synthetic data for training. Moreover, we design a constrained decoding algorithm along with a set of key ingredients for data selection to guarantee the generation of valid and coherent data. Experiments and analysis on five different domain pairs under different data regimes demonstrate that our approach can significantly improve results compared to current state-of-the-art data augmentation methods. Our approach is a practical solution to data scarcity, and we expect it to be applicable to other NLP tasks",
    "checked": true,
    "id": "aea66d304c5126b9c5fb1fe4ea3360dc222877c4",
    "semantic_title": "style transfer as data augmentation: a case study on named entity recognition",
    "citation_count": 3,
    "authors": [
      "Shuguang Chen",
      "Leonardo Neves",
      "Thamar Solorio"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.121": {
    "title": "Linguistic Corpus Annotation for Automatic Text Simplification Evaluation",
    "volume": "main",
    "abstract": "Evaluating automatic text simplification (ATS) systems is a difficult task that is either performed by automatic metrics or user-based evaluations. However, from a linguistic point-of-view, it is not always clear on what bases these evaluations operate. In this paper, we propose annotations of the ASSET corpus that can be used to shed more light on ATS evaluation. In addition to contributing with this resource, we show how it can be used to analyze SARI's behavior and to re-evaluate existing ATS systems. We present our insights as a step to improve ATS evaluation protocols in the future",
    "checked": true,
    "id": "de889e6d098c753a1302f1a1b09e141d251b9a40",
    "semantic_title": "linguistic corpus annotation for automatic text simplification evaluation",
    "citation_count": 9,
    "authors": [
      "Rémi Cardon",
      "Adrien Bibal",
      "Rodrigo Wilkens",
      "David Alfter",
      "Magali Norré",
      "Adeline Müller",
      "Watrin Patrick",
      "Thomas François"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.122": {
    "title": "Semantic Framework based Query Generation for Temporal Question Answering over Knowledge Graphs",
    "volume": "main",
    "abstract": "Answering factual questions with temporal intent over knowledge graphs (temporal KGQA) attracts rising attention in recent years.In the generation of temporal queries, existing KGQA methods ignore the fact that some intrinsic connections between events can make them temporally related, which may limit their capability.We systematically analyze the possible interpretation of temporal constraints and conclude the interpretation structures as the Semantic Framework of Temporal Constraints, SF-TCons.Based on the semantic framework, we propose a temporal question answering method, SF-TQA, which generates query graphs by exploring the relevant facts of mentioned entities, where the exploring process is restricted by SF-TCons. Our evaluations show that SF-TQA significantly outperforms existing methods on two benchmarks over different knowledge graphs",
    "checked": true,
    "id": "dae3e7d6a490f90a9faa8a22386652bddc8928c3",
    "semantic_title": "semantic framework based query generation for temporal question answering over knowledge graphs",
    "citation_count": 1,
    "authors": [
      "Wentao Ding",
      "Hao Chen",
      "Huayu Li",
      "Yuzhong Qu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.123": {
    "title": "There Is No Standard Answer: Knowledge-Grounded Dialogue Generation with Adversarial Activated Multi-Reference Learning",
    "volume": "main",
    "abstract": "Knowledge-grounded dialogue (KGC) shows excellent potential to deliver an engaging and informative response. However, existing approaches emphasize selecting one golden knowledge given a particular dialogue context, overlooking the one-to-many phenomenon in dialogue. As a result, existing paradigm limits the diversity of knowledge selection and generation. To this end, we establish a multi-reference KGC dataset and propose a series of metrics to systematically assess the one-to-many efficacy of existing KGC models. Furthermore, to extend the hypothesis space of knowledge selection to enhance the mapping relationship between multiple knowledge and multiple responses, we devise a span-based variational model and optimize the model in a wake-sleep style with an ameliorated evidence lower bound objective to learn the one-to-many generalization. Both automatic and human evaluations demonstrate the efficacy of our approach",
    "checked": true,
    "id": "b305c995821c6e9510b9c20e966bb9a6f4658bfe",
    "semantic_title": "there is no standard answer: knowledge-grounded dialogue generation with adversarial activated multi-reference learning",
    "citation_count": 3,
    "authors": [
      "Xueliang Zhao",
      "Tingchen Fu",
      "Chongyang Tao",
      "Rui Yan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.124": {
    "title": "Stop Measuring Calibration When Humans Disagree",
    "volume": "main",
    "abstract": "Calibration is a popular framework to evaluate whether a classifier knows when it does not know - i.e., its predictive probabilities are a good indication of how likely a prediction is to be correct. Correctness is commonly estimated against the human majority class. Recently, calibration to human majority has been measured on tasks where humans inherently disagree about which class applies. We show that measuring calibration to human majority given inherent disagreements is theoretically problematic, demonstrate this empirically on the ChaosNLI dataset, and derive several instance-level measures of calibration that capture key statistical properties of human judgements - including class frequency, ranking and entropy",
    "checked": true,
    "id": "851e71163d86368deb6b6d6ed5e5d2187c782ff4",
    "semantic_title": "stop measuring calibration when humans disagree",
    "citation_count": 26,
    "authors": [
      "Joris Baan",
      "Wilker Aziz",
      "Barbara Plank",
      "Raquel Fernandez"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.125": {
    "title": "Improving compositional generalization for multi-step quantitative reasoning in question answering",
    "volume": "main",
    "abstract": "Quantitative reasoning is an important aspect of question answering, especially when numeric and verbal cues interact to indicate sophisticated, multi-step programs. In this paper, we demonstrate how modeling the compositional nature of quantitative text can enhance the performance and robustness of QA models, allowing them to capture arithmetic logic that is expressed verbally. Borrowing from the literature on semantic parsing, we propose a method that encourages the QA models to adjust their attention patterns and capture input/output alignments that are meaningful to the reasoning task. We show how this strategy improves program accuracy and renders the models more robust against overfitting as the number of reasoning steps grows. Our approach is designed as a standalone module which can be prepended to many existing models and trained in an end-to-end fashion without the need for additional supervisory signal. As part of this exercise, we also create a unified dataset building on four previously released numerical QA datasets over tabular data",
    "checked": true,
    "id": "834fd676114c0b6e077c735ddffd9fa14ee856d2",
    "semantic_title": "improving compositional generalization for multi-step quantitative reasoning in question answering",
    "citation_count": 1,
    "authors": [
      "Armineh Nourbakhsh",
      "Cathy Jiao",
      "Sameena Shah",
      "Carolyn Rosé"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.126": {
    "title": "A Comprehensive Comparison of Neural Networks as Cognitive Models of Inflection",
    "volume": "main",
    "abstract": "Neural networks have long been at the center of a debate around the cognitive mechanism by which humans process inflectional morphology. This debate has gravitated into NLP by way of the question: Are neural networks a feasible account for human behavior in morphological inflection?We address that question by measuring the correlation between human judgments and neural network probabilities for unknown word inflections. We test a larger range of architectures than previously studied on two important tasks for the cognitive processing debate: English past tense, and German number inflection. We find evidence that the Transformer may be a better account of human behavior than LSTMs on these datasets, and that LSTM features known to increase inflection accuracy do not always result in more human-like behavior",
    "checked": true,
    "id": "294a75d659657b4b3b1fb48e69bd9d09e485961c",
    "semantic_title": "a comprehensive comparison of neural networks as cognitive models of inflection",
    "citation_count": 2,
    "authors": [
      "Adam Wiemerslage",
      "Shiran Dudy",
      "Katharina Kann"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.127": {
    "title": "Can Visual Context Improve Automatic Speech Recognition for an Embodied Agent?",
    "volume": "main",
    "abstract": "The usage of automatic speech recognition (ASR) systems are becoming omnipresent ranging from personal assistant to chatbots, home, and industrial automation systems, etc. Modern robots are also equipped with ASR capabilities for interacting with humans as speech is the most natural interaction modality. However, ASR in robots faces additional challenges as compared to a personal assistant. Being an embodied agent, a robot must recognize the physical entities around it and therefore reliably recognize the speech containing the description of such entities. However, current ASR systems are often unable to do so due to limitations in ASR training, such as generic datasets and open-vocabulary modeling. Also, adverse conditions during inference, such as noise, accented, and far-field speech makes the transcription inaccurate. In this work, we present a method to incorporate a robot's visual information into an ASR system and improve the recognition of a spoken utterance containing a visible entity. Specifically, we propose a new decoder biasing technique to incorporate the visual context while ensuring the ASR output does not degrade for incorrect context. We achieve a 59% relative reduction in WER from an unmodified ASR system",
    "checked": true,
    "id": "0340479e8ac5a93d55a917db81c160380634f247",
    "semantic_title": "can visual context improve automatic speech recognition for an embodied agent?",
    "citation_count": 5,
    "authors": [
      "Pradip Pramanick",
      "Chayan Sarkar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.128": {
    "title": "AfroLID: A Neural Language Identification Tool for African Languages",
    "volume": "main",
    "abstract": "Language identification (LID) is a crucial precursor for NLP, especially for mining web data. Problematically, most of the world's 7000+ languages today are not covered by LID technologies. We address this pressing issue for Africa by introducing AfroLID, a neural LID toolkit for 517 African languages and varieties. AfroLID exploits a multi-domain web dataset manually curated from across 14 language families utilizing five orthographic systems. When evaluated on our blind Test set, AfroLID achieves 95.89 F_1-score. We also compare AfroLID to five existing LID tools that each cover a small number of African languages, finding it to outperform them on most languages. We further show the utility of AfroLID in the wild by testing it on the acutely under-served Twitter domain. Finally, we offer a number of controlled case studies and perform a linguistically-motivated error analysis that allow us to both showcase AfroLID's powerful capabilities and limitations",
    "checked": true,
    "id": "64ed1bffcd94b5abe3bcd5f6405f08652900c4be",
    "semantic_title": "afrolid: a neural language identification tool for african languages",
    "citation_count": 20,
    "authors": [
      "Ife Adebara",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed",
      "Alcides Inciarte"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.129": {
    "title": "EvEntS ReaLM: Event Reasoning of Entity States via Language Models",
    "volume": "main",
    "abstract": "This paper investigates models of event implications. Specifically, how well models predict entity state-changes, by targeting their understanding of physical attributes. Nominally, Large Language models (LLM) have been exposed to procedural knowledge about how objects interact, yet our benchmarking shows they fail to reason about the world. Conversely, we also demonstrate that existing approaches often misrepresent the surprising abilities of LLMs via improper task encodings and that proper model prompting can dramatically improve performance of reported baseline results across multiple tasks. In particular, our results indicate that our prompting technique is especially useful for unseen attributes (out-of-domain) or when only limited data is available",
    "checked": true,
    "id": "748a2700ec11f51560a69ec05c67ca9f97014be7",
    "semantic_title": "events realm: event reasoning of entity states via language models",
    "citation_count": 7,
    "authors": [
      "Evangelia Spiliopoulou",
      "Artidoro Pagnoni",
      "Yonatan Bisk",
      "Eduard Hovy"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.130": {
    "title": "Large language models are few-shot clinical information extractors",
    "volume": "main",
    "abstract": "A long-running goal of the clinical NLP community is the extraction of important variables trapped in clinical notes. However, roadblocks have included dataset shift from the general domain and a lack of public clinical corpora and annotations. In this work, we show that large language models, such as InstructGPT (Ouyang et al., 2022), perform well at zero- and few-shot information extraction from clinical text despite not being trained specifically for the clinical domain. Whereas text classification and generation performance have already been studied extensively in such models, here we additionally demonstrate how to leverage them to tackle a diverse set of NLP tasks which require more structured outputs, including span identification, token-level sequence classification, and relation extraction. Further, due to the dearth of available data to evaluate these systems, we introduce new datasets for benchmarking few-shot clinical information extraction based on a manual re-annotation of the CASI dataset (Moon et al., 2014) for new tasks. On the clinical extraction tasks we studied, the GPT-3 systems significantly outperform existing zero- and few-shot baselines",
    "checked": true,
    "id": "686d9ee744fa013cc21cdd86acd864c936e9e456",
    "semantic_title": "large language models are few-shot clinical information extractors",
    "citation_count": 209,
    "authors": [
      "Monica Agrawal",
      "Stefan Hegselmann",
      "Hunter Lang",
      "Yoon Kim",
      "David Sontag"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.131": {
    "title": "Towards a Unified Multi-Dimensional Evaluator for Text Generation",
    "volume": "main",
    "abstract": "Multi-dimensional evaluation is the dominant paradigm for human evaluation in Natural Language Generation (NLG), i.e., evaluating the generated text from multiple explainable dimensions, such as coherence and fluency. However, automatic evaluation in NLG is still dominated by similarity-based metrics, and we lack a reliable framework for a more comprehensive evaluation of advanced models. In this paper, we propose a unified multi-dimensional evaluator UniEval for NLG. We re-frame NLG evaluation as a Boolean Question Answering (QA) task, and by guiding the model with different questions, we can use one evaluator to evaluate from multiple dimensions. Furthermore, thanks to the unified Boolean QA format, we are able to introduce an intermediate learning phase that enables UniEval to incorporate external knowledge from multiple related tasks and gain further improvement. Experiments on three typical NLG tasks show that UniEval correlates substantially better with human judgments than existing metrics. Specifically, compared to the top-performing unified evaluators, UniEval achieves a 23% higher correlation on text summarization, and over 43% on dialogue response generation. Also, UniEval demonstrates a strong zero-shot learning ability for unseen evaluation dimensions and tasks. Source code, data, and all pre-trained evaluators are available at https://github.com/maszhongming/UniEval",
    "checked": true,
    "id": "041f5dbfcd07a3369ac44a6b902ee4b145eccf2b",
    "semantic_title": "towards a unified multi-dimensional evaluator for text generation",
    "citation_count": 157,
    "authors": [
      "Ming Zhong",
      "Yang Liu",
      "Da Yin",
      "Yuning Mao",
      "Yizhu Jiao",
      "Pengfei Liu",
      "Chenguang Zhu",
      "Heng Ji",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.132": {
    "title": "GeoMLAMA: Geo-Diverse Commonsense Probing on Multilingual Pre-Trained Language Models",
    "volume": "main",
    "abstract": "Recent work has shown that Pre-trained Language Models (PLMs) store the relational knowledge learned from data and utilize it for performing downstream tasks. However, commonsense knowledge across different regions may vary. For instance, the color of bridal dress is white in American weddings whereas it is red in Chinese weddings. In this paper, we introduce a benchmark dataset, Geo-diverse Commonsense Multilingual Language Models Analysis (GeoMLAMA), for probing the diversity of the relational knowledge in multilingual PLMs. GeoMLAMA contains 3125 prompts in English, Chinese, Hindi, Persian, and Swahili, with a wide coverage of concepts shared by people from American, Chinese, Indian, Iranian and Kenyan cultures. We benchmark 11 standard multilingual PLMs on GeoMLAMA. Interestingly, we find that 1) larger multilingual PLMs variants do not necessarily store geo-diverse concepts better than its smaller variant; 2) multilingual PLMs are not intrinsically biased towards knowledge from the Western countries (the United States); 3) the native language of a country may not be the best language to probe its knowledge and 4) a language may better probe knowledge about a non-native country than its native country",
    "checked": true,
    "id": "e3dae33c5bdf397abdefd971ea34c48fb836dcc0",
    "semantic_title": "geomlama: geo-diverse commonsense probing on multilingual pre-trained language models",
    "citation_count": 21,
    "authors": [
      "Da Yin",
      "Hritik Bansal",
      "Masoud Monajatipoor",
      "Liunian Harold Li",
      "Kai-Wei Chang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.133": {
    "title": "The (Undesired) Attenuation of Human Biases by Multilinguality",
    "volume": "main",
    "abstract": "Some human preferences are universal. The odor of vanilla is perceived as pleasant all around the world. We expect neural models trained on human texts to exhibit these kind of preferences, i.e. biases, but we show that this is not always the case. We explore 16 static and contextual embedding models in 9 languages and, when possible, compare them under similar training conditions. We introduce and release CA-WEAT, multilingual cultural aware tests to quantify biases, and compare them to previous English-centric tests. Our experiments confirm that monolingual static embeddings do exhibit human biases, but values differ across languages, being far from universal. Biases are less evident in contextual models, to the point that the original human association might be reversed. Multilinguality proves to be another variable that attenuates and even reverses the effect of the bias, specially in contextual multilingual models. In order to explain this variance among models and languages, we examine the effect of asymmetries in the training corpus, departures from isomorphism in multilingual embedding spaces and discrepancies in the testing measures between languages",
    "checked": true,
    "id": "53ec78653f92b4a679486dda207dea43cabe8611",
    "semantic_title": "the (undesired) attenuation of human biases by multilinguality",
    "citation_count": 8,
    "authors": [
      "Cristina España-Bonet",
      "Alberto Barrón-Cedeño"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.134": {
    "title": "Entailer: Answering Questions with Faithful and Truthful Chains of Reasoning",
    "volume": "main",
    "abstract": "Our goal is a question-answering (QA) system that can show how its answers are implied by its own internal beliefs via a systematic chain of reasoning. Such a capability would allow better understanding of why a model produced the answer it did. Our approach is to recursively combine a trained backward-chainingmodel, capable of generating a set of premises entailing an answer hypothesis, with a verifier that checks that the model itself believes those premises (and the entailment itself) through self-querying. To our knowledge, this is the first system to generate multistep chains that are both faithful (the answer follows from the reasoning) and truthful (the chain reflects the system's own internal beliefs). In evaluation using two different datasets, users judge that a majority (70%+) of generated chains clearly show how an answer follows from a set of facts - substantially better than a high-performance baseline - while preserving answer accuracy. By materializing model beliefs that systematically support an answer, new opportunities arise for understanding the model's system of belief, and diagnosing and correcting its misunderstandings when an answer is wrong",
    "checked": true,
    "id": "d400a649f0f0a3de22b89a268f48aff2dcb06a09",
    "semantic_title": "entailer: answering questions with faithful and truthful chains of reasoning",
    "citation_count": 40,
    "authors": [
      "Oyvind Tafjord",
      "Bhavana Dalvi Mishra",
      "Peter Clark"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.135": {
    "title": "Near-Negative Distinction: Giving a Second Life to Human Evaluation Datasets",
    "volume": "main",
    "abstract": "Precisely assessing the progress in natural language generation (NLG) tasks is challenging, and human evaluation to establish a preference in a model's output over another is often necessary.However, human evaluation is usually costly, difficult to reproduce, and non-reusable.In this paper, we propose a new and simple automatic evaluation method for NLG called Near-Negative Distinction (NND) that repurposes prior human annotations into NND tests.In an NND test, an NLG model must place a higher likelihood on a high-quality output candidate than on a near-negative candidate with a known error.Model performance is established by the number of NND tests a model passes, as well as the distribution over task-specific errors the model fails on.Through experiments on three NLG tasks (question generation, question answering, and summarization), we show that NND achieves a higher correlation with human judgments than standard NLG evaluation metrics. We then illustrate NND evaluation in four practical scenarios, for example performing fine-grain model analysis, or studying model training dynamics. Our findings suggest that NND can give a second life to human annotations and provide low-cost NLG evaluation",
    "checked": true,
    "id": "79032fc08981bbb0ae9ae353f399f0df8bdd25ee",
    "semantic_title": "near-negative distinction: giving a second life to human evaluation datasets",
    "citation_count": 4,
    "authors": [
      "Philippe Laban",
      "Chien-Sheng Wu",
      "Wenhao Liu",
      "Caiming Xiong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.136": {
    "title": "ToKen: Task Decomposition and Knowledge Infusion for Few-Shot Hate Speech Detection",
    "volume": "main",
    "abstract": "Hate speech detection is complex; it relies on commonsense reasoning, knowledge of stereotypes, and an understanding of social nuance that differs from one culture to the next. It is also difficult to collect a large-scale hate speech annotated dataset. In this work, we frame this problem as a few-shot learning task, and show significant gains with decomposing the task into its \"constituent\" parts. In addition, we see that infusing knowledge from reasoning datasets (e.g. ATOMIC2020) improves the performance even further. Moreover, we observe that the trained models generalize to out-of-distribution datasets, showing the superiority of task decomposition and knowledge infusion compared to previously used methods. Concretely, our method outperforms the baseline by 17.83% absolute gain in the 16-shot case",
    "checked": true,
    "id": "8f4e732131e10b1df25ed7b7786f36a0886e86c5",
    "semantic_title": "token: task decomposition and knowledge infusion for few-shot hate speech detection",
    "citation_count": 13,
    "authors": [
      "Badr AlKhamissi",
      "Faisal Ladhak",
      "Srinivasan Iyer",
      "Veselin Stoyanov",
      "Zornitsa Kozareva",
      "Xian Li",
      "Pascale Fung",
      "Lambert Mathias",
      "Asli Celikyilmaz",
      "Mona Diab"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.137": {
    "title": "Are Hard Examples also Harder to Explain? A Study with Human and Model-Generated Explanations",
    "volume": "main",
    "abstract": "Recent work on explainable NLP has shown that few-shot prompting can enable large pre-trained language models (LLMs) to generate grammatical and factual natural language explanations for data labels. In this work, we study the connection between explainability and sample hardness by investigating the following research question – \"Are LLMs and humans equally good at explaining data labels for both easy and hard samples?\" We answer this question by first collecting human-written explanations in the form of generalizable commonsense rules on the task of Winograd Schema Challenge (Winogrande dataset). We compare these explanations with those generated by GPT-3 while varying the hardness of the test samples as well as the in-context samples. We observe that (1) GPT-3 explanations are as grammatical as human explanations regardless of the hardness of the test samples, (2) for easy examples, GPT-3 generates highly supportive explanations but human explanations are more generalizable, and (3) for hard examples, human explanations are significantly better than GPT-3 explanations both in terms of label-supportiveness and generalizability judgements. We also find that hardness of the in-context examples impacts the quality of GPT-3 explanations. Finally, we show that the supportiveness and generalizability aspects of human explanations are also impacted by sample hardness, although by a much smaller margin than models",
    "checked": true,
    "id": "0040dac7a1bf7a1eeb01c86ddb993f331f35b158",
    "semantic_title": "are hard examples also harder to explain? a study with human and model-generated explanations",
    "citation_count": 12,
    "authors": [
      "Swarnadeep Saha",
      "Peter Hase",
      "Nazneen Rajani",
      "Mohit Bansal"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.138": {
    "title": "Stanceosaurus: Classifying Stance Towards Multicultural Misinformation",
    "volume": "main",
    "abstract": "We present Stanceosaurus, a new corpus of 28,033 tweets in English, Hindi and Arabic annotated with stance towards 250 misinformation claims. As far as we are aware, it is the largest corpus annotated with stance towards misinformation claims. The claims in Stanceosaurus originate from 15 fact-checking sources that cover diverse geographical regions and cultures. Unlike existing stance datasets, we introduce a more fine-grained 5-class labeling strategy with additional subcategories to distinguish implicit stance. Pre-trained transformer-based stance classifiers that are fine-tuned on our corpus show good generalization on unseen claims and regional claims from countries outside the training data. Cross-lingual experiments demonstrate Stanceosaurus' capability of training multilingual models, achieving 53.1 F1 on Hindi and 50.4 F1 on Arabic without any target-language fine-tuning. Finally, we show how a domain adaptation method can be used to improve performance on Stanceosaurus using additional RumourEval-2019 data. We will make Stanceosaurus publicly available to the research community upon publication and hope it will encourage further work on misinformation identification across languages and cultures",
    "checked": true,
    "id": "1ee9231e160121d8b27f9739b75db9cba58ed05c",
    "semantic_title": "stanceosaurus: classifying stance towards multicultural misinformation",
    "citation_count": 6,
    "authors": [
      "Jonathan Zheng",
      "Ashutosh Baheti",
      "Tarek Naous",
      "Wei Xu",
      "Alan Ritter"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.139": {
    "title": "Gendered Mental Health Stigma in Masked Language Models",
    "volume": "main",
    "abstract": "Mental health stigma prevents many individuals from receiving the appropriate care, and social psychology studies have shown that mental health tends to be overlooked in men. In this work, we investigate gendered mental health stigma in masked language models. In doing so, we operationalize mental health stigma by developing a framework grounded in psychology research: we use clinical psychology literature to curate prompts, then evaluate the models' propensity to generate gendered words. We find that masked language models capture societal stigma about gender in mental health: models are consistently more likely to predict female subjects than male in sentences about having a mental health condition (32% vs. 19%), and this disparity is exacerbated for sentences that indicate treatment-seeking behavior. Furthermore, we find that different models capture dimensions of stigma differently for men and women, associating stereotypes like anger, blame, and pity more with women with mental health conditions than with men. In showing the complex nuances of models' gendered mental health stigma, we demonstrate that context and overlapping dimensions of identity are important considerations when assessing computational models' social biases",
    "checked": true,
    "id": "e4d0ec7f52c054d171ef8d4ec4a389e0757c6ea3",
    "semantic_title": "gendered mental health stigma in masked language models",
    "citation_count": 15,
    "authors": [
      "Inna Lin",
      "Lucille Njoo",
      "Anjalie Field",
      "Ashish Sharma",
      "Katharina Reinecke",
      "Tim Althoff",
      "Yulia Tsvetkov"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.140": {
    "title": "Efficient Nearest Neighbor Search for Cross-Encoder Models using Matrix Factorization",
    "volume": "main",
    "abstract": "Efficient k-nearest neighbor search is a fundamental task, foundational for many problems in NLP. When the similarity is measured by dot-product between dual-encoder vectors or L2-distance, there already exist many scalable and efficient search methods. But not so when similarity is measured by more accurate and expensive black-box neural similarity models, such as cross-encoders, which jointly encode the query and candidate neighbor. The cross-encoders' high computational cost typically limits their use to reranking candidates retrieved by a cheaper model, such as dual encoder or TF-IDF. However, the accuracy of such a two-stage approach is upper-bounded by the recall of the initial candidate set, and potentially requires additional training to align the auxiliary retrieval model with the cross-encoder model. In this paper, we present an approach that avoids the use of a dual-encoder for retrieval, relying solely on the cross-encoder. Retrieval is made efficient with CUR decomposition, a matrix decomposition approach that approximates all pairwise cross-encoder distances from a small subset of rows and columns of the distance matrix. Indexing items using our approach is computationally cheaper than training an auxiliary dual-encoder model through distillation. Empirically, for k > 10, our approach provides test-time recall-vs-computational cost trade-offs superior to the current widely-used methods that re-rank items retrieved using a dual-encoder or TF-IDF",
    "checked": true,
    "id": "280eda29f3704b53f3488497c43983c131574c3e",
    "semantic_title": "efficient nearest neighbor search for cross-encoder models using matrix factorization",
    "citation_count": 10,
    "authors": [
      "Nishant Yadav",
      "Nicholas Monath",
      "Rico Angell",
      "Manzil Zaheer",
      "Andrew McCallum"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.141": {
    "title": "Prompt-and-Rerank: A Method for Zero-Shot and Few-Shot Arbitrary Textual Style Transfer with Small Language Models",
    "volume": "main",
    "abstract": "We propose a method for arbitrary textual style transfer (TST)—the task of transforming a text into any given style—utilizing general-purpose pre-trained language models. Our method, Prompt-and-Rerank, is based on a mathematical formulation of the TST task, decomposing it into three constituent components: textual similarity, target style strength, and fluency. Our method uses zero-shot or few-shot prompting to obtain a set of candidate generations in the target style, and then re-ranks them according to the three components. Our method enables small pre-trained language models to perform on par with state-of-the-art large-scale models while using two orders of magnitude less compute and memory. We also investigate the effect of model size and prompt design (e.g., prompt paraphrasing and delimiter-pair choice) on style transfer quality across seven diverse textual style transfer datasets, finding, among other things, that delimiter-pair choice has a large impact on performance, and that models have biases on the direction of style transfer",
    "checked": true,
    "id": "0d6bb585493e34975f0437faa3179db3a02f6ae8",
    "semantic_title": "prompt-and-rerank: a method for zero-shot and few-shot arbitrary textual style transfer with small language models",
    "citation_count": 50,
    "authors": [
      "Mirac Suzgun",
      "Luke Melas-Kyriazi",
      "Dan Jurafsky"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.142": {
    "title": "Learning to Decompose: Hypothetical Question Decomposition Based on Comparable Texts",
    "volume": "main",
    "abstract": "Explicit decomposition modeling, which involves breaking down complex tasks into more straightforward and often more interpretable sub-tasks, has long been a central theme in developing robust and interpretable NLU systems. However, despite the many datasets and resources built as part of this effort, the majority have small-scale annotations and limited scope, which is insufficient to solve general decomposition tasks. In this paper, we look at large-scale intermediate pre-training of decomposition-based transformers using distant supervision from comparable texts, particularly large-scale parallel news. We show that with such intermediate pre-training, developing robust decomposition-based models for a diverse range of tasks becomes more feasible. For example, on semantic parsing, our model, DecompT5, improves 20% to 30% on two datasets, Overnight and TORQUE, over the baseline language model. We further use DecompT5 to build a novel decomposition-based QA system named DecompEntail, improving over state-of-the-art models, including GPT-3, on both HotpotQA and StrategyQA by 8% and 4%, respectively",
    "checked": true,
    "id": "1d417bdd331912a458de920459f23fcc7f6e8699",
    "semantic_title": "learning to decompose: hypothetical question decomposition based on comparable texts",
    "citation_count": 15,
    "authors": [
      "Ben Zhou",
      "Kyle Richardson",
      "Xiaodong Yu",
      "Dan Roth"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.143": {
    "title": "Why is Winoground Hard? Investigating Failures in Visuolinguistic Compositionality",
    "volume": "main",
    "abstract": "Recent visuolinguistic pre-trained models show promising progress on various end tasks such as image retrieval and video captioning. Yet, they fail miserably on the recently proposed Winoground dataset, which challenges models to match paired images and English captions, with items constructed to overlap lexically but differ in meaning (e.g., \"there is a mug in some grass\" vs. \"there is some grass in a mug\"). By annotating the dataset using new fine-grained tags, we show that solving the Winoground task requires not just compositional language understanding, but a host of other abilities like commonsense reasoning or locating small, out-of-focus objects in low-resolution images. In this paper, we identify the dataset's main challenges through a suite of experiments on related tasks (probing task, image retrieval task), data augmentation, and manual inspection of the dataset. Our analysis suggests that a main challenge in visuolinguistic models may lie in fusing visual and textual representations, rather than in compositional language understanding. We release our annotation and code at https://github.com/ajd12342/why-winoground-hard",
    "checked": true,
    "id": "251ddd5faf30fc32e4ad6abbc402573ffec2b8a3",
    "semantic_title": "why is winoground hard? investigating failures in visuolinguistic compositionality",
    "citation_count": 26,
    "authors": [
      "Anuj Diwan",
      "Layne Berry",
      "Eunsol Choi",
      "David Harwath",
      "Kyle Mahowald"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.144": {
    "title": "Gradient-based Constrained Sampling from Language Models",
    "volume": "main",
    "abstract": "Large pretrained language models are successful at generating fluent text but are notoriously hard to controllably sample from. In this work, we study constrained sampling from such language models, i.e., generating text that satisfies user-defined constraints, while maintaining fluency and model's performance in a downstream task. We propose MuCoLa—a sampling procedure that combines the log-likelihood of the language model with arbitrary (differentiable) constraints in a single energy function, and then generates samples in a non-autoregressive manner. Specifically, it initializes the entire output sequence with noise and follows a Markov chain defined by Langevin Dynamics using the gradients of this energy. We evaluate MuCoLa on text generation with soft and hard constraints as well as their combinations, obtaining significant improvements over competitive baselines for toxicity avoidance, sentiment control, and keyword-guided generation",
    "checked": true,
    "id": "f1e56def812bc398d1b2b8c9a7ea6a623abd38e5",
    "semantic_title": "gradient-based constrained sampling from language models",
    "citation_count": 41,
    "authors": [
      "Sachin Kumar",
      "Biswajit Paria",
      "Yulia Tsvetkov"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.145": {
    "title": "TaCube: Pre-computing Data Cubes for Answering Numerical-Reasoning Questions over Tabular Data",
    "volume": "main",
    "abstract": "Existing auto-regressive pre-trained language models (PLMs) like T5 and BART, have been well applied to table question answering by UNIFIEDSKG and TAPEX, respectively, and demonstrated state-of-the-art results on multiple benchmarks. However, auto-regressive PLMs are challenged by recent emerging numerical reasoning datasets, such as TAT-QA, due to the error-prone implicit calculation. In this paper, we present TaCube, to pre-compute aggregation/arithmetic results for the table in advance, so that they are handy and readily available for PLMs to answer numerical reasoning questions. TaCube systematically and comprehensively covers a collection of computational operations over table segments. By simply concatenating TaCube to the input sequence of PLMs, it shows significant experimental effectiveness. TaCube promotes the F1 score from 49.6% to 66.2% on TAT-QA and achieves new state-of-the-art results on WikiTQ (59.6% denotation accuracy). TaCube's improvements on numerical reasoning cases are even more notable: on TAT-QA, TaCube promotes the exact match accuracy of BART-large by 39.6% on sum, 52.5% on average, 36.6% on substraction, and 22.2% on division. We believe that TaCube is a general and portable pre-computation solution that can be potentially integrated to various numerical reasoning frameworks",
    "checked": true,
    "id": "52b3087525b262f6f467453e22fdfa843353d40c",
    "semantic_title": "tacube: pre-computing data cubes for answering numerical-reasoning questions over tabular data",
    "citation_count": 22,
    "authors": [
      "Fan Zhou",
      "Mengkang Hu",
      "Haoyu Dong",
      "Zhoujun Cheng",
      "Fan Cheng",
      "Shi Han",
      "Dongmei Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.146": {
    "title": "Rich Knowledge Sources Bring Complex Knowledge Conflicts: Recalibrating Models to Reflect Conflicting Evidence",
    "volume": "main",
    "abstract": "Question answering models can use rich knowledge sources — up to one hundred retrieved passages and parametric knowledge in the large-scale language model (LM). Prior work assumes information in such knowledge sources is consistent with each other, paying little attention to how models blend information stored in their LM parameters with that from retrieved evidence documents. In this paper, we simulate knowledge conflicts (i.e., where parametric knowledge suggests one answer and different passages suggest different answers) and examine model behaviors. We find retrieval performance heavily impacts which sources models rely on, and current models mostly rely on non-parametric knowledgein their best-performing settings. We discover a troubling trend that contradictions among knowledge sources affect model confidence only marginally. To address this issue, we present a new calibration study, where models are discouraged from presenting any single answer when presented with multiple conflicting answer candidates in retrieved evidences",
    "checked": true,
    "id": "5b70e69b65b29d231d37bea354b25c05daec07e2",
    "semantic_title": "rich knowledge sources bring complex knowledge conflicts: recalibrating models to reflect conflicting evidence",
    "citation_count": 52,
    "authors": [
      "Hung-Ting Chen",
      "Michael Zhang",
      "Eunsol Choi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.147": {
    "title": "QA Domain Adaptation using Hidden Space Augmentation and Self-Supervised Contrastive Adaptation",
    "volume": "main",
    "abstract": "Question answering (QA) has recently shown impressive results for answering questions from customized domains. Yet, a common challenge is to adapt QA models to an unseen target domain. In this paper, we propose a novel self-supervised framework called QADA for QA domain adaptation. QADA introduces a novel data augmentation pipeline used to augment training QA samples. Different from existing methods, we enrich the samples via hidden space augmentation. For questions, we introduce multi-hop synonyms and sample augmented token embeddings with Dirichlet distributions. For contexts, we develop an augmentation method which learns to drop context spans via a custom attentive sampling strategy. Additionally, contrastive learning is integrated in the proposed self-supervised adaptation framework QADA. Unlike existing approaches, we generate pseudo labels and propose to train the model via a novel attention-based contrastive adaptation method. The attention weights are used to build informative features for discrepancy estimation that helps the QA model separate answers and generalize across source and target domains. To the best of our knowledge, our work is the first to leverage hidden space augmentation and attention-based contrastive adaptation for self-supervised domain adaptation in QA. Our evaluation shows that QADA achieves considerable improvements on multiple target datasets over state-of-the-art baselines in QA domain adaptation",
    "checked": true,
    "id": "3269250db1cca1b18f26be4224055a2ef9eeded6",
    "semantic_title": "qa domain adaptation using hidden space augmentation and self-supervised contrastive adaptation",
    "citation_count": 2,
    "authors": [
      "Zhenrui Yue",
      "Huimin Zeng",
      "Bernhard Kratzwald",
      "Stefan Feuerriegel",
      "Dong Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.148": {
    "title": "When FLUE Meets FLANG: Benchmarks and Large Pretrained Language Model for Financial Domain",
    "volume": "main",
    "abstract": "Pre-trained language models have shown impressive performance on a variety of tasks and domains. Previous research on financial language models usually employs a generic training scheme to train standard model architectures, without completely leveraging the richness of the financial data. We propose a novel domain specific Financial LANGuage model (FLANG) which uses financial keywords and phrases for better masking, together with span boundary objective and in-filing objective. Additionally, the evaluation benchmarks in the field have been limited. To this end, we contribute the Financial Language Understanding Evaluation (FLUE), an open-source comprehensive suite of benchmarks for the financial domain. These include new benchmarks across 5 NLP tasks in financial domain as well as common benchmarks used in the previous research. Experiments on these benchmarks suggest that our model outperforms those in prior literature on a variety of NLP tasks. Our models, code and benchmark data will be made publicly available on Github and Huggingface",
    "checked": true,
    "id": "0882a2b2787b35dbcc6e341c953d964b77abd4df",
    "semantic_title": "when flue meets flang: benchmarks and large pretrained language model for financial domain",
    "citation_count": 72,
    "authors": [
      "Raj Shah",
      "Kunal Chawla",
      "Dheeraj Eidnani",
      "Agam Shah",
      "Wendi Du",
      "Sudheer Chava",
      "Natraj Raman",
      "Charese Smiley",
      "Jiaao Chen",
      "Diyi Yang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.149": {
    "title": "Retrieval as Attention: End-to-end Learning of Retrieval and Reading within a Single Transformer",
    "volume": "main",
    "abstract": "Systems for knowledge-intensive tasks such as open-domain question answering (QA) usually consist of two stages: efficient retrieval of relevant documents from a large corpus and detailed reading of the selected documents. This is usually done through two separate models, a retriever that encodes the query and finds nearest neighbors, and a reader based on Transformers. These two components are usually modeled separately, which necessitates a cumbersome implementation and is awkward to optimize in an end-to-end fashion. In this paper, we revisit this design and eschew the separate architecture and training in favor of a single Transformer that performs retrieval as attention (RAA), and end-to-end training solely based on supervision from the end QA task. We demonstrate for the first time that an end-to-end trained single Transformer can achieve both competitive retrieval and QA performance on in-domain datasets, matching or even slightly outperforming state-of-the-art dense retrievers and readers. Moreover, end-to-end adaptation of our model significantly boosts its performance on out-of-domain datasets in both supervised and unsupervised settings, making our model a simple and adaptable end-to-end solution for knowledge-intensive tasks",
    "checked": true,
    "id": "87126a964ed14d0d2207747fc732b197e2fc9493",
    "semantic_title": "retrieval as attention: end-to-end learning of retrieval and reading within a single transformer",
    "citation_count": 32,
    "authors": [
      "Zhengbao Jiang",
      "Luyu Gao",
      "Zhiruo Wang",
      "Jun Araki",
      "Haibo Ding",
      "Jamie Callan",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.150": {
    "title": "Reproducibility in Computational Linguistics: Is Source Code Enough?",
    "volume": "main",
    "abstract": "The availability of source code has been put forward as one of the most critical factors for improving the reproducibility of scientific research. This work studies trends in source code availability at major computational linguistics conferences, namely, ACL, EMNLP, LREC, NAACL, and COLING. We observe positive trends, especially in conferences that actively promote reproducibility. We follow this by conducting a reproducibility study of eight papers published in EMNLP 2021, finding that source code releases leave much to be desired. Moving forward, we suggest all conferences require self-contained artifacts and provide a venue to evaluate such artifacts at the time of publication. Authors can include small-scale experiments and explicit scripts to generate each result to improve the reproducibility of their work",
    "checked": true,
    "id": "7c9975fedb81929f0115f1fb1f7b7535121f8c4e",
    "semantic_title": "reproducibility in computational linguistics: is source code enough?",
    "citation_count": 11,
    "authors": [
      "Mohammad Arvan",
      "Luís Pina",
      "Natalie Parde"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.151": {
    "title": "Generating Information-Seeking Conversations from Unlabeled Documents",
    "volume": "main",
    "abstract": "Synthesizing datasets for conversational question answering (CQA) from unlabeled documents remains challenging due to its interactive nature.Moreover, while modeling information needs is an essential key, only few studies have discussed it.In this paper, we introduce a novel framework, **SimSeek**, (**Sim**ulating information-**Seek**ing conversation from unlabeled documents), and compare its two variants.In our baseline, **SimSeek-sym**, a questioner generates follow-up questions upon the predetermined answer by an answerer.On the contrary, **SimSeek-asym** first generates the question and then finds its corresponding answer under the conversational context.Our experiments show that they can synthesize effective training resources for CQA and conversational search tasks.As a result, conversations from **SimSeek-asym** not only make more improvements in our experiments but also are favorably reviewed in a human evaluation.We finally release a large-scale resource of synthetic conversations, **Wiki-SimSeek**, containing 2 million CQA pairs built upon Wikipedia documents.With the dataset, our CQA model achieves the state-of-the-art performance on a recent CQA benchmark, QuAC.The code and dataset are available at https://github.com/naver-ai/simseek",
    "checked": true,
    "id": "c483861a011034b8972fec3a3ec76f28335b131c",
    "semantic_title": "generating information-seeking conversations from unlabeled documents",
    "citation_count": 8,
    "authors": [
      "Gangwoo Kim",
      "Sungdong Kim",
      "Kang Min Yoo",
      "Jaewoo Kang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.152": {
    "title": "Distill The Image to Nowhere: Inversion Knowledge Distillation for Multimodal Machine Translation",
    "volume": "main",
    "abstract": "Past works on multimodal machine translation (MMT) elevate bilingual setup by incorporating additional aligned vision information.However, an image-must requirement of the multimodal dataset largely hinders MMT's development — namely that it demands an aligned form of [image, source text, target text].This limitation is generally troublesome during the inference phase especially when the aligned image is not provided as in the normal NMT setup.Thus, in this work, we introduce IKD-MMT, a novel MMT framework to support the image-free inference phase via an inversion knowledge distillation scheme.In particular, a multimodal feature generator is executed with a knowledge distillation module, which directly generates the multimodal feature from (only) source texts as the input.While there have been a few prior works entertaining the possibility to support image-free inference for machine translation, their performances have yet to rival the image-must translation.In our experiments, we identify our method as the first image-free approach to comprehensively rival or even surpass (almost) all image-must frameworks, and achieved the state-of-the-art result on the often-used Multi30k benchmark. Our code and data are availableat: https://github.com/pengr/IKD-mmt/tree/master",
    "checked": true,
    "id": "d5fd95467722501a939c140506ab133b0dab1a2d",
    "semantic_title": "distill the image to nowhere: inversion knowledge distillation for multimodal machine translation",
    "citation_count": 6,
    "authors": [
      "Ru Peng",
      "Yawen Zeng",
      "Jake Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.153": {
    "title": "A Multifaceted Framework to Evaluate Evasion, Content Preservation, and Misattribution in Authorship Obfuscation Techniques",
    "volume": "main",
    "abstract": "Authorship obfuscation techniques have commonly been evaluated based on their ability to hide the author's identity (evasion) while preserving the content of the original text. However, to avoid overstating the systems' effectiveness, evasion detection must be evaluated using competitive identification techniques in settings that mimic real-life scenarios, and the outcomes of the content-preservation evaluation have to be interpretable by potential users of these obfuscation tools. Motivated by recent work on cross-topic authorship identification and content preservation in summarization, we re-evaluate different authorship obfuscation techniques on detection evasion and content preservation. Furthermore, we propose a new information-theoretic measure to characterize the misattribution harm that can be caused by detection evasion. Our results reveal key weaknesses in state-of-the-art obfuscation techniques and a surprisingly competitive effectiveness from a back-translation baseline in all evaluation aspects",
    "checked": true,
    "id": "6c3b1efa290f67048055b1d8e5ea803e4b7b588e",
    "semantic_title": "a multifaceted framework to evaluate evasion, content preservation, and misattribution in authorship obfuscation techniques",
    "citation_count": 3,
    "authors": [
      "Malik Altakrori",
      "Thomas Scialom",
      "Benjamin C. M. Fung",
      "Jackie Chi Kit Cheung"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.154": {
    "title": "SafeText: A Benchmark for Exploring Physical Safety in Language Models",
    "volume": "main",
    "abstract": "Understanding what constitutes safe text is an important issue in natural language processing and can often prevent the deployment of models deemed harmful and unsafe. One such type of safety that has been scarcely studied is commonsense physical safety, i.e. text that is not explicitly violent and requires additional commonsense knowledge to comprehend that it leads to physical harm. We create the first benchmark dataset, SafeText, comprising real-life scenarios with paired safe and physically unsafe pieces of advice. We utilize SafeText to empirically study commonsense physical safety across various models designed for text generation and commonsense reasoning tasks. We find that state-of-the-art large language models are susceptible to the generation of unsafe text and have difficulty rejecting unsafe advice. As a result, we argue for further studies of safety and the assessment of commonsense physical safety in models before release",
    "checked": true,
    "id": "2b6291eb76e2ff885238e94704bb795046d7d530",
    "semantic_title": "safetext: a benchmark for exploring physical safety in language models",
    "citation_count": 27,
    "authors": [
      "Sharon Levy",
      "Emily Allaway",
      "Melanie Subbiah",
      "Lydia Chilton",
      "Desmond Patton",
      "Kathleen McKeown",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.155": {
    "title": "Ground-Truth Labels Matter: A Deeper Look into Input-Label Demonstrations",
    "volume": "main",
    "abstract": "Despite recent explosion of interests in in-context learning, the underlying mechanism and the precise impact of the quality of demonstrations remain elusive.Intuitively, ground-truth labels should have as much impact in in-context learning (ICL) as supervised learning, but recent work reported that the input-label correspondence is significantly less important than previously thought.Intrigued by this counter-intuitive observation, we re-examine the importance of ground-truth labels in in-context learning.With the introduction of two novel metrics, namely Label-Correctness Sensitivity and Ground-truth Label Effect Ratio (GLER), we were able to conduct quantifiable analysis on the impact of ground-truth label demonstrations.Through extensive analyses, we find that the correct input-label mappings can have varying impacts on the downstream in-context learning performances, depending on the experimental configuration.Through additional studies, we identify key components, such as the verbosity of prompt templates and the language model size, as the controlling factor to achieve more noise-resilient ICL",
    "checked": true,
    "id": "316206a2f89eb94ce02a81fba1dc304586f21b39",
    "semantic_title": "ground-truth labels matter: a deeper look into input-label demonstrations",
    "citation_count": 94,
    "authors": [
      "Kang Min Yoo",
      "Junyeob Kim",
      "Hyuhng Joon Kim",
      "Hyunsoo Cho",
      "Hwiyeol Jo",
      "Sang-Woo Lee",
      "Sang-goo Lee",
      "Taeuk Kim"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.156": {
    "title": "D4: a Chinese Dialogue Dataset for Depression-Diagnosis-Oriented Chat",
    "volume": "main",
    "abstract": "In a depression-diagnosis-directed clinical session, doctors initiate a conversation with ample emotional support that guides the patients to expose their symptoms based on clinical diagnosis criteria. Such a dialogue system is distinguished from existing single-purpose human-machine dialog systems, as it combines task-oriented and chit-chats with uniqueness in dialogue topics and procedures. However, due to the social stigma associated with mental illness, the dialogue data related to depression consultation and diagnosis are rarely disclosed. Based on clinical depression diagnostic criteria ICD-11 and DSM-5, we designed a 3-phase procedure to construct D4: a Chinese Dialogue Dataset for Depression-Diagnosis-Oriented Chat, which simulates the dialogue between doctors and patients during the diagnosis of depression, including diagnosis results and symptom summary given by professional psychiatrists for each conversation. Upon the newly-constructed dataset, four tasks mirroring the depression diagnosis process are established: response generation, topic prediction, dialog summary, and severity classification of depressive episode and suicide risk. Multi-scale evaluation results demonstrate that a more empathy-driven and diagnostic-accurate consultation dialogue system trained on our dataset can be achieved compared to rule-based bots",
    "checked": true,
    "id": "29a1f9942b7b7070bfced1bdb7d33142afb61ca2",
    "semantic_title": "d4: a chinese dialogue dataset for depression-diagnosis-oriented chat",
    "citation_count": 14,
    "authors": [
      "Binwei Yao",
      "Chao Shi",
      "Likai Zou",
      "Lingfeng Dai",
      "Mengyue Wu",
      "Lu Chen",
      "Zhen Wang",
      "Kai Yu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.157": {
    "title": "Exploiting domain-slot related keywords description for Few-Shot Cross-Domain Dialogue State Tracking",
    "volume": "main",
    "abstract": "Collecting dialogue data with domain-slot-value labels for dialogue state tracking (DST) could be a costly process. In this paper, we propose a novel framework based on domain-slot related description to tackle the challenge of few-shot cross-domain DST. Specifically, we design an extraction module to extract domain-slot related verbs and nouns in the dialogue. Then, we integrates them into the description, which aims to prompt the model to identify the slot information. Furthermore, we introduce a random sampling strategy to improve the domain generalization ability of the model. We utilize a pre-trained model to encode contexts and description and generates answers with an auto-regressive manner. Experimental results show that our approaches substantially outperform the existing few-shot DST methods on MultiWOZ and gain strong improvements on the slot accuracy comparing to existing slot description methods",
    "checked": true,
    "id": "9bb08cfe401a07bfa274cd7730a68907773c7cd9",
    "semantic_title": "exploiting domain-slot related keywords description for few-shot cross-domain dialogue state tracking",
    "citation_count": 8,
    "authors": [
      "Gao Qixiang",
      "Guanting Dong",
      "Yutao Mou",
      "Liwen Wang",
      "Chen Zeng",
      "Daichi Guo",
      "Mingyang Sun",
      "Weiran Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.158": {
    "title": "CoCoa: An Encoder-Decoder Model for Controllable Code-switched Generation",
    "volume": "main",
    "abstract": "Code-switching has seen growing interest in recent years as an important multilingual NLP phenomenon. Generating code-switched text for data augmentation has been sufficiently well-explored. However, there is no prior work on generating code-switched text with fine-grained control on the degree of code-switching and the lexical choices used to convey formality. We present CoCoa, an encoder-decoder translation model that converts monolingual Hindi text to Hindi-English code-switched text with both encoder-side and decoder-side interventions to achieve fine-grained controllable generation. CoCoa can be invoked at test-time to synthesize code-switched text that is simultaneously faithful to syntactic and lexical attributes relevant to code-switching. CoCoa outputs were subjected to rigorous subjective and objective evaluations. Human evaluations establish that our outputs are of superior quality while being faithful to desired attributes. We show significantly improved BLEU scores when compared with human-generated code-switched references. Compared to competitive baselines, we show 10% reduction in perplexity on a language modeling task and also demonstrate clear improvements on a downstream code-switched sentiment analysis task",
    "checked": true,
    "id": "5c0dafd89765fff2dd10bb4863967a3dbdb311dd",
    "semantic_title": "cocoa: an encoder-decoder model for controllable code-switched generation",
    "citation_count": 7,
    "authors": [
      "Sneha Mondal",
      "Ritika .",
      "Shreya Pathak",
      "Preethi Jyothi",
      "Aravindan Raghuveer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.159": {
    "title": "Towards Climate Awareness in NLP Research",
    "volume": "main",
    "abstract": "The climate impact of AI, and NLP research in particular, has become a serious issue given the enormous amount of energy that is increasingly being used for training and running computational models. Consequently, increasing focus is placed on efficient NLP. However, this important initiative lacks simple guidelines that would allow for systematic climate reporting of NLP research. We argue that this deficiency is one of the reasons why very few publications in NLP report key figures that would allow a more thorough examination of environmental impact, and present a quantitative survey to demonstrate this. As a remedy, we propose a climate performance model card with the primary purpose of being practically usable with only limited information about experiments and the underlying computer hardware. We describe why this step is essential to increase awareness about the environmental impact of NLP research and, thereby, paving the way for more thorough discussions",
    "checked": true,
    "id": "8d0f755dea90f35f4b126a01fa3cce96b3bdd344",
    "semantic_title": "towards climate awareness in nlp research",
    "citation_count": 29,
    "authors": [
      "Daniel Hershcovich",
      "Nicolas Webersinke",
      "Mathias Kraus",
      "Julia Bingler",
      "Markus Leippold"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.160": {
    "title": "Navigating Connected Memories with a Task-oriented Dialog System",
    "volume": "main",
    "abstract": "Recent years have seen an increasing trend in the volume of personal media captured by users, thanks to the advent of smartphones and smart glasses, resulting in large media collections. Despite conversation being an intuitive human-computer interface, current efforts focus mostly on single-shot natural language based media retrieval to aid users query their media and re-live their memories. This severely limits the search functionality as users can neither ask follow-up queries nor obtain information without first formulating a single-turn query.In this work, we propose dialogs for connected memories as a powerful tool to empower users to search their media collection through a multi-turn, interactive conversation. Towards this, we collect a new task-oriented dialog dataset COMET, which contains 11.5k user↔assistant dialogs (totalling 103k utterances), grounded in simulated personal memory graphs. We employ a resource-efficient, two-phase data collection pipeline that uses: (1) a novel multimodal dialog simulator that generates synthetic dialog flows grounded in memory graphs, and, (2) manual paraphrasing to obtain natural language utterances. We analyze COMET, formulate four main tasks to benchmark meaningful progress, and adopt state-of-the-art language models as strong baselines, in order to highlight the multimodal challenges captured by our dataset",
    "checked": true,
    "id": "b4808fd7870a36f5e4a97816db230d8bbe1fabcd",
    "semantic_title": "navigating connected memories with a task-oriented dialog system",
    "citation_count": 2,
    "authors": [
      "Satwik Kottur",
      "Seungwhan Moon",
      "Alborz Geramifard",
      "Babak Damavandi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.161": {
    "title": "Language Model Decomposition: Quantifying the Dependency and Correlation of Language Models",
    "volume": "main",
    "abstract": "Pre-trained language models (LMs), such as BERT (Devlin et al., 2018) and its variants, have led to significant improvements on various NLP tasks in past years. However, a theoretical framework for studying their relationships is still missing. In this paper, we fill this gap by investigating the linear dependency between pre-trained LMs. The linear dependency of LMs is defined analogously to the linear dependency of vectors. We propose Language Model Decomposition (LMD) to represent a LM using a linear combination of other LMs as basis, and derive the closed-form solution. A goodness-of-fit metric for LMD similar to the coefficient of determination is defined and used to measure the linear dependency of a set of LMs. In experiments, we find that BERT and eleven (11) BERT-like LMs are 91% linearly dependent. This observation suggests that current state-of-the-art (SOTA) LMs are highly \"correlated\". To further advance SOTA we need more diverse and novel LMs that are less dependent on existing LMs",
    "checked": true,
    "id": "97fa7651ed8ffa2be62e40c97b55a4590741117e",
    "semantic_title": "language model decomposition: quantifying the dependency and correlation of language models",
    "citation_count": 0,
    "authors": [
      "Hao Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.162": {
    "title": "SynGEC: Syntax-Enhanced Grammatical Error Correction with a Tailored GEC-Oriented Parser",
    "volume": "main",
    "abstract": "This work proposes a syntax-enhanced grammatical error correction (GEC) approach named SynGEC that effectively incorporates dependency syntactic information into the encoder part of GEC models. The key challenge for this idea is that off-the-shelf parsers are unreliable when processing ungrammatical sentences. To confront this challenge, we propose to build a tailored GEC-oriented parser (GOPar) using parallel GEC training data as a pivot. First, we design an extended syntax representation scheme that allows us to represent both grammatical errors and syntax in a unified tree structure. Then, we obtain parse trees of the source incorrect sentences by projecting trees of the target correct sentences. Finally, we train GOPar with such projected trees. For GEC, we employ the graph convolution network to encode source-side syntactic information produced by GOPar, and fuse them with the outputs of the Transformer encoder. Experiments on mainstream English and Chinese GEC datasets show that our proposed SynGEC approach consistently and substantially outperforms strong baselines and achieves competitive performance. Our code and data are all publicly available at https://github.com/HillZhang1999/SynGEC",
    "checked": true,
    "id": "73c852f073c2d1a3b55a8465d33ae212e4fd7d59",
    "semantic_title": "syngec: syntax-enhanced grammatical error correction with a tailored gec-oriented parser",
    "citation_count": 33,
    "authors": [
      "Yue Zhang",
      "Bo Zhang",
      "Zhenghua Li",
      "Zuyi Bao",
      "Chen Li",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.163": {
    "title": "Varifocal Question Generation for Fact-checking",
    "volume": "main",
    "abstract": "Fact-checking requires retrieving evidence related to a claim under investigation. The task can be formulated as question generation based on a claim, followed by question answering.However, recent question generation approaches assume that the answer is known and typically contained in a passage given as input,whereas such passages are what is being sought when verifying a claim.In this paper, we present Varifocal, a method that generates questions based on different focal points within a given claim, i.e. different spans of the claim and its metadata, such as its source and date.Our method outperforms previous work on a fact-checking question generation dataset on a wide range of automatic evaluation metrics.These results are corroborated by our manual evaluation, which indicates that our method generates more relevant and informative questions.We further demonstrate the potential of focal points in generating sets of clarification questions for product descriptions",
    "checked": true,
    "id": "be050e69aadd6461ff3bc35dcfa7a551742ef840",
    "semantic_title": "varifocal question generation for fact-checking",
    "citation_count": 13,
    "authors": [
      "Nedjma Ousidhoum",
      "Zhangdie Yuan",
      "Andreas Vlachos"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.164": {
    "title": "Bilingual Lexicon Induction for Low-Resource Languages using Graph Matching via Optimal Transport",
    "volume": "main",
    "abstract": "Bilingual lexicons form a critical component of various natural language processing applications, including unsupervised and semisupervised machine translation and crosslingual information retrieval. In this work, we improve bilingual lexicon induction performance across 40 language pairs with a graph-matching method based on optimal transport. The method is especially strong with low amounts of supervision",
    "checked": true,
    "id": "0d1bceb56cfb765b46886ee83f1d6a498d6ea61a",
    "semantic_title": "bilingual lexicon induction for low-resource languages using graph matching via optimal transport",
    "citation_count": 4,
    "authors": [
      "Kelly Marchisio",
      "Ali Saad-Eldin",
      "Kevin Duh",
      "Carey Priebe",
      "Philipp Koehn"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.165": {
    "title": "Whose Language Counts as High Quality? Measuring Language Ideologies in Text Data Selection",
    "volume": "main",
    "abstract": "Language models increasingly rely on massive web crawls for diverse text data. However, these sources are rife with undesirable content. As such, resources like Wikipedia, books, and news often serve as anchors for automatically selecting web text most suitable for language modeling, a process typically referred to as quality filtering. Using a new dataset of U.S. high school newspaper articles—written by students from across the country—we investigate whose language is preferred by the quality filter used for GPT-3. We find that newspapers from larger schools, located in wealthier, educated, and urban zones (ZIP codes) are more likely to be classified as high quality. We also show that this quality measurement is unaligned with other sensible metrics, such as factuality or literary acclaim. We argue that privileging any corpus as high quality entails a language ideology, and more care is needed to construct training corpora for language models, with better transparency and justification for the inclusion or exclusion of various texts",
    "checked": true,
    "id": "0a4b8b161931799d5c6bc3ecf07c53bae0e9e502",
    "semantic_title": "whose language counts as high quality? measuring language ideologies in text data selection",
    "citation_count": 53,
    "authors": [
      "Suchin Gururangan",
      "Dallas Card",
      "Sarah Dreier",
      "Emily Gade",
      "Leroy Wang",
      "Zeyu Wang",
      "Luke Zettlemoyer",
      "Noah A. Smith"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.166": {
    "title": "ConReader: Exploring Implicit Relations in Contracts for Contract Clause Extraction",
    "volume": "main",
    "abstract": "We study automatic Contract Clause Extraction (CCE) by modeling implicit relations in legal contracts. Existing CCE methods mostly treat contracts as plain text, creating a substantial barrier to understanding contracts of high complexity. In this work, we first comprehensively analyze the complexity issues of contracts and distill out three implicit relations commonly found in contracts, namely, 1) Long-range Context Relation that captures the correlations of distant clauses; 2) Term-Definition Relation that captures the relation between important terms with their corresponding definitions, and 3) Similar Clause Relation that captures the similarities between clauses of the same type. Then we propose a novel framework ConReader to exploit the above three relations for better contract understanding and improving CCE. Experimental results show that ConReader makes the prediction more interpretable and achieves new state-of-the-art on two CCE tasks in both conventional and zero-shot settings",
    "checked": true,
    "id": "0e131a325ffbdbfb8963ce8c63b1336376bf5de8",
    "semantic_title": "conreader: exploring implicit relations in contracts for contract clause extraction",
    "citation_count": 5,
    "authors": [
      "Weiwen Xu",
      "Yang Deng",
      "Wenqiang Lei",
      "Wenlong Zhao",
      "Tat-Seng Chua",
      "Wai Lam"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.167": {
    "title": "Training Dynamics for Curriculum Learning: A Study on Monolingual and Cross-lingual NLU",
    "volume": "main",
    "abstract": "Curriculum Learning (CL) is a technique of training models via ranking examples in a typically increasing difficulty trend with the aim of accelerating convergence and improving generalisability. Current approaches for Natural Language Understanding (NLU) tasks use CL to improve in-distribution data performance often via heuristic-oriented or task-agnostic difficulties. In this work, instead, we employ CL for NLU by taking advantage of training dynamics as difficulty metrics, i.e., statistics that measure the behavior of the model at hand on specific task-data instances during training and propose modifications of existing CL schedulers based on these statistics. Differently from existing works, we focus on evaluating models on in-distribution (ID), out-of-distribution (OOD) as well as zero-shot (ZS) cross-lingual transfer datasets. We show across several NLU tasks that CL with training dynamics can result in better performance mostly on zero-shot cross-lingual transfer and OOD settings with improvements up by 8.5% in certain cases. Overall, experiments indicate that training dynamics can lead to better performing models with smoother training compared to other difficulty metrics while being 20% faster on average. In addition, through analysis we shed light on the correlations of task-specific versus task-agnostic metrics",
    "checked": true,
    "id": "928196b196634cf5cbf454756c0efbadb0c042ca",
    "semantic_title": "training dynamics for curriculum learning: a study on monolingual and cross-lingual nlu",
    "citation_count": 1,
    "authors": [
      "Fenia Christopoulou",
      "Gerasimos Lampouras",
      "Ignacio Iacobacci"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.168": {
    "title": "Revisiting Parameter-Efficient Tuning: Are We Really There Yet?",
    "volume": "main",
    "abstract": "Parameter-Efficient Tuning (PETuning) methods have been deemed by many as the new paradigm for using pretrained language models (PLMs). By tuning just a fraction amount of parameters comparing to full model finetuning, PETuning methods claim to have achieved performance on par with or even better than finetuning. In this work, we take a step back and re-examine these PETuning methods by conducting the first comprehensive investigation into the training and evaluation of them. We found the problematic validation and testing practice in current studies, when accompanied by the instability nature of PETuning methods, has led to unreliable conclusions. When being compared under a truly fair evaluation protocol, PETuning cannot yield consistently competitive performance while finetuning remains to be the best-performing method in medium- and high-resource settings. We delve deeper into the cause of the instability and observed that the number of trainable parameters and training iterations are two main factors: reducing trainable parameters and prolonging training iterations may lead to higher stability in PETuning methods",
    "checked": true,
    "id": "4c09ac7b09628aa2aad12aea8dd6c2aef6c83aa0",
    "semantic_title": "revisiting parameter-efficient tuning: are we really there yet?",
    "citation_count": 65,
    "authors": [
      "Guanzheng Chen",
      "Fangyu Liu",
      "Zaiqiao Meng",
      "Shangsong Liang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.169": {
    "title": "Transfer Learning from Semantic Role Labeling to Event Argument Extraction with Template-based Slot Querying",
    "volume": "main",
    "abstract": "In this work, we investigate transfer learning from semantic role labeling (SRL) to event argument extraction (EAE), considering their similar argument structures. We view the extraction task as a role querying problem, unifying various methods into a single framework. There are key discrepancies on role labels and distant arguments between semantic role and event argument annotations. To mitigate these discrepancies, we specify natural language-like queries to tackle the label mismatch problem and devise argument augmentation to recover distant arguments. We show that SRL annotations can serve as a valuable resource for EAE, and a template-based slot querying strategy is especially effective for facilitating the transfer. In extensive evaluations on two English EAE benchmarks, our proposed model obtains impressive zero-shot results by leveraging SRL annotations, reaching nearly 80% of the fullysupervised scores. It further provides benefits in low-resource cases, where few EAE annotations are available. Moreover, we show that our approach generalizes to cross-domain and multilingual scenarios",
    "checked": true,
    "id": "eab8d879bd9a7c5e1983aa7a02e7fa944d49dbb1",
    "semantic_title": "transfer learning from semantic role labeling to event argument extraction with template-based slot querying",
    "citation_count": 10,
    "authors": [
      "Zhisong Zhang",
      "Emma Strubell",
      "Eduard Hovy"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.170": {
    "title": "Calibrating Zero-shot Cross-lingual (Un-)structured Predictions",
    "volume": "main",
    "abstract": "We investigate model calibration in the setting of zero-shot cross-lingual transfer with large-scale pre-trained language models. The level of model calibration is an important metric for evaluating the trustworthiness of predictive models. There exists an essential need for model calibration when natural language models are deployed in critical tasks. We study different post-training calibration methods in structured and unstructured prediction tasks. We find that models trained with data from the source language become less calibrated when applied to the target language and that calibration errors increase with intrinsic task difficulty and relative sparsity of training data. Moreover, we observe a potential connection between the level of calibration error and an earlier proposed measure of the distance from English to other languages. Finally, our comparison demonstrates that among other methods Temperature Scaling (TS) generalizes well to distant languages, but TS fails to calibrate more complex confidence estimation in structured predictions compared to more expressive alternatives like Gaussian Process Calibration",
    "checked": true,
    "id": "850bba74f19a9856982f8d525bfab9c49658f298",
    "semantic_title": "calibrating zero-shot cross-lingual (un-)structured predictions",
    "citation_count": 4,
    "authors": [
      "Zhengping Jiang",
      "Anqi Liu",
      "Benjamin Van Durme"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.171": {
    "title": "PRINCE: Prefix-Masked Decoding for Knowledge Enhanced Sequence-to-Sequence Pre-Training",
    "volume": "main",
    "abstract": "Pre-trained Language Models (PLMs) have shown effectiveness in various Natural Language Processing (NLP) tasks. Denoising autoencoder is one of the most successful pre-training frameworks, learning to recompose the original text given a noise-corrupted one. The existing studies mainly focus on injecting noises into the input. This paper introduces a simple yet effective pre-training paradigm, equipped with a knowledge-enhanced decoder that predicts the next entity token with noises in the prefix, explicitly strengthening the representation learning of entities that span over multiple input tokens. Specifically, when predicting the next token within an entity, we feed masks into the prefix in place of some of the previous ground-truth tokens that constitute the entity. Our model achieves new state-of-the-art results on two knowledge-driven data-to-text generation tasks with up to 2% BLEU gains",
    "checked": true,
    "id": "b6178d073afa60fa94c089d94f46fc6b754f16f0",
    "semantic_title": "prince: prefix-masked decoding for knowledge enhanced sequence-to-sequence pre-training",
    "citation_count": 0,
    "authors": [
      "Song Xu",
      "Haoran Li",
      "Peng Yuan",
      "Youzheng Wu",
      "Xiaodong He"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.172": {
    "title": "How Far are We from Robust Long Abstractive Summarization?",
    "volume": "main",
    "abstract": "Abstractive summarization has made tremendous progress in recent years. In this work, we perform fine-grained human annotations to evaluate long document abstractive summarization systems (i.e., models and metrics) with the aim of implementing them to generate reliable summaries. For long document abstractive models, we show that the constant strive for state-of-the-art ROUGE results can lead us to generate more relevant summaries but not factual ones. For long document evaluation metrics, human evaluation results show that ROUGE remains the best at evaluating the relevancy of a summary. It also reveals important limitations of factuality metrics in detecting different types of factual errors and the reasons behind the effectiveness of BARTScore. We then suggest promising directions in the endeavor of developing factual consistency metrics. Finally, we release our annotated long document dataset with the hope that it can contribute to the development of metrics across a broader range of summarization settings",
    "checked": true,
    "id": "3c5f7e7ee0ab7413ba3bf8ad3400810da542d617",
    "semantic_title": "how far are we from robust long abstractive summarization?",
    "citation_count": 22,
    "authors": [
      "Huan Yee Koh",
      "Jiaxin Ju",
      "He Zhang",
      "Ming Liu",
      "Shirui Pan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.173": {
    "title": "Measuring Context-Word Biases in Lexical Semantic Datasets",
    "volume": "main",
    "abstract": "State-of-the-art pretrained contextualized models (PCM) eg. BERT use tasks such as WiC and WSD to evaluate their word-in-context representations. This inherently assumes that performance in these tasks reflect how well a model represents the coupled word and context semantics. We question this assumption by presenting the first quantitative analysis on the context-word interaction being tested in major contextual lexical semantic tasks. To achieve this, we run probing baselines on masked input, and propose measures to calculate and visualize the degree of context or word biases in existing datasets. The analysis was performed on both models and humans. Our findings demonstrate that models are usually not being tested for word-in-context semantics in the same way as humans are in these tasks, which helps us better understand the model-human gap. Specifically, to PCMs, most existing datasets fall into the extreme ends (the retrieval-based tasks exhibit strong target word bias while WiC-style tasks and WSD show strong context bias); In comparison, humans are less biased and achieve much better performance when both word and context are available than with masked input. We recommend our framework for understanding and controlling these biases for model interpretation and future task design",
    "checked": true,
    "id": "11f7cda29fa63b0654f9601a5959aa04b50dcaae",
    "semantic_title": "measuring context-word biases in lexical semantic datasets",
    "citation_count": 2,
    "authors": [
      "Qianchu Liu",
      "Diana McCarthy",
      "Anna Korhonen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.174": {
    "title": "Iteratively Prompt Pre-trained Language Models for Chain of Thought",
    "volume": "main",
    "abstract": "While Pre-trained Language Models (PLMs) internalize a great amount of world knowledge, they have been shown incapable of recalling these knowledge to solve tasks requiring complex & multi-step reasoning. Similar to how humans develop a \"chain of thought\" for these tasks, how can we equip PLMs with such abilities? In this work, we explore an iterative prompting framework, a new prompting paradigm which progressively elicits relevant knowledge from PLMs for multi-step inference. We identify key limitations of existing prompting methods, namely they are either restricted to queries with a single identifiable relation/predicate, or being agnostic to input contexts, which makes it difficult to capture variabilities across different inference steps. We propose an iterative context-aware prompter, which addresses these limitations by learning to dynamically synthesize prompts conditioned on the current step's contexts. Experiments on three datasets involving multi-step reasoning show the effectiveness of the iterative scheme and the context-aware prompter design",
    "checked": true,
    "id": "3f4d11971f2c64be9125a7fe99c019588bbebf16",
    "semantic_title": "iteratively prompt pre-trained language models for chain of thought",
    "citation_count": 71,
    "authors": [
      "Boshi Wang",
      "Xiang Deng",
      "Huan Sun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.175": {
    "title": "Unobserved Local Structures Make Compositional Generalization Hard",
    "volume": "main",
    "abstract": "While recent work has shown that sequence-to-sequence models struggle to generalize to new compositions (termed compositional generalization), little is known on what makes compositional generalization hard on a particular test instance. In this work, we investigate the factors that make generalization to certain test instances challenging. We first substantiate that some examples are more difficult than others by showing that different models consistently fail or succeed on the same test instances. Then, we propose a criterion for the difficulty of an example: a test instance is hard if it contains a local structure that was not observed at training time. We formulate a simple decision rule based on this criterion and empirically show it predicts instance-level generalization well across 5 different semantic parsing datasets, substantially better than alternative decision rules. Last, we show local structures can be leveraged for creating difficult adversarial compositional splits and also to improve compositional generalization under limited training budgets by strategically selecting examples for the training set",
    "checked": true,
    "id": "9fe39e0f2cf3b6d5f70a379654f9c08ffa48ddee",
    "semantic_title": "unobserved local structures make compositional generalization hard",
    "citation_count": 30,
    "authors": [
      "Ben Bogin",
      "Shivanshu Gupta",
      "Jonathan Berant"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.176": {
    "title": "Mitigating Data Sparsity for Short Text Topic Modeling by Topic-Semantic Contrastive Learning",
    "volume": "main",
    "abstract": "To overcome the data sparsity issue in short text topic modeling, existing methods commonly rely on data augmentation or the data characteristic of short texts to introduce more word co-occurrence information. However, most of them do not make full use of the augmented data or the data characteristic: they insufficiently learn the relations among samples in data, leading to dissimilar topic distributions of semantically similar text pairs. To better address data sparsity, in this paper we propose a novel short text topic modeling framework, Topic-Semantic Contrastive Topic Model (TSCTM). To sufficiently model the relations among samples, we employ a new contrastive learning method with efficient positive and negative sampling strategies based on topic semantics. This contrastive learning method refines the representations, enriches the learning signals, and thus mitigates the sparsity issue. Extensive experimental results show that our TSCTM outperforms state-of-the-art baselines regardless of the data augmentation availability, producing high-quality topics and topic distributions",
    "checked": true,
    "id": "3babff52bdf8b1a9412b2fe149cf850a99d49eef",
    "semantic_title": "mitigating data sparsity for short text topic modeling by topic-semantic contrastive learning",
    "citation_count": 28,
    "authors": [
      "Xiaobao Wu",
      "Anh Tuan Luu",
      "Xinshuai Dong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.177": {
    "title": "Back to the Future: Bidirectional Information Decoupling Network for Multi-turn Dialogue Modeling",
    "volume": "main",
    "abstract": "Multi-turn dialogue modeling as a challenging branch of natural language understanding (NLU), aims to build representations for machines to understand human dialogues, which provides a solid foundation for multiple downstream tasks. Recent studies of dialogue modeling commonly employ pre-trained language models (PrLMs) to encode the dialogue history as successive tokens, which is insufficient in capturing the temporal characteristics of dialogues. Therefore, we propose Bidirectional Information Decoupling Network (BiDeN) as a universal dialogue encoder, which explicitly incorporates both the past and future contexts and can be generalized to a wide range of dialogue-related tasks. Experimental results on datasets of different downstream tasks demonstrate the universality and effectiveness of our BiDeN",
    "checked": true,
    "id": "7ba28d214d98f2a9c2e37e6cdf294d0d4e2a1e50",
    "semantic_title": "back to the future: bidirectional information decoupling network for multi-turn dialogue modeling",
    "citation_count": 7,
    "authors": [
      "Yiyang Li",
      "Hai Zhao",
      "Zhuosheng Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.178": {
    "title": "Calibration Meets Explanation: A Simple and Effective Approach for Model Confidence Estimates",
    "volume": "main",
    "abstract": "Calibration strengthens the trustworthiness of black-box models by producing better accurate confidence estimates on given examples. However, little is known about if model explanations can help confidence calibration. Intuitively, humans look at important features attributions and decide whether the model is trustworthy. Similarly, the explanations may tell us when the model might know and when it does not. Inspired by this, we propose a method named CME that leverages model explanations to make the model less confident with non-inductive attributions. The idea is that when the model is not highly confident, it is difficult to identify strong indications of any class, and the tokens accordingly do not have high attribution scores for any class and vice versa. We conduct extensive experiments on six datasets with two popular pre-trained language models in the in-domain and out-of-domain settings. The results show that CME improves calibration performance in all settings. The expected calibration errors are further reduced when combined with temperature scaling. Our findings highlight that model explanations can help calibrate posterior estimates",
    "checked": true,
    "id": "00e06c446546a51445847f11d2a89cc08aa045e8",
    "semantic_title": "calibration meets explanation: a simple and effective approach for model confidence estimates",
    "citation_count": 6,
    "authors": [
      "Dongfang Li",
      "Baotian Hu",
      "Qingcai Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.179": {
    "title": "Non-Autoregressive Neural Machine Translation: A Call for Clarity",
    "volume": "main",
    "abstract": "Non-autoregressive approaches aim to improve the inference speed of translation models by only requiring a single forward pass to generate the output sequence instead of iteratively producing each predicted token. Consequently, their translation quality still tends to be inferior to their autoregressive counterparts due to several issues involving output token interdependence. In this work, we take a step back and revisit several techniques that have been proposed for improving non-autoregressive translation models and compare their combined translation quality and speed implications under third-party testing environments. We provide novel insights for establishing strong baselines using length prediction or CTC-based architecture variants and contribute standardized BLEU, chrF++, and TER scores using sacreBLEU on four translation tasks, which crucially have been missing as inconsistencies in the use of tokenized BLEU lead to deviations of up to 1.7 BLEU points. Our open-sourced code is integrated into fairseq for reproducibility",
    "checked": true,
    "id": "258cbe92945708a9bfc7eb0c87d08516db1d8b40",
    "semantic_title": "non-autoregressive neural machine translation: a call for clarity",
    "citation_count": 7,
    "authors": [
      "Robin Schmidt",
      "Telmo Pires",
      "Stephan Peitz",
      "Jonas Lööf"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.180": {
    "title": "RED-ACE: Robust Error Detection for ASR using Confidence Embeddings",
    "volume": "main",
    "abstract": "ASR Error Detection (AED) models aim to post-process the output of Automatic Speech Recognition (ASR) systems, in order to detect transcription errors. Modern approaches usually use text-based input, comprised solely of the ASR transcription hypothesis, disregarding additional signals from the ASR model. Instead, we utilize the ASR system's word-level confidence scores for improving AED performance. Specifically, we add an ASR Confidence Embedding (ACE) layer to the AED model's encoder, allowing us to jointly encode the confidence scores and the transcribed text into a contextualized representation. Our experiments show the benefits of ASR confidence scores for AED, their complementary effect over the textual signal, as well as the effectiveness and robustness of ACE for combining these signals. To foster further research, we publish a novel AED dataset consisting of ASR outputs on the LibriSpeech corpus with annotated transcription errors",
    "checked": true,
    "id": "076e3bd06c5a5b56bcdea13f6af545b89352907b",
    "semantic_title": "red-ace: robust error detection for asr using confidence embeddings",
    "citation_count": 5,
    "authors": [
      "Zorik Gekhman",
      "Dina Zverinski",
      "Jonathan Mallinson",
      "Genady Beryozkin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.181": {
    "title": "Fast-R2D2: A Pretrained Recursive Neural Network based on Pruned CKY for Grammar Induction and Text Representation",
    "volume": "main",
    "abstract": "Chart-based models have shown great potential in unsupervised grammar induction, running recursively and hierarchically, but requiring O(n³) time-complexity. The Recursive Transformer based on Differentiable Trees (R2D2) makes it possible to scale to large language model pretraining even with a complex tree encoder, by introducing a heuristic pruning method.However, its rule-based pruning process suffers from local optima and slow inference. In this paper, we propose a unified R2D2 method that overcomes these issues. We use a top-down unsupervised parser as a model-guided pruning method, which also enables parallel encoding during inference. Our parser casts parsing as a split point scoring task by first scoring all split points for a given sentence and then using the highest-scoring one to recursively split a span into two parts. The reverse order of the splits is considered as the order of pruning in the encoder. We optimize the unsupervised parser by minimizing the Kullback–Leibler distance between tree probabilities from the parser and the R2D2 model.Our experiments show that our Fast-R2D2 significantly improves the grammar induction quality and achieves competitive results in downstream tasks",
    "checked": true,
    "id": "dc85180153687539724d20a5927b2fbdf5f8e2a4",
    "semantic_title": "fast-r2d2: a pretrained recursive neural network based on pruned cky for grammar induction and text representation",
    "citation_count": 11,
    "authors": [
      "Xiang Hu",
      "Haitao Mi",
      "Liang Li",
      "Gerard de Melo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.182": {
    "title": "A Localized Geometric Method to Match Knowledge in Low-dimensional Hyperbolic Space",
    "volume": "main",
    "abstract": "Matching equivalent entities across Knowledge graphs is a pivotal step for knowledge fusion. Previous approaches usually study the problem in Euclidean space. However, recent works have shown that hyperbolic space has a higher capacity than Euclidean space and hyperbolic embedding can represent the hierarchical structure in a knowledge graph. In this paper, we propose a localized geometric method to find equivalent entities in hyperbolic space. Specifically, we use a hyperbolic neural network to encode the lingual information of entities and the structure of both knowledge graphs into a low-dimensional hyperbolic space. To address the asymmetry of structure on different KGs and the localized nature of relations, we learn an instance-specific geometric mapping function based on rotation to match entity pairs. A contrastive loss function is used to train the model. The experiment verifies the power of low-dimensional hyperbolic space for entity matching and shows that our method outperforms the state of the art by a large margin",
    "checked": true,
    "id": "397b80b784062d40512765d35815fa1dc41a1fd7",
    "semantic_title": "a localized geometric method to match knowledge in low-dimensional hyperbolic space",
    "citation_count": 1,
    "authors": [
      "Bo Hui",
      "Tian Xia",
      "Wei-Shinn Ku"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.183": {
    "title": "Memory-assisted prompt editing to improve GPT-3 after deployment",
    "volume": "main",
    "abstract": "Large LMs such as GPT-3 are powerful, but can commit mistakes that are obvious to humans. For example, GPT-3 would mistakenly interpret \"What word is similar to good?\" to mean a homophone, while the user intended a synonym. Our goal is to effectively correct such errors via user interactions with the system but without retraining, which will be prohibitively costly. We pair GPT-3 with a growing memory of recorded cases where the model misunderstood the user's intents, along with user feedback for clarification. Such a memory allows our system to produce enhanced prompts for any new query based on the user feedback for error correction on similar cases in the past. On four tasks (two lexical tasks, two advanced ethical reasoning tasks), we show how a (simulated) user can interactively teach a deployed GPT-3, substantially increasing its accuracy over the queries with different kinds of misunderstandings by the GPT-3. Our approach is a step towards the low-cost utility enhancement for very large pre-trained LMs",
    "checked": true,
    "id": "f76c965153398cd8513ef95eaa32196c4cae3f86",
    "semantic_title": "memory-assisted prompt editing to improve gpt-3 after deployment",
    "citation_count": 0,
    "authors": [
      "Aman Madaan",
      "Niket Tandon",
      "Peter Clark",
      "Yiming Yang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.184": {
    "title": "LVP-M3: Language-aware Visual Prompt for Multilingual Multimodal Machine Translation",
    "volume": "main",
    "abstract": "Multimodal Machine Translation (MMT) focuses on enhancing text-only translation with visual features, which has attracted considerable attention from both natural language processing and computer vision communities. Recent advances still struggle to train a separate model for each language pair, which is costly and unaffordable when the number of languages increases in the real world. In other words, the multilingual multimodal machine translation (Multilingual MMT) task has not been investigated, which aims to handle the aforementioned issues by providing a shared semantic space for multiple languages. Besides, the image modality has no language boundaries, which is superior to bridging the semantic gap between languages. To this end,we first propose the Multilingual MMT task by establishing two new Multilingual MMT benchmark datasets covering seven languages.Then, an effective baseline LVP-M3 using visual prompts is proposed to support translations between different languages,which includes three stages (token encoding, language-aware visual prompt generation, and language translation). Extensive experimental results on our constructed benchmark datasets demonstrate the effectiveness of LVP-M3 method for Multilingual MMT",
    "checked": true,
    "id": "22fbef2bfef213a7619ee4f307e8f42d1888e638",
    "semantic_title": "lvp-m3: language-aware visual prompt for multilingual multimodal machine translation",
    "citation_count": 16,
    "authors": [
      "Hongcheng Guo",
      "Jiaheng Liu",
      "Haoyang Huang",
      "Jian Yang",
      "Zhoujun Li",
      "Dongdong Zhang",
      "Zheng Cui"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.185": {
    "title": "PromptEHR: Conditional Electronic Healthcare Records Generation with Prompt Learning",
    "volume": "main",
    "abstract": "Accessing longitudinal multimodal Electronic Healthcare Records (EHRs) is challenging due to privacy concerns, which hinders the use of ML for healthcare applications. Synthetic EHRs generation bypasses the need to share sensitive real patient records. However, existing methods generate single-modal EHRs by unconditional generation or by longitudinal inference, which falls short of low flexibility and makes unrealistic EHRs. In this work, we propose to formulate EHRs generation as a text-to-text translation task by language models (LMs), which suffices to highly flexible event imputation during generation. We also design prompt learning to control the generation conditioned by numerical and categorical demographic features. We evaluate synthetic EHRs quality by two perplexity measures accounting for their longitudinal pattern (longitudinal imputation perplexity, lpl) and the connections cross modalities (cross-modality imputation perplexity, mpl). Moreover, we utilize two adversaries: membership and attribute inference attacks for privacy-preserving evaluation. Experiments on MIMIC-III data demonstrate the superiority of our methods on realistic EHRs generation (53.1% decrease of lpl and 45.3% decrease of mpl on average compared to the best baselines) with low privacy risks. Software is available at https://github.com/RyanWangZf/PromptEHR",
    "checked": true,
    "id": "3c4f79018c5c68bb470d0f8ddc78e1a8cbf61209",
    "semantic_title": "promptehr: conditional electronic healthcare records generation with prompt learning",
    "citation_count": 19,
    "authors": [
      "Zifeng Wang",
      "Jimeng Sun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.186": {
    "title": "ROSE: Robust Selective Fine-tuning for Pre-trained Language Models",
    "volume": "main",
    "abstract": "Even though the large-scale language models have achieved excellent performances, they suffer from various adversarial attacks.A large body of defense methods has been proposed. However, they are still limited due to redundant attack search spaces and the inability to defend against various types of attacks.In this work, we present a novel fine-tuning approach called RObust SEletive fine-tuning (ROSE) to address this issue.ROSE conducts selective updates when adapting pre-trained models to downstream tasks, filtering out invaluable and unrobust updates of parameters.Specifically, we propose two strategies: the first-order and second-order ROSE for selecting target robust parameters.The experimental results show that ROSE achieves significant improvements in adversarial robustness on various downstream NLP tasks, and the ensemble method even surpasses both variants above.Furthermore, ROSE can be easily incorporated into existing fine-tuning methods to improve their adversarial robustness further.The empirical analysis confirms that ROSE eliminates unrobust spurious updates during fine-tuning, leading to solutions corresponding to flatter and wider optima than the conventional method.Code is available at https://github.com/jiangllan/ROSE",
    "checked": true,
    "id": "175b32c07e56f881479be4c5a74bfa3c731cc454",
    "semantic_title": "rose: robust selective fine-tuning for pre-trained language models",
    "citation_count": 6,
    "authors": [
      "Lan Jiang",
      "Hao Zhou",
      "Yankai Lin",
      "Peng Li",
      "Jie Zhou",
      "Rui Jiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.187": {
    "title": "CodeRetriever: A Large Scale Contrastive Pre-Training Method for Code Search",
    "volume": "main",
    "abstract": "In this paper, we propose the CodeRetriever model, which learns the function-level code semantic representations through large-scale code-text contrastive pre-training. We adopt two contrastive learning schemes in CodeRetriever: unimodal contrastive learning and bimodal contrastive learning. For unimodal contrastive learning, we design an unsupervised learning approach to build semantic-related code pairs based on the documentation and function name. For bimodal contrastive learning, we leverage the documentation and in-line comments of code to build code-text pairs. Both contrastive objectives can fully leverage large-scale code corpus for pre-training. Extensive experimental results show that CodeRetriever achieves new state-of-the-art with significant improvement over existing code pre-trained models, on eleven domain/language-specific code search tasks with six programming languages in different code granularity (function-level, snippet-level and statement-level).These results demonstrate the effectiveness and robustness of CodeRetriever.The codes and resources are available at https://github.com/microsoft/AR2/tree/main/CodeRetriever",
    "checked": true,
    "id": "92624f29c54cf47fcba0cd8d8324351d807544a2",
    "semantic_title": "coderetriever: a large scale contrastive pre-training method for code search",
    "citation_count": 11,
    "authors": [
      "Xiaonan Li",
      "Yeyun Gong",
      "Yelong Shen",
      "Xipeng Qiu",
      "Hang Zhang",
      "Bolun Yao",
      "Weizhen Qi",
      "Daxin Jiang",
      "Weizhu Chen",
      "Nan Duan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.188": {
    "title": "Open-Topic False Information Detection on Social Networks with Contrastive Adversarial Learning",
    "volume": "main",
    "abstract": "Current works about false information detection based on conversation graphs on social networks focus primarily on two research streams from the standpoint of topic distribution: in-topic and cross-topic techniques, which assume that the data topic distribution is identical or cross, respectively. This signifies that all test data topics are seen or unseen by the model.However, these assumptions are too harsh for actual social networks that contain both seen and unseen topics simultaneously, hence restricting their practical application.In light of this, this paper develops a novel open-topic scenario that is better suited to actual social networks. In this open-topic scenario, we empirically find that the existing models suffer from impairment in the detection performance for seen or unseen topic data, resulting in poor overall model performance. To address this issue, we propose a novel Contrastive Adversarial Learning Network, CALN, that employs an unsupervised topic clustering method to capture topic-specific features to enhance the model's performance for seen topics and an unsupervised adversarial learning method to align data representation distributions to enhance the model's generalisation to unseen topics.Experiments on two benchmark datasets and a variety of graph neural networks demonstrate the effectiveness of our approach",
    "checked": true,
    "id": "8e348f0c937f26e6f3ec80ff4e53501b6fa9b766",
    "semantic_title": "open-topic false information detection on social networks with contrastive adversarial learning",
    "citation_count": 5,
    "authors": [
      "Guanghui Ma",
      "Chunming Hu",
      "Ling Ge",
      "Hong Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.189": {
    "title": "Mitigating Inconsistencies in Multimodal Sentiment Analysis under Uncertain Missing Modalities",
    "volume": "main",
    "abstract": "For the missing modality problem in Multimodal Sentiment Analysis (MSA), the inconsistency phenomenon occurs when the sentiment changes due to the absence of a modality. The absent modality that determines the overall semantic can be considered as a key missing modality. However, previous works all ignored the inconsistency phenomenon, simply discarding missing modalities or solely generating associated features from available modalities. The neglect of the key missing modality case may lead to incorrect semantic results. To tackle the issue, we propose an Ensemble-based Missing Modality Reconstruction (EMMR) network to detect and recover semantic features of the key missing modality. Specifically, we first learn joint representations with remaining modalities via a backbone encoder-decoder network. Then, based on the recovered features, we check the semantic consistency to determine whether the absent modality is crucial to the overall sentiment polarity. Once the inconsistency problem due to the key missing modality exists, we integrate several encoder-decoder approaches for better decision making. Extensive experiments and analyses are conducted on CMU-MOSI and IEMOCAP datasets, validating the superiority of the proposed method",
    "checked": true,
    "id": "58c0b4ccfa5c997f268db07c3a7b36f5cc92864b",
    "semantic_title": "mitigating inconsistencies in multimodal sentiment analysis under uncertain missing modalities",
    "citation_count": 9,
    "authors": [
      "Jiandian Zeng",
      "Jiantao Zhou",
      "Tianyi Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.190": {
    "title": "ConvTrans: Transforming Web Search Sessions for Conversational Dense Retrieval",
    "volume": "main",
    "abstract": "Conversational search provides users with a natural and convenient new search experience. Recently, conversational dense retrieval has shown to be a promising technique for realizing conversational search. However, as conversational search systems have not been widely deployed, it is hard to get large-scale real conversational search sessions and relevance labels to support the training of conversational dense retrieval. To tackle this data scarcity problem, previous methods focus on developing better few-shot learning approaches or generating pseudo relevance labels, but the data they use for training still heavily rely on manual generation.In this paper, we present ConvTrans, a data augmentation method that can automatically transform easily-accessible web search sessions into conversational search sessions to fundamentally alleviate the data scarcity problem for conversational dense retrieval. ConvTrans eliminates the gaps between these two types of sessions in terms of session quality and query form to achieve effective session transformation. Extensive evaluations on two widely used conversational search benchmarks, i.e., CAsT-19 and CAsT-20, demonstrate that the same model trained on the data generated by ConvTrans can achieve comparable retrieval performance as it trained on high-quality but expensive artificial conversational search data",
    "checked": true,
    "id": "ab0345265a445191a590d1b5216605e6e031e495",
    "semantic_title": "convtrans: transforming web search sessions for conversational dense retrieval",
    "citation_count": 9,
    "authors": [
      "Kelong Mao",
      "Zhicheng Dou",
      "Hongjin Qian",
      "Fengran Mo",
      "Xiaohua Cheng",
      "Zhao Cao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.191": {
    "title": "MUSIED: A Benchmark for Event Detection from Multi-Source Heterogeneous Informal Texts",
    "volume": "main",
    "abstract": "Event detection (ED) identifies and classifies event triggers from unstructured texts, serving as a fundamental task for information extraction. Despite the remarkable progress achieved in the past several years, most research efforts focus on detecting events from formal texts (e.g., news articles, Wikipedia documents, financial announcements). Moreover, the texts in each dataset are either from a single source or multiple yet relatively homogeneous sources. With massive amounts of user-generated text accumulating on the Web and inside enterprises, identifying meaningful events in these informal texts, usually from multiple heterogeneous sources, has become a problem of significant practical value. As a pioneering exploration that expands event detection to the scenarios involving informal and heterogeneous texts, we propose a new large-scale Chinese event detection dataset based on user reviews, text conversations, and phone conversations in a leading e-commerce platform for food service. We carefully investigate the proposed dataset's textual informality and multi-domain heterogeneity characteristics by inspecting data samples quantitatively and qualitatively. Extensive experiments with state-of-the-art event detection methods verify the unique challenges posed by these characteristics, indicating that multi-domain informal event detection remains an open problem and requires further efforts. Our benchmark and code are released at https://github.com/myeclipse/MUSIED",
    "checked": true,
    "id": "13fc9f5d6a94657c678bd66c1992dc3d04762c19",
    "semantic_title": "musied: a benchmark for event detection from multi-source heterogeneous informal texts",
    "citation_count": 1,
    "authors": [
      "Xiangyu Xi",
      "Jianwei Lv",
      "Shuaipeng Liu",
      "Wei Ye",
      "Fan Yang",
      "Guanglu Wan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.192": {
    "title": "Reproducibility Issues for BERT-based Evaluation Metrics",
    "volume": "main",
    "abstract": "Reproducibility is of utmost concern in machine learning and natural language processing (NLP). In the field of natural language generation (especially machine translation), the seminal paper of Post (2018) has pointed out problems of reproducibility of the dominant metric, BLEU, at the time of publication. Nowadays, BERT-based evaluation metrics considerably outperform BLEU. In this paper, we ask whether results and claims from four recent BERT-based metrics can be reproduced. We find that reproduction of claims and results often fails because of (i) heavy undocumented preprocessing involved in the metrics, (ii) missing code and (iii) reporting weaker results for the baseline metrics. (iv) In one case, the problem stems from correlating not to human scores but to a wrong column in the csv file, inflating scores by 5 points. Motivated by the impact of preprocessing, we then conduct a second study where we examine its effects more closely (for one of the metrics). We find that preprocessing can have large effects, especially for highly inflectional languages. In this case, the effect of preprocessing may be larger than the effect of the aggregation mechanism (e.g., greedy alignment vs. Word Mover Distance)",
    "checked": true,
    "id": "22d59771dae574309fa74e98446b6df50472a107",
    "semantic_title": "reproducibility issues for bert-based evaluation metrics",
    "citation_count": 16,
    "authors": [
      "Yanran Chen",
      "Jonas Belouadi",
      "Steffen Eger"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.193": {
    "title": "Improving Multi-task Stance Detection with Multi-task Interaction Network",
    "volume": "main",
    "abstract": "Stance detection aims to identify people's standpoints expressed in the text towards a target, which can provide powerful information for various downstream tasks.Recent studies have proposed multi-task learning models that introduce sentiment information to boost stance detection.However, they neglect to explore capturing the fine-grained task-specific interaction between stance detection and sentiment tasks, thus degrading performance.To address this issue, this paper proposes a novel multi-task interaction network (MTIN) for improving the performance of stance detection and sentiment analysis tasks simultaneously.Specifically, we construct heterogeneous task-related graphs to automatically identify and adapt the roles that a word plays with respect to a specific task. Also, a multi-task interaction module is designed to capture the word-level interaction between tasks, so as to obtain richer task representations.Extensive experiments on two real-world datasets show that our proposed approach outperforms state-of-the-art methods in both stance detection and sentiment analysis tasks",
    "checked": true,
    "id": "0a5bb07c710602e4829a79c9f107c63e8de7e040",
    "semantic_title": "improving multi-task stance detection with multi-task interaction network",
    "citation_count": 5,
    "authors": [
      "Heyan Chai",
      "Siyu Tang",
      "Jinhao Cui",
      "Ye Ding",
      "Binxing Fang",
      "Qing Liao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.194": {
    "title": "Neural-based Mixture Probabilistic Query Embedding for Answering FOL queries on Knowledge Graphs",
    "volume": "main",
    "abstract": "Query embedding (QE)—which aims to embed entities and first-order logical (FOL) queries in a vector space, has shown great power in answering FOL queries on knowledge graphs (KGs). Existing QE methods divide a complex query into a sequence of mini-queries according to its computation graph and perform logical operations on the answer sets of mini-queries to get answers. However, most of them assume that answer sets satisfy an individual distribution (e.g., Uniform, Beta, or Gaussian), which is often violated in real applications and limit their performance. In this paper, we propose a Neural-based Mixture Probabilistic Query Embedding Model (NMP-QEM) that encodes the answer set of each mini-query as a mixed Gaussian distribution with multiple means and covariance parameters, which can approximate any random distribution arbitrarily well in real KGs. Additionally, to overcome the difficulty in defining the closed solution of negation operation, we introduce neural-based logical operators of projection, intersection and negation for a mixed Gaussian distribution to answer all the FOL queries. Extensive experiments demonstrate that NMP-QEM significantly outperforms existing state-of-the-art methods on benchmark datasets. In NELL995, NMP-QEM achieves a 31% relative improvement over the state-of-the-art",
    "checked": true,
    "id": "7b5d2be2abc0962f7feaa9fdb6ddaa6206b9e6a9",
    "semantic_title": "neural-based mixture probabilistic query embedding for answering fol queries on knowledge graphs",
    "citation_count": 4,
    "authors": [
      "Xiao Long",
      "Liansheng Zhuang",
      "Li Aodi",
      "Shafei Wang",
      "Houqiang Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.195": {
    "title": "Improving Multi-turn Emotional Support Dialogue Generation with Lookahead Strategy Planning",
    "volume": "main",
    "abstract": "Providing Emotional Support (ES) to soothe people in emotional distress is an essential capability in social interactions. Most existing researches on building ES conversation systems only considered single-turn interactions with users, which was over-simplified. In comparison, multi-turn ES conversation systems can provide ES more effectively, but face several new technical challenges, including: (1) how to adopt appropriate support strategies to achieve the long-term dialogue goal of comforting the user's emotion; (2) how to dynamically model the user's state. In this paper, we propose a novel system MultiESC to address these issues. For strategy planning, drawing inspiration from the A* search algorithm, we propose lookahead heuristics to estimate the future user feedback after using particular strategies, which helps to select strategies that can lead to the best long-term effects. For user state modeling, MultiESC focuses on capturing users' subtle emotional expressions and understanding their emotion causes. Extensive experiments show that MultiESC significantly outperforms competitive baselines in both dialogue generation and strategy planning",
    "checked": true,
    "id": "f36053a516cc4e3e72291ad2eaa042a299a19635",
    "semantic_title": "improving multi-turn emotional support dialogue generation with lookahead strategy planning",
    "citation_count": 35,
    "authors": [
      "Yi Cheng",
      "Wenge Liu",
      "Wenjie Li",
      "Jiashuo Wang",
      "Ruihui Zhao",
      "Bang Liu",
      "Xiaodan Liang",
      "Yefeng Zheng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.196": {
    "title": "Conformal Predictor for Improving Zero-Shot Text Classification Efficiency",
    "volume": "main",
    "abstract": "Pre-trained language models (PLMs) have been shown effective for zero-shot (0shot) text classification. 0shot models based on natural language inference (NLI) and next sentence prediction (NSP) employ cross-encoder architecture and infer by making a forward pass through the model for each label-text pair separately. This increases the computational cost to make inferences linearly in the number of labels. In this work, we improve the efficiency of such cross-encoder-based 0shot models by restricting the number of likely labels using another fast base classifier-based conformal predictor (CP) calibrated on samples labeled by the 0shot model. Since a CP generates prediction sets with coverage guarantees, it reduces the number of target labels without excluding the most probable label based on the 0shot model. We experiment with three intent and two topic classification datasets. With a suitable CP for each dataset, we reduce the average inference time for NLI- and NSP-based models by 25.6% and 22.2% respectively, without dropping performance below the predefined error rate of 1%",
    "checked": true,
    "id": "268fda32364892264030f9749fda5b7ca780ae11",
    "semantic_title": "conformal predictor for improving zero-shot text classification efficiency",
    "citation_count": 2,
    "authors": [
      "Prafulla Kumar Choubey",
      "Yu Bai",
      "Chien-Sheng Wu",
      "Wenhao Liu",
      "Nazneen Rajani"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.197": {
    "title": "Effective and Efficient Query-aware Snippet Extraction for Web Search",
    "volume": "main",
    "abstract": "Query-aware webpage snippet extraction is widely used in search engines to help users better understand the content of the returned webpages before clicking. The extracted snippet is expected to summarize the webpage in the context of the input query. Existing snippet extraction methods mainly rely on handcrafted features of overlapping words, which cannot capture deep semantic relationships between the query and webpages. Another idea is to extract the sentences which are most relevant to queries as snippets with existing text matching methods. However, these methods ignore the contextual information of webpages, which may be sub-optimal. In this paper, we propose an effective query-aware webpage snippet extraction method named DeepQSE. In DeepQSE, the concatenation of title, query and each candidate sentence serves as an input of query-aware sentence encoder, aiming to capture the fine-grained relevance between the query and sentences. Then, these query-aware sentence representations are modeled jointly through a document-aware relevance encoder to capture contextual information of the webpage. Since the query and each sentence are jointly modeled in DeepQSE, its online inference may be slow. Thus, we further propose an efficient version of DeepQSE, named Efficient-DeepQSE, which can significantly improve the inference speed of DeepQSE without affecting its performance. The core idea of Efficient-DeepQSE is to decompose the query-aware snippet extraction task into two stages, i.e., a coarse-grained candidate sentence selection stage where sentence representations can be cached, and a fine-grained relevance modeling stage. Experiments on two datasets validate the effectiveness and efficiency of our methods",
    "checked": true,
    "id": "aeb0335390f53a6a38090c021c77c47aca6a0021",
    "semantic_title": "effective and efficient query-aware snippet extraction for web search",
    "citation_count": 3,
    "authors": [
      "Jingwei Yi",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Xiaolong Huang",
      "Binxing Jiao",
      "Guangzhong Sun",
      "Xing Xie"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.198": {
    "title": "You Only Need One Model for Open-domain Question Answering",
    "volume": "main",
    "abstract": "Recent approaches to Open-domain Question Answering refer to an external knowledge base using a retriever model, optionally rerank passages with a separate reranker model and generate an answer using another reader model. Despite performing related tasks, the models have separate parameters and are weakly-coupled during training. We propose casting the retriever and the reranker as internal passage-wise attention mechanisms applied sequentially within the transformer architecture and feeding computed representations to the reader, with the hidden representations progressively refined at each stage. This allows us to use a single question answering model trained end-to-end, which is a more efficient use of model capacity and also leads to better gradient flow. We present a pre-training method to effectively train this architecture and evaluate our model on the Natural Questions and TriviaQA open datasets. For a fixed parameter budget, our model outperforms the previous state-of-the-art model by 1.0 and 0.7 exact match scores",
    "checked": true,
    "id": "c2b86e6dee44dd1dc711425e13eadcf04444dea9",
    "semantic_title": "you only need one model for open-domain question answering",
    "citation_count": 21,
    "authors": [
      "Haejun Lee",
      "Akhil Kedia",
      "Jongwon Lee",
      "Ashwin Paranjape",
      "Christopher Manning",
      "Kyoung-Gu Woo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.199": {
    "title": "Generative Entity Typing with Curriculum Learning",
    "volume": "main",
    "abstract": "Entity typing aims to assign types to the entity mentions in given texts. The traditional classification-based entity typing paradigm has two unignorable drawbacks: 1) it fails to assign an entity to the types beyond the predefined type set, and 2) it can hardly handle few-shot and zero-shot situations where many long-tail types only have few or even no training instances. To overcome these drawbacks, we propose a novel generative entity typing (GET) paradigm: given a text with an entity mention, the multiple types for the role that the entity plays in the text are generated with a pre-trained language model (PLM). However, PLMs tend to generate coarse-grained types after fine-tuning upon the entity typing dataset. In addition, only the heterogeneous training data consisting of a small portion of human-annotated data and a large portion of auto-generated but low-quality data are provided for model training. To tackle these problems, we employ curriculum learning (CL) to train our GET model on heterogeneous data, where the curriculum could be self-adjusted with the self-paced learning according to its comprehension of the type granularity and data heterogeneity. Our extensive experiments upon the datasets of different languages and downstream tasks justify the superiority of our GET model over the state-of-the-art entity typing models. The code has been released on https://github.com/siyuyuan/GET",
    "checked": true,
    "id": "2b787c790189c82be89b9bb3b887a69da4259dbe",
    "semantic_title": "generative entity typing with curriculum learning",
    "citation_count": 8,
    "authors": [
      "Siyu Yuan",
      "Deqing Yang",
      "Jiaqing Liang",
      "Zhixu Li",
      "Jinxi Liu",
      "Jingyue Huang",
      "Yanghua Xiao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.200": {
    "title": "SetGNER: General Named Entity Recognition as Entity Set Generation",
    "volume": "main",
    "abstract": "Recently, joint recognition of flat, nested and discontinuous entities has received increasing attention. Motivated by the observation that the target output of NER is essentially a set of sequences, we propose a novel entity set generation framework for general NER scenes in this paper. Different from sequence-to-sequence NER methods, our method does not force the entities to be generated in a predefined order and can get rid of the problem of error propagation and inefficient decoding. Distinguished from the set-prediction NER framework, our method treats each entity as a sequence and is capable of recognizing discontinuous mentions. Given an input sentence, the model first encodes the sentence in word-level and detects potential entity mentions based on the encoder's output, then reconstructs entity mentions from the detected entity heads in parallel. To let the encoder of our model capture better right-to-left semantic structure, we also propose an auxiliary Inverse Generation Training task. Extensive experiments show that our model (w/o. Inverse Generation Training) outperforms state-of-the-art generative NER models by a large margin on two discontinuous NER datasets, two nested NER datasets and one flat NER dataset. Besides, the auxiliary Inverse Generation Training task is found to further improve the model's performance on the five datasets",
    "checked": true,
    "id": "7801d0c770f1bf40e6d1410bba7ebb474e9528a1",
    "semantic_title": "setgner: general named entity recognition as entity set generation",
    "citation_count": 5,
    "authors": [
      "Yuxin He",
      "Buzhou Tang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.201": {
    "title": "Opinion Summarization by Weak-Supervision from Mix-structured Data",
    "volume": "main",
    "abstract": "Opinion summarization of multiple reviews suffers from the lack of reference summaries for training.Most previous approaches construct multiple reviews and their summary based on textual similarities between reviews,resulting in information mismatch between the review input and the summary. In this paper, we convert each review into a mixof structured and unstructured data, which we call opinion-aspect pairs (OAs) and implicit sentences (ISs).We propose a new method to synthesize training pairs of such mix-structured data as input and the textual summary as output,and design a summarization model with OA encoder and IS encoder.Experiments show that our approach outperforms previous methods on Yelp, Amazon and RottenTomatos datasets",
    "checked": true,
    "id": "ea0c686aa2c4b37ceef1874cfdc8e1b7898faf4e",
    "semantic_title": "opinion summarization by weak-supervision from mix-structured data",
    "citation_count": 0,
    "authors": [
      "Yizhu Liu",
      "Qi Jia",
      "Kenny Zhu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.202": {
    "title": "Multi-level Distillation of Semantic Knowledge for Pre-training Multilingual Language Model",
    "volume": "main",
    "abstract": "Pre-trained multilingual language models play an important role in cross-lingual natural language understanding tasks. However, existing methods did not focus on learning the semantic structure of representation, and thus could not optimize their performance. In this paper, we propose Multi-level Multilingual Knowledge Distillation (MMKD), a novel method for improving multilingual language models. Specifically, we employ a teacher-student framework to adopt rich semantic representation knowledge in English BERT. We propose token-, word-, sentence-, and structure-level alignment objectives to encourage multiple levels of consistency between source-target pairs and correlation similarity between teacher and student models. We conduct experiments on cross-lingual evaluation benchmarks including XNLI, PAWS-X, and XQuAD. Experimental results show that MMKD outperforms other baseline models of similar size on XNLI and XQuAD and obtains comparable performance on PAWS-X. Especially, MMKD obtains significant performance gains on low-resource languages",
    "checked": true,
    "id": "ae3d8af12b176d16961b53850c98d98449f9940e",
    "semantic_title": "multi-level distillation of semantic knowledge for pre-training multilingual language model",
    "citation_count": 4,
    "authors": [
      "Mingqi Li",
      "Fei Ding",
      "Dan Zhang",
      "Long Cheng",
      "Hongxin Hu",
      "Feng Luo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.203": {
    "title": "Empowering Dual-Encoder with Query Generator for Cross-Lingual Dense Retrieval",
    "volume": "main",
    "abstract": "In monolingual dense retrieval, lots of works focus on how to distill knowledge from cross-encoder re-ranker to dual-encoder retriever and these methods achieve better performance due to the effectiveness of cross-encoder re-ranker. However, we find that the performance of the cross-encoder re-ranker is heavily influenced by the number of training samples and the quality of negative samples, which is hard to obtain in the cross-lingual setting. In this paper, we propose to use a query generator as the teacher in the cross-lingual setting, which is less dependent on enough training samples and high-quality negative samples. In addition to traditional knowledge distillation, we further propose a novel enhancement method, which uses the query generator to help the dual-encoder align queries from different languages, but does not need any additional parallel sentences. The experimental results show that our method outperforms the state-of-the-art methods on two benchmark datasets",
    "checked": true,
    "id": "ca798e19f82266800f835d3b41672b385cdec0f6",
    "semantic_title": "empowering dual-encoder with query generator for cross-lingual dense retrieval",
    "citation_count": 5,
    "authors": [
      "Houxing Ren",
      "Linjun Shou",
      "Ning Wu",
      "Ming Gong",
      "Daxin Jiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.204": {
    "title": "R2F: A General Retrieval, Reading and Fusion Framework for Document-level Natural Language Inference",
    "volume": "main",
    "abstract": "Document-level natural language inference (DOCNLI) is a new challenging task in natural language processing, aiming at judging the entailment relationship between a pair of hypothesis and premise documents. Current datasets and baselines largely follow sentence-level settings, but fail to address the issues raised by longer documents. In this paper, we establish a general solution, named Retrieval, Reading and Fusion (R2F) framework, and a new setting, by analyzing the main challenges of DOCNLI: interpretability, long-range dependency, and cross-sentence inference. The basic idea of the framework is to simplify document-level task into a set of sentence-level tasks, and improve both performance and interpretability with the power of evidence. For each hypothesis sentence, the framework retrieves evidence sentences from the premise, and reads to estimate its credibility. Then the sentence-level results are fused to judge the relationship between the documents. For the setting, we contribute complementary evidence and entailment label annotation on hypothesis sentences, for interpretability study. Our experimental results show that R2F framework can obtain state-of-the-art performance and is robust for diverse evidence retrieval methods. Moreover, it can give more interpretable prediction results. Our model and code are released at https://github.com/phoenixsecularbird/R2F",
    "checked": true,
    "id": "2d6aae19d2dd9e93ba53718e2aa4d2ccf0797f1e",
    "semantic_title": "r2f: a general retrieval, reading and fusion framework for document-level natural language inference",
    "citation_count": 0,
    "authors": [
      "Hao Wang",
      "Yixin Cao",
      "Yangguang Li",
      "Zhen Huang",
      "Kun Wang",
      "Jing Shao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.205": {
    "title": "Revisiting Pre-trained Language Models and their Evaluation for Arabic Natural Language Processing",
    "volume": "main",
    "abstract": "There is a growing body of work in recent years to develop pre-trained language models (PLMs) for the Arabic language. This work addresses two major problems in existing Arabic PLMs that limit the progress of the Arabic NLU and NLG fields. First, existing Arabic PLMs are not well-explored and their pre-training can be improved significantly using a more methodical approach. Second, there is a lack of systematic and reproducible evaluation of these models in the literature. We revisit both the pre-training and evaluation of Arabic PLMs. In terms of pre-training, we explore the impact of the quality of the pretraining data, the size of the model, and the incorporation of character-level information on Arabic PLM. As a result, we release three new Arabic BERT-style models ( JABER, Char-JABER, and SABER), and two T5-style models (AT5S and AT5B). In terms of evaluation, we conduct a comprehensive empirical study to systematically evaluate the performance of existing state-of-the-art models on ALUE, a leaderboard-powered benchmark for Arabic NLU tasks, and on a subset of the Arabic generative tasks. We show that our models significantly outperform existing Arabic PLMs and achieve a new state-of-the-art performance on discriminative and generative Arabic NLU and NLG tasks. Our models and source code to reproduce results will be made available upon acceptance",
    "checked": true,
    "id": "3d3f8399d625238fddb366697acb73446129d65c",
    "semantic_title": "revisiting pre-trained language models and their evaluation for arabic natural language processing",
    "citation_count": 4,
    "authors": [
      "Abbas Ghaddar",
      "Yimeng Wu",
      "Sunyam Bagga",
      "Ahmad Rashid",
      "Khalil Bibi",
      "Mehdi Rezagholizadeh",
      "Chao Xing",
      "Yasheng Wang",
      "Xinyu Duan",
      "Zhefeng Wang",
      "Baoxing Huai",
      "Xin Jiang",
      "Qun Liu",
      "Phillippe Langlais"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.206": {
    "title": "KECP: Knowledge Enhanced Contrastive Prompting for Few-shot Extractive Question Answering",
    "volume": "main",
    "abstract": "Extractive Question Answering (EQA) is one of the most essential tasks in Machine Reading Comprehension (MRC), which can be solved by fine-tuning the span selecting heads of Pre-trained Language Models (PLMs). However, most existing approaches for MRC may perform poorly in the few-shot learning scenario. To solve this issue, we propose a novel framework named Knowledge Enhanced Contrastive Prompt-tuning (KECP). Instead of adding pointer heads to PLMs, we introduce a seminal paradigm for EQA that transforms the task into a non-autoregressive Masked Language Modeling (MLM) generation problem. Simultaneously, rich semantics from the external knowledge base (KB) and the passage context support enhancing the query's representations. In addition, to boost the performance of PLMs, we jointly train the model by the MLM and contrastive learning objectives. Experiments on multiple benchmarks demonstrate that our method consistently outperforms state-of-the-art approaches in few-shot settings by a large margin",
    "checked": true,
    "id": "375c41566e8710c7b6cbf12c1bf6347f5aa23ab8",
    "semantic_title": "kecp: knowledge enhanced contrastive prompting for few-shot extractive question answering",
    "citation_count": 11,
    "authors": [
      "Jianing Wang",
      "Chengyu Wang",
      "Minghui Qiu",
      "Qiuhui Shi",
      "Hongbin Wang",
      "Jun Huang",
      "Ming Gao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.207": {
    "title": "Knowledge Prompting in Pre-trained Language Model for Natural Language Understanding",
    "volume": "main",
    "abstract": "Knowledge-enhanced Pre-trained Language Model (PLM) has recently received significant attention, which aims to incorporate factual knowledge into PLMs. However, most existing methods modify the internal structures of fixed types of PLMs by stacking complicated modules, and introduce redundant and irrelevant factual knowledge from knowledge bases (KBs). In this paper, to address these problems, we introduce a seminal knowledge prompting paradigm and further propose a knowledge-prompting-based PLM framework KP-PLM. This framework can be flexibly combined with existing mainstream PLMs. Specifically, we first construct a knowledge sub-graph from KBs for each context. Then we design multiple continuous prompts rules and transform the knowledge sub-graph into natural language prompts. To further leverage the factual knowledge from these prompts, we propose two novel knowledge-aware self-supervised tasks including prompt relevance inspection and masked prompt modeling. Extensive experiments on multiple natural language understanding (NLU) tasks show the superiority of KP-PLM over other state-of-the-art methods in both full-resource and low-resource settings. Our source codes will be released upon the acceptance of the paper",
    "checked": true,
    "id": "17dcfef70619c0423e0527f0c9d90f4858125f5f",
    "semantic_title": "knowledge prompting in pre-trained language model for natural language understanding",
    "citation_count": 7,
    "authors": [
      "Jianing Wang",
      "Wenkang Huang",
      "Minghui Qiu",
      "Qiuhui Shi",
      "Hongbin Wang",
      "Xiang Li",
      "Ming Gao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.208": {
    "title": "On the Evaluation Metrics for Paraphrase Generation",
    "volume": "main",
    "abstract": "In this paper we revisit automatic metrics for paraphrase evaluation and obtain two findings that disobey conventional wisdom: (1) Reference-free metrics achieve better performance than their reference-based counterparts. (2) Most commonly used metrics do not align well with human annotation.Underlying reasons behind the above findings are explored through additional experiments and in-depth analyses.Based on the experiments and analyses, we propose ParaScore, a new evaluation metric for paraphrase generation. It possesses the merits of reference-based and reference-free metrics and explicitly models lexical divergence. Based on our analysis and improvements, our proposed reference-based outperforms than reference-free metrics.Experimental results demonstrate that ParaScore significantly outperforms existing metrics",
    "checked": true,
    "id": "e1fd982b8d223c0f1594c6e13176758e86b1de67",
    "semantic_title": "on the evaluation metrics for paraphrase generation",
    "citation_count": 26,
    "authors": [
      "Lingfeng Shen",
      "Lemao Liu",
      "Haiyun Jiang",
      "Shuming Shi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.209": {
    "title": "Curriculum Learning Meets Weakly Supervised Multimodal Correlation Learning",
    "volume": "main",
    "abstract": "In the field of multimodal sentiment analysis (MSA), a few studies have leveraged the inherent modality correlation information stored in samples for self-supervised learning. However, they feed the training pairs in a random order without consideration of difficulty. Without human annotation, the generated training pairs of self-supervised learning often contain noise. If noisy or hard pairs are used for training at the easy stage, the model might be stuck in bad local optimum. In this paper, we inject curriculum learning into weakly supervised multimodal correlation learning. The weakly supervised correlation learning leverages the label information to generate scores for negative pairs to learn a more discriminative embedding space, where negative pairs are defined as two unimodal embeddings from different samples. To assist the correlation learning, we feed the training pairs to the model according to difficulty by the proposed curriculum learning, which consists of elaborately designed scoring and feeding functions. The scoring function computes the difficulty of pairs using pre-trained and current correlation predictors, where the pairs with large losses are defined as hard pairs. Notably, the hardest pairs are discarded in our algorithm, which are assumed as noisy pairs. Moreover, the feeding function takes the difference of correlation losses as feedback to determine the feeding actions (‘stay', ‘step back', or ‘step forward'). The proposed method reaches state-of-the-art performance on MSA",
    "checked": true,
    "id": "775e8ce3e01690e78c7dcfc86c265b3d62226d7c",
    "semantic_title": "curriculum learning meets weakly supervised multimodal correlation learning",
    "citation_count": 0,
    "authors": [
      "Sijie Mai",
      "Ya Sun",
      "Haifeng Hu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.210": {
    "title": "Rethinking Positional Encoding in Tree Transformer for Code Representation",
    "volume": "main",
    "abstract": "Transformers are now widely used in code representation, and several recent works further develop tree Transformers to capture the syntactic structure in source code. Specifically, novel tree positional encodings have been proposed to incorporate inductive bias into Transformer.In this work, we propose a novel tree Transformer encoding node positions based on our new description method for tree structures.Technically, local and global soft bias shown in previous works is both introduced as positional encodings of our Transformer model.Our model finally outperforms strong baselines on code summarization and completion tasks across two languages, demonstrating our model's effectiveness.Besides, extensive experiments and ablation study shows that combining both local and global paradigms is still helpful in improving model performance. We release our code at https://github.com/AwdHanPeng/TreeTransformer",
    "checked": true,
    "id": "20333c34f892c8e0c2f4e6c37295a8b43ef35c02",
    "semantic_title": "rethinking positional encoding in tree transformer for code representation",
    "citation_count": 7,
    "authors": [
      "Han Peng",
      "Ge Li",
      "Yunfei Zhao",
      "Zhi Jin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.211": {
    "title": "RASAT: Integrating Relational Structures into Pretrained Seq2Seq Model for Text-to-SQL",
    "volume": "main",
    "abstract": "Relational structures such as schema linking and schema encoding have been validated as a key component to qualitatively translating natural language into SQL queries. However, introducing these structural relations comes with prices: they often result in a specialized model structure, which largely prohibits using large pretrained models in text-to-SQL. To address this problem, we propose RASAT: a Transformer seq2seq architecture augmented with relation-aware self-attention that could leverage a variety of relational structures while inheriting the pretrained parameters from the T5 model effectively. Our model can incorporate almost all types of existing relations in the literature, and in addition, we propose introducing co-reference relations for the multi-turn scenario. Experimental results on three widely used text-to-SQL datasets, covering both single-turn and multi-turn scenarios, have shown that RASAT could achieve competitive results in all three benchmarks, achieving state-of-the-art execution accuracy (75.5% EX on Spider, 52.6% IEX on SParC, and 37.4% IEX on CoSQL)",
    "checked": true,
    "id": "14793aa93920cb8f748776cc45c3895de6df5fbf",
    "semantic_title": "rasat: integrating relational structures into pretrained seq2seq model for text-to-sql",
    "citation_count": 75,
    "authors": [
      "Jiexing Qi",
      "Jingyao Tang",
      "Ziwei He",
      "Xiangpeng Wan",
      "Yu Cheng",
      "Chenghu Zhou",
      "Xinbing Wang",
      "Quanshi Zhang",
      "Zhouhan Lin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.212": {
    "title": "COM-MRC: A COntext-Masked Machine Reading Comprehension Framework for Aspect Sentiment Triplet Extraction",
    "volume": "main",
    "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to extract sentiment triplets from sentences, which was recently formalized as an effective machine reading comprehension (MRC) based framework. However, when facing multiple aspect terms, the MRC-based methods could fail due to the interference from other aspect terms. In this paper, we propose a novel COntext-Masked MRC (COM-MRC) framework for ASTE. Our COM-MRC framework comprises three closely-related components: a context augmentation strategy, a discriminative model, and an inference method. Specifically, a context augmentation strategy is designed by enumerating all masked contexts for each aspect term. The discriminative model comprises four modules, i.e., aspect and opinion extraction modules, sentiment classification and aspect detection modules. In addition, a two-stage inference method first extracts all aspects and then identifies their opinions and sentiment through iteratively masking the aspects. Extensive experimental results on benchmark datasets show the effectiveness of our proposed COM-MRC framework, which outperforms state-of-the-art methods consistently",
    "checked": true,
    "id": "c25a9acc1361ad1501c63d2830671630c3ba30dc",
    "semantic_title": "com-mrc: a context-masked machine reading comprehension framework for aspect sentiment triplet extraction",
    "citation_count": 13,
    "authors": [
      "Zepeng Zhai",
      "Hao Chen",
      "Fangxiang Feng",
      "Ruifan Li",
      "Xiaojie Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.213": {
    "title": "CEM: Machine-Human Chatting Handoff via Causal-Enhance Module",
    "volume": "main",
    "abstract": "Aiming to ensure chatbot quality by predicting chatbot failure and enabling human-agent collaboration, Machine-Human Chatting Handoff (MHCH) has attracted lots of attention from both industry and academia in recent years. However, most existing methods mainly focus on the dialogue context or assist with global satisfaction prediction based on multi-task learning, which ignore the grounded relationships among the causal variables, like the user state and labor cost. These variables are significantly associated with handoff decisions, resulting in prediction bias and cost increasement. Therefore, we propose Causal-Enhance Module (CEM) by establishing the causal graph of MHCH based on these two variables, which is a simple yet effective module and can be easy to plug into the existing MHCH methods. For the impact of users, we use the user state to correct the prediction bias according to the causal relationship of multi-task. For the labor cost, we train an auxiliary cost simulator to calculate unbiased labor cost through counterfactual learning so that a model becomes cost-aware.Extensive experiments conducted on four real-world benchmarks demonstrate the effectiveness of CEM in generally improving the performance of existing MHCH methods without any elaborated model crafting",
    "checked": true,
    "id": "920e846922002d36e062b923c58217d09ca66dfe",
    "semantic_title": "cem: machine-human chatting handoff via causal-enhance module",
    "citation_count": 3,
    "authors": [
      "Shanshan Zhong",
      "Jinghui Qin",
      "Zhongzhan Huang",
      "Daifeng Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.214": {
    "title": "Nearest Neighbor Zero-Shot Inference",
    "volume": "main",
    "abstract": "Retrieval-augmented language models (LMs) use non-parametric memory to substantially outperform their non-retrieval counterparts on perplexity-based evaluations, but it is an open question whether they achieve similar gains in few- and zero-shot end-task accuracy. We extensively study one such model, the k-nearest neighbor LM (kNN-LM), showing that the gains marginally transfer. The main challenge is to achieve coverage of the verbalizer tokens that define the different end-task class labels. To address this challenge, we also introduce kNN-Prompt, a simple and effective kNN-LM with automatically expanded fuzzy verbalizers (e.g. to expand \"terrible\" to also include \"silly\" and other task-specific synonyms for sentiment classification). Across nine diverse end-tasks, using kNN-Prompt with GPT-2 large yields significant performance boosts over strong zeroshot baselines (13.4% absolute improvement over the base LM on average). We also show that other advantages of non-parametric augmentation hold for end tasks; kNN-Prompt is effective for domain adaptation with no further training, and gains increase with the size of the retrieval model",
    "checked": true,
    "id": "563a851106623b9f112d0e2a290d3950a871079c",
    "semantic_title": "nearest neighbor zero-shot inference",
    "citation_count": 27,
    "authors": [
      "Weijia Shi",
      "Julian Michael",
      "Suchin Gururangan",
      "Luke Zettlemoyer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.215": {
    "title": "Robots-Dont-Cry: Understanding Falsely Anthropomorphic Utterances in Dialog Systems",
    "volume": "main",
    "abstract": "Dialog systems are often designed or trained to output human-like responses. However, some responses may be impossible for a machine to truthfully say (e.g. \"that movie made me cry\"). Highly anthropomorphic responses might make users uncomfortable or implicitly deceive them into thinking they are interacting with a human. We collect human ratings on the feasibility of approximately 900 two-turn dialogs sampled from 9 diverse data sources. Ratings are for two hypothetical machine embodiments: a futuristic humanoid robot and a digital assistant. We find that for some data-sources commonly used to train dialog systems, 20-30% of utterances are not viewed as possible for a machine. Rating is marginally affected by machine embodiment. We explore qualitative and quantitative reasons for these ratings. Finally, we build classifiers and explore how modeling configuration might affect output permissibly, and discuss implications for building less falsely anthropomorphic dialog systems",
    "checked": true,
    "id": "8c5dfc418b937ba78e481ca46a5f43ac61863059",
    "semantic_title": "robots-dont-cry: understanding falsely anthropomorphic utterances in dialog systems",
    "citation_count": 5,
    "authors": [
      "David Gros",
      "Yu Li",
      "Zhou Yu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.216": {
    "title": "A Joint Learning Framework for Restaurant Survival Prediction and Explanation",
    "volume": "main",
    "abstract": "The bloom of the Internet and the recent breakthroughs in deep learning techniques open a new door to AI for E-commence, with a trend of evolving from using a few financial factors such as liquidity and profitability to using more advanced AI techniques to process complex and multi-modal data. In this paper, we tackle the practical problem of restaurant survival prediction. We argue that traditional methods ignore two essential respects, which are very helpful for the task: 1) modeling customer reviews and 2) jointly considering status prediction and result explanation. Thus, we propose a novel joint learning framework for explainable restaurant survival prediction based on the multi-modal data of user-restaurant interactions and users' textual reviews. Moreover, we design a graph neural network to capture the high-order interactions and design a co-attention mechanism to capture the most informative and meaningful signal from noisy textual reviews. Our results on two datasets show a significant and consistent improvement over the SOTA techniques (average 6.8% improvement in prediction and 45.3% improvement in explanation)",
    "checked": true,
    "id": "557c0c65b6485d51cb46c500bcadef66849cb98b",
    "semantic_title": "a joint learning framework for restaurant survival prediction and explanation",
    "citation_count": 0,
    "authors": [
      "Xin Li",
      "Xiaojie Zhang",
      "Peng JiaHao",
      "Rui Mao",
      "Mingyang Zhou",
      "Xing Xie",
      "Hao Liao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.217": {
    "title": "Making Pretrained Language Models Good Long-tailed Learners",
    "volume": "main",
    "abstract": "Prompt-tuning has shown appealing performance in few-shot classification by virtue of its capability in effectively exploiting pre-trained knowledge. This motivates us to check the hypothesis that prompt-tuning is also a promising choice for long-tailed classification, since the tail classes are intuitively few-shot ones. To achieve this aim, we conduct empirical studies to examine the hypothesis. The results demonstrate that prompt-tuning makes pretrained language models at least good long-tailed learners. For intuitions on why prompt-tuning can achieve good performance in long-tailed classification, we carry out in-depth analyses by progressively bridging the gap between prompt-tuning and commonly used finetuning. The summary is that the classifier structure and parameterization form the key to making good long-tailed learners, in comparison with the less important input structure. Finally, we verify the applicability of our finding to few-shot classification",
    "checked": true,
    "id": "36eb603c63eab74179f7e4536bd07d5d4c329759",
    "semantic_title": "making pretrained language models good long-tailed learners",
    "citation_count": 7,
    "authors": [
      "Chen Zhang",
      "Lei Ren",
      "Jingang Wang",
      "Wei Wu",
      "Dawei Song"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.218": {
    "title": "UniGeo: Unifying Geometry Logical Reasoning via Reformulating Mathematical Expression",
    "volume": "main",
    "abstract": "Geometry problem solving is a well-recognized testbed for evaluating the high-level multi-modal reasoning capability of deep models. In most existing works, two main geometry problems: calculation and proving, are usually treated as two specific tasks, hindering a deep model to unify its reasoning capability on multiple math tasks. However, in essence, these two tasks have similar problem representations and overlapped math knowledge which can improve the understanding and reasoning ability of a deep model on both two tasks. Therefore, we construct a large-scale Unified Geometry problem benchmark, UniGeo, which contains 4,998 calculation problems and 9,543 proving problems. Each proving problem is annotated with a multi-step proof with reasons and mathematical expressions. The proof can be easily reformulated as a proving sequence that shares the same formats with the annotated program sequence for calculation problems. Naturally, we also present a unified multi-task Geometric Transformer framework, Geoformer, to tackle calculation and proving problems simultaneously in the form of sequence generation, which finally shows the reasoning ability can be improved on both two tasks by unifying formulation. Furthermore, we propose a Mathematical Expression Pretraining (MEP) method that aims to predict the mathematical expressions in the problem solution, thus improving the Geoformer model. Experiments on the UniGeo demonstrate that our proposed Geoformer obtains state-of-the-art performance by outperforming task-specific model NGS with over 5.6% and 3.2% accuracies on calculation and proving problems, respectively",
    "checked": true,
    "id": "72fce949725b20428e5f56247fef5c6bd1ce6154",
    "semantic_title": "unigeo: unifying geometry logical reasoning via reformulating mathematical expression",
    "citation_count": 41,
    "authors": [
      "Jiaqi Chen",
      "Tong Li",
      "Jinghui Qin",
      "Pan Lu",
      "Liang Lin",
      "Chongyu Chen",
      "Xiaodan Liang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.219": {
    "title": "Face-Sensitive Image-to-Emotional-Text Cross-modal Translation for Multimodal Aspect-based Sentiment Analysis",
    "volume": "main",
    "abstract": "Aspect-level multimodal sentiment analysis, which aims to identify the sentiment of the target aspect from multimodal data, recently has attracted extensive attention in the community of multimedia and natural language processing. Despite the recent success in textual aspect-based sentiment analysis, existing models mainly focused on utilizing the object-level semantic information in the image but ignore explicitly using the visual emotional cues, especially the facial emotions. How to distill visual emotional cues and align them with the textual content remains a key challenge to solve the problem. In this work, we introduce a face-sensitive image-to-emotional-text translation (FITE) method, which focuses on capturing visual sentiment cues through facial expressions and selectively matching and fusing with the target aspect in textual modality. To the best of our knowledge, we are the first that explicitly utilize the emotional information from images in the multimodal aspect-based sentiment analysis task. Experiment results show that our method achieves state-of-the-art results on the Twitter-2015 and Twitter-2017 datasets. The improvement demonstrates the superiority of our model in capturing aspect-level sentiment in multimodal data with facial expressions",
    "checked": true,
    "id": "78f90295ef8f808b6d5ca3d7d9b56f8983e80895",
    "semantic_title": "face-sensitive image-to-emotional-text cross-modal translation for multimodal aspect-based sentiment analysis",
    "citation_count": 16,
    "authors": [
      "Hao Yang",
      "Yanyan Zhao",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.220": {
    "title": "FineD-Eval: Fine-grained Automatic Dialogue-Level Evaluation",
    "volume": "main",
    "abstract": "Recent model-based reference-free metrics for open-domain dialogue evaluation exhibit promising correlations with human judgment. However, they either perform turn-level evaluation or look at a single dialogue quality dimension. One would expect a good evaluation metric to assess multiple quality dimensions at the dialogue level. To this end, we are motivated to propose a multi-dimensional dialogue-level metric, which consists of three sub-metrics with each targeting a specific dimension. The sub-metrics are trained with novel self-supervised objectives and exhibit strong correlations with human judgment for their respective dimensions. Moreover, we explore two approaches to combine the sub-metrics: metric ensemble and multitask learning. Both approaches yield a holistic metric that significantly outperforms individual sub-metrics. Compared to the existing state-of-the-art metric, the combined metrics achieve around 16% relative improvement on average across three high-quality dialogue-level evaluation benchmarks",
    "checked": true,
    "id": "a6f171598db5a21ece1ac38010c48df19b2b23ca",
    "semantic_title": "fined-eval: fine-grained automatic dialogue-level evaluation",
    "citation_count": 13,
    "authors": [
      "Chen Zhang",
      "Luis Fernando D’Haro",
      "Qiquan Zhang",
      "Thomas Friedrichs",
      "Haizhou Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.221": {
    "title": "Sentence Representation Learning with Generative Objective rather than Contrastive Objective",
    "volume": "main",
    "abstract": "Though offering amazing contextualized token-level representations, current pre-trained language models take less attention on accurately acquiring sentence-level representation during their self-supervised pre-training. However, contrastive objectives which dominate the current sentence representation learning bring little linguistic interpretability and no performance guarantee on downstream semantic tasks. We instead propose a novel generative self-supervised learning objective based on phrase reconstruction. To overcome the drawbacks of previous generative methods, we carefully model intra-sentence structure by breaking down one sentence into pieces of important phrases. Empirical studies show that our generative learning achieves powerful enough performance improvement and outperforms the current state-of-the-art contrastive methods not only on the STS benchmarks, but also on downstream semantic retrieval and reranking tasks. Our code is available at https://github.com/chengzhipanpan/PaSeR",
    "checked": true,
    "id": "64807d99b823dfa41eeb01e563aa78b1a64347b6",
    "semantic_title": "sentence representation learning with generative objective rather than contrastive objective",
    "citation_count": 7,
    "authors": [
      "Bohong Wu",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.222": {
    "title": "RLPrompt: Optimizing Discrete Text Prompts with Reinforcement Learning",
    "volume": "main",
    "abstract": "Prompting has shown impressive success in enabling large pre-trained language models (LMs) to perform diverse NLP tasks, especially with only few downstream data. Automatically finding the optimal prompt for each task, however, is challenging. Most existing work resorts to tuning *soft* prompts (e.g., embeddings) which fall short of interpretability, reusability across LMs, and applicability when gradients are not accessible. *Discrete* prompts, on the other hand, are difficult to optimize, and are often created by \"enumeration (e.g., paraphrasing)-then-selection\" heuristics that do not explore the prompt space systematically. This paper proposes RLPrompt, an efficient discrete prompt optimization approach with reinforcement learning (RL). RLPrompt formulates a parameter-efficient policy network that generates the optimized discrete prompt after training with reward. To harness the complex and stochastic reward signals from the large LM environment, we incorporate effective reward stabilization that substantially enhances training efficiency. RLPrompt is flexibly applicable to different types of LMs, such as masked (e.g., BERT) and left-to-right models (e.g., GPTs), for both classification and generation tasks. Experiments on few-shot classification and unsupervised text style transfer show superior performance over a wide range of existing fine-tuning or prompting methods. Interestingly, the resulting optimized prompts are often ungrammatical gibberish text; and surprisingly, those gibberish prompts are transferrable between different LMs to retain significant performance, indicating that LM prompting may not follow human language patterns",
    "checked": true,
    "id": "07759a84f27e43cfa5bc8d579f8227c96e6ae1dc",
    "semantic_title": "rlprompt: optimizing discrete text prompts with reinforcement learning",
    "citation_count": 236,
    "authors": [
      "Mingkai Deng",
      "Jianyu Wang",
      "Cheng-Ping Hsieh",
      "Yihan Wang",
      "Han Guo",
      "Tianmin Shu",
      "Meng Song",
      "Eric Xing",
      "Zhiting Hu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.223": {
    "title": "DisCup: Discriminator Cooperative Unlikelihood Prompt-tuning for Controllable Text Generation",
    "volume": "main",
    "abstract": "Prompt learning with immensely large Casual Language Models (CLMs) has been shown promising for attribute-controllable text generation (CTG). However, vanilla prompt tuning tends to imitate training corpus characteristics beyond the control attributes, resulting in a poor generalization ability. Moreover, it is less able to capture the relationship between different attributes, further limiting the control performance. In this paper, we propose a new CTG approach, namely DisCup, which incorporates the attribute knowledge of discriminator to optimize the control-prompts, steering a frozen CLM to produce attribute-specific texts. Specifically, the frozen CLM model, capable of producing multitudinous texts, is first used to generate the next-token candidates based on the context, so as to ensure the diversity of tokens to be predicted. Then, we leverage an attribute-discriminator to select desired/undesired tokens from those candidates, providing the inter-attribute knowledge. Finally, we bridge the above two traits by an unlikelihood objective for prompt-tuning. Extensive experimental results show that DisCup can achieve a new state-of-the-art control performance while maintaining an efficient and high-quality text generation, only relying on around 10 virtual tokens",
    "checked": true,
    "id": "f7122057d86f4f9f2d28565d5e2709a8b7cc6fdb",
    "semantic_title": "discup: discriminator cooperative unlikelihood prompt-tuning for controllable text generation",
    "citation_count": 27,
    "authors": [
      "Hanqing Zhang",
      "Dawei Song"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.224": {
    "title": "CPL: Counterfactual Prompt Learning for Vision and Language Models",
    "volume": "main",
    "abstract": "Prompt tuning is a new few-shot transfer learning technique that only tunes the learnable prompt for pre-trained vision and language models such as CLIP. However, existing prompt tuning methods tend to learn spurious or entangled representations, which leads to poor generalization to unseen concepts.Towards non-spurious and efficient prompt learning from limited examples, this paper presents a novel Counterfactual Prompt Learning (CPL) method for vision and language models, which simultaneously employs counterfactual generation and contrastive learning in a joint optimization framework.Particularly, CPL constructs counterfactual by identifying minimal non-spurious feature change between semantically-similar positive and negative samples that causes concept change, and learns more generalizable prompt representation from both factual and counterfactual examples via contrastive learning. Extensive experiments demonstrate that CPL can obtain superior few-shot performance on different vision and language tasks than previous prompt tuning methods on CLIP. On image classification, we achieve 3.55% average relative improvement on unseen classes across seven datasets; on image-text retrieval and visual question answering, we gain up to 4.09% and 25.08% relative improvements across three few-shot scenarios on unseen test sets respectively",
    "checked": true,
    "id": "7c4be464e68a11c8f254d9608f31280e9bcda85c",
    "semantic_title": "cpl: counterfactual prompt learning for vision and language models",
    "citation_count": 11,
    "authors": [
      "Xuehai He",
      "Diji Yang",
      "Weixi Feng",
      "Tsu-Jui Fu",
      "Arjun Akula",
      "Varun Jampani",
      "Pradyumna Narayana",
      "Sugato Basu",
      "William Yang Wang",
      "Xin Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.225": {
    "title": "Red Teaming Language Models with Language Models",
    "volume": "main",
    "abstract": "Language Models (LMs) often cannot be deployed because of their potential to harm users in hard-to-predict ways. Prior work identifies harmful behaviors before deployment by using human annotators to hand-write test cases. However, human annotation is expensive, limiting the number and diversity of test cases. In this work, we automatically find cases where a target LM behaves in a harmful way, by generating test cases (\"red teaming\") using another LM. We evaluate the target LM's replies to generated test questions using a classifier trained to detect offensive content, uncovering tens of thousands of offensive replies in a 280B parameter LM chatbot. We explore several methods, from zero-shot generation to reinforcement learning, for generating test cases with varying levels of diversity and difficulty. Furthermore, we use prompt engineering to control LM-generated test cases to uncover a variety of other harms, automatically finding groups of people that the chatbot discusses in offensive ways, personal and hospital phone numbers generated as the chatbot's own contact info, leakage of private training data in generated text, and harms that occur over the course of a conversation. Overall, LM-based red teaming is one promising tool (among many needed) for finding and fixing diverse, undesirable LM behaviors before impacting users",
    "checked": true,
    "id": "5d49c7401c5f2337c4cc88d243ae39ed659afe64",
    "semantic_title": "red teaming language models with language models",
    "citation_count": 414,
    "authors": [
      "Ethan Perez",
      "Saffron Huang",
      "Francis Song",
      "Trevor Cai",
      "Roman Ring",
      "John Aslanides",
      "Amelia Glaese",
      "Nat McAleese",
      "Geoffrey Irving"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.226": {
    "title": "CapOnImage: Context-driven Dense-Captioning on Image",
    "volume": "main",
    "abstract": "Existing image captioning systems are dedicated to generating narrative captions for images, which are spatially detached from theimage in presentation. However, texts can also be used as decorations on the image to highlight the key points and increase theattractiveness of images. In this work, we introduce a new taskcalled captioning on image (CapOnImage), which aims to generatedense captions at different locations of the image based on contextual information. To fully exploit the surrounding visual context togenerate the most suitable caption for each location, we propose amulti-modal pre-training model with multi-level pre-training tasksthat progressively learn the correspondence between texts and image locations from easy to difficult. Since the model may generateredundant captions for nearby locations, we further enhance thelocation embedding with neighbor locations as context. For thisnew task, we also introduce a large-scale benchmark called CapOnImage2M, which contains 2.1 million product images, each with anaverage of 4.8 spatially localized captions. Compared with other image captioning model variants, our model achieves the best resultsin both captioning accuracy and diversity aspects",
    "checked": true,
    "id": "140f83a8774b1b847aa0aa6a5b0ac63fce27bb00",
    "semantic_title": "caponimage: context-driven dense-captioning on image",
    "citation_count": 8,
    "authors": [
      "Yiqi Gao",
      "Xinglin Hou",
      "Yuanmeng Zhang",
      "Tiezheng Ge",
      "Yuning Jiang",
      "Peng Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.227": {
    "title": "SpanProto: A Two-stage Span-based Prototypical Network for Few-shot Named Entity Recognition",
    "volume": "main",
    "abstract": "Few-shot Named Entity Recognition (NER) aims to identify named entities with very little annotated data. Previous methods solve this problem based on token-wise classification, which ignores the information of entity boundaries, and inevitably the performance is affected by the massive non-entity tokens. To this end, we propose a seminal span-based prototypical network (SpanProto) that tackles few-shot NER via a two-stage approach, including span extraction and mention classification. In the span extraction stage, we transform the sequential tags into a global boundary matrix, enabling the model to focus on the explicit boundary information. For mention classification, we leverage prototypical learning to capture the semantic representations for each labeled span and make the model better adapt to novel-class entities. To further improve the model performance, we split out the false positives generated by the span extractor but not labeled in the current episode set, and then present a margin-based loss to separate them from each prototype region. Experiments over multiple benchmarks demonstrate that our model outperforms strong baselines by a large margin",
    "checked": true,
    "id": "d6bf4916fd488fd76985f7f487e2f054985801eb",
    "semantic_title": "spanproto: a two-stage span-based prototypical network for few-shot named entity recognition",
    "citation_count": 11,
    "authors": [
      "Jianing Wang",
      "Chengyu Wang",
      "Chuanqi Tan",
      "Minghui Qiu",
      "Songfang Huang",
      "Jun Huang",
      "Ming Gao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.228": {
    "title": "Discovering Differences in the Representation of People using Contextualized Semantic Axes",
    "volume": "main",
    "abstract": "A common paradigm for identifying semantic differences across social and temporal contexts is the use of static word embeddings and their distances. In particular, past work has compared embeddings against \"semantic axes\" that represent two opposing concepts. We extend this paradigm to BERT embeddings, and construct contextualized axes that mitigate the pitfall where antonyms have neighboring representations. We validate and demonstrate these axes on two people-centric datasets: occupations from Wikipedia, and multi-platform discussions in extremist, men's communities over fourteen years. In both studies, contextualized semantic axes can characterize differences among instances of the same word type. In the latter study, we show that references to women and the contexts around them have become more detestable over time",
    "checked": true,
    "id": "7f5801f8036e71658a12d16203617b2ab25ef14f",
    "semantic_title": "discovering differences in the representation of people using contextualized semantic axes",
    "citation_count": 9,
    "authors": [
      "Li Lucy",
      "Divya Tadimeti",
      "David Bamman"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.229": {
    "title": "Generating Literal and Implied Subquestions to Fact-check Complex Claims",
    "volume": "main",
    "abstract": "Verifying political claims is a challenging task, as politicians can use various tactics to subtly misrepresent the facts for their agenda. Existing automatic fact-checking systems fall short here, and their predictions like \"half-true\" are not very useful in isolation, since it is unclear which parts of a claim are true and which are not. In this work, we focus on decomposing a complex claim into a comprehensive set of yes-no subquestions whose answers influence the veracity of the claim. We present CLAIMDECOMP, a dataset of decompositions for over 1000 claims. Given a claim and its verification paragraph written by fact-checkers, our trained annotators write subquestions covering both explicit propositions of the original claim and its implicit facets, such as asking about additional political context that changes our view of the claim's veracity. We study whether state-of-the-art models can generate such subquestions, showing that these models generate reasonable questions to ask, but predicting the comprehensive set of subquestions from the original claim without evidence remains challenging. We further show that these subquestions can help identify relevant evidence to fact-check the full claim and derive the veracity through their answers, suggesting that they can be useful pieces of a fact-checking pipeline",
    "checked": true,
    "id": "628f08810dfd5b824caf9d831c79c11102fcd207",
    "semantic_title": "generating literal and implied subquestions to fact-check complex claims",
    "citation_count": 36,
    "authors": [
      "Jifan Chen",
      "Aniruddh Sriram",
      "Eunsol Choi",
      "Greg Durrett"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.230": {
    "title": "Machine Translation Robustness to Natural Asemantic Variation",
    "volume": "main",
    "abstract": "Current Machine Translation (MT) models still struggle with more challenging input, such as noisy data and tail-end words and phrases. Several works have addressed this robustness issue by identifying specific categories of noise and variation then tuning models to perform better on them. An important yet under-studied category involves minor variations in nuance (non-typos) that preserve meaning w.r.t. the target language. We introduce and formalize this category as Natural Asemantic Variation (NAV) and investigate it in the context of MT robustness. We find that existing MT models fail when presented with NAV data, but we demonstrate strategies to improve performance on NAV by fine-tuning them with human-generated variations. We also show that NAV robustness can be transferred across languages and find that synthetic perturbations can achieve some but not all of the benefits of organic NAV data",
    "checked": true,
    "id": "4743ee49af83d3010549ee105e0c193b36fa239a",
    "semantic_title": "machine translation robustness to natural asemantic variation",
    "citation_count": 0,
    "authors": [
      "Jacob Bremerman",
      "Xiang Ren",
      "Jonathan May"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.231": {
    "title": "Natural Language to Code Translation with Execution",
    "volume": "main",
    "abstract": "Generative models of code, pretrained on large corpora of programs, have shown great success in translating natural language to code (Chen et al., 2021; Austin et al., 2021; Li et al., 2022, inter alia). While these models do not explicitly incorporate program semantics (i.e., execution results) during training, they are able to generate correct solutions for many problems. However, choosing a single correct program from a generated set for each problem remains challenging. In this work, we introduce execution result–based minimum Bayes risk decoding (MBR-EXEC) for program selection and show that it improves the few-shot performance of pretrained code models on natural-language-to-code tasks. We select output programs from a generated candidate set by marginalizing over program implementations that share the same semantics. Because exact equivalence is intractable, we execute each program on a small number of test inputs to approximate semantic equivalence. Across datasets, execution or simulated execution significantly outperforms the methods that do not involve program semantics. We find that MBR-EXEC consistently improves over all execution-unaware selection methods, suggesting it as an effective approach for natural language to code translation",
    "checked": true,
    "id": "47e15941c8b157873c8264e4bf50318d1ba5cd18",
    "semantic_title": "natural language to code translation with execution",
    "citation_count": 90,
    "authors": [
      "Freda Shi",
      "Daniel Fried",
      "Marjan Ghazvininejad",
      "Luke Zettlemoyer",
      "Sida I. Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.232": {
    "title": "Life is a Circus and We are the Clowns: Automatically Finding Analogies between Situations and Processes",
    "volume": "main",
    "abstract": "Analogy-making gives rise to reasoning, abstraction, flexible categorization and counterfactual inference – abilities lacking in even the best AI systems today. Much research has suggested that analogies are key to non-brittle systems that can adapt to new domains. Despite their importance, analogies received little attention in the NLP community, with most research focusing on simple word analogies. Work that tackled more complex analogies relied heavily on manually constructed, hard-to-scale input representations.In this work, we explore a more realistic, challenging setup: our input is a pair of natural language procedural texts, describing a situation or a process (e.g., how the heart works/how a pump works). Our goal is to automatically extract entities and their relations from the text and find a mapping between the different domains based on relational similarity (e.g., blood is mapped to water). We develop an interpretable, scalable algorithm and demonstrate that it identifies the correct mappings 87% of the time for procedural texts and 94% for stories from cognitive-psychology literature. We show it can extract analogies from a large dataset of procedural texts, achieving 79% precision (analogy prevalence in data: 3%). Lastly, we demonstrate that our algorithm is robust to paraphrasing the input texts",
    "checked": true,
    "id": "750477d9c63652e8d5124e10952895863d5c5df5",
    "semantic_title": "life is a circus and we are the clowns: automatically finding analogies between situations and processes",
    "citation_count": 17,
    "authors": [
      "Oren Sultan",
      "Dafna Shahaf"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.233": {
    "title": "Language Contamination Helps Explains the Cross-lingual Capabilities of English Pretrained Models",
    "volume": "main",
    "abstract": "English pretrained language models, which make up the backbone of many modern NLP systems, require huge amounts of unlabeled training data. These models are generally presented as being trained only on English text but have been found to transfer surprisingly well to other languages. We investigate this phenomenon and find that common English pretraining corpora actually contain significant amounts of non-English text: even when less than 1% of data is not English (well within the error rate of strong language classifiers), this leads to hundreds of millions of foreign language tokens in large-scale datasets. We then demonstrate that even these small percentages of non-English data facilitate cross-lingual transfer for models trained on them, with target language performance strongly correlated to the amount of in-language data seen during pretraining. In light of these findings, we argue that no model is truly monolingual when pretrained at scale, which should be considered when evaluating cross-lingual transfer",
    "checked": true,
    "id": "48ac4aa7e1d8bfabea4ee39b814fab85aa3e5775",
    "semantic_title": "language contamination helps explains the cross-lingual capabilities of english pretrained models",
    "citation_count": 63,
    "authors": [
      "Terra Blevins",
      "Luke Zettlemoyer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.234": {
    "title": "Analyzing the Mono- and Cross-Lingual Pretraining Dynamics of Multilingual Language Models",
    "volume": "main",
    "abstract": "The emergent cross-lingual transfer seen in multilingual pretrained models has sparked significant interest in studying their behavior. However, because these analyses have focused on fully trained multilingual models, little is known about the dynamics of the multilingual pretraining process. We investigate when these models acquire their in-language and cross-lingual abilities by probing checkpoints taken from throughout XLM-R pretraining, using a suite of linguistic tasks. Our analysis shows that the model achieves high in-language performance early on, with lower-level linguistic skills acquired before more complex ones. In contrast, the point in pretraining when the model learns to transfer cross-lingually differs across language pairs. Interestingly, we also observe that, across many languages and tasks, the final model layer exhibits significant performance degradation over time, while linguistic knowledge propagates to lower layers of the network. Taken together, these insights highlight the complexity of multilingual pretraining and the resulting varied behavior for different languages over time",
    "checked": true,
    "id": "0b4f0f6b04476c4f2cdfeabf99d4b835227f0bb2",
    "semantic_title": "analyzing the mono- and cross-lingual pretraining dynamics of multilingual language models",
    "citation_count": 22,
    "authors": [
      "Terra Blevins",
      "Hila Gonen",
      "Luke Zettlemoyer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.235": {
    "title": "Neural Machine Translation with Contrastive Translation Memories",
    "volume": "main",
    "abstract": "Retrieval-augmented Neural Machine Translation models have been successful in many translation scenarios. Different from previous works that make use of mutually similar but redundant translation memories (TMs), we propose a new retrieval-augmented NMT to model contrastively retrieved translation memories that are holistically similar to the source sentence while individually contrastive to each other providing maximal information gain in three phases. First, in TM retrieval phase, we adopt contrastive retrieval algorithm to avoid redundancy and uninformativeness of similar translation pieces. Second, in memory encoding stage, given a set of TMs we propose a novel Hierarchical Group Attention module to gather both local context of each TM and global context of the whole TM set. Finally, in training phase, a Multi-TM contrastive learning objective is introduced to learn salient feature of each TM with respect to target sentence. Experimental results show that our framework obtains substantial improvements over strong baselines in the benchmark dataset",
    "checked": true,
    "id": "c2aac903c0645395fd99c2b0e827971c867d541a",
    "semantic_title": "neural machine translation with contrastive translation memories",
    "citation_count": 10,
    "authors": [
      "Xin Cheng",
      "Shen Gao",
      "Lemao Liu",
      "Dongyan Zhao",
      "Rui Yan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.236": {
    "title": "Distilling Causal Effect from Miscellaneous Other-Class for Continual Named Entity Recognition",
    "volume": "main",
    "abstract": "Continual Learning for Named Entity Recognition (CL-NER) aims to learn a growing number of entity types over time from a stream of data. However, simply learning Other-Class in the same way as new entity types amplifies the catastrophic forgetting and leads to a substantial performance drop. The main cause behind this is that Other-Class samples usually contain old entity types, and the old knowledge in these Other-Class samples is not preserved properly. Thanks to the causal inference, we identify that the forgetting is caused by the missing causal effect from the old data.To this end, we propose a unified causal framework to retrieve the causality from both new entity types and Other-Class.Furthermore, we apply curriculum learning to mitigate the impact of label noise and introduce a self-adaptive weight for balancing the causal effects between new entity types and Other-Class. Experimental results on three benchmark datasets show that our method outperforms the state-of-the-art method by a large margin. Moreover, our method can be combined with the existing state-of-the-art methods to improve the performance in CL-NER",
    "checked": true,
    "id": "2cad84f86b4632b356642c2c3ac799cc94383e0c",
    "semantic_title": "distilling causal effect from miscellaneous other-class for continual named entity recognition",
    "citation_count": 8,
    "authors": [
      "Junhao Zheng",
      "Zhanxian Liang",
      "Haibin Chen",
      "Qianli Ma"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.237": {
    "title": "Exploring the Secrets Behind the Learning Difficulty of Meaning Representations for Semantic Parsing",
    "volume": "main",
    "abstract": "Previous research has shown that the design of Meaning Representation (MR) greatly influences the final model performance of a neural semantic parser. Therefore, designing a good MR is a long-term goal for semantic parsing. However, it is still an art as there is no quantitative indicator that can tell us which MR among a set of candidates may have the best final model performance. In practice, in order toselect an MR design, researchers often have to go through the whole training-testing process for all design candidates, and the process often costs a lot. In this paper, we propose a data-aware metric called ISS (denoting incremental structural stability) of MRs, and demonstrate that ISS is highly correlated with the final performance. The finding shows that ISS can be used as an indicator for MR design to avoid the costly training-testing process",
    "checked": true,
    "id": "700bde5ae8a045bd8519ea45180906f04ebc8dea",
    "semantic_title": "exploring the secrets behind the learning difficulty of meaning representations for semantic parsing",
    "citation_count": 6,
    "authors": [
      "Zhenwen Li",
      "Jiaqi Guo",
      "Qian Liu",
      "Jian-Guang Lou",
      "Tao Xie"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.238": {
    "title": "That's the Wrong Lung! Evaluating and Improving the Interpretability of Unsupervised Multimodal Encoders for Medical Data",
    "volume": "main",
    "abstract": "Pretraining multimodal models on Electronic Health Records (EHRs) provides a means of learning representations that can transfer to downstream tasks with minimal supervision. Recent multimodal models induce soft local alignments between image regions and sentences. This is of particular interest in the medical domain, where alignments might highlight regions in an image relevant to specific phenomena described in free-text. While past work has suggested that attention \"heatmaps\" can be interpreted in this manner, there has been little evaluation of such alignments. We compare alignments from a state-of-the-art multimodal (image and text) model for EHR with human annotations that link image regions to sentences. Our main finding is that the text has an often weak or unintuitive influence on attention; alignments do not consistently reflect basic anatomical information. Moreover, synthetic modifications — such as substituting \"left\" for \"right\" — do not substantially influence highlights. Simple techniques such as allowing the model to opt out of attending to the image and few-shot finetuning show promise in terms of their ability to improve alignments with very little or no supervision. We make our code and checkpoints open-source",
    "checked": true,
    "id": "d3f73716de43fa42fdc88baf64949e266e2110cf",
    "semantic_title": "that's the wrong lung! evaluating and improving the interpretability of unsupervised multimodal encoders for medical data",
    "citation_count": 0,
    "authors": [
      "Jered McInerney",
      "Geoffrey Young",
      "Jan-Willem van de Meent",
      "Byron Wallace"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.239": {
    "title": "Unsupervised Tokenization Learning",
    "volume": "main",
    "abstract": "In the presented study, we discover that the so-called \"transition freedom\" metric appears superior for unsupervised tokenization purposes in comparison to statistical metrics such as mutual information and conditional probability, providing F-measure scores in range from 0.71 to 1.0 across explored multilingual corpora. We find that different languages require different offshoots of that metric (such as derivative, variance, and \"peak values\") for successful tokenization. Larger training corpora do not necessarily result in better tokenization quality, while compressing the models by eliminating statistically weak evidence tends to improve performance. The proposed unsupervised tokenization technique provides quality better than or comparable to lexicon-based ones, depending on the language",
    "checked": true,
    "id": "60eae587d084b4bc3bb7ae31d5e84a97e9dff15d",
    "semantic_title": "unsupervised tokenization learning",
    "citation_count": 3,
    "authors": [
      "Anton Kolonin",
      "Vignav Ramesh"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.240": {
    "title": "A Template-based Method for Constrained Neural Machine Translation",
    "volume": "main",
    "abstract": "Machine translation systems are expected to cope with various types of constraints in many practical scenarios. While neural machine translation (NMT) has achieved strong performance in unconstrained cases, it is non-trivial to impose pre-specified constraints into the translation process of NMT models. Although many approaches have been proposed to address this issue, most existing methods can not satisfy the following three desiderata at the same time: (1) high translation quality, (2) high match accuracy, and (3) low latency. In this work, we propose a template-based method that can yield results with high translation quality and match accuracy and the inference speed of our method is comparable with unconstrained NMT models. Our basic idea is to rearrange the generation of constrained and unconstrained tokens through a template. Our method does not require any changes in the model architecture and the decoding algorithm. Experimental results show that the proposed template-based approach can outperform several representative baselines in both lexically and structurally constrained translation tasks",
    "checked": true,
    "id": "558f8e4eabee92f2ac6c928c2f31759ce1c839b7",
    "semantic_title": "a template-based method for constrained neural machine translation",
    "citation_count": 1,
    "authors": [
      "Shuo Wang",
      "Peng Li",
      "Zhixing Tan",
      "Zhaopeng Tu",
      "Maosong Sun",
      "Yang Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.241": {
    "title": "PATS: Sensitivity-aware Noisy Learning for Pretrained Language Models",
    "volume": "main",
    "abstract": "A wide range of NLP tasks benefit from the fine-tuning of pretrained language models (PLMs). However, a number of redundant parameters which contribute less to the downstream task are observed in a directly fine-tuned model. We consider the gap between pretraining and downstream tasks hinders the training of these redundant parameters, and results in a suboptimal performance of the overall model. In this paper, we present PATS (Perturbation According To Sensitivity), a noisy training mechanism which considers each parameter's importance in the downstream task to help fine-tune PLMs. The main idea of PATS is to add bigger noise to parameters with lower sensitivity and vice versa, in order to activate more parameters' contributions to downstream tasks without affecting the sensitive ones much. Extensive experiments conducted on different tasks of the GLUE benchmark show PATS can consistently empower the fine-tuning of different sizes of PLMs, and the parameters in the well-performing models always have more concentrated distributions of sensitivities, which experimentally proves the effectiveness of our method",
    "checked": true,
    "id": "c495061b6352a3fad808bfe8268877ff39453f91",
    "semantic_title": "pats: sensitivity-aware noisy learning for pretrained language models",
    "citation_count": 1,
    "authors": [
      "Yupeng Zhang",
      "Hongzhi Zhang",
      "Sirui Wang",
      "Wei Wu",
      "Zhoujun Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.242": {
    "title": "Towards Reinterpreting Neural Topic Models via Composite Activations",
    "volume": "main",
    "abstract": "Most Neural Topic Models (NTM) use a variational auto-encoder framework producing K topics limited to the size of the encoder's output. These topics are interpreted through the selection of the top activated words via the weights or reconstructed vector of the decoder that are directly connected to each neuron. In this paper, we present a model-free two-stage process to reinterpret NTM and derive further insights on the state of the trained model. Firstly, building on the original information from a trained NTM, we generate a pool of potential candidate \"composite topics\" by exploiting possible co-occurrences within the original set of topics, which decouples the strict interpretation of topics from the original NTM. This is followed by a combinatorial formulation to select a final set of composite topics, which we evaluate for coherence and diversity on a large external corpus. Lastly, we employ a user study to derive further insights on the reinterpretation process",
    "checked": true,
    "id": "7d2b69b513828718a33fe535c7b55a839417f7c2",
    "semantic_title": "towards reinterpreting neural topic models via composite activations",
    "citation_count": 1,
    "authors": [
      "Jia Peng Lim",
      "Hady Lauw"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.243": {
    "title": "Few-shot Query-Focused Summarization with Prefix-Merging",
    "volume": "main",
    "abstract": "Query-focused summarization has been considered as an important extension for text summarization. It aims to generate a concise highlight for a given query. Different from text summarization, query-focused summarization has long been plagued by the problem of lacking high-quality large-scale datasets. In this paper, we investigate the idea that whether we can integrate and transfer the knowledge of text summarization and question answering to assist the few-shot learning in query-focused summarization. Here, we propose prefix-merging, a prefix-based pretraining strategy for few-shot learning in query-focused summarization. Drawn inspiration from prefix-tuning, we are allowed to integrate the task knowledge from text summarization and question answering into a properly designed prefix and apply the merged prefix to query-focused summarization. With only a small amount of trainable parameters, prefix-merging outperforms fine-tuning on query-focused summarization. We further discuss the influence of different prefix designs and propose a visualized explanation for how prefix-merging works",
    "checked": true,
    "id": "1e983fccd65cbd39712fa360b92235e5497d81b6",
    "semantic_title": "few-shot query-focused summarization with prefix-merging",
    "citation_count": 5,
    "authors": [
      "Ruifeng Yuan",
      "Zili Wang",
      "Ziqiang Cao",
      "Wenjie Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.244": {
    "title": "Cross-Align: Modeling Deep Cross-lingual Interactions for Word Alignment",
    "volume": "main",
    "abstract": "Word alignment which aims to extract lexicon translation equivalents between source and target sentences, serves as a fundamental tool for natural language processing. Recent studies in this area have yielded substantial improvements by generating alignments from contextualized embeddings of the pre-trained multilingual language models. However, we find that the existing approaches capture few interactions between the input sentence pairs, which degrades the word alignment quality severely, especially for the ambiguous words in the monolingual context. To remedy this problem, we propose Cross-Align to model deep interactions between the input sentence pairs, in which the source and target sentences are encoded separately with the shared self-attention modules in the shallow layers, while cross-lingual interactions are explicitly constructed by the cross-attention modules in the upper layers. Besides, to train our model effectively, we propose a two-stage training framework, where the model is trained with a simple Translation Language Modeling (TLM) objective in the first stage and then finetuned with a self-supervised alignment objective in the second stage. Experiments show that the proposed Cross-Align achieves the state-of-the-art (SOTA) performance on four out of five language pairs",
    "checked": true,
    "id": "bcce29cc190f6669fd76aacf309e06be222dfbb1",
    "semantic_title": "cross-align: modeling deep cross-lingual interactions for word alignment",
    "citation_count": 4,
    "authors": [
      "Siyu Lai",
      "Zhen Yang",
      "Fandong Meng",
      "Yufeng Chen",
      "Jinan Xu",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.245": {
    "title": "BERTScore is Unfair: On Social Bias in Language Model-Based Metrics for Text Generation",
    "volume": "main",
    "abstract": "Automatic evaluation metrics are crucial to the development of generative systems. In recent years, pre-trained language model (PLM) based metrics, such as BERTScore, have been commonly adopted in various generation tasks. However, it has been demonstrated that PLMs encode a range of stereotypical societal biases, leading to a concern about the fairness of PLMs as metrics. To that end, this work presents the first systematic study on the social bias in PLM-based metrics. We demonstrate that popular PLM-based metrics exhibit significantly higher social bias than traditional metrics on 6 sensitive attributes, namely race, gender, religion, physical appearance, age, and socioeconomic status. In-depth analysis suggests that choosing paradigms (matching, regression, or generation) of the metric has a greater impact on fairness than choosing PLMs. In addition, we develop debiasing adapters that are injected into PLM layers, mitigating bias in PLM-based metrics while retaining high performance for evaluating text generation",
    "checked": true,
    "id": "969f45a3adf5e0bcf741447b1c67a0f3a386801a",
    "semantic_title": "bertscore is unfair: on social bias in language model-based metrics for text generation",
    "citation_count": 36,
    "authors": [
      "Tianxiang Sun",
      "Junliang He",
      "Xipeng Qiu",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.246": {
    "title": "HPT: Hierarchy-aware Prompt Tuning for Hierarchical Text Classification",
    "volume": "main",
    "abstract": "Hierarchical text classification (HTC) is a challenging subtask of multi-label classification due to its complex label hierarchy.Recently, the pretrained language models (PLM)have been widely adopted in HTC through a fine-tuning paradigm. However, in this paradigm, there exists a huge gap between the classification tasks with sophisticated label hierarchy and the masked language model (MLM) pretraining tasks of PLMs and thus the potential of PLMs cannot be fully tapped.To bridge the gap, in this paper, we propose HPT, a Hierarchy-aware Prompt Tuning method to handle HTC from a multi-label MLM perspective.Specifically, we construct a dynamic virtual template and label words that take the form of soft prompts to fuse the label hierarchy knowledge and introduce a zero-bounded multi-label cross-entropy loss to harmonize the objectives of HTC and MLM.Extensive experiments show HPT achieves state-of-the-art performances on 3 popular HTC datasets and is adept at handling the imbalance and low resource situations. Our code is available at https://github.com/wzh9969/HPT",
    "checked": true,
    "id": "14c2611ab6c858cd3fab586f553eac6a10212fc3",
    "semantic_title": "hpt: hierarchy-aware prompt tuning for hierarchical text classification",
    "citation_count": 31,
    "authors": [
      "Zihan Wang",
      "Peiyi Wang",
      "Tianyu Liu",
      "Binghuai Lin",
      "Yunbo Cao",
      "Zhifang Sui",
      "Houfeng Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.247": {
    "title": "Not to Overfit or Underfit the Source Domains? An Empirical Study of Domain Generalization in Question Answering",
    "volume": "main",
    "abstract": "Machine learning models are prone to overfitting their training (source) domains, which is commonly believed to be the reason why they falter in novel target domains. Here we examine the contrasting view that multi-source domain generalization (DG) is first and foremost a problem of mitigating source domain underfitting: models not adequately learning the signal already present in their multi-domain training data. Experiments on a reading comprehension DG benchmark show that as a model learns its source domains better—using familiar methods such as knowledge distillation (KD) from a bigger model—its zero-shot out-of-domain utility improves at an even faster pace. Improved source domain learning also demonstrates superior out-of-domain generalization over three popular existing DG approaches that aim to limit overfitting. Our implementation of KD-based domain generalization is available via PrimeQA at: https://ibm.biz/domain-generalization-with-kd",
    "checked": true,
    "id": "88e0b6d3a22c177430a4ff8883879a22b250c431",
    "semantic_title": "not to overfit or underfit the source domains? an empirical study of domain generalization in question answering",
    "citation_count": 4,
    "authors": [
      "Md Arafat Sultan",
      "Avi Sil",
      "Radu Florian"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.248": {
    "title": "Neural Theory-of-Mind? On the Limits of Social Intelligence in Large LMs",
    "volume": "main",
    "abstract": "Social intelligence and Theory of Mind (TOM), i.e., the ability to reason about the different mental states, intents, and reactions of all people involved, allows humans to effectively navigate and understand everyday social interactions. As NLP systems are used in increasingly complex social situations, their ability to grasp social dynamics becomes crucial.In this work, we examine the open question of social intelligence and Theory of Mind in modern NLP systems from an empirical and theorybased perspective. We show that one of today's largest language models (GPT-3; Brown et al., 2020) lacks this kind of social intelligence out-of-the box, using two tasks: SocialIQa (Sap et al., 2019), which measure models' ability to understand intents and reactions of participants of social interactions, and ToMi (Le, Boureau, and Nickel, 2019), which measures whether models can infer mental states and realities of participants of situations.Our results show that models struggle substantially at these Theory of Mind tasks, with well-below-human accuracies of 55% and 60% on SocialIQa and ToMi, respectively. To conclude, we draw on theories from pragmatics to contextualize this shortcoming of large language models, by examining the limitations stemming from their data, neural architecture, and training paradigms. Challenging the prevalent narrative that only scale is needed, we posit that person-centric NLP approaches might be more effective towards neural Theory of Mind",
    "checked": true,
    "id": "311fd5f6f114ae51f8cbd95a0da69d7b556d25f1",
    "semantic_title": "neural theory-of-mind? on the limits of social intelligence in large lms",
    "citation_count": 152,
    "authors": [
      "Maarten Sap",
      "Ronan Le Bras",
      "Daniel Fried",
      "Yejin Choi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.249": {
    "title": "Improving Passage Retrieval with Zero-Shot Question Generation",
    "volume": "main",
    "abstract": "We propose a simple and effective re-ranking method for improving passage retrieval in open question answering. The re-ranker re-scores retrieved passages with a zero-shot question generation model, which uses a pre-trained language model to compute the probability of the input question conditioned on a retrieved passage. This approach can be applied on top of any retrieval method (e.g. neural or keyword-based), does not require any domain- or task-specific training (and therefore is expected to generalize better to data distribution shifts), and provides rich cross-attention between query and passage (i.e. it must explain every token in the question). When evaluated on a number of open-domain retrieval datasets, our re-ranker improves strong unsupervised retrieval models by 6%-18% absolute and strong supervised models by up to 12% in terms of top-20 passage retrieval accuracy. We also obtain new state-of-the-art results on full open-domain question answering by simply adding the new re-ranker to existing models with no further changes",
    "checked": true,
    "id": "5f8f992d84d5f8b5e8806dad6076bcc4dca11a34",
    "semantic_title": "improving passage retrieval with zero-shot question generation",
    "citation_count": 103,
    "authors": [
      "Devendra Sachan",
      "Mike Lewis",
      "Mandar Joshi",
      "Armen Aghajanyan",
      "Wen-tau Yih",
      "Joelle Pineau",
      "Luke Zettlemoyer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.250": {
    "title": "Summarizing Community-based Question-Answer Pairs",
    "volume": "main",
    "abstract": "Community-based Question Answering (CQA), which allows users to acquire their desired information, has increasingly become an essential component of online services in various domains such as E-commerce, travel, and dining. However, an overwhelming number of CQA pairs makes it difficult for users without particular intent to find useful information spread over CQA pairs. To help users quickly digest the key information, we propose the novel CQA summarization task that aims to create a concise summary from CQA pairs. To this end, we first design a multi-stage data annotation process and create a benchmark dataset, COQASUM, based on the Amazon QA corpus. We then compare a collection of extractive and abstractive summarization methods and establish a strong baseline approach DedupLED for the CQA summarization task. Our experiment further confirms two key challenges, sentence-type transfer and deduplication removal, towards the CQA summarization task. Our data and code are publicly available",
    "checked": true,
    "id": "3a471f72df08f7714cb84e8fc7513e484ad161a2",
    "semantic_title": "summarizing community-based question-answer pairs",
    "citation_count": 4,
    "authors": [
      "Ting-Yao Hsu",
      "Yoshi Suhara",
      "Xiaolan Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.251": {
    "title": "Logical Reasoning with Span-Level Predictions for Interpretable and Robust NLI Models",
    "volume": "main",
    "abstract": "Current Natural Language Inference (NLI) models achieve impressive results, sometimes outperforming humans when evaluating on in-distribution test sets. However, as these models are known to learn from annotation artefacts and dataset biases, it is unclear to what extent the models are learning the task of NLI instead of learning from shallow heuristics in their training data.We address this issue by introducing a logical reasoning framework for NLI, creating highly transparent model decisions that are based on logical rules. Unlike prior work, we show that improved interpretability can be achieved without decreasing the predictive accuracy. We almost fully retain performance on SNLI, while also identifying the exact hypothesis spans that are responsible for each model prediction.Using the e-SNLI human explanations, we verify that our model makes sensible decisions at a span level, despite not using any span labels during training. We can further improve model performance and the span-level decisions by using the e-SNLI explanations during training. Finally, our model is more robust in a reduced data setting. When training with only 1,000 examples, out-of-distribution performance improves on the MNLI matched and mismatched validation sets by 13% and 16% relative to the baseline. Training with fewer observations yields further improvements, both in-distribution and out-of-distribution",
    "checked": true,
    "id": "20b12e0a6c5e3fb42cc389be6d806dc2fafe523b",
    "semantic_title": "logical reasoning with span-level predictions for interpretable and robust nli models",
    "citation_count": 8,
    "authors": [
      "Joe Stacey",
      "Pasquale Minervini",
      "Haim Dubossarsky",
      "Marek Rei"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.252": {
    "title": "How to disagree well: Investigating the dispute tactics used on Wikipedia",
    "volume": "main",
    "abstract": "Disagreements are frequently studied from the perspective of either detecting toxicity or analysing argument structure. We propose a framework of dispute tactics which unifies these two perspectives, as well as other dialogue acts which play a role in resolving disputes, such as asking questions and providing clarification. This framework includes a preferential ordering among rebuttal-type tactics, ranging from ad hominem attacks to refuting the central argument. Using this framework, we annotate 213 disagreements (3,865 utterances) from Wikipedia Talk pages. This allows us to investigate research questions around the tactics used in disagreements; for instance, we provide empirical validation of the approach to disagreement recommended by Wikipedia. We develop models for multilabel prediction of dispute tactics in an utterance, achieving the best performance with a transformer-based label powerset model. Adding an auxiliary task to incorporate the ordering of rebuttal tactics further yields a statistically significant increase. Finally, we show that these annotations can be used to provide useful additional signals to improve performance on the task of predicting escalation",
    "checked": true,
    "id": "9353520f5d45ba8831afaa99110f454903cbbc2f",
    "semantic_title": "how to disagree well: investigating the dispute tactics used on wikipedia",
    "citation_count": 5,
    "authors": [
      "Christine De Kock",
      "Tom Stafford",
      "Andreas Vlachos"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.253": {
    "title": "Chapter Ordering in Novels",
    "volume": "main",
    "abstract": "Understanding narrative flow and text coherence in long-form documents (novels) remains an open problem in NLP.To gain insight, we explore the task of chapter ordering, reconstructing the original order of chapters in novel given a random permutation of the text. This can be seen as extending the well-known sentence ordering task to vastly larger documents: our task deals with over 9,000 novels with an average of twenty chapters each, versus standard sentence ordering datasets averaging only 5-8 sentences. We formulate the task of reconstructing order as a constraint solving problem, using minimum feedback arc set and traveling salesman problem optimization criteria, where the weights of the graph are generated based on models for character occurrences and chapter boundary detection, using relational chapter scores derived from RoBERTa. Our best methods yield a Spearman correlation of 0.59 on this novel and challenging task, substantially above baseline",
    "checked": true,
    "id": "4949de0080f06327cfba8d41a66f676f1ec95d2d",
    "semantic_title": "chapter ordering in novels",
    "citation_count": 1,
    "authors": [
      "Allen Kim",
      "Steve Skiena"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.254": {
    "title": "Open-ended Knowledge Tracing for Computer Science Education",
    "volume": "main",
    "abstract": "In educational applications, knowledge tracing refers to the problem of estimating students' time-varying concept/skill mastery level from their past responses to questions and predicting their future performance.One key limitation of most existing knowledge tracing methods is that they treat student responses to questions as binary-valued, i.e., whether they are correct or incorrect. Response correctness analysis/prediction is straightforward, but it ignores important information regarding mastery, especially for open-ended questions.In contrast, exact student responses can provide much more information.In this paper, we conduct the first exploration int open-ended knowledge tracing (OKT) by studying the new task of predicting students' exact open-ended responses to questions.Our work is grounded in the domain of computer science education with programming questions. We develop an initial solution to the OKT problem, a student knowledge-guided code generation approach, that combines program synthesis methods using language models with student knowledge tracing methods. We also conduct a series of quantitative and qualitative experiments on a real-world student code dataset to validate and demonstrate the promise of OKT",
    "checked": true,
    "id": "7b5aa186ca8abc585607c5ec91562e127a398601",
    "semantic_title": "open-ended knowledge tracing for computer science education",
    "citation_count": 19,
    "authors": [
      "Naiming Liu",
      "Zichao Wang",
      "Richard Baraniuk",
      "Andrew Lan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.255": {
    "title": "Logical Neural Networks for Knowledge Base Completion with Embeddings & Rules",
    "volume": "main",
    "abstract": "Knowledge base completion (KBC) has benefitted greatly by learning explainable rules in an human-interpretable dialect such as first-order logic. Rule-based KBC has so far, mainly focussed on learning one of two types of rules: conjunction-of-disjunctions and disjunction-of-conjunctions. We qualitatively show, via examples, that one of these has an advantage over the other when it comes to achieving high quality KBC. To the best of our knowledge, we are the first to propose learning both kinds of rules within a common framework. To this end, we propose to utilize logical neural networks (LNN), a powerful neuro-symbolic AI framework that can express both kinds of rules and learn these end-to-end using gradient-based optimization. Our in-depth experiments show that our LNN-based approach to learning rules for KBC leads to roughly 10% relative improvements, if not more, over SotA rule-based KBC methods. Moreover, by showing how to combine our proposed methods with knowledge graph embeddings we further achieve an additional 7.5% relative improvement",
    "checked": true,
    "id": "3b9ca1e2487bacc4147782c528f85724cdc37d09",
    "semantic_title": "logical neural networks for knowledge base completion with embeddings & rules",
    "citation_count": 5,
    "authors": [
      "Prithviraj Sen",
      "Breno William Carvalho",
      "Ibrahim Abdelaziz",
      "Pavan Kapanipathi",
      "Salim Roukos",
      "Alexander Gray"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.256": {
    "title": "MedCLIP: Contrastive Learning from Unpaired Medical Images and Text",
    "volume": "main",
    "abstract": "Existing vision-text contrastive learning like CLIP aims to match the paired image and caption embeddings while pushing others apart, which improves representation transferability and supports zero-shot prediction. However, medical image-text datasets are orders of magnitude below the general images and captions from the internet. Moreover, previous methods encounter many false negatives, i.e., images and reports from separate patients probably carry the same semantics but are wrongly treated as negatives. In this paper, we decouple images and texts for multimodal contrastive learning, thus scaling the usable training data in a combinatorial magnitude with low cost. We also propose to replace the InfoNCE loss with semantic matching loss based on medical knowledge to eliminate false negatives in contrastive learning. We prove that MedCLIP is a simple yet effective framework: it outperforms state-of-the-art methods on zero-shot prediction, supervised classification, and image-text retrieval. Surprisingly, we observe that with only 20K pre-training data, MedCLIP wins over the state-of-the-art method (using 200K data). The code is available at https://github.com/RyanWangZf/MedCLIP",
    "checked": true,
    "id": "cdd9c1d23f9e89d5113f3e31821bb174c6a6afed",
    "semantic_title": "medclip: contrastive learning from unpaired medical images and text",
    "citation_count": 191,
    "authors": [
      "Zifeng Wang",
      "Zhenbang Wu",
      "Dinesh Agarwal",
      "Jimeng Sun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.257": {
    "title": "GA-SAM: Gradient-Strength based Adaptive Sharpness-Aware Minimization for Improved Generalization",
    "volume": "main",
    "abstract": "Recently, Sharpness-Aware Minimization (SAM) algorithm has shown state-of-the-art generalization abilities in vision tasks. It demonstrates that flat minima tend to imply better generalization abilities. However, it has some difficulty implying SAM to some natural language tasks, especially to models with drastic gradient changes, such as RNNs. In this work, we analyze the relation between the flatness of the local minimum and its generalization ability from a novel and straightforward theoretical perspective. We propose that the shift of the training and test distributions can be equivalently seen as a virtual parameter corruption or perturbation, which can explain why flat minima that are robust against parameter corruptions or perturbations have better generalization performances. On its basis, we propose a Gradient-Strength based Adaptive Sharpness-Aware Minimization (GA-SAM) algorithm to help to learn algorithms find flat minima that generalize better. Results in various language benchmarks validate the effectiveness of the proposed GA-SAM algorithm on natural language tasks",
    "checked": true,
    "id": "5a41152cfa769414f9d54cf436b98f36ffb0b729",
    "semantic_title": "ga-sam: gradient-strength based adaptive sharpness-aware minimization for improved generalization",
    "citation_count": 8,
    "authors": [
      "Zhiyuan Zhang",
      "Ruixuan Luo",
      "Qi Su",
      "Xu Sun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.258": {
    "title": "Sparse Teachers Can Be Dense with Knowledge",
    "volume": "main",
    "abstract": "Recent advances in distilling pretrained language models have discovered that, besides the expressiveness of knowledge, the student-friendliness should be taken into consideration to realize a truly knowledgeable teacher. Based on a pilot study, we find that over-parameterized teachers can produce expressive yet student-unfriendly knowledge and are thus limited in overall knowledgeableness. To remove the parameters that result in student-unfriendliness, we propose a sparse teacher trick under the guidance of an overall knowledgeable score for each teacher parameter. The knowledgeable score is essentially an interpolation of the expressiveness and student-friendliness scores. The aim is to ensure that the expressive parameters are retained while the student-unfriendly ones are removed. Extensive experiments on the GLUE benchmark show that the proposed sparse teachers can be dense with knowledge and lead to students with compelling performance in comparison with a series of competitive baselines",
    "checked": true,
    "id": "2bf7978afacd83e5fc813741c11a0c0421cb2dfd",
    "semantic_title": "sparse teachers can be dense with knowledge",
    "citation_count": 9,
    "authors": [
      "Yi Yang",
      "Chen Zhang",
      "Dawei Song"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.259": {
    "title": "BBTv2: Towards a Gradient-Free Future with Large Language Models",
    "volume": "main",
    "abstract": "Most downstream adaptation methods tune all or part of the parameters of pre-trained models (PTMs) through gradient descent, where the tuning cost increases linearly with the growth of the model size.By contrast, gradient-free methods only require the forward computation of the PTM to tune the prompt, retaining the benefits of efficient tuning and deployment.Though, past work on gradient-free tuning often introduces gradient descent to seek a good initialization of prompt and lacks versatility across tasks and PTMs.In this paper, we present BBTv2, an improved version of Black-Box Tuning, to drive PTMs for few-shot learning.We prepend continuous prompts to every layer of the PTM and propose a divide-and-conquer gradient-free algorithm to optimize the prompts at different layers alternately.Extensive experiments across various tasks and PTMs show that BBTv2 can achieve comparable performance to full model tuning and state-of-the-art parameter-efficient methods (e.g., Adapter, LoRA, BitFit, etc.) under few-shot settings while maintaining much fewer tunable parameters",
    "checked": true,
    "id": "0f30612423381eb5d271c4ca4f4254149b0d22fa",
    "semantic_title": "bbtv2: towards a gradient-free future with large language models",
    "citation_count": 41,
    "authors": [
      "Tianxiang Sun",
      "Zhengfu He",
      "Hong Qian",
      "Yunhua Zhou",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.260": {
    "title": "Passage-Mask: A Learnable Regularization Strategy for Retriever-Reader Models",
    "volume": "main",
    "abstract": "Retriever-reader models achieve competitive performance across many different NLP tasks such as open question answering and dialogue conversations. In this work, we notice these models easily overfit the top-rank retrieval passages and standard training fails to reason over the entire retrieval passages. We introduce a learnable passage mask mechanism which desensitizes the impact from the top-rank retrieval passages and prevents the model from overfitting. Controlling the gradient variance with fewer mask candidates and selecting the mask candidates with one-shot bi-level optimization, our learnable regularization strategy enforces the answer generation to focus on the entire retrieval passages. Experiments on different tasks across open question answering, dialogue conversation, and fact verification show that our method consistently outperforms its baselines. Extensive experiments and ablation studies demonstrate that our method can be general, effective, and beneficial for many NLP tasks",
    "checked": true,
    "id": "5aaaf17b9bc115e6a6ff7a2b0d11b3997647b969",
    "semantic_title": "passage-mask: a learnable regularization strategy for retriever-reader models",
    "citation_count": 6,
    "authors": [
      "Shujian Zhang",
      "Chengyue Gong",
      "Xingchao Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.261": {
    "title": "Mixed-effects transformers for hierarchical adaptation",
    "volume": "main",
    "abstract": "Language differs dramatically from context to context. To some degree, large language models like GPT-3 account for such variation by conditioning on strings of initial input text, or prompts. However, prompting can be ineffective when contexts are sparse, out-of-sample, or extra-textual. In this paper, we introduce the mixed-effects transformer (MET), a novel approach for learning hierarchically-structured prefixes— lightweight modules prepended to an input sequence— to account for structured variation in language use. Specifically, we show how the popular class of mixed-effects regression models may be extended to transformer-based architectures using a regularized prefix-tuning procedure with dropout. We evaluate this approach on several domain-adaptation benchmarks, finding that it learns contextual variation from minimal data while generalizing well to unseen contexts",
    "checked": true,
    "id": "29b7ab3e305b9a57ae81d7f15596cd91a2e99139",
    "semantic_title": "mixed-effects transformers for hierarchical adaptation",
    "citation_count": 1,
    "authors": [
      "Julia White",
      "Noah Goodman",
      "Robert Hawkins"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.262": {
    "title": "On Measuring the Intrinsic Few-Shot Hardness of Datasets",
    "volume": "main",
    "abstract": "While advances in pre-training have led to dramatic improvements in few-shot learning of NLP tasks, there is limited understanding of what drives successful few-shot adaptation in datasets. In particular, given a new dataset and a pre-trained model, what properties of the dataset make it few-shot learnable, and are these properties independent of the specific adaptation techniques used? We consider an extensive set of recent few-shot learning methods and show that their performance across a large number of datasets is highly correlated, showing that few-shot hardness may be intrinsic to datasets, for a given pre-trained model. To estimate intrinsic few-shot hardness, we then propose a simple and lightweight metric called Spread that captures the intuition that few-shot learning is made possible by exploiting feature-space invariances between training and test samples. Our metric better accounts for few-shot hardness compared to existing notions of hardness and is ~8-100x faster to compute",
    "checked": true,
    "id": "d6ade4de1c5bccb052eb20e6d65f5232c8b61dc5",
    "semantic_title": "on measuring the intrinsic few-shot hardness of datasets",
    "citation_count": 4,
    "authors": [
      "Xinran Zhao",
      "Shikhar Murty",
      "Christopher Manning"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.263": {
    "title": "Group is better than individual: Exploiting Label Topologies and Label Relations for Joint Multiple Intent Detection and Slot Filling",
    "volume": "main",
    "abstract": "Recent joint multiple intent detection and slot filling models employ label embeddings to achieve the semantics-label interactions.However, they treat all labels and label embeddings as uncorrelated individuals, ignoring the dependencies among them. Besides, they conduct the decoding for the two tasks independently, without leveraging the correlations between them.Therefore, in this paper, we first construct a Heterogeneous Label Graph (HLG) containing two kinds of topologies: (1) statistical dependencies based on labels' co-occurrence patterns and hierarchies in slot labels; (2) rich relations among the label nodes.Then we propose a novel model termed ReLa-Net.It can capture beneficial correlations among the labels from HLG.The label correlations are leveraged to enhance semantic-label interactions. Moreover, we also propose the label-aware inter-dependent decoding mechanism to further exploit the label correlations for decoding. Experiment results show that our ReLa-Net significantly outperforms previous models.Remarkably, ReLa-Net surpasses the previous best model by over 20% in terms of overall accuracy on MixATIS dataset",
    "checked": true,
    "id": "7dece8abe1afea95b77322025f0f92bb9d7ed3ec",
    "semantic_title": "group is better than individual: exploiting label topologies and label relations for joint multiple intent detection and slot filling",
    "citation_count": 15,
    "authors": [
      "Bowen Xing",
      "Ivor Tsang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.264": {
    "title": "An Empirical Study on Finding Spans",
    "volume": "main",
    "abstract": "We present an empirical study on methods for span finding, the selection of consecutive tokens in text for some downstream tasks. We focus on approaches that can be employed in training end-to-end information extraction systems, and find there is no definitive solution without considering task properties, and provide our observations to help with future design choices: 1) a tagging approach often yields higher precision while span enumeration and boundary prediction provide higher recall; 2) span type information can benefit a boundary prediction approach; 3) additional contextualization does not help span finding in most cases",
    "checked": true,
    "id": "6dac365d3ff10de1a7fe464c5c5007e0aa644184",
    "semantic_title": "an empirical study on finding spans",
    "citation_count": 2,
    "authors": [
      "Weiwei Gu",
      "Boyuan Zheng",
      "Yunmo Chen",
      "Tongfei Chen",
      "Benjamin Van Durme"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.265": {
    "title": "MGDoc: Pre-training with Multi-granular Hierarchy for Document Image Understanding",
    "volume": "main",
    "abstract": "Document images are a ubiquitous source of data where the text is organized in a complex hierarchical structure ranging from fine granularity (e.g., words), medium granularity (e.g., regions such as paragraphs or figures), to coarse granularity (e.g., the whole page). The spatial hierarchical relationships between content at different levels of granularity are crucial for document image understanding tasks. Existing methods learn features from either word-level or region-level but fail to consider both simultaneously. Word-level models are restricted by the fact that they originate from pure-text language models, which only encode the word-level context. In contrast, region-level models attempt to encode regions corresponding to paragraphs or text blocks into a single embedding, but they perform worse with additional word-level features. To deal with these issues, we propose MGDoc, a new multi-modal multi-granular pre-training framework that encodes page-level, region-level, and word-level information at the same time. MGDoc uses a unified text-visual encoder to obtain multi-modal features across different granularities, which makes it possible to project the multi-granular features into the same hyperspace. To model the region-word correlation, we design a cross-granular attention mechanism and specific pre-training tasks for our model to reinforce the model of learning the hierarchy between regions and words. Experiments demonstrate that our proposed model can learn better features that perform well across granularities and lead to improvements in downstream tasks",
    "checked": true,
    "id": "64c8b27ef5789b395c59614e402c36d3109e4952",
    "semantic_title": "mgdoc: pre-training with multi-granular hierarchy for document image understanding",
    "citation_count": 11,
    "authors": [
      "Zilong Wang",
      "Jiuxiang Gu",
      "Chris Tensmeyer",
      "Nikolaos Barmpalios",
      "Ani Nenkova",
      "Tong Sun",
      "Jingbo Shang",
      "Vlad Morariu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.266": {
    "title": "Understanding Jargon: Combining Extraction and Generation for Definition Modeling",
    "volume": "main",
    "abstract": "Can machines know what twin prime is? From the composition of this phrase, machines may guess twin prime is a certain kind of prime, but it is still difficult to deduce exactly what twin stands for without additional knowledge. Here, twin prime is a jargon - a specialized term used by experts in a particular field. Explaining jargon is challenging since it usually requires domain knowledge to understand. Recently, there is an increasing interest in extracting and generating definitions of words automatically. However, existing approaches, either extraction or generation, perform poorly on jargon. In this paper, we propose to combine extraction and generation for jargon definition modeling: first extract self- and correlative definitional information of target jargon from the Web and then generate the final definitions by incorporating the extracted definitional information. Our framework is remarkably simple but effective: experiments demonstrate our method can generate high-quality definitions for jargon and outperform state-of-the-art models significantly, e.g., BLEU score from 8.76 to 22.66 and human-annotated score from 2.34 to 4.04",
    "checked": true,
    "id": "b359105b2f6553c4699a2e988e459b8e4dce0ae4",
    "semantic_title": "understanding jargon: combining extraction and generation for definition modeling",
    "citation_count": 11,
    "authors": [
      "Jie Huang",
      "Hanyin Shao",
      "Kevin Chen-Chuan Chang",
      "Jinjun Xiong",
      "Wen-mei Hwu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.267": {
    "title": "ProsocialDialog: A Prosocial Backbone for Conversational Agents",
    "volume": "main",
    "abstract": "Most existing dialogue systems fail to respond properly to potentially unsafe user utterances by either ignoring or passively agreeing with them. To address this issue, we introduce ProsocialDialog, the first large-scale multi-turn dialogue dataset to teach conversational agents to respond to problematic content following social norms. Covering diverse unethical, problematic, biased, and toxic situations, ProsocialDialog contains responses that encourage prosocial behavior, grounded in commonsense social rules (i.e., rules-of-thumb, RoTs). Created via a human-AI collaborative framework, ProsocialDialog consists of 58K dialogues, with 331K utterances, 160K unique RoTs, and 497K dialogue safety labels accompanied by free-form rationales.With this dataset, we introduce a dialogue safety detection module, Canary, capable of generating RoTs given conversational context, and a socially-informed dialogue agent, Prost. Empirical results show that Prost generates more socially acceptable dialogues compared to other state-of-the-art language and dialogue models in both in-domain and out-of-domain settings. Additionally, Canary effectively guides conversational agents and off-the-shelf language models to generate significantly more prosocial responses. Our work highlights the promise and importance of creating and steering conversational AI to be socially responsible",
    "checked": true,
    "id": "36c50e6638dddc8324eef9bfa064bfcab80cbef4",
    "semantic_title": "prosocialdialog: a prosocial backbone for conversational agents",
    "citation_count": 87,
    "authors": [
      "Hyunwoo Kim",
      "Youngjae Yu",
      "Liwei Jiang",
      "Ximing Lu",
      "Daniel Khashabi",
      "Gunhee Kim",
      "Yejin Choi",
      "Maarten Sap"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.268": {
    "title": "Exploiting Global and Local Hierarchies for Hierarchical Text Classification",
    "volume": "main",
    "abstract": "Hierarchical text classification aims to leverage label hierarchy in multi-label text classification. Existing methods encode label hierarchy in a global view, where label hierarchy is treated as the static hierarchical structure containing all labels. Since global hierarchy is static and irrelevant to text samples, it makes these methods hard to exploit hierarchical information. Contrary to global hierarchy, local hierarchy as a structured labels hierarchy corresponding to each text sample. It is dynamic and relevant to text samples, which is ignored in previous methods. To exploit global and local hierarchies, we propose Hierarchy-guided BERT with Global and Local hierarchies (HBGL), which utilizes the large-scale parameters and prior language knowledge of BERT to model both global and local hierarchies. Moreover, HBGL avoids the intentional fusion of semantic and hierarchical modules by directly modeling semantic and hierarchical information with BERT. Compared with the state-of-the-art method HGCLR, our method achieves significant improvement on three benchmark datasets",
    "checked": true,
    "id": "68137d118b31e13fb382bdceebd2365b4a6473fb",
    "semantic_title": "exploiting global and local hierarchies for hierarchical text classification",
    "citation_count": 19,
    "authors": [
      "Ting Jiang",
      "Deqing Wang",
      "Leilei Sun",
      "Zhongzhi Chen",
      "Fuzhen Zhuang",
      "Qinghong Yang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.269": {
    "title": "Semantic-aware Contrastive Learning for More Accurate Semantic Parsing",
    "volume": "main",
    "abstract": "Since the meaning representations are detailed and accurate annotations which express fine-grained sequence-level semtantics, it is usually hard to train discriminative semantic parsers via Maximum Likelihood Estimation (MLE) in an autoregressive fashion. In this paper, we propose a semantic-aware contrastive learning algorithm, which can learn to distinguish fine-grained meaning representations and take the overall sequence-level semantic into consideration. Specifically, a multi-level online sampling algorithm is proposed to sample confusing and diverse instances. Three semantic-aware similarity functions are designed to accurately measure the distance between meaning representations as a whole. And a ranked contrastive loss is proposed to pull the representations of the semantic-identical instances together and push negative instances away. Experiments on two standard datasets show that our approach achieves significant improvements over MLE baselines and gets state-of-the-art performances by simply applying semantic-aware contrastive learning on a vanilla Seq2Seq model",
    "checked": false,
    "id": "895396389a9fee1b607bf5141a6cc7925bb1e069",
    "semantic_title": "knowledge graph contrastive learning for recommendation",
    "citation_count": 196,
    "authors": [
      "Shan Wu",
      "Chunlei Xin",
      "Bo Chen",
      "Xianpei Han",
      "Le Sun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.270": {
    "title": "Scientific Paper Extractive Summarization Enhanced by Citation Graphs",
    "volume": "main",
    "abstract": "In a citation graph, adjacent paper nodes share related scientific terms and topics. The graph thus conveys unique structure information of document-level relatedness that can be utilized in the paper summarization task, for exploring beyond the intra-document information.In this work, we focus on leveraging citation graphs to improve scientific paper extractive summarization under different settings.We first propose a Multi-granularity Unsupervised Summarization model (MUS) as a simple and low-cost solution to the task.MUS finetunes a pre-trained encoder model on the citation graph by link prediction tasks.Then, the abstract sentences are extracted from the corresponding paper considering multi-granularity information.Preliminary results demonstrate that citation graph is helpful even in a simple unsupervised framework.Motivated by this, we next propose a Graph-based Supervised Summarizationmodel (GSS) to achieve more accurate results on the task when large-scale labeled data are available.Apart from employing the link prediction as an auxiliary task, GSS introduces a gated sentence encoder and a graph information fusion module to take advantage of the graph information to polish the sentence representation.Experiments on a public benchmark dataset show that MUS and GSS bring substantial improvements over the prior state-of-the-art model",
    "checked": true,
    "id": "e7b2f6960aa1eb34cb84af01f23df7ce230f1a95",
    "semantic_title": "scientific paper extractive summarization enhanced by citation graphs",
    "citation_count": 8,
    "authors": [
      "Xiuying Chen",
      "Mingzhe Li",
      "Shen Gao",
      "Rui Yan",
      "Xin Gao",
      "Xiangliang Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.271": {
    "title": "Hardness-guided domain adaptation to recognise biomedical named entities under low-resource scenarios",
    "volume": "main",
    "abstract": "Domain adaptation is an effective solution to data scarcity in low-resource scenarios. However, when applied to token-level tasks such as bioNER, domain adaptation methods often suffer from the challenging linguistic characteristics that clinical narratives possess, which leads to unsatsifactory performance. In this paper, we present a simple yet effective hardness-guided domain adaptation framework for bioNER tasks that can effectively leverage the domain hardness information to improve the adaptability of the learnt model in the low-resource scenarios. Experimental results on biomedical datasets show that our model can achieve significant performance improvement over the recently published state-of-the-art (SOTA) MetaNER model",
    "checked": true,
    "id": "d7837d577fc6821d095dffb559cfdc0e3574166f",
    "semantic_title": "hardness-guided domain adaptation to recognise biomedical named entities under low-resource scenarios",
    "citation_count": 7,
    "authors": [
      "Ngoc Dang Nguyen",
      "Lan Du",
      "Wray Buntine",
      "Changyou Chen",
      "Richard Beare"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.272": {
    "title": "Syntactic Multi-view Learning for Open Information Extraction",
    "volume": "main",
    "abstract": "Open Information Extraction (OpenIE) aims to extract relational tuples from open-domain sentences. Traditional rule-based or statistical models were developed based on syntactic structure of sentence, identified by syntactic parsers. However, previous neural OpenIE models under-explored the useful syntactic information. In this paper, we model both constituency and dependency trees into word-level graphs, and enable neural OpenIE to learn from the syntactic structures. To better fuse heterogeneous information from the two graphs, we adopt multi-view learning to capture multiple relationships from them. Finally, the finetuned constituency and dependency representations are aggregated with sentential semantic representations for tuple generation. Experiments show that both constituency and dependency information, and the multi-view learning are effective",
    "checked": true,
    "id": "9939871f8e0c6119e44734573758196de292561d",
    "semantic_title": "syntactic multi-view learning for open information extraction",
    "citation_count": 2,
    "authors": [
      "Kuicai Dong",
      "Aixin Sun",
      "Jung-Jae Kim",
      "Xiaoli Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.273": {
    "title": "TRIPS: Efficient Vision-and-Language Pre-training with Text-Relevant Image Patch Selection",
    "volume": "main",
    "abstract": "Vision Transformers (ViTs) have been widely used in large-scale Vision and Language Pre-training (VLP) models. Though previous VLP works have proved the effectiveness of ViTs, they still suffer from computational efficiency brought by the long visual sequence. To tackle this problem, in this paper, we propose an efficient vision-and-language pre-training model with Text-Relevant Image Patch Selection, namely TRIPS, which reduces the visual sequence progressively with a text-guided patch-selection layer in the visual backbone for efficient training and inference. The patch-selection layer can dynamically compute text-dependent visual attention to identify the attentive image tokens with text guidance and fuse inattentive ones in an end-to-end manner. Meanwhile, TRIPS does not introduce extra parameters to ViTs. Experimental results on a variety of popular benchmark datasets demonstrate that TRIPS gain a speedup of 40% over previous similar VLP models, yet with competitive or better downstream task performance",
    "checked": true,
    "id": "e8f7977386f981b0bb2f047b1b9470bc7024cf33",
    "semantic_title": "trips: efficient vision-and-language pre-training with text-relevant image patch selection",
    "citation_count": 12,
    "authors": [
      "Chaoya Jiang",
      "Haiyang Xu",
      "Chenliang Li",
      "Ming Yan",
      "Wei Ye",
      "Shikun Zhang",
      "Bin Bi",
      "Songfang Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.274": {
    "title": "CGoDial: A Large-Scale Benchmark for Chinese Goal-oriented Dialog Evaluation",
    "volume": "main",
    "abstract": "Practical dialog systems need to deal with various knowledge sources, noisy user expressions, and the shortage of annotated data. To better solve the above problems, we propose CGoDial, a new challenging and comprehensive Chinese benchmark for multi-domain Goal-oriented Dialog evaluation. It contains 96,763 dialog sessions, and 574,949 dialog turns totally, covering three datasets with different knowledge sources: 1) a slot-based dialog (SBD) dataset with table-formed knowledge, 2) a flow-based dialog (FBD) dataset with tree-formed knowledge, and a retrieval-based dialog (RBD) dataset with candidate-formed knowledge. To bridge the gap between academic benchmarks and spoken dialog scenarios, we either collect data from real conversations or add spoken features to existing datasets via crowd-sourcing. The proposed experimental settings include the combinations of training with either the entire training set or a few-shot training set, and testing with either the standard test set or a hard test subset, which can assess model capabilities in terms of general prediction, fast adaptability and reliable robustness",
    "checked": true,
    "id": "85d5fbd83b732151a9f19f65583a72fbcd65c766",
    "semantic_title": "cgodial: a large-scale benchmark for chinese goal-oriented dialog evaluation",
    "citation_count": 12,
    "authors": [
      "Yinpei Dai",
      "Wanwei He",
      "Bowen Li",
      "Yuchuan Wu",
      "Zheng Cao",
      "Zhongqi An",
      "Jian Sun",
      "Yongbin Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.275": {
    "title": "Kernel-Whitening: Overcome Dataset Bias with Isotropic Sentence Embedding",
    "volume": "main",
    "abstract": "Dataset bias has attracted increasing attention recently for its detrimental effect on the generalization ability of fine-tuned models. The current mainstream solution is designing an additional shallow model to pre-identify biased instances. However, such two-stage methods scale up the computational complexity of training process and obstruct valid feature information while mitigating bias.To address this issue, we utilize the representation normalization method which aims at disentangling the correlations between features of encoded sentences. We find it also promising in eliminating the bias problem by providing isotropic data distribution. We further propose Kernel-Whitening, a Nystrom kernel approximation method to achieve more thorough debiasing on nonlinear spurious correlations. Our framework is end-to-end with similar time consumption to fine-tuning. Experiments show that Kernel-Whitening significantly improves the performance of BERT on out-of-distribution datasets while maintaining in-distribution accuracy",
    "checked": true,
    "id": "f89d4d429f3689540be6ee277bc269b3b68f4938",
    "semantic_title": "kernel-whitening: overcome dataset bias with isotropic sentence embedding",
    "citation_count": 6,
    "authors": [
      "SongYang Gao",
      "Shihan Dou",
      "Qi Zhang",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.276": {
    "title": "A Unified Positive-Unlabeled Learning Framework for Document-Level Relation Extraction with Different Levels of Labeling",
    "volume": "main",
    "abstract": "Document-level relation extraction (RE) aims to identify relations between entities across multiple sentences. Most previous methods focused on document-level RE under full supervision. However, in real-world scenario, it is expensive and difficult to completely label all relations in a document because the number of entity pairs in document-level RE grows quadratically with the number of entities. To solve the common incomplete labeling problem, we propose a unified positive-unlabeled learning framework - shift and squared ranking loss positive-unlabeled (SSR-PU) learning. We use positive-unlabeled (PU) learning on document-level RE for the first time. Considering that labeled data of a dataset may lead to prior shift of unlabeled data, we introduce a PU learning under prior shift of training data. Also, using none-class score as an adaptive threshold, we propose squared ranking loss and prove its Bayesian consistency with multi-label ranking metrics. Extensive experiments demonstrate that our method achieves an improvement of about 14 F1 points relative to the previous baseline with incomplete labeling. In addition, it outperforms previous state-of-the-art results under both fully supervised and extremely unlabeled settings as well",
    "checked": true,
    "id": "b9fc9860931eb28433d128b7b9c5f4fcd76b595f",
    "semantic_title": "a unified positive-unlabeled learning framework for document-level relation extraction with different levels of labeling",
    "citation_count": 13,
    "authors": [
      "Ye Wang",
      "Xinxin Liu",
      "Wenxin Hu",
      "Tao Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.277": {
    "title": "Automatic Generation of Socratic Subquestions for Teaching Math Word Problems",
    "volume": "main",
    "abstract": "Socratic questioning is an educational method that allows students to discover answers to complex problems by asking them a series of thoughtful questions. Generation of didactically sound questions is challenging, requiring understanding of the reasoning process involved in the problem. We hypothesize that such questioning strategy can not only enhance the human performance, but also assist the math word problem (MWP) solvers.In this work, we explore the ability of large language models (LMs) in generating sequential questions for guiding math word problem-solving. We propose various guided question generation schemes based on input conditioning and reinforcement learning.On both automatic and human quality evaluations, we find that LMs constrained with desirable question properties generate superior questions and improve the overall performance of a math word problem solver. We conduct a preliminary user study to examine the potential value of such question generation models in the education domain. Results suggest that the difficulty level of problems plays an important role in determining whether questioning improves or hinders human performance. We discuss the future of using such questioning strategies in education",
    "checked": true,
    "id": "e6745fb621481ccb0ed53c267a37292e499c1b42",
    "semantic_title": "automatic generation of socratic subquestions for teaching math word problems",
    "citation_count": 28,
    "authors": [
      "Kumar Shridhar",
      "Jakub Macina",
      "Mennatallah El-Assady",
      "Tanmay Sinha",
      "Manu Kapur",
      "Mrinmaya Sachan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.278": {
    "title": "Mixture of Attention Heads: Selecting Attention Heads Per Token",
    "volume": "main",
    "abstract": "Mixture-of-Experts (MoE) networks have been proposed as an efficient way to scale up model capacity and implement conditional computing. However, the study of MoE components mostly focused on the feedforward layer in Transformer architecture. This paper proposes the Mixture of Attention Heads (MoA), a new architecture that combines multi-head attention with the MoE mechanism. MoA includes a set of attention heads that each has its own set of parameters. Given an input, a router dynamically selects a subset of k attention heads per token. This conditional computation schema allows MoA to achieve stronger performance than the standard multi-head attention layer. Furthermore, the sparsely gated MoA can easily scale up the number of attention heads and the number of parameters while preserving computational efficiency. Despite performance improvements, MoA also automatically differentiates heads' utilities, providing a new perspective to discuss the model's interpretability. We conducted experiments on several important tasks, including Machine Translation and Masked Language Modeling. Experiments have shown promising results on several tasks against strong baselines that involve large and very deep models",
    "checked": true,
    "id": "3820231d31540ecb05d94c74d959a2f61d3136ea",
    "semantic_title": "mixture of attention heads: selecting attention heads per token",
    "citation_count": 20,
    "authors": [
      "Xiaofeng Zhang",
      "Yikang Shen",
      "Zeyu Huang",
      "Jie Zhou",
      "Wenge Rong",
      "Zhang Xiong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.279": {
    "title": "The Optimal BERT Surgeon: Scalable and Accurate Second-Order Pruning for Large Language Models",
    "volume": "main",
    "abstract": "In this paper, we consider the problem of sparsifying BERT models, which are a key building block for natural language processing, in order to reduce their storage and computational cost. We introduce the Optimal BERT Surgeon (oBERT), an efficient and accurate pruning method based on approximate second-order information, which we show to yield state-of-the-art results in both stages of language tasks: pre-training and fine-tuning. Specifically, oBERT extends existing work on second-order pruning by allowing for pruning weight blocks, and is the first such method that is applicable at BERT scale. Second, we investigate compounding compression approaches to obtain highly compressed but accurate models for deployment on edge devices. These models significantly push boundaries of the current state-of-the-art sparse BERT models with respect to all metrics: model size, inference speed and task accuracy. For example, relative to the dense BERT-base, we obtain 10x model size compression with < 1% accuracy drop, 10x CPU-inference speedup with < 2% accuracy drop, and 29x CPU-inference speedup with < 7.5% accuracy drop. Our code, fully integrated with Transformers and SparseML, is available at https://github.com/neuralmagic/sparseml/tree/main/research/optimal_BERT_surgeon_oBERT",
    "checked": true,
    "id": "6da9a81b75e7ad02867860753d1aa276673a3a77",
    "semantic_title": "the optimal bert surgeon: scalable and accurate second-order pruning for large language models",
    "citation_count": 91,
    "authors": [
      "Eldar Kurtic",
      "Daniel Campos",
      "Tuan Nguyen",
      "Elias Frantar",
      "Mark Kurtz",
      "Benjamin Fineran",
      "Michael Goin",
      "Dan Alistarh"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.280": {
    "title": "Information-Theoretic Text Hallucination Reduction for Video-grounded Dialogue",
    "volume": "main",
    "abstract": "Video-grounded Dialogue (VGD) aims to decode an answer sentence to a question regarding a given video and dialogue context. Despite the recent success of multi-modal reasoning to generate answer sentences, existing dialogue systems still suffer from a text hallucination problem, which denotes indiscriminate text-copying from input texts without an understanding of the question. This is due to learning spurious correlations from the fact that answer sentences in the dataset usually include the words of input texts, thus the VGD system excessively relies on copying words from input texts by hoping those words to overlap with ground-truth texts. Hence, we design Text Hallucination Mitigating (THAM) framework, which incorporates Text Hallucination Regularization (THR) loss derived from the proposed information-theoretic text hallucination measurement approach. Applying THAM with current dialogue systems validates the effectiveness on VGD benchmarks (i.e., AVSD@DSTC7 and AVSD@DSTC8) and shows enhanced interpretability",
    "checked": true,
    "id": "c6784d18a77176f58b75e639d0b99d797a0b4f84",
    "semantic_title": "information-theoretic text hallucination reduction for video-grounded dialogue",
    "citation_count": 16,
    "authors": [
      "Sunjae Yoon",
      "Eunseop Yoon",
      "Hee Suk Yoon",
      "Junyeong Kim",
      "Chang Yoo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.281": {
    "title": "DSM: Question Generation over Knowledge Base via Modeling Diverse Subgraphs with Meta-learner",
    "volume": "main",
    "abstract": "Existing methods on knowledge base question generation (KBQG) learn a one-size-fits-all model by training together all subgraphs without distinguishing the diverse semantics of subgraphs. In this work, we show that making use of the past experience on semantically similar subgraphs can reduce the learning difficulty and promote the performance of KBQG models. To achieve this, we propose a novel approach to model diverse subgraphs with meta-learner (DSM). Specifically, we devise a graph contrastive learning-based retriever to identify semantically similar subgraphs, so that we can construct the semantics-aware learning tasks for the meta-learner to learn semantics-specific and semantics-agnostic knowledge on and across these tasks. Extensive experiments on two widely-adopted benchmarks for KBQG show that DSM derives new state-of-the-art performance and benefits the question answering tasks as a means of data augmentation",
    "checked": true,
    "id": "a982978ac64292956dc22a6dc612003757daeddf",
    "semantic_title": "dsm: question generation over knowledge base via modeling diverse subgraphs with meta-learner",
    "citation_count": 13,
    "authors": [
      "Shasha Guo",
      "Jing Zhang",
      "Yanling Wang",
      "Qianyi Zhang",
      "Cuiping Li",
      "Hong Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.282": {
    "title": "RelU-Net: Syntax-aware Graph U-Net for Relational Triple Extraction",
    "volume": "main",
    "abstract": "Relational triple extraction is a critical task for natural language processing. Existing methods mainly focused on capturing semantic information, but suffered from ignoring the syntactic structure of the sentence, which is proved in the relation classification task to contain rich relational information. This is due to the absence of entity locations, which is the prerequisite for pruning noisy edges from the dependency tree, when extracting relational triples. In this paper, we propose a unified framework to tackle this challenge and incorporate syntactic information for relational triple extraction. First, we propose to automatically contract the dependency tree into a core relational topology and eliminate redundant information with graph pooling operations. Then, we propose a symmetrical expanding path with graph unpooling operations to fuse the contracted core syntactic interactions with the original sentence context. We also propose a bipartite graph matching objective function to capture the reflections between the core topology and golden relational facts. Since our model shares similar contracting and expanding paths with encoder-decoder models like U-Net, we name our model as Relation U-Net (RelU-Net). We conduct experiments on several datasets and the results prove the effectiveness of our method",
    "checked": true,
    "id": "3188d6bb4f1689a2f496ed5c9c326c6528ed7993",
    "semantic_title": "relu-net: syntax-aware graph u-net for relational triple extraction",
    "citation_count": 3,
    "authors": [
      "Yunqi Zhang",
      "Yubo Chen",
      "Yongfeng Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.283": {
    "title": "Evidence > Intuition: Transferability Estimation for Encoder Selection",
    "volume": "main",
    "abstract": "With the increase in availability of large pre-trained language models (LMs) in Natural Language Processing (NLP), it becomes critical to assess their fit for a specific target task a priori—as fine-tuning the entire space of available LMs is computationally prohibitive and unsustainable. However, encoder transferability estimation has received little to no attention in NLP. In this paper, we propose to generate quantitative evidence to predict which LM, out of a pool of models, will perform best on a target task without having to fine-tune all candidates. We provide a comprehensive study on LM ranking for 10 NLP tasks spanning the two fundamental problem types of classification and structured prediction. We adopt the state-of-the-art Logarithm of Maximum Evidence (LogME) measure from Computer Vision (CV) and find that it positively correlates with final LM performance in 94% of the setups.In the first study of its kind, we further compare transferability measures with the de facto standard of human practitioner ranking, finding that evidence from quantitative metrics is more robust than pure intuition and can help identify unexpected LM candidates",
    "checked": true,
    "id": "504d1d9b6ecdeaadb79ad8ba80fa64ac34fca18e",
    "semantic_title": "evidence > intuition: transferability estimation for encoder selection",
    "citation_count": 5,
    "authors": [
      "Elisa Bassignana",
      "Max Müller-Eberstein",
      "Mike Zhang",
      "Barbara Plank"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.284": {
    "title": "Chunk-based Nearest Neighbor Machine Translation",
    "volume": "main",
    "abstract": "Semi-parametric models, which augment generation with retrieval, have led to impressive results in language modeling and machine translation, due to their ability to retrieve fine-grained information from a datastore of examples. One of the most prominent approaches, kNN-MT, exhibits strong domain adaptation capabilities by retrieving tokens from domain-specific datastores (Khandelwal et al., 2021). However, kNN-MT requires an expensive retrieval operation for every single generated token, leading to a very low decoding speed (around 8 times slower than a parametric model). In this paper, we introduce a chunk-based kNN-MT model which retrieves chunks of tokens from the datastore, instead of a single token. We propose several strategies for incorporating the retrieved chunks into the generation process, and for selecting the steps at which the model needs to search for neighbors in the datastore. Experiments on machine translation in two settings, static and \"on-the-fly\" domain adaptation, show that the chunk-based kNN-MT model leads to significant speed-ups (up to 4 times) with only a small drop in translation quality",
    "checked": true,
    "id": "1c811f618f40349e6e7130083ddbacaf78858737",
    "semantic_title": "chunk-based nearest neighbor machine translation",
    "citation_count": 23,
    "authors": [
      "Pedro Henrique Martins",
      "Zita Marinho",
      "André F. T. Martins"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.285": {
    "title": "FiE: Building a Global Probability Space by Leveraging Early Fusion in Encoder for Open-Domain Question Answering",
    "volume": "main",
    "abstract": "Generative models have recently started to outperform extractive models in Open Domain Question Answering, largely by leveraging their decoder to attend over multiple encoded passages and combining their information. However, generative models tend to be larger than extractive models due to the need for a decoder, run slower during inference due to auto-regressive decoder beam search, and their generated output often suffers from hallucinations. We propose to extend transformer encoders with the ability to fuse information from multiple passages, using global representation to provide cross-sample attention over all tokens across samples. Furthermore, we propose an alternative answer span probability calculation to better aggregate answer scores in the global space of all samples. Using our proposed method, we outperform the current state-of-the-art method by 2.5 Exact Match score on the Natural Question dataset while using only 25% of parameters and 35% of the latency during inference, and 4.4 Exact Match on WebQuestions dataset. When coupled with synthetic data augmentation, we outperform larger models on the TriviaQA dataset as well. The latency and parameter savings of our method make it particularly attractive for open-domain question answering, as these models are often compute-intensive",
    "checked": true,
    "id": "471a49220cea2069e8b8a76821b1d2434204a732",
    "semantic_title": "fie: building a global probability space by leveraging early fusion in encoder for open-domain question answering",
    "citation_count": 8,
    "authors": [
      "Akhil Kedia",
      "Mohd Abbas Zaidi",
      "Haejun Lee"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.286": {
    "title": "Inductive Relation Prediction with Logical Reasoning Using Contrastive Representations",
    "volume": "main",
    "abstract": "Relation prediction in knowledge graphs (KGs) aims at predicting missing relations in incomplete triples, whereas the dominant embedding paradigm has a restriction on handling unseen entities during testing. In the real-world scenario, the inductive setting is more common because entities in the training process are finite. Previous methods capture an inductive ability by implicit logic in KGs. However, it would be challenging to preciously acquire entity-independent relational semantics of compositional logic rules and to deal with the deficient supervision of logic caused by the scarcity of relational semantics. To this end, we propose a novel graph convolutional network (GCN)-based model LogCo with logical reasoning by contrastive representations. LogCo firstly extracts enclosing subgraphs and relational paths between two entities to supply the entity-independence. Then a contrastive strategy for relational path instances and the subgraph is proposed for the issue of deficient supervision. The contrastive representations are learned for a joint training regime. Finally, prediction results and logic rules for reasoning are attained. Comprehensive experiments on twelve inductive datasets show that LogCo achieves outstanding performance comparing with state-of-the-art inductive relation prediction baselines",
    "checked": true,
    "id": "f9cb56e41aeb1f6750e9b836e70259266708b093",
    "semantic_title": "inductive relation prediction with logical reasoning using contrastive representations",
    "citation_count": 10,
    "authors": [
      "Yudai Pan",
      "Jun Liu",
      "Lingling Zhang",
      "Tianzhe Zhao",
      "Qika Lin",
      "Xin Hu",
      "Qianying Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.287": {
    "title": "Improving Chinese Spelling Check by Character Pronunciation Prediction: The Effects of Adaptivity and Granularity",
    "volume": "main",
    "abstract": "Chinese spelling check (CSC) is a fundamental NLP task that detects and corrects spelling errors in Chinese texts. As most of these spelling errors are caused by phonetic similarity, effectively modeling the pronunciation of Chinese characters is a key factor for CSC. In this paper, we consider introducing an auxiliary task of Chinese pronunciation prediction (CPP) to improve CSC, and, for the first time, systematically discuss the adaptivity and granularity of this auxiliary task. We propose SCOPE which builds upon a shared encoder two parallel decoders, one for the primary CSC task and the other for a fine-grained auxiliary CPP task, with a novel adaptive weighting scheme to balance the two tasks. In addition, we design a delicate iterative correction strategy for further improvements during inference. Empirical evaluation shows that SCOPE achieves new state-of-the-art on three CSC benchmarks, demonstrating the effectiveness and superiority of the auxiliary CPP task. Comprehensive ablation studies further verify the positive effects of adaptivity and granularity of the task",
    "checked": true,
    "id": "5699d5050cc5495ad3bf4d299c0285f8239224f1",
    "semantic_title": "improving chinese spelling check by character pronunciation prediction: the effects of adaptivity and granularity",
    "citation_count": 14,
    "authors": [
      "Jiahao Li",
      "Quan Wang",
      "Zhendong Mao",
      "Junbo Guo",
      "Yanyan Yang",
      "Yongdong Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.288": {
    "title": "MT-GenEval: A Counterfactual and Contextual Dataset for Evaluating Gender Accuracy in Machine Translation",
    "volume": "main",
    "abstract": "As generic machine translation (MT) quality has improved, the need for targeted benchmarks that explore fine-grained aspects of quality has increased. In particular, gender accuracy in translation can have implications in terms of output fluency, translation accuracy, and ethics. In this paper, we introduce MT-GenEval, a benchmark for evaluating gender accuracy in translation from English into eight widely-spoken languages. MT-GenEval complements existing benchmarks by providing realistic, gender-balanced, counterfactual data in eight language pairs where the gender of individuals is unambiguous in the input segment, including multi-sentence segments requiring inter-sentential gender agreement. Our data and code is publicly available under a CC BY SA 3.0 license",
    "checked": true,
    "id": "a2ca7f29d41be0b88e447489a141ea28ece74997",
    "semantic_title": "mt-geneval: a counterfactual and contextual dataset for evaluating gender accuracy in machine translation",
    "citation_count": 23,
    "authors": [
      "Anna Currey",
      "Maria Nadejde",
      "Raghavendra Reddy Pappagari",
      "Mia Mayer",
      "Stanislas Lauly",
      "Xing Niu",
      "Benjamin Hsu",
      "Georgiana Dinu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.289": {
    "title": "A Span-level Bidirectional Network for Aspect Sentiment Triplet Extraction",
    "volume": "main",
    "abstract": "Aspect Sentiment Triplet Extraction (ASTE) is a new fine-grained sentiment analysis task that aims to extract triplets of aspect terms, sentiments, and opinion terms from review sentences. Recently, span-level models achieve gratifying results on ASTE task by taking advantage of the predictions of all possible spans. Since all possible spans significantly increases the number of potential aspect and opinion candidates, it is crucial and challenging to efficiently extract the triplet elements among them. In this paper, we present a span-level bidirectional network which utilizes all possible spans as input and extracts triplets from spans bidirectionally. Specifically, we devise both the aspect decoder and opinion decoder to decode the span representations and extract triples from aspect-to-opinion and opinion-to-aspect directions. With these two decoders complementing with each other, the whole network can extract triplets from spans more comprehensively. Moreover, considering that mutual exclusion cannot be guaranteed between the spans, we design a similar span separation loss to facilitate the downstream task of distinguishing the correct span by expanding the KL divergence of similar spans during the training process; in the inference process, we adopt an inference strategy to remove conflicting triplets from the results base on their confidence scores. Experimental results show that our framework not only significantly outperforms state-of-the-art methods, but achieves better performance in predicting triplets with multi-token entities and extracting triplets in sentences contain multi-triplets",
    "checked": true,
    "id": "787526e6a7990eccc34653ae182279472e727835",
    "semantic_title": "a span-level bidirectional network for aspect sentiment triplet extraction",
    "citation_count": 26,
    "authors": [
      "Yuqi Chen",
      "Chen Keming",
      "Xian Sun",
      "Zequn Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.290": {
    "title": "On the Calibration of Massively Multilingual Language Models",
    "volume": "main",
    "abstract": "Massively Multilingual Language Models (MMLMs) have recently gained popularity due to their surprising effectiveness in cross-lingual transfer. While there has been much work in evaluating these models for their performance on a variety of tasks and languages, little attention has been paid on how well calibrated these models are with respect to the confidence in their predictions. We first investigate the calibration of MMLMs in the zero-shot setting and observe a clear case of miscalibration in low-resource languages or those which are typologically diverse from English. Next, we empirically show that calibration methods like temperature scaling and label smoothing do reasonably well in improving calibration in the zero-shot scenario. We also find that few-shot examples in the language can further help reduce calibration errors, often substantially. Overall, our work contributes towards building more reliable multilingual models by highlighting the issue of their miscalibration, understanding what language and model-specific factors influence it, and pointing out the strategies to improve the same",
    "checked": true,
    "id": "a2b89d2196b4cc88797d4907ce7458bb7584f6b6",
    "semantic_title": "on the calibration of massively multilingual language models",
    "citation_count": 13,
    "authors": [
      "Kabir Ahuja",
      "Sunayana Sitaram",
      "Sandipan Dandapat",
      "Monojit Choudhury"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.291": {
    "title": "Momentum Contrastive Pre-training for Question Answering",
    "volume": "main",
    "abstract": "Existing pre-training methods for extractive Question Answering (QA) generate cloze-like queries different from natural questions in syntax structure, which could overfit pre-trained models to simple keyword matching. In order to address this problem, we propose a novel Momentum Contrastive pRe-training fOr queStion anSwering (MCROSS) method for extractive QA. Specifically, MCROSS introduces a momentum contrastive learning framework to align the answer probability between cloze-like and natural query-passage sample pairs. Hence, the pre-trained models can better transfer the knowledge learned in cloze-like samples to answering natural questions. Experimental results on three benchmarking QA datasets show that our method achieves noticeable improvement compared with all baselines in both supervised and zero-shot scenarios",
    "checked": true,
    "id": "4868e5cf730a9f7616d92e9a831f8b6c07b6ffe0",
    "semantic_title": "momentum contrastive pre-training for question answering",
    "citation_count": 2,
    "authors": [
      "Minda Hu",
      "Muzhi Li",
      "Yasheng Wang",
      "Irwin King"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.292": {
    "title": "A Second Wave of UD Hebrew Treebanking and Cross-Domain Parsing",
    "volume": "main",
    "abstract": "Foundational Hebrew NLP tasks such as segmentation, tagging and parsing, have relied to date on various versions of the Hebrew Treebank (HTB, Sima'an et al. 2001). However, the data in HTB, a single-source newswire corpus, is now over 30 years old, and does not cover many aspects of contemporary Hebrew on the web. This paper presents a new, freely available UD treebank of Hebrew stratified from a range of topics selected from Hebrew Wikipedia. In addition to introducing the corpus and evaluating the quality of its annotations, we deploy automatic validation tools based on grew (Guillaume, 2021), and conduct the first cross domain parsing experiments in Hebrew. We obtain new state-of-the-art (SOTA) results on UD NLP tasks, using a combination of the latest language modelling and some incremental improvements to existing transformer based approaches. We also release a new version of the UD HTB matching annotation scheme updates from our new corpus",
    "checked": true,
    "id": "0e6f7bebd93c5985ed2fd6ea078b5811cdba9e61",
    "semantic_title": "a second wave of ud hebrew treebanking and cross-domain parsing",
    "citation_count": 7,
    "authors": [
      "Amir Zeldes",
      "Nick Howell",
      "Noam Ordan",
      "Yifat Ben Moshe"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.293": {
    "title": "Finding Dataset Shortcuts with Grammar Induction",
    "volume": "main",
    "abstract": "Many NLP datasets have been found to contain shortcuts: simple decision rules that achieve surprisingly high accuracy. However, it is difficult to discover shortcuts automatically. Prior work on automatic shortcut detection has focused on enumerating features like unigrams or bigrams, which can find only low-level shortcuts, or relied on post-hoc model interpretability methods like saliency maps, which reveal qualitative patterns without a clear statistical interpretation. In this work, we propose to use probabilistic grammars to characterize and discover shortcuts in NLP datasets. Specifically, we use a context-free grammar to model patterns in sentence classification datasets and use a synchronous context-free grammar to model datasets involving sentence pairs. The resulting grammars reveal interesting shortcut features in a number of datasets, including both simple and high-level features, and automatically identify groups of test examples on which conventional classifiers fail. Finally, we show that the features we discover can be used to generate diagnostic contrast examples and incorporated into standard robust optimization methods to improve worst-group accuracy",
    "checked": true,
    "id": "7068acb5acca7b5915de5ee85a39586ab3f27198",
    "semantic_title": "finding dataset shortcuts with grammar induction",
    "citation_count": 11,
    "authors": [
      "Dan Friedman",
      "Alexander Wettig",
      "Danqi Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.294": {
    "title": "Retrieval Augmentation for Commonsense Reasoning: A Unified Approach",
    "volume": "main",
    "abstract": "A common thread of retrieval-augmented methods in the existing literature focuses on retrieving encyclopedic knowledge, such as Wikipedia, which facilitates well-defined entity and relation spaces that can be modeled. However, applying such methods to commonsense reasoning tasks faces two unique challenges, i.e., the lack of a general large-scale corpus for retrieval and a corresponding effective commonsense retriever. In this paper, we systematically investigate how to leverage commonsense knowledge retrieval to improve commonsense reasoning tasks. We proposed a unified framework of retrieval-augmented commonsense reasoning (called RACo), including a newly constructed commonsense corpus with over 20 million documents and novel strategies for training a commonsense retriever. We conducted experiments on four different commonsense reasoning tasks. Extensive evaluation results showed that our proposed RACo can significantly outperform other knowledge-enhanced method counterparts, achieving new SoTA performance on the CommonGen and CREAK leaderboards",
    "checked": true,
    "id": "d4f77cdb04d7ae02860415877cc4c463e93595a1",
    "semantic_title": "retrieval augmentation for commonsense reasoning: a unified approach",
    "citation_count": 14,
    "authors": [
      "Wenhao Yu",
      "Chenguang Zhu",
      "Zhihan Zhang",
      "Shuohang Wang",
      "Zhuosheng Zhang",
      "Yuwei Fang",
      "Meng Jiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.295": {
    "title": "Open World Classification with Adaptive Negative Samples",
    "volume": "main",
    "abstract": "Open world classification is a task in natural language processing with key practical relevance and impact.Since the open or unknown category data only manifests in the inference phase, finding a model with a suitable decision boundary accommodating for the identification of known classes and discrimination of the open category is challenging.The performance of existing models is limited by the lack of effective open category data during the training stage or the lack of a good mechanism to learn appropriate decision boundaries.We propose an approach based on Adaptive Negative Samples (ANS) designed to generate effective synthetic open category samples in the training stage and without requiring any prior knowledge or external datasets.Empirically, we find a significant advantage in using auxiliary one-versus-rest binary classifiers, which effectively utilize the generated negative samples and avoid the complex threshold-seeking stage in previous works.Extensive experiments on three benchmark datasets show that ANS achieves significant improvements over state-of-the-art methods",
    "checked": false,
    "id": "cb974c9e79e513975bea5a445dff37d05947ab0d",
    "semantic_title": "automated raman cytology for the classification of triple negative breast cancer cell lines",
    "citation_count": 0,
    "authors": [
      "Ke Bai",
      "Guoyin Wang",
      "Jiwei Li",
      "Sunghyun Park",
      "Sungjin Lee",
      "Puyang Xu",
      "Ricardo Henao",
      "Lawrence Carin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.296": {
    "title": "Re3: Generating Longer Stories With Recursive Reprompting and Revision",
    "volume": "main",
    "abstract": "We consider the problem of automatically generating longer stories of over two thousand words. Compared to prior work on shorter stories, long-range plot coherence and relevance are more central challenges here. We propose the Recursive Reprompting and Revision framework (Re3) to address these challenges by (a) prompting a general-purpose language model to construct a structured overarching plan, and (b) generating story passages by repeatedly injecting contextual information from both the plan and current story state into a language model prompt. We then revise by (c) reranking different continuations for plot coherence and premise relevance, and finally (d) editing the best continuation for factual consistency. Compared to similar-length stories generated directly from the same base model, human evaluators judged substantially more of Re3's stories as having a coherent overarching plot (by 14% absolute increase), and relevant to the given initial premise (by 20%)",
    "checked": true,
    "id": "2aab6ca1a8dae3f3db6d248231ac3fa4e222b30a",
    "semantic_title": "re3: generating longer stories with recursive reprompting and revision",
    "citation_count": 132,
    "authors": [
      "Kevin Yang",
      "Yuandong Tian",
      "Nanyun Peng",
      "Dan Klein"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.297": {
    "title": "Does Joint Training Really Help Cascaded Speech Translation?",
    "volume": "main",
    "abstract": "Currently, in speech translation, the straightforward approach - cascading a recognition system with a translation system - delivers state-of-the-art results.However, fundamental challenges such as error propagation from the automatic speech recognition system still remain.To mitigate these problems, recently, people turn their attention to direct data and propose various joint training methods.In this work, we seek to answer the question of whether joint training really helps cascaded speech translation.We review recent papers on the topic and also investigate a joint training criterion by marginalizing the transcription posterior probabilities.Our findings show that a strong cascaded baseline can diminish any improvements obtained using joint training, and we suggest alternatives to joint training.We hope this work can serve as a refresher of the current speech translation landscape, and motivate research in finding more efficient and creative ways to utilize the direct data for speech translation",
    "checked": true,
    "id": "b6ed84e0e69fc87de61645c1a50bcc169c95b983",
    "semantic_title": "does joint training really help cascaded speech translation?",
    "citation_count": 3,
    "authors": [
      "Viet Anh Khoa Tran",
      "David Thulke",
      "Yingbo Gao",
      "Christian Herold",
      "Hermann Ney"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.298": {
    "title": "MasakhaNER 2.0: Africa-centric Transfer Learning for Named Entity Recognition",
    "volume": "main",
    "abstract": "African languages are spoken by over a billion people, but they are under-represented in NLP research and development. Multiple challenges exist, including the limited availability of annotated training and evaluation datasets as well as the lack of understanding of which settings, languages, and recently proposed methods like cross-lingual transfer will be effective. In this paper, we aim to move towards solutions for these challenges, focusing on the task of named entity recognition (NER). We present the creation of the largest to-date human-annotated NER dataset for 20 African languages. We study the behaviour of state-of-the-art cross-lingual transfer methods in an Africa-centric setting, empirically demonstrating that the choice of source transfer language significantly affects performance. While much previous work defaults to using English as the source language, our results show that choosing the best transfer language improves zero-shot F1 scores by an average of 14% over 20 languages as compared to using English",
    "checked": true,
    "id": "7259ca612de44763678a30114b02d37c00280c86",
    "semantic_title": "masakhaner 2.0: africa-centric transfer learning for named entity recognition",
    "citation_count": 38,
    "authors": [
      "David Adelani",
      "Graham Neubig",
      "Sebastian Ruder",
      "Shruti Rijhwani",
      "Michael Beukman",
      "Chester Palen-Michel",
      "Constantine Lignos",
      "Jesujoba Alabi",
      "Shamsuddeen Muhammad",
      "Peter Nabende",
      "Cheikh M. Bamba Dione",
      "Andiswa Bukula",
      "Rooweither Mabuya",
      "Bonaventure F. P. Dossou",
      "Blessing Sibanda",
      "Happy Buzaaba",
      "Jonathan Mukiibi",
      "Godson Kalipe",
      "Derguene Mbaye",
      "Amelia Taylor",
      "Fatoumata Kabore",
      "Chris Chinenye Emezue",
      "Anuoluwapo Aremu",
      "Perez Ogayo",
      "Catherine Gitau",
      "Edwin Munkoh-Buabeng",
      "Victoire Memdjokam Koagne",
      "Allahsera Auguste Tapo",
      "Tebogo Macucwa",
      "Vukosi Marivate",
      "Mboning Tchiaze Elvis",
      "Tajuddeen Gwadabe",
      "Tosin Adewumi",
      "Orevaoghene Ahia",
      "Joyce Nakatumba-Nabende"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.299": {
    "title": "Ethics consideration sections in natural language processing papers",
    "volume": "main",
    "abstract": "In this paper, we present the results of a manual classification of all ethical consideration sections for ACL 2021. We also compare how many papers had an ethics consideration section per track and per world region in ACL 2021. We classified papers according to the ethical issues covered (research benefits, potential harms, and vulnerable groups affected) and whether the paper was marked as requiring ethics review by at least one reviewer. Moreover, we discuss recurring obstacles we have observed (highlighting some interesting texts we found along the way) and conclude with three suggestions. We think that this paper may be useful for anyone who needs to write — or review — an ethics section and would like to get an overview of what others have done",
    "checked": true,
    "id": "8f16c64af8021a881cc092a215bf57391d2668d0",
    "semantic_title": "ethics consideration sections in natural language processing papers",
    "citation_count": 5,
    "authors": [
      "Luciana Benotti",
      "Patrick Blackburn"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.300": {
    "title": "Continued Pretraining for Better Zero- and Few-Shot Promptability",
    "volume": "main",
    "abstract": "Recently introduced language model prompting methods can achieve high accuracy in zero- and few-shot settings while requiring few to no learned task-specific parameters. Nevertheless, these methods still often trail behind full model finetuning. In this work, we investigate if a dedicated continued pretraining stage could improve \"promptability\", i.e., zero-shot performance with natural language prompts or few-shot performance with prompt tuning. We reveal settings where existing continued pretraining methods lack promptability. We also identify current methodological gaps, which we fill with thorough large-scale experiments. We demonstrate that a simple recipe, continued pretraining that incorporates a trainable prompt during multi-task learning, leads to improved promptability in both zero- and few-shot settings compared to existing methods, up to 31% relative. On the other hand, we find that continued pretraining using MAML-style meta-learning, a method that directly optimizes few-shot promptability, yields subpar performance. We validate our findings with two prompt tuning methods, and, based on our results, we provide concrete recommendations to optimize promptability for different use cases",
    "checked": true,
    "id": "53868a2a4caea7afc487ef08993372b186fb2ddb",
    "semantic_title": "continued pretraining for better zero- and few-shot promptability",
    "citation_count": 9,
    "authors": [
      "Zhaofeng Wu",
      "Robert L Logan IV",
      "Pete Walsh",
      "Akshita Bhagia",
      "Dirk Groeneveld",
      "Sameer Singh",
      "Iz Beltagy"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.301": {
    "title": "Less is More: Summary of Long Instructions is Better for Program Synthesis",
    "volume": "main",
    "abstract": "Despite the success of large pre-trained language models (LMs) such as Codex, they show below-par performance on the larger and more complicated programming related questions. We show that LMs benefit from the summarized version of complicated questions. Our findings show that superfluous information often present in problem description such as human characters, background stories, and names (which are included to help humans in understanding a task) does not help models in understanding a task. To this extent, we create a meta-dataset from the frequently used APPS dataset and the newly created CodeContests dataset for the program synthesis task. Our meta-dataset consists of human and synthesized summaries of the long and complicated programming questions. Experimental results on Codex show that our proposed approach outperforms baseline by 8.13% on the APPS dataset and 11.88% on the CodeContests dataset on an average in terms of strict accuracy. Our analysis shows that summaries significantly improve performance for introductory (9.86%) and interview (11.48%) related programming questions. However, it shows improvement by a small margin ( 2%) for competitive programming questions, implying the scope for future research direction",
    "checked": true,
    "id": "590f6817b42407f96b079e82c935fae298196359",
    "semantic_title": "less is more: summary of long instructions is better for program synthesis",
    "citation_count": 20,
    "authors": [
      "Kirby Kuznia",
      "Swaroop Mishra",
      "Mihir Parmar",
      "Chitta Baral"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.302": {
    "title": "Is a Question Decomposition Unit All We Need?",
    "volume": "main",
    "abstract": "Large Language Models (LMs) have achieved state-of-the-art performance on many Natural Language Processing (NLP) benchmarks. With the growing number of new benchmarks, we build bigger and more complex LMs. However, building new LMs may not be an ideal option owing to the cost, time and environmental impact associated with it. We explore an alternative route: can we modify data by expressing it in terms of the model's strengths, so that a question becomes easier for models to answer? We investigate if humans can decompose a hard question into a set of simpler questions that are relatively easier for models to solve. We analyze a range of datasets involving various forms of reasoning and find that it is indeed possible to significantly improve model performance (24% for GPT3 and 29% for RoBERTa-SQuAD along with a symbolic calculator) via decomposition. Our approach provides a viable option to involve people in NLP research in a meaningful way. Our findings indicate that Human-in-the-loop Question Decomposition (HQD) can potentially provide an alternate path to building large LMs",
    "checked": true,
    "id": "a80f2102e5de3ead1b9689b440503f49383ddc94",
    "semantic_title": "is a question decomposition unit all we need?",
    "citation_count": 37,
    "authors": [
      "Pruthvi Patel",
      "Swaroop Mishra",
      "Mihir Parmar",
      "Chitta Baral"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.303": {
    "title": "Discourse-Aware Soft Prompting for Text Generation",
    "volume": "main",
    "abstract": "Current efficient fine-tuning methods(e.g., adapters, prefix-tuning, etc.) have optimized conditional text generation via training a small set of extra parameters of the neural language model, while freezing the rest for efficiency. While showing strong performance on some generation tasks, they don't generalize across all generation tasks. We show that soft-prompt based conditional text generation can be improved with simple and efficient methods that simulate modeling the discourse structure of human written text.We investigate two design choices: First, we apply hierarchical blocking on the prefix parameters to simulate a higher-level discourse structure of human written text. Second, we apply attention sparsity on the prefix parameters at different layers of the network and learn sparse transformations on the softmax-function. We show that structured design of prefix parameters yields more coherent, faithful and relevant generations than the baseline prefix-tuning on all generation tasks",
    "checked": true,
    "id": "a3c8c57075dfebf7f5a57952afafb7407762cc46",
    "semantic_title": "discourse-aware soft prompting for text generation",
    "citation_count": 4,
    "authors": [
      "Marjan Ghazvininejad",
      "Vladimir Karpukhin",
      "Vera Gor",
      "Asli Celikyilmaz"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.304": {
    "title": "ExPUNations: Augmenting Puns with Keywords and Explanations",
    "volume": "main",
    "abstract": "The tasks of humor understanding and generation are challenging and subjective even for humans, requiring commonsense and real-world knowledge to master. Puns, in particular, add the challenge of fusing that knowledge with the ability to interpret lexical-semantic ambiguity. In this paper, we present the ExPUNations (ExPUN) dataset, in which we augment an existing dataset of puns with detailed crowdsourced annotations of keywords denoting the most distinctive words that make the text funny, pun explanations describing why the text is funny, and fine-grained funniness ratings. This is the first humor dataset with such extensive and fine-grained annotations specifically for puns. Based on these annotations, we propose two tasks: explanation generation to aid with pun classification and keyword-conditioned pun generation, to challenge the current state-of-the-art natural language understanding and generation models' ability to understand and generate humor. We showcase that the annotated keywords we collect are helpful for generating better novel humorous texts in human evaluation, and that our natural language explanations can be leveraged to improve both the accuracy and robustness of humor classifiers",
    "checked": true,
    "id": "e078d5ea102673ba5962821c0109a08c2eddb7cf",
    "semantic_title": "expunations: augmenting puns with keywords and explanations",
    "citation_count": 9,
    "authors": [
      "Jiao Sun",
      "Anjali Narayan-Chen",
      "Shereen Oraby",
      "Alessandra Cervone",
      "Tagyoung Chung",
      "Jing Huang",
      "Yang Liu",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.305": {
    "title": "SLING: Sino Linguistic Evaluation of Large Language Models",
    "volume": "main",
    "abstract": "To understand what kinds of linguistic knowledge are encoded by pretrained Chinese language models (LMs), we introduce the benchmark of Sino LINGuistics (SLING), which consists of 38K minimal sentence pairs in Mandarin Chinese grouped into 9 high-level linguistic phenomena. Each pair demonstrates the acceptability contrast of a specific syntactic or semantic phenomenon (e.g., The keys are lost vs. The keys is lost), and an LM should assign lower perplexity to the acceptable sentence. In contrast to the CLiMP dataset (Xiang et al., 2021), which also contains Chinese minimal pairs and was created by translating the vocabulary of the English BLiMP dataset, the minimal pairs in SLING are derived primarily by applying syntactic and lexical transformations to naturally-occurring, linguist-annotated sentences from the Chinese Treebank 9.0, thus addressing severe issues in CLiMP's data generation process. We test 18 publicly available pretrained monolingual (e.g., BERT-base-zh, CPM) and multi-lingual (e.g., mT5, XLM) language models on SLING. Our experiments show that the average accuracy for LMs is far below human performance (69.7% vs. 97.1%), while BERT-base-zh achieves the highest accuracy (84.8%) of all tested LMs, even much larger ones. Additionally, we find that most LMs have a strong gender and number (singular/plural) bias, and they perform better on local phenomena than hierarchical ones",
    "checked": true,
    "id": "d2b1405ac8d17f8643ed1f8f7d801e9e406d8da6",
    "semantic_title": "sling: sino linguistic evaluation of large language models",
    "citation_count": 3,
    "authors": [
      "Yixiao Song",
      "Kalpesh Krishna",
      "Rajesh Bhatt",
      "Mohit Iyyer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.306": {
    "title": "Context-Situated Pun Generation",
    "volume": "main",
    "abstract": "Previous work on pun generation commonly begins with a given pun word (a pair of homophones for heterographic pun generation and a polyseme for homographic pun generation) and seeks to generate an appropriate pun. While this may enable efficient pun generation, we believe that a pun is most entertaining if it fits appropriately within a given context, e.g., a given situation or dialogue. In this work, we propose a new task, context-situated pun generation, where a specific context represented by a set of keywords is provided, and the task is to first identify suitable pun words that are appropriate for the context, then generate puns based on the context keywords and the identified pun words. We collect a new dataset, CUP (Context-sitUated Pun), containing 4.5k tuples of context words and pun pairs. Based on the new data and setup, we propose a pipeline system for context-situated pun generation, including a pun word retrieval module that identifies suitable pun words for a given context, and a pun generation module that generates puns from context keywords and pun words. Human evaluation shows that 69% of our top retrieved pun words can be used to generate context-situated puns, and our generation module yields successful puns 31% of the time given a plausible tuple of context words and pun pair, almost tripling the yield of a state-of-the-art pun generation model. With an end-to-end evaluation, our pipeline system with the top-1 retrieved pun pair for a given context can generate successful puns 40% of the time, better than all other modeling variations but 32% lower than the human success rate. This highlights the difficulty of the task, and encourages more research in this direction",
    "checked": true,
    "id": "a66b091b71f862dc8f8865e9e1cc1249a3d13252",
    "semantic_title": "context-situated pun generation",
    "citation_count": 7,
    "authors": [
      "Jiao Sun",
      "Anjali Narayan-Chen",
      "Shereen Oraby",
      "Shuyang Gao",
      "Tagyoung Chung",
      "Jing Huang",
      "Yang Liu",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.307": {
    "title": "Retrieval-Augmented Generative Question Answering for Event Argument Extraction",
    "volume": "main",
    "abstract": "Event argument extraction has long been studied as a sequential prediction problem with extractive-based methods, tackling each argument in isolation. Although recent work proposes generation-based methods to capture cross-argument dependency, they require generating and post-processing a complicated target sequence (template). Motivated by these observations and recent pretrained language models' capabilities of learning from demonstrations. We propose a retrieval-augmented generative QA model (R-GQA) for event argument extraction. It retrieves the most similar QA pair and augments it as prompt to the current example's context, then decodes the arguments as answers. Our approach outperforms substantially prior methods across various settings (i.e. fully supervised, domain transfer, and fewshot learning). Finally, we propose a clustering-based sampling strategy (JointEnc) and conduct a thorough analysis of how different strategies influence the few-shot learning performances",
    "checked": true,
    "id": "b8a69be1ea8b1e6cad89d939a5234f0f8ce11c61",
    "semantic_title": "retrieval-augmented generative question answering for event argument extraction",
    "citation_count": 20,
    "authors": [
      "Xinya Du",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.308": {
    "title": "Concadia: Towards Image-Based Text Generation with a Purpose",
    "volume": "main",
    "abstract": "Current deep learning models often achieve excellent results on benchmark image-to-text datasets but fail to generate texts that are useful in practice. We argue that to close this gap, it is vital to distinguish descriptions from captions based on their distinct communicative roles. Descriptions focus on visual features and are meant to replace an image (often to increase accessibility), whereas captions appear alongside an image to supply additional information. To motivate this distinction and help people put it into practice, we introduce the publicly available Wikipedia-based dataset Concadia consisting of 96,918 images with corresponding English-language descriptions, captions, and surrounding context. Using insights from Concadia, models trained on it, and a preregistered human-subjects experiment with human- and model-generated texts, we characterize the commonalities and differences between descriptions and captions. In addition, we show that, for generating both descriptions and captions, it is useful to augment image-to-text models with representations of the textual context in which the image appeared",
    "checked": true,
    "id": "898e66efc50279dd01dc70eb40959683e962250c",
    "semantic_title": "concadia: towards image-based text generation with a purpose",
    "citation_count": 14,
    "authors": [
      "Elisa Kreiss",
      "Fei Fang",
      "Noah Goodman",
      "Christopher Potts"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.309": {
    "title": "Context Matters for Image Descriptions for Accessibility: Challenges for Referenceless Evaluation Metrics",
    "volume": "main",
    "abstract": "Few images on the Web receive alt-text descriptions that would make them accessible to blind and low vision (BLV) users. Image-based NLG systems have progressed to the point where they can begin to address this persistent societal problem, but these systems will not be fully successful unless we evaluate them on metrics that guide their development correctly. Here, we argue against current referenceless metrics – those that don't rely on human-generated ground-truth descriptions – on the grounds that they do not align with the needs of BLV users. The fundamental shortcoming of these metrics is that they do not take context into account, whereas contextual information is highly valued by BLV users. To substantiate these claims, we present a study with BLV participants who rated descriptions along a variety of dimensions. An in-depth analysis reveals that the lack of context-awareness makes current referenceless metrics inadequate for advancing image accessibility. As a proof-of-concept, we provide a contextual version of the referenceless metric CLIPScore which begins to address the disconnect to the BLV data",
    "checked": true,
    "id": "80c8803bc3af3081d054b755f9819fe0addc6818",
    "semantic_title": "context matters for image descriptions for accessibility: challenges for referenceless evaluation metrics",
    "citation_count": 21,
    "authors": [
      "Elisa Kreiss",
      "Cynthia Bennett",
      "Shayan Hooshmand",
      "Eric Zelikman",
      "Meredith Ringel Morris",
      "Christopher Potts"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.310": {
    "title": "MetaLogic: Logical Reasoning Explanations with Fine-Grained Structure",
    "volume": "main",
    "abstract": "In this paper, we propose a comprehensive benchmark to investigate models' logical reasoning capabilities in complex real-life scenarios. Current explanation datasets often employ synthetic data with simple reasoning structures. Therefore, it cannot express more complex reasoning processes, such as the rebuttal to a reasoning step and the degree of certainty of the evidence. To this end, we propose a comprehensive logical reasoning explanation form. Based on the multi-hop chain of reasoning, the explanation form includes three main components: (1) The condition of rebuttal that the reasoning node can be challenged; (2) Logical formulae that uncover the internal texture of reasoning nodes; (3) Reasoning strength indicated by degrees of certainty. The fine-grained structure conforms to the real logical reasoning scenario, better fitting the human cognitive process but, simultaneously, is more challenging for the current models. We evaluate the current best models' performance on this new explanation form. The experimental results show that generating reasoning graphs remains a challenging task for current models, even with the help of giant pre-trained language models",
    "checked": true,
    "id": "2b22a3acb3ba1581d320b70b02343d4a0f356e3e",
    "semantic_title": "metalogic: logical reasoning explanations with fine-grained structure",
    "citation_count": 6,
    "authors": [
      "Yinya Huang",
      "Hongming Zhang",
      "Ruixin Hong",
      "Xiaodan Liang",
      "Changshui Zhang",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.311": {
    "title": "Explicit Query Rewriting for Conversational Dense Retrieval",
    "volume": "main",
    "abstract": "In a conversational search scenario, a query might be context-dependent because some words are referred to previous expressions or omitted. Previous works tackle the issue by either reformulating the query into a self-contained query (query rewriting) or learning a contextualized query embedding from the query context (context modelling). In this paper, we propose a model CRDR that can perform query rewriting and context modelling in a unified framework in which the query rewriting's supervision signals further enhance the context modelling. Instead of generating a new query, CRDR only performs necessary modifications on the original query, which improves both accuracy and efficiency of query rewriting. In the meantime, the query rewriting benefits the context modelling by explicitly highlighting relevant terms in the query context, which improves the quality of the learned contextualized query embedding. To verify the effectiveness of CRDR, we perform comprehensive experiments on TREC CAsT-19 and TREC CAsT-20 datasets, and the results show that our method outperforms all baseline models in terms of both quality of query rewriting and quality of context-aware ranking",
    "checked": true,
    "id": "17697b59ff29a1c20be1385f7e64d12d9cd95c80",
    "semantic_title": "explicit query rewriting for conversational dense retrieval",
    "citation_count": 8,
    "authors": [
      "Hongjin Qian",
      "Zhicheng Dou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.312": {
    "title": "Efficient Nearest Neighbor Emotion Classification with BERT-whitening",
    "volume": "main",
    "abstract": "Retrieval-based methods have been proven effective in many NLP tasks. Previous methods use representations from the pre-trained model for similarity search directly. However, the sentence representations from the pre-trained model like BERT perform poorly in retrieving semantically similar sentences, resulting in poor performance of the retrieval-based methods. In this paper, we propose kNN-EC, a simple and efficient non-parametric emotion classification (EC) method using nearest neighbor retrieval. We use BERT-whitening to get better sentence semantics, ensuring that nearest neighbor retrieval works. Meanwhile, BERT-whitening can also reduce memory storage of datastore and accelerate retrieval speed, solving the efficiency problem of the previous methods. kNN-EC average improves the pre-trained model by 1.17 F1-macro on two emotion classification datasets",
    "checked": true,
    "id": "af745384a71f3c8cc6b1f4514c875633344c7bc1",
    "semantic_title": "efficient nearest neighbor emotion classification with bert-whitening",
    "citation_count": 4,
    "authors": [
      "Wenbiao Yin",
      "Lin Shang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.313": {
    "title": "FastClass: A Time-Efficient Approach to Weakly-Supervised Text Classification",
    "volume": "main",
    "abstract": "Weakly-supervised text classification aims to train a classifier using only class descriptions and unlabeled data. Recent research shows that keyword-driven methods can achieve state-of-the-art performance on various tasks. However, these methods not only rely on carefully-crafted class descriptions to obtain class-specific keywords but also require substantial amount of unlabeled data and takes a long time to train. This paper proposes FastClass, an efficient weakly-supervised classification approach. It uses dense text representation to retrieve class-relevant documents from external unlabeled corpus and selects an optimal subset to train a classifier. Compared to keyword-driven methods, our approach is less reliant on initial class descriptions as it no longer needs to expand each class description into a set of class-specific keywords. Experiments on a wide range of classification tasks show that the proposed approach frequently outperforms keyword-driven models in terms of classification accuracy and often enjoys orders-of-magnitude faster training speed",
    "checked": true,
    "id": "b7d37760e1d6894bcab1a4b3054df9119fe1d556",
    "semantic_title": "fastclass: a time-efficient approach to weakly-supervised text classification",
    "citation_count": 1,
    "authors": [
      "Tingyu Xia",
      "Yue Wang",
      "Yuan Tian",
      "Yi Chang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.314": {
    "title": "Neural-Symbolic Inference for Robust Autoregressive Graph Parsing via Compositional Uncertainty Quantification",
    "volume": "main",
    "abstract": "Pre-trained seq2seq models excel at graph semantic parsing with rich annotated data, but generalize worse to out-of-distribution (OOD) and long-tail examples. In comparison, symbolic parsers under-perform on population-level metrics, but exhibit unique strength in OOD and tail generalization. In this work, we study compositionality-aware approach to neural-symbolic inference informed by model confidence, performing fine-grained neural-symbolic reasoning at subgraph level (i.e., nodes and edges) and precisely targeting subgraph components with high uncertainty in the neural parser. As a result, the method combines the distinct strength of the neural and symbolic approaches in capturing different aspects of the graph prediction, leading to well-rounded generalization performance both across domains and in the tail. We empirically investigate the approach in the English Resource Grammar (ERG) parsing problem on a diverse suite of standard in-domain and seven OOD corpora. Our approach leads to 35.26% and 35.60% error reduction in aggregated SMATCH score over neural and symbolic approaches respectively, and 14% absolute accuracy gain in key tail linguistic categories over the neural model, outperforming prior state-of-art methods that do not account for compositionality or uncertainty",
    "checked": true,
    "id": "67c0b0f0b1efb2e25084d23ed310109fb3c451aa",
    "semantic_title": "neural-symbolic inference for robust autoregressive graph parsing via compositional uncertainty quantification",
    "citation_count": 5,
    "authors": [
      "Zi Lin",
      "Jeremiah Liu",
      "Jingbo Shang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.315": {
    "title": "A Speaker-Aware Co-Attention Framework for Medical Dialogue Information Extraction",
    "volume": "main",
    "abstract": "With the development of medical digitization, the extraction and structuring of Electronic Medical Records (EMRs) have become challenging but fundamental tasks. How to accurately and automatically extract structured information from medical dialogues is especially difficult because the information needs to be inferred from complex interactions between the doctor and the patient. To this end, in this paper, we propose a speaker-aware co-attention framework for medical dialogue information extraction. To better utilize the pre-trained language representation model to perceive the semantics of the utterance and the candidate item, we develop a speaker-aware dialogue encoder with multi-task learning, which considers the speaker's identity into account. To deal with complex interactions between different utterances and the correlations between utterances and candidate items, we propose a co-attention fusion network to aggregate the utterance information. We evaluate our framework on the public medical dialogue extraction datasets to demonstrate the superiority of our method, which can outperform the state-of-the-art methods by a large margin. Codes will be publicly available upon acceptance",
    "checked": true,
    "id": "ef29d33578fc1456dd833e21e8b86b0036af1328",
    "semantic_title": "a speaker-aware co-attention framework for medical dialogue information extraction",
    "citation_count": 3,
    "authors": [
      "Yuan Xia",
      "Zhenhui Shi",
      "Jingbo Zhou",
      "Jiayu Xu",
      "Chao Lu",
      "Yehui Yang",
      "Lei Wang",
      "Haifeng Huang",
      "Xia Zhang",
      "Junwei Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.316": {
    "title": "Towards Interactivity and Interpretability: A Rationale-based Legal Judgment Prediction Framework",
    "volume": "main",
    "abstract": "Legal judgment prediction (LJP) is a fundamental task in legal AI, which aims to assist the judge to hear the case and determine the judgment. The legal judgment usually consists of the law article, charge, and term of penalty. In the real trial scenario, the judge usually makes the decision step-by-step: first concludes the rationale according to the case's facts and then determines the judgment. Recently, many models have been proposed and made tremendous progress in LJP, but most of them adopt an end-to-end manner that cannot be manually intervened by the judge for practical use. Moreover, existing models lack interpretability due to the neglect of rationale in the prediction process. Following the judge's real trial logic, in this paper, we propose a novel Rationale-based Legal Judgment Prediction (RLJP) framework. In the RLJP framework, the LJP process is split into two steps. In the first phase, the model generates the rationales according to the fact description. Then it predicts the judgment based on the fact and the generated rationales. Extensive experiments on a real-world dataset show RLJP achieves the best results compared to the state-of-the-art models. Meanwhile, the proposed framework provides good interactivity and interpretability which enables practical use",
    "checked": true,
    "id": "b1ada40cce59ea3f171eac8bf83017da49082c06",
    "semantic_title": "towards interactivity and interpretability: a rationale-based legal judgment prediction framework",
    "citation_count": 14,
    "authors": [
      "Yiquan Wu",
      "Yifei Liu",
      "Weiming Lu",
      "Yating Zhang",
      "Jun Feng",
      "Changlong Sun",
      "Fei Wu",
      "Kun Kuang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.317": {
    "title": "RelCLIP: Adapting Language-Image Pretraining for Visual Relationship Detection via Relational Contrastive Learning",
    "volume": "main",
    "abstract": "Conventional visual relationship detection models only use the numeric ids of relation labels for training, but ignore the semantic correlation between the labels, which leads to severe training biases and harms the generalization ability of representations. In this paper, we introduce compact language information of relation labels for regularizing the representation learning of visual relations. Specifically, we propose a simple yet effective visual Relationship prediction framework that transfers natural language knowledge learned from Contrastive Language-Image Pre-training (CLIP) models to enhance the relationship prediction, termed RelCLIP. Benefiting from the powerful visual-semantic alignment ability of CLIP at image level, we introduce a novel Relational Contrastive Learning (RCL) approach which explores relation-level visual-semantic alignment via learning to match cross-modal relational embeddings. By collaboratively learning the semantic coherence and discrepancy from relation triplets, the model can generate more discriminative and robust representations. Experimental results on the Visual Genome dataset show that RelCLIP achieves significant improvements over strong baselines under full (provide accurate labels) and distant supervision (provide noise labels), demonstrating its powerful generalization ability in learning relationship representations. Code will be available at https://gitee.com/mindspore/models/tree/master/research/cv/RelCLIP",
    "checked": true,
    "id": "979c3ba88b3e3604d5a9ccfcc6a8a608704b868b",
    "semantic_title": "relclip: adapting language-image pretraining for visual relationship detection via relational contrastive learning",
    "citation_count": 2,
    "authors": [
      "Yi Zhu",
      "Zhaoqing Zhu",
      "Bingqian Lin",
      "Xiaodan Liang",
      "Feng Zhao",
      "Jianzhuang Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.318": {
    "title": "Candidate Soups: Fusing Candidate Results Improves Translation Quality for Non-Autoregressive Translation",
    "volume": "main",
    "abstract": "Non-autoregressive translation (NAT) model achieves a much faster inference speed than the autoregressive translation (AT) model because it can simultaneously predict all tokens during inference. However, its translation quality suffers from degradation compared to AT. And existing NAT methods only focus on improving the NAT model's performance but do not fully utilize it. In this paper, we propose a simple but effective method called \"Candidate Soups,\" which can obtain high-quality translations while maintaining the inference speed of NAT models. Unlike previous approaches that pick the individual result and discard the remainders, Candidate Soups (CDS) can fully use the valuable information in the different candidate translations through model uncertainty. Extensive experiments on two benchmarks (WMT'14 EN–DE and WMT'16 EN–RO) demonstrate the effectiveness and generality of our proposed method, which can significantly improve the translation quality of various base models. More notably, our best variant outperforms the AT model on three translation tasks with 7.6× speedup",
    "checked": true,
    "id": "45fe20ec9a351e6f6d24316cdfef30a84062ce5b",
    "semantic_title": "candidate soups: fusing candidate results improves translation quality for non-autoregressive translation",
    "citation_count": 3,
    "authors": [
      "Huanran Zheng",
      "Wei Zhu",
      "Pengfei Wang",
      "Xiaoling Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.319": {
    "title": "Evaluating Parameter Efficient Learning for Generation",
    "volume": "main",
    "abstract": "Parameter efficient learning methods (PERMs)have recently gained significant attention asthey provide an efficient way for pre-trainedlanguage models (PLMs) to adapt to a downstream task. However, these conclusions aremostly drawn from in-domain evaluations overthe full training set. In this paper, we presentcomparisons between PERMs and finetuningfrom three new perspectives: (1) the effect ofsample and model size to in-domain evaluations, (2) generalization to unseen domains andnew datasets, and (3) the faithfulness of generations. Our results show that for in-domainsettings (a) there is a cross point of samplesize for which PERMs will perform better thanfinetuning when training with fewer samples,and (b) larger PLMs have larger cross points. For cross-domain and cross-dataset cases, weshow that (a) Adapter (Houlsby et al., 2019)performs the best amongst all the PERMs studied here, and (b) it outperforms finetuning ifthe task dataset is below a certain size. Wealso compare the faithfulness of generationsand show that PERMs can achieve better faithfulness score than finetuning, especially forsmall training set, by as much as 6%. Finally,we apply Adapter to MT-NLG 530b (Smithet al., 2022) and achieve new state-of-the-artresults on Xsum (Narayan et al., 2018) for allROUGE scores (ROUGE-1 49.17, ROUGE-227.20, ROUGE-L 40.98)",
    "checked": true,
    "id": "5f25d61830314a4302cf07feaf8be221d5e2d2fc",
    "semantic_title": "evaluating parameter efficient learning for generation",
    "citation_count": 3,
    "authors": [
      "Peng Xu",
      "Mostofa Patwary",
      "Shrimai Prabhumoye",
      "Virginia Adams",
      "Ryan Prenger",
      "Wei Ping",
      "Nayeon Lee",
      "Mohammad Shoeybi",
      "Bryan Catanzaro"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.320": {
    "title": "McQueen: a Benchmark for Multimodal Conversational Query Rewrite",
    "volume": "main",
    "abstract": "The task of query rewrite aims to convert an in-context query to its fully-specified version where ellipsis and coreference are completed and referred-back according to the history context. Although much progress has been made, less efforts have been paid to real scenario conversations that involve drawing information from more than one modalities. In this paper, we propose the task of multimodal conversational query rewrite (McQR), which performs query rewrite under the multimodal visual conversation setting. We collect a large-scale dataset named McQueen based on manual annotation, which contains 15k visual conversations and over 80k queries where each one is associated with a fully-specified rewrite version. In addition, for entities appearing in the rewrite, we provide the corresponding image box annotation. We then use the McQueen dataset to benchmark a state-of-the-art method for effectively tackling the McQR task, which is based on a multimodal pre-trained model with pointer generator. Extensive experiments are performed to demonstrate the effectiveness of our model on this task",
    "checked": true,
    "id": "90f9450ec1456816d46604d236c48712a29f7d08",
    "semantic_title": "mcqueen: a benchmark for multimodal conversational query rewrite",
    "citation_count": 5,
    "authors": [
      "Yifei Yuan",
      "Chen Shi",
      "Runze Wang",
      "Liyi Chen",
      "Feijun Jiang",
      "Yuan You",
      "Wai Lam"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.321": {
    "title": "Self-supervised Graph Masking Pre-training for Graph-to-Text Generation",
    "volume": "main",
    "abstract": "Large-scale pre-trained language models (PLMs) have advanced Graph-to-Text (G2T) generation by processing the linearised version of a graph. However, the linearisation is known to ignore the structural information. Additionally, PLMs are typically pre-trained on free text which introduces domain mismatch between pre-training and downstream G2T generation tasks. To address these shortcomings, we propose graph masking pre-training strategies that neither require supervision signals nor adjust the architecture of the underlying pre-trained encoder-decoder model. When used with a pre-trained T5, our approach achieves new state-of-the-art results on WebNLG+2020 and EventNarrative G2T generation datasets. Our method also shows to be very effective in the low-resource setting",
    "checked": true,
    "id": "6462f367550af0dab4eda55530c854743469c1d6",
    "semantic_title": "self-supervised graph masking pre-training for graph-to-text generation",
    "citation_count": 6,
    "authors": [
      "Jiuzhou Han",
      "Ehsan Shareghi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.322": {
    "title": "Improving Stability of Fine-Tuning Pretrained Language Models via Component-Wise Gradient Norm Clipping",
    "volume": "main",
    "abstract": "Fine-tuning over large pretrained language models (PLMs) has established many state-of-the-art results. Despite its superior performance, such fine-tuning can be unstable, resulting in significant variance in performance and potential risks for practical applications. Previous works have attributed such instability to the catastrophic forgetting problem in the top layers of PLMs, which indicates iteratively fine-tuning layers in a top-down manner is a promising solution. In this paper, we first point out that this method does not always work out due to the different convergence speeds of different layers/modules. Inspired by this observation, we propose a simple component-wise gradient norm clipping method to adjust the convergence speed for different components. Experiment results demonstrate that our method achieves consistent improvements in terms of generalization performance, convergence speed, and training stability. The codebase can be found at https://github.com/yangalan123/FineTuningStability",
    "checked": true,
    "id": "048a71c2b2b1fca75feff0914a375ffe5aa023c9",
    "semantic_title": "improving stability of fine-tuning pretrained language models via component-wise gradient norm clipping",
    "citation_count": 4,
    "authors": [
      "Chenghao Yang",
      "Xuezhe Ma"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.323": {
    "title": "Differentially Private Language Models for Secure Data Sharing",
    "volume": "main",
    "abstract": "To protect the privacy of individuals whose data is being shared, it is of high importance to develop methods allowing researchers and companies to release textual data while providing formal privacy guarantees to its originators. In the field of NLP, substantial efforts have been directed at building mechanisms following the framework of local differential privacy, thereby anonymizing individual text samples before releasing them. In practice, these approaches are often dissatisfying in terms of the quality of their output language due to the strong noise required for local differential privacy. In this paper, we approach the problem at hand using global differential privacy, particularly by training a generative language model in a differentially private manner and consequently sampling data from it. Using natural language prompts and a new prompt-mismatch loss, we are able to create highly accurate and fluent textual datasets taking on specific desired attributes such as sentiment or topic and resembling statistical properties of the training data. We perform thorough experiments indicating that our synthetic datasets do not leak information from our original data and are of high language quality and highly suitable for training models for further analysis on real-world data. Notably, we also demonstrate that training classifiers on private synthetic data outperforms directly training classifiers with DP-SGD",
    "checked": true,
    "id": "af710ada8965f274e810053f716f966627a136d9",
    "semantic_title": "differentially private language models for secure data sharing",
    "citation_count": 18,
    "authors": [
      "Justus Mattern",
      "Zhijing Jin",
      "Benjamin Weggenmann",
      "Bernhard Schoelkopf",
      "Mrinmaya Sachan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.324": {
    "title": "Conditional set generation using Seq2seq models",
    "volume": "main",
    "abstract": "Conditional set generation learns a mapping from an input sequence of tokens to a set. Several NLP tasks, such as entity typing and dialogue emotion tagging, are instances of set generation. Seq2Seq models are a popular choice to model set generation but they treat a set as a sequence and do not fully leverage its key properties, namely order-invariance and cardinality. We propose a novel algorithm for effectively sampling informative orders over the combinatorial space of label orders. Further, we jointly model the set cardinality and output by listing the set size as the first element and taking advantage of the autoregressive factorization used by Seq2Seq models. Our method is a model-independent data augmentation approach that endows any Seq2Seq model with the signals of order-invariance and cardinality. Training a Seq2Seq model on this new augmented data (without any additional annotations), gets an average relative improvement of 20% for four benchmarks datasets across models spanning from BART-base, T5-11B, and GPT-3. We will release all code and data upon acceptance",
    "checked": true,
    "id": "1cdcf5f527a887cb935eaf2a0109b40d2fc90fdb",
    "semantic_title": "conditional set generation using seq2seq models",
    "citation_count": 3,
    "authors": [
      "Aman Madaan",
      "Dheeraj Rajagopal",
      "Niket Tandon",
      "Yiming Yang",
      "Antoine Bosselut"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.325": {
    "title": "Analyzing and Evaluating Faithfulness in Dialogue Summarization",
    "volume": "main",
    "abstract": "Dialogue summarization is abstractive in nature, making it suffer from factual errors. The factual correctness of summaries has the highest priority before practical applications. Many efforts have been made to improve faithfulness in text summarization. However, there is a lack of systematic study on dialogue summarization systems. In this work, we first perform the fine-grained human analysis on the faithfulness of dialogue summaries and observe that over 35% of generated summaries are faithfully inconsistent respective the source dialogues. Furthermore, we present a new model-level faithfulness evaluation method. It examines generation models with multi-choice questions created by rule-based transformations. Experimental results show that our evaluation schema is a strong proxy for the factual correctness of summarization models. The human-annotated faithfulness samples and the evaluation toolkit are released to facilitate future research toward faithful dialogue summarization",
    "checked": true,
    "id": "3eda2fc2dbae1d6255c54667df3e63ff39621c2d",
    "semantic_title": "analyzing and evaluating faithfulness in dialogue summarization",
    "citation_count": 8,
    "authors": [
      "Bin Wang",
      "Chen Zhang",
      "Yan Zhang",
      "Yiming Chen",
      "Haizhou Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.326": {
    "title": "Twist Decoding: Diverse Generators Guide Each Other",
    "volume": "main",
    "abstract": "Many language generation models are now available for a wide range of generation tasks, including machine translation and summarization. Combining such diverse models may lead to further progress, but ensembling generation models is challenging during inference: conventional ensembling methods (e.g., shallow fusion) require that the models share vocabulary/tokenization schemes. We introduce Twist decoding, a simple and general text generation algorithm that benefits from diverse models at inference time. Our method does not assume the vocabulary, tokenization or even generation order is shared. Our extensive evaluations on machine translation and scientific paper summarization demonstrate that Twist decoding substantially outperforms each model decoded in isolation over various scenarios, including cases where domain-specific and general-purpose models are both available. Twist decoding also consistently outperforms the popular reranking heuristic where output candidates from one model are rescored by another. We hope that our work will encourage researchers and practitioners to examine generation models collectively, not just independently, and to seek out models with complementary strengths to the currently available models",
    "checked": true,
    "id": "ded0cd920c145ca0ae68acf306d54926cad5388c",
    "semantic_title": "twist decoding: diverse generators guide each other",
    "citation_count": 2,
    "authors": [
      "Jungo Kasai",
      "Keisuke Sakaguchi",
      "Ronan Le Bras",
      "Hao Peng",
      "Ximing Lu",
      "Dragomir Radev",
      "Yejin Choi",
      "Noah A. Smith"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.327": {
    "title": "Exploring Representation-level Augmentation for Code Search",
    "volume": "main",
    "abstract": "Code search, which aims at retrieving the most relevant code fragment for a given natural language query, is a common activity in software development practice. Recently, contrastive learning is widely used in code search research, where many data augmentation approaches for source code (e.g., semantic-preserving program transformation) are proposed to learn better representations. However, these augmentations are at the raw-data level, which requires additional code analysis in the preprocessing stage and additional training cost in the training stage. In this paper, we explore augmentation methods that augment data (both code and query) at representation level which does not require additional data processing and training, and based on this we propose a general format of representation-level augmentation that unifies existing methods. Then, we propose three new augmentation methods (linear extrapolation, binary interpolation, and Gaussian scaling) based on the general format. Furthermore, we theoretically analyze the advantages of the proposed augmentation methods over traditional contrastive learning methods on code search. We experimentally evaluate the proposed representation-level augmentation methods with state-of-the-art code search models on a large-scale public dataset consisting of six programming languages. The experimental results show that our approach can consistently boost the performance of the studied code search models",
    "checked": true,
    "id": "d1d8660ef2e5e608e25d0a484d70e3497fc5c051",
    "semantic_title": "exploring representation-level augmentation for code search",
    "citation_count": 7,
    "authors": [
      "Haochen Li",
      "Chunyan Miao",
      "Cyril Leung",
      "Yanxian Huang",
      "Yuan Huang",
      "Hongyu Zhang",
      "Yanlin Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.328": {
    "title": "Learning Semantic Textual Similarity via Topic-informed Discrete Latent Variables",
    "volume": "main",
    "abstract": "Recently, discrete latent variable models have received a surge of interest in both Natural Language Processing (NLP) and Computer Vision (CV), attributed to their comparable performance to the continuous counterparts in representation learning, while being more interpretable in their predictions. In this paper, we develop a topic-informed discrete latent variable model for semantic textual similarity, which learns a shared latent space for sentence-pair representation via vector quantization. Compared with previous models limited to local semantic contexts, our model can explore richer semantic information via topic modeling. We further boost the performance of semantic similarity by injecting the quantized representation into a transformer-based language model with a well-designed semantic-driven attention mechanism. We demonstrate, through extensive experiments across various English language datasets, that our model is able to surpass several strong neural baselines in semantic textual similarity tasks",
    "checked": true,
    "id": "5b8f1450584332cb81638b5823d48f3b632af511",
    "semantic_title": "learning semantic textual similarity via topic-informed discrete latent variables",
    "citation_count": 3,
    "authors": [
      "Erxin Yu",
      "Lan Du",
      "Yuan Jin",
      "Zhepei Wei",
      "Yi Chang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.329": {
    "title": "STRUDEL: Structured Dialogue Summarization for Dialogue Comprehension",
    "volume": "main",
    "abstract": "Abstractive dialogue summarization has long been viewed as an important standalone task in natural language processing, but no previous work has explored the possibility of whether abstractive dialogue summarization can also be used as a means to boost an NLP system's performance on other important dialogue comprehension tasks. In this paper, we propose a novel type of dialogue summarization task - STRUctured DiaLoguE Summarization (STRUDEL) - that can help pre-trained language models to better understand dialogues and improve their performance on important dialogue comprehension tasks. In contrast to the holistic approach taken by the traditional free-form abstractive summarization task for dialogues, STRUDEL aims to decompose and imitate the hierarchical, systematic and structured mental process that we human beings usually go through when understanding and analyzing dialogues, and thus has the advantage of being more focused, specific and instructive for dialogue comprehension models to learn from. We further introduce a new STRUDEL dialogue comprehension modeling framework that integrates STRUDEL into a dialogue reasoning module over transformer encoder language models to improve their dialogue comprehension ability. In our empirical experiments on two important downstream dialogue comprehension tasks - dialogue question answering and dialogue response prediction - we demonstrate that our STRUDEL dialogue comprehension models can significantly improve the dialogue comprehension performance of transformer encoder language models",
    "checked": true,
    "id": "0c003db762ad6edcdbabf178ae4e6776eb08a56e",
    "semantic_title": "strudel: structured dialogue summarization for dialogue comprehension",
    "citation_count": 1,
    "authors": [
      "Borui Wang",
      "Chengcheng Feng",
      "Arjun Nair",
      "Madelyn Mao",
      "Jai Desai",
      "Asli Celikyilmaz",
      "Haoran Li",
      "Yashar Mehdad",
      "Dragomir Radev"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.330": {
    "title": "Competency-Aware Neural Machine Translation: Can Machine Translation Know its Own Translation Quality?",
    "volume": "main",
    "abstract": "Neural machine translation (NMT) is often criticized for failures that happenwithout awareness. The lack of competency awareness makes NMT untrustworthy. This is in sharp contrast to human translators who give feedback or conduct further investigations whenever they are in doubt about predictions. To fill this gap, we propose a novel competency-aware NMT by extending conventional NMT with a self-estimator, offering abilities to translate a source sentence and estimate its competency. The self-estimator encodes the information of the decoding procedure and then examines whether it can reconstruct the original semantics of the source sentence. Experimental results on four translation tasks demonstrate that the proposed method not only carries out translation tasks intact but also delivers outstanding performance on quality estimation. Without depending on any reference or annotated data typically required by state-of-the-art metric and quality estimation methods, our model yields an even higher correlation with human quality judgments than a variety of aforementioned methods, such as BLEURT, COMET, and BERTScore. Quantitative and qualitative analyses show better robustness of competency awareness in our model",
    "checked": true,
    "id": "b078fb61a0b0f0c394b950b9ba7e7c987dc728ac",
    "semantic_title": "competency-aware neural machine translation: can machine translation know its own translation quality?",
    "citation_count": 1,
    "authors": [
      "Pei Zhang",
      "Baosong Yang",
      "Hao-Ran Wei",
      "Dayiheng Liu",
      "Kai Fan",
      "Luo Si",
      "Jun Xie"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.331": {
    "title": "PASTA: Table-Operations Aware Fact Verification via Sentence-Table Cloze Pre-training",
    "volume": "main",
    "abstract": "Fact verification has attracted a lot of attention recently, e.g., in journalism, marketing, and policymaking, as misinformation and dis- information can sway one's opinion and affect one's actions. While fact-checking is a hard task in general, in many cases, false statements can be easily debunked based on analytics over tables with reliable information. Hence, table- based fact verification has recently emerged as an important and growing research area. Yet, progress has been limited due to the lack of datasets that can be used to pre-train language models (LMs) to be aware of common table operations, such as aggregating a column or comparing tuples. To bridge this gap, this paper introduces PASTA for table-based fact verification via pre-training with synthesized sentence–table cloze questions. In particular, we design six types of common sentence–table cloze tasks, including Filter, Aggregation, Superlative, Comparative, Ordinal, and Unique, based on which we synthesize a large corpus consisting of 1.2 million sentence–table pairs from WikiTables. PASTA uses a recent pre-trained LM, DeBERTaV3, and further pre- trains it on our corpus. Our experimental results show that PASTA achieves new state-of-the-art (SOTA) performance on two table-based fact verification datasets TabFact and SEM-TAB- FACTS. In particular, on the complex set of TabFact, which contains multiple operations, PASTA largely outperforms previous SOTA by 4.7% (85.6% vs. 80.9%), and the gap between PASTA and human performance on the small test set is narrowed to just 1.5% (90.6% vs. 92.1%)",
    "checked": true,
    "id": "5fefc28ae503c465b1801da2b457f5a2cb5bd51f",
    "semantic_title": "pasta: table-operations aware fact verification via sentence-table cloze pre-training",
    "citation_count": 23,
    "authors": [
      "Zihui Gu",
      "Ju Fan",
      "Nan Tang",
      "Preslav Nakov",
      "Xiaoman Zhao",
      "Xiaoyong Du"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.332": {
    "title": "Sentiment-Aware Word and Sentence Level Pre-training for Sentiment Analysis",
    "volume": "main",
    "abstract": "Most existing pre-trained language representation models (PLMs) are sub-optimal in sentiment analysis tasks, as they capture the sentiment information from word-level while under-considering sentence-level information. In this paper, we propose SentiWSP, a novel Sentiment-aware pre-trained language model with combined Word-level and Sentence-level Pre-training tasks. The word level pre-training task detects replaced sentiment words, via a generator-discriminator framework, to enhance the PLM's knowledge about sentiment words. The sentence level pre-training task further strengthens the discriminator via a contrastive learning framework, with similar sentences as negative samples, to encode sentiments in a sentence. Extensive experimental results show that SentiWSP achieves new state-of-the-art performance on various sentence-level and aspect-level sentiment classification benchmarks. We have made our code and model publicly available at https://github.com/XMUDM/SentiWSP",
    "checked": true,
    "id": "c324a27458d16fe408ff9f5fdeffc9710e30dd5a",
    "semantic_title": "sentiment-aware word and sentence level pre-training for sentiment analysis",
    "citation_count": 9,
    "authors": [
      "Shuai Fan",
      "Chen Lin",
      "Haonan Li",
      "Zhenghao Lin",
      "Jinsong Su",
      "Hang Zhang",
      "Yeyun Gong",
      "JIan Guo",
      "Nan Duan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.333": {
    "title": "Towards Multi-Modal Sarcasm Detection via Hierarchical Congruity Modeling with Knowledge Enhancement",
    "volume": "main",
    "abstract": "Sarcasm is a linguistic phenomenon indicating a discrepancy between literal meanings and implied intentions. Due to its sophisticated nature, it is usually difficult to be detected from the text itself. As a result, multi-modal sarcasm detection has received more and more attention in both academia and industries. However, most existing techniques only modeled the atomic-level inconsistencies between the text input and its accompanying image, ignoring more complex compositions for both modalities. Moreover, they neglected the rich information contained in external knowledge, e.g., image captions. In this paper, we propose a novel hierarchical framework for sarcasm detection by exploring both the atomic-level congruity based on multi-head cross attentions and the composition-level congruity based on graph neural networks, where a post with low congruity can be identified as sarcasm. In addition, we exploit the effect of various knowledge resources for sarcasm detection. Evaluation results on a public multi-modal sarcasm detection dataset based on Twitter demonstrate the superiority of our proposed model",
    "checked": true,
    "id": "10eabe1578e74b4fb33e53269177d78a6a02aa06",
    "semantic_title": "towards multi-modal sarcasm detection via hierarchical congruity modeling with knowledge enhancement",
    "citation_count": 24,
    "authors": [
      "Hui Liu",
      "Wenya Wang",
      "Haoliang Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.334": {
    "title": "Efficiently Tuned Parameters Are Task Embeddings",
    "volume": "main",
    "abstract": "Intermediate-task transfer can benefit a wide range of NLP tasks with properly selected source datasets. However, it is computationally infeasible to experiment with all intermediate transfer combinations, making choosing a useful source task a challenging problem. In this paper, we anticipate that task-specific parameters updated in parameter-efficient tuning methods are likely to encode task-specific information. Therefore, such parameters can be predictive for inter-task transferability. Thus, we propose to exploit these efficiently tuned parameters as off-the-shelf task embeddings for the efficient selection of source datasets for intermediate-task transfer. We experiment with 11 text classification tasks and 11 question answering tasks. Experimental results show that our approach consistently outperforms existing inter-task transferability prediction methods while being conceptually simple and computationally efficient. Our analysis also reveals that the ability of efficiently tuned parameters on transferability prediction is disentangled with their in-task performance. This allows us to use parameters from early checkpoints as task embeddings to further improve efficiency",
    "checked": true,
    "id": "49c02199de8a9caca038282f130bebaebe58ab3b",
    "semantic_title": "efficiently tuned parameters are task embeddings",
    "citation_count": 5,
    "authors": [
      "Wangchunshu Zhou",
      "Canwen Xu",
      "Julian McAuley"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.335": {
    "title": "COPEN: Probing Conceptual Knowledge in Pre-trained Language Models",
    "volume": "main",
    "abstract": "Conceptual knowledge is fundamental to human cognition and knowledge bases. However, existing knowledge probing works only focus on evaluating factual knowledge of pre-trained language models (PLMs) and ignore conceptual knowledge. Since conceptual knowledge often appears as implicit commonsense behind texts, designing probes for conceptual knowledge is hard. Inspired by knowledge representation schemata, we comprehensively evaluate conceptual knowledge of PLMs by designing three tasks to probe whether PLMs organize entities by conceptual similarities, learn conceptual properties, and conceptualize entities in contexts, respectively. For the tasks, we collect and annotate 24k data instances covering 393 concepts, which is COPEN, a COnceptual knowledge Probing bENchmark. Extensive experiments on different sizes and types of PLMs show that existing PLMs systematically lack conceptual knowledge and suffer from various spurious correlations. We believe this is a critical bottleneck for realizing human-like cognition in PLMs. COPEN and our codes are publicly released at https://github.com/THU-KEG/COPEN",
    "checked": true,
    "id": "bcec7d17e68aceb91d020dd796ece075694f77c6",
    "semantic_title": "copen: probing conceptual knowledge in pre-trained language models",
    "citation_count": 11,
    "authors": [
      "Hao Peng",
      "Xiaozhi Wang",
      "Shengding Hu",
      "Hailong Jin",
      "Lei Hou",
      "Juanzi Li",
      "Zhiyuan Liu",
      "Qun Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.336": {
    "title": "Capturing Global Structural Information in Long Document Question Answering with Compressive Graph Selector Network",
    "volume": "main",
    "abstract": "Long document question answering is a challenging task due to its demands for complex reasoning over long text. Previous works usually take long documents as non-structured flat texts or only consider the local structure in long documents. However, these methods usually ignore the global structure of the long document, which is essential for long-range understanding. To tackle this problem, we propose Compressive Graph Selector Network (CGSN) to capture the global structure in a compressive and iterative manner. The proposed model mainly focuses on the evidence selection phase of long document question answering. Specifically, it consists of three modules: local graph network, global graph network and evidence memory network. Firstly, the local graph network builds the graph structure of the chunked segment in token, sentence, paragraph and segment levels to capture the short-term dependency of the text. Secondly, the global graph network selectively receives the information of each level from the local graph, compresses them into the global graph nodes and applies graph attention to the global graph nodes to build the long-range reasoning over the entire text in an iterative way. Thirdly, the evidence memory network is designed to alleviate the redundancy problem in the evidence selection by saving the selected result in the previous steps. Extensive experiments show that the proposed model outperforms previous methods on two datasets",
    "checked": true,
    "id": "077f3c382d0dce221cf6aaef0e7185a249b71b9f",
    "semantic_title": "capturing global structural information in long document question answering with compressive graph selector network",
    "citation_count": 5,
    "authors": [
      "Yuxiang Nie",
      "Heyan Huang",
      "Wei Wei",
      "Xian-Ling Mao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.337": {
    "title": "Structural generalization is hard for sequence-to-sequence models",
    "volume": "main",
    "abstract": "Sequence-to-sequence (seq2seq) models have been successful across many NLP tasks,including ones that require predicting linguistic structure. However, recent work on compositional generalization has shown that seq2seq models achieve very low accuracy in generalizing to linguistic structures that were not seen in training. We present new evidence that this is a general limitation of seq2seq models that is present not just in semantic parsing, but also in syntactic parsing and in text-to-text tasks, and that this limitation can often be overcome by neurosymbolic models that have linguistic knowledge built in. We further report on some experiments that give initial answers on the reasons for these limitations",
    "checked": true,
    "id": "dbe286676d094ca588312cbfc8f699a9a2ca1cc9",
    "semantic_title": "structural generalization is hard for sequence-to-sequence models",
    "citation_count": 11,
    "authors": [
      "Yuekun Yao",
      "Alexander Koller"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.338": {
    "title": "Contrastive Learning enhanced Author-Style Headline Generation",
    "volume": "main",
    "abstract": "Headline generation is a task of generating an appropriate headline for a given article, which can be further used for machine-aided writing or enhancing the click-through ratio. Current works only use the article itself in the generation, but have not taken the writing style of headlines into consideration. In this paper, we propose a novel Seq2Seq model called CLH3G (Contrastive Learning enhanced Historical Headlines based Headline Generation) which can use the historical headlines of the articles that the author wrote in the past to improve the headline generation of current articles. By taking historical headlines into account, we can integrate the stylistic features of the author into our model, and generate a headline not only appropriate for the article, but also consistent with the author's style. In order to efficiently learn the stylistic features of the author, we further introduce a contrastive learning based auxiliary task for the encoder of our model. Besides, we propose two methods to use the learned stylistic features to guide both the pointer and the decoder during the generation. Experimental results show that historical headlines of the same user can improve the headline generation significantly, and both the contrastive learning module and the two style features fusion methods can further boost the performance",
    "checked": true,
    "id": "2f233ddc5d6869b3d9868826d319d415463321f1",
    "semantic_title": "contrastive learning enhanced author-style headline generation",
    "citation_count": 1,
    "authors": [
      "Hui Liu",
      "Weidong Guo",
      "Yige Chen",
      "Xiangyang Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.339": {
    "title": "Multi-Granularity Optimization for Non-Autoregressive Translation",
    "volume": "main",
    "abstract": "Despite low latency, non-autoregressive machine translation (NAT) suffers severe performance deterioration due to the naive independence assumption. This assumption is further strengthened by cross-entropy loss, which encourages a strict match between the hypothesis and the reference token by token. To alleviate this issue, we propose multi-granularity optimization for NAT, which collects model behaviours on translation segments of various granularities and integrates feedback for backpropagation. Experiments on four WMT benchmarks show that the proposed method significantly outperforms the baseline models trained with cross-entropy loss, and achieves the best performance on WMT'16 En⇔Ro and highly competitive results on WMT'14 En⇔De for fully non-autoregressive translation",
    "checked": true,
    "id": "71bb0d7b5faa7c6cbcad4de8ebc4af215329f2b3",
    "semantic_title": "multi-granularity optimization for non-autoregressive translation",
    "citation_count": 4,
    "authors": [
      "Yafu Li",
      "Leyang Cui",
      "Yongjing Yin",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.340": {
    "title": "Super-NaturalInstructions: Generalization via Declarative Instructions on 1600+ NLP Tasks",
    "volume": "main",
    "abstract": "How well can NLP models generalize to a variety of unseen tasks when provided with task instructions? To address this question, we first introduce Super-NaturalInstructions, a benchmark of 1,616 diverse NLP tasks and their expert-written instructions. Our collection covers 76 distinct task types, including but not limited to classification, extraction, infilling, sequence tagging, text rewriting, and text composition. This large and diverse collection of tasks enables rigorous benchmarking of cross-task generalization under instructions—training models to follow instructions on a subset of tasks and evaluating them on the remaining unseen ones. Furthermore, we build Tk-Instruct, a transformer model trained to follow a variety of in-context instructions (plain language task definitions or k-shot examples). Our experiments show that Tk-Instruct outperforms existing instruction-following models such as InstructGPT by over 9% on our benchmark despite being an order of magnitude smaller. We further analyze generalization as a function of various scaling parameters, such as the number of observed tasks, the number of instances per task, and model sizes. We hope our dataset and model facilitate future progress towards more general-purpose NLP models",
    "checked": true,
    "id": "06d7cb8c8816360feb33c3367073e0ef66d7d0b0",
    "semantic_title": "super-naturalinstructions: generalization via declarative instructions on 1600+ nlp tasks",
    "citation_count": 427,
    "authors": [
      "Yizhong Wang",
      "Swaroop Mishra",
      "Pegah Alipoormolabashi",
      "Yeganeh Kordi",
      "Amirreza Mirzaei",
      "Atharva Naik",
      "Arjun Ashok",
      "Arut Selvan Dhanasekaran",
      "Anjana Arunkumar",
      "David Stap",
      "Eshaan Pathak",
      "Giannis Karamanolakis",
      "Haizhi Lai",
      "Ishan Purohit",
      "Ishani Mondal",
      "Jacob Anderson",
      "Kirby Kuznia",
      "Krima Doshi",
      "Kuntal Kumar Pal",
      "Maitreya Patel",
      "Mehrad Moradshahi",
      "Mihir Parmar",
      "Mirali Purohit",
      "Neeraj Varshney",
      "Phani Rohitha Kaza",
      "Pulkit Verma",
      "Ravsehaj Singh Puri",
      "Rushang Karia",
      "Savan Doshi",
      "Shailaja Keyur Sampat",
      "Siddhartha Mishra",
      "Sujan Reddy A",
      "Sumanta Patro",
      "Tanay Dixit",
      "Xudong Shen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.341": {
    "title": "MetaFill: Text Infilling for Meta-Path Generation on Heterogeneous Information Networks",
    "volume": "main",
    "abstract": "Heterogeneous information network (HIN) is essential to study complicated networks containing multiple edge types and node types. Meta-path, a sequence of node types and edge types, is the core technique to embed HINs. Since manually curating meta-paths is time-consuming, there is a pressing need to develop automated meta-path generation approaches. Existing meta-path generation approaches cannot fully exploit the rich textual information in HINs, such as node names and edge type names. To address this problem, we propose MetaFill, a text-infilling-based approach for meta-path generation. The key idea of MetaFill is to formulate meta-path identification problem as a word sequence infilling problem, which can be advanced by pretrained language models (PLMs). We observed the superior performance of MetaFill against existing meta-path generation methods and graph embedding methods that do not leverage meta-paths in both link prediction and node classification on two real-world HIN datasets. We further demonstrated how MetaFill can accurately classify edges in the zero-shot setting, where existing approaches cannot generate any meta-paths. MetaFill exploits PLMs to generate meta-paths for graph embedding, opening up new avenues for language model applications in graph analysis",
    "checked": true,
    "id": "f2dadc182d33f3ad74f95505e5b6611c3abafe02",
    "semantic_title": "metafill: text infilling for meta-path generation on heterogeneous information networks",
    "citation_count": 0,
    "authors": [
      "Zequn Liu",
      "Kefei Duan",
      "Junwei Yang",
      "Hanwen Xu",
      "Ming Zhang",
      "Sheng Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.342": {
    "title": "DRLK: Dynamic Hierarchical Reasoning with Language Model and Knowledge Graph for Question Answering",
    "volume": "main",
    "abstract": "In recent years, Graph Neural Network (GNN) approaches with enhanced knowledge graphs (KG) perform well in question answering (QA) tasks. One critical challenge is how to effectively utilize interactions between the QA context and KG. However, existing work only adopts the identical QA context representation to interact with multiple layers of KG, which results in a restricted interaction. In this paper, we propose DRLK (Dynamic Hierarchical Reasoning with Language Model and Knowledge Graphs), a novel model that utilizes dynamic hierarchical interactions between the QA context and KG for reasoning. DRLK extracts dynamic hierarchical features in the QA context, and performs inter-layer and intra-layer interactions on each iteration, allowing the KG representation to be grounded with the hierarchical features of the QA context. We conduct extensive experiments on four benchmark datasets in medical QA and commonsense reasoning. The experimental results demonstrate that DRLK achieves state-of-the-art performances on two benchmark datasets and performs competitively on the others",
    "checked": true,
    "id": "5c564ee4fa8049b4623a4253c414d0692ecfa400",
    "semantic_title": "drlk: dynamic hierarchical reasoning with language model and knowledge graph for question answering",
    "citation_count": 5,
    "authors": [
      "Miao Zhang",
      "Rufeng Dai",
      "Ming Dong",
      "Tingting He"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.343": {
    "title": "AEG: Argumentative Essay Generation via A Dual-Decoder Model with Content Planning",
    "volume": "main",
    "abstract": "Argument generation is an important but challenging task in computational argumentation. Existing studies have mainly focused on generating individual short arguments, while research on generating long and coherent argumentative essays is still under-explored. In this paper, we propose a new task, Argumentative Essay Generation (AEG).Given a writing prompt, the goal of AEG is to automatically generate an argumentative essay with strong persuasiveness. We construct a large-scale dataset, ArgEssay, for this new task and establish a strong model based on a dual-decoder Transformer architecture. Our proposed model contains two decoders, a planning decoder (PD) and a writing decoder (WD), where PD is used to generate a sequence for essay content planning and WD incorporates the planning information to write an essay. Further, we pre-train this model on a large news dataset to enhance the plan-and-write paradigm. Automatic and human evaluation results show that our model can generate more coherent and persuasive essays with higher diversity and less repetition compared to several baselines",
    "checked": true,
    "id": "31ef19b68770966f9bb799ad5d024c70f815ce9f",
    "semantic_title": "aeg: argumentative essay generation via a dual-decoder model with content planning",
    "citation_count": 1,
    "authors": [
      "Jianzhu Bao",
      "Yasheng Wang",
      "Yitong Li",
      "Fei Mi",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.344": {
    "title": "BotsTalk: Machine-sourced Framework for Automatic Curation of Large-scale Multi-skill Dialogue Datasets",
    "volume": "main",
    "abstract": "To build open-domain chatbots that are able to use diverse communicative skills, we propose a novel framework BotsTalk, where multiple agents grounded to the specific target skills participate in a conversation to automatically annotate multi-skill dialogues. We further present Blended Skill BotsTalk (BSBT), a large-scale multi-skill dialogue dataset comprising 300K conversations. Through extensive experiments, we demonstrate that our dataset can be effective for multi-skill dialogue systems which require an understanding of skill blending as well as skill grounding. Our code and data are available at https://github.com/convei-lab/BotsTalk",
    "checked": true,
    "id": "dba29a38290ff3dfbb8646ac976e48506a5f5101",
    "semantic_title": "botstalk: machine-sourced framework for automatic curation of large-scale multi-skill dialogue datasets",
    "citation_count": 8,
    "authors": [
      "Minju Kim",
      "Chaehyeong Kim",
      "Yong Ho Song",
      "Seung-won Hwang",
      "Jinyoung Yeo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.345": {
    "title": "Wider & Closer: Mixture of Short-channel Distillers for Zero-shot Cross-lingual Named Entity Recognition",
    "volume": "main",
    "abstract": "Zero-shot cross-lingual named entity recognition (NER) aims at transferring knowledge from annotated and rich-resource data in source languages to unlabeled and lean-resource data in target languages. Existing mainstream methods based on the teacher-student distillation framework ignore the rich and complementary information lying in the intermediate layers of pre-trained language models, and domain-invariant information is easily lost during transfer. In this study, a mixture of short-channel distillers (MSD) method is proposed to fully interact the rich hierarchical information in the teacher model and to transfer knowledge to the student model sufficiently and efficiently. Concretely, a multi-channel distillation framework is designed for sufficient information transfer by aggregating multiple distillers as a mixture. Besides, an unsupervised method adopting parallel domain adaptation is proposed to shorten the channels between the teacher and student models to preserve domain-invariant features. Experiments on four datasets across nine languages demonstrate that the proposed method achieves new state-of-the-art performance on zero-shot cross-lingual NER and shows great generalization and compatibility across languages and fields",
    "checked": true,
    "id": "39cc5896ca3f8f7ce77721a6b4c04ecc86149100",
    "semantic_title": "wider & closer: mixture of short-channel distillers for zero-shot cross-lingual named entity recognition",
    "citation_count": 5,
    "authors": [
      "Jun-Yu Ma",
      "Beiduo Chen",
      "Jia-Chen Gu",
      "Zhenhua Ling",
      "Wu Guo",
      "Quan Liu",
      "Zhigang Chen",
      "Cong Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.346": {
    "title": "An Efficient Memory-Augmented Transformer for Knowledge-Intensive NLP Tasks",
    "volume": "main",
    "abstract": "Access to external knowledge is essential for many natural language processing tasks, such as question answering and dialogue. Existing methods often rely on a parametric model that stores knowledge in its parameters, or use a retrieval-augmented model that has access to an external knowledge source. Parametric and retrieval-augmented models have complementary strengths in terms of computational efficiency and predictive accuracy. To combine the strength of both approaches, we propose the Efficient Memory-Augmented Transformer (EMAT) – it encodes external knowledge into a key-value memory and exploits the fast maximum inner product search for memory querying. We also introduce pre-training tasks that allow EMAT to encode informative key-value representations, and to learn an implicit strategy to integrate multiple memory slots into the transformer. Experiments on various knowledge-intensive tasks such as question answering and dialogue datasets show that, simply augmenting parametric models (T5-base) using our method produces more accurate results (e.g., 25.8 → 44.3 EM on NQ) while retaining a high throughput (e.g., 1000 queries/s on NQ). Compared to retrieval-augmented models, EMAT runs substantially faster across the board and produces more accurate results on WoW and ELI5",
    "checked": true,
    "id": "f7fd184eaa573205dff97d86c836f3038143e87a",
    "semantic_title": "an efficient memory-augmented transformer for knowledge-intensive nlp tasks",
    "citation_count": 24,
    "authors": [
      "Yuxiang Wu",
      "Yu Zhao",
      "Baotian Hu",
      "Pasquale Minervini",
      "Pontus Stenetorp",
      "Sebastian Riedel"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.347": {
    "title": "Supervised Prototypical Contrastive Learning for Emotion Recognition in Conversation",
    "volume": "main",
    "abstract": "Capturing emotions within a conversation plays an essential role in modern dialogue systems. However, the weak correlation between emotions and semantics brings many challenges to emotion recognition in conversation (ERC). Even semantically similar utterances, the emotion may vary drastically depending on contexts or speakers. In this paper, we propose a Supervised Prototypical Contrastive Learning (SPCL) loss for the ERC task. Leveraging the Prototypical Network, the SPCL targets at solving the imbalanced classification problem through contrastive learning and does not require a large batch size. Meanwhile, we design a difficulty measure function based on the distance between classes and introduce curriculum learning to alleviate the impact of extreme samples. We achieve state-of-the-art results on three widely used benchmarks. Further, we conduct analytical experiments to demonstrate the effectiveness of our proposed SPCL and curriculum learning strategy",
    "checked": true,
    "id": "23e59e22a4e028a519da1c44b5c9f16a41c187da",
    "semantic_title": "supervised prototypical contrastive learning for emotion recognition in conversation",
    "citation_count": 33,
    "authors": [
      "Xiaohui Song",
      "Longtao Huang",
      "Hui Xue",
      "Songlin Hu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.348": {
    "title": "RuCoLA: Russian Corpus of Linguistic Acceptability",
    "volume": "main",
    "abstract": "Linguistic acceptability (LA) attracts the attention of the research community due to its many uses, such as testing the grammatical knowledge of language models and filtering implausible texts with acceptability classifiers. However, the application scope of LA in languages other than English is limited due to the lack of high-quality resources. To this end, we introduce the Russian Corpus of Linguistic Acceptability (RuCoLA), built from the ground up under the well-established binary LA approach. RuCoLA consists of 9.8k in-domain sentences from linguistic publications and 3.6k out-of-domain sentences produced by generative models. The out-of-domain set is created to facilitate the practical use of acceptability for improving language generation. Our paper describes the data collection protocol and presents a fine-grained analysis of acceptability classification experiments with a range of baseline approaches. In particular, we demonstrate that the most widely used language models still fall behind humans by a large margin, especially when detecting morphological and semantic errors. We release RuCoLA, the code of experiments, and a public leaderboard to assess the linguistic competence of language models for Russian",
    "checked": true,
    "id": "7c5ee8a1d360429dccf923c3e69bae1347c0106a",
    "semantic_title": "rucola: russian corpus of linguistic acceptability",
    "citation_count": 13,
    "authors": [
      "Vladislav Mikhailov",
      "Tatiana Shamardina",
      "Max Ryabinin",
      "Alena Pestova",
      "Ivan Smurov",
      "Ekaterina Artemova"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.349": {
    "title": "Complex Hyperbolic Knowledge Graph Embeddings with Fast Fourier Transform",
    "volume": "main",
    "abstract": "The choice of geometric space for knowledge graph (KG) embeddings can have significant effects on the performance of KG completion tasks. The hyperbolic geometry has been shown to capture the hierarchical patterns due to its tree-like metrics, which addressed the limitations of the Euclidean embedding models. Recent explorations of the complex hyperbolic geometry further improved the hyperbolic embeddings for capturing a variety of hierarchical structures. However, the performance of the hyperbolic KG embedding models for non-transitive relations is still unpromising, while the complex hyperbolic embeddings do not deal with multi-relations. This paper aims to utilize the representation capacity of the complex hyperbolic geometry in multi-relational KG embeddings. To apply the geometric transformations which account for different relations and the attention mechanism in the complex hyperbolic space, we propose to use the fast Fourier transform (FFT) as the conversion between the real and complex hyperbolic space. Constructing the attention-based transformations in the complex space is very challenging, while the proposed Fourier transform-based complex hyperbolic approaches provide a simple and effective solution. Experimental results show that our methods outperform the baselines, including the Euclidean and the real hyperbolic embedding models",
    "checked": true,
    "id": "8bca1f851579df9a309102063fee3bae2486d4c0",
    "semantic_title": "complex hyperbolic knowledge graph embeddings with fast fourier transform",
    "citation_count": 4,
    "authors": [
      "Huiru Xiao",
      "Xin Liu",
      "Yangqiu Song",
      "Ginny Wong",
      "Simon See"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.350": {
    "title": "Towards Knowledge-Intensive Text-to-SQL Semantic Parsing with Formulaic Knowledge",
    "volume": "main",
    "abstract": "In this paper, we study the problem of knowledge-intensive text-to-SQL, in which domain knowledge is necessary to parse expert questions into SQL queries over domain-specific tables. We formalize this scenario by building a new benchmark KnowSQL consisting of domain-specific questions covering various domains. We then address this problem by representing formulaic knowledge rather than by annotating additional data examples. More concretely, we construct a formulaic knowledge bank as a domain knowledge base and propose a framework (ReGrouP) to leverage this formulaic knowledge during parsing. Experiments using ReGrouP demonstrate a significant 28.2% improvement overall on KnowSQL",
    "checked": true,
    "id": "b7b4398a6c1d600e9747a0b9e2625c3b5c3dfff8",
    "semantic_title": "towards knowledge-intensive text-to-sql semantic parsing with formulaic knowledge",
    "citation_count": 6,
    "authors": [
      "Longxu Dou",
      "Yan Gao",
      "Xuqi Liu",
      "Mingyang Pan",
      "Dingzirui Wang",
      "Wanxiang Che",
      "Dechen Zhan",
      "Min-Yen Kan",
      "Jian-Guang Lou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.351": {
    "title": "Should We Ban English NLP for a Year?",
    "volume": "main",
    "abstract": "Around two thirds of NLP research at top venues is devoted exclusively to developing technology for speakers of English, most speech data comes from young urban speakers, and most texts used to train language models come from male writers. These biases feed into consumer technologies to widen existing inequality gaps, not only within, but also across, societies. Many have argued that it is almost impossible to mitigate inequality amplification. I argue that, on the contrary, it is quite simple to do so, and that counter-measures would have little-to-no negative impact, except for, perhaps, in the very short term",
    "checked": true,
    "id": "ef83d6be27632b2657a59145e65397f5702ed0d8",
    "semantic_title": "should we ban english nlp for a year?",
    "citation_count": 13,
    "authors": [
      "Anders Søgaard"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.352": {
    "title": "LittleBird: Efficient Faster & Longer Transformer for Question Answering",
    "volume": "main",
    "abstract": "BERT has shown a lot of sucess in a wide variety of NLP tasks. But it has a limitation dealing with long inputs due to its attention mechanism. Longformer, ETC and BigBird addressed this issue and effectively solved the quadratic dependency problem. However we find that these models are not sufficient, and propose LittleBird, a novel model based on BigBird with improved speed and memory footprint while maintaining accuracy. In particular, we devise a more flexible and efficient position representation method based on Attention with Linear Biases(ALiBi). We also show that replacing the method of global information represented in the BigBird with pack and unpack attention is more effective. The proposed model can work on long inputs even after being pre-trained on short inputs, and can be trained efficiently reusing existing pre-trained language model for short inputs. This is a significant benefit for low-resource languages where large amounts of long text data are difficult to obtain. As a result, our experiments show that LittleBird works very well in a variety of languages, achieving high performance in question answering tasks, particularly in KorQuAD2.0, Korean Question Answering Dataset for long paragraphs",
    "checked": true,
    "id": "bccbd500f2f8af6bdfb5ef3cf77c2b99d088ee4c",
    "semantic_title": "littlebird: efficient faster & longer transformer for question answering",
    "citation_count": 3,
    "authors": [
      "Minchul Lee",
      "Kijong Han",
      "Myeong Cheol Shin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.353": {
    "title": "WeTS: A Benchmark for Translation Suggestion",
    "volume": "main",
    "abstract": "Translation suggestion (TS), which provides alternatives for specific words or phrases given the entire documents generated by machine translation (MT), has been proven to play a significant role in post-editing (PE). There are two main pitfalls for existing researches in this line. First, most conventional works only focus on the overall performance of PE but ignore the exact performance of TS, which makes the progress of PE sluggish and less explainable; Second, as no publicly available golden dataset exists to support in-depth research for TS, almost all of the previous works conduct experiments on their in-house datasets or the noisy datasets built automatically, which makes their experiments hard to be reproduced and compared. To break these limitations mentioned above and spur the research in TS, we create a benchmark dataset, called WeTS, which is a golden corpus annotated by expert translators on four translation directions. Apart from the golden corpus, we also propose several methods to generate synthetic corpora which can be used to improve the performance substantially through pre-training. As for the model, we propose the segment-aware self-attention based Transformer for TS. Experimental results show that our approach achieves the best results on all four directions, including English-to-German, German-to-English, Chinese-to-English, and English-to-Chinese",
    "checked": true,
    "id": "e88243bbf0494313556410e7f03058c95f2ddbe2",
    "semantic_title": "wets: a benchmark for translation suggestion",
    "citation_count": 10,
    "authors": [
      "Zhen Yang",
      "Fandong Meng",
      "Yingxue Zhang",
      "Ernan Li",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.354": {
    "title": "Discrete Cross-Modal Alignment Enables Zero-Shot Speech Translation",
    "volume": "main",
    "abstract": "End-to-end Speech Translation (ST) aims at translating the source language speech into target language text without generating the intermediate transcriptions. However, the training of end-to-end methods relies on parallel ST data, which are difficult and expensive to obtain. Fortunately, the supervised data for automatic speech recognition (ASR) and machine translation (MT) are usually more accessible, making zero-shot speech translation a potential direction. Existing zero-shot methods fail to align the two modalities of speech and text into a shared semantic space, resulting in much worse performance compared to the supervised ST methods. In order to enable zero-shot ST, we propose a novel Discrete Cross-Modal Alignment (DCMA) method that employs a shared discrete vocabulary space to accommodate and match both modalities of speech and text. Specifically, we introduce a vector quantization module to discretize the continuous representations of speech and text into a finite set of virtual tokens, and use ASR data to map corresponding speech and text to the same virtual token in a shared codebook. This way, source language speech can be embedded in the same semantic space as the source language text, which can be then transformed into target language text with an MT module. Experiments on multiple language pairs demonstrate that our zero-shot ST method significantly improves the SOTA, and even performers on par with the strong supervised ST baselines",
    "checked": true,
    "id": "8abd7cd18b2d7ca06fd0a15393c8bc87490a03fa",
    "semantic_title": "discrete cross-modal alignment enables zero-shot speech translation",
    "citation_count": 5,
    "authors": [
      "Chen Wang",
      "Yuchen Liu",
      "Boxing Chen",
      "Jiajun Zhang",
      "Wei Luo",
      "Zhongqiang Huang",
      "Chengqing Zong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.355": {
    "title": "Abstractive Summarization Guided by Latent Hierarchical Document Structure",
    "volume": "main",
    "abstract": "Sequential abstractive neural summarizers often do not use the underlying structure in the input article or dependencies between the input sentences. This structure is essential to integrate and consolidate information from different parts of the text. To address this shortcoming, we propose a hierarchy-aware graph neural network (HierGNN) which captures such dependencies through three main steps: 1) learning a hierarchical document structure through a latent structure tree learned by a sparse matrix-tree computation; 2) propagating sentence information over this structure using a novel message-passing node propagation mechanism to identify salient information; 3) using graph-level attention to concentrate the decoder on salient information. Experiments confirm HierGNN improves strong sequence models such as BART, with a 0.55 and 0.75 margin in average ROUGE-1/2/L for CNN/DM and XSum. Further human evaluation demonstrates that summaries produced by our model are more relevant and less redundant than the baselines, into which HierGNN is incorporated. We also find HierGNN synthesizes summaries by fusing multiple source sentences more, rather than compressing a single source sentence, and that it processes long inputs more effectively",
    "checked": true,
    "id": "65cd44ea9086fd33c1916f94cb6eb34da66e8cf2",
    "semantic_title": "abstractive summarization guided by latent hierarchical document structure",
    "citation_count": 3,
    "authors": [
      "Yifu Qiu",
      "Shay B. Cohen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.356": {
    "title": "Explainable Question Answering based on Semantic Graph by Global Differentiable Learning and Dynamic Adaptive Reasoning",
    "volume": "main",
    "abstract": "Multi-hop Question Answering is an agent task for testing the reasoning ability. With the development of pre-trained models, the implicit reasoning ability has been surprisingly improved and can even surpass human performance. However, the nature of the black box hinders the construction of explainable intelligent systems. Several researchers have explored explainable neural-symbolic reasoning methods based on question decomposition techniques. The undifferentiable symbolic operations and the error propagation in the reasoning process lead to poor performance. To alleviate it, we propose a simple yet effective Global Differentiable Learning strategy to explore optimal reasoning paths from the latent probability space so that the model learns to solve intermediate reasoning processes without expert annotations. We further design a Dynamic Adaptive Reasoner to enhance the generalization of unseen questions. Our method achieves 17% improvements in F1-score against BreakRC and shows better interpretability. We take a step forward in building interpretable reasoning methods",
    "checked": true,
    "id": "1e60182efd72793d264ba7f6cc8a579f8a11f8ac",
    "semantic_title": "explainable question answering based on semantic graph by global differentiable learning and dynamic adaptive reasoning",
    "citation_count": 0,
    "authors": [
      "Jianguo Mao",
      "Wenbin Jiang",
      "Xiangdong Wang",
      "Hong Liu",
      "Yu Xia",
      "Yajuan Lyu",
      "QiaoQiao She"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.357": {
    "title": "DuReader-Retrieval: A Large-scale Chinese Benchmark for Passage Retrieval from Web Search Engine",
    "volume": "main",
    "abstract": "In this paper, we present DuReader-retrieval, a large-scale Chinese dataset for passage retrieval. DuReader-retrieval contains more than 90K queries and over 8M unique passages from a commercial search engine. To alleviate the shortcomings of other datasets and ensure the quality of our benchmark, we (1) reduce the false negatives in development and test sets by manually annotating results pooled from multiple retrievers, and (2) remove the training queries that are semantically similar to the development and testing queries. Additionally, we provide two out-of-domain testing sets for cross-domain evaluation, as well as a set of human translated queries for for cross-lingual retrieval evaluation. The experiments demonstrate that DuReader-retrieval is challenging and a number of problems remain unsolved, such as the salient phrase mismatch and the syntactic mismatch between queries and paragraphs. These experiments also show that dense retrievers do not generalize well across domains, and cross-lingual retrieval is essentially challenging. DuReader-retrieval is publicly available at https://github.com/baidu/DuReader/tree/master/DuReader-Retrieval",
    "checked": true,
    "id": "7a54248d35448e1c95743373ddbb9170ad7c039a",
    "semantic_title": "dureader-retrieval: a large-scale chinese benchmark for passage retrieval from web search engine",
    "citation_count": 8,
    "authors": [
      "Yifu Qiu",
      "Hongyu Li",
      "Yingqi Qu",
      "Ying Chen",
      "QiaoQiao She",
      "Jing Liu",
      "Hua Wu",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.358": {
    "title": "Pair-Based Joint Encoding with Relational Graph Convolutional Networks for Emotion-Cause Pair Extraction",
    "volume": "main",
    "abstract": "Emotion-cause pair extraction (ECPE) aims to extract emotion clauses and corresponding cause clauses, which have recently received growing attention. Previous methods sequentially encode features with a specified order. They first encode the emotion and cause features for clause extraction and then combine them for pair extraction. This lead to an imbalance in inter-task feature interaction where features extracted later have no direct contact with the former. To address this issue, we propose a novel **P**air-**B**ased **J**oint **E**ncoding (**PBJE**) network, which generates pairs and clauses features simultaneously in a joint feature encoding manner to model the causal relationship in clauses. PBJE can balance the information flow among emotion clauses, cause clauses and pairs. From a multi-relational perspective, we construct a heterogeneous undirected graph and apply the Relational Graph Convolutional Network (RGCN) to capture the multiplex relationship between clauses and the relationship between pairs and clauses. Experimental results show that PBJE achieves state-of-the-art performance on the Chinese benchmark corpus",
    "checked": true,
    "id": "0433756d1a7eaf2201550a4584af6c5609e0453e",
    "semantic_title": "pair-based joint encoding with relational graph convolutional networks for emotion-cause pair extraction",
    "citation_count": 6,
    "authors": [
      "Junlong Liu",
      "Xichen Shang",
      "Qianli Ma"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.359": {
    "title": "Affective Knowledge Enhanced Multiple-Graph Fusion Networks for Aspect-based Sentiment Analysis",
    "volume": "main",
    "abstract": "Aspect-based sentiment analysis aims to identify sentiment polarity of social media users toward different aspects. Most recent methods adopt the aspect-centric latent tree to connect aspects and their corresponding opinion words, thinking that would facilitate establishing the relationship between aspects and opinion words. However, these methods ignore the roles of syntax dependency relation labels and affective semantic information in determining the sentiment polarity, resulting in the wrong prediction. In this paper, we propose a novel multi-graph fusion network (MGFN) based on latent graph to leverage the richer syntax dependency relation label information and affective semantic information of words. Specifically, we construct a novel syntax-aware latent graph (SaLG) to fully leverage the syntax dependency relation label information to facilitate the learning of sentiment representations. Subsequently, a multi-graph fusion module is proposed to fuse semantic information of surrounding contexts of aspects adaptively. Furthermore, we design an affective refinement strategy to guide the MGFN to capture significant affective clues. Extensive experiments on three datasets demonstrate that our MGFN model outperforms all state-of-the-art methods and verify the effectiveness of our model",
    "checked": true,
    "id": "4eb5d589107fc21dc60516b4c9dece291e1b3052",
    "semantic_title": "affective knowledge enhanced multiple-graph fusion networks for aspect-based sentiment analysis",
    "citation_count": 10,
    "authors": [
      "Siyu Tang",
      "Heyan Chai",
      "Ziyi Yao",
      "Ye Ding",
      "Cuiyun Gao",
      "Binxing Fang",
      "Qing Liao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.360": {
    "title": "IndicNLG Benchmark: Multilingual Datasets for Diverse NLG Tasks in Indic Languages",
    "volume": "main",
    "abstract": "Natural Language Generation (NLG) for non-English languages is hampered by the scarcity of datasets in these languages. We present the IndicNLG Benchmark, a collection of datasets for benchmarking NLG for 11 Indic languages. We focus on five diverse tasks, namely, biography generation using Wikipedia infoboxes, news headline generation, sentence summarization, paraphrase generation and, question generation. We describe the created datasets and use them to benchmark the performance of several monolingual and multilingual baselines that leverage pre-trained sequence-to-sequence models. Our results exhibit the strong performance of multilingual language-specific pre-trained models, and the utility of models trained on our dataset for other related NLG tasks. Our dataset creation methods can be easily applied to modest-resource languages as they involve simple steps such as scraping news articles and Wikipedia infoboxes, light cleaning, and pivoting through machine translation data. To the best of our knowledge, the IndicNLG Benchmark is the first NLG benchmark for Indic languages and the most diverse multilingual NLG dataset, with approximately 8M examples across 5 tasks and 11 languages. The datasets and models will be publicly available",
    "checked": true,
    "id": "dc62f2b13cc3d1384e8c4a85dc4fc8201ce1d5a6",
    "semantic_title": "indicnlg benchmark: multilingual datasets for diverse nlg tasks in indic languages",
    "citation_count": 19,
    "authors": [
      "Aman Kumar",
      "Himani Shrotriya",
      "Prachi Sahu",
      "Amogh Mishra",
      "Raj Dabre",
      "Ratish Puduppully",
      "Anoop Kunchukuttan",
      "Mitesh M. Khapra",
      "Pratyush Kumar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.361": {
    "title": "Improving Machine Translation with Phrase Pair Injection and Corpus Filtering",
    "volume": "main",
    "abstract": "In this paper, we show that the combination of Phrase Pair Injection and Corpus Filtering boosts the performance of Neural Machine Translation (NMT) systems. We extract parallel phrases and sentences from the pseudo-parallel corpus and augment it with the parallel corpus to train the NMT models. With the proposed approach, we observe an improvement in the Machine Translation (MT) system for 3 low-resource language pairs, Hindi-Marathi, English-Marathi, and English-Pashto, and 6 translation directions by up to 2.7 BLEU points, on the FLORES test data. These BLEU score improvements are over the models trained using the whole pseudo-parallel corpus augmented with the parallel corpus",
    "checked": true,
    "id": "df55699a9338d1f2d53e2b9d1400a855819919f7",
    "semantic_title": "improving machine translation with phrase pair injection and corpus filtering",
    "citation_count": 6,
    "authors": [
      "Akshay Batheja",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.362": {
    "title": "An Anchor-based Relative Position Embedding Method for Cross-Modal Tasks",
    "volume": "main",
    "abstract": "Position Embedding (PE) is essential for transformer to capture the sequence ordering of input tokens. Despite its general effectiveness verified in Natural Language Processing (NLP) and Computer Vision (CV), its application in cross-modal tasks remains unexplored and suffers from two challenges: 1) the input text tokens and image patches are not aligned, 2) the encoding space of each modality is different, making it unavailable for feature comparison. In this paper, we propose a unified position embedding method for these problems, called AnChor-basEd Relative Position Embedding (ACE-RPE), in which we first introduce an anchor locating mechanism to bridge the semantic gap and locate anchors from different modalities. Then we conduct the distance calculation of each text token and image patch by computing their shortest paths from the located anchors. Last, we embed the anchor-based distance to guide the computation of cross-attention. In this way, it calculates cross-modal relative position embedding for cross-modal transformer. Benefiting from ACE-RPE, our method obtains new SOTA results on a wide range of benchmarks, such as Image-Text Retrieval on MS-COCO and Flickr30K, Visual Entailment on SNLI-VE, Visual Reasoning on NLVR2 and Weakly-supervised Visual Grounding on RefCOCO+",
    "checked": true,
    "id": "12f721b9d135c078db4f8bb74a8d8f992efc318c",
    "semantic_title": "an anchor-based relative position embedding method for cross-modal tasks",
    "citation_count": 0,
    "authors": [
      "Ya Wang",
      "Xingwu Sun",
      "Lian Fengzong",
      "ZhanHui Kang",
      "Chengzhong Xu Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.363": {
    "title": "Norm-based Noisy Corpora Filtering and Refurbishing in Neural Machine Translation",
    "volume": "main",
    "abstract": "Recent advances in neural machine translation depend on massive parallel corpora, which are collected from any open source without much guarantee of quality. It stresses the need for noisy corpora filtering, but existing methods are insufficient to solve this issue. They spend much time ensembling multiple scorers trained on clean bitexts, unavailable for low-resource languages in practice. In this paper, we propose a norm-based noisy corpora filtering and refurbishing method with no external data and costly scorers. The noisy and clean samples are separated based on how much information from the source and target sides the model requires to fit the given translation. For the unparallel sentence, the target-side history translation is much more important than the source context, contrary to the parallel ones. The amount of these two information flows can be measured by norms of source-/target-side context vectors. Moreover, we propose to reuse the discovered noisy data by generating pseudo labels via online knowledge distillation. Extensive experiments show that our proposed filtering method performs comparably with state-of-the-art noisy corpora filtering techniques but is more efficient and easier to operate. Noisy sample refurbishing further enhances the performance by making the most of the given data",
    "checked": true,
    "id": "7dc1d0ac14419a9ed9d453162629db94b31d26ff",
    "semantic_title": "norm-based noisy corpora filtering and refurbishing in neural machine translation",
    "citation_count": 1,
    "authors": [
      "Yu Lu",
      "Jiajun Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.364": {
    "title": "TeleMelody: Lyric-to-Melody Generation with a Template-Based Two-Stage Method",
    "volume": "main",
    "abstract": "Lyric-to-melody generation is an important task in automatic songwriting. Previous lyric-to-melody generation systems usually adopt end-to-end models that directly generate melodies from lyrics, which suffer from several issues: 1) lack of paired lyric-melody training data; 2) lack of control on generated melodies. In this paper, we develop TeleMelody, a two-stage lyric-to-melody generation system with music template (e.g., tonality, chord progression, rhythm pattern, and cadence) to bridge the gap between lyrics and melodies (i.e., the system consists of a lyric-to-template module and a template-to-melody module). TeleMelody has two advantages. First, it is data efficient. The template-to-melody module is trained in a self-supervised way (i.e., the source template is extracted from the target melody) that does not need any lyric-melody paired data. The lyric-to-template module is made up of some rules and a lyric-to-rhythm model, which is trained with paired lyric-rhythm data that is easier to obtain than paired lyric-melody data. Second, it is controllable. The design of the template ensures that the generated melodies can be controlled by adjusting the musical elements in the template. Both subjective and objective experimental evaluations demonstrate that TeleMelody generates melodies with higher quality, better controllability, and less requirement on paired lyric-melody data than previous generation systems",
    "checked": true,
    "id": "e3c24c9e282f67fd77882bb0b55158023aaef59c",
    "semantic_title": "telemelody: lyric-to-melody generation with a template-based two-stage method",
    "citation_count": 28,
    "authors": [
      "Zeqian Ju",
      "Peiling Lu",
      "Xu Tan",
      "Rui Wang",
      "Chen Zhang",
      "Songruoyao Wu",
      "Kejun Zhang",
      "Xiang-Yang Li",
      "Tao Qin",
      "Tie-Yan Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.365": {
    "title": "SEEN: Structured Event Enhancement Network for Explainable Need Detection of Information Recall Assistance",
    "volume": "main",
    "abstract": "When recalling life experiences, people often forget or confuse life events, which necessitates information recall services. Previous work on information recall focuses on providing such assistance reactively, i.e., by retrieving the life event of a given query. Proactively detecting the need for information recall services is rarely discussed. In this paper, we use a human-annotated life experience retelling dataset to detect the right time to trigger the information recall service. We propose a pilot model—structured event enhancement network (SEEN) that detects life event inconsistency, additional information in life events, and forgotten events. A fusing mechanism is also proposed to incorporate event graphs of stories and enhance the textual representations. To explain the need detection results, SEEN simultaneously provides support evidence by selecting the related nodes from the event graph. Experimental results show that SEEN achieves promising performance in detecting information needs. In addition, the extracted evidence can be served as complementary information to remind users what events they may want to recall",
    "checked": true,
    "id": "020e17816373ef81016418fedcf8c9ccd22bfa96",
    "semantic_title": "seen: structured event enhancement network for explainable need detection of information recall assistance",
    "citation_count": 0,
    "authors": [
      "You-En Lin",
      "An-Zi Yen",
      "Hen-Hsen Huang",
      "Hsin-Hsi Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.366": {
    "title": "Rethinking Style Transformer with Energy-based Interpretation: Adversarial Unsupervised Style Transfer using a Pretrained Model",
    "volume": "main",
    "abstract": "Style control, content preservation, and fluency determine the quality of text style transfer models. To train on a nonparallel corpus, several existing approaches aim to deceive the style discriminator with an adversarial loss. However, adversarial training significantly degrades fluency compared to the other two metrics. In this work, we explain this phenomenon using energy-based interpretation, and leverage a pretrained language model to improve fluency. Specifically, we propose a novel approach which applies the pretrained language model to the text style transfer framework by restructuring the discriminator and the model itself, allowing the generator and the discriminator to also take advantage of the power of the pretrained model. We evaluated our model on three public benchmarks GYAFC, Amazon, and Yelp and achieved state-of-the-art performance on the overall metrics",
    "checked": true,
    "id": "21afd67b684d15ff56905c03d57497691b56c3ba",
    "semantic_title": "rethinking style transformer with energy-based interpretation: adversarial unsupervised style transfer using a pretrained model",
    "citation_count": 0,
    "authors": [
      "Hojun Cho",
      "Dohee Kim",
      "Seungwoo Ryu",
      "ChaeHun Park",
      "Hyungjong Noh",
      "Jeong-in Hwang",
      "Minseok Choi",
      "Edward Choi",
      "Jaegul Choo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.367": {
    "title": "Towards Robust k-Nearest-Neighbor Machine Translation",
    "volume": "main",
    "abstract": "k-Nearest-Neighbor Machine Translation (kNN-MT) becomes an important research direction of NMT in recent years. Its main idea is to retrieve useful key-value pairs from an additional datastore to modify translations without updating the NMT model. However, the underlying retrieved noisy pairs will dramatically deteriorate the model performance. In this paper, we conduct a preliminary study and find that this problem results from not fully exploiting the prediction of the NMT model. To alleviate the impact of noise, we propose a confidence-enhanced kNN-MT model with robust training. Concretely, we introduce the NMT confidence to refine the modeling of two important components of kNN-MT: kNN distribution and the interpolation weight. Meanwhile we inject two types of perturbations into the retrieved pairs for robust training. Experimental results on four benchmark datasets demonstrate that our model not only achieves significant improvements over current kNN-MT models, but also exhibits better robustness. Our code is available at https://github.com/DeepLearnXMU/Robust-knn-mt",
    "checked": true,
    "id": "4d8db2305e2d764205fccbae4122329cd1ecc89f",
    "semantic_title": "towards robust k-nearest-neighbor machine translation",
    "citation_count": 10,
    "authors": [
      "Hui Jiang",
      "Ziyao Lu",
      "Fandong Meng",
      "Chulun Zhou",
      "Jie Zhou",
      "Degen Huang",
      "Jinsong Su"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.368": {
    "title": "Tiny-NewsRec: Effective and Efficient PLM-based News Recommendation",
    "volume": "main",
    "abstract": "News recommendation is a widely adopted technique to provide personalized news feeds for the user. Recently, pre-trained language models (PLMs) have demonstrated the great capability of natural language understanding and benefited news recommendation via improving news modeling. However, most existing works simply finetune the PLM with the news recommendation task, which may suffer from the known domain shift problem between the pre-training corpus and downstream news texts. Moreover, PLMs usually contain a large volume of parameters and have high computational overhead, which imposes a great burden on low-latency online services. In this paper, we propose Tiny-NewsRec, which can improve both the effectiveness and the efficiency of PLM-based news recommendation. We first design a self-supervised domain-specific post-training method to better adapt the general PLM to the news domain with a contrastive matching task between news titles and news bodies. We further propose a two-stage knowledge distillation method to improve the efficiency of the large PLM-based news recommendation model while maintaining its performance. Multiple teacher models originated from different time steps of our post-training procedure are used to transfer comprehensive knowledge to the student model in both its post-training stage and finetuning stage. Extensive experiments on two real-world datasets validate the effectiveness and efficiency of our method",
    "checked": true,
    "id": "54cbf83555636ce7cfdf55a02297ddddd4717b46",
    "semantic_title": "tiny-newsrec: effective and efficient plm-based news recommendation",
    "citation_count": 15,
    "authors": [
      "Yang Yu",
      "Fangzhao Wu",
      "Chuhan Wu",
      "Jingwei Yi",
      "Qi Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.369": {
    "title": "TABS: Efficient Textual Adversarial Attack for Pre-trained NL Code Model Using Semantic Beam Search",
    "volume": "main",
    "abstract": "As pre-trained models have shown successful performance in program language processing as well as natural language processing, adversarial attacks on these models also attract attention. However, previous works on black-box adversarial attacks generated adversarial examples in a very inefficient way with simple greedy search. They also failed to find out better adversarial examples because it was hard to reduce the search space without performance loss. In this paper, we propose TABS, an efficient beam search black-box adversarial attack method. We adopt beam search to find out better adversarial examples, and contextual semantic filtering to effectively reduce the search space. Contextual semantic filtering reduces the number of candidate adversarial words considering the surrounding context and the semantic similarity. Our proposed method shows good performance in terms of attack success rate, the number of queries, and semantic similarity in attacking models for two tasks: NL code search classification and retrieval tasks",
    "checked": true,
    "id": "4546852ccca1c8d47c87bdbf18293214e2c3ebdf",
    "semantic_title": "tabs: efficient textual adversarial attack for pre-trained nl code model using semantic beam search",
    "citation_count": 2,
    "authors": [
      "YunSeok Choi",
      "Hyojun Kim",
      "Jee-Hyong Lee"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.370": {
    "title": "Investigating the Robustness of Natural Language Generation from Logical Forms via Counterfactual Samples",
    "volume": "main",
    "abstract": "The aim of Logic2Text is to generate controllable and faithful texts conditioned on tables and logical forms, which not only requires a deep understanding of the tables and logical forms, but also warrants symbolic reasoning over the tables according to the logical forms. State-of-the-art methods based on pre-trained models have achieved remarkable performance on the standard test dataset. However, we question whether these methods really learn how to perform logical reasoning, rather than just relying on the spurious correlations between the headers of the tables and operators of the logical form. To verify this hypothesis, we manually construct a set of counterfactual samples, which modify the original logical forms to generate counterfactual logical forms with rare co-occurred headers and operators and corresponding counterfactual references. SOTA methods give much worse results on these counterfactual samples compared with the results on the original test dataset, which verifies our hypothesis. To deal with this problem, we firstly analyze this bias from a causal perspective, based on which we propose two approaches to reduce the model's reliance on the shortcut. The first one incorporates the hierarchical structure of the logical forms into the model. The second one exploits automatically generated counterfactual data for training. Automatic and manual experimental results on the original test dataset and counterfactual dataset show that our method is effective to alleviate the spurious correlation. Our work points out the weakness of current methods and takes a further step toward developing Logic2Text models with real logical reasoning ability",
    "checked": true,
    "id": "eaeed0144d6a8000638c884f38d2d1e046aaa400",
    "semantic_title": "investigating the robustness of natural language generation from logical forms via counterfactual samples",
    "citation_count": 1,
    "authors": [
      "Chengyuan Liu",
      "Leilei Gan",
      "Kun Kuang",
      "Fei Wu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.371": {
    "title": "Helping the Weak Makes You Strong: Simple Multi-Task Learning Improves Non-Autoregressive Translators",
    "volume": "main",
    "abstract": "Recently, non-autoregressive (NAR) neural machine translation models have received increasing attention due to their efficient parallel decoding. However, the probabilistic framework of NAR models necessitates conditional independence assumption on target sequences, falling short of characterizing human language data. This drawback results in less informative learning signals for NAR models under conventional MLE training, thereby yielding unsatisfactory accuracy compared to their autoregressive (AR) counterparts. In this paper, we propose a simple and model-agnostic multi-task learning framework to provide more informative learning signals. During training stage, we introduce a set of sufficiently weak AR decoders that solely rely on the information provided by NAR decoder to make prediction, forcing the NAR decoder to become stronger or else it will be unable to support its weak AR partners. Experiments on WMT and IWSLT datasets show that our approach can consistently improve accuracy of multiple NAR baselines without adding any additional decoding overhead",
    "checked": true,
    "id": "921d43718376fb4e000bba8690e07b168d5f9093",
    "semantic_title": "helping the weak makes you strong: simple multi-task learning improves non-autoregressive translators",
    "citation_count": 3,
    "authors": [
      "Xinyou Wang",
      "Zaixiang Zheng",
      "Shujian Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.372": {
    "title": "RACE: Retrieval-augmented Commit Message Generation",
    "volume": "main",
    "abstract": "Commit messages are important for software development and maintenance. Many neural network-based approaches have been proposed and shown promising results on automatic commit message generation. However, the generated commit messages could be repetitive or redundant. In this paper, we propose RACE, a new retrieval-augmented neural commit message generation method, which treats the retrieved similar commit as an exemplar and leverages it to generate an accurate commit message. As the retrieved commit message may not always accurately describe the content/intent of the current code diff, we also propose an exemplar guider, which learns the semantic similarity between the retrieved and current code diff and then guides the generation of commit message based on the similarity. We conduct extensive experiments on a large public dataset with five programming languages. Experimental results show that RACE can outperform all baselines. Furthermore, RACE can boost the performance of existing Seq2Seq models in commit message generation",
    "checked": true,
    "id": "4a26009d4ffaad428eb5cc8749510bf64fcc0cd1",
    "semantic_title": "race: retrieval-augmented commit message generation",
    "citation_count": 18,
    "authors": [
      "Ensheng Shi",
      "Yanlin Wang",
      "Wei Tao",
      "Lun Du",
      "Hongyu Zhang",
      "Shi Han",
      "Dongmei Zhang",
      "Hongbin Sun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.373": {
    "title": "PLOG: Table-to-Logic Pretraining for Logical Table-to-Text Generation",
    "volume": "main",
    "abstract": "Logical table-to-text generation is a task that involves generating logically faithful sentences from tables, which requires models to derive logical-level facts from table records via logical inference. It raises a new challenge on the logical-level content planning of table-to-text models. However, directly learning the logical inference knowledge from table-text pairs is very difficult for neural models because of the ambiguity of natural language and the scarcity of parallel data. Hence even large-scale pre-trained language models present low logical fidelity on logical table-to-text. In this work, we propose a Pretrained Logical Form Generator (PLOG) framework to improve generation fidelity. Specifically, PLOG is first pretrained on a table-to-logical-form generation (table-to-logic) task, then finetuned on downstream table-to-text tasks. The logical forms are formally defined with unambiguous semantics. Hence we can collect a large amount of accurate logical forms from tables without human annotation. In addition, PLOG can learn logical inference from table-logic pairs much more reliably than from table-text pairs. To evaluate our model, we further collect a controlled logical table-to-text dataset CONTLOG based on an existing dataset. On two benchmarks, LOGICNLG and CONTLOG, PLOG outperforms strong baselines by a large margin on the logical fidelity, demonstrating the effectiveness of table-to-logic pretraining",
    "checked": true,
    "id": "39e70e5bef45c519b88f1e2cdf6b78435aff7f7e",
    "semantic_title": "plog: table-to-logic pretraining for logical table-to-text generation",
    "citation_count": 13,
    "authors": [
      "Ao Liu",
      "Haoyu Dong",
      "Naoaki Okazaki",
      "Shi Han",
      "Dongmei Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.374": {
    "title": "GHAN: Graph-Based Hierarchical Aggregation Network for Text-Video Retrieval",
    "volume": "main",
    "abstract": "Text-video retrieval focuses on two aspects: cross-modality interaction and video-language encoding. Currently, the mainstream approach is to train a joint embedding space for multimodal interactions. However, there are structural and semantic differences between text and video, making this approach challenging for fine-grained understanding. In order to solve this, we propose an end-to-end graph-based hierarchical aggregation network for text-video retrieval according to the hierarchy possessed by text and video. We design a token-level weighted network to refine intra-modality representations and construct a graph-based message passing attention network for global-local alignment across modality. We conduct experiments on the public datasets MSR-VTT-9K, MSR-VTT-7K and MSVD, and achieve Recall@1 of 73.0%, 65.6%, and 64.0% , which is 25.7%, 16.5%, and 14.2% better than the current state-of-the-art model",
    "checked": true,
    "id": "3a91396047f17932eaf02dbfc712511bfb71e7ab",
    "semantic_title": "ghan: graph-based hierarchical aggregation network for text-video retrieval",
    "citation_count": 3,
    "authors": [
      "Yahan Yu",
      "Bojie Hu",
      "Yu Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.375": {
    "title": "MuRAG: Multimodal Retrieval-Augmented Generator for Open Question Answering over Images and Text",
    "volume": "main",
    "abstract": "While language Models store a massive amount of world knowledge implicitly in their parameters, even very large models often fail to encode information about rare entities and events, while incurring huge computational costs. Recently, retrieval-augmented models, such as REALM, RAG, and RETRO, have incorporated world knowledge into language generation by leveraging an external non-parametric index and have demonstrated impressive performance with constrained model sizes. However, these methods are restricted to retrieving only textual knowledge, neglecting the ubiquitous amount of knowledge in other modalities like images – much of which contains information not covered by any text. To address this limitation, we propose the first Multimodal Retrieval-Augmented Transformer (MuRAG), which accesses an external non-parametric multimodal memory to augment language generation. MuRAG is pre-trained with a mixture of large-scale image-text and text-only corpora using a joint contrastive and generative loss. We perform experiments on two different datasets that require retrieving and reasoning over both images and text to answer a given query: WebQA, and MultimodalQA. Our results show that MuRAG achieves state-of-the-art accuracy, outperforming existing models by 10-20% absolute on both datasets and under both distractor and full-wiki settings",
    "checked": true,
    "id": "38b0803b59e4973f09018ce942164b02be4b8bc9",
    "semantic_title": "murag: multimodal retrieval-augmented generator for open question answering over images and text",
    "citation_count": 37,
    "authors": [
      "Wenhu Chen",
      "Hexiang Hu",
      "Xi Chen",
      "Pat Verga",
      "William Cohen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.376": {
    "title": "PHEE: A Dataset for Pharmacovigilance Event Extraction from Text",
    "volume": "main",
    "abstract": "The primary goal of drug safety researchers and regulators is to promptly identify adverse drug reactions. Doing so may in turn prevent or reduce the harm to patients and ultimately improve public health. Evaluating and monitoring drug safety (i.e., pharmacovigilance) involves analyzing an ever growing collection of spontaneous reports from health professionals, physicians, and pharmacists, and information voluntarily submitted by patients. In this scenario, facilitating analysis of such reports via automation has the potential to rapidly identify safety signals. Unfortunately, public resources for developing natural language models for this task are scant. We present PHEE, a novel dataset for pharmacovigilance comprising over 5000 annotated events from medical case reports and biomedical literature, making it the largest such public dataset to date. We describe the hierarchical event schema designed to provide coarse and fine-grained information about patients' demographics, treatments and (side) effects. Along with the discussion of the dataset, we present a thorough experimental evaluation of current state-of-the-art approaches for biomedical event extraction, point out their limitations, and highlight open challenges to foster future research in this area",
    "checked": true,
    "id": "1b2f6cacaa7305df32b8c70ef5c0ecd4db69a825",
    "semantic_title": "phee: a dataset for pharmacovigilance event extraction from text",
    "citation_count": 10,
    "authors": [
      "Zhaoyue Sun",
      "Jiazheng Li",
      "Gabriele Pergola",
      "Byron Wallace",
      "Bino John",
      "Nigel Greene",
      "Joseph Kim",
      "Yulan He"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.377": {
    "title": "OTSeq2Set: An Optimal Transport Enhanced Sequence-to-Set Model for Extreme Multi-label Text Classification",
    "volume": "main",
    "abstract": "Extreme multi-label text classification (XMTC) is the task of finding the most relevant subset labels from an extremely large-scale label collection. Recently, some deep learning models have achieved state-of-the-art results in XMTC tasks. These models commonly predict scores for all labels by a fully connected layer as the last layer of the model. However, such models can't predict a relatively complete and variable-length label subset for each document, because they select positive labels relevant to the document by a fixed threshold or take top k labels in descending order of scores. A less popular type of deep learning models called sequence-to-sequence (Seq2Seq) focus on predicting variable-length positive labels in sequence style. However, the labels in XMTC tasks are essentially an unordered set rather than an ordered sequence, the default order of labels restrains Seq2Seq models in training. To address this limitation in Seq2Seq, we propose an autoregressive sequence-to-set model for XMTC tasks named OTSeq2Set. Our model generates predictions in student-forcing scheme and is trained by a loss function based on bipartite matching which enables permutation-invariance. Meanwhile, we use the optimal transport distance as a measurement to force the model to focus on the closest labels in semantic label space. Experiments show that OTSeq2Set outperforms other competitive baselines on 4 benchmark datasets. Especially, on the Wikipedia dataset with 31k labels, it outperforms the state-of-the-art Seq2Seq method by 16.34% in micro-F1 score. The code is available at https://github.com/caojie54/OTSeq2Set",
    "checked": true,
    "id": "1196fc4f84e6e1cd2e17cffd9c28ff4a9ae0d092",
    "semantic_title": "otseq2set: an optimal transport enhanced sequence-to-set model for extreme multi-label text classification",
    "citation_count": 2,
    "authors": [
      "Jie Cao",
      "Yin Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.378": {
    "title": "SimQA: Detecting Simultaneous MT Errors through Word-by-Word Question Answering",
    "volume": "main",
    "abstract": "Detractors of neural machine translation admit that while its translations are fluent, it sometimes gets key facts wrong. This is particularly important in simultaneous interpretation where translations have to be provided as fast as possible: before a sentence is complete. Yet, evaluations of simultaneous machine translation (SimulMT) fail to capture if systems correctly translate the most salient elements of a question: people, places, and dates. To address this problem, we introduce a downstream word-by-word question answering evaluation task (SimQA): given a source language question, translate the question word by word into the target language, and answer as soon as possible. SimQA jointly measures whether the SimulMT models translate the question quickly and accurately, and can reveal shortcomings in existing neural systems—hallucinating or omitting facts",
    "checked": true,
    "id": "63b6a785cd41f151fe371376300cba831cd29965",
    "semantic_title": "simqa: detecting simultaneous mt errors through word-by-word question answering",
    "citation_count": 6,
    "authors": [
      "HyoJung Han",
      "Marine Carpuat",
      "Jordan Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.379": {
    "title": "Discovering Low-rank Subspaces for Language-agnostic Multilingual Representations",
    "volume": "main",
    "abstract": "Large pretrained multilingual language models (ML-LMs) have shown remarkable capabilities of zero-shot cross-lingual transfer, without direct cross-lingual supervision. While these results are promising, follow-up works found that, within the multilingual embedding spaces, there exists strong language identity information which hinders the expression of linguistic factors shared across languages. For semantic tasks like cross-lingual sentence retrieval, it is desired to remove such language identity signals to fully leverage semantic information. In this work, we provide a novel view of projecting away language-specific factors from a multilingual embedding space. Specifically, we discover that there exists a low-rank subspace that primarily encodes information irrelevant to semantics (e.g., syntactic information). To identify this subspace, we present a simple but effective unsupervised method based on singular value decomposition with multiple monolingual corpora as input. Once the subspace is found, we can directly project the original embeddings into the null space to boost language agnosticism without finetuning. We systematically evaluate our method on various tasks including the challenging language-agnostic QA retrieval task. Empirical results show that applying our method consistently leads to improvements over commonly used ML-LMs",
    "checked": true,
    "id": "d0e2e6c98a7b2c8360aa091c0dc0a270edec8468",
    "semantic_title": "discovering low-rank subspaces for language-agnostic multilingual representations",
    "citation_count": 3,
    "authors": [
      "Zhihui Xie",
      "Handong Zhao",
      "Tong Yu",
      "Shuai Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.380": {
    "title": "Rethinking the Authorship Verification Experimental Setups",
    "volume": "main",
    "abstract": "One of the main drivers of the recent advances in authorship verification is the PAN large-scale authorship dataset. Despite generating significant progress in the field, inconsistent performance differences between the closed and open test sets have been reported. To this end, we improve the experimental setup by proposing five new public splits over the PAN dataset, specifically designed to isolate and identify biases related to the text topic and to the author's writing style. We evaluate several BERT-like baselines on these splits, showing that such models are competitive with authorship verification state-of-the-art methods. Furthermore, using explainable AI, we find that these baselines are biased towards named entities. We show that models trained without the named entities obtain better results and generalize better when tested on DarkReddit, our new dataset for authorship verification",
    "checked": true,
    "id": "9424d98d7805574661da1adf4f8bc682be5714da",
    "semantic_title": "rethinking the authorship verification experimental setups",
    "citation_count": 0,
    "authors": [
      "Florin Brad",
      "Andrei Manolache",
      "Elena Burceanu",
      "Antonio Barbalau",
      "Radu Tudor Ionescu",
      "Marius Popescu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.381": {
    "title": "Borrowing Human Senses: Comment-Aware Self-Training for Social Media Multimodal Classification",
    "volume": "main",
    "abstract": "Social media is daily creating massive multimedia content with paired image and text, presenting the pressing need to automate the vision and language understanding for various multimodal classification tasks. Compared to the commonly researched visual-lingual data, social media posts tend to exhibit more implicit image-text relations. To better glue the cross-modal semantics therein, we capture hinting features from user comments, which are retrieved via jointly leveraging visual and lingual similarity. Afterwards, the classification tasks are explored via self-training in a teacher-student framework, motivated by the usually limited labeled data scales in existing benchmarks. Substantial experiments are conducted on four multimodal social media benchmarks for image-text relation classification, sarcasm detection, sentiment classification, and hate speech detection. The results show that our method further advances the performance of previous state-of-the-art models, which do not employ comment modeling or self-training",
    "checked": true,
    "id": "982a06ddea4fabfdf55f7272231ff1506123d170",
    "semantic_title": "borrowing human senses: comment-aware self-training for social media multimodal classification",
    "citation_count": 2,
    "authors": [
      "Chunpu Xu",
      "Jing Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.382": {
    "title": "Training Language Models with Memory Augmentation",
    "volume": "main",
    "abstract": "Recent work has improved language models (LMs) remarkably by equipping them with a non-parametric memory component. However, most existing approaches only introduce mem-ories at testing time or represent them using a separately trained encoder, resulting in suboptimal training of the language model. In this work, we present TRIME, a novel yet simple training approach designed for training LMs with memory augmentation. Our approach uses a training objective that directly takes in-batch examples as accessible memory. We also present new methods for memory construction and data batching, which are used for adapting to different sets of memories—local, long-term, and external memory—at testing time. We evaluate TRIME on multiple language modeling and machine translation benchmarks and show that it is able to achieve significant improvements across all the settings. Concretely, TRIME reduces the perplexity from 18.70 to 15.37 on WIKITEXT-103, by effectively leveraging a large memory set from the training corpus. Compared to standard LM training, TRIME adds negligible computational overhead and is compatible with different neural architectures, making it a versatile solution for training memory-augmented LMs",
    "checked": true,
    "id": "da1d6445b6b64ce9eb4587ba8abbdc490f648ec1",
    "semantic_title": "training language models with memory augmentation",
    "citation_count": 80,
    "authors": [
      "Zexuan Zhong",
      "Tao Lei",
      "Danqi Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.383": {
    "title": "Data-Efficient Strategies for Expanding Hate Speech Detection into Under-Resourced Languages",
    "volume": "main",
    "abstract": "Hate speech is a global phenomenon, but most hate speech datasets so far focus on English-language content. This hinders the development of more effective hate speech detection models in hundreds of languages spoken by billions across the world. More data is needed, but annotating hateful content is expensive, time-consuming and potentially harmful to annotators. To mitigate these issues, we explore data-efficient strategies for expanding hate speech detection into under-resourced languages. In a series of experiments with mono- and multilingual models across five non-English languages, we find that 1) a small amount of target-language fine-tuning data is needed to achieve strong performance, 2) the benefits of using more such data decrease exponentially, and 3) initial fine-tuning on readily-available English data can partially substitute target-language data and improve model generalisability. Based on these findings, we formulate actionable recommendations for hate speech detection in low-resource language settings",
    "checked": true,
    "id": "858dd0478bbc842953bcdddafcc274e3e1059112",
    "semantic_title": "data-efficient strategies for expanding hate speech detection into under-resourced languages",
    "citation_count": 8,
    "authors": [
      "Paul Röttger",
      "Debora Nozza",
      "Federico Bianchi",
      "Dirk Hovy"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.384": {
    "title": "Dimension Reduction for Efficient Dense Retrieval via Conditional Autoencoder",
    "volume": "main",
    "abstract": "Dense retrievers encode queries and documents and map them in an embedding space using pre-trained language models. These embeddings need to be high-dimensional to fit training signals and guarantee the retrieval effectiveness of dense retrievers. However, these high-dimensional embeddings lead to larger index storage and higher retrieval latency. To reduce the embedding dimensions of dense retrieval, this paper proposes a Conditional Autoencoder (ConAE) to compress the high-dimensional embeddings to maintain the same embedding distribution and better recover the ranking features. Our experiments show that ConAE is effective in compressing embeddings by achieving comparable ranking performance with its teacher model and making the retrieval system more efficient. Our further analyses show that ConAE can alleviate the redundancy of the embeddings of dense retrieval with only one linear layer. All codes of this work are available at https://github.com/NEUIR/ConAE",
    "checked": true,
    "id": "7b520ec107c1b698f14d8d305edd2f7bc8a202c8",
    "semantic_title": "dimension reduction for efficient dense retrieval via conditional autoencoder",
    "citation_count": 2,
    "authors": [
      "Zhenghao Liu",
      "Han Zhang",
      "Chenyan Xiong",
      "Zhiyuan Liu",
      "Yu Gu",
      "Xiaohua Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.385": {
    "title": "Controlled Text Reduction",
    "volume": "main",
    "abstract": "Producing a reduced version of a source text, as in generic or focused summarization, inherently involves two distinct subtasks: deciding on targeted content and generating a coherent text conveying it. While some popular approaches address summarization as a single end-to-end task, prominent works support decomposed modeling for individual subtasks. Further, semi-automated text reduction is also very appealing, where users may identify targeted content while models would generate a corresponding coherent summary. In this paper, we focus on the second subtask, of generating coherent text given pre-selected content. Concretely, we formalize Controlled Text Reduction as a standalone task, whose input is a source text with marked spans of targeted content (\"highlighting\").A model then needs to generate a coherent text that includes all and only the target information.We advocate the potential of such models, both for modular fully-automatic summarization, as well as for semi-automated human-in-the-loop use cases.Facilitating proper research, we crowdsource high-quality dev and test datasets for the task. Further, we automatically generate a larger \"silver\" training dataset from available summarization benchmarks, leveraging a pretrained summary-source alignment model.Finally, employing these datasets, we present a supervised baseline model, showing promising results and insightful analyses",
    "checked": true,
    "id": "b3b4e7ef399f7458db537eedea9349ee6209c643",
    "semantic_title": "controlled text reduction",
    "citation_count": 8,
    "authors": [
      "Aviv Slobodkin",
      "Paul Roit",
      "Eran Hirsch",
      "Ori Ernst",
      "Ido Dagan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.386": {
    "title": "Questioning the Validity of Summarization Datasets and Improving Their Factual Consistency",
    "volume": "main",
    "abstract": "The topic of summarization evaluation has recently attracted a surge of attention due to the rapid development of abstractive summarization systems. However, the formulation of the task is rather ambiguous, neither the linguistic nor the natural language processing communities have succeeded in giving a mutually agreed-upon definition. Due to this lack of well-defined formulation, a large number of popular abstractive summarization datasets are constructed in a manner that neither guarantees validity nor meets one of the most essential criteria of summarization: factual consistency. In this paper, we address this issue by combining state-of-the-art factual consistency models to identify the problematic instances present in popular summarization datasets. We release SummFC, a filtered summarization dataset with improved factual consistency, and demonstrate that models trained on this dataset achieve improved performance in nearly all quality aspects. We argue that our dataset should become a valid benchmark for developing and evaluating summarization systems",
    "checked": true,
    "id": "5149fbc5d21436b42e884278475d2eef32d52b28",
    "semantic_title": "questioning the validity of summarization datasets and improving their factual consistency",
    "citation_count": 6,
    "authors": [
      "Yanzhu Guo",
      "Chloé Clavel",
      "Moussa Kamal Eddine",
      "Michalis Vazirgiannis"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.387": {
    "title": "Invariant Language Modeling",
    "volume": "main",
    "abstract": "Modern pretrained language models are critical components of NLP pipelines. Yet, they suffer from spurious correlations, poor out-of-domain generalization, and biases. Inspired by recent progress in causal machine learning, in particular the invariant risk minimization (IRM) paradigm, we propose invariant language modeling, a framework for learning invariant representations that generalize better across multiple environments. In particular, we adapt a game-theoretic implementation of IRM (IRM-games) to language models, where the invariance emerges from a specific training schedule in which all the environments compete to optimize their own environment-specific loss by updating subsets of the model in a round-robin fashion. We focused on controlled experiments to precisely demonstrate the ability of our method to (i) remove structured noise, (ii) ignore specific spurious correlations without affecting global performance, and (iii) achieve better out-of-domain generalization. These benefits come with a negligible computational overhead compared to standard training, do not require changing the local loss, and can be applied to any language model. We believe this framework is promising to help mitigate spurious correlations and biases in language models",
    "checked": true,
    "id": "0974413e05f1522615d4a84b30627418c65f980e",
    "semantic_title": "invariant language modeling",
    "citation_count": 12,
    "authors": [
      "Maxime Peyrard",
      "Sarvjeet Ghotra",
      "Martin Josifoski",
      "Vidhan Agarwal",
      "Barun Patra",
      "Dean Carignan",
      "Emre Kiciman",
      "Saurabh Tiwary",
      "Robert West"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.388": {
    "title": "AdaMix: Mixture-of-Adaptations for Parameter-efficient Model Tuning",
    "volume": "main",
    "abstract": "Standard fine-tuning of large pre-trained language models (PLMs) for downstream tasks requires updating hundreds of millions to billions of parameters, and storing a large copy of the PLM weights for every task resulting in increased cost for storing, sharing and serving the models. To address this, parameter-efficient fine-tuning (PEFT) techniques were introduced where small trainable components are injected in the PLM and updated during fine-tuning. We propose AdaMix as a general PEFT method that tunes a mixture of adaptation modules – given the underlying PEFT method of choice – introduced in each Transformer layer while keeping most of the PLM weights frozen. For instance, AdaMix can leverage a mixture of adapters like Houlsby or a mixture of low rank decomposition matrices like LoRA to improve downstream task performance over the corresponding PEFT methods for fully supervised and few-shot NLU and NLG tasks. Further, we design AdaMix such that it matches the same computational cost and the number of tunable parameters as the underlying PEFT method. By only tuning 0.1-0.2% of PLM parameters, we show that AdaMix outperforms SOTA parameter-efficient fine-tuning and full model fine-tuning for both NLU and NLG tasks",
    "checked": true,
    "id": "eb4d54651c4f610749caf2bf401af3ce28ddc439",
    "semantic_title": "adamix: mixture-of-adaptations for parameter-efficient model tuning",
    "citation_count": 41,
    "authors": [
      "Yaqing Wang",
      "Sahaj Agarwal",
      "Subhabrata Mukherjee",
      "Xiaodong Liu",
      "Jing Gao",
      "Ahmed Hassan Awadallah",
      "Jianfeng Gao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.389": {
    "title": "How \"Multi\" is Multi-Document Summarization?",
    "volume": "main",
    "abstract": "The task of multi-document summarization (MDS) aims at models that, given multiple documents as input, are able to generate a summary that combines disperse information, originally spread __across__ these documents. Accordingly, it is expected that both reference summaries in MDS datasets, as well as system summaries, would indeed be based on such dispersed information. In this paper, we argue for quantifying and assessing this expectation. To that end, we propose an automated measure for evaluating the degree to which a summary is \"disperse\", in the sense of the number of source documents needed to cover its content. We apply our measure to empirically analyze several popular MDS datasets, with respect to their reference summaries, as well as the output of state-of-the-art systems. Our results show that certain MDS datasets barely require combining information from multiple documents, where a single document often covers the full summary content. Overall, we advocate using our metric for assessing and improving the degree to which summarization datasets require combining multi-document information, and similarly how summarization models actually meet this challenge",
    "checked": true,
    "id": "08357b63d13590dd73f0982c64bf0e0be9b64ddf",
    "semantic_title": "how \"multi\" is multi-document summarization?",
    "citation_count": 10,
    "authors": [
      "Ruben Wolhandler",
      "Arie Cattan",
      "Ori Ernst",
      "Ido Dagan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.390": {
    "title": "BioReader: a Retrieval-Enhanced Text-to-Text Transformer for Biomedical Literature",
    "volume": "main",
    "abstract": "The latest batch of research has equipped language models with the ability to attend over relevant and factual information from non-parametric external sources, drawing a complementary path to architectural scaling. Besides mastering language, exploiting and contextualizing the latent world knowledge is crucial in complex domains like biomedicine. However, most works in the field rely on general-purpose models supported by databases like Wikipedia and Books. We introduce BioReader, the first retrieval-enhanced text-to-text model for biomedical natural language processing. Our domain-specific T5-based solution augments the input prompt by fetching and assembling relevant scientific literature chunks from a neural database with ≈60 million tokens centered on PubMed. We fine-tune and evaluate BioReader on a broad array of downstream tasks, significantly outperforming several state-of-the-art methods despite using up to 3x fewer parameters. In tandem with extensive ablation studies, we show that domain knowledge can be easily altered or supplemented to make the model generate correct predictions bypassing the retraining step and thus addressing the literature overload issue",
    "checked": true,
    "id": "df24c0f317fc73b893c852a3fce9536ba8607dfa",
    "semantic_title": "bioreader: a retrieval-enhanced text-to-text transformer for biomedical literature",
    "citation_count": 13,
    "authors": [
      "Giacomo Frisoni",
      "Miki Mizutani",
      "Gianluca Moro",
      "Lorenzo Valgimigli"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.391": {
    "title": "T-Modules: Translation Modules for Zero-Shot Cross-Modal Machine Translation",
    "volume": "main",
    "abstract": "We present a new approach to perform zero-shot cross-modal transfer between speech and text for translation tasks. Multilingual speech and text are encoded in a joint fixed-size representation space. Then, we compare different approaches to decode these multimodal and multilingual fixed-size representations, enabling zero-shot translation between languages and modalities. All our models are trained without the need of cross-modal labeled translation data. Despite a fixed-size representation, we achieve very competitive results on several text and speech translation tasks. In particular, we significantly improve the state-of-the-art for zero-shot speech translation on Must-C. Incorporating a speech decoder in our framework, we introduce the first results for zero-shot direct speech-to-speech and text-to-speech translation",
    "checked": true,
    "id": "f20e5f1f9c33974ec3352781333759929c695ea5",
    "semantic_title": "t-modules: translation modules for zero-shot cross-modal machine translation",
    "citation_count": 12,
    "authors": [
      "Paul-Ambroise Duquenne",
      "Hongyu Gong",
      "Benoît Sagot",
      "Holger Schwenk"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.392": {
    "title": "LILA: A Unified Benchmark for Mathematical Reasoning",
    "volume": "main",
    "abstract": "Mathematical reasoning skills are essential for general-purpose intelligentsystems to perform tasks from grocery shopping to climate modeling. Towards evaluating and improving AI systems in this domain, we proposeLILA, a unified mathematical reasoning benchmark consisting of 23 diversetasks along four dimensions:(i) mathematical abilities e.g., arithmetic, calculus (ii) language format e.g., question-answering, fill-in-the-blanks (iii) language diversity e.g., no language, simple language (iv) external knowledge e.g., commonsense, physics. We construct our benchmark by extending 20 datasets benchmark by collecting task instructions and solutions in the form of Python programs,thereby obtaining explainable solutions in addition to the correct answer. We additionally introduce two evaluation datasets to measure out-of-distribution performance and robustness to language perturbation. Finally, we introduce BHASKARA,a general-purpose mathematical reasoning model trained on LILA. Importantly, we find that multi-tasking leads to significant improvements (average relative improvement of 21.83% F1 score vs. single-task models),while the best performing model only obtains 60.40%,indicating the room for improvement in general mathematical reasoning and understanding",
    "checked": true,
    "id": "52fb239ea5cea1e9a2636f8f7922c8ede3e50ba7",
    "semantic_title": "lila: a unified benchmark for mathematical reasoning",
    "citation_count": 69,
    "authors": [
      "Swaroop Mishra",
      "Matthew Finlayson",
      "Pan Lu",
      "Leonard Tang",
      "Sean Welleck",
      "Chitta Baral",
      "Tanmay Rajpurohit",
      "Oyvind Tafjord",
      "Ashish Sabharwal",
      "Peter Clark",
      "Ashwin Kalyan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.393": {
    "title": "Leveraging Affirmative Interpretations from Negation Improves Natural Language Understanding",
    "volume": "main",
    "abstract": "Negation poses a challenge in many natural language understanding tasks. Inspired by the fact that understanding a negated statement often requires humans to infer affirmative interpretations, in this paper we show that doing so benefits models for three natural language understanding tasks. We present an automated procedure to collect pairs of sentences with negation and their affirmative interpretations, resulting in over 150,000 pairs. Experimental results show that leveraging these pairs helps (a) T5 generate affirmative interpretations from negations in a previous benchmark, and (b) a RoBERTa-based classifier solve the task of natural language inference. We also leverage our pairs to build a plug-and-play neural generator that given a negated statement generates an affirmative interpretation. Then, we incorporate the pretrained generator into a RoBERTa-based classifier for sentiment analysis and show that doing so improves the results. Crucially, our proposal does not require any manual effort",
    "checked": true,
    "id": "045836fee6da2410ba912f1a05349e1e0adaa5fe",
    "semantic_title": "leveraging affirmative interpretations from negation improves natural language understanding",
    "citation_count": 2,
    "authors": [
      "Md Mosharaf Hossain",
      "Eduardo Blanco"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.394": {
    "title": "GraphQ IR: Unifying the Semantic Parsing of Graph Query Languages with One Intermediate Representation",
    "volume": "main",
    "abstract": "Subject to the huge semantic gap between natural and formal languages, neural semantic parsing is typically bottlenecked by its complexity of dealing with both input semantics and output syntax. Recent works have proposed several forms of supplementary supervision but none is generalized across multiple formal languages. This paper proposes a unified intermediate representation for graph query languages, named GraphQ IR. It has a natural-language-like expression that bridges the semantic gap and formally defined syntax that maintains the graph structure. Therefore, a neural semantic parser can more precisely convert user queries into GraphQ IR, which can be later losslessly compiled into various downstream graph query languages. Extensive experiments on several benchmarks including KQA Pro, Overnight, GrailQA, and MetaQA-Cypher under the standard i.i.d., out-of-distribution, and low-resource settings validate GraphQ IR's superiority over the previous state-of-the-arts with a maximum 11% accuracy improvement",
    "checked": true,
    "id": "5fa148e8bfcd5fa3df05311c0ec8abb13caf1c05",
    "semantic_title": "graphq ir: unifying the semantic parsing of graph query languages with one intermediate representation",
    "citation_count": 9,
    "authors": [
      "Lunyiu Nie",
      "Shulin Cao",
      "Jiaxin Shi",
      "Jiuding Sun",
      "Qi Tian",
      "Lei Hou",
      "Juanzi Li",
      "Jidong Zhai"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.395": {
    "title": "InforMask: Unsupervised Informative Masking for Language Model Pretraining",
    "volume": "main",
    "abstract": "Masked language modeling is widely used for pretraining large language models for natural language understanding (NLU). However, random masking is suboptimal, allocating an equal masking rate for all tokens. In this paper, we propose InforMask, a new unsupervised masking strategy for training masked language models. InforMask exploits Pointwise Mutual Information (PMI) to select the most informative tokens to mask. We further propose two optimizations for InforMask to improve its efficiency. With a one-off preprocessing step, InforMask outperforms random masking and previously proposed masking strategies on the factual recall benchmark LAMA and the question answering benchmark SQuAD v1 and v2",
    "checked": true,
    "id": "c1cc7cedbee57bfb4623708e7da2f5c701501860",
    "semantic_title": "informask: unsupervised informative masking for language model pretraining",
    "citation_count": 9,
    "authors": [
      "Nafis Sadeq",
      "Canwen Xu",
      "Julian McAuley"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.396": {
    "title": "CTRLsum: Towards Generic Controllable Text Summarization",
    "volume": "main",
    "abstract": "Current summarization systems yield generic summaries that are disconnected from users' preferences and expectations. To address this limitation, we present CTRLsum, a generic framework to control generated summaries through a set of keywords. During training keywords are extracted automatically without requiring additional human annotations. At test time CTRLsum features a control function to map control signal to keywords; through engineering the control function, the same trained model is able to be applied to control summaries on various dimensions, while neither affecting the model training process nor the pretrained models. We additionally explore the combination of keywords and text prompts for more control tasks. Experiments demonstrate the effectiveness of CTRLsum on three domains of summarization datasets and five control tasks: (1) entity-centric and (2) length-controllable summarization, (3) contribution summarization on scientific papers, (4) invention purpose summarization on patent filings, and (5) question-guided summarization on news articles. Moreover, when used in a standard, unconstrained summarization setting, CTRLsum is comparable or better than strong pretrained systems",
    "checked": true,
    "id": "d4e9bf1d5fab52698a3aa48c65b098ea327deea6",
    "semantic_title": "ctrlsum: towards generic controllable text summarization",
    "citation_count": 113,
    "authors": [
      "Junxian He",
      "Wojciech Kryscinski",
      "Bryan McCann",
      "Nazneen Rajani",
      "Caiming Xiong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.397": {
    "title": "Missing Counter-Evidence Renders NLP Fact-Checking Unrealistic for Misinformation",
    "volume": "main",
    "abstract": "Misinformation emerges in times of uncertainty when credible information is limited. This is challenging for NLP-based fact-checking as it relies on counter-evidence, which may not yet be available. Despite increasing interest in automatic fact-checking, it is still unclear if automated approaches can realistically refute harmful real-world misinformation. Here, we contrast and compare NLP fact-checking with how professional fact-checkers combat misinformation in the absence of counter-evidence. In our analysis, we show that, by design, existing NLP task definitions for fact-checking cannot refute misinformation as professional fact-checkers do for the majority of claims. We then define two requirements that the evidence in datasets must fulfill for realistic fact-checking: It must be (1) sufficient to refute the claim and (2) not leaked from existing fact-checking articles. We survey existing fact-checking datasets and find that all of them fail to satisfy both criteria. Finally, we perform experiments to demonstrate that models trained on a large-scale fact-checking dataset rely on leaked evidence, which makes them unsuitable in real-world scenarios. Taken together, we show that current NLP fact-checking cannot realistically combat real-world misinformation because it depends on unrealistic assumptions about counter-evidence in the data",
    "checked": true,
    "id": "bb6f8161be27877e0299af65a6a7caf3f0a1f220",
    "semantic_title": "missing counter-evidence renders nlp fact-checking unrealistic for misinformation",
    "citation_count": 18,
    "authors": [
      "Max Glockner",
      "Yufang Hou",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.398": {
    "title": "A Framework for Adapting Pre-Trained Language Models to Knowledge Graph Completion",
    "volume": "main",
    "abstract": "Recent work has demonstrated that entity representations can be extracted from pre-trained language models to develop knowledge graph completion models that are more robust to the naturally occurring sparsity found in knowledge graphs. In this work, we conduct a comprehensive exploration of how to best extract and incorporate those embeddings into knowledge graph completion models. We explore the suitability of the extracted embeddings for direct use in entity ranking and introduce both unsupervised and supervised processing methods that can lead to improved downstream performance. We then introduce supervised embedding extraction methods that can extract more informative representations. We then synthesize our findings and develop a knowledge graph completion model that significantly outperforms recent neural models",
    "checked": true,
    "id": "9dfe43db470ad2ac0ee8444a7605f28fecb2c661",
    "semantic_title": "a framework for adapting pre-trained language models to knowledge graph completion",
    "citation_count": 5,
    "authors": [
      "Justin Lovelace",
      "Carolyn Rosé"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.399": {
    "title": "Mutual Information Alleviates Hallucinations in Abstractive Summarization",
    "volume": "main",
    "abstract": "Despite significant progress in the quality of language generated from abstractive summarization models, these models still exhibit the tendency to hallucinate, i.e., output content not supported by the source document. A number of works have tried to fix—or at least uncover the source of—the problem with limited success. In this paper, we identify a simple criterion under which models are significantly more likely to assign more probability to hallucinated content during generation: high model uncertainty. This finding offers a potential explanation for hallucinations: models default to favoring text with high marginal probability, i.e., high-frequency occurrences in the training set, when uncertain about a continuation. It also motivates possible routes for real-time intervention during decoding to prevent such hallucinations. We propose a decoding strategy that switches to optimizing for pointwise mutual information of the source and target token—rather than purely the probability of the target token—when the model exhibits uncertainty. Experiments on the dataset show that our method decreases the probability of hallucinated tokens while maintaining the Rouge and BERT-S scores of top-performing decoding strategies",
    "checked": true,
    "id": "d785f543f7a344fcec7ccbe55089a7f782e32bd7",
    "semantic_title": "mutual information alleviates hallucinations in abstractive summarization",
    "citation_count": 25,
    "authors": [
      "Liam van der Poel",
      "Ryan Cotterell",
      "Clara Meister"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.400": {
    "title": "Toward the Limitation of Code-Switching in Cross-Lingual Transfer",
    "volume": "main",
    "abstract": "Multilingual pretrained models have shown strong cross-lingual transfer ability. Some works used code-switching sentences, which consist of tokens from multiple languages, to enhance the cross-lingual representation further, and have shown success in many zero-shot cross-lingual tasks. However, code-switched tokens are likely to cause grammatical incoherence in newly substituted sentences, and negatively affect the performance on token-sensitive tasks, such as Part-of-Speech (POS) tagging and Named-Entity-Recognition (NER). This paper mitigates the limitation of the code-switching method by not only making the token replacement but considering the similarity between the context and the switched tokens so that the newly substituted sentences are grammatically consistent during both training and inference. We conduct experiments on cross-lingual POS and NER over 30+ languages, and demonstrate the effectiveness of our method by outperforming the mBERT by 0.95 and original code-switching method by 1.67 on F1 scores",
    "checked": true,
    "id": "c251373110fd9d9e9275b1ab2a3f767b218ada9d",
    "semantic_title": "toward the limitation of code-switching in cross-lingual transfer",
    "citation_count": 2,
    "authors": [
      "Yukun Feng",
      "Feng Li",
      "Philipp Koehn"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.401": {
    "title": "Syntactically Rich Discriminative Training: An Effective Method for Open Information Extraction",
    "volume": "main",
    "abstract": "Open information extraction (OIE) is the task of extracting facts \"(Subject, Relation, Object)\" from natural language text. We propose several new methods for training neural OIE models in this paper. First, we propose a novel method for computing syntactically rich text embeddings using the structure of dependency trees. Second, we propose a new discriminative training approach to OIE in which tokens in the generated fact are classified as \"real\" or \"fake\", i.e., those tokens that are in both the generated and gold tuples, and those that are only in the generated tuple but not in the gold tuple. We also address the issue of repetitive tokens in generated facts and improve the models' ability to generate implicit facts. Our approach reduces repetitive tokens by a factor of 23%. Finally, we present paraphrased versions of the CaRB, OIE2016, and LSOIE datasets, and show that the models' performance substantially improves when trained on augmented datasets. Our best model beats the SOTA of IMoJIE on the recent CaRB dataset, with an improvement of 39.63% in F1 score",
    "checked": true,
    "id": "90efbf48b8d18f9a3f5c537290dc134a9d7696e4",
    "semantic_title": "syntactically rich discriminative training: an effective method for open information extraction",
    "citation_count": 1,
    "authors": [
      "Frank Mtumbuka",
      "Thomas Lukasiewicz"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.402": {
    "title": "Transformer-based Entity Typing in Knowledge Graphs",
    "volume": "main",
    "abstract": "We investigate the knowledge graph entity typing task which aims at inferring plausible entity types. In this paper, we propose a novel Transformer-based Entity Typing (TET) approach, effectively encoding the content of neighbours of an entity by means of a transformer mechanism. More precisely, TET is composed of three different mechanisms: a local transformer allowing to infer missing entity types by independently encoding the information provided by each of its neighbours; a global transformer aggregating the information of all neighbours of an entity into a single long sequence to reason about more complex entity types; and a context transformer integrating neighbours content in a differentiated way through information exchange between neighbour pairs, while preserving the graph structure. Furthermore, TET uses information about class membership of types to semantically strengthen the representation of an entity. Experiments on two real-world datasets demonstrate the superior performance of TET compared to the state-of-the-art",
    "checked": true,
    "id": "2b8f3ebcbd630a221c90049bca90e1f6081a1b38",
    "semantic_title": "transformer-based entity typing in knowledge graphs",
    "citation_count": 7,
    "authors": [
      "Zhiwei Hu",
      "Victor Gutierrez-Basulto",
      "Zhiliang Xiang",
      "Ru Li",
      "Jeff Pan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.403": {
    "title": "NewsClaims: A New Benchmark for Claim Detection from News with Attribute Knowledge",
    "volume": "main",
    "abstract": "Claim detection and verification are crucial for news understanding and have emerged as promising technologies for mitigating misinformation and disinformation in the news. However, most existing work has focused on claim sentence analysis while overlooking additional crucial attributes (e.g., the claimer and the main object associated with the claim).In this work, we present NewsClaims, a new benchmark for attribute-aware claim detection in the news domain. We extend the claim detection problem to include extraction of additional attributes related to each claim and release 889 claims annotated over 143 news articles. NewsClaims aims to benchmark claim detection systems in emerging scenarios, comprising unseen topics with little or no training data. To this end, we see that zero-shot and prompt-based baselines show promising performance on this benchmark, while still considerably behind human performance",
    "checked": true,
    "id": "a6d3aa3164688fa113f9333382a1335520c64368",
    "semantic_title": "newsclaims: a new benchmark for claim detection from news with attribute knowledge",
    "citation_count": 14,
    "authors": [
      "Revanth Gangi Reddy",
      "Sai Chetan Chinthakindi",
      "Zhenhailong Wang",
      "Yi Fung",
      "Kathryn Conger",
      "Ahmed ELsayed",
      "Martha Palmer",
      "Preslav Nakov",
      "Eduard Hovy",
      "Kevin Small",
      "Heng Ji"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.404": {
    "title": "IsoVec: Controlling the Relative Isomorphism of Word Embedding Spaces",
    "volume": "main",
    "abstract": "The ability to extract high-quality translation dictionaries from monolingual word embedding spaces depends critically on the geometric similarity of the spaces—their degree of \"isomorphism.\" We address the root-cause of faulty cross-lingual mapping: that word embedding training resulted in the underlying spaces being non-isomorphic. We incorporate global measures of isomorphism directly into the skipgram loss function, successfully increasing the relative isomorphism of trained word embedding spaces and improving their ability to be mapped to a shared cross-lingual space. The result is improved bilingual lexicon induction in general data conditions, under domain mismatch, and with training algorithm dissimilarities. We release IsoVec at https://github.com/kellymarchisio/isovec",
    "checked": true,
    "id": "0d2390cb571477ced2743003c515a47cc9661f57",
    "semantic_title": "isovec: controlling the relative isomorphism of word embedding spaces",
    "citation_count": 4,
    "authors": [
      "Kelly Marchisio",
      "Neha Verma",
      "Kevin Duh",
      "Philipp Koehn"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.405": {
    "title": "Adversarial Concept Erasure in Kernel Space",
    "volume": "main",
    "abstract": "The representation space of neural models for textual data emerges in an unsupervised manner during training. Understanding how human-interpretable concepts, such as gender, are encoded in these representations would improve the ability of users to control the content of these representations and analyze the working of the models that rely on them. One prominent approach to the control problem is the identification and removal of linear concept subspaces – subspaces in the representation space that correspond to a given concept. While those are tractable and interpretable, neural network do not necessarily represent concepts in linear subspaces. We propose a kernelization of the recently-proposed linear concept-removal objective, and show that it is effective in guarding against the ability of certain nonlinear adversaries to recover the concept. Interestingly, our findings suggest that the division between linear and nonlinear models is overly simplistic: when considering the concept of binary gender and its neutralization, we do not find a single kernel space that exclusively contains all the concept-related information. It is therefore challenging to protect against all nonlinear adversaries at once",
    "checked": true,
    "id": "4ca0f16524104777b001247662ef8d406d17ea3d",
    "semantic_title": "adversarial concept erasure in kernel space",
    "citation_count": 18,
    "authors": [
      "Shauli Ravfogel",
      "Francisco Vargas",
      "Yoav Goldberg",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.406": {
    "title": "The Authenticity Gap in Human Evaluation",
    "volume": "main",
    "abstract": "Human ratings are the gold standard in NLG evaluation. The standard protocol is to collect ratings of generated text, average across annotators, and rank NLG systems by their average scores. However, little consideration has been given as to whether this approach faithfully captures human preferences. Analyzing this standard protocol through the lens of utility theory in economics, we identify the implicit assumptions it makes about annotators. These assumptions are often violated in practice, in which case annotator ratings cease to reflect their preferences. The most egregious violations come from using Likert scales, which provably reverse the direction of the true preference in certain cases. We suggest improvements to the standard protocol to make it more theoretically sound, but even in its improved form, it cannot be used to evaluate open-ended tasks like story generation. For the latter, we propose a new human evaluation protocol called system-level probabilistic assessment (SPA). When human evaluation of stories is done with SPA, we can recover the ordering of GPT-3 models by size, with statistically significant results. However, when human evaluation is done with the standard protocol, less than half of the expected preferences can be recovered (e.g., there is no significant difference between curie and davinci, despite using a highly powered test)",
    "checked": true,
    "id": "20eca4866bb257b8d701bc7c9b19864b7c05bc23",
    "semantic_title": "the authenticity gap in human evaluation",
    "citation_count": 14,
    "authors": [
      "Kawin Ethayarajh",
      "Dan Jurafsky"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.407": {
    "title": "BERT in Plutarch's Shadows",
    "volume": "main",
    "abstract": "The extensive surviving corpus of the ancient scholar Plutarch of Chaeronea (ca. 45-120 CE) also contains several texts which, according to current scholarly opinion, did not originate with him and are therefore attributed to an anonymous author Pseudo-Plutarch. These include, in particular, the work Placita Philosophorum (Quotations and Opinions of the Ancient Philosophers), which is extremely important for the history of ancient philosophy. Little is known about the identity of that anonymous author and its relation to other authors from the same period. This paper presents a BERT language model for Ancient Greek. The model discovers previously unknown statistical properties relevant to these literary, philosophical, and historical problems and can shed new light on this authorship question. In particular, the Placita Philosophorum, together with one of the other Pseudo-Plutarch texts, shows similarities with the texts written by authors from an Alexandrian context (2nd/3rd century CE)",
    "checked": true,
    "id": "111529b3911f2adcaddc8d2b35f7c6fa562c89d2",
    "semantic_title": "bert in plutarch's shadows",
    "citation_count": 7,
    "authors": [
      "Ivan P. Yamshchikov",
      "Alexey Tikhonov",
      "Yorgos Pantis",
      "Charlotte Schubert",
      "Jürgen Jost"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.408": {
    "title": "Leveraging Locality in Abstractive Text Summarization",
    "volume": "main",
    "abstract": "Neural attention models have achieved significant improvements on many natural language processing tasks. However, the quadratic memory complexity of the self-attention module with respect to the input length hinders their applications in long text summarization. Instead of designing more efficient attention modules, we approach this problem by investigating if models with a restricted context can have competitive performance compared with the memory-efficient attention models that maintain a global context by treating the input as a single sequence. Our model is applied to individual pages, which contain parts of inputs grouped by the principle of locality, during both the encoding and decoding stages. We empirically investigated three kinds of locality in text summarization at different levels of granularity, ranging from sentences to documents. Our experimental results show that our model has a better performance compared with strong baseline models with efficient attention modules, and our analysis provides further insights into our locality-aware modeling strategy",
    "checked": true,
    "id": "85e3cf70079adb1db8b1b50321a5d336edc1c3fa",
    "semantic_title": "leveraging locality in abstractive text summarization",
    "citation_count": 13,
    "authors": [
      "Yixin Liu",
      "Ansong Ni",
      "Linyong Nan",
      "Budhaditya Deb",
      "Chenguang Zhu",
      "Ahmed Hassan Awadallah",
      "Dragomir Radev"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.409": {
    "title": "Salience Allocation as Guidance for Abstractive Summarization",
    "volume": "main",
    "abstract": "Abstractive summarization models typically learn to capture the salient information from scratch implicitly. Recent literature adds extractive summaries as guidance for abstractive summarization models to provide hints of salient content and achieves better performance. However, extractive summaries as guidance could be over strict, leading to information loss or noisy signals. Furthermore, it cannot easily adapt to documents with various abstractiveness. As the number and allocation of salience content pieces varies, it is hard to find a fixed threshold deciding which content should be included in the guidance. In this paper, we propose a novel summarization approach with a flexible and reliable salience guidance, namely SEASON (SaliencE Allocation as Guidance for Abstractive SummarizatiON).SEASON utilizes the allocation of salience expectation to guide abstractive summarization and adapts well to articles in different abstractiveness. Automatic and human evaluations on two benchmark datasets show that the proposed method is effective and reliable. Empirical results on more than one million news articles demonstrate a natural fifteen-fifty salience split for news article sentences, providing a useful insight for composing news articles",
    "checked": true,
    "id": "6788a8a0148421cf482cb8caa23504ee1e36798e",
    "semantic_title": "salience allocation as guidance for abstractive summarization",
    "citation_count": 13,
    "authors": [
      "Fei Wang",
      "Kaiqiang Song",
      "Hongming Zhang",
      "Lifeng Jin",
      "Sangwoo Cho",
      "Wenlin Yao",
      "Xiaoyang Wang",
      "Muhao Chen",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.410": {
    "title": "Fine-tuned Language Models are Continual Learners",
    "volume": "main",
    "abstract": "Recent work on large language models relies on the intuition that most natural language processing tasks can be described via natural language instructions and that models trained on these instructions show strong zero-shot performance on several standard datasets. However, these models even though impressive still perform poorly on a wide range of tasks outside of their respective training and evaluation sets. To address this limitation, we argue that a model should be able to keep extending its knowledge and abilities, without forgetting previous skills. In spite of the limited success of Continual Learning, we show that Fine-tuned Language Models can be continual learners.We empirically investigate the reason for this success and conclude that Continual Learning emerges from self-supervision pre-training. Our resulting model Continual-T0 (CT0) is able to learn 8 new diverse language generation tasks, while still maintaining good performance on previous tasks, spanning in total of 70 datasets. Finally, we show that CT0 is able to combine instructions in ways it was never trained for, demonstrating some level of instruction compositionality",
    "checked": true,
    "id": "d304d0bdfa81fd10b187aa0e4f41d410eb19d6e3",
    "semantic_title": "fine-tuned language models are continual learners",
    "citation_count": 54,
    "authors": [
      "Thomas Scialom",
      "Tuhin Chakrabarty",
      "Smaranda Muresan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.411": {
    "title": "Natural Logic-guided Autoregressive Multi-hop Document Retrieval for Fact Verification",
    "volume": "main",
    "abstract": "A key component of fact verification is the evidence retrieval, often from multiple documents. Recent approaches use dense representations and condition the retrieval of each document on the previously retrieved ones. The latter step is performed over all the documents in the collection, requiring storing their dense representations in an index, thus incurring a high memory footprint. An alternative paradigm is retrieve-and-rerank, where documents are retrieved using methods such as BM25, their sentences are reranked, and further documents are retrieved conditioned on these sentences, reducing the memory requirements. However, such approaches can be brittle as they rely on heuristics and assume hyperlinks between documents. We propose a novel retrieve-and-rerank method for multi-hop retrieval, that consists of a retriever that jointly scores documents in the knowledge source and sentences from previously retrieved documents using an autoregressive formulation and is guided by a proof system based on natural logic that dynamically terminates the retrieval process if the evidence is deemed sufficient. This method exceeds or is on par with the current state-of-the-art on FEVER, HoVer and FEVEROUS-S, while using 5 to 10 times less memory than competing systems. Evaluation on an adversarial dataset indicates improved stability of our approach compared to commonly deployed threshold-based methods. Finally, the proof system helps humans predict model decisions correctly more often than using the evidence alone",
    "checked": true,
    "id": "9376e8f9fd6a2d650906af749d4cbc0436dddce8",
    "semantic_title": "natural logic-guided autoregressive multi-hop document retrieval for fact verification",
    "citation_count": 8,
    "authors": [
      "Rami Aly",
      "Andreas Vlachos"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.412": {
    "title": "AX-MABSA: A Framework for Extremely Weakly Supervised Multi-label Aspect Based Sentiment Analysis",
    "volume": "main",
    "abstract": "Aspect Based Sentiment Analysis is a dominant research area with potential applications in social media analytics, business, finance, and health. Prior works in this area are primarily based on supervised methods, with a few techniques using weak supervision limited to predicting a single aspect category per review sentence. In this paper, we present an extremely weakly supervised multi-label Aspect Category Sentiment Analysis framework which does not use any labelled data. We only rely on a single word per class as an initial indicative information. We further propose an automatic word selection technique to choose these seed categories and sentiment words. We explore unsupervised language model post-training to improve the overall performance, and propose a multi-label generator model to generate multiple aspect category-sentiment pairs per review sentence. Experiments conducted on four benchmark datasets showcase our method to outperform other weakly supervised baselines by a significant margin",
    "checked": true,
    "id": "b26b5ba7fe6d6f7c9e0d1445c01531dc4c98c0c6",
    "semantic_title": "ax-mabsa: a framework for extremely weakly supervised multi-label aspect based sentiment analysis",
    "citation_count": 3,
    "authors": [
      "Sabyasachi Kamila",
      "Walid Magdy",
      "Sourav Dutta",
      "MingXue Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.413": {
    "title": "Transfer Learning with Synthetic Corpora for Spatial Role Labeling and Reasoning",
    "volume": "main",
    "abstract": "Recent research shows synthetic data as a source of supervision helps pretrained language models (PLM) transfer learning to new target tasks/domains. However, this idea is less explored for spatial language. We provide two new data resources on multiple spatial language processing tasks. The first dataset is synthesized for transfer learning on spatial question answering (SQA) and spatial role labeling (SpRL). Compared to previous SQA datasets, we include a larger variety of spatial relation types and spatial expressions. Our data generation process is easily extendable with new spatial expression lexicons. The second one is a real-world SQA dataset with human-generated questions built on an existing corpus with SPRL annotations. This dataset can be used to evaluate spatial language processing models in realistic situations. We show pretraining with automatically generated data significantly improves the SOTA results on several SQA and SPRL benchmarks, particularly when the training data in the target domain is small",
    "checked": true,
    "id": "e3cd9f01f87a601b274b4ef6513a84c8cde03214",
    "semantic_title": "transfer learning with synthetic corpora for spatial role labeling and reasoning",
    "citation_count": 11,
    "authors": [
      "Roshanak Mirzaee",
      "Parisa Kordjamshidi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.414": {
    "title": "A Survey of Active Learning for Natural Language Processing",
    "volume": "main",
    "abstract": "In this work, we provide a literature review of active learning (AL) for its applications in natural language processing (NLP). In addition to a fine-grained categorization of query strategies, we also investigate several other important aspects of applying AL to NLP problems. These include AL for structured prediction tasks, annotation cost, model learning (especially with deep neural models), and starting and stopping AL. Finally, we conclude with a discussion of related topics and future directions",
    "checked": true,
    "id": "3cd98a010b36832fc2bd8368cd4f34c72cd0ac6f",
    "semantic_title": "a survey of active learning for natural language processing",
    "citation_count": 32,
    "authors": [
      "Zhisong Zhang",
      "Emma Strubell",
      "Eduard Hovy"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.415": {
    "title": "Bernice: A Multilingual Pre-trained Encoder for Twitter",
    "volume": "main",
    "abstract": "The language of Twitter differs significantly from that of other domains commonly included in large language model training. While tweets are typically multilingual and contain informal language, including emoji and hashtags, most pre-trained language models for Twitter are either monolingual, adapted from other domains rather than trained exclusively on Twitter, or are trained on a limited amount of in-domain Twitter data. We introduce Bernice, the first multilingual RoBERTa language model trained from scratch on 2.5 billion tweets with a custom tweet-focused tokenizer. We evaluate on a variety of monolingual and multilingual Twitter benchmarks, finding that our model consistently exceeds or matches the performance of a variety of models adapted to social media data as well as strong multilingual baselines, despite being trained on less data overall. We posit that it is more efficient compute- and data-wise to train completely on in-domain data with a specialized domain-specific tokenizer",
    "checked": true,
    "id": "1b3eeb693c717c18955d920af11f7adb6382f430",
    "semantic_title": "bernice: a multilingual pre-trained encoder for twitter",
    "citation_count": 21,
    "authors": [
      "Alexandra DeLucia",
      "Shijie Wu",
      "Aaron Mueller",
      "Carlos Aguirre",
      "Philip Resnik",
      "Mark Dredze"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.416": {
    "title": "CEFR-Based Sentence Difficulty Annotation and Assessment",
    "volume": "main",
    "abstract": "Controllable text simplification is a crucial assistive technique for language learning and teaching. One of the primary factors hindering its advancement is the lack of a corpus annotated with sentence difficulty levels based on language ability descriptions. To address this problem, we created the CEFR-based Sentence Profile (CEFR-SP) corpus, containing 17k English sentences annotated with the levels based on the Common European Framework of Reference for Languages assigned by English-education professionals. In addition, we propose a sentence-level assessment model to handle unbalanced level distribution because the most basic and highly proficient sentences are naturally scarce. In the experiments in this study, our method achieved a macro-F1 score of 84.5% in the level assessment, thus outperforming strong baselines employed in readability assessment",
    "checked": true,
    "id": "926b7d79283e49be14db178df998d3cbda2a4513",
    "semantic_title": "cefr-based sentence difficulty annotation and assessment",
    "citation_count": 10,
    "authors": [
      "Yuki Arase",
      "Satoru Uchida",
      "Tomoyuki Kajiwara"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.417": {
    "title": "Simple Questions Generate Named Entity Recognition Datasets",
    "volume": "main",
    "abstract": "Recent named entity recognition (NER) models often rely on human-annotated datasets requiring the vast engagement of professional knowledge on the target domain and entities. This work introduces an ask-to-generate approach, which automatically generates NER datasets by asking simple natural language questions to an open-domain question answering system (e.g., \"Which disease?\"). Despite using fewer training resources, our models solely trained on the generated datasets largely outperform strong low-resource models by 19.5 F1 score across six popular NER benchmarks. Our models also show competitive performance with rich-resource models that additionally leverage in-domain dictionaries provided by domain experts. In few-shot NER, we outperform the previous best model by 5.2 F1 score on three benchmarks and achieve new state-of-the-art performance",
    "checked": true,
    "id": "49ea98fe003325b8f05e92c9a9bc22837f1a252a",
    "semantic_title": "simple questions generate named entity recognition datasets",
    "citation_count": 6,
    "authors": [
      "Hyunjae Kim",
      "Jaehyo Yoo",
      "Seunghyun Yoon",
      "Jinhyuk Lee",
      "Jaewoo Kang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.418": {
    "title": "TemporalWiki: A Lifelong Benchmark for Training and Evaluating Ever-Evolving Language Models",
    "volume": "main",
    "abstract": "Language Models (LMs) become outdated as the world changes; they often fail to perform tasks requiring recent factual information which was absent or different during training, a phenomenon called temporal misalignment. This is especially a challenging problem because the research community still lacks a coherent dataset for assessing the adaptability of LMs to frequently-updated knowledge corpus such as Wikipedia. To this end, we introduce TemporalWiki, a lifelong benchmark for ever-evolving LMs that utilizes the difference between consecutive snapshots of English Wikipedia and English Wikidata for training and evaluation, respectively. The benchmark hence allows researchers to periodically track an LM's ability to retain previous knowledge and acquire updated/new knowledge at each point in time. We also find that training an LM on the diff data through continual learning methods achieves similar or better perplexity than on the entire snapshot in our benchmark with 12 times less computational cost, which verifies that factual knowledge in LMs can be safely updated with minimal training data via continual learning",
    "checked": true,
    "id": "a3ba7fdf789bcef381acd0d277a086428153bb9f",
    "semantic_title": "temporalwiki: a lifelong benchmark for training and evaluating ever-evolving language models",
    "citation_count": 48,
    "authors": [
      "Joel Jang",
      "Seonghyeon Ye",
      "Changho Lee",
      "Sohee Yang",
      "Joongbo Shin",
      "Janghoon Han",
      "Gyeonghun Kim",
      "Minjoon Seo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.419": {
    "title": "Bi-Directional Iterative Prompt-Tuning for Event Argument Extraction",
    "volume": "main",
    "abstract": "Recently, prompt-tuning has attracted growing interests in event argument extraction (EAE). However, the existing prompt-tuning methods have not achieved satisfactory performance due to the lack of consideration of entity information. In this paper, we propose a bi-directional iterative prompt-tuning method for EAE, where the EAE task is treated as a cloze-style task to take full advantage of entity information and pre-trained language models (PLMs). Furthermore, our method explores event argument interactions by introducing the argument roles of contextual entities into prompt construction. Since template and verbalizer are two crucial components in a cloze-style prompt, we propose to utilize the role label semantic knowledge to construct a semantic verbalizer and design three kind of templates for the EAE task. Experiments on the ACE 2005 English dataset with standard and low-resource settings show that the proposed method significantly outperforms the peer state-of-the-art methods",
    "checked": true,
    "id": "0f4219a1a0f89c7364aabb27632cdcc833ab53b7",
    "semantic_title": "bi-directional iterative prompt-tuning for event argument extraction",
    "citation_count": 6,
    "authors": [
      "Lu Dai",
      "Bang Wang",
      "Wei Xiang",
      "Yijun Mo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.420": {
    "title": "Learning Robust Representations for Continual Relation Extraction via Adversarial Class Augmentation",
    "volume": "main",
    "abstract": "Continual relation extraction (CRE) aims to continually learn new relations from a class-incremental data stream. CRE model usually suffers from catastrophic forgetting problem, i.e., the performance of old relations seriously degrades when the model learns new relations. Most previous work attributes catastrophic forgetting to the corruption of the learned representations as new relations come, with an implicit assumption that the CRE models have adequately learned the old relations. In this paper, through empirical studies we argue that this assumption may not hold, and an important reason for catastrophic forgetting is that the learned representations do not have good robustness against the appearance of analogous relations in the subsequent learning process. To address this issue, we encourage the model to learn more precise and robust representations through a simple yet effective adversarial class augmentation mechanism (ACA), which is easy to implement and model-agnostic. Experimental results show that ACA can consistently improve the performance of state-of-the-art CRE models on two popular benchmarks",
    "checked": true,
    "id": "f07735d82c7013310be496faba964d785199528d",
    "semantic_title": "learning robust representations for continual relation extraction via adversarial class augmentation",
    "citation_count": 15,
    "authors": [
      "Peiyi Wang",
      "Yifan Song",
      "Tianyu Liu",
      "Binghuai Lin",
      "Yunbo Cao",
      "Sujian Li",
      "Zhifang Sui"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.421": {
    "title": "ConvFinQA: Exploring the Chain of Numerical Reasoning in Conversational Finance Question Answering",
    "volume": "main",
    "abstract": "With the recent advance in large pre-trained language models, researchers have achieved record performances in NLP tasks that mostly focus on language pattern matching. The community is experiencing the shift of the challenge from how to model language to the imitation of complex reasoning abilities like human beings. In this work, we investigate the application domain of finance that involves real-world, complex numerical reasoning. We propose a new large-scale dataset, ConvFinQA, aiming to study the chain of numerical reasoning in conversational question answering. Our dataset poses great challenge in modeling long-range, complex numerical reasoning paths in real-world conversations. We conduct comprehensive experiments and analyses with both the neural symbolic methods and the prompting-based methods, to provide insights into the reasoning mechanisms of these two divisions. We believe our new dataset should serve as a valuable resource to push forward the exploration of real-world, complex reasoning tasks as the next research focus. Our dataset and code is publicly available at https://github.com/czyssrs/ConvFinQA",
    "checked": true,
    "id": "d96997265f8146e93b4c9350f19d55e46d1317f0",
    "semantic_title": "convfinqa: exploring the chain of numerical reasoning in conversational finance question answering",
    "citation_count": 43,
    "authors": [
      "Zhiyu Chen",
      "Shiyang Li",
      "Charese Smiley",
      "Zhiqiang Ma",
      "Sameena Shah",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.422": {
    "title": "A Span-based Multimodal Variational Autoencoder for Semi-supervised Multimodal Named Entity Recognition",
    "volume": "main",
    "abstract": "Multimodal named entity recognition (MNER) on social media is a challenging task which aims to extract named entities in free text and incorporate images to classify them into user-defined types. However, the annotation for named entities on social media demands a mount of human efforts. The existing semi-supervised named entity recognition methods focus on the text modal and are utilized to reduce labeling costs in traditional NER. However, the previous methods are not efficient for semi-supervised MNER. Because the MNER task is defined to combine the text information with image one and needs to consider the mismatch between the posted text and image. To fuse the text and image features for MNER effectively under semi-supervised setting, we propose a novel span-based multimodal variational autoencoder (SMVAE) model for semi-supervised MNER. The proposed method exploits modal-specific VAEs to model text and image latent features, and utilizes product-of-experts to acquire multimodal features. In our approach, the implicit relations between labels and multimodal features are modeled by multimodal VAE. Thus, the useful information of unlabeled data can be exploited in our method under semi-supervised setting. Experimental results on two benchmark datasets demonstrate that our approach not only outperforms baselines under supervised setting, but also improves MNER performance with less labeled data than existing semi-supervised methods",
    "checked": true,
    "id": "b14820cd3c051794c8db445dc21682cb6c198f8e",
    "semantic_title": "a span-based multimodal variational autoencoder for semi-supervised multimodal named entity recognition",
    "citation_count": 1,
    "authors": [
      "Baohang Zhou",
      "Ying Zhang",
      "Kehui Song",
      "Wenya Guo",
      "Guoqing Zhao",
      "Hongbin Wang",
      "Xiaojie Yuan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.423": {
    "title": "R-TeaFor: Regularized Teacher-Forcing for Abstractive Summarization",
    "volume": "main",
    "abstract": "Teacher-forcing is widely used in training sequence generation models to improve sampling efficiency and to stabilize training. However, teacher-forcing is vulnerable to the exposure bias problem. Previous works have attempted to address exposure bias by modifying the training data to simulate model-generated results. Nevertheless, they do not consider the pairwise relationship between the original training data and the modified ones, which provides more information during training. Hence, we propose Regularized Teacher-Forcing (R-TeaFor) to utilize this relationship for better regularization. Empirically, our experiments show that R-TeaFor outperforms previous summarization state-of-the-art models, and the results can be generalized to different pre-trained models",
    "checked": true,
    "id": "a430fd7c1b85a9de796136f70e98aebc01c37c56",
    "semantic_title": "r-teafor: regularized teacher-forcing for abstractive summarization",
    "citation_count": 2,
    "authors": [
      "Guan-Yu Lin",
      "Pu-Jen Cheng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.424": {
    "title": "Modeling Consistency Preference via Lexical Chains for Document-level Neural Machine Translation",
    "volume": "main",
    "abstract": "In this paper we aim to relieve the issue of lexical translation inconsistency for document-level neural machine translation (NMT) by modeling consistency preference for lexical chains, which consist of repeated words in a source-side document and provide a representation of the lexical consistency structure of the document. Specifically, we first propose lexical-consistency attention to capture consistency context among words in the same lexical chains. Then for each lexical chain we define and learn a consistency-tailored latent variable, which will guide the translation of corresponding sentences to enhance lexical translation consistency. Experimental results on Chinese→English and French→English document-level translation tasks show that our approach not only significantly improves translation performance in BLEU, but also substantially alleviates the problem of the lexical translation inconsistency",
    "checked": true,
    "id": "799448a5b5999b1597709bfb9fecf34816107d66",
    "semantic_title": "modeling consistency preference via lexical chains for document-level neural machine translation",
    "citation_count": 0,
    "authors": [
      "Xinglin Lyu",
      "Junhui Li",
      "Shimin Tao",
      "Hao Yang",
      "Ying Qin",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.425": {
    "title": "Just Fine-tune Twice: Selective Differential Privacy for Large Language Models",
    "volume": "main",
    "abstract": "Protecting large language models from privacy leakage is becoming increasingly crucial with their wide adoption in real-world products. Yet applying *differential privacy* (DP), a canonical notion with provable privacy guarantees for machine learning models, to those models remains challenging due to the trade-off between model utility and privacy loss. Utilizing the fact that sensitive information in language data tends to be sparse, Shi et al. (2021) formalized a DP notion extension called *Selective Differential Privacy* (SDP) to protect only the sensitive tokens defined by a policy function. However, their algorithm only works for RNN-based models. In this paper, we develop a novel framework, *Just Fine-tune Twice* (JFT), that achieves SDP for state-of-the-art large transformer-based models. Our method is easy to implement: it first fine-tunes the model with *redacted* in-domain data, and then fine-tunes it again with the *original* in-domain data using a private training mechanism. Furthermore, we study the scenario of imperfect implementation of policy functions that misses sensitive tokens and develop systematic methods to handle it. Experiments show that our method achieves strong utility compared to previous baselines. We also analyze the SDP privacy guarantee empirically with the canary insertion attack",
    "checked": true,
    "id": "97333fea241659b8d804d04d326c3590c4a528f2",
    "semantic_title": "just fine-tune twice: selective differential privacy for large language models",
    "citation_count": 12,
    "authors": [
      "Weiyan Shi",
      "Ryan Shea",
      "Si Chen",
      "Chiyuan Zhang",
      "Ruoxi Jia",
      "Zhou Yu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.426": {
    "title": "Factorizing Content and Budget Decisions in Abstractive Summarization of Long Documents",
    "volume": "main",
    "abstract": "We argue that disentangling content selection from the budget used to cover salient content improves the performance and applicability of abstractive summarizers. Our method, FactorSum, does this disentanglement by factorizing summarization into two steps through an energy function: (1) generation of abstractive summary views covering salient information in subsets of the input document (document views); (2) combination of these views into a final summary, following a budget and content guidance. This guidance may come from different sources, including from an advisor model such as BART or BigBird, or in oracle mode – from the reference. This factorization achieves significantly higher ROUGE scores on multiple benchmarks for long document summarization, namely PubMed, arXiv, and GovReport. Most notably, our model is effective for domain adaptation. When trained only on PubMed samples, it achieves a 46.29 ROUGE-1 score on arXiv, outperforming PEGASUS trained in domain by a large margin. Our experimental results indicate that the performance gains are due to more flexible budget adaptation and processing of shorter contexts provided by partial document views",
    "checked": true,
    "id": "65b6753b4ce9036dbb81e4cc9899e895496717fb",
    "semantic_title": "factorizing content and budget decisions in abstractive summarization of long documents",
    "citation_count": 8,
    "authors": [
      "Marcio Fonseca",
      "Yftah Ziser",
      "Shay B. Cohen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.427": {
    "title": "Open-Domain Sign Language Translation Learned from Online Video",
    "volume": "main",
    "abstract": "Existing work on sign language translation – that is, translation from sign language videos into sentences in a written language – has focused mainly on (1) data collected in a controlled environment or (2) data in a specific domain, which limits the applicability to real-world settings. In this paper, we introduce OpenASL, a large-scale American Sign Language (ASL) - English dataset collected from online video sites (e.g., YouTube).OpenASL contains 288 hours of ASL videos in multiple domains from over 200 signers and is the largest publicly available ASL translation dataset to date. To tackle the challenges of sign language translation in realistic settings and without glosses, we propose a set of techniques including sign search as a pretext task for pre-training and fusion of mouthing and handshape features. The proposed techniques produce consistent and large improvements in translation quality, over baseline models basedon prior work",
    "checked": true,
    "id": "9f9bec2b0b27fa6995940fe493418e400ebc7420",
    "semantic_title": "open-domain sign language translation learned from online video",
    "citation_count": 23,
    "authors": [
      "Bowen Shi",
      "Diane Brentari",
      "Gregory Shakhnarovich",
      "Karen Livescu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.428": {
    "title": "Improving Temporal Generalization of Pre-trained Language Models with Lexical Semantic Change",
    "volume": "main",
    "abstract": "Recent research has revealed that neural language models at scale suffer from poor temporal generalization capability, i.e., language model pre-trained on static data from past years performs worse over time on emerging data. Existing methods mainly perform continual training to mitigate such a misalignment. While effective to some extent but is far from being addressed on both the language modeling and downstream tasks. In this paper, we empirically observe that temporal generalization is closely affiliated with lexical semantic change, which is one of the essential phenomena of natural languages. Based on this observation, we propose a simple yet effective lexical-level masking strategy to post-train a converged language model. Experiments on two pre-trained language models, two different classification tasks, and four benchmark datasets demonstrate the effectiveness of our proposed method over existing temporal adaptation methods, i.e., continual training with new data. Our code is available at https://github.com/zhaochen0110/LMLM",
    "checked": true,
    "id": "6a5e1fb8a55cf17cb3142b8829b11e4b3f722157",
    "semantic_title": "improving temporal generalization of pre-trained language models with lexical semantic change",
    "citation_count": 8,
    "authors": [
      "Zhaochen Su",
      "Zecheng Tang",
      "Xinyan Guan",
      "Lijun Wu",
      "Min Zhang",
      "Juntao Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.429": {
    "title": "ULN: Towards Underspecified Vision-and-Language Navigation",
    "volume": "main",
    "abstract": "Vision-and-Language Navigation (VLN) is a task to guide an embodied agent moving to a target position using language instructions. Despite the significant performance improvement, the wide use of fine-grained instructions fails to characterize more practical linguistic variations in reality. To fill in this gap, we introduce a new setting, namely Underspecified vision-and-Language Navigation (ULN), and associated evaluation datasets. ULN evaluates agents using multi-level underspecified instructions instead of purely fine-grained or coarse-grained, which is a more realistic and general setting. As a primary step toward ULN, we propose a VLN framework that consists of a classification module, a navigation agent, and an Exploitation-to-Exploration (E2E) module. Specifically, we propose to learn Granularity Specific Sub-networks (GSS) for the agent to ground multi-level instructions with minimal additional parameters. Then, our E2E module estimates grounding uncertainty and conducts multi-step lookahead exploration to improve the success rate further. Experimental results show that existing VLN models are still brittle to multi-level language underspecification. Our framework is more robust and outperforms the baselines on ULN by ~10% relative success rate across all levels",
    "checked": true,
    "id": "5bcbc760ceb2d288b756965836106005e1f2a271",
    "semantic_title": "uln: towards underspecified vision-and-language navigation",
    "citation_count": 1,
    "authors": [
      "Weixi Feng",
      "Tsu-Jui Fu",
      "Yujie Lu",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.430": {
    "title": "Federated Model Decomposition with Private Vocabulary for Text Classification",
    "volume": "main",
    "abstract": "With the necessity of privacy protection, it becomes increasingly vital to train deep neural models in a federated learning manner for natural language processing (NLP) tasks. However, recent studies show eavesdroppers (i.e., dishonest servers) can still reconstruct the private input in federated learning (FL). Such a data reconstruction attack relies on the mappings between vocabulary and associated word embedding in NLP tasks, which are unfortunately less studied in current FL methods. In this paper, we propose a fedrated model decomposition method that protects the privacy of vocabularies, shorted as FEDEVOCAB. In FEDEVOCAB, each participant keeps the local embedding layer in the local device and detaches the local embedding parameters from federated aggregation. However, it is challenging to train an accurate NLP model when the private mappings are unknown and vary across participants in a cross-device FL setting. To address this problem, we further propose an adaptive updating technique to improve the performance of local models. Experimental results show that FEDEVOCAB maintains competitive performance and provides better privacy-preserving capacity compared to status quo methods",
    "checked": true,
    "id": "93774805d9a8defc6b67d2d82e8a0d7bafbabaf5",
    "semantic_title": "federated model decomposition with private vocabulary for text classification",
    "citation_count": 2,
    "authors": [
      "Zhuo Zhang",
      "Xiangjing Hu",
      "Lizhen Qu",
      "Qifan Wang",
      "Zenglin Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.431": {
    "title": "ReCo: Reliable Causal Chain Reasoning via Structural Causal Recurrent Neural Networks",
    "volume": "main",
    "abstract": "Causal chain reasoning (CCR) is an essential ability for many decision-making AI systems, which requires the model to build reliable causal chains by connecting causal pairs. However, CCR suffers from two main transitive problems: threshold effect and scene drift. In other words, the causal pairs to be spliced may have a conflicting threshold boundary or scenario. To address these issues, we propose a novel Reliable Causal chain reasoning framework (ReCo), which introduces exogenous variables to represent the threshold and scene factors of each causal pair within the causal chain, and estimates the threshold and scene contradictions across exogenous variables via structural causal recurrent neural networks (SRNN). Experiments show that ReCo outperforms a series of strong baselines on both Chinese and English CCR datasets. Moreover, by injecting reliable causal chain knowledge distilled by ReCo, BERT can achieve better performances on four downstream causal-related tasks than BERT models enhanced by other kinds of knowledge",
    "checked": true,
    "id": "0866bf053f0926e115dc2329d4da226a74b10e3e",
    "semantic_title": "reco: reliable causal chain reasoning via structural causal recurrent neural networks",
    "citation_count": 1,
    "authors": [
      "Kai Xiong",
      "Xiao Ding",
      "Zhongyang Li",
      "Li Du",
      "Ting Liu",
      "Bing Qin",
      "Yi Zheng",
      "Baoxing Huai"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.432": {
    "title": "Video Question Answering: Datasets, Algorithms and Challenges",
    "volume": "main",
    "abstract": "This survey aims to sort out the recent advances in video question answering (VideoQA) and point towards future directions. We firstly categorize the datasets into 1) normal VideoQA, multi-modal VideoQA and knowledge-based VideoQA, according to the modalities invoked in the question-answer pairs, or 2) factoid VideoQA and inference VideoQA, according to the technical challenges in comprehending the questions and deriving the correct answers. We then summarize the VideoQA techniques, including those mainly designed for Factoid QA (e.g., the early spatio-temporal attention-based methods and the recently Transformer-based ones) and those targeted at explicit relation and logic inference (e.g., neural modular networks, neural symbolic methods, and graph-structured methods). Aside from the backbone techniques, we delve into the specific models and find out some common and useful insights either for video modeling, question answering, or for cross-modal correspondence learning. Finally, we point out the research trend of studying beyond factoid VideoQA to inference VideoQA, as well as towards the robustness and interpretability. Additionally, we maintain a repository, https://github.com/VRU-NExT/VideoQA, to keep trace of the latest VideoQA papers, datasets, and their open-source implementations if available. With these efforts, we strongly hope this survey could shed light on the follow-up VideoQA research",
    "checked": true,
    "id": "4cb65c1541acde658a95bb8a038cefdade703da5",
    "semantic_title": "video question answering: datasets, algorithms and challenges",
    "citation_count": 46,
    "authors": [
      "Yaoyao Zhong",
      "Wei Ji",
      "Junbin Xiao",
      "Yicong Li",
      "Weihong Deng",
      "Tat-Seng Chua"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.433": {
    "title": "Retrofitting Multilingual Sentence Embeddings with Abstract Meaning Representation",
    "volume": "main",
    "abstract": "We introduce a new method to improve existing multilingual sentence embeddings with Abstract Meaning Representation (AMR). Compared with the original textual input, AMR is a structured semantic representation that presents the core concepts and relations in a sentence explicitly and unambiguously. It also helps reduce the surface variations across different expressions and languages. Unlike most prior work that only evaluates the ability to measure semantic similarity, we present a thorough evaluation of existing multilingual sentence embeddings and our improved versions, which include a collection of five transfer tasks in different downstream applications. Experiment results show that retrofitting multilingual sentence embeddings with AMR leads to better state-of-the-art performance on both semantic textual similarity and transfer tasks",
    "checked": true,
    "id": "37fd65d01fbbde65c02800864c2f32770c30d17f",
    "semantic_title": "retrofitting multilingual sentence embeddings with abstract meaning representation",
    "citation_count": 4,
    "authors": [
      "Deng Cai",
      "Xin Li",
      "Jackie Chun-Sing Ho",
      "Lidong Bing",
      "Wai Lam"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.434": {
    "title": "Breaking the Representation Bottleneck of Chinese Characters: Neural Machine Translation with Stroke Sequence Modeling",
    "volume": "main",
    "abstract": "Existing research generally treats Chinese character as a minimum unit for representation. However, such Chinese character representation will suffer two bottlenecks: 1) Learning bottleneck, the learning cannot benefit from its rich internal features (e.g., radicals and strokes); and 2) Parameter bottleneck, each individual character has to be represented by a unique vector. In this paper, we introduce a novel representation method for Chinese characters to break the bottlenecks, namely StrokeNet, which represents a Chinese character by a Latinized stroke sequence (e.g., \"凹 (concave)\" to \"ajaie\" and \"凸 (convex)\" to \"aeaqe\"). Specifically, StrokeNet maps each stroke to a specific Latin character, thus allowing similar Chinese characters to have similar Latin representations. With the introduction of StrokeNet to neural machine translation (NMT), many powerful but not applicable techniques to non-Latin languages (e.g., shared subword vocabulary learning and ciphertext-based data augmentation) can now be perfectly implemented. Experiments on the widely-used NIST Chinese-English, WMT17 Chinese-English and IWSLT17 Japanese-English NMT tasks show that StrokeNet can provide a significant performance boost over the strong baselines with fewer model parameters, achieving 26.5 BLEU on the WMT17 Chinese-English task which is better than any previously reported results without using monolingual data. Code and scripts are freely available at https://github.com/zjwang21/StrokeNet",
    "checked": true,
    "id": "7abfcf54eeac3a5c298717a4f0fe8a5daceeaa42",
    "semantic_title": "breaking the representation bottleneck of chinese characters: neural machine translation with stroke sequence modeling",
    "citation_count": 7,
    "authors": [
      "Zhijun Wang",
      "Xuebo Liu",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.435": {
    "title": "Boundary-Driven Table-Filling for Aspect Sentiment Triplet Extraction",
    "volume": "main",
    "abstract": "Aspect Sentiment Triplet Extraction (ASTE) aims to extract the aspect terms along with the corresponding opinion terms and the expressed sentiments in the review, which is an important task in sentiment analysis. Previous research efforts generally address the ASTE task in an end-to-end fashion through the table-filling formalization, in which the triplets are represented by a two-dimensional (2D) table of word-pair relations. Under this formalization, a term-level relation is decomposed into multiple independent word-level relations, which leads to relation inconsistency and boundary insensitivity in the face of multi-word aspect terms and opinion terms. To overcome these issues, we propose Boundary-Driven Table-Filling (BDTF), which represents each triplet as a relation region in the 2D table and transforms the ASTE task into detection and classification of relation regions. We also notice that the quality of the table representation greatly affects the performance of BDTF. Therefore, we develop an effective relation representation learning approach to learn the table representation, which can fully exploit both word-to-word interactions and relation-to-relation interactions. Experiments on several public benchmarks show that the proposed approach achieves state-of-the-art performances",
    "checked": true,
    "id": "88b871d7d46c4e52d98e10a3c959f7230331cc5e",
    "semantic_title": "boundary-driven table-filling for aspect sentiment triplet extraction",
    "citation_count": 7,
    "authors": [
      "Yice Zhang",
      "Yifan Yang",
      "Yihui Li",
      "Bin Liang",
      "Shiwei Chen",
      "Yixue Dang",
      "Min Yang",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.436": {
    "title": "Attention and Edge-Label Guided Graph Convolutional Networks for Named Entity Recognition",
    "volume": "main",
    "abstract": "It has been shown that named entity recognition (NER) could benefit from incorporating the long-distance structured information captured by dependency trees. However, dependency trees built by tools usually have a certain percentage of errors. Under such circumstances, how to better use relevant structured information while ignoring irrelevant or wrong structured information from the dependency trees to improve NER performance is still a challenging research problem. In this paper, we propose the Attention and Edge-Label guided Graph Convolution Network (AELGCN) model. Then, we integrate it into BiLSTM-CRF to form BiLSTM-AELGCN-CRF model. We design an edge-aware node joint update module and introduce a node-aware edge update module to explore hidden in structured information entirely and solve the wrong dependency label information to some extent. After two modules, we apply attention-guided GCN, which automatically learns how to attend to the relevant structured information selectively. We conduct extensive experiments on several standard datasets across four languages and achieve better results than previous approaches. Through experimental analysis, it is found that our proposed model can better exploit the structured information on the dependency tree to improve the recognition of long entities",
    "checked": true,
    "id": "801d8588d4ae6938596bcbcafeb0baec0cbcae8f",
    "semantic_title": "attention and edge-label guided graph convolutional networks for named entity recognition",
    "citation_count": 3,
    "authors": [
      "Renjie Zhou",
      "Zhongyi Xie",
      "Jian Wan",
      "Jilin Zhang",
      "Yong Liao",
      "Qiang Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.437": {
    "title": "Title2Event: Benchmarking Open Event Extraction with a Large-scale Chinese Title Dataset",
    "volume": "main",
    "abstract": "Event extraction (EE) is crucial to downstream tasks such as new aggregation and event knowledge graph construction. Most existing EE datasets manually define fixed event types and design specific schema for each of them, failing to cover diverse events emerging from the online text. Moreover, news titles, an important source of event mentions, have not gained enough attention in current EE research. In this paper, we present Title2Event, a large-scale sentence-level dataset benchmarking Open Event Extraction without restricting event types. Title2Event contains more than 42,000 news titles in 34 topics collected from Chinese web pages. To the best of our knowledge, it is currently the largest manually annotated Chinese dataset for open event extraction. We further conduct experiments on Title2Event with different models and show that the characteristics of titles make it challenging for event extraction, addressing the significance of advanced study on this problem. The dataset and baseline codes are available at https://open-event-hub.github.io/title2event",
    "checked": true,
    "id": "04b2e2607000076fd9a3f63b533a0ef8732da6bc",
    "semantic_title": "title2event: benchmarking open event extraction with a large-scale chinese title dataset",
    "citation_count": 4,
    "authors": [
      "Haolin Deng",
      "Yanan Zhang",
      "Yangfan Zhang",
      "Wangyang Ying",
      "Changlong Yu",
      "Jun Gao",
      "Wei Wang",
      "Xiaoling Bai",
      "Nan Yang",
      "Jin Ma",
      "Xiang Chen",
      "Tianhua Zhou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.438": {
    "title": "Cascading Biases: Investigating the Effect of Heuristic Annotation Strategies on Data and Models",
    "volume": "main",
    "abstract": "Cognitive psychologists have documented that humans use cognitive heuristics, or mental shortcuts, to make quick decisions while expending less effort. While performing annotation work on crowdsourcing platforms, we hypothesize that such heuristic use among annotators cascades on to data quality and model robustness. In this work, we study cognitive heuristic use in the context of annotating multiple-choice reading comprehension datasets. We propose tracking annotator heuristic traces, where we tangibly measure low-effort annotation strategies that could indicate usage of various cognitive heuristics. We find evidence that annotators might be using multiple such heuristics, based on correlations with a battery of psychological tests. Importantly, heuristic use among annotators determines data quality along several dimensions: (1) known biased models, such as partial input models, more easily solve examples authoredby annotators that rate highly on heuristic use, (2) models trained on annotators scoring highly on heuristic use don't generalize as well, and (3) heuristic-seeking annotators tend to create qualitatively less challenging examples. Our findings suggest that tracking heuristic usage among annotators can potentially help with collecting challenging datasets and diagnosing model biases",
    "checked": true,
    "id": "4723d7faa58c5541f79058df2813c3b56b94f397",
    "semantic_title": "cascading biases: investigating the effect of heuristic annotation strategies on data and models",
    "citation_count": 4,
    "authors": [
      "Chaitanya Malaviya",
      "Sudeep Bhatia",
      "Mark Yatskar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.439": {
    "title": "Teaching Broad Reasoning Skills for Multi-Step QA by Generating Hard Contexts",
    "volume": "main",
    "abstract": "Question-answering datasets require a broad set of reasoning skills. We show how to use question decompositions to teach language models these broad reasoning skills in a robust fashion. Specifically, we use widely available QDMR representations to programmatically create hard-to-cheat synthetic contexts for real questions in six multi-step reasoning datasets. These contexts are carefully designed to avoid common reasoning shortcuts prevalent in real contexts that prevent models from learning the right skills. This results in a pretraining dataset, named TeaBReaC, containing 525K multi-step questions (with associated formal programs) covering about 900 reasoning patterns. We show that pretraining standard language models (LMs) on TeaBReaC before fine-tuning them on target datasets improves their performance by up to 13 F1 points across 4 multi-step QA datasets, with up to 21 point gain on more complex questions. The resulting models also demonstrate higher robustness, with a 5-8 F1 point improvement on two contrast sets. Furthermore, TeaBReaC pretraining substantially improves model performance and robustness even when starting with numerate LMs pretrained using recent methods (e.g., PReasM, POET). Our work thus shows how to effectively use decomposition-guided contexts to robustly teach multi-step reasoning",
    "checked": true,
    "id": "3bdf6c90c694e7b5900e45e43b1a44fd4f2f0360",
    "semantic_title": "teaching broad reasoning skills for multi-step qa by generating hard contexts",
    "citation_count": 9,
    "authors": [
      "Harsh Trivedi",
      "Niranjan Balasubramanian",
      "Tushar Khot",
      "Ashish Sabharwal"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.440": {
    "title": "ADDMU: Detection of Far-Boundary Adversarial Examples with Data and Model Uncertainty Estimation",
    "volume": "main",
    "abstract": "Adversarial Examples Detection (AED) is a crucial defense technique against adversarial attacks and has drawn increasing attention from the Natural Language Processing (NLP) community. Despite the surge of new AED methods, our studies show that existing methods heavily rely on a shortcut to achieve good performance. In other words, current search-based adversarial attacks in NLP stop once model predictions change, and thus most adversarial examples generated by those attacks are located near model decision boundaries. To surpass this shortcut and fairly evaluate AED methods, we propose to test AED methods with Far Boundary (FB) adversarial examples. Existing methods show worse than random guess performance under this scenario. To overcome this limitation, we propose a new technique, ADDMU, adversary detection with data and model uncertainty, which combines two types of uncertainty estimation for both regular and FB adversarial example detection. Our new method outperforms previous methods by 3.6 and 6.0 AUC points under each scenario. Finally, our analysis shows that the two types of uncertainty provided by ADDMU can be leveraged to characterize adversarialexamples and identify the ones that contribute most to model's robustness in adversarial training",
    "checked": true,
    "id": "589f351653f0daec027f27884eae5c3d3980c329",
    "semantic_title": "addmu: detection of far-boundary adversarial examples with data and model uncertainty estimation",
    "citation_count": 3,
    "authors": [
      "Fan Yin",
      "Yao Li",
      "Cho-Jui Hsieh",
      "Kai-Wei Chang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.441": {
    "title": "G-MAP: General Memory-Augmented Pre-trained Language Model for Domain Tasks",
    "volume": "main",
    "abstract": "General pre-trained language models (PLMs), such as BERT, have achieved remarkable performance on various NLP tasks. Recently, domain-specific PLMs have been proposed to boost the task performance of specific domains (e.g., biomedical and computer science) by continuing to pre-train general PLMs with domain-specific corpora. However, this domain-adaptive pre-training (DAPT (CITATION)) tends to forget the previous general knowledge acquired by general PLMs, which leads to a catastrophic forgetting phenomenon and sub-optimal performance. To alleviate this problem, we propose a new framework of Memory-Augmented Pre-trained Language Model (MAP), which augments the domain-specific PLM by a memory built from the frozen general PLM without losing the general knowledge. Specifically, we propose a new memory-augmented layer, and based on it, different augmentation strategies are explored to build memory and fusion memory into domain-specific PLM. We demonstrate the effectiveness of MAP on different domains (biomedical and computer science publications, news, and reviews) and different kinds (text classification, QA, NER) of tasks, and the extensive results show that the proposed MAP can achieve SOTA results on these tasks",
    "checked": true,
    "id": "86c79317afa13ea4a74f656e3c48f012ee1fc326",
    "semantic_title": "g-map: general memory-augmented pre-trained language model for domain tasks",
    "citation_count": 9,
    "authors": [
      "Zhongwei Wan",
      "Yichun Yin",
      "Wei Zhang",
      "Jiaxin Shi",
      "Lifeng Shang",
      "Guangyong Chen",
      "Xin Jiang",
      "Qun Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.442": {
    "title": "Towards Unifying Reference Expression Generation and Comprehension",
    "volume": "main",
    "abstract": "Reference Expression Generation (REG) and Comprehension (REC) are two highly correlated tasks. Modeling REG and REC simultaneously for utilizing the relation between them is a promising way to improve both. However, the problem of distinct inputs, as well as building connections between them in a single model, brings challenges to the design and training of the joint model. To address the problems, we propose a unified model for REG and REC, named UniRef. It unifies these two tasks with the carefully-designed Image-Region-Text Fusion layer (IRTF), which fuses the image, region and text via the image cross-attention and region cross-attention. Additionally, IRTF could generate pseudo input regions for the REC task to enable a uniform way for sharing the identical representation space across the REC and REG. We further propose Vision-conditioned Masked Language Modeling (VMLM) and Text-Conditioned Region Prediction (TRP) to pre-train UniRef model on multi-granular corpora. The VMLM and TRP are directly related to REG and REC, respectively, but could help each other. We conduct extensive experiments on three benchmark datasets, RefCOCO, RefCOCO+ and RefCOCOg. Experimental results show that our model outperforms previous state-of-the-art methods on both REG and REC",
    "checked": true,
    "id": "2b2048bfe6ffb6cb390aa299ce34687a493f8c2a",
    "semantic_title": "towards unifying reference expression generation and comprehension",
    "citation_count": 3,
    "authors": [
      "Duo Zheng",
      "Tao Kong",
      "Ya Jing",
      "Jiaan Wang",
      "Xiaojie Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.443": {
    "title": "Textual Manifold-based Defense Against Natural Language Adversarial Examples",
    "volume": "main",
    "abstract": "Despite the recent success of large pretrained language models in NLP, they are susceptible to adversarial examples. Concurrently, several studies on adversarial images have observed an intriguing property: the adversarial images tend to leave the low-dimensional natural data manifold. In this study, we find a similar phenomenon occurs in the contextualized embedding space of natural sentences induced by pretrained language models in which textual adversarial examples tend to have their embeddings diverge off the manifold of natural sentence embeddings. Based on this finding, we propose Textual Manifold-based Defense (TMD), a defense mechanism that learns the embedding space manifold of the underlying language model and projects novel inputs back to the approximated structure before classification. Through extensive experiments, we find that our method consistently and significantly outperforms previous defenses under various attack settings while remaining unaffected to the clean accuracy. To the best of our knowledge, this is the first kind of manifold-based defense adapted to the NLP domain",
    "checked": true,
    "id": "877bd47e214b858933a8e4cb53c5d74a1b095fc4",
    "semantic_title": "textual manifold-based defense against natural language adversarial examples",
    "citation_count": 9,
    "authors": [
      "Dang Nguyen Minh",
      "Anh Tuan Luu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.444": {
    "title": "Tiny-Attention Adapter: Contexts Are More Important Than the Number of Parameters",
    "volume": "main",
    "abstract": "Adapter-tuning is a paradigm that transfers a pretrained language model to downstream tasks by adding and tuning a small number of new parameters. Previously proposed adapter architectures are all feed-forward neural networks. In this paper, we investigate the effectiveness of using tiny-attention—i.e., attention with extremely small per-head dimensionality—as adapters. Our tiny-attention adapter learns to modify the hidden states at each position directly conditioned on the hidden states at all the other positions, which is missed by the previously proposed adapters. Moreover, we view its multiple attention heads as a mixture of experts and propose to average their weights during deployment, which further reduces its inference computation cost. On the GLUE benchmark, our tiny-attention adapter outperforms the other parameter-efficient transfer learning methods as well as full fine-tuning while only updating 0.05% of the parameters. On the FewGLUE benchmark, its performance is comparable to that of GPT-3 and PET",
    "checked": true,
    "id": "5c919b3669aaa382daba912be0b6f7f492e6d2ef",
    "semantic_title": "tiny-attention adapter: contexts are more important than the number of parameters",
    "citation_count": 9,
    "authors": [
      "Hongyu Zhao",
      "Hao Tan",
      "Hongyuan Mei"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.445": {
    "title": "Reduce Catastrophic Forgetting of Dense Retrieval Training with Teleportation Negatives",
    "volume": "main",
    "abstract": "In this paper, we investigate the instability in the standard dense retrieval training, which iterates between model training and hard negative selection using the being-trained model. We show the catastrophic forgetting phenomena behind the training instability, where models learn and forget different negative groups during training iterations. We then propose ANCE-Tele, which accumulates momentum negatives from past iterations and approximates future iterations using lookahead negatives, as \"teleportations\" along the time axis to smooth the learning process. On web search and OpenQA, ANCE-Tele outperforms previous state-of-the-art systems of similar size, eliminates the dependency on sparse retrieval negatives, and is competitive among systems using significantly more (50x) parameters. Our analysis demonstrates that teleportation negatives reduce catastrophic forgetting and improve convergence speed for dense retrieval training. The source code of this paper is available at https://github.com/OpenMatch/ANCE-Tele",
    "checked": true,
    "id": "83b8783ac429eafef989dccef4a5911f731a926b",
    "semantic_title": "reduce catastrophic forgetting of dense retrieval training with teleportation negatives",
    "citation_count": 6,
    "authors": [
      "Si Sun",
      "Chenyan Xiong",
      "Yue Yu",
      "Arnold Overwijk",
      "Zhiyuan Liu",
      "Jie Bao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.446": {
    "title": "ATTEMPT: Parameter-Efficient Multi-task Tuning via Attentional Mixtures of Soft Prompts",
    "volume": "main",
    "abstract": "This work introduces a new multi-task, parameter-efficient language model (LM) tuning method that learns to transfer knowledge across different tasks via a mixture of soft prompts—small prefix embedding vectors pre-trained for different tasks. Our method, called ATTEMPT (ATTEntional Mixtures of Prompt Tuning), obtains source prompts as encodings of large-scale source tasks into a small number of parameters and trains an attention module to interpolate the source prompts and a newly initialized target prompt for every instance in the target task. During training, only the target task prompt and the attention weights, which are shared between tasks in multi-task training, are updated, while the original LM and source prompts are intact. ATTEMPT is highly parameter-efficient (e.g., updates 2,300 times fewer parameters than full fine-tuning), while it overcomes instability of prompt tuning and achieves high task performance using learned knowledge from high-resource tasks. Moreover, it is modular using pre-trained soft prompts, and can flexibly add or remove source prompts for effective knowledge transfer. Our experimental results across 21 diverse NLP datasets show that ATTEMPT significantly outperforms prompt tuning and outperforms or matches fully fine-tuned or other parameter-efficient tuning approaches that use 10 times more parameters. Finally, ATTEMPT outperforms previous work in few-shot learning settings",
    "checked": true,
    "id": "55a250868627de2d202d06e7cb3f6cbcd3a66f88",
    "semantic_title": "attempt: parameter-efficient multi-task tuning via attentional mixtures of soft prompts",
    "citation_count": 53,
    "authors": [
      "Akari Asai",
      "Mohammadreza Salehi",
      "Matthew Peters",
      "Hannaneh Hajishirzi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.447": {
    "title": "Exploration of the Usage of Color Terms by Color-blind Participants in Online Discussion Platforms",
    "volume": "main",
    "abstract": "Prominent questions about the role of sensory vs. linguistic input in the way we acquire and use language have been extensively studied in the psycholinguistic literature. However, the relative effect of various factors in a person's overall experience on their linguistic system remains unclear. We study this question by making a step forward towards a better understanding of the conceptual perception of colors by color-blind individuals, as reflected in their spontaneous linguistic productions. Using a novel and carefully curated dataset, we show that red-green color-blind speakers use the \"red\" and \"green\" color terms in less predictable contexts, and in linguistic environments evoking mental image to a lower extent, when compared to their normal-sighted counterparts. These findings shed some new and interesting light on the role of sensory experience on our linguistic system",
    "checked": true,
    "id": "8604dfa846e15839141dd89f80e223d19af513ef",
    "semantic_title": "exploration of the usage of color terms by color-blind participants in online discussion platforms",
    "citation_count": 1,
    "authors": [
      "Ella Rabinovich",
      "Boaz Carmeli"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.448": {
    "title": "DEER: Descriptive Knowledge Graph for Explaining Entity Relationships",
    "volume": "main",
    "abstract": "We propose DEER (Descriptive Knowledge Graph for Explaining Entity Relationships) - an open and informative form of modeling entity relationships. In DEER, relationships between entities are represented by free-text relation descriptions. For instance, the relationship between entities of machine learning and algorithm can be represented as \"Machine learning explores the study and construction of algorithms that can learn from and make predictions on data.\" To construct DEER, we propose a self-supervised learning method to extract relation descriptions with the analysis of dependency patterns and generate relation descriptions with a transformer-based relation description synthesizing model, where no human labeling is required. Experiments demonstrate that our system can extract and generate high-quality relation descriptions for explaining entity relationships. The results suggest that we can build an open and informative knowledge graph without human annotation",
    "checked": true,
    "id": "f0575b2b10e2178f9675a6d92ab7cb80015948d0",
    "semantic_title": "deer: descriptive knowledge graph for explaining entity relationships",
    "citation_count": 7,
    "authors": [
      "Jie Huang",
      "Kerui Zhu",
      "Kevin Chen-Chuan Chang",
      "Jinjun Xiong",
      "Wen-mei Hwu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.449": {
    "title": "META-GUI: Towards Multi-modal Conversational Agents on Mobile GUI",
    "volume": "main",
    "abstract": "Task-oriented dialogue (TOD) systems have been widely used by mobile phone intelligent assistants to accomplish tasks such as calendar scheduling or hotel reservation. Current TOD systems usually focus on multi-turn text/speech interaction, then they would call back-end APIs designed for TODs to perform the task. However, this API-based architecture greatly limits the information-searching capability of intelligent assistants and may even lead to task failure if TOD-specific APIs are not available or the task is too complicated to be executed by the provided APIs. In this paper, we propose a new TOD architecture: GUI-based task-oriented dialogue system (GUI-TOD). A GUI-TOD system can directly perform GUI operations on real APPs and execute tasks without invoking TOD-specific backend APIs. Furthermore, we release META-GUI, a dataset for training a Multi-modal convErsaTional Agent on mobile GUI. We also propose a multi-model action prediction and response model, which show promising results on META-GUI. The dataset, codes and leaderboard are publicly available",
    "checked": true,
    "id": "780d4919f861ca68825d264bccf47411772e17c0",
    "semantic_title": "meta-gui: towards multi-modal conversational agents on mobile gui",
    "citation_count": 17,
    "authors": [
      "Liangtai Sun",
      "Xingyu Chen",
      "Lu Chen",
      "Tianle Dai",
      "Zichen Zhu",
      "Kai Yu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.450": {
    "title": "Understanding and Improving Knowledge Distillation for Quantization Aware Training of Large Transformer Encoders",
    "volume": "main",
    "abstract": "Knowledge distillation (KD) has been a ubiquitous method for model compression to strengthen the capability of a lightweight model with the transferred knowledge from the teacher. In particular, KD has been employed in quantization-aware training (QAT) of Transformer encoders like BERT to improve the accuracy of the student model with the reduced-precision weight parameters. However, little is understood about which of the various KD approaches best fits the QAT of Transformers. In this work, we provide an in-depth analysis of the mechanism of KD on attention recovery of quantized large Transformers. In particular, we reveal that the previously adopted MSE loss on the attention score is insufficient for recovering the self-attention information. Therefore, we propose two KD methods; attention-map and attention-output losses. Furthermore, we explore the unification of both losses to address task-dependent preference between attention-map and output losses. The experimental results on various Transformer encoder models demonstrate that the proposed KD methods achieve state-of-the-art accuracy for QAT with sub-2-bit weight quantization",
    "checked": true,
    "id": "f7655ff2b53e4c87645d85297f994d33e7e4a92b",
    "semantic_title": "understanding and improving knowledge distillation for quantization aware training of large transformer encoders",
    "citation_count": 8,
    "authors": [
      "Minsoo Kim",
      "Sihwa Lee",
      "Suk-Jin Hong",
      "Du-Seong Chang",
      "Jungwook Choi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.451": {
    "title": "Exploring Mode Connectivity for Pre-trained Language Models",
    "volume": "main",
    "abstract": "Recent years have witnessed the prevalent application of pre-trained language models (PLMs) in NLP. From the perspective of parameter space, PLMs provide generic initialization, starting from which high-performance minima could be found. Although plenty of works have studied how to effectively and efficiently adapt PLMs to high-performance minima, little is known about the connection of various minima reached under different adaptation configurations. In this paper, we investigate the geometric connections of different minima through the lens of mode connectivity, which measures whether two minima can be connected with a low-loss path. We conduct empirical analyses to investigate three questions: (1) how could hyperparameters, specific tuning methods, and training data affect PLM's mode connectivity? (2) How does mode connectivity change during pre-training? (3) How does the PLM's task knowledge change along the path connecting two minima? In general, exploring the mode connectivity of PLMs conduces to understanding the geometric connection of different minima, which may help us fathom the inner workings of PLM downstream adaptation. The codes are publicly available at https://github.com/thunlp/Mode-Connectivity-PLM",
    "checked": true,
    "id": "02c873a69b8702e3848f942fefb7437ec012422c",
    "semantic_title": "exploring mode connectivity for pre-trained language models",
    "citation_count": 12,
    "authors": [
      "Yujia Qin",
      "Cheng Qian",
      "Jing Yi",
      "Weize Chen",
      "Yankai Lin",
      "Xu Han",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.452": {
    "title": "Synergy with Translation Artifacts for Training and Inference in Multilingual Tasks",
    "volume": "main",
    "abstract": "Translation has played a crucial role in improving the performance on multilingual tasks: (1) to generate the target language data from the source language data for training and (2) to generate the source language data from the target language data for inference. However, prior works have not considered the use of both translations simultaneously. This paper shows that combining them can synergize the results on various multilingual sentence classification tasks. We empirically find that translation artifacts stylized by translators are the main factor of the performance gain. Based on this analysis, we adopt two training methods, SupCon and MixUp, considering translation artifacts. Furthermore, we propose a cross-lingual fine-tuning algorithm called MUSC, which uses SupCon and MixUp jointly and improves the performance. Our code is available at https://github.com/jongwooko/MUSC",
    "checked": true,
    "id": "5702dd4a04e9c998c018d58164bafedd55da0b85",
    "semantic_title": "synergy with translation artifacts for training and inference in multilingual tasks",
    "citation_count": 3,
    "authors": [
      "Jaehoon Oh",
      "Jongwoo Ko",
      "Se-Young Yun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.453": {
    "title": "Increasing Visual Awareness in Multimodal Neural Machine Translation from an Information Theoretic Perspective",
    "volume": "main",
    "abstract": "Multimodal machine translation (MMT) aims to improve translation quality by equipping the source sentence with its corresponding image. Despite the promising performance, MMT models still suffer the problem of input degradation: models focus more on textual information while visual information is generally overlooked. In this paper, we endeavor to improve MMT performance by increasing visual awareness from an information theoretic perspective. In detail, we decompose the informative visual signals into two parts: source-specific information and target-specific information. We use mutual information to quantify them and propose two methods for objective optimization to better leverage visual signals. Experiments on two datasets demonstrate that our approach can effectively enhance the visual awareness of MMT model and achieve superior results against strong baselines",
    "checked": true,
    "id": "8e1b951309ca6a5925d056d5b2a89a4f678480c0",
    "semantic_title": "increasing visual awareness in multimodal neural machine translation from an information theoretic perspective",
    "citation_count": 8,
    "authors": [
      "Baijun Ji",
      "Tong Zhang",
      "Yicheng Zou",
      "Bojie Hu",
      "Si Shen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.454": {
    "title": "Improving Event Coreference Resolution Using Document-level and Topic-level Information",
    "volume": "main",
    "abstract": "Event coreference resolution (ECR) aims to cluster event mentions that refer to the same real-world events. Deep learning methods have achieved SOTA results on the ECR task. However, due to the encoding length limitation, previous methods either adopt classical pairwise models based on sentence-level context or split each document into multiple chunks and encode them separately. They failed to capture the interactions and contextual cues among those long-distance event mentions. Besides, high-level information, such as event topics, is rarely considered to enhance representation learning for ECR. To address the above two issues, we first apply a Longformer-based encoder to obtain the document-level embeddings and an encoder with a trigger-mask mechanism to learn sentence-level embeddings based on local context. In addition, we propose an event topic generator to infer the latent topic-level representations. Finally, using the above event embeddings, we employ a multiple tensor matching method to capture their interactions at the document, sentence, and topic levels. Experimental results on the KBP 2017 dataset show that our model outperforms the SOTA baselines",
    "checked": true,
    "id": "4ac4f24fa28d69838b2a74bf5ab411bc993e688c",
    "semantic_title": "improving event coreference resolution using document-level and topic-level information",
    "citation_count": 3,
    "authors": [
      "Sheng Xu",
      "Peifeng Li",
      "Qiaoming Zhu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.455": {
    "title": "Vector-Quantized Input-Contextualized Soft Prompts for Natural Language Understanding",
    "volume": "main",
    "abstract": "Prompt Tuning has been largely successful as a parameter-efficient method of conditioning large-scale pre-trained language models to perform downstream tasks. Thus far, soft prompt tuning learns a fixed set of task-specific continuous vectors, i.e., soft tokens that remain static across the task samples. A fixed prompt, however, may not generalize well to the diverse kinds of inputs the task comprises. In order to address this, we propose Vector-quantized Input-contextualized Prompts (VIP) as an extension to the soft prompt tuning framework. VIP particularly focuses on two aspects—contextual prompts that learns input-specific contextualization of the soft prompt tokens through a small-scale sentence encoder and quantized prompts that maps the contextualized prompts to a set of learnable codebook vectors through a Vector quantization network. On various language understanding tasks like SuperGLUE, QA, Relation classification, NER and NLI, VIP outperforms the soft prompt tuning (PT) baseline by an average margin of 1.19%. Further, our generalization studies show that VIP learns more robust prompt representations, surpassing PT by a margin of 0.6% - 5.3% on Out-of-domain QA and NLI tasks respectively, and by 0.75% on Multi-Task setup over 4 tasks spanning across 12 domains",
    "checked": true,
    "id": "5bdb78fb79e54679a8bb45b05f77a8bf5989cfdf",
    "semantic_title": "vector-quantized input-contextualized soft prompts for natural language understanding",
    "citation_count": 5,
    "authors": [
      "Rishabh Bhardwaj",
      "Amrita Saha",
      "Steven C.H. Hoi",
      "Soujanya Poria"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.456": {
    "title": "Boosting Natural Language Generation from Instructions with Meta-Learning",
    "volume": "main",
    "abstract": "Recent work has shown that language models (LMs) trained with multi-task instructional learning (MTIL) can solve diverse NLP tasks in zero- and few-shot settings with improved performance compared to prompt tuning. MTIL illustrates that LMs can extract and use information about the task from instructions beyond the surface patterns of the inputs and outputs. This suggests that meta-learning may further enhance the utilization of instructions for effective task transfer. In this paper we investigate whether meta-learning applied to MTIL can further improve generalization to unseen tasks in a zero-shot setting. Specifically, we propose to adapt meta-learning to MTIL in three directions: 1) Model Agnostic Meta Learning (MAML), 2) Hyper-Network (HNet) based adaptation to generate task specific parameters conditioned on instructions, and 3) an approach combining HNet and MAML. Through extensive experiments on the large scale Natural Instructions V2 dataset, we show that our proposed approaches significantly improve over strong baselines in zero-shot settings. In particular, meta-learning improves the effectiveness of instructions and is most impactful when the test tasks are strictly zero-shot (i.e. no similar tasks in the training set) and are \"hard\" for LMs, illustrating the potential of meta-learning for MTIL for out-of-distribution tasks",
    "checked": true,
    "id": "3c414e3125c12dbd23f62e6c1b85c1a4dc9a522e",
    "semantic_title": "boosting natural language generation from instructions with meta-learning",
    "citation_count": 8,
    "authors": [
      "Budhaditya Deb",
      "Ahmed Hassan Awadallah",
      "Guoqing Zheng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.457": {
    "title": "Topical Segmentation of Spoken Narratives: A Test Case on Holocaust Survivor Testimonies",
    "volume": "main",
    "abstract": "The task of topical segmentation is well studied, but previous work has mostly addressed it in the context of structured, well-defined segments, such as segmentation into paragraphs, chapters, or segmenting text that originated from multiple sources. We tackle the task of segmenting running (spoken) narratives, which poses hitherto unaddressed challenges. As a test case, we address Holocaust survivor testimonies, given in English. Other than the importance of studying these testimonies for Holocaust research, we argue that they provide an interesting test case for topical segmentation, due to their unstructured surface level, relative abundance (tens of thousands of such testimonies were collected), and the relatively confined domain that they cover. We hypothesize that boundary points between segments correspond to low mutual information between the sentences proceeding and following the boundary. Based on this hypothesis, we explore a range of algorithmic approaches to the task, building on previous work on segmentation that uses generative Bayesian modeling and state-of-the-art neural machinery. Compared to manually annotated references, we find that the developed approaches show considerable improvements over previous work",
    "checked": true,
    "id": "29a037e391f29fed7a01f31a52d850eaeae8644a",
    "semantic_title": "topical segmentation of spoken narratives: a test case on holocaust survivor testimonies",
    "citation_count": 0,
    "authors": [
      "Eitan Wagner",
      "Renana Keydar",
      "Amit Pinchevski",
      "Omri Abend"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.458": {
    "title": "Unifying the Convergences in Multilingual Neural Machine Translation",
    "volume": "main",
    "abstract": "Although all-in-one-model multilingual neural machine translation (MNMT) has achieved remarkable progress, the convergence inconsistency in the joint training is ignored, i.e., different language pairs reaching convergence in different epochs. This leads to the trained MNMT model over-fitting low-resource language translations while under-fitting high-resource ones. In this paper, we propose a novel training strategy named LSSD (LanguageSpecific Self-Distillation), which can alleviate the convergence inconsistency and help MNMT models achieve the best performance on each language pair simultaneously. Specifically, LSSD picks up language-specific best checkpoints for each language pair to teach the current model on the fly. Furthermore, we systematically explore three sample-level manipulations of knowledge transferring. Experimental results on three datasets show that LSSD obtains consistent improvements towards all language pairs and achieves the state-of-the-art",
    "checked": true,
    "id": "1f32937d02f8e2665af37f7939bf6a556c7ca07b",
    "semantic_title": "unifying the convergences in multilingual neural machine translation",
    "citation_count": 5,
    "authors": [
      "Yichong Huang",
      "Xiaocheng Feng",
      "Xinwei Geng",
      "Bing Qin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.459": {
    "title": "Modeling Label Correlations for Ultra-Fine Entity Typing with Neural Pairwise Conditional Random Field",
    "volume": "main",
    "abstract": "Ultra-fine entity typing (UFET) aims to predict a wide range of type phrases that correctly describe the categories of a given entity mention in a sentence. Most recent works infer each entity type independently, ignoring the correlations between types, e.g., when an entity is inferred as a president, it should also be a politician and a leader. To this end, we use an undirected graphical model called pairwise conditional random field (PCRF) to formulate the UFET problem, in which the type variables are not only unarily influenced by the input but also pairwisely relate to all the other type variables. We use various modern backbones for entity typing to compute unary potentials, and derive pairwise potentials from type phrase representations that both capture prior semantic information and facilitate accelerated inference. We use mean-field variational inference for efficient type inference on very large type sets and unfold it as a neural network module to enable end-to-end training. Experiments on UFET show that the Neural-PCRF consistently outperforms its backbones with little cost and results in a competitive performance against cross-encoder based SOTA while being thousands of times faster. We also find Neural-PCRF effective on a widely used fine-grained entity typing dataset with a smaller type set. We pack Neural-PCRF as a network module that can be plugged onto multi-label type classifiers with ease and release it in",
    "checked": true,
    "id": "1e87aefc92004a0e4000bb0fa2f5351c3644e8e7",
    "semantic_title": "modeling label correlations for ultra-fine entity typing with neural pairwise conditional random field",
    "citation_count": 5,
    "authors": [
      "Chengyue Jiang",
      "Yong Jiang",
      "Weiqi Wu",
      "Pengjun Xie",
      "Kewei Tu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.460": {
    "title": "Help me write a Poem - Instruction Tuning as a Vehicle for Collaborative Poetry Writing",
    "volume": "main",
    "abstract": "Recent work in training large language models (LLMs) to follow natural language instructions has opened up exciting opportunities for natural language interface design. Building on the prior success of large language models in the realm of computer assisted creativity, in this work, we present CoPoet, a collaborative poetry writing system, with the goal of to study if LLM's actually improve the quality of the generated content. In contrast to auto-completing a user's text, CoPoet is controlled by user instructions that specify the attributes of the desired text, such as Write a sentence about ‘love' or Write a sentence ending in ‘fly'. The core component of our system is a language model fine-tuned on a diverse collection of instructions for poetry writing. Our model is not only competitive to publicly available LLMs trained on instructions (InstructGPT), but also capable of satisfying unseen compositional instructions. A study with 15 qualified crowdworkers shows that users successfully write poems with CoPoet on diverse topics ranging from Monarchy to Climate change, which are preferred by third-party evaluators over poems written without the system",
    "checked": true,
    "id": "77a94f6c91ee1590dd2c6fd80b4a6d8bffdb91ac",
    "semantic_title": "help me write a poem - instruction tuning as a vehicle for collaborative poetry writing",
    "citation_count": 37,
    "authors": [
      "Tuhin Chakrabarty",
      "Vishakh Padmakumar",
      "He He"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.461": {
    "title": "Open Relation and Event Type Discovery with Type Abstraction",
    "volume": "main",
    "abstract": "Conventional \"closed-world\" information extraction (IE) approaches rely on human ontologies to define the scope for extraction. As a result, such approaches fall short when applied to new domains. This calls for systems that can automatically infer new types from given corpora, a task which we refer to as type discovery. To tackle this problem, we introduce the idea of type abstraction, where the model is prompted to generalize and name the type. Then we use the similarity between inferred names to induce clusters. Observing that this abstraction-based representation is often complementary to the entity/trigger token representation, we set up these two representations as two views and design our model as a co-training framework. Our experiments on multiple relation extraction and event extraction datasets consistently show the advantage of our type abstraction approach",
    "checked": true,
    "id": "00971ecf9ea497286c0c454b34ff4ff355170df2",
    "semantic_title": "open relation and event type discovery with type abstraction",
    "citation_count": 7,
    "authors": [
      "Sha Li",
      "Heng Ji",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.462": {
    "title": "Enhancing Multilingual Language Model with Massive Multilingual Knowledge Triples",
    "volume": "main",
    "abstract": "Knowledge-enhanced language representation learning has shown promising results across various knowledge-intensive NLP tasks. However, prior methods are limited in efficient utilization of multilingual knowledge graph (KG) data for language model (LM) pretraining. They often train LMs with KGs in indirect ways, relying on extra entity/relation embeddings to facilitate knowledge injection. In this work, we explore methods to make better use of the multilingual annotation and language agnostic property of KG triples, and present novel knowledge based multilingual language models (KMLMs) trained directly on the knowledge triples. We first generate a large amount of multilingual synthetic sentences using the Wikidata KG triples. Then based on the intra- and inter-sentence structures of the generated data, we design pretraining tasks to enable the LMs to not only memorize the factual knowledge but also learn useful logical patterns. Our pretrained KMLMs demonstrate significant performance improvements on a wide range of knowledge-intensive cross-lingual tasks, including named entity recognition (NER), factual knowledge retrieval, relation classification, and a newly designed logical reasoning task",
    "checked": true,
    "id": "a466d10b80dbdee3b130bef73ec62f3a89eb389b",
    "semantic_title": "enhancing multilingual language model with massive multilingual knowledge triples",
    "citation_count": 12,
    "authors": [
      "Linlin Liu",
      "Xin Li",
      "Ruidan He",
      "Lidong Bing",
      "Shafiq Joty",
      "Luo Si"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.463": {
    "title": "Revisiting Grammatical Error Correction Evaluation and Beyond",
    "volume": "main",
    "abstract": "Pretraining-based (PT-based) automatic evaluation metrics (e.g., BERTScore and BARTScore) have been widely used in several sentence generation tasks (e.g., machine translation and text summarization) due to their better correlation with human judgments over traditional overlap-based methods. Although PT-based methods have become the de facto standard for training grammatical error correction (GEC) systems, GEC evaluation still does not benefit from pretrained knowledge. This paper takes the first step towards understanding and improving GEC evaluation with pretraining. We first find that arbitrarily applying PT-based metrics to GEC evaluation brings unsatisfactory correlation results because of the excessive attention to inessential systems outputs (e.g., unchanged parts). To alleviate the limitation, we propose a novel GEC evaluation metric to achieve the best of both worlds, namely PT-M2 which only uses PT-based metrics to score those corrected parts. Experimental results on the CoNLL14 evaluation task show that PT-M2 significantly outperforms existing methods, achieving a new state-of-the-art result of 0.949 Pearson correlation. Further analysis reveals that PT-M2 is robust to evaluate competitive GEC systems. Source code and scripts are freely available at https://github.com/pygongnlp/PT-M2",
    "checked": true,
    "id": "c84165f7601871997f795357c55d12523b31f3e4",
    "semantic_title": "revisiting grammatical error correction evaluation and beyond",
    "citation_count": 9,
    "authors": [
      "Peiyuan Gong",
      "Xuebo Liu",
      "Heyan Huang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.464": {
    "title": "R2D2: Robust Data-to-Text with Replacement Detection",
    "volume": "main",
    "abstract": "Unfaithful text generation is a common problem for text generation systems. In the case of Data-to-Text (D2T) systems, the factuality of the generated text is particularly crucial for any real-world applications. We introduce R2D2, a training framework that addresses unfaithful Data-to-Text generation by training a system both as a generator and a faithfulness discriminator with additional replacement detection and unlikelihood learning tasks. To facilitate such training, we propose two methods for sampling unfaithful sentences. We argue that the poor entity retrieval capability of D2T systems is one of the primary sources of unfaithfulness, so in addition to the existing metrics, we further propose named entity based metrics to evaluate the fidelity of D2T generations. Our experimental results show that R2D2 systems could effectively mitigate the unfaithful text generation, and they achieve new state-of-theart results on FeTaQA, LogicNLG, and ToTTo, all with significant improvements",
    "checked": true,
    "id": "4c9c07ae5d81e067d3b1ecaf18a0ddcbea213fa3",
    "semantic_title": "r2d2: robust data-to-text with replacement detection",
    "citation_count": 8,
    "authors": [
      "Linyong Nan",
      "Lorenzo Jaime Flores",
      "Yilun Zhao",
      "Yixin Liu",
      "Luke Benson",
      "Weijin Zou",
      "Dragomir Radev"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.465": {
    "title": "IDK-MRC: Unanswerable Questions for Indonesian Machine Reading Comprehension",
    "volume": "main",
    "abstract": "Machine Reading Comprehension (MRC) has become one of the essential tasks in Natural Language Understanding (NLU) as it is often included in several NLU benchmarks (Liang et al., 2020; Wilie et al., 2020). However, most MRC datasets only have answerable question type, overlooking the importance of unanswerable questions. MRC models trained only on answerable questions will select the span that is most likely to be the answer, even when the answer does not actually exist in the given passage (Rajpurkar et al., 2018). This problem especially remains in medium- to low-resource languages like Indonesian. Existing Indonesian MRC datasets (Purwarianti et al., 2007; Clark et al., 2020) are still inadequate because of the small size and limited question types, i.e., they only cover answerable questions. To fill this gap, we build a new Indonesian MRC dataset called I(n)don'tKnow- MRC (IDK-MRC) by combining the automatic and manual unanswerable question generation to minimize the cost of manual dataset construction while maintaining the dataset quality. Combined with the existing answerable questions, IDK-MRC consists of more than 10K questions in total. Our analysis shows that our dataset significantly improves the performance of Indonesian MRC models, showing a large improvement for unanswerable questions",
    "checked": true,
    "id": "4b14fb1ae60ceeaec9ccbf2c03475d324de507b2",
    "semantic_title": "idk-mrc: unanswerable questions for indonesian machine reading comprehension",
    "citation_count": 6,
    "authors": [
      "Rifki Afina Putri",
      "Alice Oh"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.466": {
    "title": "XLM-D: Decorate Cross-lingual Pre-training Model as Non-Autoregressive Neural Machine Translation",
    "volume": "main",
    "abstract": "Pre-training language models have achieved thriving success in numerous natural language understanding and autoregressive generation tasks, but non-autoregressive generation in applications such as machine translation has not sufficiently benefited from the pre-training paradigm. In this work, we establish the connection between a pre-trained masked language model (MLM) and non-autoregressive generation on machine translation. From this perspective, we present XLM-D, which seamlessly transforms an off-the-shelf cross-lingual pre-training model into a non-autoregressive translation (NAT) model with a lightweight yet effective decorator. Specifically, the decorator ensures the representation consistency of the pre-trained model and brings only one additional trainable parameter. Extensive experiments on typical translation datasets show that our models obtain state-of-the-art performance while realizing the inference speed-up by 19.9x. One striking result is that on WMT14 En-De, our XLM-D obtains 29.80 BLEU points with multiple iterations, which outperforms the previous mask-predict model by 2.77 points",
    "checked": true,
    "id": "83a83b9614e0bea67d2c259ca4f4c09c96cad01f",
    "semantic_title": "xlm-d: decorate cross-lingual pre-training model as non-autoregressive neural machine translation",
    "citation_count": 3,
    "authors": [
      "Yong Wang",
      "Shilin He",
      "Guanhua Chen",
      "Yun Chen",
      "Daxin Jiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.467": {
    "title": "Cross-stitching Text and Knowledge Graph Encoders for Distantly Supervised Relation Extraction",
    "volume": "main",
    "abstract": "Bi-encoder architectures for distantly-supervised relation extraction are designed to make use of the complementary information found in text and knowledge graphs (KG).However, current architectures suffer from two drawbacks. They either do not allow any sharing between the text encoder and the KG encoder at all, or, in case of models with KG-to-text attention, only share information in one direction. Here, we introduce cross-stitch bi-encoders, which allow full interaction between the text encoder and the KG encoder via a cross-stitch mechanism. The cross-stitch mechanism allows sharing and updating representations between the two encoders at any layer, with the amount of sharing being dynamically controlled via cross-attention-based gates. Experimental results on two relation extraction benchmarks from two different domains show that enabling full interaction between the two encoders yields strong improvements",
    "checked": true,
    "id": "10f3cf6dc50f9d52a313481f103daf959d567479",
    "semantic_title": "cross-stitching text and knowledge graph encoders for distantly supervised relation extraction",
    "citation_count": 3,
    "authors": [
      "Qin Dai",
      "Benjamin Heinzerling",
      "Kentaro Inui"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.468": {
    "title": "Assist Non-native Viewers: Multimodal Cross-Lingual Summarization for How2 Videos",
    "volume": "main",
    "abstract": "Multimodal summarization for videos aims to generate summaries from multi-source information (videos, audio transcripts), which has achieved promising progress. However, existing works are restricted to monolingual video scenarios, ignoring the demands of non-native video viewers to understand the cross-language videos in practical applications. It stimulates us to propose a new task, named Multimodal Cross-Lingual Summarization for videos (MCLS), which aims to generate cross-lingual summaries from multimodal inputs of videos. First, to make it applicable to MCLS scenarios, we conduct a Video-guided Dual Fusion network (VDF) that integrates multimodal and cross-lingual information via diverse fusion strategies at both encoder and decoder. Moreover, to alleviate the problem of high annotation costs and limited resources in MCLS, we propose a triple-stage training framework to assist MCLS by transferring the knowledge from monolingual multimodal summarization data, which includes: 1) multimodal summarization on sufficient prevalent language videos with a VDF model; 2) knowledge distillation (KD) guided adjustment on bilingual transcripts; 3) multimodal summarization for cross-lingual videos with a KD induced VDF model. Experiment results on the reorganized How2 dataset show that the VDF model alone outperforms previous methods for multimodal summarization, and the performance further improves by a large margin via the proposed triple-stage training framework",
    "checked": true,
    "id": "04e4b7e12e940856b26a5c4cc4e01ae7cb651654",
    "semantic_title": "assist non-native viewers: multimodal cross-lingual summarization for how2 videos",
    "citation_count": 5,
    "authors": [
      "Nayu Liu",
      "Kaiwen Wei",
      "Xian Sun",
      "Hongfeng Yu",
      "Fanglong Yao",
      "Li Jin",
      "Guo Zhi",
      "Guangluan Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.469": {
    "title": "PACIFIC: Towards Proactive Conversational Question Answering over Tabular and Textual Data in Finance",
    "volume": "main",
    "abstract": "To facilitate conversational question answering (CQA) over hybrid contexts in finance, we present a new dataset, named PACIFIC. Compared with existing CQA datasets, PACIFIC exhibits three key features: (i) proactivity, (ii) numerical reasoning, and (iii) hybrid context of tables and text. A new task is defined accordingly to study Proactive Conversational Question Answering (PCQA), which combines clarification question generation and CQA. In addition, we propose a novel method, namely UniPCQA, to adapt a hybrid format of input and output content in PCQA into the Seq2Seq problem, including the reformulation of the numerical reasoning process as code generation. UniPCQA performs multi-task learning over all sub-tasks in PCQA and incorporates a simple ensemble strategy to alleviate the error propagation issue in the multi-task learning by cross-validating top-k sampled Seq2Seq outputs. We benchmark the PACIFIC dataset with extensive baselines and provide comprehensive evaluations on each sub-task of PCQA",
    "checked": true,
    "id": "87a31b729295a3357949683276a2625288fdd0f0",
    "semantic_title": "pacific: towards proactive conversational question answering over tabular and textual data in finance",
    "citation_count": 20,
    "authors": [
      "Yang Deng",
      "Wenqiang Lei",
      "Wenxuan Zhang",
      "Wai Lam",
      "Tat-Seng Chua"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.470": {
    "title": "Generative Data Augmentation with Contrastive Learning for Zero-Shot Stance Detection",
    "volume": "main",
    "abstract": "Stance detection aims to identify whether the author of an opinionated text is in favor of, against, or neutral towards a given target. Remarkable success has been achieved when sufficient labeled training data is available. However, it is labor-intensive to annotate sufficient data and train the model for every new target. Therefore, zero-shot stance detection, aiming at identifying stances of unseen targets with seen targets, has gradually attracted attention. Among them, one of the important challenges is to reduce the domain transfer between seen and unseen targets. To tackle this problem, we propose a generative data augmentation approach to generate training samples containing targets and stances for testing data, and map the real samples and generated synthetic samples into the same embedding space with contrastive learning, then perform the final classification based on the augmented data. We evaluate our proposed model on two benchmark datasets. Experimental results show that our approach achieves state-of-the-art performance on most topics in the task of zero-shot stance detection",
    "checked": true,
    "id": "ef8332d6298c4b22215f35116e80c0a0bbc9db68",
    "semantic_title": "generative data augmentation with contrastive learning for zero-shot stance detection",
    "citation_count": 3,
    "authors": [
      "Yang Li",
      "Jiawei Yuan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.471": {
    "title": "Better Few-Shot Relation Extraction with Label Prompt Dropout",
    "volume": "main",
    "abstract": "Few-shot relation extraction aims to learn to identify the relation between two entities based on very limited training examples. Recent efforts found that textual labels (i.e., relation names and relation descriptions) could be extremely useful for learning class representations, which will benefit the few-shot learning task. However, what is the best way to leverage such label information in the learning process is an important research question. Existing works largely assume such textual labels are always present during both learning and prediction. In this work, we argue that such approaches may not always lead to optimal results. Instead, we present a novel approach called label prompt dropout, which randomly removes label descriptions in the learning process. Our experiments show that our approach is able to lead to improved class representations, yielding significantly better results on the few-shot relation extraction task",
    "checked": true,
    "id": "faf73f722cb72f6fd4a0ebf9646f5e3407a72609",
    "semantic_title": "better few-shot relation extraction with label prompt dropout",
    "citation_count": 10,
    "authors": [
      "Peiyuan Zhang",
      "Wei Lu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.472": {
    "title": "Break it Down into BTS: Basic, Tiniest Subword Units for Korean",
    "volume": "main",
    "abstract": "We introduce Basic, Tiniest Subword (BTS) units for the Korean language, which are inspired by the invention principle of Hangeul, the Korean writing system. Instead of relying on 51 Korean consonant and vowel letters, we form the letters from BTS units by adding strokes or combining them. To examine the impact of BTS units on Korean language processing, we develop a novel BTS-based word embedding framework that is readily applicable to various models. Our experiments reveal that BTS units significantly improve the performance of Korean word embedding on all intrinsic and extrinsic tasks in our evaluation. In particular, BTS-based word embedding outperforms the state-of-theart Korean word embedding by 11.8% in word analogy. We further investigate the unique advantages provided by BTS units through indepth analysis",
    "checked": true,
    "id": "fd4274bd2d313c2821b63cebec9ae6a9e8329a2f",
    "semantic_title": "break it down into bts: basic, tiniest subword units for korean",
    "citation_count": 1,
    "authors": [
      "Nayeon Kim",
      "Jun-Hyung Park",
      "Joon-Young Choi",
      "Eojin Jeon",
      "Youjin Kang",
      "SangKeun Lee"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.473": {
    "title": "The Devil in Linear Transformer",
    "volume": "main",
    "abstract": "Linear transformers aim to reduce the quadratic space-time complexity of vanilla transformers. However, they usually suffer from degraded performances on various tasks and corpus. In this paper, we examine existing kernel-based linear transformers and identify two key issues that lead to such performance gaps: 1) unbounded gradients in the attention computation adversely impact the convergence of linear transformer models; 2) attention dilution which trivially distributes attention scores over long sequences while neglecting neighbouring structures. To address these issues, we first identify that the scaling of attention matrices is the devil in unbounded gradients, which turns out unnecessary in linear attention as we show theoretically and empirically. To this end, we propose a new linear attention that replaces the scaling operation with a normalization to stabilize gradients. For the issue of attention dilution, we leverage a diagonal attention to confine attention to only neighbouring tokens in early layers. Benefiting from the stable gradients and improved attention, our new linear transformer model, transNormer, demonstrates superior performance on text classification and language modeling tasks, as well as on the challenging Long-Range Arena benchmark, surpassing vanilla transformer and existing linear variants by a clear margin while being significantly more space-time efficient. The code is available at https://github.com/OpenNLPLab/Transnormer",
    "checked": true,
    "id": "e3fc46d5f4aae2c7a8a86b6bd21ca8db5d40fcbd",
    "semantic_title": "the devil in linear transformer",
    "citation_count": 23,
    "authors": [
      "Zhen Qin",
      "Xiaodong Han",
      "Weixuan Sun",
      "Dongxu Li",
      "Lingpeng Kong",
      "Nick Barnes",
      "Yiran Zhong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.474": {
    "title": "Zero-Shot Learners for Natural Language Understanding via a Unified Multiple Choice Perspective",
    "volume": "main",
    "abstract": "We propose a new paradigm for zero-shot learners that is format agnostic, i.e., it is compatible with any format and applicable to a list of language tasks, such as text classification, commonsense reasoning, coreference resolution, and sentiment analysis. Zero-shot learning aims to train a model on a given task such that it can address new learning tasks without any additional training. Our approach converts zero-shot learning into multiple-choice tasks, avoiding problems in commonly used large-scale generative models such as FLAN. It not only adds generalization ability to models but also significantly reduces the number of parameters. Our method shares the merits of efficient training and deployment. Our approach shows state-of-the-art performance on several benchmarks and produces satisfactory results on tasks such as natural language inference and text classification. Our model achieves this success with only 235M parameters, which is substantially smaller than state-of-the-art models with billions of parameters. The code and pre-trained models are available at https://github.com/IDEA-CCNL/Fengshenbang-LM/tree/main/fengshen/examples/unimc",
    "checked": true,
    "id": "8862ed012fe06a794fda3ceae3f471a0c2a40fbe",
    "semantic_title": "zero-shot learners for natural language understanding via a unified multiple choice perspective",
    "citation_count": 16,
    "authors": [
      "Ping Yang",
      "Junjie Wang",
      "Ruyi Gan",
      "Xinyu Zhu",
      "Lin Zhang",
      "Ziwei Wu",
      "Xinyu Gao",
      "Jiaxing Zhang",
      "Tetsuya Sakai"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.475": {
    "title": "Hypoformer: Hybrid Decomposition Transformer for Edge-friendly Neural Machine Translation",
    "volume": "main",
    "abstract": "Transformer has been demonstrated effective in Neural Machine Translation (NMT). However, it is memory-consuming and time-consuming in edge devices, resulting in some difficulties for real-time feedback. To compress and accelerate Transformer, we propose a Hybrid Tensor-Train (HTT) decomposition, which retains full rank and meanwhile reduces operations and parameters. A Transformer using HTT, named Hypoformer, consistently and notably outperforms the recent light-weight SOTA methods on three standard translation tasks under different parameter and speed scales. In extreme low resource scenarios, Hypoformer has 7.1 points absolute improvement in BLEU and 1.27 X speedup than vanilla Transformer on IWSLT'14 De-En task",
    "checked": true,
    "id": "1c939d9726eff12d8cf305c85d875d9fb0caf840",
    "semantic_title": "hypoformer: hybrid decomposition transformer for edge-friendly neural machine translation",
    "citation_count": 5,
    "authors": [
      "Sunzhu Li",
      "Peng Zhang",
      "Guobing Gan",
      "Xiuqing Lv",
      "Benyou Wang",
      "Junqiu Wei",
      "Xin Jiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.476": {
    "title": "FigMemes: A Dataset for Figurative Language Identification in Politically-Opinionated Memes",
    "volume": "main",
    "abstract": "Real-world politically-opinionated memes often rely on figurative language to cloak propaganda and radical ideas to help them spread. It is not only a scientific challenge to develop machine learning models to recognize them in memes, but also sociologically beneficial to understand hidden meanings at scale and raise awareness. These memes are fast-evolving (in both topics and visuals) and it remains unclear whether current multimodal machine learning models are robust to such distribution shifts. To enable future research into this area, we first present FigMemes, a dataset for figurative language classification in politically-opinionated memes. We evaluate the performance of state-of-the-art unimodal and multimodal models and provide comprehensive benchmark results. The key contributions of this proposed dataset include annotations of six commonly used types of figurative language in politically-opinionated memes, and a wide range of topics and visual styles. We also provide analyses on the ability of multimodal models to generalize across distribution shifts in memes. Our dataset poses unique machine learning challenges and our results show that current models have significant room for improvement in both performance and robustness to distribution shifts",
    "checked": true,
    "id": "555d789a2ff9a93e0aaacb31f596695345b663ec",
    "semantic_title": "figmemes: a dataset for figurative language identification in politically-opinionated memes",
    "citation_count": 9,
    "authors": [
      "Chen Liu",
      "Gregor Geigle",
      "Robin Krebs",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.477": {
    "title": "UniRel: Unified Representation and Interaction for Joint Relational Triple Extraction",
    "volume": "main",
    "abstract": "Relational triple extraction is challenging for its difficulty in capturing rich correlations between entities and relations. Existing works suffer from 1) heterogeneous representations of entities and relations, and 2) heterogeneous modeling of entity-entity interactions and entity-relation interactions. Therefore, the rich correlations are not fully exploited by existing works. In this paper, we propose UniRel to address these challenges. Specifically, we unify the representations of entities and relations by jointly encoding them within a concatenated natural language sequence, and unify the modeling of interactions with a proposed Interaction Map, which is built upon the off-the-shelf self-attention mechanism within any Transformer block. With comprehensive experiments on two popular relational triple extraction datasets, we demonstrate that UniRel is more effective and computationally efficient. The source code is available at https://github.com/wtangdev/UniRel",
    "checked": true,
    "id": "c9f28c6fce7eb9f505875daa9b078f4f9d15c20a",
    "semantic_title": "unirel: unified representation and interaction for joint relational triple extraction",
    "citation_count": 14,
    "authors": [
      "Wei Tang",
      "Benfeng Xu",
      "Yuyue Zhao",
      "Zhendong Mao",
      "Yifeng Liu",
      "Yong Liao",
      "Haiyong Xie"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.478": {
    "title": "X-FACTOR: A Cross-metric Evaluation of Factual Correctness in Abstractive Summarization",
    "volume": "main",
    "abstract": "Abstractive summarization models often produce factually inconsistent summaries that are not supported by the original article. Recently, a number of fact-consistent evaluation techniques have been proposed to address this issue; however, a detailed analysis of how these metrics agree with one another has yet to be conducted. In this paper, we present X-FACTOR, a cross-evaluation of three high-performing fact-aware abstractive summarization methods. First, we show that summarization models are often fine-tuned on datasets that contain factually inconsistent summaries and propose a fact-aware filtering mechanism that improves the quality of training data and, consequently, the factuality of these models. Second, we propose a corrector module that can be used to improve the factual consistency of generated summaries. Third, we present a re-ranking technique that samples summary instances from the output distribution of a summarization model and re-ranks the sampled instances based on their factuality. Finally, we provide a detailed cross-metric agreement analysis that shows how tuning a model to output summaries based on a particular factuality metric influences factuality as determined by the other metrics. Our goal in this work is to facilitate research that improves the factuality and faithfulness of abstractive summarization models",
    "checked": true,
    "id": "e59cf68d162ddfe7052316548515349e38720160",
    "semantic_title": "x-factor: a cross-metric evaluation of factual correctness in abstractive summarization",
    "citation_count": 6,
    "authors": [
      "Subhajit Chaudhury",
      "Sarathkrishna Swaminathan",
      "Chulaka Gunasekara",
      "Maxwell Crouse",
      "Srinivas Ravishankar",
      "Daiki Kimura",
      "Keerthiram Murugesan",
      "Ramón Fernandez Astudillo",
      "Tahira Naseem",
      "Pavan Kapanipathi",
      "Alexander Gray"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.479": {
    "title": "ParaTag: A Dataset of Paraphrase Tagging for Fine-Grained Labels, NLG Evaluation, and Data Augmentation",
    "volume": "main",
    "abstract": "Paraphrase identification has been formulated as a binary classification task to decide whether two sentences hold a paraphrase relationship. Existing paraphrase datasets only annotate a binary label for each sentence pair. However, after a systematical analysis of existing paraphrase datasets, we found that the degree of paraphrase cannot be well characterized by a single binary label. And the criteria of paraphrase are not even consistent within the same dataset. We hypothesize that such issues would limit the effectiveness of paraphrase models trained on these data. To this end, we propose a novel fine-grained paraphrase annotation schema that labels the minimum spans of tokens in a sentence that don't have the corresponding paraphrases in the other sentence. Under this setting, we frame paraphrasing as a sequence tagging task. We collect 30k sentence pairs in English with the new annotation schema, resulting in the ParaTag dataset. In addition to reporting baseline results on ParaTag using state-of-art language models, we show that ParaTag is especially useful for training an automatic scorer for language generation evaluation. Finally, we train a paraphrase generation model from ParaTag and achieve better data augmentation performance on the GLUE benchmark than other public paraphrasing datasets",
    "checked": true,
    "id": "c6e3b3e287296e5afcb670eedd38a546d1dd20b8",
    "semantic_title": "paratag: a dataset of paraphrase tagging for fine-grained labels, nlg evaluation, and data augmentation",
    "citation_count": 1,
    "authors": [
      "Shuohang Wang",
      "Ruochen Xu",
      "Yang Liu",
      "Chenguang Zhu",
      "Michael Zeng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.480": {
    "title": "Factual Accuracy is not Enough: Planning Consistent Description Order for Radiology Report Generation",
    "volume": "main",
    "abstract": "Radiology report generation systems have the potential to reduce the workload of radiologists by automatically describing the findings in medical images. To broaden the application of the report generation system, the system should generate reports that are not only factually accurate but also chronologically consistent, describing images that are presented in time order, that is, the correct order. We employ a planning-based radiology report generation system that generates the overall structure of reports as \"plans'\" prior to generating reports that are accurate and consistent in order. Additionally, we propose a novel reinforcement learning and inference method, Coordinated Planning (CoPlan), that includes a content planner and a text generator to train and infer in a coordinated manner to alleviate the cascading of errors that are often inherent in planning-based models. We conducted experiments with single-phase diagnostic reports in which the factual accuracy is critical and multi-phase diagnostic reports in which the description order is critical. Our proposed CoPlan improves the content order score by 5.1 pt in time series critical scenarios and the clinical factual accuracy F-score by 9.1 pt in time series irrelevant scenarios, compared those of the baseline models without CoPlan",
    "checked": true,
    "id": "9ed2efebdf373dadf45fdfbdde13dcd2c9910f5e",
    "semantic_title": "factual accuracy is not enough: planning consistent description order for radiology report generation",
    "citation_count": 4,
    "authors": [
      "Toru Nishino",
      "Yasuhide Miura",
      "Tomoki Taniguchi",
      "Tomoko Ohkuma",
      "Yuki Suzuki",
      "Shoji Kido",
      "Noriyuki Tomiyama"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.481": {
    "title": "FLUTE: Figurative Language Understanding through Textual Explanations",
    "volume": "main",
    "abstract": "Figurative language understanding has been recently framed as a recognizing textual entailment (RTE) task (a.k.a. natural language inference (NLI)). However, similar to classical RTE/NLI datasets they suffer from spurious correlations and annotation artifacts. To tackle this problem, work on NLI has built explanation-based datasets such as eSNLI, allowing us to probe whether language models are right for the right reasons. Yet no such data exists for figurative language, making it harder to assess genuine understanding of such expressions. To address this issue, we release FLUTE, a dataset of 9,000 figurative NLI instances with explanations, spanning four categories: Sarcasm, Simile, Metaphor, and Idioms. We collect the data through a Human-AI collaboration framework based on GPT-3, crowd workers, and expert annotators. We show how utilizing GPT-3 in conjunction with human annotators (novices and experts) can aid in scaling up the creation of datasets even for such complex linguistic phenomena as figurative language. The baseline performance of the T5 model fine-tuned on FLUTE shows that our dataset can bring us a step closer to developing models that understand figurative language through textual explanations",
    "checked": true,
    "id": "fd975e67a2b7b2e43943ac32a16f5fd5be80734b",
    "semantic_title": "flute: figurative language understanding through textual explanations",
    "citation_count": 29,
    "authors": [
      "Tuhin Chakrabarty",
      "Arkadiy Saakyan",
      "Debanjan Ghosh",
      "Smaranda Muresan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.482": {
    "title": "Precisely the Point: Adversarial Augmentations for Faithful and Informative Text Generation",
    "volume": "main",
    "abstract": "Though model robustness has been extensively studied in language understanding, the robustness of Seq2Seq generation remains understudied. In this paper, we conduct the first quantitative analysis on the robustness of pre-trained Seq2Seq models. We find that even current SOTA pre-trained Seq2Seq model (BART) is still vulnerable, which leads to significant degeneration in faithfulness and informativeness for text generation tasks. This motivated us to further propose a novel adversarial augmentation framework, namely AdvSeq, for generally improving faithfulness and informativeness of Seq2Seq models via enhancing their robustness. AdvSeq automatically constructs two types of adversarial augmentations during training, including implicit adversarial samples by perturbing word representations and explicit adversarial samples by word swapping, both of which effectively improve Seq2Seq robustness. Extensive experiments on three popular text generation tasks demonstrate that AdvSeq significantly improves both the faithfulness and informativeness of Seq2Seq generation under both automatic and human evaluation settings",
    "checked": true,
    "id": "c4b6a269f4adfc06508104b5b792e402105a1865",
    "semantic_title": "precisely the point: adversarial augmentations for faithful and informative text generation",
    "citation_count": 2,
    "authors": [
      "Wenhao Wu",
      "Wei Li",
      "Jiachen Liu",
      "Xinyan Xiao",
      "Sujian Li",
      "Yajuan Lyu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.483": {
    "title": "RLET: A Reinforcement Learning Based Approach for Explainable QA with Entailment Trees",
    "volume": "main",
    "abstract": "Interpreting the reasoning process from questions to answers poses a challenge in approaching explainable QA. A recently proposed structured reasoning format, entailment tree, manages to offer explicit logical deductions with entailment steps in a tree structure. To generate entailment trees, prior single pass sequence-to-sequence models lack visible internal decision probability, while stepwise approaches are supervised with extracted single step data and cannot model the tree as a whole. In this work, we propose RLET, a Reinforcement Learning based Entailment Tree generation framework, which is trained utilising the cumulative signals across the whole tree. RLET iteratively performs single step reasoning with sentence selection and deduction generation modules, from which the training signal is accumulated across the tree with elaborately designed aligned reward function that is consistent with the evaluation. To the best of our knowledge, we are the first to introduce RL into the entailment tree generation task. Experiments on three settings of the EntailmentBank dataset demonstrate the strength of using RL framework",
    "checked": true,
    "id": "fadc0a6bcf968ed2ac71f567a48cd302dd62adde",
    "semantic_title": "rlet: a reinforcement learning based approach for explainable qa with entailment trees",
    "citation_count": 6,
    "authors": [
      "Tengxiao Liu",
      "Qipeng Guo",
      "Xiangkun Hu",
      "Yue Zhang",
      "Xipeng Qiu",
      "Zheng Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.484": {
    "title": "Let the CAT out of the bag: Contrastive Attributed explanations for Text",
    "volume": "main",
    "abstract": "Contrastive explanations for understanding the behavior of black box models has gained a lot of attention recently as they provide potential for recourse. In this paper, we propose a method Contrastive Attributed explanations for Text (CAT) which provides contrastive explanations for natural language text data with a novel twist as we build and exploit attribute classifiers leading to more semantically meaningful explanations. To ensure that our contrastive generated text has the fewest possible edits with respect to the original text, while also being fluent and close to a human generated contrastive, we resort to a minimal perturbation approach regularized using a BERT language model and attribute classifiers trained on available attributes. We show through qualitative examples and a user study that our method not only conveys more insight because of these attributes, but also leads to better quality (contrastive) text. Quantitatively, we show that our method outperforms other state-of-the-art methods across four data sets on four benchmark metrics",
    "checked": true,
    "id": "27b2ee756d49840d4b0a3f050b6525332b0b5eaa",
    "semantic_title": "let the cat out of the bag: contrastive attributed explanations for text",
    "citation_count": 7,
    "authors": [
      "Saneem Chemmengath",
      "Amar Prakash Azad",
      "Ronny Luss",
      "Amit Dhurandhar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.485": {
    "title": "monoQA: Multi-Task Learning of Reranking and Answer Extraction for Open-Retrieval Conversational Question Answering",
    "volume": "main",
    "abstract": "To address the Conversational Question Answering (ORConvQA) task, previous work has considered an effective three-stage architecture, consisting of a retriever, a reranker, and a reader to extract the answers. In order to effectively answer the users' questions, a number of existing approaches have applied multi-task learning, such that the same model is shared between the reranker and the reader. Such approaches also typically tackle reranking and reading as classification tasks. On the other hand, recent text generation models, such as monoT5 and UnifiedQA, have been shown to respectively yield impressive performances in passage reranking and reading. However, no prior work has combined monoT5 and UnifiedQA to share a single text generation model that directly extracts the answers for the users instead of predicting the start/end positions in a retrieved passage. In this paper, we investigate the use of Multi-Task Learning (MTL) to improve performance on the ORConvQA task by sharing the reranker and reader's learned structure in a generative model. In particular, we propose monoQA, which uses a text generation model with multi-task learning for both the reranker and reader. Our model, which is based on the T5 text generation model, is fine-tuned simultaneously for both reranking (in order to improve the precision of the top retrieved passages) and extracting the answer. Our results on the OR-QuAC and OR-CoQA datasets demonstrate the effectiveness of our proposed model, which significantly outperforms existing strong baselines with improvements ranging from +12.31% to +19.51% in MAP and from +5.70% to +23.34% in F1 on all used test sets",
    "checked": true,
    "id": "73e851e42286030d7c511e3e74a01fbb0fb0c3b9",
    "semantic_title": "monoqa: multi-task learning of reranking and answer extraction for open-retrieval conversational question answering",
    "citation_count": 2,
    "authors": [
      "Sarawoot Kongyoung",
      "Craig Macdonald",
      "Iadh Ounis"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.486": {
    "title": "Composing Ci with Reinforced Non-autoregressive Text Generation",
    "volume": "main",
    "abstract": "Composing Ci (also widely known as Song Ci), a special type of classical Chinese poetry, requires to follow particular format once their tune patterns are given. To automatically generate a well-formed Ci, text generation systems should strictly take into account pre-defined rigid formats (e.g., length and rhyme). Yet, most existing approaches regard Ci generation as a conventional sequence-to-sequence task and use autoregressive models, while it is challenging for such models to properly handle the constraints (according to tune patterns) of Ci during the generation process. Moreover, consider that with the format prepared, Ci generation can be operated by an efficient synchronous process, where autoregressive models are limited in doing so since they follow the character-by-character generation protocol. Therefore, in this paper, we propose to compose Ci through a non-autoregressive approach, which not only ensure that the generation process accommodates tune patterns by controlling the rhythm and essential meaning of each sentence, but also allow the model to perform synchronous generation. In addition, we further improve our approach by applying reinforcement learning to the generation process with the rigid constraints of Ci as well as the diversity in content serving as rewards, so as to further maintain the format and content requirement. Experiments on a collected Ci dataset confirm that our proposed approach outperforms strong baselines and previous studies in terms of both automatic evaluation metrics and human judgements",
    "checked": true,
    "id": "3d200aaf170d78a847f96bb092a28a9bc3c0deae",
    "semantic_title": "composing ci with reinforced non-autoregressive text generation",
    "citation_count": 0,
    "authors": [
      "Yan Song"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.487": {
    "title": "MetaTKG: Learning Evolutionary Meta-Knowledge for Temporal Knowledge Graph Reasoning",
    "volume": "main",
    "abstract": "Reasoning over Temporal Knowledge Graphs (TKGs) aims to predict future facts based on given history. One of the key challenges for prediction is to learn the evolution of facts. Most existing works focus on exploring evolutionary information in history to obtain effective temporal embeddings for entities and relations, but they ignore the variation in evolution patterns of facts, which makes them struggle to adapt to future data with different evolution patterns. Moreover, new entities continue to emerge along with the evolution of facts over time. Since existing models highly rely on historical information to learn embeddings for entities, they perform poorly on such entities with little historical information. To tackle these issues, we propose a novel Temporal Meta-learning framework for TKG reasoning, MetaTKG for brevity. Specifically, our method regards TKG prediction as many temporal meta-tasks, and utilizes the designed Temporal Meta-learner to learn evolutionary meta-knowledge from these meta-tasks. The proposed method aims to guide the backbones to learn to adapt quickly to future data and deal with entities with little historical information by the learned meta-knowledge. Specially, in temporal meta-learner, we design a Gating Integration module to adaptively establish temporal correlations between meta-tasks. Extensive experiments on four widely-used datasets and three backbones demonstrate that our method can greatly improve the performance",
    "checked": true,
    "id": "8e8b0e5ffcdbcbc71e98afc0c567cfc1b00bd341",
    "semantic_title": "metatkg: learning evolutionary meta-knowledge for temporal knowledge graph reasoning",
    "citation_count": 5,
    "authors": [
      "Yuwei Xia",
      "Mengqi Zhang",
      "Qiang Liu",
      "Shu Wu",
      "Xiao-Yu Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.488": {
    "title": "mPLUG: Effective and Efficient Vision-Language Learning by Cross-modal Skip-connections",
    "volume": "main",
    "abstract": "Large-scale pre-trained foundation models have been an emerging paradigm for building artificial intelligence (AI) systems, which can be quickly adapted to a wide range of downstream tasks. This paper presents mPLUG, a new vision-language foundation model for both cross-modal understanding and generation. Most existing pre-trained models suffer from inefficiency and linguistic signal overwhelmed by long visual sequences in cross-modal alignment. To address both problems, mPLUG introduces an effective and efficient vision-language architecture with novel cross-modal skip-connections.mPLUG is pre-trained end-to-end on large-scale image-text pairs with both discriminative and generative objectives. It achieves state-of-the-art results on a wide range of vision-language downstream tasks, including image captioning, image-text retrieval, visual grounding and visual question answering. mPLUG also demonstrates strong zero-shot transferability on vision-language and video-language tasks. The code and pre-trained models are available at https://github.com/alibaba/AliceMind",
    "checked": true,
    "id": "f5c165b6317896a65151050201c737536fa17c31",
    "semantic_title": "mplug: effective and efficient vision-language learning by cross-modal skip-connections",
    "citation_count": 106,
    "authors": [
      "Chenliang Li",
      "Haiyang Xu",
      "Junfeng Tian",
      "Wei Wang",
      "Ming Yan",
      "Bin Bi",
      "Jiabo Ye",
      "He Chen",
      "Guohai Xu",
      "Zheng Cao",
      "Ji Zhang",
      "Songfang Huang",
      "Fei Huang",
      "Jingren Zhou",
      "Luo Si"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.489": {
    "title": "Q-TOD: A Query-driven Task-oriented Dialogue System",
    "volume": "main",
    "abstract": "Existing pipelined task-oriented dialogue systems usually have difficulties adapting to unseen domains, whereas end-to-end systems are plagued by large-scale knowledge bases in practice. In this paper, we introduce a novel query-driven task-oriented dialogue system, namely Q-TOD. The essential information from the dialogue context is extracted into a query, which is further employed to retrieve relevant knowledge records for response generation. Firstly, as the query is in the form of natural language and not confined to the schema of the knowledge base, the issue of domain adaption is alleviated remarkably in Q-TOD. Secondly, as the query enables the decoupling of knowledge retrieval from the generation, Q-TOD gets rid of the issue of knowledge base scalability. To evaluate the effectiveness of the proposed Q-TOD, we collect query annotations for three publicly available task-oriented dialogue datasets. Comprehensive experiments verify that Q-TOD outperforms strong baselines and establishes a new state-of-the-art performance on these datasets",
    "checked": true,
    "id": "d891de52e7c58e2443199a20bba7468bdc0736ae",
    "semantic_title": "q-tod: a query-driven task-oriented dialogue system",
    "citation_count": 10,
    "authors": [
      "Xin Tian",
      "Yingzhan Lin",
      "Mengfei Song",
      "Siqi Bao",
      "Fan Wang",
      "Huang He",
      "Shuqi Sun",
      "Hua Wu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.490": {
    "title": "Dial2vec: Self-Guided Contrastive Learning of Unsupervised Dialogue Embeddings",
    "volume": "main",
    "abstract": "In this paper, we introduce the task of learning unsupervised dialogue embeddings.Trivial approaches such as combining pre-trained word or sentence embeddings and encoding through pre-trained language models (PLMs) have been shown to be feasible for this task. However, these approaches typically ignore the conversational interactions between interlocutors, resulting in poor performance. To address this issue, we proposed a self-guided contrastive learning approach named dial2vec.Dial2vec considers a dialogue as an information exchange process. It captures the interaction patterns between interlocutors and leverages them to guide the learning of the embeddings corresponding to each interlocutor. Then the dialogue embedding is obtained by an aggregation of the embeddings from all interlocutors. To verify our approach, we establish a comprehensive benchmark consisting of six widely-used dialogue datasets. We consider three evaluation tasks: domain categorization, semantic relatedness, and dialogue retrieval. Dial2vec achieves on average 8.7, 9.0, and 13.8 points absolute improvements in terms of purity, Spearman's correlation, and mean average precision (MAP) over the strongest baseline on the three tasks respectively. Further analysis shows that dial2vec obtains informative and discriminative embeddings for both interlocutors under the guidance of the conversational interactions and achieves the best performance when aggregating them through the interlocutor-level pooling strategy. All codes and data are publicly available at https://github.com/AlibabaResearch/DAMO-ConvAI/tree/main/dial2vec",
    "checked": true,
    "id": "35f4bc71e41ff70bbc752955c1b00e0501bc2cf7",
    "semantic_title": "dial2vec: self-guided contrastive learning of unsupervised dialogue embeddings",
    "citation_count": 4,
    "authors": [
      "Che Liu",
      "Rui Wang",
      "Junfeng Jiang",
      "Yongbin Li",
      "Fei Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.491": {
    "title": "WR-One2Set: Towards Well-Calibrated Keyphrase Generation",
    "volume": "main",
    "abstract": "Keyphrase generation aims to automatically generate short phrases summarizing an input document. The recently emerged ONE2SET paradigm (Ye et al., 2021) generates keyphrases as a set and has achieved competitive performance. Nevertheless, we observe serious calibration errors outputted by ONE2SET, especially in the over-estimation of ∅ token (means \"no corresponding keyphrase\"). In this paper, we deeply analyze this limitation and identify two main reasons behind: 1) the parallel generation has to introduce excessive ∅ as padding tokens into training instances; and 2) the training mechanism assigning target to each slot is unstable and further aggravates the ∅ token over-estimation. To make the model well-calibrated, we propose WR-ONE2SET which extends ONE2SET with an adaptive instance-level cost Weighting strategy and a target Re-assignment mechanism. The former dynamically penalizes the over-estimated slots for different instances thus smoothing the uneven training distribution. The latter refines the original inappropriate assignment and reduces the supervisory signals of over-estimated slots. Experimental results on commonly-used datasets demonstrate the effectiveness and generality of our proposed paradigm",
    "checked": true,
    "id": "8bac7937789202f88f58476e98331c60d2f184df",
    "semantic_title": "wr-one2set: towards well-calibrated keyphrase generation",
    "citation_count": 8,
    "authors": [
      "Binbin Xie",
      "Xiangpeng Wei",
      "Baosong Yang",
      "Huan Lin",
      "Jun Xie",
      "Xiaoli Wang",
      "Min Zhang",
      "Jinsong Su"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.492": {
    "title": "Eeny, meeny, miny, moe. How to choose data for morphological inflection",
    "volume": "main",
    "abstract": "Data scarcity is a widespread problem for numerous natural language processing (NLP) tasks within low-resource languages. Within morphology, the labour-intensive task of tagging/glossing data is a serious bottleneck for both NLP and fieldwork. Active learning (AL) aims to reduce the cost of data annotation by selecting data that is most informative for the model. In this paper, we explore four sampling strategies for the task of morphological inflection using a Transformer model: a pair of oracle experiments where data is chosen based on correct/incorrect predictions by the model, model confidence, entropy, and random selection. We investigate the robustness of each sampling strategy across 30 typologically diverse languages, as well as a 10-cycle iteration using Natügu as a case study. Our results show a clear benefit to selecting data based on model confidence. Unsurprisingly, the oracle experiment, which is presented as a proxy for linguist/language informer feedback, shows the most improvement. This is followed closely by low-confidence and high-entropy forms. We also show that despite the conventional wisdom of larger data sets yielding better accuracy, introducing more instances of high-confidence, low-entropy, or forms that the model can already inflect correctly, can reduce model performance",
    "checked": true,
    "id": "a96a7069bd35ac4a2473651a92cccabacce50dfd",
    "semantic_title": "eeny, meeny, miny, moe. how to choose data for morphological inflection",
    "citation_count": 7,
    "authors": [
      "Saliha Muradoglu",
      "Mans Hulden"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.493": {
    "title": "An Adaptive Logical Rule Embedding Model for Inductive Reasoning over Temporal Knowledge Graphs",
    "volume": "main",
    "abstract": "Temporal knowledge graphs (TKGs) extrapolation reasoning predicts future events based on historical information, which has great research significance and broad application value. Existing methods can be divided into embedding-based methods and logical rule-based methods. Embedding-based methods rely on learned entity and relation embeddings to make predictions and thus lack interpretability. Logical rule-based methods bring scalability problems due to being limited by the learned logical rules. We combine the two methods to capture deep causal logic by learning rule embeddings, and propose an interpretable model for temporal knowledge graph reasoning called adaptive logical rule embedding model for inductive reasoning (ALRE-IR). ALRE-IR can adaptively extract and assess reasons contained in historical events, and make predictions based on causal logic. Furthermore, we propose a one-class augmented matching loss for optimization. When evaluated on the ICEWS14, ICEWS0515 and ICEWS18 datasets, the performance of ALRE-IR outperforms other state-of-the-art baselines. The results also demonstrate that ALRE-IR still shows outstanding performance when transferred to related dataset with common relation vocabulary, indicating our proposed model has good zero-shot reasoning ability",
    "checked": true,
    "id": "f0004055579ad3c6be69eefa23938eaea2dc145e",
    "semantic_title": "an adaptive logical rule embedding model for inductive reasoning over temporal knowledge graphs",
    "citation_count": 5,
    "authors": [
      "Xin Mei",
      "Libin Yang",
      "Xiaoyan Cai",
      "Zuowei Jiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.494": {
    "title": "UniNL: Aligning Representation Learning with Scoring Function for OOD Detection via Unified Neighborhood Learning",
    "volume": "main",
    "abstract": "Detecting out-of-domain (OOD) intents from user queries is essential for avoiding wrong operations in task-oriented dialogue systems. The key challenge is how to distinguish in-domain (IND) and OOD intents. Previous methods ignore the alignment between representation learning and scoring function, limiting the OOD detection performance. In this paper, we propose a unified neighborhood learning framework (UniNL) to detect OOD intents. Specifically, we design a KNCL objective for representation learning, and introduce a KNN-based scoring function for OOD detection. We aim to align representation learning with scoring function. Experiments and analysis on two benchmark datasets show the effectiveness of our method",
    "checked": true,
    "id": "14b414eaccf08950c2aa489ad5fd719b3a12d35e",
    "semantic_title": "uninl: aligning representation learning with scoring function for ood detection via unified neighborhood learning",
    "citation_count": 6,
    "authors": [
      "Yutao Mou",
      "Pei Wang",
      "Keqing He",
      "Yanan Wu",
      "Jingang Wang",
      "Wei Wu",
      "Weiran Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.495": {
    "title": "Open-domain Video Commentary Generation",
    "volume": "main",
    "abstract": "Live commentary plays an important role in sports broadcasts and video games, making spectators more excited and immersed. In this context, though approaches for automatically generating such commentary have been proposed in the past, they have been generally concerned with specific fields, where it is possible to leverage domain-specific information. In light of this, we propose the task of generating video commentary in an open-domain fashion. We detail the construction of a new large-scale dataset of transcribed commentary aligned with videos containing various human actions in a variety of domains, and propose approaches based on well-known neural architectures to tackle the task. To understand the strengths and limitations of current approaches, we present an in-depth empirical study based on our data. Our results suggest clear trade-offs between textual and visual inputs for the models and highlight the importance of relying on external knowledge in this open-domain setting, resulting in a set of robust baselines for our task",
    "checked": true,
    "id": "5d6a198f4c02056b1f1b9188449d88537f28a89a",
    "semantic_title": "open-domain video commentary generation",
    "citation_count": 1,
    "authors": [
      "Edison Marrese-Taylor",
      "Yumi Hamazono",
      "Tatsuya Ishigaki",
      "Goran Topić",
      "Yusuke Miyao",
      "Ichiro Kobayashi",
      "Hiroya Takamura"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.496": {
    "title": "One size does not fit all: Investigating strategies for differentially-private learning across NLP tasks",
    "volume": "main",
    "abstract": "Preserving privacy in contemporary NLP models allows us to work with sensitive data, but unfortunately comes at a price. We know that stricter privacy guarantees in differentially-private stochastic gradient descent (DP-SGD) generally degrade model performance. However, previous research on the efficiency of DP-SGD in NLP is inconclusive or even counter-intuitive. In this short paper, we provide an extensive analysis of different privacy preserving strategies on seven downstream datasets in five different ‘typical' NLP tasks with varying complexity using modern neural models based on BERT and XtremeDistil architectures. We show that unlike standard non-private approaches to solving NLP tasks, where bigger is usually better, privacy-preserving strategies do not exhibit a winning pattern, and each task and privacy regime requires a special treatment to achieve adequate performance",
    "checked": true,
    "id": "14cb3ed64cbdd11444c98c97be3ecef7394e8a56",
    "semantic_title": "one size does not ﬁt all: investigating strategies for differentially-private learning across nlp tasks",
    "citation_count": 12,
    "authors": [
      "Manuel Senge",
      "Timour Igamberdiev",
      "Ivan Habernal"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.497": {
    "title": "Counterfactual Recipe Generation: Exploring Compositional Generalization in a Realistic Scenario",
    "volume": "main",
    "abstract": "People can acquire knowledge in an unsupervised manner by reading, and compose the knowledge to make novel combinations. In this paper, we investigate whether pretrained language models can perform compositional generalization in a realistic setting: recipe generation. We design the counterfactual recipe generation task, which asks models to modify a base recipe according to the change of an ingredient. This task requires compositional generalization at two levels: the surface level of incorporating the new ingredient into the base recipe, and the deeper level of adjusting actions related to the changing ingredient. We collect a large-scale recipe dataset in Chinese for models to learn culinary knowledge, and a subset of action-level fine-grained annotations for evaluation. We finetune pretrained language models on the recipe corpus, and use unsupervised counterfactual generation methods to generate modified recipes. Results show that existing models have difficulties in modifying the ingredients while preserving the original text style, and often miss actions that need to be adjusted. Although pretrained language models can generate fluent recipe texts, they fail to truly learn and use the culinary knowledge in a compositional way. Code and data are available at https://github.com/xxxiaol/counterfactual-recipe-generation",
    "checked": true,
    "id": "c6e4518dfd687a2a5bed4e78d5d9f999292a1746",
    "semantic_title": "counterfactual recipe generation: exploring compositional generalization in a realistic scenario",
    "citation_count": 3,
    "authors": [
      "Xiao Liu",
      "Yansong Feng",
      "Jizhi Tang",
      "Chengang Hu",
      "Dongyan Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.498": {
    "title": "Tutoring Helps Students Learn Better: Improving Knowledge Distillation for BERT with Tutor Network",
    "volume": "main",
    "abstract": "Pre-trained language models have achieved remarkable successes in natural language processing tasks, coming at the cost of increasing model size. To address this issue, knowledge distillation (KD) has been widely applied to compress language models. However, typical KD approaches for language models have overlooked the difficulty of training examples, suffering from incorrect teacher prediction transfer and sub-efficient training. In this paper, we propose a novel KD framework, Tutor-KD, which improves the distillation effectiveness by controlling the difficulty of training examples during pre-training. We introduce a tutor network that generates samples that are easy for the teacher but difficult for the student, with training on a carefully designed policy gradient method. Experimental results show that Tutor-KD significantly and consistently outperforms the state-of-the-art KD methods with variously sized student models on the GLUE benchmark, demonstrating that the tutor can effectively generate training examples for the student",
    "checked": true,
    "id": "ba87303f323f09157a70f2c362c01aa34091c8b4",
    "semantic_title": "tutoring helps students learn better: improving knowledge distillation for bert with tutor network",
    "citation_count": 2,
    "authors": [
      "Junho Kim",
      "Jun-Hyung Park",
      "Mingyu Lee",
      "Wing-Lam Mok",
      "Joon-Young Choi",
      "SangKeun Lee"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.499": {
    "title": "Does Corpus Quality Really Matter for Low-Resource Languages?",
    "volume": "main",
    "abstract": "The vast majority of non-English corpora are derived from automatically filtered versions of CommonCrawl. While prior work has identified major issues on the quality of these datasets (Kreutzer et al., 2021), it is not clear how this impacts downstream performance. Taking representation learning in Basque as a case study, we explore tailored crawling (manually identifying and scraping websites with high-quality content) as an alternative to filtering CommonCrawl. Our new corpus, called EusCrawl, is similar in size to the Basque portion of popular multilingual corpora like CC100 and mC4, yet it has a much higher quality according to native annotators. For instance, 66% of documents are rated as high-quality for EusCrawl, in contrast with <33% for both mC4 and CC100. Nevertheless, we obtain similar results on downstream NLU tasks regardless of the corpus used for pre-training. Our work suggests that NLU performance in low-resource languages is not primarily constrained by the quality of the data, and other factors like corpus size and domain coverage can play a more important role",
    "checked": true,
    "id": "db5881b21f58e31dcc5ef05088028de77b363bb9",
    "semantic_title": "does corpus quality really matter for low-resource languages?",
    "citation_count": 11,
    "authors": [
      "Mikel Artetxe",
      "Itziar Aldabe",
      "Rodrigo Agerri",
      "Olatz Perez-de-Viñaspre",
      "Aitor Soroa"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.500": {
    "title": "Unifying Data Perspectivism and Personalization: An Application to Social Norms",
    "volume": "main",
    "abstract": "Instead of using a single ground truth for language processing tasks, several recent studies have examined how to represent and predict the labels of the set of annotators. However, often little or no information about annotators is known, or the set of annotators is small. In this work, we examine a corpus of social media posts about conflict from a set of 13k annotators and 210k judgements of social norms. We provide a novel experimental setup that applies personalization methods to the modeling of annotators and compare their effectiveness for predicting the perception of social norms. We further provide an analysis of performance across subsets of social situations that vary by the closeness of the relationship between parties in conflict, and assess where personalization helps the most",
    "checked": true,
    "id": "2bd3a8ff987fba0368291dc72fa7738ca0299782",
    "semantic_title": "unifying data perspectivism and personalization: an application to social norms",
    "citation_count": 11,
    "authors": [
      "Joan Plepi",
      "Béla Neuendorf",
      "Lucie Flek",
      "Charles Welch"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.501": {
    "title": "Does Self-Rationalization Improve Robustness to Spurious Correlations?",
    "volume": "main",
    "abstract": "Rationalization is fundamental to human reasoning and learning. NLP models trained to produce rationales along with predictions, called self-rationalization models, have been investigated for their interpretability and utility to end-users. However, the extent to which training with human-written rationales facilitates learning remains an under-explored question. We ask whether training models to self-rationalize can aid in their learning to solve tasks for the right reasons. Specifically, we evaluate how training self-rationalization models with free-text rationales affects robustness to spurious correlations in fine-tuned encoder-decoder and decoder-only models of six different sizes. We evaluate robustness to spurious correlations by measuring performance on 1) manually annotated challenge datasets and 2) subsets of original test sets where reliance on spurious correlations would fail to produce correct answers. We find that while self-rationalization can improve robustness to spurious correlations in low-resource settings, it tends to hurt robustness in higher-resource settings. Furthermore, these effects depend on model family and size, as well as on rationale content. Together, our results suggest that explainability can come at the cost of robustness; thus, appropriate care should be taken when training self-rationalizing models with the goal of creating more trustworthy models",
    "checked": true,
    "id": "36543b4441c9d88b57b06a7ba887f409afd8141d",
    "semantic_title": "does self-rationalization improve robustness to spurious correlations?",
    "citation_count": 5,
    "authors": [
      "Alexis Ross",
      "Matthew Peters",
      "Ana Marasovic"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.502": {
    "title": "Efficient Pre-training of Masked Language Model via Concept-based Curriculum Masking",
    "volume": "main",
    "abstract": "Self-supervised pre-training has achieved remarkable success in extensive natural language processing tasks. Masked language modeling (MLM) has been widely used for pre-training effective bidirectional representations but comes at a substantial training cost. In this paper, we propose a novel concept-based curriculum masking (CCM) method to efficiently pre-train a language model. CCM has two key differences from existing curriculum learning approaches to effectively reflect the nature of MLM. First, we introduce a novel curriculum that evaluates the MLM difficulty of each token based on a carefully-designed linguistic difficulty criterion. Second, we construct a curriculum that masks easy words and phrases first and gradually masks related ones to the previously masked ones based on a knowledge graph. Experimental results show that CCM significantly improves pre-training efficiency. Specifically, the model trained with CCM shows comparative performance with the original BERT on the General Language Understanding Evaluation benchmark at half of the training cost",
    "checked": true,
    "id": "1d52755458a0fae5b5abd23c1ebb7c66926d2bd5",
    "semantic_title": "efficient pre-training of masked language model via concept-based curriculum masking",
    "citation_count": 5,
    "authors": [
      "Mingyu Lee",
      "Jun-Hyung Park",
      "Junho Kim",
      "Kang-Min Kim",
      "SangKeun Lee"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.503": {
    "title": "Subword Evenness (SuE) as a Predictor of Cross-lingual Transfer to Low-resource Languages",
    "volume": "main",
    "abstract": "Pre-trained multilingual models, such as mBERT, XLM-R and mT5, are used to improve the performance on various tasks in low-resource languages via cross-lingual transfer. In this framework, English is usually seen as the most natural choice for a transfer language (for fine-tuning or continued training of a multilingual pre-trained model), but it has been revealed recently that this is often not the best choice. The success of cross-lingual transfer seems to depend on some properties of languages, which are currently hard to explain. Successful transfer often happens between unrelated languages and it often cannot be explained by data-dependent factors. In this study, we show that languages written in non-Latin and non-alphabetic scripts (mostly Asian languages) are the best choices for improving performance on the task of Masked Language Modelling (MLM) in a diverse set of 30 low-resource languages and that the success of the transfer is well predicted by our novel measure of Subword Evenness (SuE). Transferring language models over the languages that score low on our measure results in the lowest average perplexity over target low-resource languages. Our correlation coefficients obtained with three different pre-trained multilingual models are consistently higher than all the other predictors, including text-based measures (type-token ratio, entropy) and linguistically motivated choice (genealogical and typological proximity)",
    "checked": true,
    "id": "3895423c2e2ed608ba1439a6a21b66e43f5ef8b8",
    "semantic_title": "subword evenness (sue) as a predictor of cross-lingual transfer to low-resource languages",
    "citation_count": 0,
    "authors": [
      "Olga Pelloni",
      "Anastassia Shaitarova",
      "Tanja Samardzic"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.504": {
    "title": "A Unified Neural Network Model for Readability Assessment with Feature Projection and Length-Balanced Loss",
    "volume": "main",
    "abstract": "Readability assessment is a basic research task in the field of education. Traditional methods mainly employ machine learning classifiers with hundreds of linguistic features. Although the deep learning model has become the prominent approach for almost all NLP tasks, it is less explored for readability assessment. In this paper, we propose a BERT-based model with feature projection and length-balanced loss (BERT-FP-LBL) to determine the difficulty level of a given text. First, we introduce topic features guided by difficulty knowledge to complement the traditional linguistic features. From the linguistic features, we extract really useful orthogonal features to supplement BERT representations by means of projection filtering. Furthermore, we design a length-balanced loss to handle the greatly varying length distribution of the readability data. We conduct experiments on three English benchmark datasets and one Chinese dataset, and the experimental results show that our proposed model achieves significant improvements over baseline models. Interestingly, our proposed model achieves comparable results with human experts in consistency test",
    "checked": true,
    "id": "bede390c23e652109eb9b49cb601d0fdbf2a525e",
    "semantic_title": "a unified neural network model for readability assessment with feature projection and length-balanced loss",
    "citation_count": 2,
    "authors": [
      "Wenbiao Li",
      "Wang Ziyang",
      "Yunfang Wu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.505": {
    "title": "Speaker Overlap-aware Neural Diarization for Multi-party Meeting Analysis",
    "volume": "main",
    "abstract": "Recently, hybrid systems of clustering and neural diarization models have been successfully applied in multi-party meeting analysis. However, current models always treat overlapped speaker diarization as a multi-label classification problem, where speaker dependency and overlaps are not well considered. To overcome the disadvantages, we reformulate overlapped speaker diarization task as a single-label prediction problem via the proposed power set encoding (PSE). Through this formulation, speaker dependency and overlaps can be explicitly modeled. To fully leverage this formulation, we further propose the speaker overlap-aware neural diarization (SOND) model, which consists of a context-independent (CI) scorer to model global speaker discriminability, a context-dependent scorer (CD) to model local discriminability, and a speaker combining network (SCN) to combine and reassign speaker activities. Experimental results show that using the proposed formulation can outperform the state-of-the-art methods based on target speaker voice activity detection, and the performance can be further improved with SOND, resulting in a 6.30% relative diarization error reduction",
    "checked": true,
    "id": "04f4009041fd3f8b3587572fa8efb815de2cbf99",
    "semantic_title": "speaker overlap-aware neural diarization for multi-party meeting analysis",
    "citation_count": 6,
    "authors": [
      "Zhihao Du",
      "ShiLiang Zhang",
      "Siqi Zheng",
      "Zhi-Jie Yan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.506": {
    "title": "GREENER: Graph Neural Networks for News Media Profiling",
    "volume": "main",
    "abstract": "We study the problem of profiling news media on the Web with respect to their factuality of reporting and bias. This is an important but under-studied problem related to disinformation and \"fake news\" detection, but it addresses the issue at a coarser granularity compared to looking at an individual article or an individual claim. This is useful as it allows to profile entire media outlets in advance. Unlike previous work, which has focused primarily on text (e.g., on the text of the articles published by the target website, or on the textual description in their social media profiles or in Wikipedia), here our main focus is on modeling the similarity between media outlets based on the overlap of their audience. This is motivated by homophily considerations, i.e., the tendency of people to have connections to people with similar interests, which we extend to media, hypothesizing that similar types of media would be read by similar kinds of users. In particular, we propose GREENER (GRaph nEural nEtwork for News mEdia pRofiling), a model that builds a graph of inter-media connections based on their audience overlap, and then uses graph neural networks to represent each medium. We find that such representations are quite useful for predicting the factuality and the bias of news media outlets, yielding improvements over state-of-the-art results reported on two datasets. When augmented with conventionally used representations obtained from news articles, Twitter, YouTube, Facebook, and Wikipedia, prediction accuracy is found to improve by 2.5-27 macro-F1 points for the two tasks",
    "checked": true,
    "id": "4b361b54fb8eb38539518803fbe3bef03c7899ad",
    "semantic_title": "greener: graph neural networks for news media profiling",
    "citation_count": 11,
    "authors": [
      "Panayot Panayotov",
      "Utsav Shukla",
      "Husrev Taha Sencar",
      "Mohamed Nabeel",
      "Preslav Nakov"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.507": {
    "title": "Graph Hawkes Transformer for Extrapolated Reasoning on Temporal Knowledge Graphs",
    "volume": "main",
    "abstract": "Temporal Knowledge Graph (TKG) reasoning has attracted increasing attention due to its enormous potential value, and the critical issue is how to model the complex temporal structure information effectively. Recent studies use the method of encoding graph snapshots into hidden vector space and then performing heuristic deductions, which perform well on the task of entity prediction. However, these approaches cannot predict when an event will occur and have the following limitations: 1) there are many facts not related to the query that can confuse the model; 2) there exists information forgetting caused by long-term evolutionary processes. To this end, we propose a Graph Hawkes Transformer (GHT) for both TKG entity prediction and time prediction tasks in the future time. In GHT, there are two variants of Transformer, which capture the instantaneous structural information and temporal evolution information, respectively, and a new relational continuous-time encoding function to facilitate feature evolution with the Hawkes process. Extensive experiments on four public datasets demonstrate its superior performance, especially on long-term evolutionary tasks",
    "checked": true,
    "id": "2a98fd84fd7a1eadbeb4513ad322d13286ecb9ac",
    "semantic_title": "graph hawkes transformer for extrapolated reasoning on temporal knowledge graphs",
    "citation_count": 12,
    "authors": [
      "Haohai Sun",
      "Shangyi Geng",
      "Jialun Zhong",
      "Han Hu",
      "Kun He"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.508": {
    "title": "UniRPG: Unified Discrete Reasoning over Table and Text as Program Generation",
    "volume": "main",
    "abstract": "Question answering requiring discrete reasoning, e.g., arithmetic computing, comparison, and counting, over knowledge is a challenging task. In this paper, we propose UniRPG, a semantic-parsing-based approach advanced in interpretability and scalability, to perform Unified discrete Reasoning over heterogeneous knowledge resources, i.e., table and text, as Program Generation. Concretely, UniRPG consists of a neural programmer and a symbolic program executor,where a program is the composition of a set of pre-defined general atomic and higher-order operations and arguments extracted from table and text. First, the programmer parses a question into a program by generating operations and copying arguments, and then, the executor derives answers from table and text based on the program. To alleviate the costly program annotation issue, we design a distant supervision approach for programmer learning, where pseudo programs are automatically constructed without annotated derivations. Extensive experiments on the TAT-QA dataset show that UniRPG achieves tremendous improvements and enhances interpretability and scalability compared with previous state-of-the-art methods, even without derivation annotation. Moreover, it achieves promising performance on the textual dataset DROP without derivation annotation",
    "checked": true,
    "id": "6876e7b5526a93462f9b3e0b55a93b5561f1c993",
    "semantic_title": "unirpg: unified discrete reasoning over table and text as program generation",
    "citation_count": 14,
    "authors": [
      "Yongwei Zhou",
      "Junwei Bao",
      "Chaoqun Duan",
      "Youzheng Wu",
      "Xiaodong He",
      "Tiejun Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.509": {
    "title": "Don't Prompt, Search! Mining-based Zero-Shot Learning with Language Models",
    "volume": "main",
    "abstract": "Masked language models like BERT can perform text classification in a zero-shot fashion by reformulating downstream tasks as text infilling. However, this approach is highly sensitive to the template used to prompt the model, yet practitioners are blind when designing them in strict zero-shot settings. In this paper, we propose an alternative mining-based approach for zero-shot learning. Instead of prompting language models, we use regular expressions to mine labeled examples from unlabeled corpora, which can optionally be filtered through prompting, and used to finetune a pretrained model. Our method is more flexible and interpretable than prompting, and outperforms it on a wide range of tasks when using comparable templates. Our results suggest that the success of prompting can partly be explained by the model being exposed to similar examples during pretraining, which can be directly retrieved through regular expressions",
    "checked": true,
    "id": "990026128083f5a47b061f6237b8135b2d3a41a9",
    "semantic_title": "don't prompt, search! mining-based zero-shot learning with language models",
    "citation_count": 11,
    "authors": [
      "Mozes van de Kar",
      "Mengzhou Xia",
      "Danqi Chen",
      "Mikel Artetxe"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.510": {
    "title": "SEMGraph: Incorporating Sentiment Knowledge and Eye Movement into Graph Model for Sentiment Analysis",
    "volume": "main",
    "abstract": "This paper investigates the sentiment analysis task from a novel perspective by incorporating sentiment knowledge and eye movement into a graph architecture, aiming to draw the eye movement-based sentiment relationships for learning the sentiment expression of the context. To be specific, we first explore a linguistic probing eye movement paradigm to extract eye movement features based on the close relationship between linguistic features and the early and late processes of human reading behavior. Furthermore, to derive eye movement features with sentiment concepts, we devise a novel weighting strategy to integrate sentiment scores extracted from affective commonsense knowledge into eye movement features, called sentiment-eye movement weights. Then, the sentiment-eye movement weights are exploited to build the sentiment-eye movement guided graph (SEMGraph) model, so as to model the intricate sentiment relationships in the context. Experimental results on two sentiment analysis datasets with eye movement signals and three sentiment analysis datasets without eye movement signals show that the proposed SEMGraph achieves state-of-the-art performance, and can also be directly generalized to those sentiment analysis datasets without eye movement signals",
    "checked": true,
    "id": "0d2868aba3c76c1238834d9cdbb2b0f7a48104ca",
    "semantic_title": "semgraph: incorporating sentiment knowledge and eye movement into graph model for sentiment analysis",
    "citation_count": 1,
    "authors": [
      "Bingbing Wang",
      "Bin Liang",
      "Jiachen Du",
      "Min Yang",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.511": {
    "title": "Cross-lingual neural fuzzy matching for exploiting target-language monolingual corpora in computer-aided translation",
    "volume": "main",
    "abstract": "Computer-aided translation (CAT) tools based on translation memories (MT) play a prominent role in the translation workflow of professional translators. However, the reduced availability of in-domain TMs, as compared to in-domain monolingual corpora, limits its adoption for a number of translation tasks. In this paper, we introduce a novel neural approach aimed at overcoming this limitation by exploiting not only TMs, but also in-domain target-language (TL) monolingual corpora, and still enabling a similar functionality to that offered by conventional TM-based CAT tools. Our approach relies on cross-lingual sentence embeddings to retrieve translation proposals from TL monolingual corpora, and on a neural model to estimate their post-editing effort. The paper presents an automatic evaluation of these techniques on four language pairs that shows that our approach can successfully exploit monolingual texts in a TM-based CAT environment, increasing the amount of useful translation proposals, and that our neural model for estimating the post-editing effort enables the combination of translation proposals obtained from monolingual corpora and from TMs in the usual way. A human evaluation performed on a single language pair confirms the results of the automatic evaluation and seems to indicate that the translation proposals retrieved with our approach are more useful than what the automatic evaluation shows",
    "checked": true,
    "id": "3dbb5b6ac39ef4fe4df663cbc52aa59052a82d5c",
    "semantic_title": "cross-lingual neural fuzzy matching for exploiting target-language monolingual corpora in computer-aided translation",
    "citation_count": 1,
    "authors": [
      "Miquel Esplà-Gomis",
      "Víctor M. Sánchez-Cartagena",
      "Juan Antonio Pérez-Ortiz",
      "Felipe Sánchez-Martínez"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.512": {
    "title": "Multi-Label Intent Detection via Contrastive Task Specialization of Sentence Encoders",
    "volume": "main",
    "abstract": "Deploying task-oriented dialog ToD systems for new domains and tasks requires natural language understanding models that are 1) resource-efficient and work under low-data regimes; 2) adaptable, efficient, and quick-to-train; 3) expressive and can handle complex ToD scenarios with multiple user intents in a single utterance. Motivated by these requirements, we introduce a novel framework for multi-label intent detection (mID): MultI-ConvFiT (Multi-Label Intent Detection via Contrastive Conversational Fine-Tuning). While previous work on efficient single-label intent detection learns a classifier on top of a fixed sentence encoder (SE), we propose to 1) transform general-purpose SEs into task-specialized SEs via contrastive fine-tuning on annotated multi-label data, 2) where task specialization knowledge can be stored into lightweight adapter modules without updating the original parameters of the input SE, and then 3) we build improved mID classifiers stacked on top of fixed specialized SEs. Our main results indicate that MultI-ConvFiT yields effective mID models, with large gains over non-specialized SEs reported across a spectrum of different mID datasets, both in low-data and high-data regimes",
    "checked": true,
    "id": "08c21c5d88b5756bfd684948c56aff19f0e71d3a",
    "semantic_title": "multi-label intent detection via contrastive task specialization of sentence encoders",
    "citation_count": 4,
    "authors": [
      "Ivan Vulić",
      "Iñigo Casanueva",
      "Georgios Spithourakis",
      "Avishek Mondal",
      "Tsung-Hsien Wen",
      "Paweł Budzianowski"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.513": {
    "title": "Discovering Language-neutral Sub-networks in Multilingual Language Models",
    "volume": "main",
    "abstract": "Multilingual pre-trained language models transfer remarkably well on cross-lingual downstream tasks. However, the extent to which they learn language-neutral representations (i.e., shared representations that encode similar phenomena across languages), and the effect of such representations on cross-lingual transfer performance, remain open questions. In this work, we conceptualize language neutrality of multilingual models as a function of the overlap between language-encoding sub-networks of these models. We employ the lottery ticket hypothesis to discover sub-networks that are individually optimized for various languages and tasks. Our evaluation across three distinct tasks and eleven typologically-diverse languages demonstrates that sub-networks for different languages are topologically similar (i.e., language-neutral), making them effective initializations for cross-lingual transfer with limited performance degradation",
    "checked": true,
    "id": "d66dcad5d9f0564a96c035e0f6c64fe046738885",
    "semantic_title": "discovering language-neutral sub-networks in multilingual language models",
    "citation_count": 20,
    "authors": [
      "Negar Foroutan",
      "Mohammadreza Banaei",
      "Rémi Lebret",
      "Antoine Bosselut",
      "Karl Aberer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.514": {
    "title": "Parameter-Efficient Tuning Makes a Good Classification Head",
    "volume": "main",
    "abstract": "In recent years, pretrained models revolutionized the paradigm of natural language understanding (NLU), where we append a randomly initialized classification head after the pretrained backbone, e.g. BERT, and finetune the whole model. As the pretrained backbone makes a major contribution to the improvement, we naturally expect a good pretrained classification head can also benefit the training. However, the final-layer output of the backbone, i.e. the input of the classification head, will change greatly during finetuning, making the usual head-only pretraining ineffective. In this paper, we find that parameter-efficient tuning makes a good classification head, with which we can simply replace the randomly initialized heads for a stable performance gain. Our experiments demonstrate that the classification head jointly pretrained with parameter-efficient tuning consistently improves the performance on 9 tasks in GLUE and SuperGLUE",
    "checked": true,
    "id": "02d2527aca2ecbda72475dd90ac461a3eb73abd7",
    "semantic_title": "parameter-efficient tuning makes a good classification head",
    "citation_count": 7,
    "authors": [
      "Zhuoyi Yang",
      "Ming Ding",
      "Yanhui Guo",
      "Qingsong Lv",
      "Jie Tang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.515": {
    "title": "STGN: an Implicit Regularization Method for Learning with Noisy Labels in Natural Language Processing",
    "volume": "main",
    "abstract": "Noisy labels are ubiquitous in natural language processing (NLP) tasks. Existing work, namely learning with noisy labels in NLP, is often limited to dedicated tasks or specific training procedures, making it hard to be widely used. To address this issue, SGD noise has been explored to provide a more general way to alleviate the effect of noisy labels by involving benign noise in the process of stochastic gradient descent. However, previous studies exert identical perturbation for all samples, which may cause overfitting on incorrect ones or optimizing correct ones inadequately. To facilitate this, we propose a novel stochastic tailor-made gradient noise (STGN), mitigating the effect of inherent label noise by introducing tailor-made benign noise for each sample. Specifically, we investigate multiple principles to precisely and stably discriminate correct samples from incorrect ones and thus apply different intensities of perturbation to them. A detailed theoretical analysis shows that STGN has good properties, beneficial for model generalization. Experiments on three different NLP tasks demonstrate the effectiveness and versatility of STGN. Also, STGN can boost existing robust training methods",
    "checked": true,
    "id": "a34473d8b505e6714bab4a8e92bd05f46223f2d7",
    "semantic_title": "stgn: an implicit regularization method for learning with noisy labels in natural language processing",
    "citation_count": 2,
    "authors": [
      "Tingting Wu",
      "Xiao Ding",
      "Minji Tang",
      "Hao Zhang",
      "Bing Qin",
      "Ting Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.516": {
    "title": "Cross-Modal Similarity-Based Curriculum Learning for Image Captioning",
    "volume": "main",
    "abstract": "Image captioning models require the high-level generalization ability to describe the contents of various images in words. Most existing approaches treat the image–caption pairs equally in their training without considering the differences in their learning difficulties. Several image captioning approaches introduce curriculum learning methods that present training data with increasing levels of difficulty. However, their difficulty measurements are either based on domain-specific features or prior model training. In this paper, we propose a simple yet efficient difficulty measurement for image captioning using cross-modal similarity calculated by a pretrained vision–language model. Experiments on the COCO and Flickr30k datasets show that our proposed approach achieves superior performance and competitive convergence speed to baselines without requiring heuristics or incurring additional training costs. Moreover, the higher model performance on difficult examples and unseen data also demonstrates the generalization ability",
    "checked": true,
    "id": "1c5dc727d624da1fd0474570775ad2da6385eef6",
    "semantic_title": "cross-modal similarity-based curriculum learning for image captioning",
    "citation_count": 1,
    "authors": [
      "Hongkuan Zhang",
      "Saku Sugawara",
      "Akiko Aizawa",
      "Lei Zhou",
      "Ryohei Sasano",
      "Koichi Takeda"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.517": {
    "title": "Debiasing Masks: A New Framework for Shortcut Mitigation in NLU",
    "volume": "main",
    "abstract": "Debiasing language models from unwanted behaviors in Natural Language Understanding (NLU) tasks is a topic with rapidly increasing interest in the NLP community. Spurious statistical correlations in the data allow models to perform shortcuts and avoid uncovering more advanced and desirable linguistic features.A multitude of effective debiasing approaches has been proposed, but flexibility remains a major issue. For the most part, models must be retrained to find a new set of weights with debiased behavior. We propose a new debiasing method in which we identify debiased pruning masks that can be applied to a finetuned model. This enables the selective and conditional application of debiasing behaviors. We assume that bias is caused by a certain subset of weights in the network; our method is, in essence, a mask search to identify and remove biased weights. Our masks show equivalent or superior performance to the standard counterparts, while offering important benefits. Pruning masks can be stored with high efficiency in memory, and it becomes possible to switch among several debiasing behaviors (or revert back to the original biased model) at inference time. Finally, it opens the doors to further research on how biases are acquired by studying the generated masks. For example, we observed that the early layers and attention heads were pruned more aggressively, possibly hinting towards the location in which biases may be encoded",
    "checked": true,
    "id": "76baaa18783fbfc5c7ee99d9d44d00a6c37e1a00",
    "semantic_title": "debiasing masks: a new framework for shortcut mitigation in nlu",
    "citation_count": 9,
    "authors": [
      "Johannes Mario Meissner",
      "Saku Sugawara",
      "Akiko Aizawa"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.518": {
    "title": "Extending Phrase Grounding with Pronouns in Visual Dialogues",
    "volume": "main",
    "abstract": "Conventional phrase grounding aims to localize noun phrases mentioned in a given caption to their corresponding image regions, which has achieved great success recently. Apparently, sole noun phrase grounding is not enough for cross-modal visual language understanding. Here we extend the task by considering pronouns as well. First, we construct a dataset of phrase grounding with both noun phrases and pronouns to image regions. Based on the dataset, we test the performance of phrase grounding by using a state-of-the-art literature model of this line. Then, we enhance the baseline grounding model with coreference information which should help our task potentially, modeling the coreference structures with graph convolutional networks. Experiments on our dataset, interestingly, show that pronouns are easier to ground than noun phrases, where the possible reason might be that these pronouns are much less ambiguous. Additionally, our final model with coreference information can significantly boost the grounding performance of both noun phrases and pronouns",
    "checked": true,
    "id": "44c934eb40e2fd4b2e50afbf29459f852ed5e6f9",
    "semantic_title": "extending phrase grounding with pronouns in visual dialogues",
    "citation_count": 3,
    "authors": [
      "Panzhong Lu",
      "Xin Zhang",
      "Meishan Zhang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.519": {
    "title": "EUR-Lex-Sum: A Multi- and Cross-lingual Dataset for Long-form Summarization in the Legal Domain",
    "volume": "main",
    "abstract": "Existing summarization datasets come with two main drawbacks: (1) They tend to focus on overly exposed domains, such as news articles or wiki-like texts, and (2) are primarily monolingual, with few multilingual datasets. In this work, we propose a novel dataset, called EUR-Lex-Sum, based on manually curated document summaries of legal acts from the European Union law platform (EUR-Lex). Documents and their respective summaries exist as cross-lingual paragraph-aligned data in several of the 24 official European languages, enabling access to various cross-lingual and lower-resourced summarization setups. We obtain up to 1,500 document/summary pairs per language, including a subset of 375 cross-lingually aligned legal acts with texts available in *all* 24 languages. In this work, the data acquisition process is detailed and key characteristics of the resource are compared to existing summarization resources. In particular, we illustrate challenging sub-problems and open questions on the dataset that could help the facilitation of future research in the direction of domain-specific cross-lingual summarization. Limited by the extreme length and language diversity of samples, we further conduct experiments with suitable extractive monolingual and cross-lingual baselines for future work. Code for the extraction as well as access to our data and baselines is available online at: [https://github.com/achouhan93/eur-lex-sum](https://github.com/achouhan93/eur-lex-sum)",
    "checked": true,
    "id": "9309b0d1dd78cee485710075cba8e69b57f0488c",
    "semantic_title": "eur-lex-sum: a multi- and cross-lingual dataset for long-form summarization in the legal domain",
    "citation_count": 19,
    "authors": [
      "Dennis Aumiller",
      "Ashish Chouhan",
      "Michael Gertz"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.520": {
    "title": "Differentiable Data Augmentation for Contrastive Sentence Representation Learning",
    "volume": "main",
    "abstract": "Fine-tuning a pre-trained language model via the contrastive learning framework with a large amount of unlabeled sentences or labeled sentence pairs is a common way to obtain high-quality sentence representations. Although the contrastive learning framework has shown its superiority on sentence representation learning over previous methods, the potential of such a framework is under-explored so far due to the simple method it used to construct positive pairs. Motivated by this, we propose a method that makes hard positives from the original training examples. A pivotal ingredient of our approach is the use of prefix that attached to a pre-trained language model, which allows for differentiable data augmentation during contrastive learning. Our method can be summarized in two steps: supervised prefix-tuning followed by joint contrastive fine-tuning with unlabeled or labeled examples. Our experiments confirm the effectiveness of our data augmentation approach. The proposed method yields significant improvements over existing methods under both semi-supervised and supervised settings. Our experiments under a low labeled data setting also show that our method is more label-efficient than the state-of-the-art contrastive learning methods",
    "checked": true,
    "id": "3e73561daf893074ab2b7e198e9dd7f1fa4f1263",
    "semantic_title": "differentiable data augmentation for contrastive sentence representation learning",
    "citation_count": 5,
    "authors": [
      "Tianduo Wang",
      "Wei Lu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.521": {
    "title": "Text Style Transferring via Adversarial Masking and Styled Filling",
    "volume": "main",
    "abstract": "Text style transfer is an important task in natural language processing with broad applications. Existing models following the masking and filling scheme suffer two challenges: the word masking procedure may mistakenly remove unexpected words and the selected words in the word filling procedure may lack diversity and semantic consistency. To tackle both challenges, in this study, we propose a style transfer model, with an adversarial masking approach and a styled filling technique (AMSF). Specifically, AMSF first trains a mask predictor by adversarial training without manual configuration. Then two additional losses, i.e. an entropy maximization loss and a consistency regularization loss, are introduced in training the word filling module to guarantee the diversity and semantic consistency of the transferred texts. Experimental results and analysis on two benchmark text style transfer data sets demonstrate the effectiveness of the proposed approaches",
    "checked": true,
    "id": "d20f8eb6d56d7d73fdfb255b9ea462b806d1813e",
    "semantic_title": "text style transferring via adversarial masking and styled filling",
    "citation_count": 3,
    "authors": [
      "Jiarui Wang",
      "Richong Zhang",
      "Junfan Chen",
      "Jaein Kim",
      "Yongyi Mao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.522": {
    "title": "Character-level White-Box Adversarial Attacks against Transformers via Attachable Subwords Substitution",
    "volume": "main",
    "abstract": "We propose the first character-level white-box adversarial attack method against transformer models. The intuition of our method comes from the observation that words are split into subtokens before being fed into the transformer models and the substitution between two close subtokens has a similar effect with the character modification. Our method mainly contains three steps. First, a gradient-based method is adopted to find the most vulnerable words in the sentence. Then we split the selected words into subtokens to replace the origin tokenization result from the transformer tokenizer. Finally, we utilize an adversarial loss to guide the substitution of attachable subtokens in which the Gumbel-softmax trick is introduced to ensure gradient propagation. Meanwhile, we introduce the visual and length constraint in the optimization process to achieve minimum character modifications. Extensive experiments on both sentence-level and token-level tasks demonstrate that our method could outperform the previous attack methods in terms of success rate and edit distance. Furthermore, human evaluation verifies our adversarial examples could preserve their origin labels",
    "checked": true,
    "id": "4e5de292334f5cb29be475dedb548e71c0fd40c2",
    "semantic_title": "character-level white-box adversarial attacks against transformers via attachable subwords substitution",
    "citation_count": 15,
    "authors": [
      "Aiwei Liu",
      "Honghai Yu",
      "Xuming Hu",
      "Shu’ang Li",
      "Li Lin",
      "Fukun Ma",
      "Yawen Yang",
      "Lijie Wen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.523": {
    "title": "Query-based Instance Discrimination Network for Relational Triple Extraction",
    "volume": "main",
    "abstract": "Joint entity and relation extraction has been a core task in the field of information extraction. Recent approaches usually consider the extraction of relational triples from a stereoscopic perspective, either learning a relation-specific tagger or separate classifiers for each relation type. However, they still suffer from error propagation, relation redundancy and lack of high-level connections between triples. To address these issues, we propose a novel query-based approach to construct instance-level representations for relational triples. By metric-based comparison between query embeddings and token embeddings, we can extract all types of triples in one step, thus eliminating the error propagation problem. In addition, we learn the instance-level representation of relational triples via contrastive learning. In this way, relational triples can not only enclose rich class-level semantics but also access to high-order global connections. Experimental results show that our proposed method achieves the state of the art on five widely used benchmarks",
    "checked": true,
    "id": "949479b4fce4ceceead0d38c5a0e43672cc79dcc",
    "semantic_title": "query-based instance discrimination network for relational triple extraction",
    "citation_count": 6,
    "authors": [
      "Zeqi Tan",
      "Yongliang Shen",
      "Xuming Hu",
      "Wenqi Zhang",
      "Xiaoxia Cheng",
      "Weiming Lu",
      "Yueting Zhuang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.524": {
    "title": "Learning Inter-Entity-Interaction for Few-Shot Knowledge Graph Completion",
    "volume": "main",
    "abstract": "Few-shot knowledge graph completion (FKGC) aims to infer unknown fact triples of a relation using its few-shot reference entity pairs. Recent FKGC studies focus on learning semantic representations of entity pairs by separately encoding the neighborhoods of head and tail entities. Such practice, however, ignores the inter-entity interaction, resulting in low-discrimination representations for entity pairs, especially when these entity pairs are associated with 1-to-N, N-to-1, and N-to-N relations. To address this issue, this paper proposes a novel FKGC model, named Cross-Interaction Attention Network (CIAN) to investigate the inter-entity interaction between head and tail entities. Specifically, we first explore the interactions within entities by computing the attention between the task relation and each entity neighbor, and then model the interactions between head and tail entities by letting an entity to attend to the neighborhood of its paired entity. In this way, CIAN can figure out the relevant semantics between head and tail entities, thereby generating more discriminative representations for entity pairs. Extensive experiments on two public datasets show that CIAN outperforms several state-of-the-art methods. The source code is available at https://github.com/cjlyl/FKGC-CIAN",
    "checked": true,
    "id": "b9b2d5e384dfbbe64b0ad00469fbb89426c08ae5",
    "semantic_title": "learning inter-entity-interaction for few-shot knowledge graph completion",
    "citation_count": 4,
    "authors": [
      "Yuling Li",
      "Kui Yu",
      "Xiaoling Huang",
      "Yuhong Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.525": {
    "title": "Empowering the Fact-checkers! Automatic Identification of Claim Spans on Twitter",
    "volume": "main",
    "abstract": "The widespread diffusion of medical and political claims in the wake of COVID-19 has led to a voluminous rise in misinformation and fake news. The current vogue is to employ manual fact-checkers to efficiently classify and verify such data to combat this avalanche of claim-ridden misinformation. However, the rate of information dissemination is such that it vastly outpaces the fact-checkers' strength. Therefore, to aid manual fact-checkers in eliminating the superfluous content, it becomes imperative to automatically identify and extract the snippets of claim-worthy (mis)information present in a post. In this work, we introduce the novel task of Claim Span Identification (CSI). We propose CURT, a large-scale Twitter corpus with token-level claim spans on more than 7.5k tweets. Furthermore, along with the standard token classification baselines, we benchmark our dataset with DABERTa, an adapter-based variation of RoBERTa. The experimental results attest that DABERTa outperforms the baseline systems across several evaluation metrics, improving by about 1.5 points. We also report detailed error analysis to validate the model's performance along with the ablation studies. Lastly, we release our comprehensive span annotation guidelines for public use",
    "checked": true,
    "id": "83392602a2dc739dd85c5a3dc338febfd33c9b4e",
    "semantic_title": "empowering the fact-checkers! automatic identification of claim spans on twitter",
    "citation_count": 10,
    "authors": [
      "Megha Sundriyal",
      "Atharva Kulkarni",
      "Vaibhav Pulastya",
      "Md. Shad Akhtar",
      "Tanmoy Chakraborty"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.526": {
    "title": "ClidSum: A Benchmark Dataset for Cross-Lingual Dialogue Summarization",
    "volume": "main",
    "abstract": "We present ClidSum, a benchmark dataset towards building cross-lingual summarization systems on dialogue documents. It consists of 67k+ dialogue documents and 112k+ annotated summaries in different target languages. Based on the proposed ClidSum, we introduce two benchmark settings for supervised and semi-supervised scenarios, respectively. We then build various baseline systems in different paradigms (pipeline and end-to-end) and conduct extensive experiments on ClidSum to provide deeper analyses. Furthermore, we propose mDialBART which extends mBART via further pre-training, where the multiple objectives help the pre-trained model capture the structural characteristics as well as key content in dialogues and the transformation from source to the target language. Experimental results show the superiority of mDialBART, as an end-to-end model, outperforms strong pipeline models on ClidSum. Finally, we discuss specific challenges that current approaches faced with this task and give multiple promising directions for future research. We have released the dataset and code at https://github.com/krystalan/ClidSum",
    "checked": true,
    "id": "8de8bb09515370a44a6830b3041dd6f131d7ee3e",
    "semantic_title": "clidsum: a benchmark dataset for cross-lingual dialogue summarization",
    "citation_count": 27,
    "authors": [
      "Jiaan Wang",
      "Fandong Meng",
      "Ziyao Lu",
      "Duo Zheng",
      "Zhixu Li",
      "Jianfeng Qu",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.527": {
    "title": "Spectral Probing",
    "volume": "main",
    "abstract": "Linguistic information is encoded at varying timescales (subwords, phrases, etc.) and communicative levels, such as syntax and semantics. Contextualized embeddings have analogously been found to capture these phenomena at distinctive layers and frequencies. Leveraging these findings, we develop a fully learnable frequency filter to identify spectral profiles for any given task. It enables vastly more granular analyses than prior handcrafted filters, and improves on efficiency. After demonstrating the informativeness of spectral probing over manual filters in a monolingual setting, we investigate its multilingual characteristics across seven diverse NLP tasks in six languages. Our analyses identify distinctive spectral profiles which quantify cross-task similarity in a linguistically intuitive manner, while remaining consistent across languages—highlighting their potential as robust, lightweight task descriptors",
    "checked": true,
    "id": "b99001e74f77af866c0da1aa735e74592e7c949f",
    "semantic_title": "spectral probing",
    "citation_count": 2,
    "authors": [
      "Max Müller-Eberstein",
      "Rob van der Goot",
      "Barbara Plank"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.528": {
    "title": "QASem Parsing: Text-to-text Modeling of QA-based Semantics",
    "volume": "main",
    "abstract": "Various works suggest the appeals of incorporating explicit semantic representations when addressing challenging realistic NLP scenarios. Common approaches offer either comprehensive linguistically-based formalisms, like AMR, or alternatively Open-IE, which provides a shallow and partial representation. More recently, an appealing trend introduces semi-structured natural-language structures as an intermediate meaning-capturing representation, often in the form of questions and answers. In this work, we further promote this line of research by considering three prior QA-based semantic representations. These cover verbal, nominalized and discourse-based predications, regarded as jointly providing a comprehensive representation of textual information — termed QASem. To facilitate this perspective, we investigate how to best utilize pre-trained sequence-to-sequence language models, which seem particularly promising for generating representations that consist of natural language expressions (questions and answers). In particular, we examine and analyze input and output linearization strategies, as well as data augmentation and multitask learning for a scarce training data setup. Consequently, we release the first unified QASem parsing tool, easily applicable for downstream tasks that can benefit from an explicit semi-structured account of information units in text",
    "checked": true,
    "id": "ae654627c4beed0afb94c9276701fd7e33907b9a",
    "semantic_title": "qasem parsing: text-to-text modeling of qa-based semantics",
    "citation_count": 8,
    "authors": [
      "Ayal Klein",
      "Eran Hirsch",
      "Ron Eliav",
      "Valentina Pyatkin",
      "Avi Caciularu",
      "Ido Dagan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.529": {
    "title": "Keyphrase Generation via Soft and Hard Semantic Corrections",
    "volume": "main",
    "abstract": "Keyphrase generation aims to generate a set of condensed phrases given a source document. Although maximum likelihood estimation (MLE) based keyphrase generation methods have shown impressive performance, they suffer from the bias on the source-prediction sequence pair and the bias on the prediction-target pair. To tackle the above biases, we propose a novel correction model CorrKG on top of the MLE pipeline, where the biases are corrected via the optimal transport (OT) and a frequency-based filtering-and-sorting (FreqFS) strategy. Specifically, OT is introduced as soft correction to facilitate the alignment of salient information and rectify the semantic bias in the source document and predicted keyphrases pair. An adaptive semantic mass learning scheme is conducted on the vanilla OT to achieve a proper pair-wise optimal transport procedure, which promotes the OT learning brought by rectifying semantic masses dynamically. Besides, the FreqFS strategy is designed as hard correction to reduce the bias of predicted and ground truth keyphrases, and thus to generate accurate and sufficient keyphrases. Extensive experiments over multiple benchmark datasets show that our model achieves superior keyphrase generation as compared with the state-of-the-arts",
    "checked": true,
    "id": "722ab6384537740fbfe30d10bdd6fa974b553d51",
    "semantic_title": "keyphrase generation via soft and hard semantic corrections",
    "citation_count": 3,
    "authors": [
      "Guangzhen Zhao",
      "Guoshun Yin",
      "Peng Yang",
      "Yu Yao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.530": {
    "title": "Modal-specific Pseudo Query Generation for Video Corpus Moment Retrieval",
    "volume": "main",
    "abstract": "Video corpus moment retrieval (VCMR) is the task to retrieve the most relevant video moment from a large video corpus using a natural language query. For narrative videos, e.g., drama or movies, the holistic understanding of temporal dynamics and multimodal reasoning are crucial. Previous works have shown promising results; however, they relied on the expensive query annotations for the VCMR, i.e., the corresponding moment intervals. To overcome this problem, we propose a self-supervised learning framework: Modal-specific Pseudo Query Generation Network (MPGN).First, MPGN selects candidate temporal moments via subtitle-based moment sampling. Then, it generates pseudo queries exploiting both visualand textual information from the selected temporal moments. Through the multimodal information in the pseudo queries, we show that MPGN successfully learns to localize the video corpus moment without any explicit annotation. We validate the effectiveness of MPGN on TVR dataset, showing the competitive results compared with both supervised models and unsupervised setting models",
    "checked": true,
    "id": "42d0c43d016b1cc1b8bf0fb01cbad17bdbb16400",
    "semantic_title": "modal-specific pseudo query generation for video corpus moment retrieval",
    "citation_count": 2,
    "authors": [
      "Minjoon Jung",
      "SeongHo Choi",
      "JooChan Kim",
      "Jin-Hwa Kim",
      "Byoung-Tak Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.531": {
    "title": "DuQM: A Chinese Dataset of Linguistically Perturbed Natural Questions for Evaluating the Robustness of Question Matching Models",
    "volume": "main",
    "abstract": "In this paper, we focus on the robustness evaluation of Chinese Question Matching (QM) models. Most of the previous work on analyzing robustness issues focus on just one or a few types of artificial adversarial examples. Instead, we argue that a comprehensive evaluation should be conducted on natural texts, which takes into account the fine-grained linguistic capabilities of QM models. For this purpose, we create a Chinese dataset namely DuQM which contains natural questions with linguistic perturbations to evaluate the robustness of QM models. DuQM contains 3 categories and 13 subcategories with 32 linguistic perturbations. The extensive experiments demonstrate that DuQM has a better ability to distinguish different models. Importantly, the detailed breakdown of evaluation by the linguistic phenomena in DuQM helps us easily diagnose the strength and weakness of different models. Additionally, our experiment results show that the effect of artificial adversarial examples does not work on natural texts. Our baseline codes and a leaderboard are now publicly available",
    "checked": true,
    "id": "3d9c624ce3a4c968f901d17c507b06fa5abe4c5b",
    "semantic_title": "duqm: a chinese dataset of linguistically perturbed natural questions for evaluating the robustness of question matching models",
    "citation_count": 3,
    "authors": [
      "Hongyu Zhu",
      "Yan Chen",
      "Jing Yan",
      "Jing Liu",
      "Yu Hong",
      "Ying Chen",
      "Hua Wu",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.532": {
    "title": "DivEMT: Neural Machine Translation Post-Editing Effort Across Typologically Diverse Languages",
    "volume": "main",
    "abstract": "We introduce DivEMT, the first publicly available post-editing study of Neural Machine Translation (NMT) over a typologically diverse set of target languages. Using a strictly controlled setup, 18 professional translators were instructed to translate or post-edit the same set of English documents into Arabic, Dutch, Italian, Turkish, Ukrainian, and Vietnamese. During the process, their edits, keystrokes, editing times and pauses were recorded, enabling an in-depth, cross-lingual evaluation of NMT quality and post-editing effectiveness. Using this new dataset, we assess the impact of two state-of-the-art NMT systems, Google Translate and the multilingual mBART-50 model, on translation productivity. We find that post-editing is consistently faster than translation from scratch. However, the magnitude of productivity gains varies widely across systems and languages, highlighting major disparities in post-editing effectiveness for languages at different degrees of typological relatedness to English, even when controlling for system architecture and training data size. We publicly release the complete dataset including all collected behavioral data, to foster new research on the translation capabilities of NMT systems for typologically diverse languages",
    "checked": true,
    "id": "457987f1e7c22e193a8d0dd3704781b3a51b977f",
    "semantic_title": "divemt: neural machine translation post-editing effort across typologically diverse languages",
    "citation_count": 3,
    "authors": [
      "Gabriele Sarti",
      "Arianna Bisazza",
      "Ana Guerberof-Arenas",
      "Antonio Toral"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.533": {
    "title": "Bridging Fairness and Environmental Sustainability in Natural Language Processing",
    "volume": "main",
    "abstract": "Fairness and environmental impact are important research directions for the sustainable development of artificial intelligence. However, while each topic is an active research area in natural language processing (NLP), there is a surprising lack of research on the interplay between the two fields. This lacuna is highly problematic, since there is increasing evidence that an exclusive focus on fairness can actually hinder environmental sustainability, and vice versa. In this work, we shed light on this crucial intersection in NLP by (1) investigating the efficiency of current fairness approaches through surveying example methods for reducing unfair stereotypical bias from the literature, and (2) evaluating a common technique to reduce energy consumption (and thus environmental impact) of English NLP models, knowledge distillation (KD), for its impact on fairness. In this case study, we evaluate the effect of important KD factors, including layer and dimensionality reduction, with respect to: (a) performance on the distillation task (natural language inference and semantic similarity prediction), and (b) multiple measures and dimensions of stereotypical bias (e.g., gender bias measured via the Word Embedding Association Test). Our results lead us to clarify current assumptions regarding the effect of KD on unfair bias: contrary to other findings, we show that KD can actually decrease model fairness",
    "checked": true,
    "id": "a8c09c41f39d798dc4201eeec1452fe617e428df",
    "semantic_title": "bridging fairness and environmental sustainability in natural language processing",
    "citation_count": 5,
    "authors": [
      "Marius Hessenthaler",
      "Emma Strubell",
      "Dirk Hovy",
      "Anne Lauscher"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.534": {
    "title": "UniMSE: Towards Unified Multimodal Sentiment Analysis and Emotion Recognition",
    "volume": "main",
    "abstract": "Multimodal sentiment analysis (MSA) and emotion recognition in conversation (ERC) are key research topics for computers to understand human behaviors. From a psychological perspective, emotions are the expression of affect or feelings during a short period, while sentiments are formed and held for a longer period. However, most existing works study sentiment and emotion separately and do not fully exploit the complementary knowledge behind the two. In this paper, we propose a multimodal sentiment knowledge-sharing framework (UniMSE) that unifies MSA and ERC tasks from features, labels, and models. We perform modality fusion at the syntactic and semantic levels and introduce contrastive learning between modalities and samples to better capture the difference and consistency between sentiments and emotions. Experiments on four public benchmark datasets, MOSI, MOSEI, MELD, and IEMOCAP, demonstrate the effectiveness of the proposed method and achieve consistent improvements compared with state-of-the-art methods",
    "checked": true,
    "id": "bd982b3628977709ec0fc9ae5756417209ed803c",
    "semantic_title": "unimse: towards unified multimodal sentiment analysis and emotion recognition",
    "citation_count": 35,
    "authors": [
      "Guimin Hu",
      "Ting-En Lin",
      "Yi Zhao",
      "Guangming Lu",
      "Yuchuan Wu",
      "Yongbin Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.535": {
    "title": "Is the Brain Mechanism for Hierarchical Structure Building Universal Across Languages? An fMRI Study of Chinese and English",
    "volume": "main",
    "abstract": "Evidence from psycholinguistic studies suggests that the human brain builds a hierarchical syntactic structure during language comprehension. However, it is still unknown whether the neural basis of such structures is universal across languages. In this paper, we first analyze the differences in language structure between two diverse languages: Chinese and English. By computing the working memory requirements when applying parsing strategies to different language structures, we find that top-down parsing generates less memory load for the right-branching English and bottom-up parsing is less memory-demanding for Chinese.Then we use functional magnetic resonance imaging (fMRI) to investigate whether the brain has different syntactic adaptation strategies in processing Chinese and English. Specifically, for both Chinese and English, we extract predictors from the implementations of different parsing strategies, i.e., bottom-up and top-down. Then, these predictors are separately associated with fMRI signals. Results show that for Chinese and English, the brain utilizes bottom-up and top-down parsing strategies separately. These results reveal that the brain adopts parsing strategies with less memory processing load according to different language structures",
    "checked": true,
    "id": "a53b9a833d3093054a8aa5a26af38cfce4c94107",
    "semantic_title": "is the brain mechanism for hierarchical structure building universal across languages? an fmri study of chinese and english",
    "citation_count": 2,
    "authors": [
      "Xiaohan Zhang",
      "Shaonan Wang",
      "Nan Lin",
      "Chengqing Zong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.536": {
    "title": "HashFormers: Towards Vocabulary-independent Pre-trained Transformers",
    "volume": "main",
    "abstract": "Transformer-based pre-trained language models are vocabulary-dependent, mapping by default each token to its corresponding embedding. This one-to-one mapping results into embedding matrices that occupy a lot of memory (i.e. millions of parameters) and grow linearly with the size of the vocabulary. Previous work on on-device transformers dynamically generate token embeddings on-the-fly without embedding matrices using locality-sensitive hashing over morphological information. These embeddings are subsequently fed into transformer layers for text classification. However, these methods are not pre-trained. Inspired by this line of work, we propose HashFormers, a new family of vocabulary-independent pre-trained transformers that support an unlimited vocabulary (i.e. all possible tokens in a corpus) given a substantially smaller fixed-sized embedding matrix. We achieve this by first introducing computationally cheap hashing functions that bucket together individual tokens to embeddings. We also propose three variants that do not require an embedding matrix at all, further reducing the memory requirements. We empirically demonstrate that HashFormers are more memory efficient compared to standard pre-trained transformers while achieving comparable predictive performance when fine-tuned on multiple text classification tasks. For example, our most efficient HashFormer variant has a negligible performance degradation (0.4% on GLUE) using only 99.1K parameters for representing the embeddings compared to 12.3-38M parameters of state-of-the-art models",
    "checked": true,
    "id": "12d2a697f1ee6a63859efe6b288ddb5eb6bd97c1",
    "semantic_title": "hashformers: towards vocabulary-independent pre-trained transformers",
    "citation_count": 3,
    "authors": [
      "Huiyin Xue",
      "Nikolaos Aletras"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.537": {
    "title": "MatchPrompt: Prompt-based Open Relation Extraction with Semantic Consistency Guided Clustering",
    "volume": "main",
    "abstract": "Relation clustering is a general approach for open relation extraction (OpenRE). Current methods have two major problems. One is that their good performance relies on large amounts of labeled and pre-defined relational instances for pre-training, which are costly to acquire in reality. The other is that they only focus on learning a high-dimensional metric space to measure the similarity of novel relations and ignore the specific relational representations of clusters. In this work, we propose a new prompt-based framework named MatchPrompt, which can realize OpenRE with efficient knowledge transfer from only a few pre-defined relational instances as well as mine the specific meanings for cluster interpretability. To our best knowledge, we are the first to introduce a prompt-based framework for unlabeled clustering. Experimental results on different datasets show that MatchPrompt achieves the new SOTA results for OpenRE",
    "checked": true,
    "id": "c92ffbf75a1d2e39026ddb39d14c20ad534dc9c5",
    "semantic_title": "matchprompt: prompt-based open relation extraction with semantic consistency guided clustering",
    "citation_count": 3,
    "authors": [
      "Jiaxin Wang",
      "Lingling Zhang",
      "Jun Liu",
      "Xi Liang",
      "Yujie Zhong",
      "Yaqiang Wu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.538": {
    "title": "Improving Aspect Sentiment Quad Prediction via Template-Order Data Augmentation",
    "volume": "main",
    "abstract": "Recently, aspect sentiment quad prediction (ASQP) has become a popular task in the field of aspect-level sentiment analysis. Previous work utilizes a predefined template to paraphrase the original sentence into a structure target sequence, which can be easily decoded as quadruplets of the form (aspect category, aspect term, opinion term, sentiment polarity). The template involves the four elements in a fixed order. However, we observe that this solution contradicts with the order-free property of the ASQP task, since there is no need to fix the template order as long as the quadruplet is extracted correctly. Inspired by the observation, we study the effects of template orders and find that some orders help the generative model achieve better performance. It is hypothesized that different orders provide various views of the quadruplet. Therefore, we propose a simple but effective method to identify the most proper orders, and further combine multiple proper templates as data augmentation to improve the ASQP task. Specifically, we use the pre-trained language model to select the orders with minimal entropy. By fine-tuning the pre-trained language model with these template orders, our approach improves the performance of quad prediction, and outperforms state-of-the-art methods significantly in low-resource settings",
    "checked": true,
    "id": "d8cf0c34bc0e986a71a0a01472d124261172cd7f",
    "semantic_title": "improving aspect sentiment quad prediction via template-order data augmentation",
    "citation_count": 14,
    "authors": [
      "Mengting Hu",
      "Yike Wu",
      "Hang Gao",
      "Yinhao Bai",
      "Shiwan Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.539": {
    "title": "SocioProbe: What, When, and Where Language Models Learn about Sociodemographics",
    "volume": "main",
    "abstract": "Pre-trained language models (PLMs) have outperformed other NLP models on a wide range of tasks. Opting for a more thorough understanding of their capabilities and inner workings, researchers have established the extend to which they capture lower-level knowledge like grammaticality, and mid-level semantic knowledge like factual understanding. However, there is still little understanding of their knowledge of higher-level aspects of language. In particular, despite the importance of sociodemographic aspects in shaping our language, the questions of whether, where, and how PLMs encode these aspects, e.g., gender or age, is still unexplored. We address this research gap by probing the sociodemographic knowledge of different single-GPU PLMs on multiple English data sets via traditional classifier probing and information-theoretic minimum description length probing. Our results show that PLMs do encode these sociodemographics, and that this knowledge is sometimes spread across the layers of some of the tested PLMs. We further conduct a multilingual analysis and investigate the effect of supplementary training to further explore to what extent, where, and with what amount of pre-training data the knowledge is encoded. Our overall results indicate that sociodemographic knowledge is still a major challenge for NLP. PLMs require large amounts of pre-training data to acquire the knowledge and models that excel in general language understanding do not seem to own more knowledge about these aspects",
    "checked": true,
    "id": "1d4d3bdbc70ab400d206ae209546f267f85817c4",
    "semantic_title": "socioprobe: what, when, and where language models learn about sociodemographics",
    "citation_count": 4,
    "authors": [
      "Anne Lauscher",
      "Federico Bianchi",
      "Samuel R. Bowman",
      "Dirk Hovy"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.540": {
    "title": "When does Parameter-Efficient Transfer Learning Work for Machine Translation?",
    "volume": "main",
    "abstract": "Parameter-efficient fine-tuning methods (PEFTs) offer the promise of adapting large pre-trained models while only tuning a small number of parameters. They have been shown to be competitive with full model fine-tuning for many downstream tasks. However, prior work indicates that PEFTs may not work as well for machine translation (MT), and there is no comprehensive study showing when PEFTs work for MT. We conduct a comprehensive empirical study of PEFTs for MT, considering (1) various parameter budgets, (2) a diverse set of language-pairs, and (3) different pre-trained models. We find that ‘adapters', in which small feed-forward networks are added after every layer, are indeed on par with full model fine-tuning when the parameter budget corresponds to 10% of total model parameters. Nevertheless, as the number of tuned parameters decreases, the performance of PEFTs decreases. The magnitude of this decrease depends on the language pair, with PEFTs particularly struggling for distantly related language-pairs. We find that using PEFTs with a larger pre-trained model outperforms full fine-tuning with a smaller model, and for smaller training data sizes, PEFTs outperform full fine-tuning for the same pre-trained model",
    "checked": true,
    "id": "4f68042a0aa40f34027a49ceec64ad2bbe2211aa",
    "semantic_title": "when does parameter-efficient transfer learning work for machine translation?",
    "citation_count": 2,
    "authors": [
      "Ahmet Üstün",
      "Asa Cooper Stickland"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.541": {
    "title": "Hyper-X: A Unified Hypernetwork for Multi-Task Multilingual Transfer",
    "volume": "main",
    "abstract": "Massively multilingual models are promising for transfer learning across tasks and languages. However, existing methods are unable to fully leverage training data when it is available in different task-language combinations. To exploit such heterogeneous supervision, we propose Hyper-X, a single hypernetwork that unifies multi-task and multilingual learning with efficient adaptation. It generates weights for adapter modules conditioned on both tasks and language embeddings. By learning to combine task and language-specific knowledge, our model enables zero-shot transfer for unseen languages and task-language combinations. Our experiments on a diverse set of languages demonstrate that Hyper-X achieves the best or competitive gain when a mixture of multiple resources is available, while on par with strong baseline in the standard scenario. Hyper-X is also considerably more efficient in terms of parameters and resources compared to methods that train separate adapters. Finally, Hyper-X consistently produces strong results in few-shot scenarios for new languages, showing the versatility of our approach beyond zero-shot transfer",
    "checked": true,
    "id": "6aeb1469188354fbf572f6039822dde06b8e65bc",
    "semantic_title": "hyper-x: a unified hypernetwork for multi-task multilingual transfer",
    "citation_count": 18,
    "authors": [
      "Ahmet Üstün",
      "Arianna Bisazza",
      "Gosse Bouma",
      "Gertjan van Noord",
      "Sebastian Ruder"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.542": {
    "title": "Towards Robust Numerical Question Answering: Diagnosing Numerical Capabilities of NLP Systems",
    "volume": "main",
    "abstract": "Numerical Question Answering is the task of answering questions that require numerical capabilities. Previous works introduce general adversarial attacks to Numerical Question Answering, while not systematically exploring numerical capabilities specific to the topic. In this paper, we propose to conduct numerical capability diagnosis on a series of Numerical Question Answering systems and datasets. A series of numerical capabilities are highlighted, and corresponding dataset perturbations are designed. Empirical results indicate that existing systems are severely challenged by these perturbations. E.g., Graph2Tree experienced a 53.83% absolute accuracy drop against the \"Extra\" perturbation on ASDiv-a, and BART experienced 13.80% accuracy drop against the \"Language\" perturbation on the numerical subset of DROP. As a counteracting approach, we also investigate the effectiveness of applying perturbations as data augmentation to relieve systems' lack of robust numerical capabilities. With experiment analysis and empirical studies, it is demonstrated that Numerical Question Answering with robust numerical capabilities is still to a large extent an open question. We discuss future directions of Numerical Question Answering and summarize guidelines on future dataset collection and system design",
    "checked": true,
    "id": "1a174b63d294f96568517b91f2c8d6c9362118b5",
    "semantic_title": "towards robust numerical question answering: diagnosing numerical capabilities of nlp systems",
    "citation_count": 3,
    "authors": [
      "Jialiang Xu",
      "Mengyu Zhou",
      "Xinyi He",
      "Shi Han",
      "Dongmei Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.543": {
    "title": "Enhancing Joint Multiple Intent Detection and Slot Filling with Global Intent-Slot Co-occurrence",
    "volume": "main",
    "abstract": "Multi-intent detection and slot filling joint model attracts more and more attention since it can handle multi-intent utterances, which is closer to complex real-world scenarios. Most existing joint models rely entirely on the training procedure to obtain the implicit correlation between intents and slots. However, they ignore the fact that leveraging the rich global knowledge in the corpus can determine the intuitive and explicit correlation between intents and slots. In this paper, we aim to make full use of the statistical co-occurrence frequency between intents and slots as prior knowledge to enhance joint multiple intent detection and slot filling. To be specific, an intent-slot co-occurrence graph is constructed based on the entire training corpus to globally discover correlation between intents and slots. Based on the global intent-slot co-occurrence, we propose a novel graph neural network to model the interaction between the two subtasks. Experimental results on two public multi-intent datasets demonstrate that our approach outperforms the state-of-the-art models",
    "checked": true,
    "id": "e3d10b503682d32916ccca0ddbe0beda774cf055",
    "semantic_title": "enhancing joint multiple intent detection and slot filling with global intent-slot co-occurrence",
    "citation_count": 9,
    "authors": [
      "Mengxiao Song",
      "Bowen Yu",
      "Li Quangang",
      "Wang Yubin",
      "Tingwen Liu",
      "Hongbo Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.544": {
    "title": "Towards Pragmatic Production Strategies for Natural Language Generation Tasks",
    "volume": "main",
    "abstract": "This position paper proposes a conceptual framework for the design of Natural Language Generation (NLG) systems that follow efficient and effective production strategies in order to achieve complex communicative goals. In this general framework, efficiency is characterised as the parsimonious regulation of production and comprehension costs while effectiveness is measured with respect to task-oriented and contextually grounded communicative goals. We provide concrete suggestions for the estimation of goals, costs, and utility via modern statistical methods, demonstrating applications of our framework to the classic pragmatic task of visually grounded referential games and to abstractive text summarisation, two popular generation tasks with real-world applications. In sum, we advocate for the development of NLG systems that learn to make pragmatic production decisions from experience, by reasoning about goals, costs, and utility in a human-like way",
    "checked": true,
    "id": "d1670333cd0e264f5b45b4c94f14fa741bd5066b",
    "semantic_title": "towards pragmatic production strategies for natural language generation tasks",
    "citation_count": 3,
    "authors": [
      "Mario Giulianelli"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.545": {
    "title": "LiteVL: Efficient Video-Language Learning with Enhanced Spatial-Temporal Modeling",
    "volume": "main",
    "abstract": "Recent large-scale video-language pre-trained models have shown appealing performance on various downstream tasks. However, the pre-training process is computationally expensive due to the requirement of millions of video-text pairs and the redundant data structure of each video. To mitigate these problems, we propose LiteVL, which adapts a pre-trained image-language model BLIP into a video-text model directly on downstream tasks, without heavy pre-training. To enhance the temporal modeling lacking in the image-language model, we propose to add temporal attention modules in the image encoder of BLIP with dynamic temporal scaling. Besides the model-wise adaptation, we also propose a non-parametric pooling mechanism to adaptively reweight the fine-grained video embedding conditioned on the text. Experimental results on text-video retrieval and video question answering show that the proposed LiteVL even outperforms previous video-language pre-trained models by a clear margin, though without any video-language pre-training",
    "checked": true,
    "id": "60979e2ae04a61dac30b5198784c0c2fb5cd8039",
    "semantic_title": "litevl: efficient video-language learning with enhanced spatial-temporal modeling",
    "citation_count": 10,
    "authors": [
      "Dongsheng Chen",
      "Chaofan Tao",
      "Lu Hou",
      "Lifeng Shang",
      "Xin Jiang",
      "Qun Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.546": {
    "title": "Communication breakdown: On the low mutual intelligibility between human and neural captioning",
    "volume": "main",
    "abstract": "We compare the 0-shot performance of a neural caption-based image retriever when given as input either human-produced captions or captions generated by a neural captioner. We conduct this comparison on the recently introduced ImageCoDe data-set (Krojer et al. 2022), which contains hard distractors nearly identical to the images to be retrieved. We find that the neural retriever has much higher performance when fed neural rather than human captions, despite the fact that the former, unlike the latter, were generated without awareness of the distractors that make the task hard. Even more remarkably, when the same neural captions are given to human subjects, their retrieval performance is almost at chance level. Our results thus add to the growing body of evidence that, even when the \"language\" of neural models resembles English, this superficial resemblance might be deeply misleading",
    "checked": true,
    "id": "c279ae3ae94803f1cdbaa68bbede7c4c709f48d0",
    "semantic_title": "communication breakdown: on the low mutual intelligibility between human and neural captioning",
    "citation_count": 4,
    "authors": [
      "Roberto Dessì",
      "Eleonora Gualdoni",
      "Francesca Franzon",
      "Gemma Boleda",
      "Marco Baroni"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.547": {
    "title": "Normalizing Mutual Information for Robust Adaptive Training for Translation",
    "volume": "main",
    "abstract": "Despite the success of neural machine translation models, tensions between fluency of optimizing target language modeling and source-faithfulness remain as challenges. Previously, Conditional Bilingual Mutual Information (CBMI), a scoring metric for the importance of target sentences and tokens, was proposed to encourage fluent and faithful translations. The score is obtained by combining the probability from the translation model and the target language model, which is then used to assign different weights to losses from sentences and tokens. Meanwhile, we argue this metric is not properly normalized, for which we propose Normalized Pointwise Mutual Information (NPMI). NPMI utilizes an additional language model on source language to approximate the joint likelihood of source-target pair and the likelihood of the source, which is then used for normalizing the score. We showed that NPMI better captures the dependence between source-target and that NPMI-based token-level adaptive training brings improvements over baselines with empirical results from En-De, De-En, and En-Ro translation tasks",
    "checked": true,
    "id": "6d734a6b3241c5864da0b03248a46ce4f8b3057e",
    "semantic_title": "normalizing mutual information for robust adaptive training for translation",
    "citation_count": 1,
    "authors": [
      "Youngwon Lee",
      "Changmin Lee",
      "Hojin Lee",
      "Seung-won Hwang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.548": {
    "title": "Bilingual Synchronization: Restoring Translational Relationships with Editing Operations",
    "volume": "main",
    "abstract": "Machine Translation (MT) is usually viewed as a one-shot process that generates the target language equivalent of some source text from scratch. We consider here a more general setting which assumes an initial target sequence, that must be transformed into a valid translation of the source, thereby restoring parallelism between source and target. For this bilingual synchronization task, we consider several architectures (both autoregressive and non-autoregressive) and training regimes, and experiment with multiple practical settings such as simulated interactive MT, translating with Translation Memory (TM) and TM cleaning. Our results suggest that one single generic edit-based system, once fine-tuned, can compare with, or even outperform, dedicated systems specifically trained for these tasks",
    "checked": true,
    "id": "c9d382d9960f5d7d54ca260ffa2e3bff7092f0be",
    "semantic_title": "bilingual synchronization: restoring translational relationships with editing operations",
    "citation_count": 4,
    "authors": [
      "Jitao Xu",
      "Josep Crego",
      "François Yvon"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.549": {
    "title": "Human-Machine Collaboration Approaches to Build a Dialogue Dataset for Hate Speech Countering",
    "volume": "main",
    "abstract": "Fighting online hate speech is a challenge that is usually addressed using Natural Language Processing via automatic detection and removal of hate content. Besides this approach, counter narratives have emerged as an effective tool employed by NGOs to respond to online hate on social media platforms. For this reason, Natural Language Generation is currently being studied as a way to automatize counter narrative writing. However, the existing resources necessary to train NLG models are limited to 2-turn interactions (a hate speech and a counter narrative as response), while in real life, interactions can consist of multiple turns. In this paper, we present a hybrid approach for dialogical data collection, which combines the intervention of human expert annotators over machine generated dialogues obtained using 19 different configurations. The result of this work is DIALOCONAN, the first dataset comprising over 3000 fictitious multi-turn dialogues between a hater and an NGO operator, covering 6 targets of hate",
    "checked": true,
    "id": "b22a61395dd47f74c3c05c9e801deaec3f01f482",
    "semantic_title": "human-machine collaboration approaches to build a dialogue dataset for hate speech countering",
    "citation_count": 21,
    "authors": [
      "Helena Bonaldi",
      "Sara Dellantonio",
      "Serra Sinem Tekiroğlu",
      "Marco Guerini"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.550": {
    "title": "JANUS: Joint Autoregressive and Non-autoregressive Training with Auxiliary Loss for Sequence Generation",
    "volume": "main",
    "abstract": "Transformer-based autoregressive and non-autoregressive models have played an essential role in sequence generation tasks. The autoregressive model can obtain excellent performance, while the non-autoregressive model brings fast decoding speed for inference. In this paper, we propose JANUS, a Joint Autoregressive and Non-autoregressive training method using aUxiliary losS to enhance the model performance in both AR and NAR manner simultaneously and effectively alleviate the problem of distribution discrepancy.Further, we pre-train BART with JANUS on a large corpus with minimal cost (16 GPU days) and make the BART-JANUS capable of non-autoregressive generation, demonstrating that our approach can transfer the AR knowledge to NAR. Empirically, we show our approach and BART-JANUS can achieve significant improvement on multiple generation tasks, including machine translation and GLGE benchmarks. Our code is available at Github",
    "checked": true,
    "id": "e89de16512d72d4e911e3b58ee08c73c62cb0d70",
    "semantic_title": "janus: joint autoregressive and non-autoregressive training with auxiliary loss for sequence generation",
    "citation_count": 2,
    "authors": [
      "Xiaobo Liang",
      "Lijun Wu",
      "Juntao Li",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.551": {
    "title": "Entity-Focused Dense Passage Retrieval for Outside-Knowledge Visual Question Answering",
    "volume": "main",
    "abstract": "Most Outside-Knowledge Visual Question Answering (OK-VQA) systems employ a two-stage framework that first retrieves external knowledge given the visual question and then predicts the answer based on the retrieved content. However, the retrieved knowledge is often inadequate. Retrievals are frequently too general and fail to cover specific knowledge needed to answer the question. Also, the naturally available supervision (whether the passage contains the correct answer) is weak and does not guarantee question relevancy. To address these issues, we propose an Entity-Focused Retrieval (EnFoRe) model that provides stronger supervision during training and recognizes question-relevant entities to help retrieve more specific knowledge. Experiments show that our EnFoRe model achieves superior retrieval performance on OK-VQA, the currently largest outside-knowledge VQA dataset. We also combine the retrieved knowledge with state-of-the-art VQA models, and achieve a new state-of-the-art performance on OK-VQA",
    "checked": true,
    "id": "915db407b5bbeb0ca9a9f33668533450d8e54af4",
    "semantic_title": "entity-focused dense passage retrieval for outside-knowledge visual question answering",
    "citation_count": 5,
    "authors": [
      "Jialin Wu",
      "Raymond Mooney"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.552": {
    "title": "Cross-Linguistic Syntactic Difference in Multilingual BERT: How Good is It and How Does It Affect Transfer?",
    "volume": "main",
    "abstract": "Multilingual BERT (mBERT) has demonstrated considerable cross-lingual syntactic ability, whereby it enables effective zero-shot cross-lingual transfer of syntactic knowledge. The transfer is more successful between some languages, but it is not well understood what leads to this variation and whether it fairly reflects difference between languages. In this work, we investigate the distributions of grammatical relations induced from mBERT in the context of 24 typologically different languages. We demonstrate that the distance between the distributions of different languages is highly consistent with the syntactic difference in terms of linguistic formalisms. Such difference learnt via self-supervision plays a crucial role in the zero-shot transfer performance and can be predicted by variation in morphosyntactic properties between languages. These results suggest that mBERT properly encodes languages in a way consistent with linguistic diversity and provide insights into the mechanism of cross-lingual transfer",
    "checked": true,
    "id": "bfff952fb890f3eb4ba22718f1df70a030741b74",
    "semantic_title": "cross-linguistic syntactic difference in multilingual bert: how good is it and how does it affect transfer?",
    "citation_count": 9,
    "authors": [
      "Ningyu Xu",
      "Tao Gui",
      "Ruotian Ma",
      "Qi Zhang",
      "Jingting Ye",
      "Menghan Zhang",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.553": {
    "title": "It's Not Just Hate\": A Multi-Dimensional Perspective on Detecting Harmful Speech Online",
    "volume": "main",
    "abstract": "Well-annotated data is a prerequisite for good Natural Language Processing models. Too often, though, annotation decisions are governed by optimizing time or annotator agreement. We make a case for nuanced efforts in an interdisciplinary setting for annotating offensive online speech. Detecting offensive content is rapidly becoming one of the most important real-world NLP tasks. However, most datasets use a single binary label, e.g., for hate or incivility, even though each concept is multi-faceted. This modeling choice severely limits nuanced insights, but also performance. We show that a more fine-grained multi-label approach to predicting incivility and hateful or intolerant content addresses both conceptual and performance issues. We release a novel dataset of over 40,000 tweets about immigration from the US and UK, annotated with six labels for different aspects of incivility and intolerance. Our dataset not only allows for a more nuanced understanding of harmful speech online, models trained on it also outperform or match performance on benchmark datasets",
    "checked": true,
    "id": "1daf323d06fc68feba72d8826ea3372ef50aee14",
    "semantic_title": "it's not just hate\": a multi-dimensional perspective on detecting harmful speech online",
    "citation_count": 7,
    "authors": [
      "Federico Bianchi",
      "Stefanie HIlls",
      "Patricia Rossini",
      "Dirk Hovy",
      "Rebekah Tromble",
      "Nava Tintarev"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.554": {
    "title": "Long Text Generation with Topic-aware Discrete Latent Variable Model",
    "volume": "main",
    "abstract": "Generating coherent long texts is an important yet challenging task, particularly forthe open-ended generation. Prior work based on discrete latent codes focuses on the modeling of discourse relation, resulting in discrete codes only learning shallow semantics (Ji and Huang, 2021). A natural text always revolves around several related topics and the transition across them is natural and smooth. In this work, we investigate whether discrete latent codes can learn information of topics. To this end, we build a topic-aware latent code-guided text generation model. To encourage discrete codes to model information about topics, we propose a span-level bag-of-words training objective for the model. Automatic and manual evaluation experiments show that our method can generate more topic-relevant and coherent texts",
    "checked": true,
    "id": "aae974a2abbdfcb26a5034d5cf4e764b7a37c97b",
    "semantic_title": "long text generation with topic-aware discrete latent variable model",
    "citation_count": 0,
    "authors": [
      "Erguang Yang",
      "Mingtong Liu",
      "Deyi Xiong",
      "Yujie Zhang",
      "Yufeng Chen",
      "Jinan Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.555": {
    "title": "TIARA: Multi-grained Retrieval for Robust Question Answering over Large Knowledge Base",
    "volume": "main",
    "abstract": "Pre-trained language models (PLMs) have shown their effectiveness in multiple scenarios. However, KBQA remains challenging, especially regarding coverage and generalization settings. This is due to two main factors: i) understanding the semantics of both questions and relevant knowledge from the KB; ii) generating executable logical forms with both semantic and syntactic correctness. In this paper, we present a new KBQA model, TIARA, which addresses those issues by applying multi-grained retrieval to help the PLM focus on the most relevant KB context, viz., entities, exemplary logical forms, and schema items. Moreover, constrained decoding is used to control the output space and reduce generation errors. Experiments over important benchmarks demonstrate the effectiveness of our approach. TIARA outperforms previous SOTA, including those using PLMs or oracle entity annotations, by at least 4.1 and 1.1 F1 points on GrailQA and WebQuestionsSP, respectively. Specifically on GrailQA, TIARA outperforms previous models in all categories, with an improvement of 4.7 F1 points in zero-shot generalization",
    "checked": true,
    "id": "dbc6622b8c70bc1a3cc290fdb166229d80ec8f83",
    "semantic_title": "tiara: multi-grained retrieval for robust question answering over large knowledge base",
    "citation_count": 36,
    "authors": [
      "Yiheng Shu",
      "Zhiwei Yu",
      "Yuhan Li",
      "Börje Karlsson",
      "Tingting Ma",
      "Yuzhong Qu",
      "Chin-Yew Lin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.556": {
    "title": "Structure-Unified M-Tree Coding Solver for Math Word Problem",
    "volume": "main",
    "abstract": "As one of the challenging NLP tasks, designing math word problem (MWP) solvers has attracted increasing research attention for the past few years. In previous work, models designed by taking into account the properties of the binary tree structure of mathematical expressions at the output side have achieved better performance. However, the expressions corresponding to a MWP are often diverse (e.g., n1+n2 × n3-n4, n3× n2-n4+n1, etc.), and so are the corresponding binary trees, which creates difficulties in model learning due to the non-deterministic output space. In this paper, we propose the Structure-Unified M-Tree Coding Solver (SUMC-Solver), which applies a tree with any M branches (M-tree) to unify the output structures. To learn the M-tree, we use a mapping to convert the M-tree into the M-tree codes, where codes store the information of the paths from tree root to leaf nodes and the information of leaf nodes themselves, and then devise a Sequence-to-Code (seq2code) model to generate the codes. Experimental results on the widely used MAWPS and Math23K datasets have demonstrated that SUMC-Solver not only outperforms several state-of-the-art models under similar experimental settings but also performs much better under low-resource conditions",
    "checked": true,
    "id": "c50501a64ceeeff5c37e200df670bbf6ae0e904b",
    "semantic_title": "structure-unified m-tree coding solver for math word problem",
    "citation_count": 5,
    "authors": [
      "Bin Wang",
      "Jiangzhou Ju",
      "Yang Fan",
      "Xinyu Dai",
      "Shujian Huang",
      "Jiajun Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.557": {
    "title": "FormLM: Recommending Creation Ideas for Online Forms by Modelling Semantic and Structural Information",
    "volume": "main",
    "abstract": "Online forms are widely used to collect data from human and have a multi-billion market. Many software products provide online services for creating semi-structured forms where questions and descriptions are organized by predefined structures. However, the design and creation process of forms is still tedious and requires expert knowledge. To assist form designers, in this work we present FormLM to model online forms (by enhancing pre-trained language model with form structural information) and recommend form creation ideas (including question / options recommendations and block type suggestion). For model training and evaluation, we collect the first public online form dataset with 62K online forms. Experiment results show that FormLM significantly outperforms general-purpose language models on all tasks, with an improvement by 4.71 on Question Recommendation and 10.6 on Block Type Suggestion in terms of ROUGE-1 and Macro-F1, respectively",
    "checked": true,
    "id": "c9d90133c08a92d3d99cddee5d107933cf241367",
    "semantic_title": "formlm: recommending creation ideas for online forms by modelling semantic and structural information",
    "citation_count": 1,
    "authors": [
      "Yijia Shao",
      "Mengyu Zhou",
      "Yifan Zhong",
      "Tao Wu",
      "Hongwei Han",
      "Shi Han",
      "Gideon Huang",
      "Dongmei Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.558": {
    "title": "Generate, Discriminate and Contrast: A Semi-Supervised Sentence Representation Learning Framework",
    "volume": "main",
    "abstract": "Most sentence embedding techniques heavily rely on expensive human-annotated sentence pairs as the supervised signals. Despite the use of large-scale unlabeled data, the performance of unsupervised methods typically lags far behind that of the supervised counterparts in most downstream tasks. In this work, we propose a semi-supervised sentence embedding framework, GenSE, that effectively leverages large-scale unlabeled data. Our method include three parts: 1) Generate: A generator/discriminator model is jointly trained to synthesize sentence pairs from open-domain unlabeled corpus; 2) Discriminate: Noisy sentence pairs are filtered out by the discriminator to acquire high-quality positive and negative sentence pairs; 3) Contrast: A prompt-based contrastive approach is presented for sentence representation learning with both annotated and synthesized data. Comprehensive experiments show that GenSE achieves an average correlation score of 85.19 on the STS datasets and consistent performance improvement on four domain adaptation tasks, significantly surpassing the state-of-the-art methods and convincingly corroborating its effectiveness and generalization ability",
    "checked": true,
    "id": "5509a26ed65b31982506a6f704f927230f78f133",
    "semantic_title": "generate, discriminate and contrast: a semi-supervised sentence representation learning framework",
    "citation_count": 13,
    "authors": [
      "Yiming Chen",
      "Yan Zhang",
      "Bin Wang",
      "Zuozhu Liu",
      "Haizhou Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.559": {
    "title": "GPS: Genetic Prompt Search for Efficient Few-Shot Learning",
    "volume": "main",
    "abstract": "Prompt-based techniques have demostrated great potential for improving the few-shot generalization of pretrained language models. However, their performance heavily relies on the manual design of prompts and thus requiring a lot of human efforts. In this paper, we introduce Genetic Prompt Search (GPS) to improve few-shot learning with prompts, which utilizes a genetic algorithm to automatically search for the best prompt.GPS is gradient-free and requires no update of model parameters but only a small validation set. Experiments on diverse datasets proved the effectiveness of GPS, which outperforms manual prompts by a large margin of 2.6 points. Our method is also better than other parameter-efficient tuning methods such as prompt tuning",
    "checked": true,
    "id": "37f0f1f55f44bff84aac27a346dd47d0c6c136e3",
    "semantic_title": "gps: genetic prompt search for efficient few-shot learning",
    "citation_count": 15,
    "authors": [
      "Hanwei Xu",
      "Yujun Chen",
      "Yulun Du",
      "Nan Shao",
      "Wang Yanggang",
      "Haiyu Li",
      "Zhilin Yang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.560": {
    "title": "Multitask Instruction-based Prompting for Fallacy Recognition",
    "volume": "main",
    "abstract": "Fallacies are used as seemingly valid arguments to support a position and persuade the audience about its validity. Recognizing fallacies is an intrinsically difficult task both for humans and machines. Moreover, a big challenge for computational models lies in the fact that fallacies are formulated differently across the datasets with differences in the input format (e.g., question-answer pair, sentence with fallacy fragment), genre (e.g., social media, dialogue, news), as well as types and number of fallacies (from 5 to 18 types per dataset). To move towards solving the fallacy recognition task, we approach these differences across datasets as multiple tasks and show how instruction-based prompting in a multitask setup based on the T5 model improves the results against approaches built for a specific dataset such as T5, BERT or GPT-3. We show the ability of this multitask prompting approach to recognize 28 unique fallacies across domains and genres and study the effect of model size and prompt choice by analyzing the per-class (i.e., fallacy type) results. Finally, we analyze the effect of annotation quality on model performance, and the feasibility of complementing this approach with external knowledge",
    "checked": true,
    "id": "2eb0e52354b7bbee820905189985877700651108",
    "semantic_title": "multitask instruction-based prompting for fallacy recognition",
    "citation_count": 11,
    "authors": [
      "Tariq Alhindi",
      "Tuhin Chakrabarty",
      "Elena Musi",
      "Smaranda Muresan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.561": {
    "title": "Rethinking Multi-Modal Alignment in Multi-Choice VideoQA from Feature and Sample Perspectives",
    "volume": "main",
    "abstract": "Reasoning about causal and temporal event relations in videos is a new destination of Video Question Answering (VideoQA). The major stumbling block to achieve this purpose is the semantic gap between language and video since they are at different levels of abstraction. Existing efforts mainly focus on designing sophisticated architectures while utilizing frame- or object-level visual representations. In this paper, we reconsider the multi-modal alignment problem in VideoQA from feature and sample perspectives to achieve better performance. From the view of feature, we break down the video into trajectories and first leverage trajectory feature in VideoQA to enhance the alignment between two modalities. Moreover, we adopt a heterogeneous graph architecture and design a hierarchical framework to align both trajectory-level and frame-level visual feature with language feature. In addition, we found that VideoQA models are largely dependent on languagepriors and always neglect visual-language interactions. Thus, two effective yet portable training augmentation strategies are designed to strengthen the cross-modal correspondence ability of our model from the view of sample. Extensive results show that our method outperforms all the state-of the-art models on the challenging NExT-QA benchmark",
    "checked": true,
    "id": "8791a6af0d45807bd2681bf2f2ed137f8c68cc27",
    "semantic_title": "rethinking multi-modal alignment in multi-choice videoqa from feature and sample perspectives",
    "citation_count": 3,
    "authors": [
      "Shaoning Xiao",
      "Long Chen",
      "Kaifeng Gao",
      "Zhao Wang",
      "Yi Yang",
      "Zhimeng Zhang",
      "Jun Xiao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.562": {
    "title": "Towards Table-to-Text Generation with Pretrained Language Model: A Table Structure Understanding and Text Deliberating Approach",
    "volume": "main",
    "abstract": "Although remarkable progress on the neural table-to-text methods has been made, the generalization issues hinder the applicability of these models due to the limited source tables. Large-scale pretrained language models sound like a promising solution to tackle such issues. However, how to effectively bridge the gap between the structured table and the text input by fully leveraging table information to fuel the pretrained model is still not well explored. Besides, another challenge of integrating the deliberation mechanism into the text-to-text pretrained model for solving the table-to-text task remains seldom studied. In this paper, to implement the table-to-text generation with pretrained language model, we propose a table structure understanding and text deliberating approach, namely TASD. To be specific, we devise a three-layered multi-head attention network to realize the table-structureaware text generation model with the help of the pretrained language model. Furthermore, a multi-pass decoder framework is adopted to enhance the capability of polishing generated text for table descriptions. The empirical studies, as well as human evaluation, on two public datasets, validate that our approach can generate faithful and fluent descriptive texts for different types of tables",
    "checked": true,
    "id": "80e441b19d2f8e1d1df5d230ae6a3ef18a0919d7",
    "semantic_title": "towards table-to-text generation with pretrained language model: a table structure understanding and text deliberating approach",
    "citation_count": 5,
    "authors": [
      "Miao Chen",
      "Xinjiang Lu",
      "Tong Xu",
      "Yanyan Li",
      "Zhou Jingbo",
      "Dejing Dou",
      "Hui Xiong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.563": {
    "title": "Hierarchical Phrase-Based Sequence-to-Sequence Learning",
    "volume": "main",
    "abstract": "This paper describes a neural transducer that maintains the flexibility of standard sequence-to-sequence (seq2seq) models while incorporating hierarchical phrases as a source of inductive bias during training and as explicit constraints during inference. Our approach trains two models: a discriminative parser based on a bracketing transduction grammar whose derivation tree hierarchically aligns source and target phrases, and a neural seq2seq model that learns to translate the aligned phrases one-by-one. We use the same seq2seq model to translate at all phrase scales, which results in two inference modes: one mode in which the parser is discarded and only the seq2seq component is used at the sequence-level, and another in which the parser is combined with the seq2seq model. Decoding in the latter mode is done with the cube-pruned CKY algorithm, which is more involved but can make use of new translation rules during inference. We formalize our model as a source-conditioned synchronous grammar and develop an efficient variational inference algorithm for training. When applied on top of both randomly initialized and pretrained seq2seq models, we find that it performs well compared to baselines on small scale machine translation benchmarks",
    "checked": true,
    "id": "eb88ec94470df34af2a49d768f3dd6a1a8316c2b",
    "semantic_title": "hierarchical phrase-based sequence-to-sequence learning",
    "citation_count": 7,
    "authors": [
      "Bailin Wang",
      "Ivan Titov",
      "Jacob Andreas",
      "Yoon Kim"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.564": {
    "title": "Natural Language Deduction with Incomplete Information",
    "volume": "main",
    "abstract": "A growing body of work studies how to answer a question or verify a claim by generating a natural language \"proof:\" a chain of deductive inferences yielding the answer based on a set of premises. However, these methods can only make sound deductions when they follow from evidence that is given. We propose a new system that can handle the underspecified setting where not all premises are stated at the outset; that is, additional assumptions need to be materialized to prove a claim. By using a natural language generation model to abductively infer a premise given another premise and a conclusion, we can impute missing pieces of evidence needed for the conclusion to be true. Our system searches over two fringes in a bidirectional fashion, interleaving deductive (forward-chaining) and abductive (backward-chaining) generation steps. We sample multiple possible outputs for each step to achieve coverage of the search space, at the same time ensuring correctness by filtering low-quality generations with a round-trip validation procedure. Results on a modified version of the EntailmentBank dataset and a new dataset called Everyday Norms: Why Not? Show that abductive generation with validation can recover premises across in- and out-of-domain settings",
    "checked": true,
    "id": "18b3ab9763ed3c4633ee68aa6dd75f6377837553",
    "semantic_title": "natural language deduction with incomplete information",
    "citation_count": 12,
    "authors": [
      "Zayne Sprague",
      "Kaj Bostrom",
      "Swarat Chaudhuri",
      "Greg Durrett"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.565": {
    "title": "Character-centric Story Visualization via Visual Planning and Token Alignment",
    "volume": "main",
    "abstract": "Story visualization advances the traditional text-to-image generation by enabling multiple image generation based on a complete story. This task requires machines to 1) understand long text inputs, and 2) produce a globally consistent image sequence that illustrates the contents of the story. A key challenge of consistent story visualization is to preserve characters that are essential in stories. To tackle the challenge, we propose to adapt a recent work that augments VQ-VAE with a text-to-visual-token (transformer) architecture. Specifically, we modify the text-to-visual-token module with a two-stage framework: 1) character token planning model that predicts the visual tokens for characters only; 2) visual token completion model that generates the remaining visual token sequence, which is sent to VQ-VAE for finalizing image generations. To encourage characters to appear in the images, we further train the two-stage framework with a character-token alignment objective. Extensive experiments and evaluations demonstrate that the proposed method excels at preserving characters and can produce higher quality image sequences compared with the strong baselines",
    "checked": true,
    "id": "a6238191cc43c41a544caadcf8b00947293cf099",
    "semantic_title": "character-centric story visualization via visual planning and token alignment",
    "citation_count": 12,
    "authors": [
      "Hong Chen",
      "Rujun Han",
      "Te-Lin Wu",
      "Hideki Nakayama",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.566": {
    "title": "ASQA: Factoid Questions Meet Long-Form Answers",
    "volume": "main",
    "abstract": "Recent progress on open domain factoid question answering (QA) does not easily transfer to the task of long-form QA, where the goal is to answer questions that require in-depth explanations. The hurdles include a lack of high-quality data and the absence of a well-defined notion of an answer's quality. In this work, we address these problems by releasing a novel dataset and a task that we call ASQA (Answer Summaries for Questions which are Ambiguous); and proposing a reliable metric for measuring performance on ASQA. Our task focuses on ambiguous factoid questions which have different correct answers depending on the interpretation. Answers to ambiguous questions should combine factual information from multiple sources into a coherent long-form summary that resolves the ambiguity. In contrast to existing long-form QA tasks (such as ELI5), ASQA admits a clear notion of correctness: a user faced with a good summary should be able to answer different interpretations of the original ambiguous question. Our analysis demonstrates an agreement between this metric and human judgments, and reveals a considerable gap between human performance and strong baselines",
    "checked": true,
    "id": "203636315f7c9526189d88c541bedf623d63ea7c",
    "semantic_title": "asqa: factoid questions meet long-form answers",
    "citation_count": 43,
    "authors": [
      "Ivan Stelmakh",
      "Yi Luan",
      "Bhuwan Dhingra",
      "Ming-Wei Chang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.567": {
    "title": "Algorithms for Acyclic Weighted Finite-State Automata with Failure Arcs",
    "volume": "main",
    "abstract": "Weighted finite-state automata (WSFAs) arecommonly used in NLP. Failure transitions area useful extension for compactly representingbackoffs or interpolation in n-gram modelsand CRFs, which are special cases of WFSAs.Unfortunately, applying standard algorithmsfor computing the pathsum requires expand-ing these compact failure transitions. As aresult, na ̈ıve computation of the pathsum inacyclic WFSAs with failure transitions runs inO(|Q|2|Σ|) (O(|Q||Σ|) for deterministic WF-SAs) while the equivalent algorithm in normalWFSAs runs in O(|E|), where E representsthe set of transitions, Q the set of states, andΣ the alphabet. In this work, we present moreefficient algorithms for computing the pathsumin sparse acyclic WFSAs, i.e., WFSAs with av-erage out symbol fraction s ≪ 1. In those,backward runs in O(s|Q||Σ|). We proposean algorithm for semiring-weighted automatawhich runs in O(|E| + s|Σ||Q||Tmax| log |Σ|),where |Tmax| is the size of the largest con-nected component of failure transitions. Ad-ditionally, we propose faster algorithms fortwo specific cases. For ring-weighted WF-SAs we propose an algorithm with complex-ity O(|E| + s|Σ||Q||πmax|), where |πmax| de-notes the longest path length of failure transi-tions stemming from q and Σ(q) the set of sym-bols on the outgoing transitions from q. Forsemiring-weighted WFSAs whose failure tran-sition topology satisfies a condition exemplifiedby CRFs, we propose an algorithm with com-plexity O(|E| + s|Σ||Q| log |Σ|)",
    "checked": true,
    "id": "5289b0490e9e82314726834b6c9f8cc7dde88991",
    "semantic_title": "algorithms for acyclic weighted finite-state automata with failure arcs",
    "citation_count": 0,
    "authors": [
      "Anej Svete",
      "Benjamin Dayan",
      "Ryan Cotterell",
      "Tim Vieira",
      "Jason Eisner"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.568": {
    "title": "Towards Better Document-level Relation Extraction via Iterative Inference",
    "volume": "main",
    "abstract": "Document-level relation extraction (RE) aims to extract the relations between entities from the input document that usually containing many difficultly-predicted entity pairs whose relations can only be predicted through relational inference. Existing methods usually directly predict the relations of all entity pairs of input document in a one-pass manner, ignoring the fact that predictions of some entity pairs heavily depend on the predicted results of other pairs. To deal with this issue, in this paper, we propose a novel document-level RE model with iterative inference. Our model is mainly composed of two modules: 1) a base module expected to provide preliminary relation predictions on entity pairs; 2) an inference module introduced to refine these preliminary predictions by iteratively dealing with difficultly-predicted entity pairs depending on other pairs in an easy-to-hard manner. Unlike previous methods which only consider feature information of entity pairs, our inference module is equipped with two Extended Cross Attention units, allowing it to exploit both feature information and previous predictions of entity pairs during relational inference. Furthermore, we adopt a two-stage strategy to train our model. At the first stage, we only train our base module. During the second stage, we train the whole model, where contrastive learning is introduced to enhance the training of inference module. Experimental results on three commonly-used datasets show that our model consistently outperforms other competitive baselines",
    "checked": true,
    "id": "ec1e29c33cfc4fb6c317c30deb84bf11bbdd411e",
    "semantic_title": "towards better document-level relation extraction via iterative inference",
    "citation_count": 4,
    "authors": [
      "Liang Zhang",
      "Jinsong Su",
      "Yidong Chen",
      "Zhongjian Miao",
      "Min Zijun",
      "Qingguo Hu",
      "Xiaodong Shi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.569": {
    "title": "Efficient Adversarial Training with Robust Early-Bird Tickets",
    "volume": "main",
    "abstract": "Adversarial training is one of the most powerful methods to improve the robustness of pre-trained language models (PLMs). However, this approach is typically more expensive than traditional fine-tuning because of the necessity to generate adversarial examples via gradient descent. Delving into the optimization process of adversarial training, we find that robust connectivity patterns emerge in the early training phase (typically 0.15~0.3 epochs), far before parameters converge. Inspired by this finding, we dig out robust early-bird tickets (i.e., subnetworks) to develop an efficient adversarial training method: (1) searching for robust tickets with structured sparsity in the early stage; (2) fine-tuning robust tickets in the remaining time. To extract the robust tickets as early as possible, we design a ticket convergence metric to automatically terminate the searching process. Experiments show that the proposed efficient adversarial training method can achieve up to 7× ∼ 13 × training speedups while maintaining comparable or even better robustness compared to the most competitive state-of-the-art adversarial training methods",
    "checked": true,
    "id": "3f91227c2a5b08815569b4c420883c56dd4833ab",
    "semantic_title": "efficient adversarial training with robust early-bird tickets",
    "citation_count": 5,
    "authors": [
      "Zhiheng Xi",
      "Rui Zheng",
      "Tao Gui",
      "Qi Zhang",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.570": {
    "title": "Quantifying Privacy Risks of Masked Language Models Using Membership Inference Attacks",
    "volume": "main",
    "abstract": "The wide adoption and application of Masked language models (MLMs) on sensitive data (from legal to medical) necessitates a thorough quantitative investigation into their privacy vulnerabilities. Prior attempts at measuring leakage of MLMs via membership inference attacks have been inconclusive, implying potential robustness of MLMs to privacy attacks. In this work, we posit that prior attempts were inconclusive because they based their attack solely on the MLM's model score. We devise a stronger membership inference attack based on likelihood ratio hypothesis testing that involves an additional reference MLM to more accurately quantify the privacy risks of memorization in MLMs. We show that masked language models are indeed susceptible to likelihood ratio membership inference attacks: Our empirical results, on models trained on medical notes, show that our attack improves the AUC of prior membership inference attacks from 0.66 to an alarmingly high 0.90 level",
    "checked": true,
    "id": "cc3b41c4d2ededb94b481089633ecb43d6b2162f",
    "semantic_title": "quantifying privacy risks of masked language models using membership inference attacks",
    "citation_count": 71,
    "authors": [
      "Fatemehsadat Mireshghallah",
      "Kartik Goyal",
      "Archit Uniyal",
      "Taylor Berg-Kirkpatrick",
      "Reza Shokri"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.571": {
    "title": "SMaLL-100: Introducing Shallow Multilingual Machine Translation Model for Low-Resource Languages",
    "volume": "main",
    "abstract": "In recent years, multilingual machine translation models have achieved promising performance on low-resource language pairs by sharing information between similar languages, thus enabling zero-shot translation. To overcome the \"curse of multilinguality\", these models often opt for scaling up the number of parameters, which makes their use in resource-constrained environments challenging. We introduce SMaLL-100, a distilled version of the M2M-100(12B) model, a massively multilingual machine translation model covering 100 languages. We train SMaLL-100 with uniform sampling across all language pairs and therefore focus on preserving the performance of low-resource languages. We evaluate SMaLL-100 on different low-resource benchmarks: FLORES-101, Tatoeba, and TICO-19 and demonstrate that it outperforms previous massively multilingual models of comparable sizes (200-600M) while improving inference latency and memory usage. Additionally, our model achieves comparable results to M2M-100 (1.2B), while being 3.6x smaller and 4.3x faster at inference",
    "checked": true,
    "id": "83608aadb17443beba22c4087030c8704ccd7c64",
    "semantic_title": "small-100: introducing shallow multilingual machine translation model for low-resource languages",
    "citation_count": 12,
    "authors": [
      "Alireza Mohammadshahi",
      "Vassilina Nikoulina",
      "Alexandre Berard",
      "Caroline Brun",
      "James Henderson",
      "Laurent Besacier"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.572": {
    "title": "TextFusion: Privacy-Preserving Pre-trained Model Inference via Token Fusion",
    "volume": "main",
    "abstract": "Recently, more and more pre-trained language models are released as a cloud service. It allows users who lack computing resources to perform inference with a powerful model by uploading data to the cloud. The plain text may contain private information, as the result, users prefer to do partial computations locally and upload intermediate representations to the cloud for subsequent inference. However, recent studies have shown that intermediate representations can also be recovered to plain text with reasonable accuracy, thus the risk of privacy leakage still exists. To address this issue, we propose TextFusion, a novel method for preserving inference privacy. Specifically, we train a Fusion Predictor to dynamically fuse token representations, which hides multiple private token representations behind an unrecognizable one. Furthermore, an adversarial training regime is employed to privatize these representations. In this way, the cloud only receives incomplete and perturbed representations, making it difficult to accurately recover the complete plain text. The experimental results on diverse classification tasks show that our approach can effectively preserve inference privacy without significantly sacrificing performance in different scenarios",
    "checked": true,
    "id": "24d7a40c088baab6c3ae99fb0b368a16e4bfb8dd",
    "semantic_title": "textfusion: privacy-preserving pre-trained model inference via token fusion",
    "citation_count": 6,
    "authors": [
      "Xin Zhou",
      "Jinzhu Lu",
      "Tao Gui",
      "Ruotian Ma",
      "Zichu Fei",
      "Yuran Wang",
      "Yong Ding",
      "Yibo Cheung",
      "Qi Zhang",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.573": {
    "title": "Learning to Explain Selectively: A Case Study on Question Answering",
    "volume": "main",
    "abstract": "Explanations promise to bridge the gap between humans and AI, yet it remains difficult to achieve consistent improvement in AI-augmented human decision making. The usefulness of AI explanations depends on many factors, and always showing the same type of explanation in all cases is suboptimal—so is relying on heuristics to adapt explanations for each scenario. We propose learning to explain\"selectively\": for each decision that the user makes, we use a model to choose the best explanation from a set of candidates and update this model with feedback to optimize human performance. We experiment on a question answering task, Quizbowl, and show that selective explanations improve human performance for both experts and crowdworkers",
    "checked": true,
    "id": "b885e139b54e7aa8b68fa7b17c326b3002bbe6db",
    "semantic_title": "learning to explain selectively: a case study on question answering",
    "citation_count": 9,
    "authors": [
      "Shi Feng",
      "Jordan Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.574": {
    "title": "ConsistTL: Modeling Consistency in Transfer Learning for Low-Resource Neural Machine Translation",
    "volume": "main",
    "abstract": "Transfer learning is a simple and powerful method that can be used to boost model performance of low-resource neural machine translation (NMT). Existing transfer learning methods for NMT are static, which simply transfer knowledge from a parent model to a child model once via parameter initialization. In this paper, we propose a novel transfer learning method for NMT, namely ConsistTL, which can continuously transfer knowledge from the parent model during the training of the child model. Specifically, for each training instance of the child model, ConsistTL constructs the semantically-equivalent instance for the parent model and encourages prediction consistency between the parent and child for this instance, which is equivalent to the child model learning each instance under the guidance of the parent model. Experimental results on five low-resource NMT tasks demonstrate that ConsistTL results in significant improvements over strong transfer learning baselines, with a gain up to 1.7 BLEU over the existing back-translation model on the widely-used WMT17 Turkish-English benchmark. Further analysis reveals that ConsistTL can improve the inference calibration of the child model. Code and scripts are freely available at https://github.com/NLP2CT/ConsistTL",
    "checked": true,
    "id": "0fd94b38505a2541cef118a1263db0b411615675",
    "semantic_title": "consisttl: modeling consistency in transfer learning for low-resource neural machine translation",
    "citation_count": 8,
    "authors": [
      "Zhaocong Li",
      "Xuebo Liu",
      "Derek F. Wong",
      "Lidia S. Chao",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.575": {
    "title": "Better Hit the Nail on the Head than Beat around the Bush: Removing Protected Attributes with a Single Projection",
    "volume": "main",
    "abstract": "Bias elimination and recent probing studies attempt to remove specific information from embedding spaces. Here it is important to remove as much of the target information as possible, while preserving any other information present. INLP is a popular recent method which removes specific information through iterative nullspace projections. Multiple iterations, however, increase the risk that information other than the target is negatively affected. We introduce two methods that find a single targeted projection: Mean Projection (MP, more efficient) and Tukey Median Projection (TMP, with theoretical guarantees). Our comparison between MP and INLP shows that (1) one MP projection removes linear separability based on the target and (2) MP has less impact on the overall space. Further analysis shows that applying random projections after MP leads to the same overall effects on the embedding space as the multiple projections of INLP. Applying one targeted (MP) projection hence is methodologically cleaner than applying multiple (INLP) projections that introduce random effects",
    "checked": true,
    "id": "d4d148a26f187482ad3016a296e4b7bdeffb2d37",
    "semantic_title": "better hit the nail on the head than beat around the bush: removing protected attributes with a single projection",
    "citation_count": 4,
    "authors": [
      "Pantea Haghighatkhah",
      "Antske Fokkens",
      "Pia Sommerauer",
      "Bettina Speckmann",
      "Kevin Verbeek"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.576": {
    "title": "IELM: An Open Information Extraction Benchmark for Pre-Trained Language Models",
    "volume": "main",
    "abstract": "We introduce a new open information extraction (OIE) benchmark for pre-trained language models (LM). Recent studies have demonstrated that pre-trained LMs, such as BERT and GPT, may store linguistic and relational knowledge. In particular, LMs are able to answer \"fill-in-the-blank\" questions when given a pre-defined relation category. Instead of focusing on pre-defined relations, we create an OIE benchmark aiming to fully examine the open relational information present in the pre-trained LMs. We accomplish this by turning pre-trained LMs into zero-shot OIE systems. Surprisingly, pre-trained LMs are able to obtain competitive performance on both standard OIE datasets (CaRB and Re-OIE2016) and two new large-scale factual OIE datasets (TAC KBP-OIE and Wikidata-OIE) that we establish via distant supervision. For instance, the zero-shot pre-trained LMs outperform the F1 score of the state-of-the-art supervised OIE methods on our factual OIE datasets without needing to use any training sets",
    "checked": true,
    "id": "1933a0ef47f8d2ba4a8277d702d522a06319302c",
    "semantic_title": "ielm: an open information extraction benchmark for pre-trained language models",
    "citation_count": 1,
    "authors": [
      "Chenguang Wang",
      "Xiao Liu",
      "Dawn Song"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.577": {
    "title": "ConNER: Consistency Training for Cross-lingual Named Entity Recognition",
    "volume": "main",
    "abstract": "Cross-lingual named entity recognition (NER) suffers from data scarcity in the target languages, especially under zero-shot settings. Existing translate-train or knowledge distillation methods attempt to bridge the language gap, but often introduce a high level of noise. To solve this problem, consistency training methods regularize the model to be robust towards perturbations on data or hidden states. However, such methods are likely to violate the consistency hypothesis, or mainly focus on coarse-grain consistency. We propose ConNER as a novel consistency training framework for cross-lingual NER, which comprises of: (1) translation-based consistency training on unlabeled target-language data, and (2) dropout-based consistency training on labeled source-language data. ConNER effectively leverages unlabeled target-language data and alleviates overfitting on the source language to enhance the cross-lingual adaptability. Experimental results show our ConNER achieves consistent improvement over various baseline methods",
    "checked": true,
    "id": "91e24327e4502a95a2ed7f2ac4c36cf0139284cb",
    "semantic_title": "conner: consistency training for cross-lingual named entity recognition",
    "citation_count": 15,
    "authors": [
      "Ran Zhou",
      "Xin Li",
      "Lidong Bing",
      "Erik Cambria",
      "Luo Si",
      "Chunyan Miao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.578": {
    "title": "A Sequential Flow Control Framework for Multi-hop Knowledge Base Question Answering",
    "volume": "main",
    "abstract": "One of the key challenges of knowledge base question answering (KBQA) is the multi-hop reasoning. Since in different hops, one attends to different parts of question, it is important to dynamically represent the question semantics for each hop. Existing methods, however, (i) infer the dynamic question representation only through coarse-grained attention mechanisms, which may bring information loss, (ii) and have not effectively modeled the sequential logic, which is crucial for the multi-hop reasoning process in KBQA.To address these issues, we propose a sequential reasoning self-attention mechanism to capture the crucial reasoning information of each single hop in a more fine-grained way. Based on Gated Recurrent Unit (GRU) which is good at modeling sequential process, we propose a simple but effective GRU-inspired Flow Control (GFC) framework to model sequential logic in the whole multi-hop process. Extensive experiments on three popular benchmark datasets have demonstrated the superior effectiveness of our model. In particular, GFC achieves new state-of-the-art Hits@1 of 76.8% on WebQSP and is also effective when KB is incomplete. Our code and data are available at https://github.com/Xie-Minghui/GFC",
    "checked": true,
    "id": "d7e2e65a423beb73815ed8361307a9dc5a75dacf",
    "semantic_title": "a sequential flow control framework for multi-hop knowledge base question answering",
    "citation_count": 2,
    "authors": [
      "Minghui Xie",
      "Chuzhan Hao",
      "Peng Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.579": {
    "title": "ACENet: Attention Guided Commonsense Reasoning on Hybrid Knowledge Graph",
    "volume": "main",
    "abstract": "Augmenting pre-trained language models (PLMs) with knowledge graphs (KGs) has demonstrated superior performance on commonsense reasoning. Given a commonsense based QA context (question and multiple choices), existing approaches usually estimate the plausibility of candidate choices separately based on their respective retrieved KGs, without considering the interference among different choices. In this paper, we propose an Attention guided Commonsense rEasoning Network (ACENet) to endow the neural network with the capability of integrating hybrid knowledge. Specifically, our model applies the multi-layer interaction of answer choices to continually strengthen correct choice information and guide the message passing of GNN. In addition, we also design a mix attention mechanism of nodes and edges to iteratively select supporting evidence on hybrid knowledge graph. Experimental results demonstrate the effectiveness of our proposed model through considerable performance gains across CommonsenseQA and OpenbookQA datasets",
    "checked": true,
    "id": "ce2c938d7d218eb63ba8092994360e55ad66e89a",
    "semantic_title": "acenet: attention guided commonsense reasoning on hybrid knowledge graph",
    "citation_count": 3,
    "authors": [
      "Chuzhan Hao",
      "Minghui Xie",
      "Peng Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.580": {
    "title": "Revisiting DocRED - Addressing the False Negative Problem in Relation Extraction",
    "volume": "main",
    "abstract": "The DocRED dataset is one of the most popular and widely used benchmarks for document-level relation extraction (RE). It adopts a recommend-revise annotation scheme so as to have a large-scale annotated dataset. However, we find that the annotation of DocRED is incomplete, i.e., false negative samples are prevalent. We analyze the causes and effects of the overwhelming false negative problem in the DocRED dataset. To address the shortcoming, we re-annotate 4,053 documents in the DocRED dataset by adding the missed relation triples back to the original DocRED. We name our revised DocRED dataset Re-DocRED. We conduct extensive experiments with state-of-the-art neural models on both datasets, and the experimental results show that the models trained and evaluated on our Re-DocRED achieve performance improvements of around 13 F1 points. Moreover, we conduct a comprehensive analysis to identify the potential areas for further improvement",
    "checked": true,
    "id": "c86754c01fc64a8e8b445f530fe95c1dbab4eb03",
    "semantic_title": "revisiting docred - addressing the false negative problem in relation extraction",
    "citation_count": 21,
    "authors": [
      "Qingyu Tan",
      "Lu Xu",
      "Lidong Bing",
      "Hwee Tou Ng",
      "Sharifah Mahani Aljunied"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.581": {
    "title": "Towards Summary Candidates Fusion",
    "volume": "main",
    "abstract": "Sequence-to-sequence deep neural models fine-tuned for abstractive summarization can achieve great performance on datasets with enough human annotations. Yet, it has been shown that they have not reached their full potential, with a wide gap between the top beam search output and the oracle beam. Recently, re-ranking methods have been proposed, to learn to select a better summary candidate. However, such methods are limited by the summary quality aspects captured by the first-stage candidates. To bypass this limitation, we propose a new paradigm in second-stage abstractive summarization called SummaFusion that fuses several summary candidates to produce a novel abstractive second-stage summary. Our method works well on several summarization datasets, improving both the ROUGE scores and qualitative properties of fused summaries. It is especially good when the candidates to fuse are worse, such as in the few-shot setup where we set a new state-of-the art. We will make our code and checkpoints available at https://github.com/ntunlp/SummaFusion/",
    "checked": true,
    "id": "3d4f9226303a79e76ad5ef69b5253e78dbf5b1c7",
    "semantic_title": "towards summary candidates fusion",
    "citation_count": 11,
    "authors": [
      "Mathieu Ravaut",
      "Shafiq Joty",
      "Nancy Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.582": {
    "title": "Multimodal Robustness for Neural Machine Translation",
    "volume": "main",
    "abstract": "In this paper, we look at the case of a Generic text-to-text NMT model that has to deal with data coming from various modalities, like speech, images, or noisy text extracted from the web. We propose a two-step method, based on composable adapters, to deal with this problem of Multimodal Robustness. In a first step, we separately learn domain adapters and modality specific adapters, to deal with noisy input coming from various sources: ASR, OCR, or noisy text (UGC). In a second step, we combine these components at runtime via dynamic routing or, when the source of noise is unknown, via two new transfer learning mechanisms (Fast Fusion and Multi Fusion). We show that our method provides a flexible, state-of-the-art, architecture able to deal with noisy multimodal inputs",
    "checked": true,
    "id": "eec04588f97b750965da44e27de5fa4bae9c39b6",
    "semantic_title": "multimodal robustness for neural machine translation",
    "citation_count": 3,
    "authors": [
      "Yuting Zhao",
      "Ioan Calapodescu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.583": {
    "title": "TranSHER: Translating Knowledge Graph Embedding with Hyper-Ellipsoidal Restriction",
    "volume": "main",
    "abstract": "Knowledge graph embedding methods are important for the knowledge graph completion (or link prediction) task. One state-of-the-art method, PairRE, leverages two separate vectors to model complex relations (i.e., 1-to-N, N-to-1, and N-to-N) in knowledge graphs. However, such a method strictly restricts entities on the hyper-ellipsoid surfaces which limits the optimization of entity distribution, leading to suboptimal performance of knowledge graph completion. To address this issue, we propose a novel score function TranSHER, which leverages relation-specific translations between head and tail entities to relax the constraint of hyper-ellipsoid restrictions. By introducing an intuitive and simple relation-specific translation, TranSHER can provide more direct guidance on optimization and capture more semantic characteristics of entities with complex relations. Experimental results show that TranSHER achieves state-of-the-art performance on link prediction and generalizes well to datasets in different domains and scales. Our codes are public available at https://github.com/yizhilll/TranSHER",
    "checked": true,
    "id": "4a3dfe9f4085591e17c19d6a5438c1bb94279183",
    "semantic_title": "transher: translating knowledge graph embedding with hyper-ellipsoidal restriction",
    "citation_count": 5,
    "authors": [
      "Yizhi Li",
      "Wei Fan",
      "Chao Liu",
      "Chenghua Lin",
      "Jiang Qian"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.584": {
    "title": "IRRGN: An Implicit Relational Reasoning Graph Network for Multi-turn Response Selection",
    "volume": "main",
    "abstract": "The task of response selection in multi-turn dialogue is to find the best option from all candidates. In order to improve the reasoning ability of the model, previous studies pay more attention to using explicit algorithms to model the dependencies between utterances, which are deterministic, limited and inflexible. In addition, few studies consider differences between the options before and after reasoning. In this paper, we propose an Implicit Relational Reasoning Graph Network to address these issues, which consists of the Utterance Relational Reasoner (URR) and the Option Dual Comparator (ODC). URR aims to implicitly extract dependencies between utterances, as well as utterances and options, and make reasoning with relational graph convolutional networks. ODC focuses on perceiving the difference between the options through dual comparison, which can eliminate the interference of the noise options. Experimental results on two multi-turn dialogue reasoning benchmark datasets MuTual and MuTualplus show that our method significantly improves the baseline of four pre-trained language models and achieves state-of-the-art performance. The model surpasses human performance for the first time on the MuTual dataset",
    "checked": true,
    "id": "63bf767bb4f8ea20cd73833d9a85c3563054ad96",
    "semantic_title": "irrgn: an implicit relational reasoning graph network for multi-turn response selection",
    "citation_count": 0,
    "authors": [
      "Jingcheng Deng",
      "Hengwei Dai",
      "Xuewei Guo",
      "Yuanchen Ju",
      "Wei Peng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.585": {
    "title": "Predicting Prerequisite Relations for Unseen Concepts",
    "volume": "main",
    "abstract": "Concept prerequisite learning (CPL) plays a key role in developing technologies that assist people to learn a new complex topic or concept. Previous work commonly assumes that all concepts are given at training time and solely focuses on predicting the unseen prerequisite relationships between them. However, many real-world scenarios deal with concepts that are left undiscovered at training time, which is relatively unexplored. This paper studies this problem and proposes a novel alternating knowledge distillation approach to take advantage of both content- and graph-based models for this task. Extensive experiments on three public benchmarks demonstrate up to 10% improvements in terms of F1 score",
    "checked": true,
    "id": "c225484a715a5af9b9669e15c907d221273c24a0",
    "semantic_title": "predicting prerequisite relations for unseen concepts",
    "citation_count": 0,
    "authors": [
      "Yaxin Zhu",
      "Hamed Zamani"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.586": {
    "title": "Contrastive Learning with Expectation-Maximization for Weakly Supervised Phrase Grounding",
    "volume": "main",
    "abstract": "Weakly supervised phrase grounding aims to learn an alignment between phrases in a caption and objects in a corresponding image using only caption-image annotations, i.e., without phrase-object annotations. Previous methods typically use a caption-image contrastive loss to indirectly supervise the alignment between phrases and objects, which hinders the maximum use of the intrinsic structure of the multimodal data and leads to unsatisfactory performance. In this work, we directly use the phrase-object contrastive loss in the condition that no positive annotation is available in the first place. Specifically, we propose a novel contrastive learning framework based on the expectation-maximization algorithm that adaptively refines the target prediction. Experiments on two widely used benchmarks, Flickr30K Entities and RefCOCO+, demonstrate the effectiveness of our framework. We obtain 63.05% top-1 accuracy on Flickr30K Entities and 59.51%/43.46% on RefCOCO+ TestA/TestB, outperforming the previous methods by a large margin, even surpassing a previous SoTA that uses a pre-trained vision-language model. Furthermore, we deliver a theoretical analysis of the effectiveness of our method from the perspective of the maximum likelihood estimate with latent variables",
    "checked": true,
    "id": "b59a2fb4f9dd9727ec4f80a0bba94210fcac1b0c",
    "semantic_title": "contrastive learning with expectation-maximization for weakly supervised phrase grounding",
    "citation_count": 2,
    "authors": [
      "Keqin Chen",
      "Richong Zhang",
      "Samuel Mensah",
      "Yongyi Mao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.587": {
    "title": "Beyond prompting: Making Pre-trained Language Models Better Zero-shot Learners by Clustering Representations",
    "volume": "main",
    "abstract": "Recent work has demonstrated that pre-trained language models (PLMs) are zero-shot learners. However, most existing zero-shot methods involve heavy human engineering or complicated self-training pipelines, hindering their application to new situations. In this work, we show that zero-shot text classification can be improved simply by clustering texts in the embedding spaces of PLMs. Specifically, we fit the unlabeled texts with a Bayesian Gaussian Mixture Model after initializing cluster positions and shapes using class names. Despite its simplicity, this approach achieves superior or comparable performance on both topic and sentiment classification datasets and outperforms prior works significantly on unbalanced datasets. We further explore the applicability of our clustering approach by evaluating it on 14 datasets with more diverse topics, text lengths, and numbers of classes. Our approach achieves an average of 20% absolute improvement over prompt-based zero-shot learning. Finally, we compare different PLM embedding spaces and find that texts are well-clustered by topics even if the PLM is not explicitly pre-trained to generate meaningful sentence embeddings. This work indicates that PLM embeddings can categorize texts without task-specific fine-tuning, thus providing a new way to analyze and utilize their knowledge and zero-shot learning ability",
    "checked": true,
    "id": "5c7f3e8b4e07e1d1ad9e708b4219b18de5e798e9",
    "semantic_title": "beyond prompting: making pre-trained language models better zero-shot learners by clustering representations",
    "citation_count": 11,
    "authors": [
      "Yu Fei",
      "Zhao Meng",
      "Ping Nie",
      "Roger Wattenhofer",
      "Mrinmaya Sachan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.588": {
    "title": "Generalizing over Long Tail Concepts for Medical Term Normalization",
    "volume": "main",
    "abstract": "Medical term normalization consists in mapping a piece of text to a large number of output classes. Given the small size of the annotated datasets and the extremely long tail distribution of the concepts, it is of utmost importance to develop models that are capable to generalize to scarce or unseen concepts. An important attribute of most target ontologies is their hierarchical structure. In this paper we introduce a simple and effective learning strategy that leverages such information to enhance the generalizability of both discriminative and generative models. The evaluation shows that the proposed strategy produces state-of-the-art performance on seen concepts and consistent improvements on unseen ones, allowing also for efficient zero-shot knowledge transfer across text typologies and datasets",
    "checked": true,
    "id": "b0bef201932b106795ba210827bf04c9117a11df",
    "semantic_title": "generalizing over long tail concepts for medical term normalization",
    "citation_count": 6,
    "authors": [
      "Beatrice Portelli",
      "Simone Scaboro",
      "Enrico Santus",
      "Hooman Sedghamiz",
      "Emmanuele Chersoni",
      "Giuseppe Serra"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.589": {
    "title": "Unsupervised Opinion Summarisation in the Wasserstein Space",
    "volume": "main",
    "abstract": "Opinion summarisation synthesises opinions expressed in a group of documents discussingthe same topic to produce a single summary. Recent work has looked at opinion summarisation of clusters of social media posts. Such posts are noisy and have unpredictable structure, posing additional challenges for the construction of the summary distribution and the preservation of meaning compared to online reviews, which has been so far the focus on opinion summarisation. To address these challenges we present WassOS, an unsupervised abstractive summarization model which makesuse of the Wasserstein distance. A Variational Autoencoder is first used to obtain the distribution of documents/posts, and the summary distribution is obtained as the Wasserstein barycenter. We create separate disentangled latent semantic and syntactic representations of the summary, which are fed into a GRU decoder with a transformer layer to produce the final summary. Our experiments onmultiple datasets including reviews, Twitter clusters and Reddit threads show that WassOSalmost always outperforms the state-of-the-art on ROUGE metrics and consistently producesthe best summaries with respect to meaning preservation according to human evaluations",
    "checked": true,
    "id": "a7a6faf1906f1aef95707f289269e41fd033c5aa",
    "semantic_title": "unsupervised opinion summarisation in the wasserstein space",
    "citation_count": 1,
    "authors": [
      "Jiayu Song",
      "Iman Munire Bilal",
      "Adam Tsakalidis",
      "Rob Procter",
      "Maria Liakata"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.590": {
    "title": "Bloom Library: Multimodal Datasets in 300+ Languages for a Variety of Downstream Tasks",
    "volume": "main",
    "abstract": "We present Bloom Library, a linguistically diverse set of multimodal and multilingual datasets for language modeling, image captioning, visual storytelling, and speech synthesis/recognition. These datasets represent either the most, or among the most, multilingual datasets for each of the included downstream tasks. In total, the initial release of the Bloom Library datasets covers 363 languages across 32 language families. We train downstream task models for various languages represented in the data, showing the viability of the data for future work in low-resource, multimodal NLP and establishing the first known baselines for these downstream tasks in certain languages (e.g., Bisu [bzi], with an estimated population of 700 users). Some of these first-of-their-kind baselines are comparable to state-of-the-art performance for higher-resourced languages. The Bloom Library datasets are released under Creative Commons licenses on the Hugging Face datasets hub to catalyze more linguistically diverse research in the included downstream tasks",
    "checked": true,
    "id": "fddaeb14ae30217ee7cd77a1043fb98884ab927b",
    "semantic_title": "bloom library: multimodal datasets in 300+ languages for a variety of downstream tasks",
    "citation_count": 11,
    "authors": [
      "Colin Leong",
      "Joshua Nemecek",
      "Jacob Mansdorfer",
      "Anna Filighera",
      "Abraham Owodunni",
      "Daniel Whitenack"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.591": {
    "title": "Disentangling Uncertainty in Machine Translation Evaluation",
    "volume": "main",
    "abstract": "Trainable evaluation metrics for machine translation (MT) exhibit strong correlation with human judgements, but they are often hard to interpret and might produce unreliable scores under noisy or out-of-domain data. Recent work has attempted to mitigate this with simple uncertainty quantification techniques (Monte Carlo dropout and deep ensembles), however these techniques (as we show) are limited in several ways – for example, they are unable to distinguish between different kinds of uncertainty, and they are time and memory consuming. In this paper, we propose more powerful and efficient uncertainty predictors for MT evaluation, and we assess their ability to target different sources of aleatoric and epistemic uncertainty. To this end, we develop and compare training objectives for the COMET metric to enhance it with an uncertainty prediction output, including heteroscedastic regression, divergence minimization, and direct uncertainty prediction. Our experiments show improved results on uncertainty prediction for the WMT metrics task datasets, with a substantial reduction in computational costs. Moreover, they demonstrate the ability of these predictors to address specific uncertainty causes in MT evaluation, such as low quality references and out-of-domain data",
    "checked": true,
    "id": "ccd51e04c62b357e8c908d94176e394f356147b8",
    "semantic_title": "disentangling uncertainty in machine translation evaluation",
    "citation_count": 7,
    "authors": [
      "Chrysoula Zerva",
      "Taisiya Glushkova",
      "Ricardo Rei",
      "André F. T. Martins"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.592": {
    "title": "Does Your Model Classify Entities Reasonably? Diagnosing and Mitigating Spurious Correlations in Entity Typing",
    "volume": "main",
    "abstract": "Entity typing aims at predicting one or more words that describe the type(s) of a specific mention in a sentence. Due to shortcuts from surface patterns to annotated entity labels and biased training, existing entity typing models are subject to the problem of spurious correlations. To comprehensively investigate the faithfulness and reliability of entity typing methods, we first systematically define distinct kinds of model biases that are reflected mainly from spurious correlations. Particularly, we identify six types of existing model biases, including mention-context bias, lexical overlapping bias, named entity bias, pronoun bias, dependency bias, and overgeneralization bias. To mitigate model biases, we then introduce a counterfactual data augmentation method. By augmenting the original training set with their debiasedcounterparts, models are forced to fully comprehend sentences and discover the fundamental cues for entity typing, rather than relying on spurious correlations for shortcuts. Experimental results on the UFET dataset show our counterfactual data augmentation approach helps improve generalization of different entity typing models with consistently better performance on both the original and debiased test sets",
    "checked": true,
    "id": "467c5ef31db6639fc6cd7aa9a3f0cbd151313673",
    "semantic_title": "does your model classify entities reasonably? diagnosing and mitigating spurious correlations in entity typing",
    "citation_count": 10,
    "authors": [
      "Nan Xu",
      "Fei Wang",
      "Bangzheng Li",
      "Mingtao Dong",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.593": {
    "title": "EDIN: An End-to-end Benchmark and Pipeline for Unknown Entity Discovery and Indexing",
    "volume": "main",
    "abstract": "Existing work on Entity Linking mostly assumes that the reference knowledge base is complete, and therefore all mentions can be linked. In practice this is hardly ever the case, as knowledge bases are incomplete and because novel concepts arise constantly. We introduce the temporally segmented Unknown Entity Discovery and Indexing (EDIN)-benchmark where unknown entities, that is entities not part of the knowledge base and without descriptions and labeled mentions, have to be integrated into an existing entity linking system. By contrasting EDIN with zero-shot entity linking, we provide insight on the additional challenges it poses. Building on dense-retrieval based entity linking, we introduce the end-to-end EDIN-pipeline that detects, clusters, and indexes mentions of unknown entities in context. Experiments show that indexing a single embedding per entity unifying the information of multiple mentions works better than indexing mentions independently",
    "checked": true,
    "id": "65d217468f1f3fd7088da17d8e81afc408a8c235",
    "semantic_title": "edin: an end-to-end benchmark and pipeline for unknown entity discovery and indexing",
    "citation_count": 5,
    "authors": [
      "Nora Kassner",
      "Fabio Petroni",
      "Mikhail Plekhanov",
      "Sebastian Riedel",
      "Nicola Cancedda"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.594": {
    "title": "POQue: Asking Participant-specific Outcome Questions for a Deeper Understanding of Complex Events",
    "volume": "main",
    "abstract": "Knowledge about outcomes is critical for complex event understanding but is hard to acquire. We show that by pre-identifying a participant in a complex event, crowdworkers are ableto (1) infer the collective impact of salient events that make up the situation, (2) annotate the volitional engagement of participants in causing the situation, and (3) ground theoutcome of the situation in state changes of the participants. By creating a multi-step interface and a careful quality control strategy, we collect a high quality annotated dataset of8K short newswire narratives and ROCStories with high inter-annotator agreement (0.74-0.96weighted Fleiss Kappa). Our dataset, POQUe (Participant Outcome Questions), enables theexploration and development of models that address multiple aspects of semantic understanding. Experimentally, we show that current language models lag behind human performance in subtle ways through our task formulations that target abstract and specific comprehension of a complex event, its outcome, and a participant's influence over the event culmination",
    "checked": true,
    "id": "dcbf0f6b067855bb7374d2a4a4bbe7ea21caef35",
    "semantic_title": "poque: asking participant-specific outcome questions for a deeper understanding of complex events",
    "citation_count": 1,
    "authors": [
      "Sai Vallurupalli",
      "Sayontan Ghosh",
      "Katrin Erk",
      "Niranjan Balasubramanian",
      "Francis Ferraro"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.595": {
    "title": "Measuring the Mixing of Contextual Information in the Transformer",
    "volume": "main",
    "abstract": "The Transformer architecture aggregates input information through the self-attention mechanism, but there is no clear understanding of how this information is mixed across the entire model. Additionally, recent works have demonstrated that attention weights alone are not enough to describe the flow of information. In this paper, we consider the whole attention block –multi-head attention, residual connection, and layer normalization– and define a metric to measure token-to-token interactions within each layer. Then, we aggregate layer-wise interpretations to provide input attribution scores for model predictions. Experimentally, we show that our method, ALTI (Aggregation of Layer-wise Token-to-token Interactions), provides more faithful explanations and increased robustness than gradient-based methods",
    "checked": true,
    "id": "bb1c9cb431e771660cffdda1d80a7f15ff40c764",
    "semantic_title": "measuring the mixing of contextual information in the transformer",
    "citation_count": 21,
    "authors": [
      "Javier Ferrando",
      "Gerard I. Gállego",
      "Marta R. Costa-jussà"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.596": {
    "title": "Dealing with Abbreviations in the Slovenian Biographical Lexicon",
    "volume": "main",
    "abstract": "Abbreviations present a significant challenge for NLP systems because they cause tokenization and out-of-vocabulary errors. They can also make the text less readable, especially in reference printed books, where they are extensively used. Abbreviations are especially problematic in low-resource settings, where systems are less robust to begin with. In this paper, we propose a new method for addressing the problems caused by a high density of domain-specific abbreviations in a text. We apply this method to the case of a Slovenian biographical lexicon and evaluate it on a newly developed gold-standard dataset of 51 Slovenian biographies. Our abbreviation identification method performs significantly better than commonly used ad-hoc solutions, especially at identifying unseen abbreviations. We also propose and present the results of a method for expanding the identified abbreviations in context",
    "checked": true,
    "id": "09677c42e427a6593df78926831b56f4bb83b17a",
    "semantic_title": "dealing with abbreviations in the slovenian biographical lexicon",
    "citation_count": 0,
    "authors": [
      "Angel Daza",
      "Antske Fokkens",
      "Tomaž Erjavec"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.597": {
    "title": "AfriCLIRMatrix: Enabling Cross-Lingual Information Retrieval for African Languages",
    "volume": "main",
    "abstract": "Language diversity in NLP is critical in enabling the development of tools for a wide range of users. However, there are limited resources for building such tools for many languages, particularly those spoken in Africa.For search, most existing datasets feature few or no African languages, directly impacting researchers' ability to build and improve information access capabilities in those languages. Motivated by this, we created AfriCLIRMatrix, a test collection for cross-lingual information retrieval research in 15 diverse African languages. In total, our dataset contains 6 million queries in English and 23 million relevance judgments automatically mined from Wikipedia inter-language links, covering many more African languages than any existing information retrieval test collection. In addition, we release BM25, dense retrieval, and sparse–dense hybrid baselines to provide a starting point for the development of future systems. We hope that these efforts can spur additional work in search for African languages.AfriCLIRMatrix can be downloaded at https://github.com/castorini/africlirmatrix",
    "checked": true,
    "id": "cf387294994faf86b3c8332ba72fc17b1442651c",
    "semantic_title": "africlirmatrix: enabling cross-lingual information retrieval for african languages",
    "citation_count": 2,
    "authors": [
      "Odunayo Ogundepo",
      "Xinyu Zhang",
      "Shuo Sun",
      "Kevin Duh",
      "Jimmy Lin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.598": {
    "title": "CONDAQA: A Contrastive Reading Comprehension Dataset for Reasoning about Negation",
    "volume": "main",
    "abstract": "The full power of human language-based communication cannot be realized without negation. All human languages have some form of negation. Despite this, negation remains a challenging phenomenon for current natural language understanding systems. To facilitate the future development of models that can process negation effectively, we present CONDAQA, the first English reading comprehension dataset which requires reasoning about the implications of negated statements in paragraphs. We collect paragraphs with diverse negation cues, then have crowdworkers ask questions about the implications of the negated statement in the passage. We also have workers make three kinds of edits to the passage—paraphrasing the negated statement, changing the scope of the negation, and reversing the negation—resulting in clusters of question-answer pairs that are difficult for models to answer with spurious shortcuts. CONDAQA features 14,182 question-answer pairs with over 200 unique negation cues and is challenging for current state-of-the-art models. The best performing model on CONDAQA (UnifiedQA-v2-3b) achieves only 42% on our consistency metric, well below human performance which is 81%. We release our dataset, along with fully-finetuned, few-shot, and zero-shot evaluations, to facilitate the development of future NLP methods that work on negated language",
    "checked": true,
    "id": "ca2ea26b851fea6914a65b233b7daf8f32e38073",
    "semantic_title": "condaqa: a contrastive reading comprehension dataset for reasoning about negation",
    "citation_count": 15,
    "authors": [
      "Abhilasha Ravichander",
      "Matt Gardner",
      "Ana Marasovic"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.599": {
    "title": "Towards Opening the Black Box of Neural Machine Translation: Source and Target Interpretations of the Transformer",
    "volume": "main",
    "abstract": "In Neural Machine Translation (NMT), each token prediction is conditioned on the source sentence and the target prefix (what has been previously translated at a decoding step). However, previous work on interpretability in NMT has mainly focused solely on source sentence tokens' attributions. Therefore, we lack a full understanding of the influences of every input token (source sentence and target prefix) in the model predictions. In this work, we propose an interpretability method that tracks input tokens' attributions for both contexts. Our method, which can be extended to any encoder-decoder Transformer-based model, allows us to better comprehend the inner workings of current NMT models. We apply the proposed method to both bilingual and multilingual Transformers and present insights into their behaviour",
    "checked": true,
    "id": "fd06e7aaf9131c9a625d374841844adce6e0ed09",
    "semantic_title": "towards opening the black box of neural machine translation: source and target interpretations of the transformer",
    "citation_count": 25,
    "authors": [
      "Javier Ferrando",
      "Gerard I. Gállego",
      "Belen Alastruey",
      "Carlos Escolano",
      "Marta R. Costa-jussà"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.600": {
    "title": "ArtELingo: A Million Emotion Annotations of WikiArt with Emphasis on Diversity over Language and Culture",
    "volume": "main",
    "abstract": "This paper introduces ArtELingo, a new benchmark and dataset, designed to encourage work on diversity across languages and cultures. Following ArtEmis, a collection of 80k artworks from WikiArt with 0.45M emotion labels and English-only captions, ArtELingo adds another 0.79M annotations in Arabic and Chinese, plus 4.8K in Spanish to evaluate \"cultural-transfer\" performance. 51K artworks have 5 annotations or more in 3 languages. This diversity makes it possible to study similarities and differences across languages and cultures. Further, we investigate captioning tasks, and find diversity improves the performance of baseline models. ArtELingo is publicly available at ‘www.artelingo.org‘ with standard splits and baseline models. We hope our work will help ease future research on multilinguality and culturally-aware AI",
    "checked": true,
    "id": "710d50e2a072d4dfc85d76de6684400c80ea59ce",
    "semantic_title": "artelingo: a million emotion annotations of wikiart with emphasis on diversity over language and culture",
    "citation_count": 9,
    "authors": [
      "Youssef Mohamed",
      "Mohamed Abdelfattah",
      "Shyma Alhuwaider",
      "Feifan Li",
      "Xiangliang Zhang",
      "Kenneth Church",
      "Mohamed Elhoseiny"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.601": {
    "title": "Decoding a Neural Retriever's Latent Space for Query Suggestion",
    "volume": "main",
    "abstract": "Neural retrieval models have superseded classic bag-of-words methods such as BM25 as the retrieval framework of choice. However, neural systems lack the interpretability of bag-of-words models; it is not trivial to connect a query change to a change in the latent space that ultimately determines the retrieval results. To shed light on this embedding space, we learn a \"query decoder\" that, given a latent representation of a neural search engine, generates the corresponding query. We show that it is possible to decode a meaningful query from its latent representation and, when moving in the right direction in latent space, to decode a query that retrieves the relevant paragraph. In particular, the query decoder can be useful to understand \"what should have been asked\" to retrieve a particular paragraph from the collection. We employ the query decoder to generate a large synthetic dataset of query reformulations for MSMarco, leading to improved retrieval performance. On this data, we train a pseudo-relevance feedback (PRF) T5 model for the application of query suggestion that outperforms both query reformulation and PRF information retrieval baselines",
    "checked": true,
    "id": "02ab15d5a21715724889cf2a34242a330972fbb5",
    "semantic_title": "decoding a neural retriever's latent space for query suggestion",
    "citation_count": 5,
    "authors": [
      "Leonard Adolphs",
      "Michelle Chen Huebscher",
      "Christian Buck",
      "Sertan Girgin",
      "Olivier Bachem",
      "Massimiliano Ciaramita",
      "Thomas Hofmann"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.602": {
    "title": "T-STAR: Truthful Style Transfer using AMR Graph as Intermediate Representation",
    "volume": "main",
    "abstract": "Unavailability of parallel corpora for training text style transfer (TST) models is a very challenging yet common scenario. Also, TST models implicitly need to preserve the content while transforming a source sentence into the target style. To tackle these problems, an intermediate representation is often constructed that is devoid of style while still preserving the meaning of the source sentence. In this work, we study the usefulness of Abstract Meaning Representation (AMR) graph as the intermediate style agnostic representation. We posit that semantic notations like AMR are a natural choice for an intermediate representation. Hence, we propose T-STAR: a model comprising of two components, text-to-AMR encoder and a AMR-to-text decoder. We propose several modeling improvements to enhance the style agnosticity of the generated AMR. To the best of our knowledge, T-STAR is the first work that uses AMR as an intermediate representation for TST. With thorough experimental evaluation we show T-STAR significantly outperforms state of the art techniques by achieving on an average 15.2% higher content preservation with negligible loss (~3%) in style accuracy. Through detailed human evaluation with 90,000 ratings, we also show that T-STAR has upto 50% lesser hallucinations compared to state of the art TST models",
    "checked": true,
    "id": "a87f0a4e0e076e943b84d7af6ca4e58f20c9147b",
    "semantic_title": "t-star: truthful style transfer using amr graph as intermediate representation",
    "citation_count": 3,
    "authors": [
      "Anubhav Jangra",
      "Preksha Nema",
      "Aravindan Raghuveer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.603": {
    "title": "PromptBERT: Improving BERT Sentence Embeddings with Prompts",
    "volume": "main",
    "abstract": "We propose PromptBERT, a novel contrastive learning method for learning better sentence representation. We firstly analysis the drawback of current sentence embedding from original BERT and find that it is mainly due to the static token embedding bias and ineffective BERT layers. Then we propose the first prompt-based sentence embeddings method and discuss two prompt representing methods and three prompt searching methods to make BERT achieve better sentence embeddings .Moreover, we propose a novel unsupervised training objective by the technology of template denoising, which substantially shortens the performance gap between the supervised and unsupervised settings. Extensive experiments show the effectiveness of our method. Compared to SimCSE, PromptBert achieves 2.29 and 2.58 points of improvement based on BERT and RoBERTa in the unsupervised setting",
    "checked": true,
    "id": "27b6acf6bbb8fcad1f6bf1b90331b49489bd5ff1",
    "semantic_title": "promptbert: improving bert sentence embeddings with prompts",
    "citation_count": 69,
    "authors": [
      "Ting Jiang",
      "Jian Jiao",
      "Shaohan Huang",
      "Zihan Zhang",
      "Deqing Wang",
      "Fuzhen Zhuang",
      "Furu Wei",
      "Haizhen Huang",
      "Denvy Deng",
      "Qi Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.604": {
    "title": "Extending Logic Explained Networks to Text Classification",
    "volume": "main",
    "abstract": "Recently, Logic Explained Networks (LENs) have been proposed as explainable-by-design neural models providing logic explanations for their predictions. However, these models have only been applied to vision and tabular data, and they mostly favour the generation of global explanations, while local ones tend to be noisy and verbose. For these reasons, we propose LENp, improving local explanations by perturbing input words, and we test it on text classification. Our results show that (i) LENp provides better local explanations than LIME in terms of sensitivity and faithfulness, and (ii) its logic explanations are more useful and user-friendly than the feature scoring provided by LIME as attested by a human survey",
    "checked": true,
    "id": "26bb261580f6c01f49e52db99907bfc0a9ea4c3d",
    "semantic_title": "extending logic explained networks to text classification",
    "citation_count": 5,
    "authors": [
      "Rishabh Jain",
      "Gabriele Ciravegna",
      "Pietro Barbiero",
      "Francesco Giannini",
      "Davide Buffelli",
      "Pietro Lio"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.605": {
    "title": "Uni-Parser: Unified Semantic Parser for Question Answering on Knowledge Base and Database",
    "volume": "main",
    "abstract": "Parsing natural language questions into executable logical forms is a useful and interpretable way to perform question answering on structured data such as knowledge bases (KB) or databases (DB). However, existing approaches on semantic parsing cannot adapt to both modalities, as they suffer from the exponential growth of the logical form candidates and can hardly generalize to unseen data. In this work, we propose Uni-Parser, a unified semantic parser for question answering (QA) on both KB and DB. We define the primitive (relation and entity in KB, and table name, column name and cell value in DB) as the essential element in our framework. The number of primitives grows only at a linear rate to the number of retrieved relations in KB and DB, preventing us from exponential logic form candidates. We leverage the generator to predict final logical forms by altering and composing top-ranked primitives with different operations (e.g. select, where, count). With sufficiently pruned search space by a contrastive primitive ranker, the generator is empowered to capture the composition of primitives enhancing its generalization ability. We achieve competitive results on multiple KB and DB QA benchmarks with more efficiency, especially in the compositional and zero-shot settings",
    "checked": true,
    "id": "4dbd5febea8968acda097642e3daf2c312618bed",
    "semantic_title": "uni-parser: unified semantic parser for question answering on knowledge base and database",
    "citation_count": 15,
    "authors": [
      "Ye Liu",
      "Semih Yavuz",
      "Rui Meng",
      "Dragomir Radev",
      "Caiming Xiong",
      "Yingbo Zhou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.606": {
    "title": "RAPO: An Adaptive Ranking Paradigm for Bilingual Lexicon Induction",
    "volume": "main",
    "abstract": "Bilingual lexicon induction induces the word translations by aligning independently trained word embeddings in two languages. Existing approaches generally focus on minimizing the distances between words in the aligned pairs, while suffering from low discriminative capability to distinguish the relative orders between positive and negative candidates. In addition, the mapping function is globally shared by all words, whose performance might be hindered by the deviations in the distributions of different languages. In this work, we propose a novel ranking-oriented induction model RAPO to learn personalized mapping function for each word. RAPO is capable of enjoying the merits from the unique characteristics of a single word and the cross-language isomorphism simultaneously. Extensive experimental results on public datasets including both rich-resource and low-resource languages demonstrate the superiority of our proposal. Our code is publicly available in https://github.com/Jlfj345wf/RAPO",
    "checked": true,
    "id": "4b3c82cff291cb4be1e5405d05264d001cfc1e83",
    "semantic_title": "rapo: an adaptive ranking paradigm for bilingual lexicon induction",
    "citation_count": 2,
    "authors": [
      "Zhoujin Tian",
      "Chaozhuo Li",
      "Shuo Ren",
      "Zhiqiang Zuo",
      "Zengxuan Wen",
      "Xinyue Hu",
      "Xiao Han",
      "Haizhen Huang",
      "Denvy Deng",
      "Qi Zhang",
      "Xing Xie"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.607": {
    "title": "On Parsing as Tagging",
    "volume": "main",
    "abstract": "There are many proposals to reduce constituency parsing to tagging. To figure out what these approaches have in common, we offer a unifying pipeline, which consists of three steps: linearization, learning, and decoding. We prove that classic shift–reduce parsing can be reduced to tetratagging—the state-of-the-art constituency tagger—under two assumptions: right-corner transformation in the linearization step and factored scoring in the learning step. We ask what is the most critical factor that makes parsing-as-tagging methods accurate while being efficient. To answer this question, we empirically evaluate a taxonomy of tagging pipelines with different choices of linearizers, learners, and decoders. Based on the results in English as well as a set of 8 typologically diverse languages, we conclude that the linearization of the derivation tree and its alignment with the input sequence is the most critical factor in achieving accurate parsers as taggers",
    "checked": true,
    "id": "ef55b093b2870c41818ed317dfbc075716bff3ff",
    "semantic_title": "on parsing as tagging",
    "citation_count": 0,
    "authors": [
      "Afra Amini",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.608": {
    "title": "Distilled Dual-Encoder Model for Vision-Language Understanding",
    "volume": "main",
    "abstract": "On vision-language understanding (VLU) tasks, fusion-encoder vision-language models achieve superior results but sacrifice efficiency because of the simultaneous encoding of images and text. On the contrary, the dual encoder model that separately encodes images and text has the advantage in efficiency, while failing on VLU tasks due to the lack of deep cross-modal interactions. To get the best of both worlds, we propose DiDE, a framework that distills the knowledge of the fusion-encoder teacher model into the dual-encoder student model. Since the cross-modal interaction is the key to the superior performance of teacher model but is absent in the student model, we encourage the student not only to mimic the predictions of teacher, but also to calculate the cross-modal attention distributions and align with the teacher. Experimental results demonstrate that DiDE is competitive with the fusion-encoder teacher model in performance (only a 1% drop) while enjoying 4 times faster inference. Further analyses reveal that the proposed cross-modal attention distillation is crucial to the success of our framework",
    "checked": true,
    "id": "96362c3467d70ff1b471f74e0f83085b52afec34",
    "semantic_title": "distilled dual-encoder model for vision-language understanding",
    "citation_count": 20,
    "authors": [
      "Zekun Wang",
      "Wenhui Wang",
      "Haichao Zhu",
      "Ming Liu",
      "Bing Qin",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.609": {
    "title": "Argument Mining for Review Helpfulness Prediction",
    "volume": "main",
    "abstract": "The importance of reliably determining the helpfulness of product reviews is rising as both helpful and unhelpful reviews continue to accumulate on e-commerce websites. And argumentational features—such as the structure of arguments and the types of underlying elementary units—have shown to be promising indicators of product review helpfulness. However, their adoption has been limited due to the lack of sufficient resources and large-scale experiments investigating their utility. To this end, we present the AMazon Argument Mining (AM2) corpus—a corpus of 878 Amazon reviews on headphones annotated according to a theoretical argumentation model designed to evaluate argument quality.Experiments show that employing argumentational features leads to statistically significant improvements over the state-of-the-art review helpfulness predictors under both text-only and text-and-image settings",
    "checked": true,
    "id": "fda85a10a2d50fed3d893181871bcbe495905d33",
    "semantic_title": "argument mining for review helpfulness prediction",
    "citation_count": 4,
    "authors": [
      "Zaiqian Chen",
      "Daniel Verdi do Amarante",
      "Jenna Donaldson",
      "Yohan Jo",
      "Joonsuk Park"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.610": {
    "title": "Hierarchical Multi-Label Classification of Scientific Documents",
    "volume": "main",
    "abstract": "Automatic topic classification has been studied extensively to assist managing and indexing scientific documents in a digital collection. With the large number of topics being available in recent years, it has become necessary to arrange them in a hierarchy. Therefore, the automatic classification systems need to be able to classify the documents hierarchically. In addition, each paper is often assigned to more than one relevant topic. For example, a paper can be assigned to several topics in a hierarchy tree. In this paper, we introduce a new dataset for hierarchical multi-label text classification (HMLTC) of scientific papers called SciHTC, which contains 186,160 papers and 1,234 categories from the ACM CCS tree. We establish strong baselines for HMLTC and propose a multi-task learning approach for topic classification with keyword labeling as an auxiliary task. Our best model achieves a Macro-F1 score of 34.57% which shows that this dataset provides significant research opportunities on hierarchical scientific topic classification. We make our dataset and code for all experiments publicly available",
    "checked": true,
    "id": "8f066cdf7a5a37834b147dfa8e21e3275008ae8c",
    "semantic_title": "hierarchical multi-label classification of scientific documents",
    "citation_count": 8,
    "authors": [
      "Mobashir Sadat",
      "Cornelia Caragea"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.611": {
    "title": "Rainier: Reinforced Knowledge Introspector for Commonsense Question Answering",
    "volume": "main",
    "abstract": "Knowledge underpins reasoning. Recent research demonstrates that when relevant knowledge is provided as additional context to commonsense question answering (QA), it can substantially enhance the performance even on top of state-of-the-art. The fundamental challenge is where and how to find such knowledge that is high quality and on point with respect to the question; knowledge retrieved from knowledge bases are incomplete and knowledge generated from language models are inconsistent. We present Rainier, or Reinforced Knowledge Introspector, that learns to generate contextually relevant knowledge in response to given questions. Our approach starts by imitating knowledge generated by GPT-3, then learns to generate its own knowledge via reinforcement learning where rewards are shaped based on the increased performance on the resulting question answering. Rainier demonstrates substantial and consistent performance gains when tested over 9 different commonsense benchmarks: including 5 datasets that are seen during model training, as well as 4 datasets that are kept unseen. Our work is the first to report that knowledge generated by models that are orders of magnitude smaller than GPT-3, even without direct supervision on the knowledge itself, can exceed the quality of commonsense knowledge elicited from GPT-3",
    "checked": true,
    "id": "2591c66c6006c9c275a3dc7108a487934bc1c06f",
    "semantic_title": "rainier: reinforced knowledge introspector for commonsense question answering",
    "citation_count": 44,
    "authors": [
      "Jiacheng Liu",
      "Skyler Hallinan",
      "Ximing Lu",
      "Pengfei He",
      "Sean Welleck",
      "Hannaneh Hajishirzi",
      "Yejin Choi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.612": {
    "title": "A Major Obstacle for NLP Research: Let's Talk about Time Allocation!",
    "volume": "main",
    "abstract": "The field of natural language processing (NLP) has grown over the last few years: conferences have become larger, we have published an incredible amount of papers, and state-of-the-art research has been implemented in a large variety of customer-facing products. However, this paper argues that we have been less successful than we *should* have been and reflects on where and how the field fails to tap its full potential. Specifically, we demonstrate that, in recent years, **subpar time allocation has been a major obstacle for NLP research**. We outline multiple concrete problems together with their negative consequences and, importantly, suggest remedies to improve the status quo. We hope that this paper will be a starting point for discussions around which common practices are – or are *not* – beneficial for NLP research",
    "checked": true,
    "id": "a94e2ce7f94d189e5f788cfa431c504b3fb49402",
    "semantic_title": "a major obstacle for nlp research: let's talk about time allocation!",
    "citation_count": 1,
    "authors": [
      "Katharina Kann",
      "Shiran Dudy",
      "Arya D. McCarthy"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.613": {
    "title": "Towards Inter-character Relationship-driven Story Generation",
    "volume": "main",
    "abstract": "In this paper, we introduce the task of modeling interpersonal relationships for story generation. For addressing this task, we propose Relationships as Latent Variables for Story Generation, (ReLiSt). ReLiSt generates stories sentence by sentence and has two major components - a relationship selector and a story continuer. The relationship selector specifies a latent variable to pick the relationship to exhibit in the next sentence and the story continuer generates the next sentence while expressing the selected relationship in a coherent way. Our automatic and human evaluations demonstrate that ReLiSt is able to generate stories with relationships that are more faithful to desired relationships while maintaining the content quality. The relationship assignments to sentences during inference brings interpretability to ReLiSt",
    "checked": true,
    "id": "684e0925aa11628a165a6faf2095e45447258769",
    "semantic_title": "towards inter-character relationship-driven story generation",
    "citation_count": 5,
    "authors": [
      "Anvesh Rao Vijjini",
      "Faeze Brahman",
      "Snigdha Chaturvedi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.614": {
    "title": "Incorporating Relevance Feedback for Information-Seeking Retrieval using Few-Shot Document Re-Ranking",
    "volume": "main",
    "abstract": "Pairing a lexical retriever with a neural re-ranking model has set state-of-the-art performance on large-scale information retrieval datasets. This pipeline covers scenarios like question answering or navigational queries, however, for information-seeking scenarios, users often provide information on whether a document is relevant to their query in form of clicks or explicit feedback. Therefore, in this work, we explore how relevance feedback can be directly integrated into neural re-ranking models by adopting few-shot and parameter-efficient learning techniques. Specifically, we introduce a kNN approach that re-ranks documents based on their similarity with the query and the documents the user considers relevant. Further, we explore Cross-Encoder models that we pre-train using meta-learning and subsequently fine-tune for each query, training only on the feedback documents. To evaluate our different integration strategies, we transform four existing information retrieval datasets into the relevance feedback scenario. Extensive experiments demonstrate that integrating relevance feedback directly in neural re-ranking models improves their performance, and fusing lexical ranking with our best performing neural re-ranker outperforms all other methods by 5.2% nDCG@20",
    "checked": true,
    "id": "036e81bc9ef13272c74e9a504be23676dcce1d9d",
    "semantic_title": "incorporating relevance feedback for information-seeking retrieval using few-shot document re-ranking",
    "citation_count": 3,
    "authors": [
      "Tim Baumgärtner",
      "Leonardo F. R. Ribeiro",
      "Nils Reimers",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.615": {
    "title": "ReasTAP: Injecting Table Reasoning Skills During Pre-training via Synthetic Reasoning Examples",
    "volume": "main",
    "abstract": "Reasoning over tabular data requires both table structure understanding and a broad set of table reasoning skills. Current models with table-specific architectures and pre-training methods perform well on understanding table structures, but they still struggle with tasks that require various table reasoning skills. In this work, we develop ReasTAP to show that high-level table reasoning skills can be injected into models during pre-training without a complex table-specific architecture design. We define 7 table reasoning skills, such as numerical operation, temporal comparison, and conjunction. Each reasoning skill is associated with one example generator, which synthesizes questions over semi-structured tables according to the sampled templates. We model the table pre-training task as a sequence generation task and pre-train ReasTAP to generate precise answers of the synthetic examples. ReasTAP is evaluated on four benchmarks covering three downstream tasks including 1) WikiSQL-Weak and WikiTQ for Table Question Answering, 2) TabFact for Table Fact Verification, and 3) LogicNLG for Faithful Table-to-Text Generation. Experimental results demonstrate that ReasTAP achieves new state-of-the-art results on all of them and delivers a significant improvement under low-resource setting. Our code is publicly available at https://github.com/Yale-LILY/ReasTAP",
    "checked": true,
    "id": "e1801f68d42f4a1a96d580b73706733883bf6af8",
    "semantic_title": "reastap: injecting table reasoning skills during pre-training via synthetic reasoning examples",
    "citation_count": 19,
    "authors": [
      "Yilun Zhao",
      "Linyong Nan",
      "Zhenting Qi",
      "Rui Zhang",
      "Dragomir Radev"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.616": {
    "title": "Few-shot Learning with Multilingual Generative Language Models",
    "volume": "main",
    "abstract": "Large-scale generative language models such as GPT-3 are competitive few-shot learners. While these models are known to be able to jointly represent many different languages, their training data is dominated by English, potentially limiting their cross-lingual generalization. In this work, we train multilingual generative language models on a corpus covering a diverse set of languages, and study their few- and zero-shot learning capabilities in a wide range of tasks. Our largest model with 7.5 billion parameters sets new state of the art in few-shot learning in more than 20 representative languages, outperforming GPT-3 of comparable size in multilingual commonsense reasoning (with +7.4% absolute accuracy improvement in 0-shot settings and +9.4% in 4-shot settings) and natural language inference (+5.4% in each of 0-shot and 4-shot settings). On the FLORES-101 machine translation benchmark, our model outperforms GPT-3 on 171 out of 182 directions with 32 training examples, while surpassing the official supervised baseline in 45 directions. We conduct an in-depth analysis of different multilingual prompting approaches, showing in particular that strong few-shot learning performance across languages can be achieved via cross-lingual transfer through both templates and demonstration examples",
    "checked": true,
    "id": "4724ebee34ca2cd0a19c3a1ddb83d6d870dd7904",
    "semantic_title": "few-shot learning with multilingual generative language models",
    "citation_count": 145,
    "authors": [
      "Xi Victoria Lin",
      "Todor Mihaylov",
      "Mikel Artetxe",
      "Tianlu Wang",
      "Shuohui Chen",
      "Daniel Simig",
      "Myle Ott",
      "Naman Goyal",
      "Shruti Bhosale",
      "Jingfei Du",
      "Ramakanth Pasunuru",
      "Sam Shleifer",
      "Punit Singh Koura",
      "Vishrav Chaudhary",
      "Brian O’Horo",
      "Jeff Wang",
      "Luke Zettlemoyer",
      "Zornitsa Kozareva",
      "Mona Diab",
      "Veselin Stoyanov",
      "Xian Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.617": {
    "title": "Are representations built from the ground up? An empirical examination of local composition in language models",
    "volume": "main",
    "abstract": "Compositionality, the phenomenon where the meaning of a phrase can be derived from its constituent parts, is a hallmark of human language. At the same time, many phrases are non-compositional, carrying a meaning beyond that of each part in isolation. Representing both of these types of phrases is critical for language understanding, but it is an open question whether modern language models (LMs) learn to do so; in this work we examine this question. We first formulate a problem of predicting the LM-internal representations of longer phrases given those of their constituents. We find that the representation of a parent phrase can be predicted with some accuracy given an affine transformation of its children. While we would expect the predictive accuracy to correlate with human judgments of semantic compositionality, we find this is largely not the case, indicating that LMs may not accurately distinguish between compositional and non-compositional phrases. We perform a variety of analyses, shedding light on when different varieties of LMs do and do not generate compositional representations, and discuss implications for future modeling work",
    "checked": true,
    "id": "ee5895aa70bb4dbbdda256e23cada2d2ad1b15ae",
    "semantic_title": "are representations built from the ground up? an empirical examination of local composition in language models",
    "citation_count": 7,
    "authors": [
      "Emmy Liu",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.618": {
    "title": "Detecting Label Errors by Using Pre-Trained Language Models",
    "volume": "main",
    "abstract": "We show that large pre-trained language models are inherently highly capable of identifying label errors in natural language datasets: simply examining out-of-sample data points in descending order of fine-tuned task loss significantly outperforms more complex error-detection mechanisms proposed in previous work. To this end, we contribute a novel method for introducing realistic, human-originated label noise into existing crowdsourced datasets such as SNLI and TweetNLP. We show that this noise has similar properties to real, hand-verified label errors, and is harder to detect than existing synthetic noise, creating challenges for model robustness. We argue that human-originated noise is a better standard for evaluation than synthetic noise. Finally, we use crowdsourced verification to evaluate the detection of real errors on IMDB, Amazon Reviews, and Recon, and confirm that pre-trained models perform at a 9–36% higher absolute Area Under the Precision-Recall Curve than existing models",
    "checked": true,
    "id": "ed6957836b262c4604b96e8bf175123ea59827e9",
    "semantic_title": "detecting label errors by using pre-trained language models",
    "citation_count": 11,
    "authors": [
      "Derek Chong",
      "Jenny Hong",
      "Christopher Manning"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.619": {
    "title": "Intriguing Properties of Compression on Multilingual Models",
    "volume": "main",
    "abstract": "Multilingual models are often particularly dependent on scaling to generalize to a growing number of languages. Compression techniques are widely relied upon to reconcile the growth in model size with real world resource constraints, but compression can have a disparate effect on model performance for low-resource languages. It is thus crucial to understand the trade-offs between scale, multilingualism, and compression. In this work, we propose an experimental framework to characterize the impact of sparsifying multilingual pre-trained language models during fine-tuning. Applying this framework to mBERT named entity recognition models across 40 languages, we find that compression confers several intriguing and previously unknown generalization properties. In contrast to prior findings, we find that compression may improve model robustness over dense models. We additionally observe that under certain sparsification regimes compression may aid, rather than disproportionately impact the performance of low-resource languages",
    "checked": true,
    "id": "8f2c32a272c7bf074d652054ba87fc02f8de3d03",
    "semantic_title": "intriguing properties of compression on multilingual models",
    "citation_count": 8,
    "authors": [
      "Kelechi Ogueji",
      "Orevaoghene Ahia",
      "Gbemileke Onilude",
      "Sebastian Gehrmann",
      "Sara Hooker",
      "Julia Kreutzer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.620": {
    "title": "Sequence Models for Document Structure Identification in an Undeciphered Script",
    "volume": "main",
    "abstract": "This work describes the first thorough analysis of \"header\" signs in proto-Elamite, an undeciphered script from 3100-2900 BCE. Headers are a category of signs which have been provisionally identified through painstaking manual analysis of this script by domain experts. We use unsupervised neural and statistical sequence modeling techniques to provide new and independent evidence for the existence of headers, without supervision from domain experts. Having affirmed the existence of headers as a legitimate structural feature, we next arrive at a richer understanding of their possible meaning and purpose by (i) examining which features predict their presence; (ii) identifying correlations between these features and other document properties; and (iii) examining cases where these features predict the presence of a header in texts where domain experts do not expect one (or vice versa). We provide more concrete processes for labeling headers in this corpus and a clearer justification for existing intuitions about document structure in proto-Elamite",
    "checked": true,
    "id": "d34e126793a8e67e10a163040dbb93764665c352",
    "semantic_title": "sequence models for document structure identification in an undeciphered script",
    "citation_count": 3,
    "authors": [
      "Logan Born",
      "M. Monroe",
      "Kathryn Kelley",
      "Anoop Sarkar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.621": {
    "title": "English Contrastive Learning Can Learn Universal Cross-lingual Sentence Embeddings",
    "volume": "main",
    "abstract": "Universal cross-lingual sentence embeddings map semantically similar cross-lingual sentences into a shared embedding space. Aligning cross-lingual sentence embeddings usually requires supervised cross-lingual parallel sentences. In this work, we propose mSimCSE, which extends SimCSE to multilingual settings and reveal that contrastive learning on English data can surprisingly learn high-quality universal cross-lingual sentence embeddings without any parallel data. In unsupervised and weakly supervised settings, mSimCSE significantly improves previous sentence embedding methods on cross-lingual retrieval and multilingual STS tasks. The performance of unsupervised mSimCSE is comparable to fully supervised methods in retrieving low-resource languages and multilingual STS.The performance can be further enhanced when cross-lingual NLI data is available",
    "checked": true,
    "id": "1fec9a1c1d28228b1d23874c74de7315928dea6f",
    "semantic_title": "english contrastive learning can learn universal cross-lingual sentence embeddings",
    "citation_count": 12,
    "authors": [
      "Yaushian Wang",
      "Ashley Wu",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.622": {
    "title": "Active Example Selection for In-Context Learning",
    "volume": "main",
    "abstract": "With a handful of demonstration examples, large-scale language models demonstrate strong capability to perform various tasks by in-context learning from these examples, without any fine-tuning. We demonstrate that in-context learning performance can be highly unstable across samples of examples, indicating the idiosyncrasies of how language models acquire information. We formulate example selection for in-context learning as a sequential decision problem, and propose a reinforcement learning algorithm for identifying generalizable policies to select demonstration examples. For GPT-2, our learned policies demonstrate strong abilities of generalizing to unseen tasks in training, with a 5.8% improvement on average. Examples selected from our learned policies can even achieve a small improvement on GPT-3 Ada. However, the improvement diminishes on larger GPT-3 models, suggesting emerging capabilities of large language models",
    "checked": true,
    "id": "b8bd29a6104d26a16687400049a4e7e026ae6258",
    "semantic_title": "active example selection for in-context learning",
    "citation_count": 88,
    "authors": [
      "Yiming Zhang",
      "Shi Feng",
      "Chenhao Tan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.623": {
    "title": "Improving Factual Consistency in Summarization with Compression-Based Post-Editing",
    "volume": "main",
    "abstract": "State-of-the-art summarization models still struggle to be factually consistent with the input text. A model-agnostic way to address this problem is post-editing the generated summaries. However, existing approaches typically fail to remove entity errors if a suitable input entity replacement is not available or may insert erroneous content. In our work, we focus on removing extrinsic entity errors, or entities not in the source, to improve consistency while retaining the summary's essential information and form. We propose to use sentence-compression data to train the post-editing model to take a summary with extrinsic entity errors marked with special tokens and output a compressed, well-formed summary with those errors removed. We show that this model improves factual consistency while maintaining ROUGE, improving entity precision by up to 30% on XSum, and that this model can be applied on top of another post-editor, improving entity precision by up to a total of 38%. We perform an extensive comparison of post-editing approaches that demonstrate trade-offs between factual consistency, informativeness, and grammaticality, and we analyze settings where post-editors show the largest improvements",
    "checked": true,
    "id": "7cf1944c133679356afd75d735abcbe5332d76e7",
    "semantic_title": "improving factual consistency in summarization with compression-based post-editing",
    "citation_count": 11,
    "authors": [
      "Alex Fabbri",
      "Prafulla Kumar Choubey",
      "Jesse Vig",
      "Chien-Sheng Wu",
      "Caiming Xiong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.624": {
    "title": "Evaluating the Impact of Model Scale for Compositional Generalization in Semantic Parsing",
    "volume": "main",
    "abstract": "Despite their strong performance on many tasks, pre-trained language models have been shown to struggle on out-of-distribution compositional generalization. Meanwhile, recent work has shown considerable improvements on many NLP tasks from model scaling. Can scaling up model size also improve compositional generalization in semantic parsing? We evaluate encoder-decoder models up to 11B parameters and decoder-only models up to 540B parameters, and compare model scaling curves for three different methods for applying a pre-trained language model to a new task: fine-tuning all parameters, prompt tuning, and in-context learning. We observe that fine-tuning generally has flat or negative scaling curves on out-of-distribution compositional generalization in semantic parsing evaluations. In-context learning has positive scaling curves, but is generally outperformed by much smaller fine-tuned models. Prompt-tuning can outperform fine-tuning, suggesting further potential improvements from scaling as it exhibits a more positive scaling curve. Additionally, we identify several error trends that vary with model scale. For example, larger models are generally better at modeling the syntax of the output space, but are also more prone to certain types of overfitting. Overall, our study highlights limitations of current techniques for effectively leveraging model scale for compositional generalization, while our analysis also suggests promising directions for future work",
    "checked": true,
    "id": "6e10343767ab09dde83cf99ea3442907402a9810",
    "semantic_title": "evaluating the impact of model scale for compositional generalization in semantic parsing",
    "citation_count": 39,
    "authors": [
      "Linlu Qiu",
      "Peter Shaw",
      "Panupong Pasupat",
      "Tianze Shi",
      "Jonathan Herzig",
      "Emily Pitler",
      "Fei Sha",
      "Kristina Toutanova"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.625": {
    "title": "I'm sorry to hear that\": Finding New Biases in Language Models with a Holistic Descriptor Dataset",
    "volume": "main",
    "abstract": "As language models grow in popularity, it becomes increasingly important to clearly measure all possible markers of demographic identity in order to avoid perpetuating existing societal harms. Many datasets for measuring bias currently exist, but they are restricted in their coverage of demographic axes and are commonly used with preset bias tests that presuppose which types of biases models can exhibit. In this work, we present a new, more inclusive bias measurement dataset, HolisticBias, which includes nearly 600 descriptor terms across 13 different demographic axes. HolisticBias was assembled in a participatory process including experts and community members with lived experience of these terms. These descriptors combine with a set of bias measurement templates to produce over 450,000 unique sentence prompts, which we use to explore, identify, and reduce novel forms of bias in several generative models. We demonstrate that HolisticBias is effective at measuring previously undetectable biases in token likelihoods from language models, as well as in an offensiveness classifier. We will invite additions and amendments to the dataset, which we hope will serve as a basis for more easy-to-use and standardized methods for evaluating bias in NLP models",
    "checked": true,
    "id": "7ef43bacd43393ff116e6fcda6a52a6902e016d7",
    "semantic_title": "i'm sorry to hear that\": finding new biases in language models with a holistic descriptor dataset",
    "citation_count": 59,
    "authors": [
      "Eric Michael Smith",
      "Melissa Hall",
      "Melanie Kambadur",
      "Eleonora Presani",
      "Adina Williams"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.626": {
    "title": "Understanding ME? Multimodal Evaluation for Fine-grained Visual Commonsense",
    "volume": "main",
    "abstract": "Visual commonsense understanding requires Vision Language (VL) models to not only understand image and text but also cross-reference in-between to fully integrate and achieve comprehension of the visual scene described. Recently, various approaches have been developed and have achieved high performance on visual commonsense benchmarks. However, it is unclear whether the models really understand the visual scene and underlying commonsense knowledge due to limited evaluation data resources. To provide an in-depth analysis, we present a Multimodal Evaluation (ME) pipeline to automatically generate question-answer pairs to test models' understanding of the visual scene, text, and related knowledge. We then take a step further to show that training with the ME data boosts the model's performance in standard VCR evaluation. Lastly, our in-depth analysis and comparison reveal interesting findings: (1) semantically low-level information can assist the learning of high-level information but not the opposite; (2) visual information is generally under utilization compared with text",
    "checked": true,
    "id": "ca3f163a5ffbb1ee6d2399b01b417726bfaa4b8c",
    "semantic_title": "understanding me? multimodal evaluation for fine-grained visual commonsense",
    "citation_count": 5,
    "authors": [
      "Zhecan Wang",
      "Haoxuan You",
      "Yicheng He",
      "Wenhao Li",
      "Kai-Wei Chang",
      "Shih-Fu Chang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.627": {
    "title": "Semantic Novelty Detection and Characterization in Factual Text Involving Named Entities",
    "volume": "main",
    "abstract": "Much of the existing work on text novelty detection has been studied at the topic level, i.e., identifying whether the topic of a document or a sentence is novel or not. Little work has been done at the fine-grained semantic level (or contextual level). For example, given that we know Elon Musk is the CEO of a technology company, the sentence \"Elon Musk acted in the sitcom The Big Bang Theory\" is novel and surprising because normally a CEO would not be an actor. Existing topic-based novelty detection methods work poorly on this problem because they do not perform semantic reasoning involving relations between named entities in the text and their background knowledge. This paper proposes an effective model (called PAT-SND) to solve the problem, which can also characterize the novelty. An annotated dataset is also created. Evaluation shows that PAT-SND outperforms 10 baselines by large margins",
    "checked": true,
    "id": "2ed73ad70f4569e5fa93c742a1eddc2c7487220d",
    "semantic_title": "semantic novelty detection and characterization in factual text involving named entities",
    "citation_count": 1,
    "authors": [
      "Nianzu Ma",
      "Sahisnu Mazumder",
      "Alexander Politowicz",
      "Bing Liu",
      "Eric Robertson",
      "Scott Grigsby"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.628": {
    "title": "CN-AutoMIC: Distilling Chinese Commonsense Knowledge from Pretrained Language Models",
    "volume": "main",
    "abstract": "Commonsense knowledge graphs (CKGs) are increasingly applied in various natural language processing tasks. However, most existing CKGs are limited to English, which hinders related research in non-English languages. Meanwhile, directly generating commonsense knowledge from pretrained language models has recently received attention, yet it has not been explored in non-English languages. In this paper, we propose a large-scale Chinese CKG generated from multilingual PLMs, named as **CN-AutoMIC**, aiming to fill the research gap of non-English CKGs. To improve the efficiency, we propose generate-by-category strategy to reduce invalid generation. To ensure the filtering quality, we develop cascaded filters to discard low-quality results. To further increase the diversity and density, we introduce a bootstrapping iteration process to reuse generated results. Finally, we conduct detailed analyses on CN-AutoMIC from different aspects. Empirical results show the proposed CKG has high quality and diversity, surpassing the direct translation version of similar English CKGs. We also find some interesting deficiency patterns and differences between relations, which reveal pending problems in commonsense knowledge generation. We share the resources and related models for further study",
    "checked": true,
    "id": "d9698d8ed8b3c678e1a17e21364024f84e174620",
    "semantic_title": "cn-automic: distilling chinese commonsense knowledge from pretrained language models",
    "citation_count": 3,
    "authors": [
      "Chenhao Wang",
      "Jiachun Li",
      "Yubo Chen",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.629": {
    "title": "Calibrating Student Models for Emotion-related Tasks",
    "volume": "main",
    "abstract": "Knowledge Distillation (KD) is an effective method to transfer knowledge from one network (a.k.a. teacher) to another (a.k.a. student). In this paper, we study KD on the emotion-related tasks from a new perspective: calibration. We further explore the impact of the mixup data augmentation technique on the distillation objective and propose to use a simple yet effective mixup method informed by training dynamics for calibrating the student models. Underpinned by the regularization impact of the mixup process by providing better training signals to the student models using training dynamics, our proposed mixup strategy gradually enhances the student model's calibration while effectively improving its performance. We evaluate the calibration of pre-trained language models through knowledge distillation over three tasks of emotion detection, sentiment analysis, and empathy detection. By conducting extensive experiments on different datasets, with both in-domain and out-of-domain test sets, we demonstrate that student models distilled from teacher models trained using our proposed mixup method obtained the lowest Expected Calibration Errors (ECEs) and best performance on both in-domain and out-of-domain test sets",
    "checked": true,
    "id": "a31e2fdd8c8e2e6d053d512625bbdf32eb9ee5d2",
    "semantic_title": "calibrating student models for emotion-related tasks",
    "citation_count": 1,
    "authors": [
      "Mahshid Hosseini",
      "Cornelia Caragea"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.630": {
    "title": "Overcoming Catastrophic Forgetting in Zero-Shot Cross-Lingual Generation",
    "volume": "main",
    "abstract": "In this paper, we explore the challenging problem of performing a generative task in a target language when labeled data is only available in English, using summarization as a case study. We assume a strict setting with no access to parallel data or machine translation and find that common transfer learning approaches struggle in this setting, as a generative multilingual model fine-tuned purely on English catastrophically forgets how to generate non-English. Given the recent rise of parameter-efficient adaptation techniques, we conduct the first investigation into how one such method, prompt tuning (Lester et al., 2021), can overcome catastrophic forgetting to enable zero-shot cross-lingual generation. Our experiments show that parameter-efficient prompt tuning provides gains over standard fine-tuning when transferring between less-related languages, e.g., from English to Thai. However, a significant gap still remains between these methods and fully-supervised baselines. To improve cross-lingual transfer further, we explore several approaches, including: (1) mixing in unlabeled multilingual data, and (2) explicitly factoring prompts into recombinable language and task components. Our approaches can provide further quality gains, suggesting that robust zero-shot cross-lingual generation is within reach",
    "checked": true,
    "id": "ffd8f81ed69ddfef6cddc3e8d0eae78f7b13435a",
    "semantic_title": "overcoming catastrophic forgetting in zero-shot cross-lingual generation",
    "citation_count": 37,
    "authors": [
      "Tu Vu",
      "Aditya Barua",
      "Brian Lester",
      "Daniel Cer",
      "Mohit Iyyer",
      "Noah Constant"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.631": {
    "title": "Improving Large-scale Paraphrase Acquisition and Generation",
    "volume": "main",
    "abstract": "This paper addresses the quality issues in existing Twitter-based paraphrase datasets, and discusses the necessity of using two separate definitions of paraphrase for identification and generation tasks. We present a new Multi-Topic Paraphrase in Twitter (MultiPIT) corpus that consists of a total of 130k sentence pairs with crowdsoursing (MultiPIT_crowd) and expert (MultiPIT_expert) annotations using two different paraphrase definitions for paraphrase identification, in addition to a multi-reference test set (MultiPIT_NMR) and a large automatically constructed training set (MultiPIT_Auto) for paraphrase generation. With improved data annotation quality and task-specific paraphrase definition, the best pre-trained language model fine-tuned on our dataset achieves the state-of-the-art performance of 84.2 F1 for automatic paraphrase identification. Furthermore, our empirical results also demonstrate that the paraphrase generation models trained on MultiPIT_Auto generate more diverse and high-quality paraphrases compared to their counterparts fine-tuned on other corpora such as Quora, MSCOCO, and ParaNMT",
    "checked": true,
    "id": "dc62b87f2eae1683f5dc667d5035ffbd36bbe011",
    "semantic_title": "improving large-scale paraphrase acquisition and generation",
    "citation_count": 6,
    "authors": [
      "Yao Dou",
      "Chao Jiang",
      "Wei Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.632": {
    "title": "Entropy- and Distance-Based Predictors From GPT-2 Attention Patterns Predict Reading Times Over and Above GPT-2 Surprisal",
    "volume": "main",
    "abstract": "Transformer-based large language models are trained to make predictions about the next word by aggregating representations of previous tokens through their self-attention mechanism. In the field of cognitive modeling, such attention patterns have recently been interpreted as embodying the process of cue-based retrieval, in which attention over multiple targets is taken to generate interference and latency during retrieval. Under this framework, this work first defines an entropy-based predictor that quantifies the diffuseness of self-attention, as well as distance-based predictors that capture the incremental change in attention patterns across timesteps. Moreover, following recent studies that question the informativeness of attention weights, we also experiment with alternative methods for incorporating vector norms into attention weights. Regression experiments using predictors calculated from the GPT-2 language model show that these predictors deliver a substantially better fit to held-out self-paced reading and eye-tracking data over a rigorous baseline including GPT-2 surprisal",
    "checked": true,
    "id": "db6d3dfebaf1ee8b9aeb97b83d8697e5bd62a9b3",
    "semantic_title": "entropy- and distance-based predictors from gpt-2 attention patterns predict reading times over and above gpt-2 surprisal",
    "citation_count": 9,
    "authors": [
      "Byung-Doh Oh",
      "William Schuler"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.633": {
    "title": "A Survey of Computational Framing Analysis Approaches",
    "volume": "main",
    "abstract": "Framing analysis is predominantly qualitative and quantitative, examining a small dataset with manual coding. Easy access to digital data in the last two decades prompts scholars in both computation and social sciences to utilize various computational methods to explore frames in large-scale datasets. The growing scholarship, however, lacks a comprehensive understanding and resources of computational framing analysis methods. Aiming to address the gap, this article surveys existing computational framing analysis approaches and puts them together. The research is expected to help scholars and journalists gain a deeper understanding of how frames are being explored computationally, better equip them to analyze frames in large-scale datasets, and, finally, work on advancing methodological approaches",
    "checked": true,
    "id": "94427dfc3278ca6a8e439a63e8fb899d5e45cd84",
    "semantic_title": "a survey of computational framing analysis approaches",
    "citation_count": 12,
    "authors": [
      "Mohammad Ali",
      "Naeemul Hassan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.634": {
    "title": "Learning Cross-Task Dependencies for Joint Extraction of Entities, Events, Event Arguments, and Relations",
    "volume": "main",
    "abstract": "Extracting entities, events, event arguments, and relations (i.e., task instances) from text represents four main challenging tasks in information extraction (IE), which have been solved jointly (JointIE) to boost the overall performance for IE. As such, previous work often leverages two types of dependencies between the tasks, i.e., cross-instance and cross-type dependencies representing relatedness between task instances and correlations between information types of the tasks. However, the cross-task dependencies in prior work are not optimal as they are only designed manually according to some task heuristics. To address this issue, we propose a novel model for JointIE that aims to learn cross-task dependencies from data. In particular, we treat each task instance as a node in a dependency graph where edges between the instances are inferred through information from different layers of a pretrained language model (e.g., BERT). Furthermore, we utilize the Chow-Liu algorithm to learn a dependency tree between information types for JointIE by seeking to approximate the joint distribution of the types from data. Finally, the Chow-Liu dependency tree is used to generate cross-type patterns, serving as anchor knowledge to guide the learning of representations and dependencies between instances for JointIE. Experimental results show that our proposed model significantly outperforms strong JointIE baselines over four datasets with different languages",
    "checked": true,
    "id": "11f7a9caf21341c4fcb8f7d50fc62afc58f68ede",
    "semantic_title": "learning cross-task dependencies for joint extraction of entities, events, event arguments, and relations",
    "citation_count": 5,
    "authors": [
      "Minh Van Nguyen",
      "Bonan Min",
      "Franck Dernoncourt",
      "Thien Nguyen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.635": {
    "title": "Don't Copy the Teacher: Data and Model Challenges in Embodied Dialogue",
    "volume": "main",
    "abstract": "Embodied dialogue instruction following requires an agent to complete a complex sequence of tasks from a natural language exchange. The recent introduction of benchmarks raises the question of how best to train and evaluate models for this multi-turn, multi-agent, long-horizon task. This paper contributes to that conversation, by arguing that imitation learning (IL) and related low-level metrics are actually misleading and do not align with the goals of embodied dialogue research and may hinder progress. We provide empirical comparisons of metrics, analysis of three models, and make suggestions for how the field might best progress. First, we observe that models trained with IL take spurious actions during evaluation. Second, we find that existing models fail to ground query utterances, which are essential for task completion. Third, we argue evaluation should focus on higher-level semantic goals. We will release code to additionally filter the data and benchmark models for improved evaluation",
    "checked": true,
    "id": "a19a9b3db8b67e91b45724e349aa2ab3f2006437",
    "semantic_title": "don't copy the teacher: data and model challenges in embodied dialogue",
    "citation_count": 3,
    "authors": [
      "So Yeon Min",
      "Hao Zhu",
      "Ruslan Salakhutdinov",
      "Yonatan Bisk"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.636": {
    "title": "ALFRED-L: Investigating the Role of Language for Action Learning in Interactive Visual Environments",
    "volume": "main",
    "abstract": "Embodied Vision and Language Task Completion requires an embodied agent to interpret natural language instructions and egocentric visual observations to navigate through and interact with environments. In this work, we examine ALFRED, a challenging benchmark for embodied task completion, with the goal of gaining insight into how effectively models utilize language. We find evidence that sequence-to-sequence and transformer-based models trained on this benchmark are not sufficiently sensitive to changes in input language instructions. Next, we construct a new test split – ALFRED-L to test whether ALFRED models can generalize to task structures not seen during training that intuitively require the same types of language understanding required in ALFRED. Evaluation of existing models on ALFRED-L suggests that (a) models are overly reliant on the sequence in which objects are visited in typical ALFRED trajectories and fail to adapt to modifications of this sequence and (b) models trained with additional augmented trajectories are able to adapt relatively better to such changes in input language instructions",
    "checked": true,
    "id": "b94fdb81b71747f1d2afa171c077a2491a753401",
    "semantic_title": "alfred-l: investigating the role of language for action learning in interactive visual environments",
    "citation_count": 1,
    "authors": [
      "Arjun Akula",
      "Spandana Gella",
      "Aishwarya Padmakumar",
      "Mahdi Namazifar",
      "Mohit Bansal",
      "Jesse Thomason",
      "Dilek Hakkani-Tur"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.637": {
    "title": "Dungeons and Dragons as a Dialog Challenge for Artificial Intelligence",
    "volume": "main",
    "abstract": "AI researchers have posited Dungeons and Dragons (D&D) as a challenge problem to test systems on various language-related capabilities. In this paper, we frame D&D specifically as a dialogue system challenge, where the tasks are to both generate the next conversational turn in the game and predict the state of the game given the dialogue history. We create a gameplay dataset consisting of nearly 900 games, with a total of 7,000 players, 800,000 dialogue turns, 500,000 dice rolls, and 58 million words. We automatically annotate the data with partial state information about the game play. We train a large language model (LM) to generate the next game turn, conditioning it on different information. The LM can respond as a particular character or as the player who runs the game—i.e., the Dungeon Master (DM). It is trained to produce dialogue that is either in-character (roleplaying in the fictional world) or out-of-character (discussing rules or strategy). We perform a human evaluation to determine what factors make the generated output plausible and interesting. We further perform an automatic evaluation to determine how well the model can predict the game state given the history and examine how well tracking the game state improves its ability to produce plausible conversational output",
    "checked": true,
    "id": "22d34b881d64523da54f13d01fc3c6d93a8412e3",
    "semantic_title": "dungeons and dragons as a dialog challenge for artificial intelligence",
    "citation_count": 22,
    "authors": [
      "Chris Callison-Burch",
      "Gaurav Singh Tomar",
      "Lara J. Martin",
      "Daphne Ippolito",
      "Suma Bailis",
      "David Reitter"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.638": {
    "title": "Unsupervised Entity Linking with Guided Summarization and Multiple-Choice Selection",
    "volume": "main",
    "abstract": "Entity linking, the task of linking potentially ambiguous mentions in texts to corresponding knowledge-base entities, is an important component for language understanding. We address two challenge in entity linking: how to leverage wider contexts surrounding a mention, and how to deal with limited training data. We propose a fully unsupervised model called SumMC that first generates a guided summary of the contexts conditioning on the mention, and then casts the task to a multiple-choice problem where the model chooses an entity from a list of candidates. In addition to evaluating our model on existing datasets that focus on named entities, we create a new dataset that links noun phrases from WikiHow to Wikidata. We show that our SumMC model achieves state-of-the-art unsupervised performance on our new dataset and on exiting datasets",
    "checked": true,
    "id": "4412cf194a6c1dab0515011137fbf06632e18d7a",
    "semantic_title": "unsupervised entity linking with guided summarization and multiple-choice selection",
    "citation_count": 4,
    "authors": [
      "Young Min Cho",
      "Li Zhang",
      "Chris Callison-Burch"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.639": {
    "title": "Weakly-Supervised Temporal Article Grounding",
    "volume": "main",
    "abstract": "Given a long untrimmed video and natural language queries, video grounding (VG) aims to temporally localize the semantically-aligned video segments. Almost all existing VG work holds two simple but unrealistic assumptions: 1) All query sentences can be grounded in the corresponding video. 2) All query sentences for the same video are always at the same semantic scale. Unfortunately, both assumptions make today's VG models fail to work in practice. For example, in real-world multimodal assets (eg, news articles), most of the sentences in the article can not be grounded in their affiliated videos, and they typically have rich hierarchical relations (ie, at different semantic scales). To this end, we propose a new challenging grounding task: Weakly-Supervised temporal Article Grounding (WSAG). Specifically, given an article and a relevant video, WSAG aims to localize all \"groundable\" sentences to the video, and these sentences are possibly at different semantic scales. Accordingly, we collect the first WSAG dataset to facilitate this task: YouwikiHow, which borrows the inherent multi-scale descriptions in wikiHow articles and plentiful YouTube videos. In addition, we propose a simple but effective method DualMIL for WSAG, which consists of a two-level MIL loss and a single-/cross- sentence constraint loss. These training objectives are carefully designed for these relaxed assumptions. Extensive ablations have verified the effectiveness of DualMIL",
    "checked": true,
    "id": "aaea3b1c481098686c34c093d2b36156689db115",
    "semantic_title": "weakly-supervised temporal article grounding",
    "citation_count": 4,
    "authors": [
      "Long Chen",
      "Yulei Niu",
      "Brian Chen",
      "Xudong Lin",
      "Guangxing Han",
      "Christopher Thomas",
      "Hammad Ayyubi",
      "Heng Ji",
      "Shih-Fu Chang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.640": {
    "title": "Exploring Dual Encoder Architectures for Question Answering",
    "volume": "main",
    "abstract": "Dual encoders have been used for question-answering (QA) and information retrieval (IR) tasks with good results. There are two major types of dual encoders, Siamese Dual Encoders (SDE), with parameters shared across two encoders, and Asymmetric Dual Encoder (ADE), with two distinctly parameterized encoders. In this work, we explore the dual encoder architectures for QA retrieval tasks. By evaluating on MS MARCO, open domain NQ, and the MultiReQA benchmarks, we show that SDE performs significantly better than ADE. We further propose three different improved versions of ADEs. Based on the evaluation of QA retrieval tasks and direct analysis of the embeddings, we demonstrate that sharing parameters in projection layers would enable ADEs to perform competitively with SDEs",
    "checked": true,
    "id": "b9a7a565c0af63f467595f69263974f2e5bc0bbe",
    "semantic_title": "exploring dual encoder architectures for question answering",
    "citation_count": 6,
    "authors": [
      "Zhe Dong",
      "Jianmo Ni",
      "Dan Bikel",
      "Enrique Alfonseca",
      "Yuan Wang",
      "Chen Qu",
      "Imed Zitouni"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.641": {
    "title": "arXivEdits: Understanding the Human Revision Process in Scientific Writing",
    "volume": "main",
    "abstract": "Scientific publications are the primary means to communicate research discoveries, where the writing quality is of crucial importance. However, prior work studying the human editing process in this domain mainly focused on the abstract or introduction sections, resulting in an incomplete picture. In this work, we provide a complete computational framework for studying text revision in scientific writing. We first introduce arXivEdits, a new annotated corpus of 751 full papers from arXiv with gold sentence alignment across their multiple versions of revision, as well as fine-grained span-level edits and their underlying intentions for 1,000 sentence pairs. It supports our data-driven analysis to unveil the common strategies practiced by researchers for revising their papers. To scale up the analysis, we also develop automatic methods to extract revision at document-, sentence-, and word-levels. A neural CRF sentence alignment model trained on our corpus achieves 93.8 F1, enabling the reliable matching of sentences between different versions. We formulate the edit extraction task as a span alignment problem, and our proposed method extracts more fine-grained and explainable edits, compared to the commonly used diff algorithm. An intention classifier trained on our dataset achieves 78.9 F1 on the fine-grained intent classification task. Our data and system are released at tiny.one/arxivedits",
    "checked": true,
    "id": "758f216e2370bd517eeda23c2d7db963a95104f9",
    "semantic_title": "arxivedits: understanding the human revision process in scientific writing",
    "citation_count": 9,
    "authors": [
      "Chao Jiang",
      "Wei Xu",
      "Samuel Stevens"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.642": {
    "title": "Why Do You Feel This Way? Summarizing Triggers of Emotions in Social Media Posts",
    "volume": "main",
    "abstract": "Crises such as the COVID-19 pandemic continuously threaten our world and emotionally affect billions of people worldwide in distinct ways. Understanding the triggers leading to people's emotions is of crucial importance. Social media posts can be a good source of such analysis, yet these texts tend to be charged with multiple emotions, with triggers scattering across multiple sentences. This paper takes a novel angle, namely, emotion detection and trigger summarization, aiming to both detect perceived emotions in text, and summarize events and their appraisals that trigger each emotion. To support this goal, we introduce CovidET (Emotions and their Triggers during Covid-19), a dataset of ~1,900 English Reddit posts related to COVID-19, which contains manual annotations of perceived emotions and abstractive summaries of their triggers described in the post. We develop strong baselines to jointly detect emotions and summarize emotion triggers. Our analyses show that CovidET presents new challenges in emotion-specific summarization, as well as multi-emotion detection in long social media posts",
    "checked": true,
    "id": "bb6bbc8f5dd79e06b85be269603a38dcc1799436",
    "semantic_title": "why do you feel this way? summarizing triggers of emotions in social media posts",
    "citation_count": 4,
    "authors": [
      "Hongli Zhan",
      "Tiberiu Sosea",
      "Cornelia Caragea",
      "Junyi Jessy Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.643": {
    "title": "Analogical Math Word Problems Solving with Enhanced Problem-Solution Association",
    "volume": "main",
    "abstract": "Math word problem (MWP) solving is an important task in question answering which requires human-like reasoning ability. Analogical reasoning has long been used in mathematical education, as it enables students to apply common relational structures of mathematical situations to solve new problems. In this paper, we propose to build a novel MWP solver by leveraging analogical MWPs, which advance the solver's generalization ability across different kinds of MWPs. The key idea, named analogy identification, is to associate the analogical MWP pairs in a latent space, i.e., encoding an MWP close to another analogical MWP, while leaving away from the non-analogical ones. Moreover, a solution discriminator is integrated into the MWP solver to enhance the association between an MWP and its true solution. The evaluation results verify that our proposed analogical learning strategy promotes the performance of MWP-BERT on Math23k over the state-of-the-art model Generate2Rank, with 5 times fewer parameters in the encoder. We also find that our model has a stronger generalization ability in solving difficult MWPs due to the analogical learning from easy MWPs",
    "checked": true,
    "id": "71471561137956d6aeec39173db460a28d86c11b",
    "semantic_title": "analogical math word problems solving with enhanced problem-solution association",
    "citation_count": 7,
    "authors": [
      "Zhenwen Liang",
      "Jipeng Zhang",
      "Xiangliang Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.644": {
    "title": "Towards Teachable Reasoning Systems: Using a Dynamic Memory of User Feedback for Continual System Improvement",
    "volume": "main",
    "abstract": "Our goal is a teachable reasoning system for question-answering (QA), where a user can interact with faithful answer explanations, and correct its errors so that the system improves over time. Our approach is to augment a QA model with a dynamic memory of user feedback, containing user-supplied corrections toerroneous model beliefs that users identify during interaction. Retrievals from memory are used as additional context for QA, to help avoid previous mistakes in similar new situations - a novel application of memory-based continuous learning. With simulated feedback, we find that our system (called TeachMe) continually improves with time, and without model retraining, requiring feedback on only 25% of training examples to reach within 1% of the upper-bound (feedback on all examples). Similarly, in experiments with real users, we observe a similar trend, with performance improving by over 15% on a hidden test set after teaching. This suggests new opportunities for using frozen language models in an interactive setting where users can inspect, debug, and correct the model's beliefs, leading to improved system's performance over time",
    "checked": true,
    "id": "e7d75b80e0fa3ae190ff91676dbf18a006d3a311",
    "semantic_title": "towards teachable reasoning systems: using a dynamic memory of user feedback for continual system improvement",
    "citation_count": 27,
    "authors": [
      "Bhavana Dalvi Mishra",
      "Oyvind Tafjord",
      "Peter Clark"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.645": {
    "title": "Knowledge Transfer from Answer Ranking to Answer Generation",
    "volume": "main",
    "abstract": "Recent studies show that Question Answering (QA) based on Answer Sentence Selection (AS2) can be improved by generating an improved answer from the top-k ranked answer sentences (termed GenQA). This allows for synthesizing the information from multiple candidates into a concise, natural-sounding answer. However, creating large-scale supervised training data for GenQA models is very challenging. In this paper, we propose to train a GenQA model by transferring knowledge from a trained AS2 model, to overcome the aforementioned issue. First, we use an AS2 model to produce a ranking over answer candidates for a set of questions. Then, we use the top ranked candidate as the generation target, and the next k top ranked candidates as context for training a GenQA model. We also propose to use the AS2 model prediction scores for loss weighting and score-conditioned input/output shaping, to aid the knowledge transfer. Our evaluation on three public and one large industrial datasets demonstrates the superiority of our approach over the AS2 baseline, and GenQA trained using supervised data",
    "checked": true,
    "id": "27202f962798d08b39601a36127360c5ccd9c625",
    "semantic_title": "knowledge transfer from answer ranking to answer generation",
    "citation_count": 5,
    "authors": [
      "Matteo Gabburo",
      "Rik Koncel-Kedziorski",
      "Siddhant Garg",
      "Luca Soldaini",
      "Alessandro Moschitti"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.646": {
    "title": "Perturbation Augmentation for Fairer NLP",
    "volume": "main",
    "abstract": "Unwanted and often harmful social biases are becoming ever more salient in NLP research, affecting both models and datasets. In this work, we ask whether training on demographically perturbed data leads to fairer language models. We collect a large dataset of human annotated text perturbations and train a neural perturbation model, which we show outperforms heuristic alternatives. We find that (i) language models (LMs) pre-trained on demographically perturbed corpora are typically more fair, and (ii) LMs finetuned on perturbed GLUE datasets exhibit less demographic bias on downstream tasks, and (iii) fairness improvements do not come at the expense of performance on downstream tasks. Lastly, we discuss outstanding questions about how best to evaluate the (un)fairness of large language models. We hope that this exploration of neural demographic perturbation will help drive more improvement towards fairer NLP",
    "checked": true,
    "id": "011095a0082e5e301f9bf30267b193c1c9e7e370",
    "semantic_title": "perturbation augmentation for fairer nlp",
    "citation_count": 34,
    "authors": [
      "Rebecca Qian",
      "Candace Ross",
      "Jude Fernandes",
      "Eric Michael Smith",
      "Douwe Kiela",
      "Adina Williams"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.647": {
    "title": "Automatic Document Selection for Efficient Encoder Pretraining",
    "volume": "main",
    "abstract": "Building pretrained language models is considered expensive and data-intensive, but must we increase dataset size to achieve better performance? We propose an alternative to larger training sets by automatically identifying smaller yet domain-representative subsets. We extend Cynical Data Selection, a statistical sentence scoring method that conditions on a representative target domain corpus. As an example, we treat the OntoNotes corpus as a target domain and pretrain a RoBERTa-like encoder from a cynically selected subset of the Pile. On both perplexity and across several downstream tasks in the target domain, it consistently outperforms random selection with 20x less data, 3x fewer training iterations, and 2x less estimated cloud compute cost, validating the recipe of automatic document selection for LM pretraining",
    "checked": true,
    "id": "4bef9d46209ac8988ea5ab83547149760d4af65e",
    "semantic_title": "automatic document selection for efficient encoder pretraining",
    "citation_count": 5,
    "authors": [
      "Yukun Feng",
      "Patrick Xia",
      "Benjamin Van Durme",
      "João Sedoc"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.648": {
    "title": "The Aligned Multimodal Movie Treebank: An audio, video, dependency-parse treebank",
    "volume": "main",
    "abstract": "Treebanks have traditionally included only text and were derived from written sources such as newspapers or the web. We introduce the Aligned Multimodal Movie Treebank (AMMT), an English language treebank derived from dialog in Hollywood movies which includes transcriptions of the audio-visual streams with word-level alignment, as well as part of speech tags and dependency parses in the Universal Dependencies formalism. AMMT consists of 31,264 sentences and 218,090 words, that will amount to the 3rd largest UD English treebank and the only multimodal treebank in UD. To help with the web-based annotation effort, we also introduce the Efficient Audio Alignment Annotator (EAAA), a companion tool that enables annotators to significantly speed-up their annotation processes",
    "checked": true,
    "id": "ea41d9d03850d7c702b8c9e7b666835c3a40a96f",
    "semantic_title": "the aligned multimodal movie treebank: an audio, video, dependency-parse treebank",
    "citation_count": 0,
    "authors": [
      "Adam Yaari",
      "Jan DeWitt",
      "Henry Hu",
      "Bennett Stankovits",
      "Sue Felshin",
      "Yevgeni Berzak",
      "Helena Aparicio",
      "Boris Katz",
      "Ignacio Cases",
      "Andrei Barbu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.649": {
    "title": "DEMETR: Diagnosing Evaluation Metrics for Translation",
    "volume": "main",
    "abstract": "While machine translation evaluation metrics based on string overlap (e.g., BLEU) have their limitations, their computations are transparent: the BLEU score assigned to a particular candidate translation can be traced back to the presence or absence of certain words. The operations of newer learned metrics (e.g., BLEURT, COMET), which leverage pretrained language models to achieve higher correlations with human quality judgments than BLEU, are opaque in comparison. In this paper, we shed light on the behavior of these learned metrics by creating DEMETR, a diagnostic dataset with 31K English examples (translated from 10 source languages) for evaluating the sensitivity of MT evaluation metrics to 35 different linguistic perturbations spanning semantic, syntactic, and morphological error categories. All perturbations were carefully designed to form minimal pairs with the actual translation (i.e., differ in only one aspect). We find that learned metrics perform substantially better than string-based metrics on DEMETR. Additionally, learned metrics differ in their sensitivity to various phenomena (e.g., BERTScore is sensitive to untranslated words but relatively insensitive to gender manipulation, while COMET is much more sensitive to word repetition than to aspectual changes). We publicly release DEMETR to spur more informed future development of machine translation evaluation metrics",
    "checked": true,
    "id": "9443a623d6e0d423adb9c61b5d225f0077f38767",
    "semantic_title": "demetr: diagnosing evaluation metrics for translation",
    "citation_count": 23,
    "authors": [
      "Marzena Karpinska",
      "Nishant Raj",
      "Katherine Thai",
      "Yixiao Song",
      "Ankita Gupta",
      "Mohit Iyyer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.650": {
    "title": "Empowering Language Models with Knowledge Graph Reasoning for Open-Domain Question Answering",
    "volume": "main",
    "abstract": "Answering open-domain questions requires world knowledge about in-context entities. As pre-trained Language Models (LMs) lack the power to store all required knowledge, external knowledge sources, such as knowledge graphs, are often used to augment LMs. In this work, we propose knOwledge REasOning empowered Language Model(OREO-LM), which consists of a novel Knowledge Interaction Layer that can be flexibly plugged into existing Transformer-based LMs to interact with a differentiable Knowledge Graph Reasoning module collaboratively. In this way, LM guides KG to walk towards the desired answer, while the retrieved knowledge improves LM.By adopting OREO-LM to RoBERTa and T5, we show significant performance gain, achieving state-of-art results in the Closed-Book setting. The performance enhancement is mainly from the KG reasoning's capacity to infer missing relational facts. In addition, OREO-LM provides reasoning paths as rationales to interpret the model's decision",
    "checked": true,
    "id": "8806ba65f2a477fe685c250c1536d2e8ef450958",
    "semantic_title": "empowering language models with knowledge graph reasoning for open-domain question answering",
    "citation_count": 17,
    "authors": [
      "Ziniu Hu",
      "Yichong Xu",
      "Wenhao Yu",
      "Shuohang Wang",
      "Ziyi Yang",
      "Chenguang Zhu",
      "Kai-Wei Chang",
      "Yizhou Sun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.651": {
    "title": "Debiasing Pretrained Text Encoders by Paying Attention to Paying Attention",
    "volume": "main",
    "abstract": "Natural Language Processing (NLP) models are found to exhibit discriminatory stereotypes across many social constructs, e.g. gender and race. In comparison to the progress made in reducing bias from static word embeddings, fairness in sentence-level text encoders received little consideration despite their wider applicability in contemporary NLP tasks. In this paper, we propose a debiasing method for pre-trained text encoders that both reduces social stereotypes, and inflicts next to no semantic damage. Unlike previous studies that directly manipulate the embeddings, we suggest to dive deeper into the operation of these encoders, and pay more attention to the way they pay attention to different social groups. We find that stereotypes are also encoded in the attention layer. Then, we work on model debiasing by redistributing the attention scores of a text encoder such that it forgets any preference to historically advantaged groups, and attends to all social classes with the same intensity. Our experiments confirm that reducing bias from attention effectively mitigates it from the model's text representations",
    "checked": true,
    "id": "1fbb406a7387451bb1b6b67a44975c65120ad03a",
    "semantic_title": "debiasing pretrained text encoders by paying attention to paying attention",
    "citation_count": 12,
    "authors": [
      "Yacine Gaci",
      "Boualem Benatallah",
      "Fabio Casati",
      "Khalid Benabdeslem"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.652": {
    "title": "MEE: A Novel Multilingual Event Extraction Dataset",
    "volume": "main",
    "abstract": "Event Extraction (EE) is one of the fundamental tasks in Information Extraction (IE) that aims to recognize event mentions and their arguments (i.e., participants) from text. Due to its importance, extensive methods and resources have been developed for Event Extraction. However, one limitation of current research for EE involves the under-exploration for non-English languages in which the lack of high-quality multilingual EE datasets for model training and evaluation has been the main hindrance. To address this limitation, we propose a novel Multilingual Event Extraction dataset (MEE) that provides annotation for more than 50K event mentions in 8 typologically different languages. MEE comprehensively annotates data for entity mentions, event triggers and event arguments. We conduct extensive experiments on the proposed dataset to reveal challenges and opportunities for multilingual EE. To foster future research in this direction, our dataset will be publicly available",
    "checked": true,
    "id": "316036e725f031a743829365f5c5a5614a091b16",
    "semantic_title": "mee: a novel multilingual event extraction dataset",
    "citation_count": 10,
    "authors": [
      "Amir Pouran Ben Veyseh",
      "Javid Ebrahimi",
      "Franck Dernoncourt",
      "Thien Nguyen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.653": {
    "title": "RobustLR: A Diagnostic Benchmark for Evaluating Logical Robustness of Deductive Reasoners",
    "volume": "main",
    "abstract": "Transformers have been shown to be able to perform deductive reasoning on inputs containing rules and statements written in the English natural language. However, it is unclear if these models indeed follow rigorous logical reasoning to arrive at the prediction or rely on spurious correlation patterns in making decisions. A strong deductive reasoning model should consistently understand the semantics of different logical operators. To this end, we present RobustLR, a diagnostic benchmark that evaluates the robustness of language models to minimal logical edits in the inputs and different logical equivalence conditions. In our experiments with RoBERTa, T5, and GPT3 we show that the models trained on deductive reasoning datasets do not perform consistently on the RobustLR test set, thus showing that the models are not robust to our proposed logical perturbations. Further, we observe that the models find it especially hard to learn logical negation operators. Our results demonstrate the shortcomings of current language models in logical reasoning and call for the development of better inductive biases to teach the logical semantics to language models. All the datasets and code base have been made publicly available",
    "checked": true,
    "id": "721a09d68364aef489fa593b446923df4c6df8f2",
    "semantic_title": "robustlr: a diagnostic benchmark for evaluating logical robustness of deductive reasoners",
    "citation_count": 14,
    "authors": [
      "Soumya Sanyal",
      "Zeyi Liao",
      "Xiang Ren"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.654": {
    "title": "Evaluating and Improving Factuality in Multimodal Abstractive Summarization",
    "volume": "main",
    "abstract": "Current metrics for evaluating factuality for abstractive document summarization have achieved high correlations with human judgment, but they do not account for the vision modality and thus are not adequate for vision-and-language summarization. We propose CLIPBERTSCORE, a simple weighted combination of CLIPScore and BERTScore to leverage the robustness and strong factuality detection performance between image-summary and document-summary, respectively. Next, due to the lack of meta-evaluation benchmarks to evaluate the quality of multimodal factuality metrics, we collect human judgments of factuality with respect to documents and images. We show that this simple combination of two metrics in the zero-shot setting achieves higher correlations than existing factuality metrics for document summarization, outperforms an existing multimodal summarization metric, and performs competitively with strong multimodal factuality metrics specifically fine-tuned for the task. Our thorough analysis demonstrates the robustness and high correlation of CLIPBERTSCORE and its components on four factuality metric-evaluation benchmarks. Finally, we demonstrate two practical downstream applications of our CLIPBERTSCORE metric: for selecting important images to focus on during training, and as a reward for reinforcement learning to improve factuality of multimodal summary generation w.r.t automatic and human evaluation",
    "checked": true,
    "id": "10edd3ef21ad148ac1517fbc5a31a944e78b7d63",
    "semantic_title": "evaluating and improving factuality in multimodal abstractive summarization",
    "citation_count": 4,
    "authors": [
      "David Wan",
      "Mohit Bansal"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.655": {
    "title": "Referee: Reference-Free Sentence Summarization with Sharper Controllability through Symbolic Knowledge Distillation",
    "volume": "main",
    "abstract": "We present Referee, a novel framework for sentence summarization that can be trained reference-free (i.e., requiring no gold summaries for supervision), while allowing direct control for compression ratio. Our work is the first to demonstrate that reference-free, controlled sentence summarization is feasible via the conceptual framework of Symbolic Knowledge Distillation (West et al., 2022), where latent knowledge in pre-trained language models is distilled via explicit examples sampled from the teacher models, further purified with three types of filters: length, fidelity, and Information Bottleneck. Moreover, we uniquely propose iterative distillation of knowledge, where student models from the previous iteration of distillation serve as teacher models in the next iteration. Starting off from a relatively modest set of GPT3-generated summaries, we demonstrate how iterative knowledge distillation can lead to considerably smaller, but better summarizers with sharper controllability. A useful by-product of this iterative distillation process is a high-quality dataset of sentence-summary pairs with varying degrees of compression ratios. Empirical results demonstrate that the final student models vastly outperform the much larger GPT3-Instruct model in terms of the controllability of compression ratios, without compromising the quality of resulting summarization",
    "checked": true,
    "id": "78d3955e30d99650d078ba3ce1a523745da31040",
    "semantic_title": "referee: reference-free sentence summarization with sharper controllability through symbolic knowledge distillation",
    "citation_count": 12,
    "authors": [
      "Melanie Sclar",
      "Peter West",
      "Sachin Kumar",
      "Yulia Tsvetkov",
      "Yejin Choi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.656": {
    "title": "Algorithms for Weighted Pushdown Automata",
    "volume": "main",
    "abstract": "Weighted pushdown automata (WPDAs) are at the core of many natural language processing tasks, like syntax-based statistical machine translation and transition-based dependency parsing. As most existing dynamic programming algorithms are designed for context-free grammars (CFGs), algorithms for PDAs often resort to a PDA-to-CFG conversion. In this paper, we develop novel algorithms that operate directly on WPDAs. Our algorithms are inspired by Lang's algorithm, but use a more general definition of pushdown automaton and either reduce the space requirements by a factor of |Gamma| (the size of the stack alphabet) or reduce the runtime by a factor of more than |Q| (the number of states). When run on the same class of PDAs as Lang's algorithm, our algorithm is both more space-efficient by a factor of |Gamma| and more time-efficient by a factor of |Q| x |Gamma|",
    "checked": true,
    "id": "37f85277e20c1c99ec0abf3a5b2a7da9f7cda53c",
    "semantic_title": "algorithms for weighted pushdown automata",
    "citation_count": 3,
    "authors": [
      "Alexandra Butoi",
      "Brian DuSell",
      "Tim Vieira",
      "Ryan Cotterell",
      "David Chiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.657": {
    "title": "MABEL: Attenuating Gender Bias using Textual Entailment Data",
    "volume": "main",
    "abstract": "Pre-trained language models encode undesirable social biases, which are further exacerbated in downstream use. To this end, we propose MABEL (a Method for Attenuating Gender Bias using Entailment Labels), an intermediate pre-training approach for mitigating gender bias in contextualized representations. Key to our approach is the use of a contrastive learning objective on counterfactually augmented, gender-balanced entailment pairs from natural language inference (NLI) datasets. We also introduce an alignment regularizer that pulls identical entailment pairs along opposite gender directions closer. We extensively evaluate our approach on intrinsic and extrinsic metrics, and show that MABEL outperforms previous task-agnostic debiasing approaches in terms of fairness. It also preserves task performance after fine-tuning on downstream tasks. Together, these findings demonstrate the suitability of NLI data as an effective means of bias mitigation, as opposed to only using unlabeled sentences in the literature. Finally, we identify that existing approaches often use evaluation settings that are insufficient or inconsistent. We make an effort to reproduce and compare previous methods, and call for unifying the evaluation settings across gender debiasing methods for better future comparison",
    "checked": true,
    "id": "20e1ef6a126bd9bc0b4e899debbf65c6baa21652",
    "semantic_title": "mabel: attenuating gender bias using textual entailment data",
    "citation_count": 14,
    "authors": [
      "Jacqueline He",
      "Mengzhou Xia",
      "Christiane Fellbaum",
      "Danqi Chen"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.658": {
    "title": "Breakpoint Transformers for Modeling and Tracking Intermediate Beliefs",
    "volume": "main",
    "abstract": "Can we teach models designed for language understanding tasks to track and improve their beliefs through intermediate points in text? Besides making their inner workings more transparent, this would also help make models more reliable and consistent. To this end, we propose a representation learning framework called breakpoint modeling that allows for efficient and robust learning of this type. Given any text encoder and data marked with intermediate states (breakpoints) along with corresponding textual queries viewed as true/false propositions (i.e., the candidate intermediate beliefs of a model), our approach trains models in an efficient and end-to-end fashion to build intermediate representations that facilitate direct querying and training of beliefs at arbitrary points in text, alongside solving other end-tasks. We evaluate breakpoint modeling on a diverse set of NLU tasks including relation reasoning on Cluttr and narrative understanding on bAbI. Using novel proposition prediction tasks alongside these end-tasks, we show the benefit of our T5-based breakpoint transformer over strong conventional representation learning approaches in terms of processing efficiency, belief accuracy, and belief consistency, all with minimal to no degradation on the end-task. To show the feasibility of incorporating our belief tracker into more complex reasoning pipelines, we also obtain state-of-the-art performance on the three-tiered reasoning challenge for the recent TRIP benchmark (23-32% absolute improvement on Tasks 2-3)",
    "checked": true,
    "id": "fee5088cc8242189f298be604114e8b8e9f7ce28",
    "semantic_title": "breakpoint transformers for modeling and tracking intermediate beliefs",
    "citation_count": 6,
    "authors": [
      "Kyle Richardson",
      "Ronen Tamari",
      "Oren Sultan",
      "Dafna Shahaf",
      "Reut Tsarfaty",
      "Ashish Sabharwal"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.659": {
    "title": "Late Fusion with Triplet Margin Objective for Multimodal Ideology Prediction and Analysis",
    "volume": "main",
    "abstract": "Prior work on ideology prediction has largely focused on single modalities, i.e., text or images. In this work, we introduce the task of multimodal ideology prediction, where a model predicts binary or five-point scale ideological leanings, given a text-image pair with political content. We first collect five new large-scale datasets with English documents and images along with their ideological leanings, covering news articles from a wide range of mainstream media in US and social media posts from Reddit and Twitter. We conduct in-depth analyses on news articles and reveal differences in image content and usage across the political spectrum. Furthermore, we perform extensive experiments and ablation studies, demonstrating the effectiveness of targeted pretraining objectives on different model components. Our best-performing model, a late-fusion architecture pretrained with a triplet objective over multimodal content, outperforms the state-of-the-art text-only model by almost 4% and a strong multimodal baseline with no pretraining by over 3%",
    "checked": true,
    "id": "9272a06ea006171f34d29d46319230438fd531a7",
    "semantic_title": "late fusion with triplet margin objective for multimodal ideology prediction and analysis",
    "citation_count": 0,
    "authors": [
      "Changyuan Qiu",
      "Winston Wu",
      "Xinliang Frederick Zhang",
      "Lu Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.660": {
    "title": "Leveraging QA Datasets to Improve Generative Data Augmentation",
    "volume": "main",
    "abstract": "The ability of generative language models (GLMs) to generate text has improved considerably in the last few years, enabling their use for generative data augmentation. In this work, we propose CONDA, an approach to further improve GLM's ability to generate synthetic data by reformulating data generation as context generation for a given question-answer (QA) pair and leveraging QA datasets for training context generators. Then, we cast downstream tasks into the same question answering format and adapt the fine-tuned context generators to the target task domain. Finally, we use the fine-tuned GLM to generate relevant contexts, which are in turn used as synthetic training data for their corresponding tasks. We perform extensive experiments on multiple classification datasets and demonstrate substantial improvements in performance for both few- and zero-shot settings. Our analysis reveals that QA datasets that require high-level reasoning abilities (e.g., abstractive and common-sense QA datasets) tend to give the best boost in performance in both few-shot and zero-shot settings",
    "checked": true,
    "id": "889045714af6c2e9c187dd5347f1b308447edcc9",
    "semantic_title": "leveraging qa datasets to improve generative data augmentation",
    "citation_count": 8,
    "authors": [
      "Dheeraj Mekala",
      "Tu Vu",
      "Timo Schick",
      "Jingbo Shang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.661": {
    "title": "Meta-Learning Fast Weight Language Models",
    "volume": "main",
    "abstract": "Dynamic evaluation of language models (LMs) adapts model parameters at test time using gradient information from previous tokens and substantially improves LM performance. However, it requires over 3x more compute than standard inference. We present Fast Weight Layers (FWLs), a neural component that provides the benefits of dynamic evaluation much more efficiently by expressing gradient updates as linear attention. A key improvement over dynamic evaluation is that FWLs can also be applied at training time, so the model learns to make good use of gradient updates. FWLs can easily be added on top of existing transformer models, require relatively little extra compute or memory to run, and significantly improve language modeling perplexity",
    "checked": true,
    "id": "37ba9c33025fb31f25436010e12c65a0bafc0e1f",
    "semantic_title": "meta-learning fast weight language models",
    "citation_count": 6,
    "authors": [
      "Kevin Clark",
      "Kelvin Guu",
      "Ming-Wei Chang",
      "Panupong Pasupat",
      "Geoffrey Hinton",
      "Mohammad Norouzi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.662": {
    "title": "CTL++: Evaluating Generalization on Never-Seen Compositional Patterns of Known Functions, and Compatibility of Neural Representations",
    "volume": "main",
    "abstract": "Well-designed diagnostic tasks have played a key role in studying the failure of neural nets (NNs) to generalize systematically. Famous examples include SCAN and Compositional Table Lookup (CTL). Here we introduce CTL++, a new diagnostic dataset based on compositions of unary symbolic functions. While the original CTL is used to test length generalization or productivity, CTL++ is designed to test systematicity of NNs, that is, their capability to generalize to unseen compositions of known functions. CTL++ splits functions into groups and tests performance on group elements composed in a way not seen during training. We show that recent CTL-solving Transformer variants fail on CTL++. The simplicity of the task design allows for fine-grained control of task difficulty, as well as many insightful analyses. For example, we measure how much overlap between groups is needed by tested NNs for learning to compose. We also visualize how learned symbol representations in outputs of functions from different groups are compatible in case of success but not in case of failure. These results provide insights into failure cases reported on more complex compositions in the natural language domain. Our code is public",
    "checked": true,
    "id": "b1f33e956e36bf25e118c0d537dcc519cfe52e60",
    "semantic_title": "ctl++: evaluating generalization on never-seen compositional patterns of known functions, and compatibility of neural representations",
    "citation_count": 6,
    "authors": [
      "Róbert Csordás",
      "Kazuki Irie",
      "Juergen Schmidhuber"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.663": {
    "title": "Learning with Rejection for Abstractive Text Summarization",
    "volume": "main",
    "abstract": "State-of-the-art abstractive summarization systems frequently hallucinate content that is not supported by the source document, mainly due to noise in the training dataset. Existing methods opt to drop the noisy samples or tokens from the training set entirely, reducing the effective training set size and creating an artificial propensity to copy words from the source. In this work, we propose a training objective for abstractive summarization based on rejection learning, in which the model learns whether or not to reject potentially noisy tokens. We further propose a regularized decoding objective that penalizes non-factual candidate summaries during inference by using the rejection probability learned during training. We show that our method considerably improves the factuality of generated summaries in automatic and human evaluations when compared to five baseline models, and that it does so while increasing the abstractiveness of the generated summaries",
    "checked": true,
    "id": "b680558fdb76ba37c7337ce5fe3c929a7e23a677",
    "semantic_title": "learning with rejection for abstractive text summarization",
    "citation_count": 5,
    "authors": [
      "Meng Cao",
      "Yue Dong",
      "Jingyi He",
      "Jackie Chi Kit Cheung"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.664": {
    "title": "Adaptive Label Smoothing with Self-Knowledge in Natural Language Generation",
    "volume": "main",
    "abstract": "Overconfidence has been shown to impair generalization and calibration of a neural network. Previous studies remedy this issue by adding a regularization term to a loss function, preventing a model from making a peaked distribution. Label smoothing smoothes target labels with a pre-defined prior label distribution; as a result, a model is learned to maximize the likelihood of predicting the soft label. Nonetheless, the amount of smoothing is the same in all samples and remains fixed in training. In other words, label smoothing does not reflect the change in probability distribution mapped by a model over the course of training. To address this issue, we propose a regularization scheme that brings dynamic nature into the smoothing parameter by taking model probability distribution into account, thereby varying the parameter per instance. A model in training self-regulates the extent of smoothing on the fly during forward propagation. Furthermore, inspired by recent work in bridging label smoothing and knowledge distillation, our work utilizes self-knowledge as a prior label distribution in softening target labels, and presents theoretical support for the regularization effect by knowledge distillation and the dynamic smoothing parameter. Our regularizer is validated comprehensively, and the result illustrates marked improvements in model generalization and calibration, enhancing robustness and trustworthiness of a model",
    "checked": true,
    "id": "40b0d9e116c46bd8d6813712f013c54c2790c17c",
    "semantic_title": "adaptive label smoothing with self-knowledge in natural language generation",
    "citation_count": 3,
    "authors": [
      "Dongkyu Lee",
      "Ka Chun Cheung",
      "Nevin Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.665": {
    "title": "Hard Gate Knowledge Distillation - Leverage Calibration for Robust and Reliable Language Model",
    "volume": "main",
    "abstract": "In knowledge distillation, a student model is trained with supervisions from both knowledge from a teacher and observations drawn from a training data distribution. Knowledge of a teacher is considered a subject that holds inter-class relations which send a meaningful supervision to a student; hence, much effort has been put to find such knowledge to be distilled. In this paper, we explore a question that has been given little attention: \"when to distill such knowledge.\" The question is answered in our work with the concept of model calibration; we view a teacher model not only as a source of knowledge but also as a gauge to detect miscalibration of a student. This simple and yet novel view leads to a hard gate knowledge distillation scheme that switches between learning from a teacher model and training data. We verify the gating mechanism in the context of natural language generation at both the token-level and the sentence-level. Empirical comparisons with strong baselines show that hard gate knowledge distillation not only improves model generalization, but also significantly lowers model calibration error",
    "checked": true,
    "id": "0514444cd3564a7d7a561c4e5851c854000adb9f",
    "semantic_title": "hard gate knowledge distillation - leverage calibration for robust and reliable language model",
    "citation_count": 1,
    "authors": [
      "Dongkyu Lee",
      "Zhiliang Tian",
      "Yingxiu Zhao",
      "Ka Chun Cheung",
      "Nevin Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.666": {
    "title": "Are All Spurious Features in Natural Language Alike? An Analysis through a Causal Lens",
    "volume": "main",
    "abstract": "The term ‘spurious correlations' has been used in NLP to informally denote any undesirable feature-label correlations. However, a correlation can be undesirable because (i) the feature is irrelevant to the label (e.g. punctuation in a review), or (ii) the feature's effect on the label depends on the context (e.g. negation words in a review), which is ubiquitous in language tasks. In case (i), we want the model to be invariant to the feature, which is neither necessary nor sufficient for prediction. But in case (ii), even an ideal model (e.g. humans) must rely on the feature, since it is necessary (but not sufficient) for prediction. Therefore, a more fine-grained treatment of spurious features is needed to specify the desired model behavior. We formalize this distinction using a causal model and probabilities of necessity and sufficiency, which delineates the causal relations between a feature and a label. We then show that this distinction helps explain results of existing debiasing methods on different spurious features, and demystifies surprising results such as the encoding of spurious features in model representations after debiasing",
    "checked": true,
    "id": "b135144dd8853b7c515f15da1ce943a5be789c1e",
    "semantic_title": "are all spurious features in natural language alike? an analysis through a causal lens",
    "citation_count": 19,
    "authors": [
      "Nitish Joshi",
      "Xiang Pan",
      "He He"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.667": {
    "title": "Correcting Diverse Factual Errors in Abstractive Summarization via Post-Editing and Language Model Infilling",
    "volume": "main",
    "abstract": "Abstractive summarization models often generate inconsistent summaries containing factual errors or hallucinated content. Recent works focus on correcting factual errors in generated summaries via post-editing. Such correction models are trained using adversarial non-factual summaries constructed using heuristic rules for injecting errors. However, generating non-factual summaries using heuristics often does not generalize well to actual model errors. In this work, we propose to generate hard, representative synthetic examples of non-factual summaries through infilling language models. With this data, we train a more robust fact-correction model to post-edit the summaries to improve factual consistency. Through quantitative and qualitative experiments on two popular summarization datasets— CNN/DM and XSum—we show that our approach vastly outperforms prior methods in correcting erroneous summaries. Our model—FactEdit—improves factuality scores by over ~11 points on CNN/DM and over ~31 points on XSum on average across multiple summarization models, producing more factual summaries while maintaining competitive summarization quality",
    "checked": true,
    "id": "3e9b4218f6b943de8e57fe70f903911db11d24b6",
    "semantic_title": "correcting diverse factual errors in abstractive summarization via post-editing and language model infilling",
    "citation_count": 28,
    "authors": [
      "Vidhisha Balachandran",
      "Hannaneh Hajishirzi",
      "William Cohen",
      "Yulia Tsvetkov"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.668": {
    "title": "Coordinated Topic Modeling",
    "volume": "main",
    "abstract": "We propose a new problem called coordinated topic modeling that imitates human behavior while describing a text corpus. It considers a set of well-defined topics like the axes of a semantic space with a reference representation. It then uses the axes to model a corpus for easily understandable representation. This new task helps represent a corpus more interpretably by reusing existing knowledge and benefits the corpora comparison task. We design ECTM, an embedding-based coordinated topic model that effectively uses the reference representation to capture the target corpus-specific aspects while maintaining each topic's global semantics. In ECTM, we introduce the topic- and document-level supervision with a self-training mechanism to solve the problem. Finally, extensive experiments on multiple domains show the superiority of our model over other baselines",
    "checked": true,
    "id": "675fed9e9aa7a170ba2595acd5ac64bdbf12d315",
    "semantic_title": "coordinated topic modeling",
    "citation_count": 1,
    "authors": [
      "Pritom Saha Akash",
      "Jie Huang",
      "Kevin Chen-Chuan Chang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.669": {
    "title": "Large Dual Encoders Are Generalizable Retrievers",
    "volume": "main",
    "abstract": "It has been shown that dual encoders trained on one domain often fail to generalize to other domains for retrieval tasks. One widespread belief is that the bottleneck layer of a dual encoder, where the final score is simply a dot-product between a query vector and a passage vector, is too limited compared to models with fine-grained interactions between the query and the passage. In this paper, we challenge this belief by scaling up the size of the dual encoder model while keeping the bottleneck layer as a single dot-product with a fixed size. With multi-stage training, scaling up the model size brings significant improvement on a variety of retrieval tasks, especially for out-of-domain generalization. We further analyze the impact of the bottleneck layer and demonstrate diminishing improvement when scaling up the embedding size. Experimental results show that our dual encoders, Generalizable T5-based dense Retrievers (GTR), outperform previous sparse and dense retrievers on the BEIR dataset significantly. Most surprisingly, our ablation study finds that GTR is very data efficient, as it only needs 10% of MS Marco supervised data to match the out-of-domain performance of using all supervised data",
    "checked": true,
    "id": "9f2cf7b35224aad3a8d261e4456fe2d65a5f5d3e",
    "semantic_title": "large dual encoders are generalizable retrievers",
    "citation_count": 208,
    "authors": [
      "Jianmo Ni",
      "Chen Qu",
      "Jing Lu",
      "Zhuyun Dai",
      "Gustavo Hernandez Abrego",
      "Ji Ma",
      "Vincent Zhao",
      "Yi Luan",
      "Keith Hall",
      "Ming-Wei Chang",
      "Yinfei Yang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.670": {
    "title": "CRIPP-VQA: Counterfactual Reasoning about Implicit Physical Properties via Video Question Answering",
    "volume": "main",
    "abstract": "Videos often capture objects, their visible properties, their motion, and the interactions between different objects. Objects also have physical properties such as mass, which the imaging pipeline is unable to directly capture. However, these properties can be estimated by utilizing cues from relative object motion and the dynamics introduced by collisions. In this paper, we introduce CRIPP-VQA, a new video question answering dataset for reasoning about the implicit physical properties of objects in a scene. CRIPP-VQA contains videos of objects in motion, annotated with questions that involve counterfactual reasoning about the effect of actions, questions about planning in order to reach a goal, and descriptive questions about visible properties of objects. The CRIPP-VQA test set enables evaluation under several out-of-distribution settings – videos with objects with masses, coefficients of friction, and initial velocities that are not observed in the training distribution. Our experiments reveal a surprising and significant performance gap in terms of answering questions about implicit properties (the focus of this paper) and explicit properties of objects (the focus of prior work)",
    "checked": true,
    "id": "e881cc29a647bf5f0c9edcbd710ef56e3e2b2a7a",
    "semantic_title": "cripp-vqa: counterfactual reasoning about implicit physical properties via video question answering",
    "citation_count": 4,
    "authors": [
      "Maitreya Patel",
      "Tejas Gokhale",
      "Chitta Baral",
      "Yezhou Yang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.671": {
    "title": "Entity-centered Cross-document Relation Extraction",
    "volume": "main",
    "abstract": "Relation Extraction (RE) is a fundamental task of information extraction, which has attracted a large amount of research attention. Previous studies focus on extracting the relations within a sentence or document, while currently researchers begin to explore cross-document RE. However, current cross-document RE methods directly utilize text snippets surrounding target entities in multiple given documents, which brings considerable noisy and non-relevant sentences. Moreover, they utilize all the text paths in a document bag in a coarse-grained way, without considering the connections between these text paths. In this paper, we aim to address both of these shortages and push the state-of-the-art for cross-document RE. First, we focus on input construction for our RE model and propose an entity-based document-context filter to retain useful information in the given documents by using the bridge entities in the text paths. Second, we propose a cross-document RE model based on cross-path entity relation attention, which allow the entity relations across text paths to interact with each other. We compare our cross-document RE method with the state-of-the-art methods in the dataset CodRED. Our method outperforms them by at least 10% in F1, thus demonstrating its effectiveness",
    "checked": true,
    "id": "1a86ace250747324619cce9d80a636a1ad4df553",
    "semantic_title": "entity-centered cross-document relation extraction",
    "citation_count": 14,
    "authors": [
      "Fengqi Wang",
      "Fei Li",
      "Hao Fei",
      "Jingye Li",
      "Shengqiong Wu",
      "Fangfang Su",
      "Wenxuan Shi",
      "Donghong Ji",
      "Bo Cai"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.672": {
    "title": "Exploring Document-Level Literary Machine Translation with Parallel Paragraphs from World Literature",
    "volume": "main",
    "abstract": "Literary translation is a culturally significant task, but it is bottlenecked by the small number of qualified literary translators relative to the many untranslated works published around the world. Machine translation (MT) holds potential to complement the work of human translators by improving both training procedures and their overall efficiency. Literary translation is less constrained than more traditional MT settings since translators must balance meaning equivalence, readability, and critical interpretability in the target language. This property, along with the complex discourse-level context present in literary texts, also makes literary MT more challenging to computationally model and evaluate. To explore this task, we collect a dataset (Par3) of non-English language novels in the public domain, each aligned at the paragraph level to both human and automatic English translations. Using Par3, we discover that expert literary translators prefer reference human translations over machine-translated paragraphs at a rate of 84%, while state-of-the-art automatic MT metrics do not correlate with those preferences. The experts note that MT outputs contain not only mistranslations, but also discourse-disrupting errors and stylistic inconsistencies. To address these problems, we train a post-editing model whose output is preferred over normal MT output at a rate of 69% by experts. We publicly release Par3 to spur future research into literary MT",
    "checked": true,
    "id": "671e84e7001bdc590281009e5f83072342c7d8b3",
    "semantic_title": "exploring document-level literary machine translation with parallel paragraphs from world literature",
    "citation_count": 21,
    "authors": [
      "Katherine Thai",
      "Marzena Karpinska",
      "Kalpesh Krishna",
      "Bill Ray",
      "Moira Inghilleri",
      "John Wieting",
      "Mohit Iyyer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.673": {
    "title": "Label-aware Multi-level Contrastive Learning for Cross-lingual Spoken Language Understanding",
    "volume": "main",
    "abstract": "Despite the great success of spoken language understanding (SLU) in high-resource languages, it remains challenging in low-resource languages mainly due to the lack of labeled training data. The recent multilingual code-switching approach achieves better alignments of model representations across languages by constructing a mixed-language context in zero-shot cross-lingual SLU. However, current code-switching methods are limited to implicit alignment and disregard the inherent semantic structure in SLU, i.e., the hierarchical inclusion of utterances, slots and words. In this paper, we propose to model the utterance-slot-word structure by a multi-level contrastive learning framework at the utterance, slot and word levels to facilitate explicit alignment. Novel code-switching schemes are introduced to generate hard negative examples for our contrastive learning framework. Furthermore, we develop a label-aware joint model leveraging label semantics to enhance the implicit alignment and feed to contrastive learning. Our experimental results show that our proposed methods significantly improve the performance compared with the strong baselines on two zero-shot cross-lingual SLU benchmark datasets",
    "checked": true,
    "id": "c8eb8822f70f48d025119bd2b274d1bd4f595730",
    "semantic_title": "label-aware multi-level contrastive learning for cross-lingual spoken language understanding",
    "citation_count": 6,
    "authors": [
      "Shining Liang",
      "Linjun Shou",
      "Jian Pei",
      "Ming Gong",
      "Wanli Zuo",
      "Xianglin Zuo",
      "Daxin Jiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.674": {
    "title": "Polyglot Prompt: Multilingual Multitask Prompt Training",
    "volume": "main",
    "abstract": "This paper aims for a potential architectural improvement for multilingual learning and asks: Can different tasks from different languages be modeled in a monolithic framework, i.e. without any task/language-specific module? The benefit of achieving this could open new doors for future multilingual research, including allowing systems trained on low resources to be further assisted by other languages as well as other tasks. We approach this goal by developing a learning framework named Polyglot Prompting to exploit prompting methods for learning a unified semantic space for different languages and tasks with multilingual prompt engineering. We performed a comprehensive evaluation of 6 tasks, namely topic classification, sentiment classification, named entity recognition, question answering, natural language inference, and summarization, covering 24 datasets and 49 languages. The experimental results demonstrated the efficacy of multilingual multitask prompt-based learning and led to inspiring observations. We also present an interpretable multilingual evaluation methodology and show how the proposed framework, multilingual multitask prompt training, works. We release all datasets prompted in the best setting and code",
    "checked": true,
    "id": "15437760a28d528bb1b76794aa4b1d15e7ba2a16",
    "semantic_title": "polyglot prompt: multilingual multitask prompt training",
    "citation_count": 6,
    "authors": [
      "Jinlan Fu",
      "See-Kiong Ng",
      "Pengfei Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.675": {
    "title": "VisToT: Vision-Augmented Table-to-Text Generation",
    "volume": "main",
    "abstract": "Table-to-text generation has been widely studied in the Natural Language Processing community in the recent years. We give a new perspective to this problem by incorporating signals from both tables as well as associated images to generate relevant text. While tables contain a structured list of facts, images are a rich source of unstructured visual information. For example, in the tourism domain, images can be used to infer knowledge such as the type of landmark (e.g., church), its architecture (e.g., Ancient Roman), and composition (e.g., white marble). Therefore, in this paper, we introduce the novel task of Vision-augmented Table-To-Text Generation (VisToT, defined as follows: given a table and an associated image, produce a descriptive sentence conditioned on the multimodal input. For the task, we present a novel multimodal table-to-text dataset, WikiLandmarks, covering 73,084 unique world landmarks. Further, we also present a competitive architecture, namely, VT3 that generates accurate sentences conditioned on the image and table pairs. Through extensive analyses and experiments, we show that visual cues from images are helpful in (i) inferring missing information from incomplete or sparse tables, and (ii) strengthening the importance of useful information from noisy tables for natural language generation. We make the code and data publicly available",
    "checked": true,
    "id": "72ded4257a589582adebffa6004b25998cfc734b",
    "semantic_title": "vistot: vision-augmented table-to-text generation",
    "citation_count": 1,
    "authors": [
      "Prajwal Gatti",
      "Anand Mishra",
      "Manish Gupta",
      "Mithun Das Gupta"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.676": {
    "title": "Generative Entity-to-Entity Stance Detection with Knowledge Graph Augmentation",
    "volume": "main",
    "abstract": "Stance detection is typically framed as predicting the sentiment in a given text towards a target entity. However, this setup overlooks the importance of the source entity, i.e., who is expressing the opinion. In this paper, we emphasize the imperative need for studying interactions among entities when inferring stances. We first introduce a new task, entity-to-entity (E2E) stance detection, which primes models to identify entities in their canonical names and discern stances jointly. To support this study, we curate a new dataset with 10,641 annotations labeled at the sentence level from news articles of different ideological leanings. We present a novel generative framework to allow the generation of canonical names for entities as well as stances among them. We further enhance the model with a graph encoder to summarize entity activities and external knowledge surrounding the entities. Experiments show that our model outperforms strong comparisons by large margins. Further analyses demonstrate the usefulness of E2E stance detection for understanding media quotation and stance landscape as well as inferring entity ideology",
    "checked": true,
    "id": "2f09e6722eea9be4f80b4ff6bb66469a09c2fc98",
    "semantic_title": "generative entity-to-entity stance detection with knowledge graph augmentation",
    "citation_count": 6,
    "authors": [
      "Xinliang Frederick Zhang",
      "Nick Beauchamp",
      "Lu Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.677": {
    "title": "Symptom Identification for Interpretable Detection of Multiple Mental Disorders on Social Media",
    "volume": "main",
    "abstract": "Mental disease detection (MDD) from social media has suffered from poor generalizability and interpretability, due to lack of symptom modeling. This paper introduces PsySym, the first annotated symptom identification corpus of multiple psychiatric disorders, to facilitate further research progress. PsySym is annotated according to a knowledge graph of the 38 symptom classes related to 7 mental diseases complied from established clinical manuals and scales, and a novel annotation framework for diversity and quality. Experiments show that symptom-assisted MDD enabled by PsySym can outperform strong pure-text baselines. We also exhibit the convincing MDD explanations provided by symptom predictions with case studies, and point to their further potential applications",
    "checked": true,
    "id": "3979f023b328c766c9ef3e1174a84a23619fedec",
    "semantic_title": "symptom identification for interpretable detection of multiple mental disorders on social media",
    "citation_count": 12,
    "authors": [
      "Zhiling Zhang",
      "Siyuan Chen",
      "Mengyue Wu",
      "Kenny Zhu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.678": {
    "title": "Improving Iterative Text Revision by Learning Where to Edit from Other Revision Tasks",
    "volume": "main",
    "abstract": "Iterative text revision improves text quality by fixing grammatical errors, rephrasing for better readability or contextual appropriateness, or reorganizing sentence structures throughout a document. Most recent research has focused on understanding and classifying different types of edits in the iterative revision process from human-written text instead of building accurate and robust systems for iterative text revision. In this work, we aim to build an end-to-end text revision system that can iteratively generate helpful edits by explicitly detecting editable spans (where-to-edit) with their corresponding edit intents and then instructing a revision model to revise the detected edit spans. Leveraging datasets from other related text editing NLP tasks, combined with the specification of editable spans, leads our system to more accurately model the process of iterative text refinement, as evidenced by empirical results and human evaluations. Our system significantly outperforms previous baselines on our text revision tasks and other standard text revision tasks, including grammatical error correction, text simplification, sentence fusion, and style transfer. Through extensive qualitative and quantitative analysis, we make vital connections between edit intentions and writing quality, and better computational modeling of iterative text revisions",
    "checked": true,
    "id": "3961fee54aae34f2cf18dbde6309a3bb447e382f",
    "semantic_title": "improving iterative text revision by learning where to edit from other revision tasks",
    "citation_count": 11,
    "authors": [
      "Zae Myung Kim",
      "Wanyu Du",
      "Vipul Raheja",
      "Dhruv Kumar",
      "Dongyeop Kang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.679": {
    "title": "CONQRR: Conversational Query Rewriting for Retrieval with Reinforcement Learning",
    "volume": "main",
    "abstract": "Compared to standard retrieval tasks, passage retrieval for conversational question answering (CQA) poses new challenges in understanding the current user question, as each question needs to be interpreted within the dialogue context. Moreover, it can be expensive to re-train well-established retrievers such as search engines that are originally developed for non-conversational queries. To facilitate their use, we develop a query rewriting model CONQRR that rewrites a conversational question in the context into a standalone question. It is trained with a novel reward function to directly optimize towards retrieval using reinforcement learning and can be adapted to any off-the-shelf retriever. CONQRR achieves state-of-the-art results on a recent open-domain CQA dataset containing conversations from three different sources, and is effective for two different off-the-shelf retrievers. Our extensive analysis also shows the robustness of CONQRR to out-of-domain dialogues as well as to zero query rewriting supervision",
    "checked": true,
    "id": "946d51acd20d9acc649d0238628261b093ec572b",
    "semantic_title": "conqrr: conversational query rewriting for retrieval with reinforcement learning",
    "citation_count": 41,
    "authors": [
      "Zeqiu Wu",
      "Yi Luan",
      "Hannah Rashkin",
      "David Reitter",
      "Hannaneh Hajishirzi",
      "Mari Ostendorf",
      "Gaurav Singh Tomar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.680": {
    "title": "Specializing Multi-domain NMT via Penalizing Low Mutual Information",
    "volume": "main",
    "abstract": "Multi-domain Neural Machine Translation (NMT) trains a single model with multiple domains. It is appealing because of its efficacy in handling multiple domains within one model. An ideal multi-domain NMT learns distinctive domain characteristics simultaneously, however, grasping the domain peculiarity is a non-trivial task. In this paper, we investigate domain-specific information through the lens of mutual information (MI) and propose a new objective that penalizes low MI to become higher. Our method achieved the state-of-the-art performance among the current competitive multi-domain NMT models. Also, we show our objective promotes low MI to be higher resulting in domain-specialized multi-domain NMT",
    "checked": true,
    "id": "a3949033c9bc075d34e5c9aa9c7a49f763b295b0",
    "semantic_title": "specializing multi-domain nmt via penalizing low mutual information",
    "citation_count": 2,
    "authors": [
      "Jiyoung Lee",
      "Hantae Kim",
      "Hyunchang Cho",
      "Edward Choi",
      "Cheonbok Park"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.681": {
    "title": "A Simple Contrastive Learning Framework for Interactive Argument Pair Identification via Argument-Context Extraction",
    "volume": "main",
    "abstract": "Interactive argument pair identification is an emerging research task for argument mining, aiming to identify whether two arguments are interactively related. It is pointed out that the context of the argument is essential to improve identification performance. However, current context-based methods achieve limited improvements since the entire context typically contains much irrelevant information. In this paper, we propose a simple contrastive learning framework to solve this problem by extracting valuable information from the context. This framework can construct hard argument-context samples and obtain a robust and uniform representation by introducing contrastive learning. We also propose an argument-context extraction module to enhance information extraction by discarding irrelevant blocks. The experimental results show that our method achieves the state-of-the-art performance on the benchmark dataset. Further analysis demonstrates the effectiveness of our proposed modules and visually displays more compact semantic representations",
    "checked": true,
    "id": "cbc8c5237e97949df9a5f87fef9318edea60a339",
    "semantic_title": "a simple contrastive learning framework for interactive argument pair identification via argument-context extraction",
    "citation_count": 1,
    "authors": [
      "Lida Shi",
      "Fausto Giunchiglia",
      "Rui Song",
      "Daqian Shi",
      "Tongtong Liu",
      "Xiaolei Diao",
      "Hao Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.682": {
    "title": "Sentence-level Media Bias Analysis Informed by Discourse Structures",
    "volume": "main",
    "abstract": "As polarization continues to rise among both the public and the news media, increasing attention has been devoted to detecting media bias. Most recent work in the NLP community, however, identify bias at the level of individual articles. However, each article itself comprises multiple sentences, which vary in their ideological bias. In this paper, we aim to identify sentences within an article that can illuminate and explain the overall bias of the entire article. We show that understanding the discourse role of a sentence in telling a news story, as well as its relation with nearby sentences, can reveal the ideological leanings of an author even when the sentence itself appears merely neutral. In particular, we consider using a functional news discourse structure and PDTB discourse relations to inform bias sentence identification, and distill the auxiliary knowledge from the two types of discourse structure into our bias sentence identification system. Experimental results on benchmark datasets show that incorporating both the global functional discourse structure and local rhetorical discourse relations can effectively increase the recall of bias sentence identification by 8.27% - 8.62%, as well as increase the precision by 2.82% - 3.48%",
    "checked": true,
    "id": "d9cbe86b3f4d22a682b6859f62c9d4daac4b0b64",
    "semantic_title": "sentence-level media bias analysis informed by discourse structures",
    "citation_count": 24,
    "authors": [
      "Yuanyuan Lei",
      "Ruihong Huang",
      "Lu Wang",
      "Nick Beauchamp"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.683": {
    "title": "Towards Efficient Dialogue Pre-training with Transferable and Interpretable Latent Structure",
    "volume": "main",
    "abstract": "With the availability of massive general-domain dialogue data, pre-trained dialogue generation appears to be super appealing to transfer knowledge from the general domain to downstream applications. In most existing work, such transferable ability is mainly obtained by fitting a large model with hundreds of millions of parameters on massive data in an exhaustive way, leading to inefficient running and poor interpretability. This paper proposes a novel dialogue generation model with a latent structure that is easily transferable from the general domain to downstream tasks in a lightweight and transparent way. Experiments on two benchmarks validate the effectiveness of the proposed model. Thanks to the transferable latent structure, our model is able to yield better dialogue responses than four strong baselines in terms of both automatic and human evaluations, and our model with about 22% parameters particularly delivers a 5x speedup in running time compared with the strongest baseline. Moreover, the proposed model is explainable by interpreting the discrete latent variables",
    "checked": true,
    "id": "e13c88ebe339573f01251e68a8e5def84b6651a8",
    "semantic_title": "towards efficient dialogue pre-training with transferable and interpretable latent structure",
    "citation_count": 3,
    "authors": [
      "Xueliang Zhao",
      "Lemao Liu",
      "Tingchen Fu",
      "Shuming Shi",
      "Dongyan Zhao",
      "Rui Yan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.684": {
    "title": "An Empirical Revisiting of Linguistic Knowledge Fusion in Language Understanding Tasks",
    "volume": "main",
    "abstract": "Though linguistic knowledge emerges during large-scale language model pretraining, recent work attempt to explicitly incorporate human-defined linguistic priors into task-specific fine-tuning. Infusing language models with syntactic or semantic knowledge from parsers has shown improvements on many language understanding tasks. To further investigate the effectiveness of structural linguistic priors, we conduct empirical study of replacing parsed graphs or trees with trivial ones (rarely carrying linguistic knowledge e.g., balanced tree) for tasks in the GLUE benchmark. Encoding with trivial graphs achieves competitive or even better performance in fully-supervised and few-shot settings. It reveals that the gains might not be significantly attributed to explicit linguistic priors but rather to more feature interactions brought by fusion layers. Hence we call for attention to using trivial graphs as necessary baselines to design advanced knowledge fusion methods in the future",
    "checked": true,
    "id": "511e69bfa4213442e0afa35d7bbc503aa5d93405",
    "semantic_title": "an empirical revisiting of linguistic knowledge fusion in language understanding tasks",
    "citation_count": 1,
    "authors": [
      "Changlong Yu",
      "Tianyi Xiao",
      "Lingpeng Kong",
      "Yangqiu Song",
      "Wilfred Ng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.685": {
    "title": "Unsupervised Non-transferable Text Classification",
    "volume": "main",
    "abstract": "Training a good deep learning model requires substantial data and computing resources, which makes the resulting neural model a valuable intellectual property. To prevent the neural network from being undesirably exploited, non-transferable learning has been proposed to reduce the model generalization ability in specific target domains. However, existing approaches require labeled data for the target domain which can be difficult to obtain. Furthermore, they do not have the mechanism to still recover the model's ability to access the target domain. In this paper, we propose a novel unsupervised non-transferable learning method for the text classification task that does not require annotated target domain data. We further introduce a secret key component in our approach for recovering the access to the target domain, where we design both an explicit and an implicit method for doing so. Extensive experiments demonstrate the effectiveness of our approach",
    "checked": true,
    "id": "50166380a8bbd7dbee795f5dee897ecc420084e8",
    "semantic_title": "unsupervised non-transferable text classification",
    "citation_count": 1,
    "authors": [
      "Guangtao Zeng",
      "Wei Lu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.686": {
    "title": "Adaptive Contrastive Learning on Multimodal Transformer for Review Helpfulness Prediction",
    "volume": "main",
    "abstract": "Modern Review Helpfulness Prediction systems are dependent upon multiple modalities, typically texts and images. Unfortunately, those contemporary approaches pay scarce attention to polish representations of cross-modal relations and tend to suffer from inferior optimization. This might cause harm to model's predictions in numerous cases. To overcome the aforementioned issues, we propose Multi-modal Contrastive Learning for Multimodal Review Helpfulness Prediction (MRHP) problem, concentrating on mutual information between input modalities to explicitly elaborate cross-modal relations. In addition, we introduce Adaptive Weighting scheme for our contrastive learning approach in order to increase flexibility in optimization. Lastly, we propose Multimodal Interaction module to address the unalignment nature of multimodal data, thereby assisting the model in producing more reasonable multimodal representations. Experimental results show that our method outperforms prior baselines and achieves state-of-the-art results on two publicly available benchmark datasets for MRHP problem",
    "checked": true,
    "id": "c28d44774cca23cbaf9e9fcb8fb76e13c09260d9",
    "semantic_title": "adaptive contrastive learning on multimodal transformer for review helpfulness prediction",
    "citation_count": 6,
    "authors": [
      "Thong Nguyen",
      "Xiaobao Wu",
      "Anh Tuan Luu",
      "Zhen Hai",
      "Lidong Bing"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.687": {
    "title": "Adaptive Token-level Cross-lingual Feature Mixing for Multilingual Neural Machine Translation",
    "volume": "main",
    "abstract": "Multilingual neural machine translation aims to translate multiple language pairs in a single model and has shown great success thanks to the knowledge transfer across languages with the shared parameters. Despite promising, this share-all paradigm suffers from insufficient ability to capture language-specific features. Currently, the common practice is to insert or search language-specific networks to balance the shared and specific features. However, those two types of features are not sufficient enough to model the complex commonality and divergence across languages, such as the locally shared features among similar languages, which leads to sub-optimal transfer, especially in massively multilingual translation. In this paper, we propose a novel token-level feature mixing method that enables the model to capture different features and dynamically determine the feature sharing across languages. Based on the observation that the tokens in the multilingual model are usually shared by different languages, we we insert a feature mixing layer into each Transformer sublayer and model each token representation as a mix of different features, with a proportion indicating its feature preference. In this way, we can perform fine-grained feature sharing and achieve better multilingual transfer. Experimental results on multilingual datasets show that our method outperforms various strong baselines and can be extended to zero-shot translation. Further analyses reveal that our method can capture different linguistic features and bridge the representation gap across languages",
    "checked": true,
    "id": "5655abc98aebd36855f23111b82e3ddd098b3890",
    "semantic_title": "adaptive token-level cross-lingual feature mixing for multilingual neural machine translation",
    "citation_count": 2,
    "authors": [
      "Junpeng Liu",
      "Kaiyu Huang",
      "Jiuyi Li",
      "Huan Liu",
      "Jinsong Su",
      "Degen Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.688": {
    "title": "A Dataset for Hyper-Relational Extraction and a Cube-Filling Approach",
    "volume": "main",
    "abstract": "Relation extraction has the potential for large-scale knowledge graph construction, but current methods do not consider the qualifier attributes for each relation triplet, such as time, quantity or location. The qualifiers form hyper-relational facts which better capture the rich and complex knowledge graph structure. For example, the relation triplet (Leonard Parker, Educated At, Harvard University) can be factually enriched by including the qualifier (End Time, 1967). Hence, we propose the task of hyper-relational extraction to extract more specific and complete facts from text. To support the task, we construct HyperRED, a large-scale and general-purpose dataset. Existing models cannot perform hyper-relational extraction as it requires a model to consider the interaction between three entities. Hence, we propose CubeRE, a cube-filling model inspired by table-filling approaches and explicitly considers the interaction between relation triplets and qualifiers. To improve model scalability and reduce negative class imbalance, we further propose a cube-pruning method. Our experiments show that CubeRE outperforms strong baselines and reveal possible directions for future research. Our code and data are available at github.com/declare-lab/HyperRED",
    "checked": true,
    "id": "637337f4a84156ea9eee0ca69a4604e5aa43afee",
    "semantic_title": "a dataset for hyper-relational extraction and a cube-filling approach",
    "citation_count": 7,
    "authors": [
      "Yew Ken Chia",
      "Lidong Bing",
      "Sharifah Mahani Aljunied",
      "Luo Si",
      "Soujanya Poria"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.689": {
    "title": "Low-resource Neural Machine Translation with Cross-modal Alignment",
    "volume": "main",
    "abstract": "How to achieve neural machine translation with limited parallel data? Existing techniques often rely on large-scale monolingual corpus, which is impractical for some low-resource languages. In this paper, we turn to connect several low-resource languages to a particular high-resource one by additional visual modality. Specifically, we propose a cross-modal contrastive learning method to learn a shared space for all languages, where both a coarse-grained sentence-level objective and a fine-grained token-level one are introduced. Experimental results and further analysis show that our method can effectively learn the cross-modal and cross-lingual alignment with a small amount of image-text pairs, and achieves significant improvements over the text-only baseline under both zero-shot and few-shot scenarios",
    "checked": true,
    "id": "2108f664b992e8f3be4ad376f172aca29b33e31e",
    "semantic_title": "low-resource neural machine translation with cross-modal alignment",
    "citation_count": 6,
    "authors": [
      "Zhe Yang",
      "Qingkai Fang",
      "Yang Feng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.690": {
    "title": "Prompt-based Distribution Alignment for Domain Generalization in Text Classification",
    "volume": "main",
    "abstract": "Prompt-based learning (a.k.a. prompting) achieves high performance by bridging the gap between the objectives of language modeling and downstream tasks. Domain generalization ability can be improved by prompting since classification across different domains can be unified into the prediction of the same set of label words. The remaining challenge for domain generalization by prompting comes from discrepancies between the data distribution of different domains. To improve domain generalization with prompting, we learn distributional invariance across source domains via two alignment regularization loss functions. The first is vocabulary distribution alignment, which uses a Kullback-Leibler divergence regularization on source-domain vocabulary distributions. The second is feature distribution alignment, which uses a novel adversarial training strategy to learn domain invariant representation across source domains. Experiments on sentiment analysis and natural language inference show the effectiveness of our method and achieve state-of-the-art results on six datasets",
    "checked": true,
    "id": "d361b7aafcb9ff71304aba8eb415a13085d38d0b",
    "semantic_title": "prompt-based distribution alignment for domain generalization in text classification",
    "citation_count": 6,
    "authors": [
      "Chen Jia",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.691": {
    "title": "Two is Better than Many? Binary Classification as an Effective Approach to Multi-Choice Question Answering",
    "volume": "main",
    "abstract": "We propose a simple refactoring of multi-choice question answering (MCQA) tasks as a series of binary classifications. The MCQA task is generally performed by scoring each (question, answer) pair normalized over all the pairs, and then selecting the answer from the pair that yield the highest score. For n answer choices, this is equivalent to an n-class classification setup where only one class (true answer) is correct. We instead show that classifying (question, true answer) as positive instances and (question, false answer) as negative instances is significantly more effective across various models and datasets. We show the efficacy of our proposed approach in different tasks – abductive reasoning, commonsense question answering, science question answering, and sentence completion. Our DeBERTa binary classification model reaches the top or close to the top performance on public leaderboards for these tasks. The source code of the proposed approach is available at https://github.com/declare-lab/TEAM",
    "checked": true,
    "id": "40e3cd767c9520171ac8ecbd2e27f3a1bf043b61",
    "semantic_title": "two is better than many? binary classification as an effective approach to multi-choice question answering",
    "citation_count": 5,
    "authors": [
      "Deepanway Ghosal",
      "Navonil Majumder",
      "Rada Mihalcea",
      "Soujanya Poria"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.692": {
    "title": "HEGEL: Hypergraph Transformer for Long Document Summarization",
    "volume": "main",
    "abstract": "Extractive summarization for long documents is challenging due to the extended structured input context. The long-distance sentence dependency hinders cross-sentence relations modeling, the critical step of extractive summarization. This paper proposes HEGEL, a hypergraph neural network for long document summarization by capturing high-order cross-sentence relations. HEGEL updates and learns effective sentence representations with hypergraph transformer layers and fuses different types of sentence dependencies, including latent topics, keywords coreference, and section structure. We validate HEGEL by conducting extensive experiments on two benchmark datasets, and experimental results demonstrate the effectiveness and efficiency of HEGEL",
    "checked": true,
    "id": "1df0d9c553aee087fe3a7dd1c5f9e03556eb1fe4",
    "semantic_title": "hegel: hypergraph transformer for long document summarization",
    "citation_count": 19,
    "authors": [
      "Haopeng Zhang",
      "Xiao Liu",
      "Jiawei Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.693": {
    "title": "Adapting a Language Model While Preserving its General Knowledge",
    "volume": "main",
    "abstract": "Domain-adaptive pre-training (or DA-training for short), also known as post-training, aimsto train a pre-trained general-purpose language model (LM) using an unlabeled corpus of aparticular domain to adapt the LM so that end-tasks in the domain can give improved performances. However, existing DA-training methods are in some sense blind as they do not explicitly identify what knowledge in the LM should be preserved and what should be changed by the domain corpus. This paper shows that the existing methods are suboptimal and proposes a novel method to perform a more informed adaptation of the knowledge in the LM by (1) soft-masking the attention heads based on their importance to best preserve the general knowledge in the LM and (2) contrasting the representations of the general and the full (both general and domain knowledge) to learn an integrated representation with both general and domain-specific knowledge. Experimental results will demonstrate the effectiveness of the proposed approach",
    "checked": true,
    "id": "e3f839b01567ae73af822a3da5e160dac2fb4708",
    "semantic_title": "adapting a language model while preserving its general knowledge",
    "citation_count": 12,
    "authors": [
      "Zixuan Ke",
      "Yijia Shao",
      "Haowei Lin",
      "Hu Xu",
      "Lei Shu",
      "Bing Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.694": {
    "title": "Human Guided Exploitation of Interpretable Attention Patterns in Summarization and Topic Segmentation",
    "volume": "main",
    "abstract": "The multi-head self-attention mechanism of the transformer model has been thoroughly investigated recently. In one vein of study, researchers are interested in understanding why and how transformers work. In another vein, researchers propose new attention augmentation methods to make transformers more accurate, efficient and interpretable. In this paper, we combine these two lines of research in a human-in-the-loop pipeline to first discover important task-specific attention patterns. Then those patterns are injected, not only to smaller models, but also to the original model. The benefits of our pipeline and discovered patterns are demonstrated in two case studies with extractive summarization and topic segmentation. After discovering interpretable patterns in BERT-based models fine-tuned for the two downstream tasks, experiments indicate that when we inject the patterns into attention heads, the models show considerable improvements in accuracy and efficiency",
    "checked": true,
    "id": "571469045c49877f78a4522f7f21e8c30e2f5c89",
    "semantic_title": "human guided exploitation of interpretable attention patterns in summarization and topic segmentation",
    "citation_count": 4,
    "authors": [
      "Raymond Li",
      "Wen Xiao",
      "Linzi Xing",
      "Lanjun Wang",
      "Gabriel Murray",
      "Giuseppe Carenini"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.695": {
    "title": "Continual Training of Language Models for Few-Shot Learning",
    "volume": "main",
    "abstract": "Recent work on applying large language models (LMs) achieves impressive performance in many NLP applications. Adapting or posttraining an LM using an unlabeled domain corpus can produce even better performance for end-tasks in the domain. This paper proposes the problem of continually extending an LM by incrementally post-train the LM with a sequence of unlabeled domain corpora to expand its knowledge without forgetting its previous skills. The goal is to improve the few-shot end-task learning in these domains. The resulting system is called CPT (Continual PostTraining), which to our knowledge, is the first continual post-training system. Experimental results verify its effectiveness",
    "checked": true,
    "id": "e053be7f36a0772b68eaaa14f15650c14071e4ab",
    "semantic_title": "continual training of language models for few-shot learning",
    "citation_count": 20,
    "authors": [
      "Zixuan Ke",
      "Haowei Lin",
      "Yijia Shao",
      "Hu Xu",
      "Lei Shu",
      "Bing Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.696": {
    "title": "Dictionary-Assisted Supervised Contrastive Learning",
    "volume": "main",
    "abstract": "Text analysis in the social sciences often involves using specialized dictionaries to reason with abstract concepts, such as perceptions about the economy or abuse on social media. These dictionaries allow researchers to impart domain knowledge and note subtle usages of words relating to a concept(s) of interest. We introduce the dictionary-assisted supervised contrastive learning (DASCL) objective, allowing researchers to leverage specialized dictionaries when fine-tuning pretrained language models. The text is first keyword simplified: a common, fixed token replaces any word in the corpus that appears in the dictionary(ies) relevant to the concept of interest. During fine-tuning, a supervised contrastive objective draws closer the embeddings of the original and keyword-simplified texts of the same class while pushing further apart the embeddings of different classes. The keyword-simplified texts of the same class are more textually similar than their original text counterparts, which additionally draws the embeddings of the same class closer together. Combining DASCL and cross-entropy improves classification performance metrics in few-shot learning settings and social science applications compared to using cross-entropy alone and alternative contrastive and data augmentation methods",
    "checked": true,
    "id": "441c3a6e37d0b8dda0b00effda7552f3bc71d92a",
    "semantic_title": "dictionary-assisted supervised contrastive learning",
    "citation_count": 0,
    "authors": [
      "Patrick Wu",
      "Richard Bonneau",
      "Joshua Tucker",
      "Jonathan Nagler"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.697": {
    "title": "Fine-Tuning Pre-trained Transformers into Decaying Fast Weights",
    "volume": "main",
    "abstract": "Autoregressive Transformers are strong language models but incur O(T) complexity during per-token generation due to the self-attention mechanism. Recent work proposes kernel-based methods to approximate causal self-attention by replacing it with recurrent formulations with various update rules and feature maps to achieve O(1) time and memory complexity. We explore these approaches and find that they are unnecessarily complex, and propose a simple alternative - decaying fast weights - that runs fast on GPU, outperforms prior methods, and retains 99% of attention's performance for GPT-2. We also show competitive performance on WikiText-103 against more complex attention substitutes",
    "checked": true,
    "id": "f6d8beb02771791d628f7e0773d8906261ce707c",
    "semantic_title": "fine-tuning pre-trained transformers into decaying fast weights",
    "citation_count": 3,
    "authors": [
      "Huanru Henry Mao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.698": {
    "title": "PRO-CS : An Instance-Based Prompt Composition Technique for Code-Switched Tasks",
    "volume": "main",
    "abstract": "Code-switched (CS) data is ubiquitous in today's globalized world, but the dearth of annotated datasets in code-switching poses a significant challenge for learning diverse tasks across different language pairs. Parameter-efficient prompt-tuning approaches conditioned on frozen language models have shown promise for transfer learning in limited-resource setups. In this paper, we propose a novel instance-based prompt composition technique, PRO-CS, for CS tasks that combine language and task knowledge. We compare our approach with prompt-tuning and fine-tuning for code-switched tasks on 10 datasets across 4 language pairs. Our model outperforms the prompt-tuning approach by significant margins across all datasets and outperforms or remains at par with fine-tuning by using just 0.18% of total parameters. We also achieve competitive results when compared with the fine-tuned model in the low-resource cross-lingual and cross-task setting, indicating the effectiveness of our approach to incorporate new code-switched tasks",
    "checked": true,
    "id": "413bfdd01291d3bc013cdc9cb91066a3c8a1d0e0",
    "semantic_title": "pro-cs : an instance-based prompt composition technique for code-switched tasks",
    "citation_count": 0,
    "authors": [
      "Srijan Bansal",
      "Suraj Tripathi",
      "Sumit Agarwal",
      "Teruko Mitamura",
      "Eric Nyberg"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.699": {
    "title": "SentBS: Sentence-level Beam Search for Controllable Summarization",
    "volume": "main",
    "abstract": "A wide range of control perspectives have been explored in controllable text generation. Structure-controlled summarization is recently proposed as a useful and interesting research direction. However, current structure-controlling methods have limited effectiveness in enforcing the desired structure. To address this limitation, we propose a sentence-level beam search generation method (SentBS), where evaluation is conducted throughout the generation process to select suitable sentences for subsequent generations. We experiment with different combinations of decoding methods to be used as sub-components by SentBS and evaluate results on the structure-controlled dataset MReD. Experiments show that all explored combinations for SentBS can improve the agreement between the generated text and the desired structure, with the best method significantly reducing the structural discrepancies suffered by the existing model, by approximately 68%",
    "checked": true,
    "id": "d04677ae74143a793a3946b6a80576c4653e2e53",
    "semantic_title": "sentbs: sentence-level beam search for controllable summarization",
    "citation_count": 9,
    "authors": [
      "Chenhui Shen",
      "Liying Cheng",
      "Lidong Bing",
      "Yang You",
      "Luo Si"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.700": {
    "title": "A Fine-grained Chinese Software Privacy Policy Dataset for Sequence Labeling and Regulation Compliant Identification",
    "volume": "main",
    "abstract": "Privacy protection raises great attention on both legal levels and user awareness. To protect user privacy, countries enact laws and regulations requiring software privacy policies to regulate their behavior. However, privacy policies are written in professional languages with many legal terms and software jargon that prevent users from understanding and even reading them. It is necessary and urgent to use NLP techniques to analyze privacy policies. However, existing datasets ignore law requirements and are limited to English. In this paper, we construct the first Chinese privacy policy dataset, namely CA4P-483, to facilitate the sequence labeling tasks and regulation compliance identification between privacy policies and software. Our dataset includes 483 Chinese Android application privacy policies, over 11K sentences, and 52K fine-grained annotations. We evaluate families of robust and representative baseline models on our dataset. Based on baseline performance, we provide findings and potential research directions on our dataset. Finally, we investigate the potential applications of CA4P-483 combing regulation requirements and program analysis",
    "checked": true,
    "id": "df69f54ec1f5af999353e252ca2d835da1dc5471",
    "semantic_title": "a fine-grained chinese software privacy policy dataset for sequence labeling and regulation compliant identification",
    "citation_count": 4,
    "authors": [
      "Kaifa Zhao",
      "Le Yu",
      "Shiyao Zhou",
      "Jing Li",
      "Xiapu Luo",
      "Yat Fei Aemon Chiu",
      "Yutong Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.701": {
    "title": "Saving Dense Retriever from Shortcut Dependency in Conversational Search",
    "volume": "main",
    "abstract": "Conversational search (CS) needs a holistic understanding of conversational inputs to retrieve relevant passages. In this paper, we demonstrate the existence of a retrieval shortcut in CS, which causes models to retrieve passages solely relying on partial history while disregarding the latest question. With in-depth analysis, we first show that naively trained dense retrievers heavily exploit the shortcut and hence perform poorly when asked to answer history-independent questions. To build more robust models against shortcut dependency, we explore various hard negative mining strategies. Experimental results show that training with the model-based hard negatives effectively mitigates the dependency on the shortcut, significantly improving dense retrievers on recent CS benchmarks. In particular, our retriever outperforms the previous state-of-the-art model by 11.0 in Recall@10 on QReCC",
    "checked": true,
    "id": "c2f9a27ab32bff87573e31594c97742af90f11b2",
    "semantic_title": "saving dense retriever from shortcut dependency in conversational search",
    "citation_count": 17,
    "authors": [
      "Sungdong Kim",
      "Gangwoo Kim"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.702": {
    "title": "Graph-Induced Transformers for Efficient Multi-Hop Question Answering",
    "volume": "main",
    "abstract": "A graph is a suitable data structure to represent the structural information of text. Recently, multi-hop question answering (MHQA) tasks, which require inter-paragraph/sentence linkages, have come to exploit such properties of a graph. Previous approaches to MHQA relied on leveraging the graph information along with the pre-trained language model (PLM) encoders. However, this trend exhibits the following drawbacks: (i) sample inefficiency while training in a low-resource setting; (ii) lack of reusability due to changes in the model structure or input. Our work proposes the Graph-Induced Transformer (GIT) that applies graph-derived attention patterns directly into a PLM, without the need to employ external graph modules. GIT can leverage the useful inductive bias of graphs while retaining the unperturbed Transformer structure and parameters. Our experiments on HotpotQA successfully demonstrate both the sample efficient characteristic of GIT and its capacity to replace the graph modules while preserving model performance",
    "checked": true,
    "id": "b75202954bbd13f97ea58b23bcad31cf347ab6c5",
    "semantic_title": "graph-induced transformers for efficient multi-hop question answering",
    "citation_count": 3,
    "authors": [
      "Giwon Hong",
      "Jeonghwan Kim",
      "Junmo Kang",
      "Sung-Hyon Myaeng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.703": {
    "title": "DiscoSense: Commonsense Reasoning with Discourse Connectives",
    "volume": "main",
    "abstract": "We present DiscoSense, a benchmark for commonsense reasoning via understanding a wide variety of discourse connectives. We generate compelling distractors in DiscoSense using Conditional Adversarial Filtering, an extension of Adversarial Filtering that employs conditional generation. We show that state-of-the-art pre-trained language models struggle to perform well on DiscoSense, which makes this dataset ideal for evaluating next-generation commonsense reasoning systems",
    "checked": true,
    "id": "1a5f48161df983a0e9485425495121201902433b",
    "semantic_title": "discosense: commonsense reasoning with discourse connectives",
    "citation_count": 3,
    "authors": [
      "Prajjwal Bhargava",
      "Vincent Ng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.704": {
    "title": "Boosting Document-Level Relation Extraction by Mining and Injecting Logical Rules",
    "volume": "main",
    "abstract": "Document-level relation extraction (DocRE) aims at extracting relations of all entity pairs in a document. A key challenge to DocRE lies in the complex interdependency between the relations of entity pairs. Unlike most prior efforts focusing on implicitly powerful representations, the recently proposed LogiRE (Ru et al., 2021) explicitly captures the interdependency by learning logical rules. However, LogiRE requires extra parameterized modules to reason merely after training backbones, and this disjointed optimization of backbones and extra modules may lead to sub-optimal results. In this paper, we propose MILR, a logic enhanced framework that boosts DocRE by Mining and Injecting Logical Rules. MILR first mines logical rules from annotations based on frequencies. Then in training, consistency regularizationis leveraged as an auxiliary loss to penalize instances that violate mined rules. Finally, MILR infers from a global perspective based on integer programming. Compared with LogiRE, MILR does not introduce extra parameters and injects logical rules during both training and inference. Extensive experiments on two benchmarks demonstrate that MILR not only improves the relation extraction performance (1.1%-3.8% F1) but also makes predictions more logically consistent (over 4.5% Logic). More importantly, MILR also consistently outperforms LogiRE on both counts. Code is available at https://github.com/XingYing-stack/MILR",
    "checked": true,
    "id": "f9a479516a764e750102cbc45915f19a17a219de",
    "semantic_title": "boosting document-level relation extraction by mining and injecting logical rules",
    "citation_count": 0,
    "authors": [
      "Shengda Fan",
      "Shasha Mo",
      "Jianwei Niu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.705": {
    "title": "MOCHA: A Multi-Task Training Approach for Coherent Text Generation from Cognitive Perspective",
    "volume": "main",
    "abstract": "Teaching neural models to generate narrative coherent texts is a critical problem. Recent pre-trained language models have achieved promising results, but there is still a gap between human written texts and machine-generated outputs. In this work, we propose a novel multi-task training strategy for long text generation grounded on the cognitive theory of writing, which empowers the model to learn essential subskills needed for writing including planning and reviewing besides end-to-end generation. We extensively evaluate our model on three open-ended generation tasks including story generation, news article writing and argument generation. Experiments show that our model achieves better results on both few-shot and fully-supervised settings than strong baselines, and human evaluations confirm that our model can generate more coherent outputs",
    "checked": true,
    "id": "ffa0032150e2edf21633b6a6867b54ea121cb9d9",
    "semantic_title": "mocha: a multi-task training approach for coherent text generation from cognitive perspective",
    "citation_count": 3,
    "authors": [
      "Zhe Hu",
      "Hou Pong Chan",
      "Lifu Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.706": {
    "title": "Variational Autoencoder with Disentanglement Priors for Low-Resource Task-Specific Natural Language Generation",
    "volume": "main",
    "abstract": "In this paper, we propose a variational autoencoder with disentanglement priors, VAE-Dprior, for task-specific natural language generation with none or a handful of task-specific labeled examples. In order to tackle compositional generalization across tasks, our model performs disentangled representation learning by introducing a conditional prior for the latent content space and another conditional prior for the latent label space. Both types of priors satisfy a novel property called 𝜖-disentangled. We show both empirically and theoretically that the novel priors can disentangle representations even without specific regularizations as in the prior work. The content prior enables directly sampling diverse content representations from the content space learned from the seen tasks, and fuse them with the representations of novel tasks for generating semantically diverse texts in the low-resource settings. Our extensive experiments demonstrate the superior performance of our model over competitive baselines in terms of i) data augmentation in continuous zero/few-shot learning, and ii) text style transfer in the few-shot setting",
    "checked": true,
    "id": "4da1cfb77084ef04a1bb6924de11eac05daa381b",
    "semantic_title": "variational autoencoder with disentanglement priors for low-resource task-specific natural language generation",
    "citation_count": 2,
    "authors": [
      "Zhuang Li",
      "Lizhen Qu",
      "Qiongkai Xu",
      "Tongtong Wu",
      "Tianyang Zhan",
      "Gholamreza Haffari"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.707": {
    "title": "CISLR: Corpus for Indian Sign Language Recognition",
    "volume": "main",
    "abstract": "Indian Sign Language, though used by a diverse community, still lacks well-annotated resources for developing systems that would enable sign language processing. In recent years researchers have actively worked for sign languages like American Sign Languages, however, Indian Sign language is still far from data-driven tasks like machine translation. To address this gap, in this paper, we introduce a new dataset CISLR (Corpus for Indian Sign Language Recognition) for word-level recognition in Indian Sign Language using videos. The corpus has a large vocabulary of around 4700 words covering different topics and domains. Further, we propose a baseline model for word recognition from sign language videos. To handle the low resource problem in the Indian Sign Language, the proposed model consists of a prototype-based one-shot learner that leverages resource rich American Sign Language to learn generalized features for improving predictions in Indian Sign Language. Our experiments show that gesture features learned in another sign language can help perform one-shot predictions in CISLR",
    "checked": true,
    "id": "dfe0315936e55c01484cd5dc36661d42f405b592",
    "semantic_title": "cislr: corpus for indian sign language recognition",
    "citation_count": 3,
    "authors": [
      "Abhinav Joshi",
      "Ashwani Bhat",
      "Pradeep S",
      "Priya Gole",
      "Shashwat Gupta",
      "Shreyansh Agarwal",
      "Ashutosh Modi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.708": {
    "title": "Mask the Correct Tokens: An Embarrassingly Simple Approach for Error Correction",
    "volume": "main",
    "abstract": "Text error correction aims to correct the errors in text sequences such as those typed by humans or generated by speech recognition models. Previous error correction methods usually take the source (incorrect) sentence as encoder input and generate the target (correct) sentence through the decoder. Since the error rate of the incorrect sentence is usually low (e.g., 10%), the correction model can only learn to correct on limited error tokens but trivially copy on most tokens (correct tokens), which harms the effective training of error correction. In this paper, we argue that the correct tokens should be better utilized to facilitate effective training and then propose a simple yet effective masking strategy to achieve this goal. Specifically, we randomly mask out a part of the correct tokens in the source sentence and let the model learn to not only correct the original error tokens but also predict the masked tokens based on their context information. Our method enjoys several advantages: 1) it alleviates trivial copy; 2) it leverages effective training signals from correct tokens; 3) it is a plug-and-play module and can be applied to different models and tasks. Experiments on spelling error correction and speech recognition error correction on Mandarin datasets and grammar error correction on English datasets with both autoregressive and non-autoregressive generation models show that our method improves the correctionaccuracy consistently",
    "checked": true,
    "id": "b58d9b8c91fa2a2ffb622682021fadd4159d35ba",
    "semantic_title": "mask the correct tokens: an embarrassingly simple approach for error correction",
    "citation_count": 7,
    "authors": [
      "Kai Shen",
      "Yichong Leng",
      "Xu Tan",
      "Siliang Tang",
      "Yuan Zhang",
      "Wenjie Liu",
      "Edward Lin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.709": {
    "title": "AMAL: Meta Knowledge-Driven Few-Shot Adapter Learning",
    "volume": "main",
    "abstract": "NLP has advanced greatly together with the proliferation of Transformer-based pre-trained language models. To adapt to a downstream task, the pre-trained language models need to be fine-tuned with a sufficient supply of annotated examples. In recent years, Adapter-based fine-tuning methods have expanded the applicability of pre-trained language models by substantially lowering the required amount of annotated examples. However, existing Adapter-based methods still fail to yield meaningful results in the few-shot regime where only a few annotated examples are provided. In this study, we present a meta-learning-driven low-rank adapter pooling method, called AMAL, for leveraging pre-trained language models even with just a few data points. We evaluate our method on five text classification benchmark datasets. The results show that AMAL significantly outperforms previous few-shot learning methods and achieves a new state-of-the-art",
    "checked": true,
    "id": "9d601892947dfe20378d33963ad9f440d0ff0727",
    "semantic_title": "amal: meta knowledge-driven few-shot adapter learning",
    "citation_count": 0,
    "authors": [
      "S. K. Hong",
      "Tae Young Jang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.710": {
    "title": "Discourse Context Predictability Effects in Hindi Word Order",
    "volume": "main",
    "abstract": "We test the hypothesis that discourse predictability influences Hindi syntactic choice. While prior work has shown that a number of factors (e.g., information status, dependency length, and syntactic surprisal) influence Hindi word order preferences, the role of discourse predictability is underexplored in the literature. Inspired by prior work on syntactic priming, we investigate how the words and syntactic structures in a sentence influence the word order of the following sentences. Specifically, we extract sentences from the Hindi-Urdu Treebank corpus (HUTB), permute the preverbal constituents of those sentences, and build a classifier to predict which sentences actually occurred in the corpus against artificially generated distractors. The classifier uses a number of discourse-based features and cognitive features to make its predictions, including dependency length, surprisal, and information status. We find that information status and LSTM-based discourse predictability influence word order choices, especially for non-canonical object-fronted orders. We conclude by situating our results within the broader syntactic priming literature",
    "checked": true,
    "id": "26674f055f75c494f3e39913a5f986f6e74bba29",
    "semantic_title": "discourse context predictability effects in hindi word order",
    "citation_count": 1,
    "authors": [
      "Sidharth Ranjan",
      "Marten van Schijndel",
      "Sumeet Agarwal",
      "Rajakrishnan Rajkumar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.711": {
    "title": "Covid vaccine is against Covid but Oxford vaccine is made at Oxford!\" Semantic Interpretation of Proper Noun Compounds",
    "volume": "main",
    "abstract": "Proper noun compounds, e.g., \"Covid vaccine\", convey information in a succinct manner (a \"Covid vaccine\" is a \"vaccine that immunizes against the Covid disease\"). These are commonly used in short-form domains, such as news headlines, but are largely ignored in information-seeking applications. To address this limitation, we release a new manually annotated dataset, ProNCI, consisting of 22.5K proper noun compounds along with their free-form semantic interpretations. ProNCI is 60 times larger than prior noun compound datasets and also includes non-compositional examples, which have not been previously explored. We experiment with various neural models for automatically generating the semantic interpretations from proper noun compounds, ranging from few-shot prompting to supervised learning, with varying degrees of knowledge about the constituent nouns. We find that adding targeted knowledge, particularly about the common noun, results in performance gains of upto 2.8%. Finally, we integrate our model generated interpretations with an existing Open IE system and observe an 7.5% increase in yield at a precision of 85%. The dataset and code are available at https://github.com/dair-iitd/pronci",
    "checked": true,
    "id": "33285e02758788b681754d283df20971fef6e31f",
    "semantic_title": "covid vaccine is against covid but oxford vaccine is made at oxford!\" semantic interpretation of proper noun compounds",
    "citation_count": 1,
    "authors": [
      "Keshav Kolluru",
      "Gabriel Stanovsky",
      "Mausam -"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.712": {
    "title": "Context Limitations Make Neural Language Models More Human-Like",
    "volume": "main",
    "abstract": "Language models (LMs) have been used in cognitive modeling as well as engineering studies—they compute information-theoretic complexity metrics that simulate humans' cognitive load during reading. This study highlights a limitation of modern neural LMs as the model of choice for this purpose: there is a discrepancy between their context access capacities and that of humans. Our results showed that constraining the LMs' context access improved their simulation of human reading behavior. We also showed that LM-human gaps in context access were associated with specific syntactic constructions; incorporating syntactic biases into LMs' context access might enhance their cognitive plausibility",
    "checked": true,
    "id": "2c162ee2a942e4b096773ca5394be47d9c6ab60d",
    "semantic_title": "context limitations make neural language models more human-like",
    "citation_count": 15,
    "authors": [
      "Tatsuki Kuribayashi",
      "Yohei Oseki",
      "Ana Brassard",
      "Kentaro Inui"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.713": {
    "title": "A Generative Model for End-to-End Argument Mining with Reconstructed Positional Encoding and Constrained Pointer Mechanism",
    "volume": "main",
    "abstract": "Argument mining (AM) is a challenging task as it requires recognizing the complex argumentation structures involving multiple subtasks. To handle all subtasks of AM in an end-to-end fashion, previous works generally transform AM into a dependency parsing task. However, such methods largely require complex pre- and post-processing to realize the task transformation. In this paper, we investigate the end-to-end AM task from a novel perspective by proposing a generative framework, in which the expected outputs of AM are framed as a simple target sequence. Then, we employ a pre-trained sequence-to-sequence language model with a constrained pointer mechanism (CPM) to model the clues for all the subtasks of AM in the light of the target sequence. Furthermore, we devise a reconstructed positional encoding (RPE) to alleviate the order biases induced by the autoregressive generation paradigm. Experimental results show that our proposed framework achieves new state-of-the-art performance on two AM benchmarks",
    "checked": true,
    "id": "2de5967fc762861749ba55e70787e5d799914b34",
    "semantic_title": "a generative model for end-to-end argument mining with reconstructed positional encoding and constrained pointer mechanism",
    "citation_count": 4,
    "authors": [
      "Jianzhu Bao",
      "Yuhang He",
      "Yang Sun",
      "Bin Liang",
      "Jiachen Du",
      "Bing Qin",
      "Min Yang",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.714": {
    "title": "Reflect, Not Reflex: Inference-Based Common Ground Improves Dialogue Response Quality",
    "volume": "main",
    "abstract": "Human communication relies on common ground (CG), the mutual knowledge and beliefs shared by participants, to produce coherent and interesting conversations. In this paper, we demonstrate that current response generation (RG) models produce generic and dull responses in dialogues because they act reflexively, failing to explicitly model CG, both due to the lack of CG in training data and the standard RG training procedure. We introduce Reflect, a dataset that annotates dialogues with explicit CG (materialized as inferences approximating shared knowledge and beliefs) and solicits 9k diverse human-generated responses each following one common ground. Using Reflect, we showcase the limitations of current dialogue data and RG models: less than half of the responses in current data is rated as high quality (sensible, specific, and interesting) and models trained using this data have even lower quality, while most Reflect responses are judged high quality. Next, we analyze whether CG can help models produce better quality responses by using Reflect CG to guide RG models. Surprisingly, we find that simply prompting GPT3 to \"think\" about CG generates 30% more quality responses, showing promising benefits to integrating CG into the RG process",
    "checked": true,
    "id": "ddbbf78334ef65d412520236e5d9067c82ef8984",
    "semantic_title": "reflect, not reflex: inference-based common ground improves dialogue response quality",
    "citation_count": 12,
    "authors": [
      "Pei Zhou",
      "Hyundong Cho",
      "Pegah Jandaghi",
      "Dong-Ho Lee",
      "Bill Yuchen Lin",
      "Jay Pujara",
      "Xiang Ren"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.715": {
    "title": "FlowEval: A Consensus-Based Dialogue Evaluation Framework Using Segment Act Flows",
    "volume": "main",
    "abstract": "Despite recent progress in open-domain dialogue evaluation, how to develop automatic metrics remains an open problem. We explore the potential of dialogue evaluation featuring dialog act information, which was hardly explicitly modeled in previous methods. However, defined at the utterance level in general, dialog act is of coarse granularity, as an utterance can contain multiple segments possessing different functions. Hence, we propose segment act, an extension of dialog act from utterance level to segment level, and crowdsource a large-scale dataset for it. To utilize segment act flows, sequences of segment acts, for evaluation, we develop the first consensus-based dialogue evaluation framework, FlowEval. This framework provides a reference-free approach for dialog evaluation by finding pseudo-references. Extensive experiments against strong baselines on three benchmark datasets demonstrate the effectiveness and other desirable characteristics of our FlowEval, pointing out a potential path for better dialogue evaluation",
    "checked": true,
    "id": "e0af8f2dd390fabcdf2c373640833efc62faa530",
    "semantic_title": "floweval: a consensus-based dialogue evaluation framework using segment act flows",
    "citation_count": 3,
    "authors": [
      "Jianqiao Zhao",
      "Yanyang Li",
      "Wanyu Du",
      "Yangfeng Ji",
      "Dong Yu",
      "Michael Lyu",
      "Liwei Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.716": {
    "title": "FaD-VLP: Fashion Vision-and-Language Pre-training towards Unified Retrieval and Captioning",
    "volume": "main",
    "abstract": "Multimodal tasks in the fashion domain have significant potential for e-commerce, but involve challenging vision-and-language learning problems—e.g., retrieving a fashion item given a reference image plus text feedback from a user. Prior works on multimodal fashion tasks have either been limited by the data in individual benchmarks, or have leveraged generic vision-and-language pre-training but have not taken advantage of the characteristics of fashion data. Additionally, these works have mainly been restricted to multimodal understanding tasks. To address these gaps, we make two key contributions. First, we propose a novel fashion-specific pre-training framework based on weakly-supervised triplets constructed from fashion image-text pairs. We show the triplet-based tasks are an effective addition to standard multimodal pre-training tasks. Second, we propose a flexible decoder-based model architecture capable of both fashion retrieval and captioning tasks. Together, our model design and pre-training approach are competitive on a diverse set of fashion tasks, including cross-modal retrieval, image retrieval with text feedback, image captioning, relative image captioning, and multimodal categorization",
    "checked": true,
    "id": "1cc512fc89651dc4e9a1998447a6693d90b73ee0",
    "semantic_title": "fad-vlp: fashion vision-and-language pre-training towards unified retrieval and captioning",
    "citation_count": 7,
    "authors": [
      "Suvir Mirchandani",
      "Licheng Yu",
      "Mengjiao Wang",
      "Animesh Sinha",
      "Wenwen Jiang",
      "Tao Xiang",
      "Ning Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.717": {
    "title": "MM-Align: Learning Optimal Transport-based Alignment Dynamics for Fast and Accurate Inference on Missing Modality Sequences",
    "volume": "main",
    "abstract": "Existing multimodal tasks mostly target at the complete input modality setting, i.e., each modality is either complete or completely missing in both training and test sets. However, the randomly missing situations have still been underexplored. In this paper, we present a novel approach named MM-Align to address the missing-modality inference problem. Concretely, we propose 1) an alignment dynamics learning module based on the theory of optimal transport (OT) for missing data imputation; 2) a denoising training algorithm to enhance the quality of imputation as well as the accuracy of model predictions. Compared with previous generative methods which devote to restoring the missing inputs, MM-Align learns to capture and imitate the alignment dynamics between modality sequences. Results of comprehensive experiments on two multimodal tasks empirically demonstrate that our method can perform more accurate and faster inference and alleviate the overfitting issue under different missing conditions",
    "checked": true,
    "id": "69f4f0d587197a00179637ae9e747f662ada9c38",
    "semantic_title": "mm-align: learning optimal transport-based alignment dynamics for fast and accurate inference on missing modality sequences",
    "citation_count": 4,
    "authors": [
      "Wei Han",
      "Hui Chen",
      "Min-Yen Kan",
      "Soujanya Poria"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.718": {
    "title": "Evaluating the Knowledge Dependency of Questions",
    "volume": "main",
    "abstract": "The automatic generation of Multiple Choice Questions (MCQ) has the potential to reduce the time educators spend on student assessment significantly. However, existing evaluation metrics for MCQ generation, such as BLEU, ROUGE, and METEOR, focus on the n-gram based similarity of the generated MCQ to the gold sample in the dataset and disregard their educational value. They fail to evaluate the MCQ's ability to assess the student's knowledge of the corresponding target fact. To tackle this issue, we propose a novel automatic evaluation metric, coined Knowledge Dependent Answerability (KDA), which measures the MCQ's answerability given knowledge of the target fact. Specifically, we first show how to measure KDA based on student responses from a human survey. Then, we propose two automatic evaluation metrics, KDA_disc and KDA_cont, that approximate KDA by leveraging pre-trained language models to imitate students' problem-solving behavior. Through our human studies, we show that KDA_disc and KDA_soft have strong correlations with both (1) KDA and (2) usability in an actual classroom setting, labeled by experts. Furthermore, when combined with n-gram based similarity metrics, KDA_disc and KDA_cont are shown to have a strong predictive power for various expert-labeled MCQ quality measures",
    "checked": true,
    "id": "5f98a78b1e17a594d4c9178d8610a053884a2203",
    "semantic_title": "evaluating the knowledge dependency of questions",
    "citation_count": 3,
    "authors": [
      "Hyeongdon Moon",
      "Yoonseok Yang",
      "Hangyeol Yu",
      "Seunghyun Lee",
      "Myeongho Jeong",
      "Juneyoung Park",
      "Jamin Shin",
      "Minsam Kim",
      "Seungtaek Choi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.719": {
    "title": "MoSE: Modality Split and Ensemble for Multimodal Knowledge Graph Completion",
    "volume": "main",
    "abstract": "Multimodal knowledge graph completion (MKGC) aims to predict missing entities in MKGs. Previous works usually share relation representation across modalities. This results in mutual interference between modalities during training, since for a pair of entities, the relation from one modality probably contradicts that from another modality. Furthermore, making a unified prediction based on the shared relation representation treats the input in different modalities equally, while their importance to the MKGC task should be different. In this paper, we propose MoSE, a Modality Split representation learning and Ensemble inference framework for MKGC. Specifically, in the training phase, we learn modality-split relation embeddings for each modality instead of a single modality-shared one, which alleviates the modality interference. Based on these embeddings, in the inference phase, we first make modality-split predictions and then exploit various ensemble methods to combine the predictions with different weights, which models the modality importance dynamically. Experimental results on three KG datasets show that MoSE outperforms state-of-the-art MKGC methods. Codes are available at https://github.com/OreOZhao/MoSE4MKGC",
    "checked": true,
    "id": "f399dce9bbb2754d33c5aefb60bfe54f260a4b21",
    "semantic_title": "mose: modality split and ensemble for multimodal knowledge graph completion",
    "citation_count": 10,
    "authors": [
      "Yu Zhao",
      "Xiangrui Cai",
      "Yike Wu",
      "Haiwei Zhang",
      "Ying Zhang",
      "Guoqing Zhao",
      "Ning Jiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.720": {
    "title": "Entropy-Based Vocabulary Substitution for Incremental Learning in Multilingual Neural Machine Translation",
    "volume": "main",
    "abstract": "In a practical real-world scenario, the longstanding goal is that a universal multilingual translation model can be incrementally updated when new language pairs arrive. Specifically, the initial vocabulary only covers some of the words in new languages, which hurts the translation quality for incremental learning. Although existing approaches attempt to address this issue by replacing the original vocabulary with a rebuilt vocabulary or constructing independent language-specific vocabularies, these methods can not meet the following three demands simultaneously: (1) High translation quality for original and incremental languages, (2) low cost for model training, (3) low time overhead for preprocessing. In this work, we propose an entropy-based vocabulary substitution (EVS) method that just needs to walk through new language pairs for incremental learning in a large-scale multilingual data updating while remaining the size of the vocabulary. Our method has access to learn new knowledge from updated training samples incrementally while keeping high translation quality for original language pairs, alleviating the issue of catastrophic forgetting. Results of experiments show that EVS can achieve better performance and save excess overhead for incremental learning in the multilingual machine translation task",
    "checked": true,
    "id": "b6f4877861be9a40711763394d8f5f0377ad1a8f",
    "semantic_title": "entropy-based vocabulary substitution for incremental learning in multilingual neural machine translation",
    "citation_count": 2,
    "authors": [
      "Kaiyu Huang",
      "Peng Li",
      "Jin Ma",
      "Yang Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.721": {
    "title": "Eliciting Knowledge from Large Pre-Trained Models for Unsupervised Knowledge-Grounded Conversation",
    "volume": "main",
    "abstract": "Recent advances in large-scale pre-training provide large models with the potential to learn knowledge from the raw text. It is thus natural to ask whether it is possible to leverage these large models as knowledge bases for downstream tasks. In this work, we answer the aforementioned question in unsupervised knowledge-grounded conversation. We explore various methods that best elicit knowledge from large models. Our human study indicates that, though hallucinations exist, large models post the unique advantage of being able to output common sense and summarize facts that cannot be directly retrieved from the search engine. To better exploit such generated knowledge in dialogue generation, we treat the generated knowledge as a noisy knowledge source and propose the posterior-based reweighing as well as the noisy training strategy. Empirical results on two benchmarks show advantages over the state-of-the-art methods",
    "checked": true,
    "id": "0f7a6c557e376d8c77d684bcda0daee74fc29acf",
    "semantic_title": "eliciting knowledge from large pre-trained models for unsupervised knowledge-grounded conversation",
    "citation_count": 7,
    "authors": [
      "Yanyang Li",
      "Jianqiao Zhao",
      "Michael Lyu",
      "Liwei Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.722": {
    "title": "An Unsupervised, Geometric and Syntax-aware Quantification of Polysemy",
    "volume": "main",
    "abstract": "Polysemy is the phenomenon where a single word form possesses two or more related senses. It is an extremely ubiquitous part of natural language and analyzing it has sparked rich discussions in the linguistics, psychology and philosophy communities alike. With scarce attention paid to polysemy in computational linguistics, and even scarcer attention toward quantifying polysemy, in this paper, we propose a novel, unsupervised framework to compute and estimate polysemy scores for words in multiple languages. We infuse our proposed quantification with syntactic knowledge in the form of dependency structures. This informs the final polysemy scores of the lexicon motivated by recent linguistic findings that suggest there is an implicit relation between syntax and ambiguity/polysemy. We adopt a graph based approach by computing the discrete Ollivier Ricci curvature on a graph of the contextual nearest neighbors. We test our framework on curated datasets controlling for different sense distributions of words in 3 typologically diverse languages - English, French and Spanish. The effectiveness of our framework is demonstrated by significant correlations of our quantification with expert human annotated language resources like WordNet. We observe a 0.3 point increase in the correlation coefficient as compared to previous quantification studies in English. Our research leverages contextual language models and syntactic structures to empirically support the widely held theoretical linguistic notion that syntax is intricately linked to ambiguity/polysemy",
    "checked": true,
    "id": "b59c8af32e315148a0b3bfe21785189abab2f208",
    "semantic_title": "an unsupervised, geometric and syntax-aware quantification of polysemy",
    "citation_count": 3,
    "authors": [
      "Anmol Goel",
      "Charu Sharma",
      "Ponnurangam Kumaraguru"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.723": {
    "title": "Reorder and then Parse, Fast and Accurate Discontinuous Constituency Parsing",
    "volume": "main",
    "abstract": "Discontinuous constituency parsing is still kept developing for its efficiency and accuracy are far behind its continuous counterparts. Motivated by the observation that a discontinuous constituent tree can be simply transformed into a pseudo-continuous one by artificially reordering words in the sentence, we propose a novel reordering method, thereby construct fast and accurate discontinuous constituency parsing systems working in continuous way. Specifically, we model the relative position changes of words as a list of actions. By parsing and performing this actions, the corresponding pseudo-continuous sequence is derived. Discontinuous parse tree can be further inferred via integrating a high-performance pseudo-continuous constituency parser. Our systems are evaluated on three classical discontinuous constituency treebanks, achieving new state-of-the-art on two treebanks and showing a distinct advantage in speed",
    "checked": true,
    "id": "f5b186a9cd3eb321004d6fc750f63d4282f922f1",
    "semantic_title": "reorder and then parse, fast and accurate discontinuous constituency parsing",
    "citation_count": 3,
    "authors": [
      "Kailai Sun",
      "Zuchao Li",
      "Hai Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.724": {
    "title": "Making Science Simple: Corpora for the Lay Summarisation of Scientific Literature",
    "volume": "main",
    "abstract": "Lay summarisation aims to jointly summarise and simplify a given text, thus making its content more comprehensible to non-experts. Automatic approaches for lay summarisation can provide significant value in broadening access to scientific literature, enabling a greater degree of both interdisciplinary knowledge sharing and public understanding when it comes to research findings. However, current corpora for this task are limited in their size and scope, hindering the development of broadly applicable data-driven approaches. Aiming to rectify these issues, we present two novel lay summarisation datasets, PLOS (large-scale) and eLife (medium-scale), each of which contains biomedical journal articles alongside expert-written lay summaries. We provide a thorough characterisation of our lay summaries, highlighting differing levels of readability and abstractivenessbetween datasets that can be leveraged to support the needs of different applications. Finally, we benchmark our datasets using mainstream summarisation approaches and perform a manual evaluation with domain experts, demonstrating their utility and casting light on the key challenges of this task",
    "checked": true,
    "id": "73bf67f9ac4a28c5618f8df32cb64d810f57a9b9",
    "semantic_title": "making science simple: corpora for the lay summarisation of scientific literature",
    "citation_count": 33,
    "authors": [
      "Tomas Goldsack",
      "Zhihao Zhang",
      "Chenghua Lin",
      "Carolina Scarton"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.725": {
    "title": "Looking at the Overlooked: An Analysis on the Word-Overlap Bias in Natural Language Inference",
    "volume": "main",
    "abstract": "It has been shown that NLI models are usually biased with respect to the word-overlap between the premise and the hypothesis, as they take this feature as a primary cue for predicting the entailment label. In this paper, we focus on an overlooked aspect of the overlap bias in the NLI models: the reverse word-overlap bias. Our experimental results demonstrate that current NLI systems are also highly biased towards the non-entailment label on instances with low overlap and that existing debiasing methods, which are reportedly successful on challenge datasets, are generally ineffective in addressing this category of bias. Through a set of analyses, we investigate the reasons for the emergence of the overlap bias and the role of minority examples in mitigating this bias. For the former, we find that the word overlap bias does not stem from pre-training, and in the latter, we observe that in contrast to the accepted assumption, eliminating minority examples does not affect the generalizability of debiasing methods with respect to the overlap bias",
    "checked": true,
    "id": "86ea35528a2b9ed59834c23a5cb0e47c5e6d876d",
    "semantic_title": "looking at the overlooked: an analysis on the word-overlap bias in natural language inference",
    "citation_count": 3,
    "authors": [
      "Sara Rajaee",
      "Yadollah Yaghoobzadeh",
      "Mohammad Taher Pilehvar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.726": {
    "title": "An Empirical Study on the Transferability of Transformer Modules in Parameter-efficient Fine-tuning",
    "volume": "main",
    "abstract": "Parameter-efficient fine-tuning has garnered lots of attention in recent studies. On this subject, we investigate the capability of different transformer modules in transferring knowledge from a pre-trained model to a downstream task. Our empirical results suggest that every transformer module is a winning ticket such that fine-tuning the specific module while the rest of the network is frozen achieves a comparable performance to the full fine-tuning case. Among different modules in LMs, LayerNorms exhibit a significant capacity for transfer learning to the extent that with only 0.003% updateable parameters in the layer-wise analysis, they can show acceptable performance on various target tasks. We argue that the performance of LayerNorms could be attributed to their high-magnitude weights compared to other components in a pre-trained model",
    "checked": true,
    "id": "684b0f42aa5d5b2bea09f6e0400336cf288cc787",
    "semantic_title": "an empirical study on the transferability of transformer modules in parameter-efficient fine-tuning",
    "citation_count": 0,
    "authors": [
      "Mohammad AkbarTajari",
      "Sara Rajaee",
      "Mohammad Taher Pilehvar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.727": {
    "title": "CODER: An efficient framework for improving retrieval through COntextual Document Embedding Reranking",
    "volume": "main",
    "abstract": "Contrastive learning has been the dominant approach to training dense retrieval models. In this work, we investigate the impact of ranking context - an often overlooked aspect of learning dense retrieval models. In particular, we examine the effect of its constituent parts: jointly scoring a large number of negatives per query, using retrieved (query-specific) instead of random negatives, and a fully list-wise loss. To incorporate these factors into training, we introduce Contextual Document Embedding Reranking (CODER), a highly efficient retrieval framework. When reranking, it incurs only a negligible computational overhead on top of a first-stage method at run time (approx. 5 ms delay per query), allowing it to be easily combined with any state-of-the-art dual encoder method. Models trained through CODER can also be used as stand-alone retrievers. Evaluating CODER in a large set of experiments on the MS MARCO and TripClick collections, we show that the contextual reranking of precomputed document embeddings leads to a significant improvement in retrieval performance. This improvement becomes even more pronounced when more relevance information per query is available, shown in the TripClick collection, where we establish new state-of-the-art results by a large margin",
    "checked": true,
    "id": "6b259f83ca9a23fc0c0f8c53ae1268be16cbf037",
    "semantic_title": "coder: an efficient framework for improving retrieval through contextual document embedding reranking",
    "citation_count": 3,
    "authors": [
      "George Zerveas",
      "Navid Rekabsaz",
      "Daniel Cohen",
      "Carsten Eickhoff"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.728": {
    "title": "AdapterShare: Task Correlation Modeling with Adapter Differentiation",
    "volume": "main",
    "abstract": "Thanks to the development of pre-trained language models, multitask learning (MTL) methods achieve a great success in natural language understanding area. However, current MTL methods pay more attention to task selection or model design to fuse as much knowledge as possible, while intrinsic task correlation is often neglected. It is important to learn sharing strategy among multiple tasks rather than sharing everything.%The MTL model is directly shared among all the tasks. %For example, in traditional MTL methods, the last classification layers or the decoder layers are manually separated. More deeply, In this paper, we propose AdapterShare, an adapter differentiation method to explicitly model the task correlation among multiple tasks. AdapterShare is automatically learned based on the gradients on tiny held-out validation data. Compared to single-task learning and fully shared MTL methods, our proposed method obtains obvious performance improvement. Compared to the existing MTL method AdapterFusion, AdapterShare achieves absolute 1.90 average points improvement on five dialogue understanding tasks and 2.33 points gain on NLU tasks",
    "checked": true,
    "id": "3de1538acb641deeed5bd88ea6231508b7cc9944",
    "semantic_title": "adaptershare: task correlation modeling with adapter differentiation",
    "citation_count": 0,
    "authors": [
      "Zhi Chen",
      "Bei Chen",
      "Lu Chen",
      "Kai Yu",
      "Jian-Guang Lou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.729": {
    "title": "Rethinking Task-Specific Knowledge Distillation: Contextualized Corpus as Better Textbook",
    "volume": "main",
    "abstract": "Knowledge distillation has been proven effective when customizing small language models for specific tasks. Here, a corpus as ‘textbook' plays an indispensable role, only through which the teacher can teach the student. Prevailing methods adopt a two-stage distillation paradigm: general distillation first with task-agnostic general corpus and task-specific distillation next with augmented task-specific corpus. We argue that such a paradigm may not be optimal. In general distillation, it's extravagant to let the diverse but desultory general knowledge overwhelms the limited model capacity of the student. While in task-specific distillation, the task corpus is usually limited and narrow, preventing the student from learning enough knowledge. To mitigate the issues in the two gapped corpora, we present a better textbook for the student to learn: contextualized corpus that contextualizes task corpus with large-scale general corpus through relevance-based text retrieval. Experimental results on GLUE benchmark demonstrate that contextualized corpus is the better textbook compared with jointly using general corpus and augmented task-specific corpus. Surprisingly, it enables task-specific distillation from scratch without general distillation while maintaining comparable performance, making it more flexible to customize the student model with desired model size under various computation constraints",
    "checked": true,
    "id": "cde8963149d55c20463df74f0e1ceaeb63e1d4e0",
    "semantic_title": "rethinking task-specific knowledge distillation: contextualized corpus as better textbook",
    "citation_count": 4,
    "authors": [
      "Chang Liu",
      "Chongyang Tao",
      "Jianxin Liang",
      "Tao Shen",
      "Jiazhan Feng",
      "Quzhe Huang",
      "Dongyan Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.730": {
    "title": "Recovering Gold from Black Sand: Multilingual Dense Passage Retrieval with Hard and False Negative Samples",
    "volume": "main",
    "abstract": "Negative samples have not been efficiently explored in multilingual dense passage retrieval. In this paper, we propose a novel multilingual dense passage retrieval framework, mHFN, to recover and utilize hard and false negative samples. mHFN consists of three key components: 1) a multilingual hard negative sample augmentation module that allows knowledge of indistinguishable passages to be shared across multiple languages and synthesizes new hard negative samples by interpolating representations of queries and existing hard negative samples, 2) a multilingual negative sample cache queue that stores negative samples from previous batches in each language to increase the number of multilingual negative samples used in training beyond the batch size limit, and 3) a lightweight adaptive false negative sample filter that uses generated pseudo labels to separate unlabeled false negative samples and converts them into positive passages in training. We evaluate mHFN on Mr. TyDi, a high-quality multilingual dense passage retrieval dataset covering eleven typologically diverse languages, and experimental results show that mHFN outperforms strong sparse, dense and hybrid baselines and achieves new state-of-the-art performance on all languages. Our source code is available at https://github.com/Magnetic2014/mHFN",
    "checked": true,
    "id": "8752a918fc1a772e15798dcf7f3a75891f545e95",
    "semantic_title": "recovering gold from black sand: multilingual dense passage retrieval with hard and false negative samples",
    "citation_count": 1,
    "authors": [
      "Tianhao Shen",
      "Mingtong Liu",
      "Ming Zhou",
      "Deyi Xiong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.731": {
    "title": "The \"Problem\" of Human Label Variation: On Ground Truth in Data, Modeling and Evaluation",
    "volume": "main",
    "abstract": "Human variation in labeling is often considered noise. Annotation projects for machine learning (ML) aim at minimizing human label variation, with the assumption to maximize data quality and in turn optimize and maximize machine learning metrics. However, thisconventional practice assumes that there exists a *ground truth*, and neglects that there exists genuine human variation in labeling due to disagreement, subjectivity in annotation or multiple plausible answers. In this position paper, we argue that this big open problem of human label variation persists and critically needs more attention to move our field forward. This is because human label variation impacts all stages of the ML pipeline: *data, modeling and evaluation*. However, few works consider all of these dimensions jointly; and existing research is fragmented. We reconcile different previously proposed notions of human label variation, provide a repository of publicly-available datasets with un-aggregated labels, depict approaches proposed so far, identify gaps and suggest ways forward. As datasets are becoming increasingly available, we hope that this synthesized view on the \"problem\" will lead to an open discussion on possible strategies to devise fundamentally new directions",
    "checked": true,
    "id": "aea731e7cf33aa3d482b13f42cedbc1adb3271c6",
    "semantic_title": "the \"problem\" of human label variation: on ground truth in data, modeling and evaluation",
    "citation_count": 58,
    "authors": [
      "Barbara Plank"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.732": {
    "title": "Quality Scoring of Source Words in Neural Translation Models",
    "volume": "main",
    "abstract": "Word-level quality scores on input source sentences can provide useful feedback to an end-user when translating into an unfamiliar target language. Recent approaches either require training special word-scoring models based on synthetic data or require repeated invocation of the translation model. We propose a simple approach based on comparing the difference of probabilities from two language models. The basic premise of our method is to reason how well each source word is explained by the target sentence as against the source language model. Our approach provides up to five points higher F1 scores and is significantly faster than the state of the art methods on three language pairs. Also, our method does not require training any new model. We release a public dataset on word omissions and mistranslations on a new language pair",
    "checked": true,
    "id": "f31046a0cd1aaed5b0b7dffbce1467acdd49ca7e",
    "semantic_title": "quality scoring of source words in neural translation models",
    "citation_count": 0,
    "authors": [
      "Priyesh Jain",
      "Sunita Sarawagi",
      "Tushar Tomar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.733": {
    "title": "Pneg: Prompt-based Negative Response Generation for Dialogue Response Selection Task",
    "volume": "main",
    "abstract": "In retrieval-based dialogue systems, a response selection model acts as a ranker to select the most appropriate response among several candidates. However, such selection models tend to rely on context-response content similarity, which makes models vulnerable to adversarial responses that are semantically similar but not relevant to the dialogue context. Recent studies have shown that leveraging these adversarial responses as negative training samples is useful for improving the discriminating power of the selection model. Nevertheless, collecting human-written adversarial responses is expensive, and existing synthesizing methods often have limited scalability. To overcome these limitations, this paper proposes a simple but efficient method for generating adversarial negative responses leveraging a large-scale language model. Experimental results on dialogue selection tasks show that our method outperforms other methods of synthesizing adversarial negative responses. These results suggest that our method can be an effective alternative to human annotators in generating adversarial responses. Our code and dataset will be released if the paper is accepted",
    "checked": true,
    "id": "82eea58ca6e16e7b2df9a6f76b796da5a7cfcbc5",
    "semantic_title": "pneg: prompt-based negative response generation for dialogue response selection task",
    "citation_count": 4,
    "authors": [
      "Nyoungwoo Lee",
      "ChaeHun Park",
      "Ho-Jin Choi",
      "Jaegul Choo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.734": {
    "title": "Facilitating Contrastive Learning of Discourse Relational Senses by Exploiting the Hierarchy of Sense Relations",
    "volume": "main",
    "abstract": "Implicit discourse relation recognition is a challenging task that involves identifying the sense or senses that hold between two adjacent spans of text, in the absense of an explicit connective between them. In both PDTB-2 (prasad et al., 2008) and PDTB-3 (Webber et al., 2019), discourse relational senses are organized into a three-level hierarchy ranging from four broad top-level senses, to more specific senses below them. Most previous work on implicitf discourse relation recognition have used the sense hierarchy simply to indicate what sense labels were available. Here we do more — incorporating the sense hierarchy into the recognition process itself and using it to select the negative examples used in contrastive learning. With no additional effort, the approach achieves state-of-the-art performance on the task. Our code is released in https://github.com/wanqiulong0923/Contrastive_IDRR",
    "checked": true,
    "id": "5408d49eb9772b0e552b66bef1aa8545d813e9d6",
    "semantic_title": "facilitating contrastive learning of discourse relational senses by exploiting the hierarchy of sense relations",
    "citation_count": 14,
    "authors": [
      "Wanqiu Long",
      "Bonnie Webber"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.735": {
    "title": "Simplified Graph Learning for Inductive Short Text Classification",
    "volume": "main",
    "abstract": "Short text classification (STC) is hard as short texts lack context information and labeled data is not enough. Graph neural networks obtain the state-of-the-art on STC since they can merge various auxiliary information via the message passing framework. However, existing works conduct transductive learning, which requires retraining to accommodate new samples and takes large memory. In this paper, we present SimpleSTC which handles inductive STC problem but only leverages words. We construct word graph from an external large corpus to compensate for the lack of semantic information, and learn text graph to handle the lack of labeled data. Results show that SimpleSTC obtains state-of-the-art performance with lower memory consumption and faster inference speed",
    "checked": true,
    "id": "24b7b41472c0b4566c041ea8c41f807827fbf5c9",
    "semantic_title": "simplified graph learning for inductive short text classification",
    "citation_count": 5,
    "authors": [
      "Kaixin Zheng",
      "Yaqing Wang",
      "Quanming Yao",
      "Dejing Dou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.736": {
    "title": "Don't Stop Fine-Tuning: On Training Regimes for Few-Shot Cross-Lingual Transfer with Multilingual Language Models",
    "volume": "main",
    "abstract": "A large body of recent work highlights the fallacies of zero-shot cross-lingual transfer (ZS-XLT) with large multilingual language models. Namely, their performance varies substantially for different target languages and is the weakest where needed the most: for low-resource languages distant to the source language. One remedy is few-shot transfer (FS-XLT), where leveraging only a few task-annotated instances in the target language(s) may yield sizable performance gains. However, FS-XLT also succumbs to large variation, as models easily overfit to the small datasets. In this work, we present a systematic study focused on a spectrum of FS-XLT fine-tuning regimes, analyzing key properties such as effectiveness, (in)stability, and modularity. We conduct extensive experiments on both higher-level (NLI, paraphrasing) and lower-level tasks (NER, POS), presenting new FS-XLT strategies that yield both improved and more stable FS-XLT across the board. Our findings challenge established FS-XLT methods: e.g., we propose to replace sequential fine-tuning with joint fine-tuning on source and target language instances, offering consistent gains with different number of shots (including resource-rich scenarios). We also show that further gains can be achieved with multi-stage FS-XLT training in which joint multilingual fine-tuning precedes the bilingual source-target specialization",
    "checked": true,
    "id": "6aca5e5d6919dcc6986813b16a910b8db41b59f4",
    "semantic_title": "don't stop fine-tuning: on training regimes for few-shot cross-lingual transfer with multilingual language models",
    "citation_count": 16,
    "authors": [
      "Fabian David Schmidt",
      "Ivan Vulić",
      "Goran Glavaš"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.737": {
    "title": "Towards Compositional Generalization in Code Search",
    "volume": "main",
    "abstract": "We study compositional generalization, which aims to generalize on unseen combinations of seen structural elements, for code search. Unlike existing approaches of partially pursuing this goal, we study how to extract structural elements, which we name a template that directly targets compositional generalization. Thus we propose CTBERT, or Code Template BERT, representing codes using automatically extracted templates as building blocks. We empirically validate CTBERT on two public code search benchmarks, AdvTest and CSN. Further, we show that templates are complementary to data flow graphs in GraphCodeBERT, by enhancing structural context around variables",
    "checked": true,
    "id": "4b99104d817b195273ff78a152beca24bf4248a2",
    "semantic_title": "towards compositional generalization in code search",
    "citation_count": 0,
    "authors": [
      "Hojae Han",
      "Seung-won Hwang",
      "Shuai Lu",
      "Nan Duan",
      "Seungtaek Choi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.738": {
    "title": "Towards relation extraction from speech",
    "volume": "main",
    "abstract": "Relation extraction typically aims to extract semantic relationships between entities from the unstructured text. One of the most essential data sources for relation extraction is the spoken language, such as interviews and dialogues. However, the error propagation introduced in automatic speech recognition (ASR) has been ignored in relation extraction, and the end-to-end speech-based relation extraction method has been rarely explored. In this paper, we propose a new listening information extraction task, i.e., speech relation extraction. We construct the training dataset for speech relation extraction via text-to-speech systems, and we construct the testing dataset via crowd-sourcing with native English speakers. We explore speech relation extraction via two approaches: the pipeline approach conducting text-based extraction with a pretrained ASR module, and the end2end approach via a new proposed encoder-decoder model, or what we called SpeechRE.We conduct comprehensive experiments to distinguish the challenges in speech relation extraction, which may shed light on future explorations. We share the code and data on https://github.com/wutong8023/SpeechRE",
    "checked": true,
    "id": "4bdcfb8bc450987c4f91c1cb6598fab04a96cf5c",
    "semantic_title": "towards relation extraction from speech",
    "citation_count": 8,
    "authors": [
      "Tongtong Wu",
      "Guitao Wang",
      "Jinming Zhao",
      "Zhaoran Liu",
      "Guilin Qi",
      "Yuan-Fang Li",
      "Gholamreza Haffari"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.739": {
    "title": "Structural Constraints and Natural Language Inference for End-to-End Flowchart Grounded Dialog Response Generation",
    "volume": "main",
    "abstract": "Flowchart grounded dialog systems converse with users by following a given flowchart and a corpus of FAQs. The existing state-of-the-art approach (Raghu et al, 2021) for learning such a dialog system, named FLONET, has two main limitations. (1) It uses a Retrieval Augmented Generation (RAG) framework which represents a flowchart as a bag of nodes. By doing so, it loses the connectivity structure between nodes that can aid in better response generation. (2) Typically dialogs progress with the agent asking polar (Y/N) questions, but users often respond indirectly without the explicit use of polar words. In such cases, it fails to understand the correct polarity of the answer. To overcome these issues, we propose Structure-Aware FLONET (SA-FLONET) which infuses structural constraints derived from the connectivity structure of flowcharts into the RAG framework. It uses natural language inference to better predict the polarity of indirect Y/N answers. We find that SA-FLONET outperforms FLONET, with a success rate improvement of 68% and 123% in flowchart grounded response generation and zero-shot flowchart grounded response generation tasks respectively",
    "checked": true,
    "id": "1b46f99a9c1b481cfa4cf7cf50e994bb9cc0b2d9",
    "semantic_title": "structural constraints and natural language inference for end-to-end flowchart grounded dialog response generation",
    "citation_count": 0,
    "authors": [
      "Dinesh Raghu",
      "Suraj Joshi",
      "Sachindra Joshi",
      "Mausam -"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.740": {
    "title": "SLICER: Sliced Fine-Tuning for Low-Resource Cross-Lingual Transfer for Named Entity Recognition",
    "volume": "main",
    "abstract": "Large multilingual language models generally demonstrate impressive results in zero-shot cross-lingual transfer, yet often fail to successfully transfer to low-resource languages, even for token-level prediction tasks like named entity recognition (NER). In this work, we introduce a simple yet highly effective approach for improving zero-shot transfer for NER to low-resource languages. We observe that NER fine-tuning in the source language decontextualizes token representations, i.e., tokens increasingly attend to themselves. This increased reliance on token information itself, we hypothesize, triggers a type of overfitting to properties that NE tokens within the source languages share, but are generally not present in NE mentions of target languages. As a remedy, we propose a simple yet very effective sliced fine-tuning for NER (SLICER) that forces stronger token contextualization in the Transformer: we divide the transformed token representations and classifier into disjoint slices that are then independently classified during training. We evaluate SLICER on two standard benchmarks for NER that involve low-resource languages, WikiANN and MasakhaNER, and show that it (i) indeed reduces decontextualization (i.e., extent to which NE tokens attend to themselves), consequently (ii) yielding consistent transfer gains, especially prominent for low-resource target languages distant from the source language",
    "checked": true,
    "id": "114ddc45646ff59f13d818e3ca747614e80964d9",
    "semantic_title": "slicer: sliced fine-tuning for low-resource cross-lingual transfer for named entity recognition",
    "citation_count": 0,
    "authors": [
      "Fabian David Schmidt",
      "Ivan Vulić",
      "Goran Glavaš"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.741": {
    "title": "EdgeFormer: A Parameter-Efficient Transformer for On-Device Seq2seq Generation",
    "volume": "main",
    "abstract": "We introduce EdgeFormer – a parameter-efficient Transformer for on-device seq2seq generation under the strict computation and memory constraints. Compared with the previous parameter-efficient Transformers, EdgeFormer applies two novel principles for cost-effective parameterization, allowing it to perform better given the same parameter budget; moreover, EdgeFormer is further enhanced by layer adaptation innovation that is proposed for improving the network with shared layers. Extensive experiments show EdgeFormer can effectively outperform previous parameter-efficient Transformer baselines and achieve competitive results under both the computation and memory constraints. Given the promising results, we release EdgeLM – the pretrained version of EdgeFormer, which is the first publicly available pretrained on-device seq2seq model that can be easily fine-tuned for seq2seq tasks with strong results, facilitating on-device seq2seq generation in practice",
    "checked": true,
    "id": "886b460c87555fe073174d207d9721557b14b9d9",
    "semantic_title": "edgeformer: a parameter-efficient transformer for on-device seq2seq generation",
    "citation_count": 11,
    "authors": [
      "Tao Ge",
      "Si-Qing Chen",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.742": {
    "title": "End-to-End Unsupervised Vision-and-Language Pre-training with Referring Expression Matching",
    "volume": "main",
    "abstract": "Recently there has been an emerging interest in unsupervised vision-and-language pre-training (VLP) that learns multimodal representations without parallel image-caption data. These pioneering works significantly reduce the cost of VLP on data collection and achieve promising results compared to supervised VLP. However, existing unsupervised VLP methods take as input pre-extracted region-based visual features from external object detectors, which both limits flexibility and reduces computational efficiency. In this paper, we explore end-to-end unsupervised VLP with a vision encoder to directly encode images. The vision encoder is pre-trained on image-only data and jointly optimized during multimodal pre-training. To further enhance the learned cross-modal features, we propose a novel pre-training task that predicts which patches contain an object referred to in natural language from the encoded visual features. Extensive experiments on four vision-and-language tasks show that our approach outperforms previous unsupervised VLP methods and obtains new state-of-the-art results",
    "checked": true,
    "id": "9225b5cae29be4ca2d37a94bd1b24a6e67f583fd",
    "semantic_title": "end-to-end unsupervised vision-and-language pre-training with referring expression matching",
    "citation_count": 3,
    "authors": [
      "Chi Chen",
      "Peng Li",
      "Maosong Sun",
      "Yang Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.743": {
    "title": "Faithful Knowledge Graph Explanations in Commonsense Question Answering",
    "volume": "main",
    "abstract": "Knowledge graphs are commonly used as sources of information in commonsense question answering, and can also be used to express explanations for the model's answer choice. A common way of incorporating facts from the graph is to encode them separately from the question, and then combine the two representations to select an answer. In this paper, we argue that highly faithful graph-based explanations cannot be extracted from existing models of this type. Such explanations will not include reasoning done by the transformer encoding the question, so will be incomplete. We confirm this theory with a novel proxy measure for faithfulness and propose two architecture changes to address the problem. Our findings suggest a path forward for developing architectures for faithful graph-based explanations",
    "checked": true,
    "id": "f5f1004674a2b5bd882f8fe125d71c9fdbfd9b5b",
    "semantic_title": "faithful knowledge graph explanations in commonsense question answering",
    "citation_count": 2,
    "authors": [
      "Guy Aglionby",
      "Simone Teufel"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.744": {
    "title": "KOLD: Korean Offensive Language Dataset",
    "volume": "main",
    "abstract": "Recent directions for offensive language detection are hierarchical modeling, identifying the type and the target of offensive language, and interpretability with offensive span annotation and prediction. These improvements are focused on English and do not transfer well to other languages because of cultural and linguistic differences. In this paper, we present the Korean Offensive Language Dataset (KOLD) comprising 40,429 comments, which are annotated hierarchically with the type and the target of offensive language, accompanied by annotations of the corresponding text spans. We collect the comments from NAVER news and YouTube platform and provide the titles of the articles and videos as the context information for the annotation process. We use these annotated comments as training data for Korean BERT and RoBERTa models and find that they are effective at offensiveness detection, target classification, and target span detection while having room for improvement for target group classification and offensive span detection. We discover that the target group distribution differs drastically from the existing English datasets, and observe that providing the context information improves the model performance in offensiveness detection (+0.3), target classification (+1.5), and target group classification (+13.1). We publicly release the dataset and baseline models",
    "checked": true,
    "id": "82159bec7a4f9e399af1b632d56bb7f98439810e",
    "semantic_title": "kold: korean offensive language dataset",
    "citation_count": 16,
    "authors": [
      "Younghoon Jeong",
      "Juhyun Oh",
      "Jongwon Lee",
      "Jaimeen Ahn",
      "Jihyung Moon",
      "Sungjoon Park",
      "Alice Oh"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.745": {
    "title": "Evade the Trap of Mediocrity: Promoting Diversity and Novelty in Text Generation via Concentrating Attention",
    "volume": "main",
    "abstract": "Recently, powerful Transformer architectures have proven superior in generating high-quality sentences. Nevertheless, these models tend to produce dull high-frequency phrases, severely hurting the diversity and novelty of generated text. In this work, we dig into the intrinsic mechanism of this problem and found that sparser attention values in Transformer could improve diversity. To understand such a phenomenon, we first conduct both empirical and theoretical analysis and then attribute it to representation degeneration caused by the attentive mixture of the hidden states during training. We term this process the Trap of Mediocrity. To escape from such a trap, we introduce a novel attention regularization loss to control the sharpness of the attention distribution, which is transparent to model structures and can be easily implemented within 20 lines of python code. We prove that this method could be mathematically regarded as learning a Bayesian approximation of posterior attention. Experiments show that our method improved the diversity and novelty of the generated text while maintaining comparable quality on a variety of conditional and unconditional generation tasks",
    "checked": true,
    "id": "82df0e8419fe147a6c0fa9a8c7f69d6b85931865",
    "semantic_title": "evade the trap of mediocrity: promoting diversity and novelty in text generation via concentrating attention",
    "citation_count": 0,
    "authors": [
      "Wenhao Li",
      "Xiaoyuan Yi",
      "Jinyi Hu",
      "Maosong Sun",
      "Xing Xie"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.746": {
    "title": "The better your Syntax, the better your Semantics? Probing Pretrained Language Models for the English Comparative Correlative",
    "volume": "main",
    "abstract": "Construction Grammar (CxG) is a paradigm from cognitive linguistics emphasising the connection between syntax and semantics. Rather than rules that operate on lexical items, it posits constructions as the central building blocks of language, i.e., linguistic units of different granularity that combine syntax and semantics. As a first step towards assessing the compatibility of CxG with the syntactic and semantic knowledge demonstrated by state-of-the-art pretrained language models (PLMs), we present an investigation of their capability to classify and understand one of the most commonly studied constructions, the English comparative correlative (CC). We conduct experiments examining the classification accuracy of a syntactic probe on the one hand and the models' behaviour in a semantic application task on the other, with BERT, RoBERTa, and DeBERTa as the example PLMs. Our results show that all three investigated PLMs are able to recognise the structure of the CC but fail to use its meaning. While human-like performance of PLMs on many NLP tasks has been alleged, this indicates that PLMs still suffer from substantial shortcomings in central domains of linguistic knowledge",
    "checked": true,
    "id": "21fc58eea259e101318a9a4c8ddb03c001b3ada7",
    "semantic_title": "the better your syntax, the better your semantics? probing pretrained language models for the english comparative correlative",
    "citation_count": 18,
    "authors": [
      "Leonie Weissweiler",
      "Valentin Hofmann",
      "Abdullatif Köksal",
      "Hinrich Schütze"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.747": {
    "title": "ProofInfer: Generating Proof via Iterative Hierarchical Inference",
    "volume": "main",
    "abstract": "Proof generation focuses on deductive reasoning: given a hypothesis and a set of theories, including some supporting facts and logical rules expressed in natural language, the model generates a proof tree indicating how to deduce the hypothesis from given theories. Current models with state-of-the-art performance employ the stepwise method that adds an individual node to the proof step-by-step. However, these methods actually focus on generating several proof paths rather than a whole tree. During generation, they focus on the most relevant areas of the currently generated node while neglecting the rest of the proof tree. To address this problem, we propose ProofInfer, which generates the proof tree via iterative hierarchical inference. At each step, ProofInfer adds the entire layer to the proof, where all nodes in this layer are generated simultaneously. Since the conventional autoregressive generation architecture cannot simultaneously predict multiple nodes, ProofInfer employs text-to-text paradigm. To this end, we propose a divide-and-conquer algorithm to encode the proof tree as the plain text without losing structure information. Experimental results show that ProofInfer significantly improves performance on several widely-used datasets. In addition, ProofInfer still performs well with data-limited, achieving comparable performance to the state-of-the-art model with about 40% of the training data",
    "checked": true,
    "id": "38a11b4988088373b2fc34cd6d99736adfda8ee1",
    "semantic_title": "proofinfer: generating proof via iterative hierarchical inference",
    "citation_count": 0,
    "authors": [
      "Zichu Fei",
      "Qi Zhang",
      "Xin Zhou",
      "Tao Gui",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.748": {
    "title": "ECTSum: A New Benchmark Dataset For Bullet Point Summarization of Long Earnings Call Transcripts",
    "volume": "main",
    "abstract": "Despite tremendous progress in automatic summarization, state-of-the-art methods are predominantly trained to excel in summarizing short newswire articles, or documents with strong layout biases such as scientific articles or government reports. Efficient techniques to summarize financial documents, discussing facts and figures, have largely been unexplored, majorly due to the unavailability of suitable datasets. In this work, we present ECTSum, a new dataset with transcripts of earnings calls (ECTs), hosted by publicly traded companies, as documents, and experts-written short telegram-style bullet point summaries derived from corresponding Reuters articles. ECTs are long unstructured documents without any prescribed length limit or format. We benchmark our dataset with state-of-the-art summarization methods across various metrics evaluating the content quality and factual consistency of the generated summaries. Finally, we present a simple yet effective approach, ECT-BPS, to generate a set of bullet points that precisely capture the important facts discussed in the calls",
    "checked": true,
    "id": "9c1f2985d9f2cc03f78c813b61641318bc794d0d",
    "semantic_title": "ectsum: a new benchmark dataset for bullet point summarization of long earnings call transcripts",
    "citation_count": 10,
    "authors": [
      "Rajdeep Mukherjee",
      "Abhinav Bohra",
      "Akash Banerjee",
      "Soumya Sharma",
      "Manjunath Hegde",
      "Afreen Shaikh",
      "Shivani Shrivastava",
      "Koustuv Dasgupta",
      "Niloy Ganguly",
      "Saptarshi Ghosh",
      "Pawan Goyal"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.749": {
    "title": "Cross-domain Generalization for AMR Parsing",
    "volume": "main",
    "abstract": "Abstract Meaning Representation (AMR) parsing aims to predict an AMR graph from textual input. Recently, there has been notable growth in AMR parsing performance. However, most existing work focuses on improving the performance in the specific domain, ignoring the potential domain dependence of AMR parsing systems. To address this, we extensively evaluate five representative AMR parsers on five domains and analyze challenges to cross-domain AMR parsing. We observe that challenges to cross-domain AMR parsing mainly arise from the distribution shift of words and AMR concepts. Based on our observation, we investigate two approaches to reduce the domain distribution divergence of text and AMR features, respectively. Experimental results on two out-of-domain test sets show the superiority of our method",
    "checked": true,
    "id": "53607fe723da15a943a39631c00b43e34a306511",
    "semantic_title": "cross-domain generalization for amr parsing",
    "citation_count": 2,
    "authors": [
      "Xuefeng Bai",
      "Sen Yang",
      "Leyang Cui",
      "Linfeng Song",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.750": {
    "title": "CiteSum: Citation Text-guided Scientific Extreme Summarization and Domain Adaptation with Limited Supervision",
    "volume": "main",
    "abstract": "Scientific extreme summarization (TLDR) aims to form ultra-short summaries of scientific papers. Previous efforts on curating scientific TLDR datasets failed to scale up due to the heavy human annotation and domain expertise required. In this paper, we propose a simple yet effective approach to automatically extracting TLDR summaries for scientific papers from their citation texts. Based on the proposed approach, we create a new benchmark CiteSum without human annotation, which is around 30 times larger than the previous human-curated dataset SciTLDR. We conduct a comprehensive analysis of CiteSum, examining its data characteristics and establishing strong baselines. We further demonstrate the usefulness of CiteSum by adapting models pre-trained on CiteSum (named CITES) to new tasks and domains with limited supervision. For scientific extreme summarization, CITES outperforms most fully-supervised methods on SciTLDR without any fine-tuning and obtains state-of-the-art results with only 128 examples. For news extreme summarization, CITES achieves significant gains on XSum over its base model (not pre-trained on CiteSum), e.g., +7.2 ROUGE-1 zero-shot performance and state-of-the-art few-shot performance. For news headline generation, CITES performs the best among unsupervised and zero-shot methods on Gigaword",
    "checked": true,
    "id": "c4b37f29253882031c3f799b34187015ca803667",
    "semantic_title": "citesum: citation text-guided scientific extreme summarization and domain adaptation with limited supervision",
    "citation_count": 10,
    "authors": [
      "Yuning Mao",
      "Ming Zhong",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.751": {
    "title": "FETA: A Benchmark for Few-Sample Task Transfer in Open-Domain Dialogue",
    "volume": "main",
    "abstract": "Task transfer, transferring knowledge contained in related tasks, holds the promise of reducing the quantity of labeled data required to fine-tune language models. Dialogue understanding encompasses many diverse tasks, yet task transfer has not been thoroughly studied in conversational AI. This work explores conversational task transfer by introducing FETA: a benchmark for FEw-sample TAsk transfer in open-domain dialogue.FETA contains two underlying sets of conversations upon which there are 10 and 7 tasks annotated, enabling the study of intra-dataset task transfer; task transfer without domain adaptation. We utilize three popular language models and three learning algorithms to analyze the transferability between 132 source-target task pairs and create a baseline for future work. We run experiments in the single- and multi-source settings and report valuable findings, e.g., most performance trends are model-specific, and span extraction and multiple-choice tasks benefit the most from task transfer. In addition to task transfer, FETA can be a valuable resource for future research into the efficiency and generalizability of pre-training datasets and model architectures, as well as for learning settings such as continual and multitask learning",
    "checked": true,
    "id": "59707fbd3308257628470d94e56c8165bf4e1cff",
    "semantic_title": "feta: a benchmark for few-sample task transfer in open-domain dialogue",
    "citation_count": 9,
    "authors": [
      "Alon Albalak",
      "Yi-Lin Tuan",
      "Pegah Jandaghi",
      "Connor Pryor",
      "Luke Yoffe",
      "Deepak Ramachandran",
      "Lise Getoor",
      "Jay Pujara",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.752": {
    "title": "Do Children Texts Hold The Key To Commonsense Knowledge?",
    "volume": "main",
    "abstract": "Compiling comprehensive repositories of commonsense knowledge is a long-standing problem in AI. Many concerns revolve around the issue of reporting bias, i.e., that frequency in text sources is not a good proxy for relevance or truth. This paper explores whether children's texts hold the key to commonsense knowledge compilation, based on the hypothesis that such content makes fewer assumptions on the reader's knowledge, and therefore spells out commonsense more explicitly. An analysis with several corpora shows that children's texts indeed contain much more, and more typical commonsense assertions. Moreover, experiments show that this advantage can be leveraged in popular language-model-based commonsense knowledge extraction settings, where task-unspecific fine-tuning on small amounts of children texts (childBERT) already yields significant improvements. This provides a refreshing perspective different from the common trend of deriving progress from ever larger models and corpora",
    "checked": true,
    "id": "eaec704a9a2ebe5b045dc23246640e6561bc276e",
    "semantic_title": "do children texts hold the key to commonsense knowledge?",
    "citation_count": 1,
    "authors": [
      "Julien Romero",
      "Simon Razniewski"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.753": {
    "title": "On the Limitations of Reference-Free Evaluations of Generated Text",
    "volume": "main",
    "abstract": "There is significant interest in developing evaluation metrics which accurately estimate the quality of generated text without the aid of a human-written reference text, which can be time consuming and expensive to collect or entirely unavailable in online applications. However, in this work, we demonstrate that these reference-free metrics are inherently biased and limited in their ability to evaluate generated text, and we argue that they should not be used to measure progress on tasks like machine translation or summarization. We show how reference-free metrics are equivalent to using one generation model to evaluate another, which has several limitations: (1) the metrics can be optimized at test time to find the approximate best-possible output, (2) they are inherently biased toward models which are more similar to their own, and (3) they can be biased against higher-quality outputs, including those written by humans. Therefore, we recommend that reference-free metrics should be used as diagnostic tools for analyzing and understanding model behavior instead of measures of how well models perform a task, in which the goal is to achieve as high of a score as possible",
    "checked": true,
    "id": "b5306e0217eb51e1fbaee1c39522750f9f294b1a",
    "semantic_title": "on the limitations of reference-free evaluations of generated text",
    "citation_count": 17,
    "authors": [
      "Daniel Deutsch",
      "Rotem Dror",
      "Dan Roth"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.754": {
    "title": "Sampling-Based Approximations to Minimum Bayes Risk Decoding for Neural Machine Translation",
    "volume": "main",
    "abstract": "In NMT we search for the mode of the model distribution to form predictions. The mode and other high-probability translations found by beam search have been shown to often be inadequate in a number of ways. This prevents improving translation quality through better search, as these idiosyncratic translations end up selected by the decoding algorithm, a problem known as the beam search curse. Recently, an approximation to minimum Bayes risk (MBR) decoding has been proposed as an alternative decision rule that would likely not suffer from the same problems. We analyse this approximation and establish that it has no equivalent to the beam search curse. We then design approximations that decouple the cost of exploration from the cost of robust estimation of expected utility. This allows for much larger hypothesis spaces, which we show to be beneficial. We also show that mode-seeking strategies can aid in constructing compact sets of promising hypotheses and that MBR is effective in identifying good translations in them. We conduct experiments on three language pairs varying in amounts of resources available: English into and from German, Romanian, and Nepali",
    "checked": true,
    "id": "f65a1b74daf26ac495982ba8e3b4484cdd0688ae",
    "semantic_title": "sampling-based approximations to minimum bayes risk decoding for neural machine translation",
    "citation_count": 23,
    "authors": [
      "Bryan Eikema",
      "Wilker Aziz"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.755": {
    "title": "IndicXNLI: Evaluating Multilingual Inference for Indian Languages",
    "volume": "main",
    "abstract": "While Indic NLP has made rapid advances recently in terms of the availability of corpora and pre-trained models, benchmark datasets on standard NLU tasks are limited. To this end, we introduce INDICXNLI, an NLI dataset for 11 Indic languages. It has been created by high-quality machine translation of the original English XNLI dataset and our analysis attests to the quality of INDICXNLI. By finetuning different pre-trained LMs on this INDICXNLI, we analyze various cross-lingual transfer techniques with respect to the impact of the choice of language models, languages, multi-linguality, mix-language input, etc. These experiments provide us with useful insights into the behaviour of pre-trained models for a diverse set of languages",
    "checked": true,
    "id": "1141aa5ee59a19844e00611c97efa39689906a69",
    "semantic_title": "indicxnli: evaluating multilingual inference for indian languages",
    "citation_count": 12,
    "authors": [
      "Divyanshu Aggarwal",
      "Vivek Gupta",
      "Anoop Kunchukuttan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.756": {
    "title": "Model Cascading: Towards Jointly Improving Efficiency and Accuracy of NLP Systems",
    "volume": "main",
    "abstract": "Do all instances need inference through the big models for a correct prediction? Perhaps not; some instances are easy and can be answered correctly by even small capacity models. This provides opportunities for improving the computational efficiency of systems. In this work, we present an explorative study on ‘model cascading', a simple technique that utilizes a collection of models of varying capacities to accurately yet efficiently output predictions. Through comprehensive experiments in multiple task settings that differ in the number of models available for cascading (K value), we show that cascading improves both the computational efficiency and the prediction accuracy. For instance, in K=3 setting, cascading saves up to 88.93% computation cost and consistently achieves superior prediction accuracy with an improvement of up to 2.18%. We also study the impact of introducing additional models in the cascade and show that it further increases the efficiency improvements. Finally, we hope that our work will facilitate development of efficient NLP systems making their widespread adoption in real-world applications possible",
    "checked": true,
    "id": "5bb42863524b0ae4e5a47c46c53d9e7ec9552fef",
    "semantic_title": "model cascading: towards jointly improving efficiency and accuracy of nlp systems",
    "citation_count": 14,
    "authors": [
      "Neeraj Varshney",
      "Chitta Baral"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.757": {
    "title": "Semantic Simplification for Sentiment Classification",
    "volume": "main",
    "abstract": "Recent work on document-level sentiment classification has shown that the sentiment in the original text is often hard to capture, since the sentiment is usually either expressed implicitly or shifted due to the occurrences of negation and rhetorical words. To this end, we enhance the original text with a sentiment-driven simplified clause to intensify its sentiment. The simplified clause shares the same opinion with the original text but expresses the opinion much more simply. Meanwhile, we employ Abstract Meaning Representation (AMR) for generating simplified clauses, since AMR explicitly provides core semantic knowledge, and potentially offers core concepts and explicit structures of original texts. Empirical studies show the effectiveness of our proposed model over several strong baselines. The results also indicate the importance of simplified clauses for sentiment classification",
    "checked": true,
    "id": "89087c3cbf2feb7f0f417fb01316028e13dfe3ce",
    "semantic_title": "semantic simplification for sentiment classification",
    "citation_count": 2,
    "authors": [
      "Xiaotong Jiang",
      "Zhongqing Wang",
      "Guodong Zhou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.758": {
    "title": "XPrompt: Exploring the Extreme of Prompt Tuning",
    "volume": "main",
    "abstract": "Prompt tuning learns soft prompts to condition the frozen Pre-trained Language Models (PLMs) for performing downstream tasks in a parameter-efficient manner. While prompt tuning has gradually reached the performance level of fine-tuning as the model scale increases, there is still a large performance gap between prompt tuning and fine-tuning for models of moderate and small scales (typically less than 11B parameters). In this paper, we empirically show that the trained prompt tokens can have a negative impact on a downstream task and thus degrade its performance. To bridge the gap, we propose a novel Prompt tuning model with an eXtremely small scale (XPrompt) under the regime of lottery tickets hypothesis. Specifically, XPrompt eliminates the negative prompt tokens at different granularity levels through a hierarchical structured pruning, yielding a more parameter-efficient prompt yet with a competitive performance. Comprehensive experiments are carried out on the SuperGLUE tasks, and the results indicate that XPrompt is able to close the performance gap at smaller model scales",
    "checked": true,
    "id": "40e49ba41eca31f9c2661cc65f2c13dc4f2c7859",
    "semantic_title": "xprompt: exploring the extreme of prompt tuning",
    "citation_count": 15,
    "authors": [
      "Fang Ma",
      "Chen Zhang",
      "Lei Ren",
      "Jingang Wang",
      "Qifan Wang",
      "Wei Wu",
      "Xiaojun Quan",
      "Dawei Song"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.759": {
    "title": "Rethinking the Role of Demonstrations: What Makes In-Context Learning Work?",
    "volume": "main",
    "abstract": "Large language models (LMs) are able to in-context learn—perform a new task via inference alone by conditioning on a few input-label pairs (demonstrations) and making predictions for new inputs. However, there has been little understanding of how the model learns and which aspects of the demonstrations contribute to end task performance. In this paper, we show that ground truth demonstrations are in fact not required—randomly replacing labels in the demonstrations barely hurts performance on a range of classification and multi-choce tasks, consistently over 12 different models including GPT-3. Instead, we find that other aspects of the demonstrations are the key drivers of endtask performance, including the fact that they provide a few examples of (1) the label space, (2) the distribution of the input text, and (3) the overall format of the sequence. Together, our analysis provides a new way of understanding how and why in-context learning works, while opening up new questions about how much can be learned from large language models through inference alone",
    "checked": true,
    "id": "87e02a265606f31e65986f3c1c448a3e3a3a066e",
    "semantic_title": "rethinking the role of demonstrations: what makes in-context learning work?",
    "citation_count": 718,
    "authors": [
      "Sewon Min",
      "Xinxi Lyu",
      "Ari Holtzman",
      "Mikel Artetxe",
      "Mike Lewis",
      "Hannaneh Hajishirzi",
      "Luke Zettlemoyer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.760": {
    "title": "The Curious Case of Control",
    "volume": "main",
    "abstract": "Children acquiring English make systematic errors on subject control sentences even after they have reached near-adult competence (Chomsky, 1969), possibly due to heuristics based on semantic roles (Maratsos, 1974).Given the advanced fluency of large generative language models, we ask whether model outputs are consistent with these heuristics, and to what degree different models are consistent with each other. We find that models can be categorized by behavior into three separate groups, with broad differences between the groups. The outputs of models in the largest group are consistent with positional heuristics that succeed on subject control but fail on object control. This result is surprising, given that object control is orders of magnitude more frequent in the text data used to train such models. We examine to what degree the models are sensitive to prompting with agent-patient information, finding that raising the salience of agent and patient relations results in significant changes in the outputs of most models. Based on this observation, we leverage an existing dataset of semantic proto-role annotations (White et al. 2020) to explore the connections between control and labeling event participants with properties typically associated with agents and patients",
    "checked": true,
    "id": "a3780e8f45b6c1ab3e27c0ad87c3ea23176dc8a7",
    "semantic_title": "the curious case of control",
    "citation_count": 0,
    "authors": [
      "Elias Stengel-Eskin",
      "Benjamin Van Durme"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.761": {
    "title": "SHARE: a System for Hierarchical Assistive Recipe Editing",
    "volume": "main",
    "abstract": "The large population of home cooks with dietary restrictions is under-served by existing cooking resources and recipe generation models. To help them, we propose the task of controllable recipe editing: adapt a base recipe to satisfy a user-specified dietary constraint. This task is challenging, and cannot be adequately solved with human-written ingredient substitution rules or existing end-to-end recipe generation models. We tackle this problem with SHARE: a System for Hierarchical Assistive Recipe Editing, which performs simultaneous ingredient substitution before generating natural-language steps using the edited ingredients. By decoupling ingredient and step editing, our step generator can explicitly integrate the available ingredients. Experiments on the novel RecipePairs dataset—83K pairs of similar recipes where each recipe satisfies one of seven dietary constraints—demonstrate that SHARE produces convincing, coherent recipes that are appropriate for a target dietary constraint. We further show through human evaluations and real-world cooking trials that recipes edited by SHARE can be easily followed by home cooks to create appealing dishes",
    "checked": true,
    "id": "5480cf7fd2fb7f62153bd7c1a6b7edbef0744e26",
    "semantic_title": "share: a system for hierarchical assistive recipe editing",
    "citation_count": 12,
    "authors": [
      "Shuyang Li",
      "Yufei Li",
      "Jianmo Ni",
      "Julian McAuley"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.762": {
    "title": "IM2: an Interpretable and Multi-category Integrated Metric Framework for Automatic Dialogue Evaluation",
    "volume": "main",
    "abstract": "Evaluation metrics shine the light on the best models and thus strongly influence the research directions, such as the recently developed dialogue metrics USR, FED, and GRADE. However, most current metrics evaluate the dialogue data as isolated and static because they only focus on a single quality or several qualities. To mitigate the problem, this paper proposes an interpretable, multi-faceted, and controllable framework IM^2 (Interpretable and Multi-category Integrated Metric) to combine a large number of metrics which are good at measuring different qualities. The IM^2 framework first divides current popular dialogue qualities into different categories and then applies or proposes dialogue metrics to measure the qualities within each category and finally generates an overall IM^2 score. An initial version of IM^2 was submitted to the AAAI 2022 Track5.1@DSTC10 challenge and took the 2^nd place on both of the development and test leaderboard. After the competition, we develop more metrics and improve the performance of our model. We compare IM^2 with other 13 current dialogue metrics and experimental results show that IM^2 correlates more strongly with human judgments than any of them on each evaluated dataset",
    "checked": true,
    "id": "5a2a22d322183584d7a319718582086a65362937",
    "semantic_title": "im^2: an interpretable and multi-category integrated metric framework for automatic dialogue evaluation",
    "citation_count": 3,
    "authors": [
      "Zhihua Jiang",
      "Guanghui Ye",
      "Dongning Rao",
      "Di Wang",
      "Xin Miao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.763": {
    "title": "PEVL: Position-enhanced Pre-training and Prompt Tuning for Vision-language Models",
    "volume": "main",
    "abstract": "Vision-language pre-training (VLP) has shown impressive performance on a wide range of cross-modal tasks, where VLP models without reliance on object detectors are becoming the mainstream due to their superior computation efficiency and competitive performance. However, the removal of object detectors also deprives the capability of VLP models in explicit object modeling, which is essential to various position-sensitive vision-language (VL) tasks, such as referring expression comprehension and visual commonsense reasoning. To address the challenge, we introduce PEVL that enhances the pre-training and prompt tuning of VLP models with explicit object position modeling. Specifically, PEVL reformulates discretized object positions and language in a unified language modeling framework, which facilitates explicit VL alignment during pre-training, and also enables flexible prompt tuning for various downstream tasks. We show that PEVL enables state-of-the-art performance of detector-free VLP models on position-sensitive tasks such as referring expression comprehension and phrase grounding, and also improves the performance on position-insensitive tasks with grounded inputs. We make the data and code for this paper publicly available at https://github.com/thunlp/PEVL",
    "checked": true,
    "id": "c9cc62881bc4ef571785b06fd54d4e6adaecb321",
    "semantic_title": "pevl: position-enhanced pre-training and prompt tuning for vision-language models",
    "citation_count": 30,
    "authors": [
      "Yuan Yao",
      "Qianyu Chen",
      "Ao Zhang",
      "Wei Ji",
      "Zhiyuan Liu",
      "Tat-Seng Chua",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.764": {
    "title": "Pre-training Language Models with Deterministic Factual Knowledge",
    "volume": "main",
    "abstract": "Previous works show that Pre-trained Language Models (PLMs) can capture factual knowledge. However, some analyses reveal that PLMs fail to perform it robustly, e.g., being sensitive to the changes of prompts when extracting factual knowledge. To mitigate this issue, we propose to let PLMs learn the deterministic relationship between the remaining context and the masked content. The deterministic relationship ensures that the masked factual content can be deterministically inferable based on the existing clues in the context. That would provide more stable patterns for PLMs to capture factual knowledge than randomly masking. Two pre-training tasks are further introduced to motivate PLMs to rely on the deterministic relationship when filling masks. Specifically, we use an external Knowledge Base (KB) to identify deterministic relationships and continuously pre-train PLMs with the proposed methods. The factual knowledge probing experiments indicate that the continuously pre-trained PLMs achieve better robustness in factual knowledge capturing. Further experiments on question-answering datasets show that trying to learn a deterministic relationship with the proposed methods can also help other knowledge-intensive tasks",
    "checked": true,
    "id": "118e5b53976a69da9277cdb8d9ffcefa5a081340",
    "semantic_title": "pre-training language models with deterministic factual knowledge",
    "citation_count": 7,
    "authors": [
      "Shaobo Li",
      "Xiaoguang Li",
      "Lifeng Shang",
      "Chengjie Sun",
      "Bingquan Liu",
      "Zhenzhou Ji",
      "Xin Jiang",
      "Qun Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.765": {
    "title": "Finding Skill Neurons in Pre-trained Transformer-based Language Models",
    "volume": "main",
    "abstract": "Transformer-based pre-trained language models have demonstrated superior performance on various natural language processing tasks. However, it remains unclear how the skills required to handle these tasks distribute among model parameters. In this paper, we find that after prompt tuning for specific tasks, the activations of some neurons within pre-trained Transformers are highly predictive of the task labels. We dub these neurons skill neurons and confirm they encode task-specific skills by finding that: (1) Skill neurons are crucial for handling tasks. Performances of pre-trained Transformers on a task significantly drop when corresponding skill neurons are perturbed. (2) Skill neurons are task-specific. Similar tasks tend to have similar distributions of skill neurons. Furthermore, we demonstrate the skill neurons are most likely generated in pre-training rather than fine-tuning by showing that the skill neurons found with prompt tuning are also crucial for other fine-tuning methods freezing neuron weights, such as the adapter-based tuning and BitFit. We also explore the applications of skill neurons, including accelerating Transformers with network pruning and building better transferability indicators. These findings may promote further research on understanding Transformers. The source code can be obtained from https://github.com/THU-KEG/Skill-Neuron",
    "checked": true,
    "id": "5d3cf0909ba206cd6bc2e86610f77ca25d9b2d1c",
    "semantic_title": "finding skill neurons in pre-trained transformer-based language models",
    "citation_count": 32,
    "authors": [
      "Xiaozhi Wang",
      "Kaiyue Wen",
      "Zhengyan Zhang",
      "Lei Hou",
      "Zhiyuan Liu",
      "Juanzi Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.766": {
    "title": "Prompt Conditioned VAE: Enhancing Generative Replay for Lifelong Learning in Task-Oriented Dialogue",
    "volume": "main",
    "abstract": "Lifelong learning (LL) is vital for advanced task-oriented dialogue (ToD) systems. To address the catastrophic forgetting issue of LL, generative replay methods are widely employed to consolidate past knowledge with generated pseudo samples. However, most existing generative replay methods use only a single task-specific token to control their models. This scheme is usually not strong enough to constrain the generative model due to insufficient information involved. In this paper, we propose a novel method, prompt conditioned VAE for lifelong learning (PCLL), to enhance generative replay by incorporating tasks' statistics. PCLL captures task-specific distributions with a conditional variational autoencoder, conditioned on natural language prompts to guide the pseudo-sample generation. Moreover, it leverages a distillation process to further consolidate past knowledge by alleviating the noise in pseudo samples. Experiments on natural language understanding tasks of ToD systems demonstrate that PCLL significantly outperforms competitive baselines in building lifelong learning models",
    "checked": true,
    "id": "8d474304a985bfbe838ed3e068710cfb86ead2cf",
    "semantic_title": "prompt conditioned vae: enhancing generative replay for lifelong learning in task-oriented dialogue",
    "citation_count": 7,
    "authors": [
      "Yingxiu Zhao",
      "Yinhe Zheng",
      "Zhiliang Tian",
      "Chang Gao",
      "Jian Sun",
      "Nevin L. Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.767": {
    "title": "PreQuEL: Quality Estimation of Machine Translation Outputs in Advance",
    "volume": "main",
    "abstract": "We present the task of PreQuEL, Pre-(Quality-Estimation) Learning. A PreQuEL system predicts how well a given sentence will be translated, without recourse to the actual translation, thus eschewing unnecessary resource allocation when translation quality is bound to be low. PreQuEL can be defined relative to a given MT system (e.g., some industry service) or generally relative to the state-of-the-art. From a theoretical perspective, PreQuEL places the focus on the source text, tracing properties, possibly linguistic features, that make a sentence harder to machine translate. We develop a baseline model for the task and analyze its performance. We also develop a data augmentation method (from parallel corpora), that improves results substantially. We show that this augmentation method can improve the performance of the Quality-Estimation task as well. We investigate the properties of the input text that our model is sensitive to, by testing it on challenge sets and different languages. We conclude that it is aware of syntactic and semantic distinctions, and correlates and even over-emphasizes the importance of standard NLP features",
    "checked": true,
    "id": "88d24b4f19ee59da3b6932a2bd0eb794f9d40bf7",
    "semantic_title": "prequel: quality estimation of machine translation outputs in advance",
    "citation_count": 7,
    "authors": [
      "Shachar Don-Yehiya",
      "Leshem Choshen",
      "Omri Abend"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.768": {
    "title": "Can Transformers Reason in Fragments of Natural Language?",
    "volume": "main",
    "abstract": "State-of-the-art deep-learning-based approaches to Natural Language Processing (NLP) are credited with various capabilities that involve reasoning with natural language texts. %However, reasoning in this setting is often ill-defined and shallow. In this paper we carry out a large-scale empirical study investigating the detection of formally valid inferences in controlled fragments of natural language for which the satisfiability problem becomes increasingly complex. We find that, while transformer-based language models perform surprisingly well in these scenarios, a deeper analysis reveals that they appear to overfit to superficial patterns in the data rather than acquiring the logical principles governing the reasoning in these fragments",
    "checked": true,
    "id": "8ee376114a43432399554be39a79c1a2b6c65d51",
    "semantic_title": "can transformers reason in fragments of natural language?",
    "citation_count": 5,
    "authors": [
      "Viktor Schlegel",
      "Kamen Pavlov",
      "Ian Pratt-Hartmann"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.769": {
    "title": "Textless Speech Emotion Conversion using Discrete & Decomposed Representations",
    "volume": "main",
    "abstract": "Speech emotion conversion is the task of modifying the perceived emotion of a speech utterance while preserving the lexical content and speaker identity. In this study, we cast the problem of emotion conversion as a spoken language translation task. We use a decomposition of the speech signal into discrete learned representations, consisting of phonetic-content units, prosodic features, speaker, and emotion. First, we modify the speech content by translating the phonetic-content units to a target emotion, and then predict the prosodic features based on these units. Finally, the speech waveform is generated by feeding the predicted representations into a neural vocoder. Such a paradigm allows us to go beyond spectral and parametric changes of the signal, and model non-verbal vocalizations, such as laughter insertion, yawning removal, etc. We demonstrate objectively and subjectively that the proposed method is vastly superior to current approaches and even beats text-based systems in terms of perceived emotion and audio quality. We rigorously evaluate all components of such a complex system and conclude with an extensive model analysis and ablation study to better emphasize the architectural choices, strengths and weaknesses of the proposed method. Samples are available under the following link: https://speechbot.github.io/emotion",
    "checked": true,
    "id": "44ff1432414805bbbff7b7c814c758989d3028c9",
    "semantic_title": "textless speech emotion conversion using discrete & decomposed representations",
    "citation_count": 17,
    "authors": [
      "Felix Kreuk",
      "Adam Polyak",
      "Jade Copet",
      "Eugene Kharitonov",
      "Tu Anh Nguyen",
      "Morgan Rivière",
      "Wei-Ning Hsu",
      "Abdelrahman Mohamed",
      "Emmanuel Dupoux",
      "Yossi Adi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.770": {
    "title": "Textual Backdoor Attacks Can Be More Harmful via Two Simple Tricks",
    "volume": "main",
    "abstract": "Backdoor attacks are a kind of emergent security threat in deep learning. After being injected with a backdoor, a deep neural model will behave normally on standard inputs but give adversary-specified predictions once the input contains specific backdoor triggers. In this paper, we find two simple tricks that can make existing textual backdoor attacks much more harmful. The first trick is to add an extra training task to distinguish poisoned and clean data during the training of the victim model, and the second one is to use all the clean training data rather than remove the original clean data corresponding to the poisoned data. These two tricks are universally applicable to different attack models. We conduct experiments in three tough situations including clean data fine-tuning, low-poisoning-rate, and label-consistent attacks. Experimental results show that the two tricks can significantly improve attack performance. This paper exhibits the great potential harmfulness of backdoor attacks. All the code and data can be obtained at https://github.com/thunlp/StyleAttack",
    "checked": true,
    "id": "51f177a28b3c5918b6dfef7112859f1e433f33f7",
    "semantic_title": "textual backdoor attacks can be more harmful via two simple tricks",
    "citation_count": 9,
    "authors": [
      "Yangyi Chen",
      "Fanchao Qi",
      "Hongcheng Gao",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.771": {
    "title": "Why Should Adversarial Perturbations be Imperceptible? Rethink the Research Paradigm in Adversarial NLP",
    "volume": "main",
    "abstract": "Textual adversarial samples play important roles in multiple subfields of NLP research, including security, evaluation, explainability, and data augmentation. However, most work mixes all these roles, obscuring the problem definitions and research goals of the security role that aims to reveal the practical concerns of NLP models. In this paper, we rethink the research paradigm of textual adversarial samples in security scenarios. We discuss the deficiencies in previous work and propose our suggestions that the research on the Security-oriented adversarial NLP (SoadNLP) should: (1) evaluate their methods on security tasks to demonstrate the real-world concerns; (2) consider real-world attackers' goals, instead of developing impractical methods. To this end, we first collect, process, and release a security datasets collection Advbench. Then, we reformalize the task and adjust the emphasis on different goals in SoadNLP. Next, we propose a simple method based on heuristic rules that can easily fulfill the actual adversarial goals to simulate real-world attack methods. We conduct experiments on both the attack and the defense sides on Advbench. Experimental results show that our method has higher practical value, indicating that the research paradigm in SoadNLP may start from our new benchmark. All the code and data of Advbench can be obtained at https://github.com/thunlp/Advbench",
    "checked": true,
    "id": "e6c832118529361cd2e8ae834767a8ab79a9ec19",
    "semantic_title": "why should adversarial perturbations be imperceptible? rethink the research paradigm in adversarial nlp",
    "citation_count": 23,
    "authors": [
      "Yangyi Chen",
      "Hongcheng Gao",
      "Ganqu Cui",
      "Fanchao Qi",
      "Longtao Huang",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.772": {
    "title": "Retrieval Augmented Visual Question Answering with Outside Knowledge",
    "volume": "main",
    "abstract": "Outside-Knowledge Visual Question Answering (OK-VQA) is a challenging VQA task that requires retrieval of external knowledge to answer questions about images. Recent OK-VQA systems use Dense Passage Retrieval (DPR) to retrieve documents from external knowledge bases, such as Wikipedia, but with DPR trained separately from answer generation, introducing a potential limit on the overall system performance. Instead, we propose a joint training scheme which includes differentiable DPR integrated with answer generation so that the system can be trained in an end-to-end fashion. Our experiments show that our scheme outperforms recent OK-VQA systems with strong DPR for retrieval. We also introduce new diagnostic metrics to analyze how retrieval and generation interact. The strong retrieval ability of our model significantly reduces the number of retrieved documents needed in training, yielding significant benefits in answer quality and computation required for training",
    "checked": true,
    "id": "6f85ec89d9c07a8db4545e64888ced820370a21b",
    "semantic_title": "retrieval augmented visual question answering with outside knowledge",
    "citation_count": 28,
    "authors": [
      "Weizhe Lin",
      "Bill Byrne"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.773": {
    "title": "Instance Regularization for Discriminative Language Model Pre-training",
    "volume": "main",
    "abstract": "Discriminative pre-trained language models (PrLMs) can be generalized as denoising auto-encoders that work with two procedures, ennoising and denoising. First, an ennoising process corrupts texts with arbitrary noising functions to construct training instances. Then, a denoising language model is trained to restore the corrupted tokens. Existing studies have made progress by optimizing independent strategies of either ennoising or denosing. They treat training instances equally throughout the training process, with little attention on the individual contribution of those instances. To model explicit signals of instance contribution, this work proposes to estimate the complexity of restoring the original sentences from corrupted ones in language model pre-training. The estimations involve the corruption degree in the ennoising data construction process and the prediction confidence in the denoising counterpart. Experimental results on natural language understanding and reading comprehension benchmarks show that our approach improves pre-training efficiency, effectiveness, and robustness. Code is publicly available at https://github.com/cooelf/InstanceReg",
    "checked": true,
    "id": "8350f6e01b22cd6ba85450f52572a022543e0f53",
    "semantic_title": "instance regularization for discriminative language model pre-training",
    "citation_count": 1,
    "authors": [
      "Zhuosheng Zhang",
      "Hai Zhao",
      "Ming Zhou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.774": {
    "title": "GuoFeng: A Benchmark for Zero Pronoun Recovery and Translation",
    "volume": "main",
    "abstract": "The phenomenon of zero pronoun (ZP) has attracted increasing interest in the machine translation (MT) community due to its importance and difficulty. However, previous studies generally evaluate the quality of translating ZPs with BLEU scores on MT testsets, which is not expressive or sensitive enough for accurate assessment. To bridge the data and evaluation gaps, we propose a benchmark testset for target evaluation on Chinese-English ZP translation. The human-annotated testset covers five challenging genres, which reveal different characteristics of ZPs for comprehensive evaluation. We systematically revisit eight advanced models on ZP translation and identify current challenges for future exploration. We release data, code, models and annotation guidelines, which we hope can significantly promote research in this field (https://github.com/longyuewangdcu/mZPRT)",
    "checked": true,
    "id": "2511a2c321909ebec3125c4ee0b2beea8ed5496a",
    "semantic_title": "guofeng: a benchmark for zero pronoun recovery and translation",
    "citation_count": 5,
    "authors": [
      "Mingzhou Xu",
      "Longyue Wang",
      "Derek F. Wong",
      "Hongye Liu",
      "Linfeng Song",
      "Lidia S. Chao",
      "Shuming Shi",
      "Zhaopeng Tu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.775": {
    "title": "ScienceWorld: Is your Agent Smarter than a 5th Grader?",
    "volume": "main",
    "abstract": "We present ScienceWorld, a benchmark to test agents' scientific reasoning abilities in a new interactive text environment at the level of a standard elementary school science curriculum. Despite the transformer-based progress seen in question-answering and scientific text processing, we find that current models cannot reason about or explain learned science concepts in novel contexts. For instance, models can easily answer what the conductivity of a known material is but struggle when asked how they would conduct an experiment in a grounded environment to find the conductivity of an unknown material. This begs the question of whether current models are simply retrieving answers by way of seeing a large number of similar examples or if they have learned to reason about concepts in a reusable manner. We hypothesize that agents need to be grounded in interactive environments to achieve such reasoning capabilities. Our experiments provide empirical evidence supporting this hypothesis – showing that a 1.5 million parameter agent trained interactively for 100k steps outperforms a 11 billion parameter model statically trained for scientific question-answering and reasoning from millions of expert demonstrations",
    "checked": true,
    "id": "0e41fd22d483047bd8fdb1757d90c7702493567e",
    "semantic_title": "scienceworld: is your agent smarter than a 5th grader?",
    "citation_count": 44,
    "authors": [
      "Ruoyao Wang",
      "Peter Jansen",
      "Marc-Alexandre Côté",
      "Prithviraj Ammanabrolu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.776": {
    "title": "Improving Embeddings Representations for Comparing Higher Education Curricula: A Use Case in Computing",
    "volume": "main",
    "abstract": "We propose an approach for comparing curricula of study programs in higher education. Pre-trained word embeddings are fine-tuned in a study program classification task, where each curriculum is represented by the names and content of its courses. By combining metric learning with a novel course-guided attention mechanism, our method obtains more accurate curriculum representations than strong baselines. Experiments on a new dataset with curricula of computing programs demonstrate the intuitive power of our approach via attention weights, topic modeling, and embeddings visualizations. We also present a use case comparing computing curricula from USA and Latin America to showcase the capabilities of our improved embeddings representations",
    "checked": true,
    "id": "6c3582585dc69ce6f522a2f54700c4579dd8dd8f",
    "semantic_title": "improving embeddings representations for comparing higher education curricula: a use case in computing",
    "citation_count": 0,
    "authors": [
      "Jeffri Murrugarra-Llerena",
      "Fernando Alva-Manchego",
      "Nils Murrugarra-LLerena"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.777": {
    "title": "Mitigating Spurious Correlation in Natural Language Understanding with Counterfactual Inference",
    "volume": "main",
    "abstract": "Despite their promising results on standard benchmarks, NLU models are still prone to make predictions based on shortcuts caused by unintended bias in the dataset. For example, an NLI model may use lexical overlap as a shortcut to make entailment predictions due to repetitive data generation patterns from annotators, also called annotation artifacts. In this paper, we propose a causal analysis framework to help debias NLU models. We show that (1) by defining causal relationships, we can introspect how much annotation artifacts affect the outcomes. (2) We can utilize counterfactual inference to mitigate bias with this knowledge. We found that viewing a model as a treatment can mitigate bias more effectively than viewing annotation artifacts as treatment. (3) In addition to bias mitigation, we can interpret how much each debiasing strategy is affected by annotation artifacts. Our experimental results show that using counterfactual inference can improve out-of-distribution performance in all settings while maintaining high in-distribution performance",
    "checked": true,
    "id": "9425da9962d9bd63595832a5fd18e737bdb8488f",
    "semantic_title": "mitigating spurious correlation in natural language understanding with counterfactual inference",
    "citation_count": 6,
    "authors": [
      "Can Udomcharoenchaikit",
      "Wuttikorn Ponwitayarat",
      "Patomporn Payoungkhamdee",
      "Kanruethai Masuk",
      "Weerayut Buaphet",
      "Ekapol Chuangsuwanich",
      "Sarana Nutanong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.778": {
    "title": "End-to-End Neural Discourse Deixis Resolution in Dialogue",
    "volume": "main",
    "abstract": "We adapt Lee et al.'s (2018) span-based entity coreference model to the task of end-to-end discourse deixis resolution in dialogue, specifically by proposing extensions to their model that exploit task-specific characteristics. The resulting model, dd-utt, achieves state-of-the-art results on the four datasets in the CODI-CRAC 2021 shared task",
    "checked": true,
    "id": "f8b2c1d9442f70566d0037e337dcbd70caf3af92",
    "semantic_title": "end-to-end neural discourse deixis resolution in dialogue",
    "citation_count": 0,
    "authors": [
      "Shengjie Li",
      "Vincent Ng"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.779": {
    "title": "Balancing out Bias: Achieving Fairness Through Balanced Training",
    "volume": "main",
    "abstract": "Group bias in natural language processing tasks manifests as disparities in system error rates across texts authorized by different demographic groups, typically disadvantaging minority groups. Dataset balancing has been shown to be effective at mitigating bias, however existing approaches do not directly account for correlations between author demographics and linguistic variables, limiting their effectiveness. To achieve Equal Opportunity fairness, such as equal job opportunity without regard to demographics, this paper introduces a simple, but highly effective, objective for countering bias using balanced training. We extend the method in the form of a gated model, which incorporates protected attributes as input, and show that it is effective at reducing bias in predictions through demographic input perturbation, outperforming all other bias mitigation techniques when combined with balanced training",
    "checked": true,
    "id": "5b0926522572161dd10fb35b229b3dfb2014faee",
    "semantic_title": "balancing out bias: achieving fairness through balanced training",
    "citation_count": 20,
    "authors": [
      "Xudong Han",
      "Timothy Baldwin",
      "Trevor Cohn"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.780": {
    "title": "Prompting ELECTRA: Few-Shot Learning with Discriminative Pre-Trained Models",
    "volume": "main",
    "abstract": "Pre-trained masked language models successfully perform few-shot learning by formulating downstream tasks as text infilling. How- ever, as a strong alternative in full-shot settings, discriminative pre-trained models like ELECTRA do not fit into the paradigm. In this work, we adapt prompt-based few-shot learning to ELECTRA and show that it outperforms masked language models in a wide range of tasks. ELECTRA is pre-trained to distinguish if a token is generated or original. We naturally extend that to prompt-based few-shot learning by training to score the originality of the target options without introducing new parameters. Our method can be easily adapted to tasks involving multi-token predictions without extra computation overhead. Analysis shows that ELECTRA learns distributions that align better with downstream tasks",
    "checked": true,
    "id": "94f09dd93d278e80e342168eee9973830af6fd5c",
    "semantic_title": "prompting electra: few-shot learning with discriminative pre-trained models",
    "citation_count": 4,
    "authors": [
      "Mengzhou Xia",
      "Mikel Artetxe",
      "Jingfei Du",
      "Danqi Chen",
      "Veselin Stoyanov"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.781": {
    "title": "Identifying Physical Object Use in Sentences",
    "volume": "main",
    "abstract": "Commonsense knowledge about the typicalfunctions of physical objects allows people tomake inferences during sentence understanding. For example, we infer that \"Sam enjoyedthe book\" means that Sam enjoyed reading thebook, even though the action is implicit. Priorresearch has focused on learning the prototypicalfunctions of physical objects in order toenable inferences about implicit actions. Butmany sentences refer to objects even when theyare not used (e.g., \"The book fell\"). We arguethat NLP systems need to recognize whether anobject is being used before inferring how theobject is used. We define a new task called ObjectUse Classification that determines whethera physical object mentioned in a sentence wasused or likely will be used. We introduce a newdataset for this task and present a classificationmodel that exploits data augmentation methodsand FrameNet when fine-tuning a pre-trainedlanguage model. We also show that object useclassification combined with knowledge aboutthe prototypical functions of objects has thepotential to yield very good inferences aboutimplicit and anticipated actions",
    "checked": true,
    "id": "bf9097371d7a88f45bbdc380680e5b2c98ffd793",
    "semantic_title": "identifying physical object use in sentences",
    "citation_count": 1,
    "authors": [
      "Tianyu Jiang",
      "Ellen Riloff"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.782": {
    "title": "CDialog: A Multi-turn Covid-19 Conversation Dataset for Entity-Aware Dialog Generation",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7ae089060ecb7ac2788e94ee7e04a3eb7009f6b4",
    "semantic_title": "cdialog: a multi-turn covid-19 conversation dataset for entity-aware dialog generation",
    "citation_count": 1,
    "authors": [
      "Deeksha Varshney",
      "Aizan Zafar",
      "Niranshu Behera",
      "Asif Ekbal"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.783": {
    "title": "Robustifying Sentiment Classification by Maximally Exploiting Few Counterfactuals",
    "volume": "main",
    "abstract": "For text classification tasks, finetuned language models perform remarkably well. Yet, they tend to rely on spurious patterns in training data, thus limiting their performance on out-of-distribution (OOD) test data. Among recent models aiming to avoid this spurious pattern problem, adding extra counterfactual samples to the training data has proven to be very effective. Yet, counterfactual data generation is costly since it relies on human annotation. Thus, we propose a novel solution that only requires annotation of a small fraction (e.g., 1%) of the original training data, and uses automatic generation of extra counterfactuals in an encoding vector space. We demonstrate the effectiveness of our approach in sentiment classification, using IMDb data for training and other sets for OOD tests (i.e., Amazon, SemEval and Yelp). We achieve noticeable accuracy improvements by adding only 1% manual counterfactuals: +3% compared to adding +100% in-distribution training samples, +1.3% compared to alternate counterfactual approaches",
    "checked": true,
    "id": "b03bc940f673eba0fdc78df053d5fa6c5f5c3a14",
    "semantic_title": "robustifying sentiment classification by maximally exploiting few counterfactuals",
    "citation_count": 0,
    "authors": [
      "Maarten De Raedt",
      "Fréderic Godin",
      "Chris Develder",
      "Thomas Demeester"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.784": {
    "title": "Data-Efficient Playlist Captioning With Musical and Linguistic Knowledge",
    "volume": "main",
    "abstract": "Music streaming services feature billions of playlists created by users, professional editors or algorithms. In this content overload scenario, it is crucial to characterise playlists, so that music can be effectively organised and accessed. Playlist titles and descriptions are proposed in natural language either manually by music editors and users or automatically from pre-defined templates. However, the former is time-consuming while the latter is limited by the vocabulary and covered music themes. In this work, we propose PlayNTell, a data-efficient multi-modal encoder-decoder model for automatic playlist captioning. Compared to existing music captioning algorithms, PlayNTell leverages also linguistic and musical knowledge to generate correct and thematic captions. We benchmark PlayNTell on a new editorial playlists dataset collected from two major music streaming services. PlayNTell yields 2x-3x higher BLEU@4 and CIDEr than state of the art captioning algorithms",
    "checked": true,
    "id": "c857f68c6564f25d0cec315b619f7eac0171d828",
    "semantic_title": "data-efficient playlist captioning with musical and linguistic knowledge",
    "citation_count": 3,
    "authors": [
      "Giovanni Gabbolini",
      "Romain Hennequin",
      "Elena Epure"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.785": {
    "title": "Improved grammatical error correction by ranking elementary edits",
    "volume": "main",
    "abstract": "We offer a two-stage reranking method for grammatical error correction: the first model serves as edit generator, while the second classifies the proposed edits as correct or false. We show how to use both encoder-decoder and sequence labeling models for the first step of our pipeline. We achieve state-of-the-art quality on BEA 2019 English dataset even using weak BERT-GEC edit generator. Combining our roberta-base scorer with state-of-the-art GECToR edit generator, we surpass GECToR by 2-3%. With a larger model we establish a new SOTA on BEA development and test sets. Our model also sets a new SOTA on Russian, despite using smaller models and less data than the previous approaches",
    "checked": true,
    "id": "204292e4c957e4e2001ad1dce25d7185a8108838",
    "semantic_title": "improved grammatical error correction by ranking elementary edits",
    "citation_count": 8,
    "authors": [
      "Alexey Sorokin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.786": {
    "title": "Improving Tokenisation by Alternative Treatment of Spaces",
    "volume": "main",
    "abstract": "",
    "checked": true,
    "id": "7e15af5f6b3a794167bc4dc194768b348becc5d3",
    "semantic_title": "improving tokenisation by alternative treatment of spaces",
    "citation_count": 10,
    "authors": [
      "Edward Gow-Smith",
      "Harish Tayyar Madabushi",
      "Carolina Scarton",
      "Aline Villavicencio"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.787": {
    "title": "GENIE: Toward Reproducible and Standardized Human Evaluation for Text Generation",
    "volume": "main",
    "abstract": "While often assumed a gold standard, effective human evaluation of text generation remains an important, open area for research. We revisit this problem with a focus on producing consistent evaluations that are reproducible—over time and across different populations. We study this goal in different stages of the human evaluation pipeline. In particular, we consider design choices for the annotation interface used to elicit human judgments and their impact on reproducibility. Furthermore, we develop an automated mechanism for maintaining annotator quality via a probabilistic model that detects and excludes noisy annotators. Putting these lessons together, we introduce GENIE: a system for running standardized human evaluations across different generation tasks. We instantiate GENIE with datasets representing four core challenges in text generation: machine translation, summarization, commonsense reasoning, and machine comprehension. For each task, GENIE offers a leaderboard that automatically crowdsources annotations for submissions, evaluating them along axes such as correctness, conciseness, and fluency. We have made the GENIE leaderboards publicly available, and have already ranked 50 submissions from 10 different research groups. We hope GENIE encourages further progress toward effective, standardized evaluations for text generation",
    "checked": true,
    "id": "04052cfab34af874498726209225216bb3b89d3d",
    "semantic_title": "genie: toward reproducible and standardized human evaluation for text generation",
    "citation_count": 15,
    "authors": [
      "Daniel Khashabi",
      "Gabriel Stanovsky",
      "Jonathan Bragg",
      "Nicholas Lourie",
      "Jungo Kasai",
      "Yejin Choi",
      "Noah A. Smith",
      "Daniel Weld"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.788": {
    "title": "Attentional Probe: Estimating a Module's Functional Potential",
    "volume": "main",
    "abstract": "In this paper, we seek to measure how much information a component in a neural network could extract from the representations fed into it. Our work stands in contrast to prior probing work, most of which investigates how much information a model's representations contain. This shift in perspective leads us to propose a new principle for probing, the architectural bottleneck principle: In order to estimate how much information a given component could extract, a probe should look exactly like the component. Relying on this principle, we estimate how much syntactic information is available to transformers through our attentional probe, a probe that exactly resembles a transformer's self-attention head. Experimentally, we find that, in three models (BERT, ALBERT, and RoBERTa), a sentence's syntax tree is mostly extractable by our probe, suggesting these models have access to syntactic information while composing their contextual representations. Whether this information is actually used by these models, however, remains an open question",
    "checked": true,
    "id": "b9b5ace8835b1fd01b9ff4162b87b258fb8aae7f",
    "semantic_title": "attentional probe: estimating a module's functional potential",
    "citation_count": 3,
    "authors": [
      "Tiago Pimentel",
      "Josef Valvoda",
      "Niklas Stoehr",
      "Ryan Cotterell"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.789": {
    "title": "When More Data Hurts: A Troubling Quirk in Developing Broad-Coverage Natural Language Understanding Systems",
    "volume": "main",
    "abstract": "In natural language understanding (NLU) production systems, users' evolving needs necessitate the addition of new features over time, indexed by new symbols added to the meaning representation space. This requires additional training data and results in ever-growing datasets. We present the first systematic investigation into this incremental symbol learning scenario. Our analysis reveals a troubling quirk in building broad-coverage NLU systems: as the training dataset grows, performance on a small set of new symbols often decreases. We show that this trend holds for multiple mainstream models on two common NLU tasks: intent recognition and semantic parsing. Rejecting class imbalance as the sole culprit, we reveal that the trend is closely associated with an effect we call source signal dilution, where strong lexical cues for the new symbol become diluted as the training dataset grows. Selectively dropping training examples to prevent dilution often reverses the trend, showing the over-reliance of mainstream neural NLU models on simple lexical cues",
    "checked": true,
    "id": "1a5fcd44ebba0aaecc0397b26957fcc5e5476033",
    "semantic_title": "when more data hurts: a troubling quirk in developing broad-coverage natural language understanding systems",
    "citation_count": 3,
    "authors": [
      "Elias Stengel-Eskin",
      "Emmanouil Antonios Platanios",
      "Adam Pauls",
      "Sam Thomson",
      "Hao Fang",
      "Benjamin Van Durme",
      "Jason Eisner",
      "Yu Su"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.790": {
    "title": "Zero-shot Cross-lingual Transfer of Prompt-based Tuning with a Unified Multilingual Prompt",
    "volume": "main",
    "abstract": "Prompt-based tuning has been proven effective for pretrained language models (PLMs). While most of the existing work focuses on the monolingual prompts, we study the multilingual prompts for multilingual PLMs, especially in the zero-shot cross-lingual setting. To alleviate the effort of designing different prompts for multiple languages, we propose a novel model that uses a unified prompt for all languages, called UniPrompt. Different from the discrete prompts and soft prompts, the unified prompt is model-based and language-agnostic. Specifically, the unified prompt is initialized by a multilingual PLM to produce language-independent representation, after which is fused with the text input. During inference, the prompts can be pre-computed so that no extra computation cost is needed. To collocate with the unified prompt, we propose a new initialization method for the target label word to further improve the model's transferability across languages. Extensive experiments show that our proposed methods can significantly outperform the strong baselines across different languages. We release data and code to facilitate future research",
    "checked": true,
    "id": "4645535d33d9c8792d217c81d2657e99036b85ff",
    "semantic_title": "zero-shot cross-lingual transfer of prompt-based tuning with a unified multilingual prompt",
    "citation_count": 20,
    "authors": [
      "Lianzhe Huang",
      "Shuming Ma",
      "Dongdong Zhang",
      "Furu Wei",
      "Houfeng Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.791": {
    "title": "Three Real-World Datasets and Neural Computational Models for Classification Tasks in Patent Landscaping",
    "volume": "main",
    "abstract": "Patent Landscaping, one of the central tasks of intellectual property management, includes selecting and grouping patents according to user-defined technical or application-oriented criteria. While recent transformer-based models have been shown to be effective for classifying patents into taxonomies such as CPC or IPC, there is yet little research on how to support real-world Patent Landscape Studies (PLSs) using natural language processing methods. With this paper, we release three labeled datasets for PLS-oriented classification tasks covering two diverse domains. We provide a qualitative analysis and report detailed corpus statistics. Most research on neural models for patents has been restricted to leveraging titles and abstracts. We compare strong neural and non-neural baselines, proposing a novel model that takes into account textual information from the patents' full texts as well as embeddings created based on the patents' CPC labels. We find that for PLS-oriented classification tasks, going beyond title and abstract is crucial, CPC labels are an effective source of information, and combining all features yields the best results",
    "checked": true,
    "id": "8be6826f9df11e6451a301b2de9d4ffb3471ce66",
    "semantic_title": "three real-world datasets and neural computational models for classification tasks in patent landscaping",
    "citation_count": 0,
    "authors": [
      "Subhash Pujari",
      "Jannik Strötgen",
      "Mark Giereth",
      "Michael Gertz",
      "Annemarie Friedrich"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.792": {
    "title": "Topic Modeling With Topological Data Analysis",
    "volume": "main",
    "abstract": "Recent unsupervised topic modelling ap-proaches that use clustering techniques onword, token or document embeddings can ex-tract coherent topics. A common limitationof such approaches is that they reveal noth-ing about inter-topic relationships which areessential in many real-world application do-mains. We present an unsupervised topic mod-elling method which harnesses TopologicalData Analysis (TDA) to extract a topologicalskeleton of the manifold upon which contextu-alised word embeddings lie. We demonstratethat our approach, which performs on par witha recent baseline, is able to construct a networkof coherent topics together with meaningfulrelationships between them",
    "checked": true,
    "id": "7e560e24c9946a5213bed19f48cbea0ad1a30271",
    "semantic_title": "topic modeling with topological data analysis",
    "citation_count": 1,
    "authors": [
      "Ciarán Byrne",
      "Danijela Horak",
      "Karo Moilanen",
      "Amandla Mabona"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.793": {
    "title": "Predicting Fine-Tuning Performance with Probing",
    "volume": "main",
    "abstract": "Large NLP models have recently shown impressive performance in language understanding tasks, typically evaluated by their fine-tuned performance. Alternatively, probing has received increasing attention as being a lightweight method for interpreting the intrinsic mechanisms of large NLP models. In probing, post-hoc classifiers are trained on \"out-of-domain\" datasets that diagnose specific abilities. While probing the language models has led to insightful findings, they appear disjointed from the development of models. This paper explores the utility of probing deep NLP models to extract a proxy signal widely used in model development – the fine-tuning performance. We find that it is possible to use the accuracies of only three probing tests to predict the fine-tuning performance with errors 40% - 80% smaller than baselines. We further discuss possible avenues where probing can empower the development of deep NLP models",
    "checked": true,
    "id": "157ff71fb4818aab80ef4b54187251bff23449c6",
    "semantic_title": "predicting fine-tuning performance with probing",
    "citation_count": 6,
    "authors": [
      "Zining Zhu",
      "Soroosh Shahtalebi",
      "Frank Rudzicz"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.794": {
    "title": "Diverse Parallel Data Synthesis for Cross-Database Adaptation of Text-to-SQL Parsers",
    "volume": "main",
    "abstract": "Text-to-SQL parsers typically struggle with databases unseen during the train time. Adapting Text-to-SQL parsers to new database schemas is a challenging problem owing to a vast diversity of schemas and zero availability of natural language queries in new schemas. We present ReFill, a framework for synthesizing high-quality and textually diverse parallel datasets for adapting Text-to-SQL parsers. Unlike prior methods that utilize SQL-to-Text generation, ReFill learns to retrieve-and-edit text queries in existing schemas and transfer them to the new schema. ReFill utilizes a simple method for retrieving diverse existing text, masking their schema-specific tokens, and refilling with tokens relevant to the new schema. We show that this process leads to significantly more diverse text queries than achievable by standard SQL-to-Text generation models. Through experiments on several databases, we show that adapting a parser by finetuning it on datasets synthesized by ReFill consistently outperforms prior data-augmentation methods",
    "checked": true,
    "id": "697452b24c3b884cff8f7dbbc9c8e62bc59e0fdf",
    "semantic_title": "diverse parallel data synthesis for cross-database adaptation of text-to-sql parsers",
    "citation_count": 1,
    "authors": [
      "Abhijeet Awasthi",
      "Ashutosh Sathe",
      "Sunita Sarawagi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.795": {
    "title": "Agent-Specific Deontic Modality Detection in Legal Language",
    "volume": "main",
    "abstract": "Legal documents are typically long and written in legalese, which makes it particularly difficult for laypeople to understand their rights and duties. While natural language understanding technologies can be valuable in supporting such understanding in the legal domain, the limited availability of datasets annotated for deontic modalities in the legal domain, due to the cost of hiring experts and privacy issues, is a bottleneck. To this end, we introduce, LEXDEMOD, a corpus of English contracts annotatedwith deontic modality expressed with respect to a contracting party or agent along with the modal triggers. We benchmark this dataset on two tasks: (i) agent-specific multi-label deontic modality classification, and (ii) agent-specific deontic modality and trigger span detection using Transformer-based (Vaswani et al., 2017) language models. Transfer learning experiments show that the linguistic diversity of modal expressions in LEXDEMOD generalizes reasonably from lease to employment andrental agreements. A small case study indicates that a model trained on LEXDEMOD can detect red flags with high recall. We believe our work offers a new research direction for deontic modality detection in the legal domain",
    "checked": true,
    "id": "3eb4d4ec27accd8023a1eecfe2bd49d2e18dfa3d",
    "semantic_title": "agent-specific deontic modality detection in legal language",
    "citation_count": 5,
    "authors": [
      "Abhilasha Sancheti",
      "Aparna Garimella",
      "Balaji Vasan Srinivasan",
      "Rachel Rudinger"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.796": {
    "title": "COLD: A Benchmark for Chinese Offensive Language Detection",
    "volume": "main",
    "abstract": "Offensive language detection is increasingly crucial for maintaining a civilized social media platform and deploying pre-trained language models. However, this task in Chinese is still under exploration due to the scarcity of reliable datasets. To this end, we propose a benchmark –COLD for Chinese offensive language analysis, including a Chinese Offensive Language Dataset –COLDATASET and a baseline detector –COLDETECTOR which is trained on the dataset. We show that the COLD benchmark contributes to Chinese offensive language detection which is challenging for existing resources. We then deploy the COLDETECTOR and conduct detailed analyses on popular Chinese pre-trained language models. We first analyze the offensiveness of existing generative models and show that these models inevitably expose varying degrees of offensive issues. Furthermore, we investigate the factors that influence the offensive generations, and we find that anti-bias contents and keywords referring to certain groups or revealing negative attitudes trigger offensive outputs easier",
    "checked": true,
    "id": "3664cceee40f91c75d1ee2d2e17a050e846e52bb",
    "semantic_title": "cold: a benchmark for chinese offensive language detection",
    "citation_count": 51,
    "authors": [
      "Jiawen Deng",
      "Jingyan Zhou",
      "Hao Sun",
      "Chujie Zheng",
      "Fei Mi",
      "Helen Meng",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.797": {
    "title": "Fixing Model Bugs with Natural Language Patches",
    "volume": "main",
    "abstract": "Current approaches for fixing systematic problems in NLP models (e.g., regex patches, finetuning on more data) are either brittle, or labor-intensive and liable to shortcuts. In contrast, humans often provide corrections to each other through natural language. Taking inspiration from this, we explore natural language patches—declarative statements that allow developers to provide corrective feedback at the right level of abstraction, either overriding the model (\"if a review gives 2 stars, the sentiment is negative\") or providing additional information the model may lack (\"if something is described as the bomb, then it is good\"). We model the task of determining if a patch applies separately from the task of integrating patch information, and show that with a small amount of synthetic data, we can teach models to effectively use real patches on real data—1 to 7 patches improve accuracy by ~1–4 accuracy points on different slices of a sentiment analysis dataset, and F1 by 7 points on a relation extraction dataset. Finally, we show that finetuning on as many as 100 labeled examples may be needed to match the performance of a small set of language patches",
    "checked": true,
    "id": "61ddf932488405ab1c7b275460d2b3c5dfa274a0",
    "semantic_title": "fixing model bugs with natural language patches",
    "citation_count": 21,
    "authors": [
      "Shikhar Murty",
      "Christopher Manning",
      "Scott Lundberg",
      "Marco Tulio Ribeiro"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.798": {
    "title": "WeDef: Weakly Supervised Backdoor Defense for Text Classification",
    "volume": "main",
    "abstract": "Existing backdoor defense methods are only effective for limited trigger types. To defend different trigger types at once, we start from the class-irrelevant nature of the poisoning process and propose a novel weakly supervised backdoor defense framework WeDef. Recent advances in weak supervision make it possible to train a reasonably accurate text classifier using only a small number of user-provided, class-indicative seed words. Such seed words shall be considered independent of the triggers. Therefore, a weakly supervised text classifier trained by only the poisoned documents without their labels will likely have no backdoor. Inspired by this observation, in WeDef, we define the reliability of samples based on whether the predictions of the weak classifier agree with their labels in the poisoned training set. We further improve the results through a two-phase sanitization: (1) iteratively refine the weak classifier based on the reliable samples and (2) train a binary poison classifier by distinguishing the most unreliable samples from the most reliable samples. Finally, we train the sanitized model on the samples that the poison classifier predicts as benign. Extensive experiments show that WeDef is effective against popular trigger-based attacks (e.g., words, sentences, and paraphrases), outperforming existing defense methods",
    "checked": true,
    "id": "ac808422a8a7ddbacfe7b0c6f777ac7f036a3225",
    "semantic_title": "wedef: weakly supervised backdoor defense for text classification",
    "citation_count": 5,
    "authors": [
      "Lesheng Jin",
      "Zihan Wang",
      "Jingbo Shang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.799": {
    "title": "Interventional Training for Out-Of-Distribution Natural Language Understanding",
    "volume": "main",
    "abstract": "Out-of-distribution (OOD) settings are used to measure a model's performance when the distribution of the test data is different from that of the training data. NLU models are known to suffer in OOD. We study this issue from the perspective of causality, which sees confounding bias as the reason for models to learn spurious correlations. While a common solution is to perform intervention, existing methods handle only known and single confounder, but in many NLU tasks the confounders can be both unknown and multifactorial. In this paper, we propose a novel interventional training method called Bottom-up Automatic Intervention (BAI) that performs multi-granular intervention with identified multifactorial confounders. Our experiments on three NLU tasks, namely, natural language inference, fact verification and paraphrase identification, show the effectiveness of BAI for tackling OOD settings",
    "checked": true,
    "id": "4468974fc2974f2fcb1c19fec56579065f8c5dcc",
    "semantic_title": "interventional training for out-of-distribution natural language understanding",
    "citation_count": 2,
    "authors": [
      "Sicheng Yu",
      "Jing Jiang",
      "Hao Zhang",
      "Yulei Niu",
      "Qianru Sun",
      "Lidong Bing"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.800": {
    "title": "Pseudo-Relevance for Enhancing Document Representation",
    "volume": "main",
    "abstract": "This paper studies how to enhance the document representation for the bi-encoder approach in dense document retrieval. The bi-encoder, separately encoding a query and a document as a single vector, is favored for high efficiency in large-scale information retrieval, compared to more effective but complex architectures. To combine the strength of the two, the multi-vector representation of documents for bi-encoder, such as ColBERT preserving all token embeddings, has been widely adopted. Our contribution is to reduce the size of the multi-vector representation, without compromising the effectiveness, supervised by query logs. Our proposed solution decreases the latency and the memory footprint, up to 8- and 3-fold, validated on MSMARCO and real-world search query logs",
    "checked": true,
    "id": "e05a67b9b464c7d4e798a89f61d3eeaefa39af7c",
    "semantic_title": "pseudo-relevance for enhancing document representation",
    "citation_count": 0,
    "authors": [
      "Jihyuk Kim",
      "Seung-won Hwang",
      "Seoho Song",
      "Hyeseon Ko",
      "Young-In Song"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.801": {
    "title": "ZeroGen: Efficient Zero-shot Learning via Dataset Generation",
    "volume": "main",
    "abstract": "There is a growing interest in dataset generation recently due to the superior generative capacity of large pre-trained language models (PLMs). In this paper, we study a flexible and efficient zero-short learning method, ZeroGen. Given a zero-shot task, we first generate a dataset from scratch using PLMs in an unsupervised manner. Then, we train a tiny task model (e.g., LSTM) under the supervision of the synthesized dataset. This approach allows highly efficient inference as the final task model only has orders of magnitude fewer parameters comparing to PLMs (e.g., GPT2-XL).Apart from being annotation-free and efficient, we argue that ZeroGen can also provide useful insights from the perspective of data-free model-agnostic knowledge distillation, and unreferenced text generation evaluation. Experiments and analysis on different NLP tasks, namely, text classification, question answering, and natural language inference, show the effectiveness of ZeroGen",
    "checked": true,
    "id": "2145fcceeb69385e108bf1796d52f974854d4c0b",
    "semantic_title": "zerogen: efficient zero-shot learning via dataset generation",
    "citation_count": 100,
    "authors": [
      "Jiacheng Ye",
      "Jiahui Gao",
      "Qintong Li",
      "Hang Xu",
      "Jiangtao Feng",
      "Zhiyong Wu",
      "Tao Yu",
      "Lingpeng Kong"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.802": {
    "title": "Neighborhood Contrastive Learning for Scientific Document Representations with Citation Embeddings",
    "volume": "main",
    "abstract": "Learning scientific document representations can be substantially improved through contrastive learning objectives, where the challenge lies in creating positive and negative training samples that encode the desired similarity semantics. Prior work relies on discrete citation relations to generate contrast samples. However, discrete citations enforce a hard cut-off to similarity. This is counter-intuitive to similarity-based learning and ignores that scientific papers can be very similar despite lacking a direct citation - a core problem of finding related research. Instead, we use controlled nearest neighbor sampling over citation graph embeddings for contrastive learning. This control allows us to learn continuous similarity, to sample hard-to-learn negatives and positives, and also to avoid collisions between negative and positive samples by controlling the sampling margin between them. The resulting method SciNCL outperforms the state-of-the-art on the SciDocs benchmark. Furthermore, we demonstrate that it can train (or tune) language models sample-efficiently and that it can be combined with recent training-efficient methods. Perhaps surprisingly, even training a general-domain language model this way outperforms baselines pretrained in-domain",
    "checked": true,
    "id": "72d5bd1095f9719742212f81a2a3790583e95796",
    "semantic_title": "neighborhood contrastive learning for scientific document representations with citation embeddings",
    "citation_count": 45,
    "authors": [
      "Malte Ostendorff",
      "Nils Rethmeier",
      "Isabelle Augenstein",
      "Bela Gipp",
      "Georg Rehm"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.803": {
    "title": "SPE: Symmetrical Prompt Enhancement for Fact Probing",
    "volume": "main",
    "abstract": "Pretrained language models (PLMs) have been shown to accumulate factual knowledge during pretraining (Petroni et al. 2019). Recent works probe PLMs for the extent of this knowledge through prompts either in discrete or continuous forms. However, these methods do not consider symmetry of the task: object prediction and subject prediction. In this work, we propose Symmetrical Prompt Enhancement (SPE), a continuous prompt-based method for factual probing in PLMs that leverages the symmetry of the task by constructing symmetrical prompts for subject and object prediction. Our results on a popular factual probing dataset, LAMA, show significant improvement of SPE over previous probing methods",
    "checked": true,
    "id": "872748081a8fb66703a3b89fb46840642565513d",
    "semantic_title": "spe: symmetrical prompt enhancement for fact probing",
    "citation_count": 3,
    "authors": [
      "Yiyuan Li",
      "Tong Che",
      "Yezhen Wang",
      "Zhengbao Jiang",
      "Caiming Xiong",
      "Snigdha Chaturvedi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.804": {
    "title": "Efficient Large Scale Language Modeling with Mixtures of Experts",
    "volume": "main",
    "abstract": "Mixture of Experts layers (MoEs) enable efficient scaling of language models through conditional computation. This paper presents a detailed empirical study of how autoregressive MoE language models scale in comparison with dense models in a wide range of settings: in- and out-of-domain language modeling, zero- and few-shot priming, and full-shot fine-tuning. With the exception of fine-tuning, we find MoEs to be substantially more compute efficient. At more modest training budgets, MoEs can match the performance of dense models using ~4 times less compute. This gap narrows at scale, but our largest MoE model (1.1T parameters) consistently outperforms a compute-equivalent dense model (6.7B parameters). Overall, this performance gap varies greatly across tasks and domains, suggesting that MoE and dense models generalize differently in ways that are worthy of future study. We make our code and models publicly available for research use",
    "checked": true,
    "id": "7bdc6a2a05c7650fa0404973b670bba72acf056e",
    "semantic_title": "efficient large scale language modeling with mixtures of experts",
    "citation_count": 5,
    "authors": [
      "Mikel Artetxe",
      "Shruti Bhosale",
      "Naman Goyal",
      "Todor Mihaylov",
      "Myle Ott",
      "Sam Shleifer",
      "Xi Victoria Lin",
      "Jingfei Du",
      "Srinivasan Iyer",
      "Ramakanth Pasunuru",
      "Giridharan Anantharaman",
      "Xian Li",
      "Shuohui Chen",
      "Halil Akin",
      "Mandeep Baines",
      "Louis Martin",
      "Xing Zhou",
      "Punit Singh Koura",
      "Brian O’Horo",
      "Jeffrey Wang",
      "Luke Zettlemoyer",
      "Mona Diab",
      "Zornitsa Kozareva",
      "Veselin Stoyanov"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.805": {
    "title": "MedJEx: A Medical Jargon Extraction Model with Wiki's Hyperlink Span and Contextualized Masked Language Model Score",
    "volume": "main",
    "abstract": "This paper proposes a new natural language processing (NLP) application for identifying medical jargon terms potentially difficult for patients to comprehend from electronic health record (EHR) notes. We first present a novel and publicly available dataset with expert-annotated medical jargon terms from 18K+ EHR note sentences (MedJ). Then, we introduce a novel medical jargon extraction (MedJEx) model which has been shown to outperform existing state-of-the-art NLP models. First, MedJEx improved the overall performance when it was trained on an auxiliary Wikipedia hyperlink span dataset, where hyperlink spans provide additional Wikipedia articles to explain the spans (or terms), and then fine-tuned on the annotated MedJ data. Secondly, we found that a contextualized masked language model score was beneficial for detecting domain-specific unfamiliar jargon terms. Moreover, our results show that training on the auxiliary Wikipedia hyperlink span datasets improved six out of eight biomedical named entity recognition benchmark datasets. MedJEx is publicly available",
    "checked": true,
    "id": "38e995753f222ba7d198d6d54033058de84a77f1",
    "semantic_title": "medjex: a medical jargon extraction model with wiki's hyperlink span and contextualized masked language model score",
    "citation_count": 14,
    "authors": [
      "Sunjae Kwon",
      "Zonghai Yao",
      "Harmon Jordan",
      "David Levy",
      "Brian Corner",
      "Hong Yu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.806": {
    "title": "Discourse Comprehension: A Question Answering Framework to Represent Sentence Connections",
    "volume": "main",
    "abstract": "While there has been substantial progress in text comprehension through simple factoid question answering, more holistic comprehension of a discourse still presents a major challenge (Dunietz et al., 2020). Someone critically reflecting on a text as they read it will pose curiosity-driven, often open-ended questions, which reflect deep understanding of the content and require complex reasoning to answer (Ko et al., 2020; Westera et al., 2020). A key challenge in building and evaluating models for this type of discourse comprehension is the lack of annotated data, especially since collecting answers to such questions requires high cognitive load for annotators. This paper presents a novel paradigm that enables scalable data collection targeting the comprehension of news documents, viewing these questions through the lens of discourse. The resulting corpus, DCQA (Discourse Comprehension by Question Answering), captures both discourse and semantic links between sentences in the form of free-form, open-ended questions. On an evaluation set that we annotated on questions from Ko et al. (2020), we show that DCQA provides valuable supervision for answering open-ended questions. We additionally design pre-training methods utilizing existing question-answering resources, and use synthetic data to accommodate unanswerable questions",
    "checked": true,
    "id": "192f2b973840791d2fc2aa638db3ca157f3401b7",
    "semantic_title": "discourse comprehension: a question answering framework to represent sentence connections",
    "citation_count": 11,
    "authors": [
      "Wei-Jen Ko",
      "Cutter Dalton",
      "Mark Simmons",
      "Eliza Fisher",
      "Greg Durrett",
      "Junyi Jessy Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.807": {
    "title": "Learning to Generate Overlap Summaries through Noisy Synthetic Data",
    "volume": "main",
    "abstract": "Semantic Overlap Summarization (SOS) is a novel and relatively under-explored seq-to-seq task which entails summarizing common information from multiple alternate narratives. One of the major challenges for solving this task is the lack of existing datasets for supervised training. To address this challenge, we propose a novel data augmentation technique, which allows us to create large amount of synthetic data for training a seq-to-seq model that can perform the SOS task. Through extensive experiments using narratives from the news domain, we show that the models fine-tuned using the synthetic dataset provide significant performance improvements over the pre-trained vanilla summarization techniques and are close to the models fine-tuned on the golden training data; which essentially demonstrates the effectiveness of out proposed data augmentation technique for training seq-to-seq models on the SOS task",
    "checked": true,
    "id": "0f427251a09c7c3ca6310184e28dcaa2f2f6746b",
    "semantic_title": "learning to generate overlap summaries through noisy synthetic data",
    "citation_count": 3,
    "authors": [
      "Naman Bansal",
      "Mousumi Akter",
      "Shubhra Kanti Karmaker Santu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.808": {
    "title": "Mutual Exclusivity Training and Primitive Augmentation to Induce Compositionality",
    "volume": "main",
    "abstract": "Recent datasets expose the lack of the systematic generalization ability in standard sequence-to-sequence models. In this work, we analyze this behavior of seq2seq models and identify two contributing factors: a lack of mutual exclusivity bias (one target sequence can only be mapped to one source sequence), and the tendency to memorize whole examples rather than separating structures from contents. We propose two techniques to address these two issues respectively: Mutual Exclusivity Training that prevents the model from producing seen generations when facing novel examples via an unlikelihood-based loss, and prim2primX data augmentation that automatically diversifies the arguments of every syntactic function to prevent memorizing and provide a compositional inductive bias without exposing test-set data. Combining these two techniques, we show substantial empirical improvements using standard sequence-to-sequence models (LSTMs and Transformers) on two widely-used compositionality datasets: SCAN and COGS. Finally, we provide analysis characterizing the improvements as well as the remaining challenges, and provide detailed ablations of our method",
    "checked": true,
    "id": "2e935268b66e12dd310af5c715013147d454e560",
    "semantic_title": "mutual exclusivity training and primitive augmentation to induce compositionality",
    "citation_count": 6,
    "authors": [
      "Yichen Jiang",
      "Xiang Zhou",
      "Mohit Bansal"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.809": {
    "title": "Directions for NLP Practices Applied to Online Hate Speech Detection",
    "volume": "main",
    "abstract": "Addressing hate speech in online spaces has been conceptualized as a classification task that uses Natural Language Processing (NLP) techniques. Through this conceptualization, the hate speech detection task has relied on common conventions and practices from NLP. For instance, inter-annotator agreement is conceptualized as a way to measure dataset quality and certain metrics and benchmarks are used to assure model generalization. However, hate speech is a deeply complex and situated concept that eludes such static and disembodied practices. In this position paper, we critically reflect on these methodologies for hate speech detection, we argue that many conventions in NLP are poorly suited for the problem and encourage researchers to develop methods that are more appropriate for the task",
    "checked": true,
    "id": "2fc9870ff7f8b5e5f109695103a23d9e13687555",
    "semantic_title": "directions for nlp practices applied to online hate speech detection",
    "citation_count": 8,
    "authors": [
      "Paula Fortuna",
      "Monica Dominguez",
      "Leo Wanner",
      "Zeerak Talat"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.810": {
    "title": "Pre-training Transformer Models with Sentence-Level Objectives for Answer Sentence Selection",
    "volume": "main",
    "abstract": "An important task for designing QA systems is answer sentence selection (AS2): selecting the sentence containing (or constituting) the answer to a question from a set of retrieved relevant documents. In this paper, we propose three novel sentence-level transformer pre-training objectives that incorporate paragraph-level semantics within and across documents, to improve the performance of transformers for AS2, and mitigate the requirement of large labeled datasets. Specifically, the model is tasked to predict whether: (i) two sentences are extracted from the same paragraph, (ii) a given sentence is extracted from a given paragraph, and (iii) two paragraphs are extracted from the same document. Our experiments on three public and one industrial AS2 datasets demonstrate the empirical superiority of our pre-trained transformers over baseline models such as RoBERTa and ELECTRA for AS2",
    "checked": true,
    "id": "c6dbd9577212838d66c28ac446712cfe04ef28a8",
    "semantic_title": "pre-training transformer models with sentence-level objectives for answer sentence selection",
    "citation_count": 14,
    "authors": [
      "Luca Di Liello",
      "Siddhant Garg",
      "Luca Soldaini",
      "Alessandro Moschitti"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.811": {
    "title": "OpenCQA: Open-ended Question Answering with Charts",
    "volume": "main",
    "abstract": "Charts are very popular to analyze data and convey important insights. People often analyze visualizations to answer open-ended questions that require explanatory answers. Answering such questions are often difficult and time-consuming as it requires a lot of cognitive and perceptual efforts. To address this challenge, we introduce a new task called OpenCQA, where the goal is to answer an open-ended question about a chart with descriptive texts. We present the annotation process and an in-depth analysis of our dataset. We implement and evaluate a set of baselines under three practical settings. In the first setting, a chart and the accompanying article is provided as input to the model. The second setting provides only the relevant paragraph(s) to the chart instead of the entire article, whereas the third setting requires the model to generate an answer solely based on the chart. Our analysis of the results show that the top performing models generally produce fluent and coherent text while they struggle to perform complex logical and arithmetic reasoning",
    "checked": true,
    "id": "6c52c74debc49cd3ed58a74658655c30adc59d42",
    "semantic_title": "opencqa: open-ended question answering with charts",
    "citation_count": 14,
    "authors": [
      "Shankar Kantharaj",
      "Xuan Long Do",
      "Rixie Tiffany Leong",
      "Jia Qing Tan",
      "Enamul Hoque",
      "Shafiq Joty"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.812": {
    "title": "A Systematic Investigation of Commonsense Knowledge in Large Language Models",
    "volume": "main",
    "abstract": "Language models (LMs) trained on large amounts of data have shown impressive performance on many NLP tasks under the zero-shot and few-shot setup. Here we aim to better understand the extent to which such models learn commonsense knowledge — a critical component of many NLP applications. We conduct a systematic and rigorous zero-shot and few-shot commonsense evaluation of large pre-trained LMs, where we: (i) carefully control for the LMs' ability to exploit potential surface cues and annotation artefacts, and (ii) account for variations in performance that arise from factors that are not related to commonsense knowledge. Our findings highlight the limitations of pre-trained LMs in acquiring commonsense knowledge without task-specific supervision; furthermore, using larger models or few-shot evaluation is insufficient to achieve human-level commonsense performance",
    "checked": true,
    "id": "c09ebcb1ca6ad1eced57340f3e81e456416ed185",
    "semantic_title": "a systematic investigation of commonsense knowledge in large language models",
    "citation_count": 29,
    "authors": [
      "Xiang Lorraine Li",
      "Adhiguna Kuncoro",
      "Jordan Hoffmann",
      "Cyprien de Masson d’Autume",
      "Phil Blunsom",
      "Aida Nematzadeh"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.813": {
    "title": "Transforming Sequence Tagging Into A Seq2Seq Task",
    "volume": "main",
    "abstract": "Pretrained, large, generative language models (LMs) have had great success in a wide range of sequence tagging and structured prediction tasks. Casting a sequence tagging task as a Seq2Seq one requires deciding the formats of the input and output sequences. However, we lack a principled understanding of the trade-offs associated with these formats (such as the effect on model accuracy, sequence length, multilingual generalization, hallucination). In this paper, we rigorously study different formats one could use for casting input text sentences and their output labels into the input and target (i.e., output) of a Seq2Seq model. Along the way, we introduce a new format, which we show to to be both simpler and more effective. Additionally the new format demonstrates significant gains in the multilingual settings – both zero-shot transfer learning and joint training. Lastly, we find that the new format is more robust and almost completely devoid of hallucination – an issue we find common in existing formats. With well over a 1000 experiments studying 14 different formats, over 7 diverse public benchmarks – including 3 multilingual datasets spanning 7 languages – we believe our findings provide a strong empirical basis in understanding how we should tackle sequence tagging tasks",
    "checked": true,
    "id": "7f9eb2a4e79671445ebee0c2c55de44b80481f14",
    "semantic_title": "transforming sequence tagging into a seq2seq task",
    "citation_count": 15,
    "authors": [
      "Karthik Raman",
      "Iftekhar Naim",
      "Jiecao Chen",
      "Kazuma Hashimoto",
      "Kiran Yalasangi",
      "Krishna Srinivasan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.814": {
    "title": "CycleKQR: Unsupervised Bidirectional Keyword-Question Rewriting",
    "volume": "main",
    "abstract": "Users expect their queries to be answered by search systems, regardless of the query's surface form, which include keyword queries and natural questions. Natural Language Understanding (NLU) components of Search and QA systems may fail to correctly interpret semantically equivalent inputs if this deviates from how the system was trained, leading to suboptimal understanding capabilities. We propose the keyword-question rewriting task to improve query understanding capabilities of NLU systems for all surface forms. To achieve this, we present CycleKQR, an unsupervised approach, enabling effective rewriting between keyword and question queries using non-parallel data. Empirically we show the impact on QA performance of unfamiliar query forms for open domain and Knowledge Base QA systems (trained on either keywords or natural language questions). We demonstrate how CycleKQR significantly improves QA performance by rewriting queries into the appropriate form, while at the same time retaining the original semantic meaning of input queries, allowing CycleKQR to improve performance by up to 3% over supervised baselines. Finally, we release a datasetof 66k keyword-question pairs",
    "checked": true,
    "id": "dba68e64c93d71a2c462e8c40a9074fa5dc3f41e",
    "semantic_title": "cyclekqr: unsupervised bidirectional keyword-question rewriting",
    "citation_count": 2,
    "authors": [
      "Andrea Iovine",
      "Anjie Fang",
      "Besnik Fetahu",
      "Jie Zhao",
      "Oleg Rokhlenko",
      "Shervin Malmasi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.815": {
    "title": "Model Criticism for Long-Form Text Generation",
    "volume": "main",
    "abstract": "Language models have demonstrated the ability to generate highly fluent text; however, it remains unclear whether their output retains coherent high-level structure (e.g., story progression). Here, we propose to apply a statistical tool, model criticism in latent space, to evaluate the high-level structure of the generated text. Model criticism compares the distributions between real and generated data in a latent space obtained according to an assumptive generative process. Different generative processes identify specific failure modes of the underlying model. We perform experiments on three representative aspects of high-level discourse—coherence, coreference, and topicality—and find that transformer-based language models are able to capture topical structures but have a harder time maintaining structural coherence or modeling coreference",
    "checked": true,
    "id": "d9d12205007ac48b03d921225f9cdaf90f7c3fdd",
    "semantic_title": "model criticism for long-form text generation",
    "citation_count": 10,
    "authors": [
      "Yuntian Deng",
      "Volodymyr Kuleshov",
      "Alexander Rush"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.816": {
    "title": "Improving Faithfulness by Augmenting Negative Summaries from Fake Documents",
    "volume": "main",
    "abstract": "Current abstractive summarization systems tend to hallucinate content that is unfaithful to the source document, posing a risk of misinformation. To mitigate hallucination, we must teach the model to distinguish hallucinated summaries from faithful ones. However, the commonly used maximum likelihood training does not disentangle factual errors from other model errors. To address this issue,we propose a back-translation-style approach to augment negative samples that mimic factual errors made by the model. Specifically, we train an elaboration model that generates hallucinated documents given the reference summaries, and then generates negative summaries from the fake documents. We incorporate the negative samples into training through a controlled generator, which produces faithful/unfaithful summaries conditioned on the control codes. Additionally, we find that adding textual entailment data through multitasking further boosts the performance. Experiments on three datasets (XSum, Gigaword, and WikiHow) show that our method consistently improves faithfulness without sacrificing informativeness according to both human and automatic evaluation",
    "checked": true,
    "id": "b459d699b5e5541f3dbf2d56c1107ddbd1b9695d",
    "semantic_title": "improving faithfulness by augmenting negative summaries from fake documents",
    "citation_count": 4,
    "authors": [
      "Tianshu Wang",
      "Faisal Ladhak",
      "Esin Durmus",
      "He He"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.817": {
    "title": "Joint Completion and Alignment of Multilingual Knowledge Graphs",
    "volume": "main",
    "abstract": "Knowledge Graph Completion (KGC) predicts missing facts in an incomplete Knowledge Graph (KG). Multilingual KGs associate entities and relations with surface forms written in different languages. An entity or relation may be associated with distinct IDs in different KGs, necessitating entity alignment (EA) and relation alignment (RA). Many effective algorithms have been proposed for completion and alignment as separate tasks. Here we show that these tasks are synergistic and best solved together. Our multitask approach starts with a state-of-the-art KG embedding scheme, but adds a novel relation representation based on sets of embeddings of (subject, object) entity pairs. This representation leads to a new relation alignment loss term based on a maximal bipartite matching between two sets of embedding vectors. This loss is combined with traditional KGC loss and optionally, losses based on text embeddings of entity (and relation) names. In experiments over KGs in seven languages, we find that our system achieves large improvements in KGC compared to a strong completion model that combines known facts in all languages. It also outperforms strong EA and RA baselines, underscoring the value of joint alignment and completion",
    "checked": true,
    "id": "4e563124f4f67470e56ac2826b2d9ecdcc4ffb70",
    "semantic_title": "joint completion and alignment of multilingual knowledge graphs",
    "citation_count": 5,
    "authors": [
      "Soumen Chakrabarti",
      "Harkanwar Singh",
      "Shubham Lohiya",
      "Prachi Jain",
      "Mausam -"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.818": {
    "title": "Offer a Different Perspective: Modeling the Belief Alignment of Arguments in Multi-party Debates",
    "volume": "main",
    "abstract": "In contexts where debate and deliberation are the norm, the participants are regularly presented with new information that conflicts with their original beliefs. When required to update their beliefs (belief alignment), they may choose arguments that align with their worldview (confirmation bias). We test this and competing hypotheses in a constraint-based modeling approach to predict the winning arguments in multi-party interactions in the Reddit Change My View and Intelligence Squared debates datasets. We adopt a hierarchical generative Variational Autoencoder as our model and impose structural constraints that reflect competing hypotheses about the nature of argumentation. Our findings suggest that in most settings, predictive models that anticipate winning arguments to be further from the initial argument of the opinion holder are more likely to succeed",
    "checked": true,
    "id": "2998c718ba26b7707e2dfe4ab87a4ea2f0356b45",
    "semantic_title": "offer a different perspective: modeling the belief alignment of arguments in multi-party debates",
    "citation_count": 1,
    "authors": [
      "Suzanna Sia",
      "Kokil Jaidka",
      "Hansin Ahuja",
      "Niyati Chhaya",
      "Kevin Duh"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.819": {
    "title": "A Federated Approach to Predicting Emojis in Hindi Tweets",
    "volume": "main",
    "abstract": "The use of emojis affords a visual modality to, often private, textual communication. The task of predicting emojis however provides a challenge for machine learning as emoji use tends to cluster into the frequently used and the rarely used emojis.Much of the machine learning research on emoji use has focused on high resource languages and has conceptualised the task of predicting emojis around traditional server-side machine learning approaches. However, traditional machine learning approaches for private communication can introduce privacy concerns, as these approaches require all data to be transmitted to a central storage. In this paper, we seek to address the dual concerns of emphasising high resource languages for emoji prediction and risking the privacy of people's data. We introduce a new dataset of 118k tweets (augmented from 25k unique tweets) for emoji prediction in Hindi, and propose a modification to the federated learning algorithm, CausalFedGSD, which aims to strike a balance between model performance and user privacy. We show that our approach obtains comparative scores with more complex centralised models while reducing the amount of data required to optimise the models and minimising risks to user privacy",
    "checked": true,
    "id": "dd86f36c4f8abb6beb43d8bdc27250728ea974cb",
    "semantic_title": "a federated approach to predicting emojis in hindi tweets",
    "citation_count": 3,
    "authors": [
      "Deep Gandhi",
      "Jash Mehta",
      "Nirali Parekh",
      "Karan Waghela",
      "Lynette D’Mello",
      "Zeerak Talat"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.820": {
    "title": "Injecting Domain Knowledge in Language Models for Task-oriented Dialogue Systems",
    "volume": "main",
    "abstract": "Pre-trained language models (PLM) have advanced the state-of-the-art across NLP applications, but lack domain-specific knowledge that does not naturally occur in pre-training data. Previous studies augmented PLMs with symbolic knowledge for different downstream NLP tasks. However, knowledge bases (KBs) utilized in these studies are usually large-scale and static, in contrast to small, domain-specific, and modifiable knowledge bases that are prominent in real-world task-oriented dialogue (TOD) systems. In this paper, we showcase the advantages of injecting domain-specific knowledge prior to fine-tuning on TOD tasks. To this end, we utilize light-weight adapters that can be easily integrated with PLMs and serve as a repository for facts learned from different KBs. To measure the efficacy of proposed knowledge injection methods, we introduce Knowledge Probing using Response Selection (KPRS) – a probe designed specifically for TOD models. Experiments on KPRS and the response generation task show improvements of knowledge injection with adapters over strong baselines",
    "checked": true,
    "id": "c1bc6168ee5e8b943d3b904266fc445b08f3aa3d",
    "semantic_title": "injecting domain knowledge in language models for task-oriented dialogue systems",
    "citation_count": 12,
    "authors": [
      "Denis Emelin",
      "Daniele Bonadiman",
      "Sawsan Alqahtani",
      "Yi Zhang",
      "Saab Mansour"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.821": {
    "title": "TASA: Deceiving Question Answering Models by Twin Answer Sentences Attack",
    "volume": "main",
    "abstract": "We present Twin Answer Sentences Attack (TASA), an adversarial attack method for question answering (QA) models that produces fluent and grammatical adversarial contexts while maintaining gold answers. Despite phenomenal progress on general adversarial attacks, few works have investigated the vulnerability and attack specifically for QA models. In this work, we first explore the biases in the existing models and discover that they mainly rely on keyword matching between the question and context, and ignore the relevant contextual relations for answer prediction. Based on two biases above, TASA attacks the target model in two folds: (1) lowering the model's confidence on the gold answer with a perturbed answer sentence; (2) misguiding the model towards a wrong answer with a distracting answer sentence. Equipped with designed beam search and filtering methods, TASA can generate more effective attacks than existing textual attack methods while sustaining the quality of contexts, in extensive experiments on five QA datasets and human evaluations",
    "checked": true,
    "id": "fe36f5fa06eabc57a59c5da95887c33d8c67efa1",
    "semantic_title": "tasa: deceiving question answering models by twin answer sentences attack",
    "citation_count": 6,
    "authors": [
      "Yu Cao",
      "Dianqi Li",
      "Meng Fang",
      "Tianyi Zhou",
      "Jun Gao",
      "Yibing Zhan",
      "Dacheng Tao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.822": {
    "title": "Improving Low-Resource Languages in Pre-Trained Multilingual Language Models",
    "volume": "main",
    "abstract": "Pre-trained multilingual language models are the foundation of many NLP approaches, including cross-lingual transfer solutions. However, languages with small available monolingual corpora are often not well-supported by these models leading to poor performance. We propose an unsupervised approach to improve the cross-lingual representations of low-resource languages by bootstrapping word translation pairs from monolingual corpora and using them to improve language alignment in pre-trained language models. We perform experiments on nine languages, using contextual word retrieval and zero-shot named entity recognition to measure both intrinsic cross-lingual word representation quality and downstream task performance, showing improvements on both tasks. Our results show that it is possible to improve pre-trained multilingual language models by relying only on non-parallel resources",
    "checked": true,
    "id": "2ac5442a32988f86730e460b3198f475592ae410",
    "semantic_title": "improving low-resource languages in pre-trained multilingual language models",
    "citation_count": 8,
    "authors": [
      "Viktor Hangya",
      "Hossain Shaikh Saadi",
      "Alexander Fraser"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.823": {
    "title": "SCROLLS: Standardized CompaRison Over Long Language Sequences",
    "volume": "main",
    "abstract": "NLP benchmarks have largely focused on short texts, such as sentences and paragraphs, even though long texts comprise a considerable amount of natural language in the wild. We introduce SCROLLS, a suite of tasks that require reasoning over long texts. We examine existing long-text datasets, and handpick ones where the text is naturally long, while prioritizing tasks that involve synthesizing information across the input. SCROLLS contains summarization, question answering, and natural language inference tasks, covering multiple domains, including literature, science, business, and entertainment. Initial baselines, including Longformer Encoder-Decoder, indicate that there is ample room for improvement on SCROLLS. We make all datasets available in a unified text-to-text format and host a live leaderboard to facilitate research on model architecture and pretraining methods",
    "checked": true,
    "id": "6281c40c66febca1d8003bcc6fdfd2189b30c38f",
    "semantic_title": "scrolls: standardized comparison over long language sequences",
    "citation_count": 79,
    "authors": [
      "Uri Shaham",
      "Elad Segal",
      "Maor Ivgi",
      "Avia Efrat",
      "Ori Yoran",
      "Adi Haviv",
      "Ankit Gupta",
      "Wenhan Xiong",
      "Mor Geva",
      "Jonathan Berant",
      "Omer Levy"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.824": {
    "title": "PAR: Political Actor Representation Learning with Social Context and Expert Knowledge",
    "volume": "main",
    "abstract": "Modeling the ideological perspectives of political actors is an essential task in computational political science with applications in many downstream tasks. Existing approaches are generally limited to textual data and voting records, while they neglect the rich social context and valuable expert knowledge for holistic ideological analysis. In this paper, we propose PAR, a Political Actor Representation learning framework that jointly leverages social context and expert knowledge. Specifically, we retrieve and extract factual statements about legislators to leverage social context information. We then construct a heterogeneous information network to incorporate social context and use relational graph neural networks to learn legislator representations. Finally, we train PAR with three objectives to align representation learning with expert knowledge, model ideological stance consistency, and simulate the echo chamber phenomenon. Extensive experiments demonstrate that PAR is better at augmenting political text understanding and successfully advances the state-of-the-art in political perspective detection and roll call vote prediction. Further analysis proves that PAR learns representations that reflect the political reality and provide new insights into political behavior",
    "checked": true,
    "id": "b4c9b57c0d9aacfa98db6247015def1826172bbd",
    "semantic_title": "par: political actor representation learning with social context and expert knowledge",
    "citation_count": 9,
    "authors": [
      "Shangbin Feng",
      "Zhaoxuan Tan",
      "Zilong Chen",
      "Ningnan Wang",
      "Peisheng Yu",
      "Qinghua Zheng",
      "Xiaojun Chang",
      "Minnan Luo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.825": {
    "title": "JDDC 2.1: A Multimodal Chinese Dialogue Dataset with Joint Tasks of Query Rewriting, Response Generation, Discourse Parsing, and Summarization",
    "volume": "main",
    "abstract": "The popularity of multimodal dialogue has stimulated the need for a new generation of dialogue agents with multimodal interactivity. When users communicate with customer service, they may express their requirements by means of text, images, or even videos. Visual information usually acts as discriminators for product models, or indicators of product failures, which play an important role in the E-commerce scenario. On the other hand, detailed information provided by the images is limited, and typically, customer service systems cannot understand the intent of users without the input text. Thus, bridging the gap between the image and text is crucial for communicating with customers. In this paper, we construct JDDC 2.1, a large-scale multimodal multi-turn dialogue dataset collected from a mainstream Chinese E-commerce platform, containing about 246K dialogue sessions, 3M utterances, and 507K images, along with product knowledge bases and image category annotations. Over our dataset, we jointly define four tasks: the multimodal dialogue response generation task,the multimodal query rewriting task, the multimodal dialogue discourse parsing task, and the multimodal dialogue summarization task.JDDC 2.1 is the first corpus with annotations for all the above tasks over the same dialogue sessions, which facilitates the comprehensive research around the dialogue. In addition, we present several text-only and multimodal baselines and show the importance of visual information for these tasks. Our dataset and implements will be publicly available",
    "checked": true,
    "id": "c91a52946e0601c8f63355157789b5aa2776882f",
    "semantic_title": "jddc 2.1: a multimodal chinese dialogue dataset with joint tasks of query rewriting, response generation, discourse parsing, and summarization",
    "citation_count": 4,
    "authors": [
      "Nan Zhao",
      "Haoran Li",
      "Youzheng Wu",
      "Xiaodong He"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.826": {
    "title": "PCL: Peer-Contrastive Learning with Diverse Augmentations for Unsupervised Sentence Embeddings",
    "volume": "main",
    "abstract": "Learning sentence embeddings in an unsupervised manner is fundamental in natural language processing. Recent common practice is to couple pre-trained language models with unsupervised contrastive learning, whose success relies on augmenting a sentence with a semantically-close positive instance to construct contrastive pairs. Nonetheless, existing approaches usually depend on a mono-augmenting strategy, which causes learning shortcuts towards the augmenting biases and thus corrupts the quality of sentence embeddings. A straightforward solution is resorting to more diverse positives from a multi-augmenting strategy, while an open question remains about how to unsupervisedly learn from the diverse positives but with uneven augmenting qualities in the text field. As one answer, we propose a novel Peer-Contrastive Learning (PCL) with diverse augmentations. PCL constructs diverse contrastive positives and negatives at the group level for unsupervised sentence embeddings. PCL performs peer-positive contrast as well as peer-network cooperation, which offers an inherent anti-bias ability and an effective way to learn from diverse augmentations. Experiments on STS benchmarks verify the effectiveness of PCL against its competitors in unsupervised sentence embeddings",
    "checked": true,
    "id": "11500f6a5a5f00969b7600a8047e0c08ece4d9d2",
    "semantic_title": "pcl: peer-contrastive learning with diverse augmentations for unsupervised sentence embeddings",
    "citation_count": 18,
    "authors": [
      "Qiyu Wu",
      "Chongyang Tao",
      "Tao Shen",
      "Can Xu",
      "Xiubo Geng",
      "Daxin Jiang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.827": {
    "title": "Digging Errors in NMT: Evaluating and Understanding Model Errors from Partial Hypothesis Space",
    "volume": "main",
    "abstract": "Solid evaluation of neural machine translation (NMT) is key to its understanding and improvement. Current evaluation of an NMT system is usually built upon a heuristic decoding algorithm (e.g., beam search) and an evaluation metric assessing similarity between the translation and golden reference. However, this system-level evaluation framework is limited by evaluating only one best hypothesis and search errors brought by heuristic decoding algorithms. To better understand NMT models, we propose a novel evaluation protocol, which defines model errors with model's ranking capability over hypothesis space. To tackle the problem of exponentially large space, we propose two approximation methods, top region evaluation along with an exact top-k decoding algorithm, which finds top-ranked hypotheses in the whole hypothesis space, and Monte Carlo sampling evaluation, which simulates hypothesis space from a broader perspective. To quantify errors, we define our NMT model errors by measuring distance between the hypothesis array ranked by the model and the ideally ranked hypothesis array. After confirming the strong correlation with human judgment, we apply our evaluation to various NMT benchmarks and model architectures. We show that the state-of-the-art Transformer models face serious ranking issues and only perform at the random chance level in the top region. We further analyze model errors on architectures with different depths and widths, as well as different data-augmentation techniques, showing how these factors affect model errors. Finally, we connect model errors with the search algorithms and provide interesting findings of beam search inductive bias and correlation with Minimum Bayes Risk (MBR) decoding",
    "checked": true,
    "id": "90f7cbdc6f649f1b058df0bab1b9e52a86c28d76",
    "semantic_title": "digging errors in nmt: evaluating and understanding model errors from partial hypothesis space",
    "citation_count": 0,
    "authors": [
      "Jianhao Yan",
      "Chenming Wu",
      "Fandong Meng",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-main.828": {
    "title": "DialogConv: A Lightweight Fully Convolutional Network for Multi-view Response Selection",
    "volume": "main",
    "abstract": "Current end-to-end retrieval-based dialogue systems are mainly based on Recurrent Neural Networks or Transformers with attention mechanisms. Although promising results have been achieved, these models often suffer from slow inference or huge number of parameters. In this paper, we propose a novel lightweight fully convolutional architecture, called DialogConv, for response selection. DialogConv is exclusively built on top of convolution to extract matching features of context and response. Dialogues are modeled in 3D views, where DialogConv performs convolution operations on embedding view, word view and utterance view to capture richer semantic information from multiple contextual views. On the four benchmark datasets, compared with state-of-the-art baselines, DialogConv is on average about 8.5x smaller in size, and 79.39x and 10.64x faster on CPU and GPU devices, respectively. At the same time, DialogConv achieves the competitive effectiveness of response selection",
    "checked": true,
    "id": "36b1bb9d1149586ae4e9a1867a179760051028e9",
    "semantic_title": "dialogconv: a lightweight fully convolutional network for multi-view response selection",
    "citation_count": 2,
    "authors": [
      "Yongkang Liu",
      "Shi Feng",
      "Wei Gao",
      "Daling Wang",
      "Yifei Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-tutorials.1": {
    "title": "Meaning Representations for Natural Languages: Design, Models and Applications",
    "volume": "tutorial",
    "abstract": "This tutorial reviews the design of common meaning representations, SoTA models for predicting meaning representations, and the applications of meaning representations in a wide range of downstream NLP tasks and real-world applications. Reporting by a diverse team of NLP researchers from academia and industry with extensive experience in designing, building and using meaning representations, our tutorial has three components: (1) an introduction to common meaning representations, including basic concepts and design challenges; (2) a review of SoTA methods on building models for meaning representations; and (3) an overview of applications of meaning representations in downstream NLP tasks and real-world applications. We will also present qualitative comparisons of common meaning representations and a quantitative study on how their differences impact model performance. Finally, we will share best practices in choosing the right meaning representation for downstream tasks",
    "checked": true,
    "id": "5f02c45168ebe30d05f12b5178a93cb7186cd4df",
    "semantic_title": "meaning representations for natural languages: design, models and applications",
    "citation_count": 0,
    "authors": [
      "Jeffrey Flanigan",
      "Ishan Jindal",
      "Yunyao Li",
      "Tim O’Gorman",
      "Martha Palmer",
      "Nianwen Xue"
    ]
  },
  "https://aclanthology.org/2022.emnlp-tutorials.2": {
    "title": "Arabic Natural Language Processing",
    "volume": "tutorial",
    "abstract": "The Arabic language continues to be the focus of an increasing number of projects in natural language processing (NLP) and computational linguistics (CL). This tutorial provides NLP/CL system developers and researchers (computer scientists and linguists alike) with the necessary background information for working with Arabic in its various forms: Classical, Modern Standard and Dialectal. We discuss various Arabic linguistic phenomena and review the state-of-the-art in Arabic processing from enabling technologies and resources, to common tasks and applications. The tutorial will explain important concepts, common wisdom, and common pitfalls in Arabic processing. Given the wide range of possible issues, we invite tutorial attendees to bring up interesting challenges and problems they are working on to discuss during the tutorial",
    "checked": true,
    "id": "0beb7b527bb6d53ad5250654008eaffc44686cd5",
    "semantic_title": "arabic natural language processing",
    "citation_count": 11,
    "authors": [
      "Nizar Habash"
    ]
  },
  "https://aclanthology.org/2022.emnlp-tutorials.3": {
    "title": "Emergent Language-Based Coordination In Deep Multi-Agent Systems",
    "volume": "tutorial",
    "abstract": "Large pre-trained deep networks are the standard building blocks of modern AI applications. This raises fundamental questions about how to control their behaviour and how to make them efficiently interact with each other. Deep net emergent communication tackles these challenges by studying how to induce communication protocols between neural network agents, and how to include humans in the communication loop. Traditionally, this research had focussed on relatively small-scale experiments where two networks had to develop a discrete code from scratch for referential communication. However, with the rise of large pre-trained language models that can work well on many tasks, the emphasis is now shifting on how to let these models interact through a language-like channel to engage in more complex behaviors. By reviewing several representative papers, we will provide an introduction to deep net emergent communication, we will cover various central topics from the present and recent past, as well as discussing current shortcomings and suggest future directions. The presentation is complemented by a hands-on section where participants will implement and analyze two emergent communications setups from the literature. The tutorial should be of interest to researchers wanting to develop more flexible AI systems, but also to cognitive scientists and linguists interested in the evolution of communication systems",
    "checked": true,
    "id": "9e5b99f3bf5383e75ceb858149b9ecf03304287b",
    "semantic_title": "emergent language-based coordination in deep multi-agent systems",
    "citation_count": 0,
    "authors": [
      "Marco Baroni",
      "Roberto Dessi",
      "Angeliki Lazaridou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-tutorials.4": {
    "title": "CausalNLP Tutorial: An Introduction to Causality for Natural Language Processing",
    "volume": "tutorial",
    "abstract": "Causal inference is becoming an increasingly important topic in deep learning, with the potential to help with critical deep learning problems such as model robustness, interpretability, and fairness. In addition, causality is naturally widely used in various disciplines of science, to discover causal relationships among variables and estimate causal effects of interest. In this tutorial, we introduce the fundamentals of causal discovery and causal effect estimation to the natural language processing (NLP) audience, provide an overview of causal perspectives to NLP problems, and aim to inspire novel approaches to NLP further. This tutorial is inclusive to a variety of audiences and is expected to facilitate the community's developments in formulating and addressing new, important NLP problems in light of emerging causal principles and methodologies",
    "checked": true,
    "id": "0b031700fd4fb450ee7fabbd2120900e73c95c54",
    "semantic_title": "causalnlp tutorial: an introduction to causality for natural language processing",
    "citation_count": 4,
    "authors": [
      "Zhijing Jin",
      "Amir Feder",
      "Kun Zhang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-tutorials.5": {
    "title": "Modular and Parameter-Efficient Fine-Tuning for NLP Models",
    "volume": "tutorial",
    "abstract": "State-of-the-art language models in NLP perform best when fine-tuned even on small datasets, but due to their increasing size, fine-tuning and downstream usage have become extremely compute-intensive. Being able to efficiently and effectively fine-tune the largest pre-trained models is thus key in order to reap the benefits of the latest advances in NLP. In this tutorial, we provide a comprehensive overview of parameter-efficient fine-tuning methods. We highlight their similarities and differences by presenting them in a unified view. We explore the benefits and usage scenarios of a neglected property of such parameter-efficient models—modularity—such as composition of modules to deal with previously unseen data conditions. We finally highlight how both properties——parameter efficiency and modularity——can be useful in the real-world setting of adapting pre-trained models to under-represented languages and domains with scarce annotated data for several downstream applications",
    "checked": true,
    "id": "ddd9fb4516561a36b46860b5dc102981dca34134",
    "semantic_title": "modular and parameter-efficient fine-tuning for nlp models",
    "citation_count": 9,
    "authors": [
      "Sebastian Ruder",
      "Jonas Pfeiffer",
      "Ivan Vulić"
    ]
  },
  "https://aclanthology.org/2022.emnlp-tutorials.6": {
    "title": "Non-Autoregressive Models for Fast Sequence Generation",
    "volume": "tutorial",
    "abstract": "Autoregressive (AR) models have achieved great success in various sequence generation tasks. However, AR models can only generate target sequence word-by-word due to the AR mechanism and hence suffer from slow inference. Recently, non-autoregressive (NAR) models, which generate all the tokens in parallel by removing the sequential dependencies within the target sequence, have received increasing attention in sequence generation tasks such as neural machine translation (NMT), automatic speech recognition (ASR), and text to speech (TTS). In this tutorial, we will provide a comprehensive introduction to non-autoregressive sequence generation",
    "checked": true,
    "id": "f41739647288725831048998aee9d708851e9652",
    "semantic_title": "non-autoregressive models for fast sequence generation",
    "citation_count": 1,
    "authors": [
      "Yang Feng",
      "Chenze Shao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.1": {
    "title": "CogKTR: A Knowledge-Enhanced Text Representation Toolkit for Natural Language Understanding",
    "volume": "demo",
    "abstract": "As the first step of modern natural language processing, text representation encodes discrete texts as continuous embeddings. Pre-trained language models (PLMs) have demonstrated strong ability in text representation and significantly promoted the development of natural language understanding (NLU). However, existing PLMs represent a text solely by its context, which is not enough to support knowledge-intensive NLU tasks. Knowledge is power, and fusing external knowledge explicitly into PLMs can provide knowledgeable text representations. Since previous knowledge-enhanced methods differ in many aspects, making it difficult for us to reproduce previous methods, implement new methods, and transfer between different methods. It is highly desirable to have a unified paradigm to encompass all kinds of methods in one framework. In this paper, we propose CogKTR, a knowledge-enhanced text representation toolkit for natural language understanding. According to our proposed Unified Knowledge-Enhanced Paradigm (UniKEP), CogKTR consists of four key stages, including knowledge acquisition, knowledge representation, knowledge injection, and knowledge application. CogKTR currently supports easy-to-use knowledge acquisition interfaces, multi-source knowledge embeddings, diverse knowledge-enhanced models, and various knowledge-intensive NLU tasks. Our unified, knowledgeable and modular toolkit is publicly available at GitHub, with an online system and a short instruction video",
    "checked": true,
    "id": "75e9d631955838c139cd6bcfb1d1e2b022d86b2e",
    "semantic_title": "cogktr: a knowledge-enhanced text representation toolkit for natural language understanding",
    "citation_count": 0,
    "authors": [
      "Zhuoran Jin",
      "Tianyi Men",
      "Hongbang Yuan",
      "Yuyang Zhou",
      "Pengfei Cao",
      "Yubo Chen",
      "Zhipeng Xue",
      "Kang Liu",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.2": {
    "title": "LM-Debugger: An Interactive Tool for Inspection and Intervention in Transformer-Based Language Models",
    "volume": "demo",
    "abstract": "The opaque nature and unexplained behavior of transformer-based language models (LMs) have spurred a wide interest in interpreting their predictions. However, current interpretation methods mostly focus on probing models from outside, executing behavioral tests, and analyzing salience input features, while the internal prediction construction process is largely not understood. In this work, we introduce LM-Debugger, an interactive debugger tool for transformer-based LMs, which provides a fine-grained interpretation of the model's internal prediction process, as well as a powerful framework for intervening in LM behavior. For its backbone, LM-Debugger relies on a recent method that interprets the inner token representations and their updates by the feed-forward layers in the vocabulary space. We demonstrate the utility of LM-Debugger for single-prediction debugging, by inspecting the internal disambiguation process done by GPT2. Moreover, we show how easily LM-Debugger allows to shift model behavior in a direction of the user's choice, by identifying a few vectors in the network and inducing effective interventions to the prediction process. We release LM-Debugger as an open-source tool and a demo over GPT2 models",
    "checked": true,
    "id": "e6ecbf7b24fd10406416cd5e4e6c2839277f03a2",
    "semantic_title": "lm-debugger: an interactive tool for inspection and intervention in transformer-based language models",
    "citation_count": 22,
    "authors": [
      "Mor Geva",
      "Avi Caciularu",
      "Guy Dar",
      "Paul Roit",
      "Shoval Sadde",
      "Micah Shlain",
      "Bar Tamir",
      "Yoav Goldberg"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.3": {
    "title": "EasyNLP: A Comprehensive and Easy-to-use Toolkit for Natural Language Processing",
    "volume": "demo",
    "abstract": "Pre-Trained Models (PTMs) have reshaped the development of Natural Language Processing (NLP) and achieved significant improvement in various benchmarks. Yet, it is not easy for industrial practitioners to obtain high-performing PTM-based models without a large amount of labeled training data and deploy them online with fast inference speed. To bridge this gap, EasyNLP is designed to make it easy to build NLP applications, which supports a comprehensive suite of NLP algorithms. It further features knowledge-enhanced pre-training, knowledge distillation and few-shot learning functionalities, and provides a unified framework of model training, inference and deployment for real-world applications. EasyNLP has powered over ten business units within Alibaba Group and is seamlessly integrated to the Platform of AI (PAI) products on Alibaba Cloud. The source code of EasyNLP is released at GitHub (https://github.com/alibaba/EasyNLP)",
    "checked": true,
    "id": "6d19a6ba6b1e89fb81ce100452c069d011ac8e40",
    "semantic_title": "easynlp: a comprehensive and easy-to-use toolkit for natural language processing",
    "citation_count": 20,
    "authors": [
      "Chengyu Wang",
      "Minghui Qiu",
      "Taolin Zhang",
      "Tingting Liu",
      "Lei Li",
      "Jianing Wang",
      "Ming Wang",
      "Jun Huang",
      "Wei Lin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.4": {
    "title": "An Explainable Toolbox for Evaluating Pre-trained Vision-Language Models",
    "volume": "demo",
    "abstract": "We introduce VL-CheckList, a toolbox for evaluating Vision-Language Pretraining (VLP) models, including the preliminary datasets that deepen the image-texting ability of a VLP model. Most existing VLP works evaluated their systems by comparing the fine-tuned downstream task performance. However, only average downstream task accuracy provides little information about the pros and cons of each VLP method. In this paper, we demonstrate how minor input changes in language and vision will affect the prediction outputs. Then, we describe the detailed user guidelines to utilize and contribute to the community. We show new findings on one of the representative VLP models to provide an example analysis. The data/code is available at https://github.com/om-ai-lab/VL-CheckList",
    "checked": true,
    "id": "8165b22a94a8bc3269c54cf51511c40d26b0048e",
    "semantic_title": "an explainable toolbox for evaluating pre-trained vision-language models",
    "citation_count": 6,
    "authors": [
      "Tiancheng Zhao",
      "Tianqi Zhang",
      "Mingwei Zhu",
      "Haozhan Shen",
      "Kyusong Lee",
      "Xiaopeng Lu",
      "Jianwei Yin"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.5": {
    "title": "TweetNLP: Cutting-Edge Natural Language Processing for Social Media",
    "volume": "demo",
    "abstract": "In this paper we present TweetNLP, an integrated platform for Natural Language Processing (NLP) in social media. TweetNLP supports a diverse set of NLP tasks, including generic focus areas such as sentiment analysis and named entity recognition, as well as social media-specific tasks such as emoji prediction and offensive language identification. Task-specific systems are powered by reasonably-sized Transformer-based language models specialized on social media text (in particular, Twitter) which can be run without the need for dedicated hardware or cloud services. The main contributions of TweetNLP are: (1) an integrated Python library for a modern toolkit supporting social media analysis using our various task-specific models adapted to the social domain; (2) an interactive online demo for codeless experimentation using our models; and (3) a tutorial covering a wide variety of typical social media applications",
    "checked": true,
    "id": "4e0526421da87d88627fef66e9e84ed559fff249",
    "semantic_title": "tweetnlp: cutting-edge natural language processing for social media",
    "citation_count": 35,
    "authors": [
      "Jose Camacho-collados",
      "Kiamehr Rezaee",
      "Talayeh Riahi",
      "Asahi Ushio",
      "Daniel Loureiro",
      "Dimosthenis Antypas",
      "Joanne Boisson",
      "Luis Espinosa Anke",
      "Fangyu Liu",
      "Eugenio Martínez Cámara"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.6": {
    "title": "JoeyS2T: Minimalistic Speech-to-Text Modeling with JoeyNMT",
    "volume": "demo",
    "abstract": "JoeyS2T is a JoeyNMT extension for speech-to-text tasks such as automatic speech recognition and end-to-end speech translation. It inherits the core philosophy of JoeyNMT, a minimalist NMT toolkit built on PyTorch, seeking simplicity and accessibility. JoeyS2T's workflow is self-contained, starting from data pre-processing, over model training and prediction to evaluation, and is seamlessly integrated into JoeyNMT's compact and simple code base. On top of JoeyNMT's state-of-the-art Transformer-based Encoder-Decoder architecture, JoeyS2T provides speech-oriented components such as convolutional layers, SpecAugment, CTC-loss, and WER evaluation. Despite its simplicity compared to prior implementations, JoeyS2T performs competitively on English speech recognition and English-to-German speech translation benchmarks. The implementation is accompanied by a walk-through tutorial and available on https://github.com/may-/joeys2t",
    "checked": true,
    "id": "f5669510806e6a671cece0920b7593adafdae7d8",
    "semantic_title": "joeys2t: minimalistic speech-to-text modeling with joeynmt",
    "citation_count": 0,
    "authors": [
      "Mayumi Ohta",
      "Julia Kreutzer",
      "Stefan Riezler"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.7": {
    "title": "FairLib: A Unified Framework for Assessing and Improving Fairness",
    "volume": "demo",
    "abstract": "This paper presents FairLib, an open-source python library for assessing and improving model fairness. It provides a systematic framework for quickly accessing benchmark datasets, reproducing existing debiasing baseline models, developing new methods, evaluating models with different metrics, and visualizing their results. Its modularity and extensibility enable the framework to be used for diverse types of inputs, including natural language, images, and audio. We implement 14 debiasing methods, including pre-processing,at-training-time, and post-processing approaches. The built-in metrics cover the most commonly acknowledged fairness criteria and can be further generalized and customized for fairness evaluation",
    "checked": true,
    "id": "1106d264f99e674f6d3630cb5b2fd62f3e3fc042",
    "semantic_title": "fairlib: a unified framework for assessing and improving fairness",
    "citation_count": 6,
    "authors": [
      "Xudong Han",
      "Aili Shen",
      "Yitong Li",
      "Lea Frermann",
      "Timothy Baldwin",
      "Trevor Cohn"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.8": {
    "title": "ELEVANT: A Fully Automatic Fine-Grained Entity Linking Evaluation and Analysis Tool",
    "volume": "demo",
    "abstract": "We present Elevant, a tool for the fully automatic fine-grained evaluation of a set of entity linkers on a set of benchmarks. Elevant provides an automatic breakdown of the performance by various error categories and by entity type. Elevant also provides a rich and compact, yet very intuitive and self-explanatory visualization of the results of a linker on a benchmark in comparison to the ground truth. A live demo, the link to the complete code base on GitHub and a link to a demo video are provided under https://elevant.cs.uni-freiburg.de",
    "checked": true,
    "id": "42cbbc8a3e507eb2f09b1153d07f054f9acdcd73",
    "semantic_title": "elevant: a fully automatic fine-grained entity linking evaluation and analysis tool",
    "citation_count": 2,
    "authors": [
      "Hannah Bast",
      "Matthias Hertel",
      "Natalie Prange"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.9": {
    "title": "A Pipeline for Generating, Annotating and Employing Synthetic Data for Real World Question Answering",
    "volume": "demo",
    "abstract": "Question Answering (QA) is a growing area of research, often used to facilitate the extraction of information from within documents. State-of-the-art QA models are usually pre-trained on domain-general corpora like Wikipedia and thus tend to struggle on out-of-domain documents without fine-tuning. We demonstrate that synthetic domain-specific datasets can be generated easily using domain-general models, while still providing significant improvements to QA performance. We present two new tools for this task: A flexible pipeline for validating the synthetic QA data and training down stream models on it, and an online interface to facilitate human annotation of this generated data. Using this interface, crowdworkers labelled 1117 synthetic QA pairs, which we then used to fine-tune downstream models and improve domain-specific QA performance by 8.75 F1",
    "checked": true,
    "id": "d3c6f2c2efc715ec1a2cc192c4d52804ca0cb540",
    "semantic_title": "a pipeline for generating, annotating and employing synthetic data for real world question answering",
    "citation_count": 1,
    "authors": [
      "Matt Maufe",
      "James Ravenscroft",
      "Rob Procter",
      "Maria Liakata"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.10": {
    "title": "DeepKE: A Deep Learning Based Knowledge Extraction Toolkit for Knowledge Base Population",
    "volume": "demo",
    "abstract": "We present an open-source and extensible knowledge extraction toolkit DeepKE, supporting complicated low-resource, document-level and multimodal scenarios in the knowledge base population. DeepKE implements various information extraction tasks, including named entity recognition, relation extraction and attribute extraction. With a unified framework, DeepKE allows developers and researchers to customize datasets and models to extract information from unstructured data according to their requirements. Specifically, DeepKE not only provides various functional modules and model implementation for different tasks and scenarios but also organizes all components by consistent frameworks to maintain sufficient modularity and extensibility. We release the source code at GitHub in https://github.com/zjunlp/DeepKE with Google Colab tutorials and comprehensive documents for beginners. Besides, we present an online system in http://deepke.openkg.cn/EN/re_doc_show.html for real-time extraction of various tasks, and a demo video",
    "checked": true,
    "id": "ee024f8287e264ec8f8aa2795ae425f6e9e0c0c1",
    "semantic_title": "deepke: a deep learning based knowledge extraction toolkit for knowledge base population",
    "citation_count": 27,
    "authors": [
      "Ningyu Zhang",
      "Xin Xu",
      "Liankuan Tao",
      "Haiyang Yu",
      "Hongbin Ye",
      "Shuofei Qiao",
      "Xin Xie",
      "Xiang Chen",
      "Zhoubo Li",
      "Lei Li"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.11": {
    "title": "AnEMIC: A Framework for Benchmarking ICD Coding Models",
    "volume": "demo",
    "abstract": "Diagnostic coding, or ICD coding, is the task of assigning diagnosis codes defined by the ICD (International Classification of Diseases) standard to patient visits based on clinical notes. The current process of manual ICD coding is time-consuming and often error-prone, which suggests the need for automatic ICD coding. However, despite the long history of automatic ICD coding, there have been no standardized frameworks for benchmarking ICD coding models. We open-source an easy-to-use tool named AnEMIC, which provides a streamlined pipeline for preprocessing, training, and evaluating for automatic ICD coding. We correct errors in preprocessing by existing works, and provide key models and weights trained on the correctly preprocessed datasets. We also provide an interactive demo performing real-time inference from custom inputs, and visualizations drawn from explainable AI to analyze the models. We hope the framework helps move the research of ICD coding forward and helps professionals explore the potential of ICD coding. The framework and the associated code are available here",
    "checked": true,
    "id": "fbd5476aa5cf8f952b02f960348eac1b156721c7",
    "semantic_title": "anemic: a framework for benchmarking icd coding models",
    "citation_count": 3,
    "authors": [
      "Juyong Kim",
      "Abheesht Sharma",
      "Suhas Shanbhogue",
      "Jeremy Weiss",
      "Pradeep Ravikumar"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.12": {
    "title": "SPEAR : Semi-supervised Data Programming in Python",
    "volume": "demo",
    "abstract": "We present SPEAR, an open-source python library for data programming with semi supervision. The package implements several recent data programming approaches including facility to programmatically label and build training data. SPEAR facilitates weak supervision in the form of heuristics (or rules) and association of noisy labels to the training dataset. These noisy labels are aggregated to assign labels to the unlabeled data for downstream tasks. We have implemented several label aggregation approaches that aggregate the noisy labels and then train using the noisily labeled set in a cascaded manner. Our implementation also includes other approaches that jointly aggregate and train the model for text classification tasks. Thus, in our python package, we integrate several cascade and joint data-programming approaches while also providing the facility of data programming by letting the user define labeling functions or rules. The code and tutorial notebooks are available at https://github.com/decile-team/spear. Further, extensive documentation can be found at https://spear-decile.readthedocs.io/. Video tutorials demonstrating the usage of our package are available https://youtube.com/playlist?list=PLW8agt_HvkVnOJoJAqBpaerFb-z-ZlqlP. We also present some real-world use cases of SPEAR",
    "checked": true,
    "id": "a2accb8cea3701600882a886e0fc786f3b3b90a9",
    "semantic_title": "spear : semi-supervised data programming in python",
    "citation_count": 7,
    "authors": [
      "Guttu Abhishek",
      "Harshad Ingole",
      "Parth Laturia",
      "Vineeth Dorna",
      "Ayush Maheshwari",
      "Ganesh Ramakrishnan",
      "Rishabh Iyer"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.13": {
    "title": "Evaluate & Evaluation on the Hub: Better Best Practices for Data and Model Measurements",
    "volume": "demo",
    "abstract": "Evaluation is a key part of machine learning (ML), yet there is a lack of support and tooling to enable its informed and systematic practice. We introduce Evaluate and Evaluation on the Hub—a set of tools to facilitate the evaluation of models and datasets in ML. Evaluate is a library to support best practices for measurements, metrics, and comparisons of data and models. Its goal is to support reproducibility of evaluation, centralize and document the evaluation process, and broaden evaluation to cover more facets of model performance. It includes over 50 efficient canonical implementations for a variety of domains and scenarios, interactive documentation, and the ability to easily share implementations and outcomes. The library is available at https://github.com/huggingface/evaluate. In addition, we introduce Evaluation on the Hub, a platform that enables the large-scale evaluation of over 75,000 models and 11,000 datasets on the Hugging Face Hub, for free, at the click of a button. Evaluation on the Hub is available at https://huggingface.co/autoevaluate",
    "checked": true,
    "id": "fad6cfcf1349eb779f61a3efbe633ee7027549d2",
    "semantic_title": "evaluate & evaluation on the hub: better best practices for data and model measurements",
    "citation_count": 14,
    "authors": [
      "Leandro Von Werra",
      "Lewis Tunstall",
      "Abhishek Thakur",
      "Sasha Luccioni",
      "Tristan Thrush",
      "Aleksandra Piktus",
      "Felix Marty",
      "Nazneen Rajani",
      "Victor Mustar",
      "Helen Ngo"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.14": {
    "title": "KeywordScape: Visual Document Exploration using Contextualized Keyword Embeddings",
    "volume": "demo",
    "abstract": "Although contextualized word embeddings have led to great improvements in automatic language understanding, their potential for practical applications in document exploration and visualization has been little explored. Common visualization techniques used for, e.g., model analysis usually provide simple scatter plots of token-level embeddings that do not provide insight into their contextual use. In this work, we propose KeywordScape, a visual exploration tool that allows to overview, summarize, and explore the semantic content of documents based on their keywords. While existing keyword-based exploration tools assume that keywords have static meanings, our tool represents keywords in terms of their contextualized embeddings. Our application visualizes these embeddings in a semantic landscape that represents keywords as islands on a spherical map. This keeps keywords with similar context close to each other, allowing for a more precise search and comparison of documents",
    "checked": true,
    "id": "2ab02e5a42f89ac15e1f2f9a9222e10bb408400f",
    "semantic_title": "keywordscape: visual document exploration using contextualized keyword embeddings",
    "citation_count": 2,
    "authors": [
      "Henrik Voigt",
      "Monique Meuschke",
      "Sina Zarrieß",
      "Kai Lawonn"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.15": {
    "title": "MedConQA: Medical Conversational Question Answering System based on Knowledge Graphs",
    "volume": "demo",
    "abstract": "The medical conversational system can relieve doctors' burden and improve healthcare efficiency, especially during the COVID-19 pandemic. However, the existing medical dialogue systems have the problems of weak scalability, insufficient knowledge, and poor controllability. Thus, we propose a medical conversational question-answering (CQA) system based on the knowledge graph, namely MedConQA, which is designed as a pipeline framework to maintain high flexibility. Our system utilizes automated medical procedures, including medical triage, consultation, image-text drug recommendation, and record. Each module has been open-sourced as a tool, which can be used alone or in combination, with robust scalability. Besides, to conduct knowledge-grounded dialogues with users, we first construct a Chinese Medical Knowledge Graph (CMKG) and collect a large-scale Chinese Medical CQA (CMCQA) dataset, and we design a series of methods for reasoning more intellectually. Finally, we use several state-of-the-art (SOTA) techniques to keep the final generated response more controllable, which is further assured by hospital and professional evaluations. We have open-sourced related code, datasets, web pages, and tools, hoping to advance future research",
    "checked": true,
    "id": "79bbf1fb50dfb9989c3fb5dd3cfa7112f9a7394f",
    "semantic_title": "medconqa: medical conversational question answering system based on knowledge graphs",
    "citation_count": 9,
    "authors": [
      "Fei Xia",
      "Bin Li",
      "Yixuan Weng",
      "Shizhu He",
      "Kang Liu",
      "Bin Sun",
      "Shutao Li",
      "Jun Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.16": {
    "title": "Label Sleuth: From Unlabeled Text to a Classifier in a Few Hours",
    "volume": "demo",
    "abstract": "Label Sleuth is an open source platform for building text classifiers which does not require coding skills nor machine learning knowledge.- Project website: [https://www.label-sleuth.org/](https://www.label-sleuth.org/)- Link to screencast video: [https://vimeo.com/735675461](https://vimeo.com/735675461)### AbstractText classification can be useful in many real-world scenarios, saving a lot of time for end users. However, building a classifier generally requires coding skills and ML knowledge, which poses a significant barrier for many potential users. To lift this barrier we introduce *Label Sleuth*, a free open source system for labeling and creating text classifiers. This system is unique for: - being a no-code system, making NLP accessible for non-experts. - guiding its users throughout the entire labeling process until they obtain their desired classifier, making the process efficient - from cold start to a classifier in a few hours. - being open for configuration and extension by developers. By open sourcing Label Sleuth we hope to build a community of users and developers that will widen the utilization of NLP models",
    "checked": true,
    "id": "6f00dceaf0717e83f3b75c209b48936db1faf4ac",
    "semantic_title": "label sleuth: from unlabeled text to a classifier in a few hours",
    "citation_count": 12,
    "authors": [
      "Eyal Shnarch",
      "Alon Halfon",
      "Ariel Gera",
      "Marina Danilevsky",
      "Yannis Katsis",
      "Leshem Choshen",
      "Martin Santillan Cooper",
      "Dina Epelboim",
      "Zheng Zhang",
      "Dakuo Wang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.17": {
    "title": "AGReE: A system for generating Automated Grammar Reading Exercises",
    "volume": "demo",
    "abstract": "We describe the AGReE system, which takes user-submitted passages as input and automatically generates grammar practice exercises that can be completed while reading. Multiple-choice practice items are generated for a variety of different grammar constructs: punctuation, articles, conjunctions, pronouns, prepositions, verbs, and nouns. We also conducted a large-scale human evaluation with around 4,500 multiple-choice practice items. We notice for 95% of items, a majority of raters out of five were able to identify the correct answer, for 85% of cases, raters agree that there is only one correct answer among the choices. Finally, the error analysis shows that raters made the most mistakes for punctuation and conjunctions",
    "checked": true,
    "id": "d2e3b1f8aae82cc623fd446bcb7c0de4b88eec9e",
    "semantic_title": "agree: a system for generating automated grammar reading exercises",
    "citation_count": 1,
    "authors": [
      "Sophia Chan",
      "Swapna Somasundaran",
      "Debanjan Ghosh",
      "Mengxuan Zhao"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.18": {
    "title": "BotSIM: An End-to-End Bot Simulation Framework for Commercial Task-Oriented Dialog Systems",
    "volume": "demo",
    "abstract": "We present BotSIM, a data-efficient end-to-end Bot SIMulation framework for commercial task-oriented dialog (TOD) systems. BotSIM consists of three major components: 1) a Generator that can infer semantic-level dialog acts and entities from bot definitions and generate user queries via model-based paraphrasing; 2) an agenda-based dialog user Simulator (ABUS) to simulate conversations with the dialog agents; 3) a Remediator to analyze the simulated conversations, visualize the bot health reports and provide actionable remediation suggestions for bot troubleshooting and improvement. We demonstrate BotSIM's effectiveness in end-to-end evaluation, remediation and multi-intent dialog generation via case studies on two commercial bot platforms. BotSIM's \"generation-simulation-remediation\" paradigm accelerates the end-to-end bot evaluation and iteration process by: 1) reducing manual test cases creation efforts; 2) enabling a holistic gauge of the bot in terms of NLU and end-to-end performance via extensive dialog simulation; 3) improving the bot troubleshooting process with actionable suggestions. A demo of our system can be found at https://tinyurl.com/mryu74cd and a demo video at https://youtu.be/qLPJm6_UOKY",
    "checked": true,
    "id": "5b8f147e5789c664a2bb3b204b892e1372b711de",
    "semantic_title": "botsim: an end-to-end bot simulation framework for commercial task-oriented dialog systems",
    "citation_count": 2,
    "authors": [
      "Guangsen Wang",
      "Samson Tan",
      "Shafiq Joty",
      "Gang Wu",
      "Jimmy Au",
      "Steven C.h. Hoi"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.19": {
    "title": "DeepGen: Diverse Search Ad Generation and Real-Time Customization",
    "volume": "demo",
    "abstract": "Demo: https://youtu.be/WQLL93TPB-cAbstract:We present DeepGen, a system deployed at web scale for automatically creating sponsored search advertisements (ads) for BingAds customers. We leverage state-of-the-art natural language generation (NLG) models to generate fluent ads from advertiser's web pages in an abstractive fashion and solve practical issues such as factuality and inference speed. In addition, our system creates a customized ad in real-time in response to the user's search query, therefore highlighting different aspects of the same product based on what the user is looking for. To achieve this, our system generates a diverse choice of smaller pieces of the ad ahead of time and, at query time, selects the most relevant ones to be stitched into a complete ad. We improve generation diversity by training a controllable NLG model to generate multiple ads for the same web page highlighting different selling points. Our system design further improves diversity horizontally by first running an ensemble of generation models trained with different objectives and then using a diversity sampling algorithm to pick a diverse subset of generation results for online selection. Experimental results show the effectiveness of our proposed system design. Our system is currently deployed in production, serving ~4% of global ads served in Bing",
    "checked": true,
    "id": "0f141ca7bba0f80609c40d12653bff4089d332a7",
    "semantic_title": "deepgen: diverse search ad generation and real-time customization",
    "citation_count": 3,
    "authors": [
      "Konstantin Golobokov",
      "Junyi Chai",
      "Victor Ye Dong",
      "Mandy Gu",
      "Bingyu Chi",
      "Jie Cao",
      "Yulan Yan",
      "Yi Liu"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.20": {
    "title": "ACCoRD: A Multi-Document Approach to Generating Diverse Descriptions of Scientific Concepts",
    "volume": "demo",
    "abstract": "Systems that automatically define unfamiliar terms hold the promise of improving the accessibility of scientific texts, especially for readers who may lack prerequisite background knowledge. However, current systems assume a single \"best\" description per concept, which fails to account for the many ways a concept can be described. We present ACCoRD, an end-to-end system tackling the novel task of generating sets of descriptions of scientific concepts. Our system takes advantage of the myriad ways a concept is mentioned across the scientific literature to produce distinct, diverse descriptions oftarget concepts in terms of different reference concepts. In a user study, we find that users prefer (1) descriptions produced by our end-to-end system, and (2) multiple descriptions to a single \"best\" description. We release the ACCoRD corpus which includes 1,275 labeled contexts and 1,787 expert-authored concept descriptions to support research on our task",
    "checked": true,
    "id": "449e58a29a3971d4d54d9bb28df3b31c60d20483",
    "semantic_title": "accord: a multi-document approach to generating diverse descriptions of scientific concepts",
    "citation_count": 9,
    "authors": [
      "Sonia Murthy",
      "Kyle Lo",
      "Daniel King",
      "Chandra Bhagavatula",
      "Bailey Kuehl",
      "Sophie Johnson",
      "Jonathan Borchardt",
      "Daniel Weld",
      "Tom Hope",
      "Doug Downey"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.21": {
    "title": "Automatic Comment Generation for Chinese Student Narrative Essays",
    "volume": "demo",
    "abstract": "Automatic essay evaluation can help reduce teachers' workload and enable students to refine their works rapidly. Previous studies focus mainly on giving discrete scores for either the holistic quality orseveral distinct traits. However, real-world teachers usually provide detailed comments in natural language, which are more informative than single scores. In this paper, we present the comment generation task, which aims to generate commentsfor specified segments from given student narrative essays. To tackle this task, we propose a planning-based generation model, which first plans a sequence of keywords, and then expands these keywords into a complete comment. To improve the correctness and informativeness of generated comments, we adopt two following techniques: (1) training an error correction module to filter out incorrect keywords, and (2) recognizing fine-grained structured features from source essays to enrich the keywords. To support the evaluation of the task, we collect a human-written Chinese dataset, which contains 22,399 essay-comment pairs. Extensive experiments show that our model outperforms strong baselines significantly. Moreover, we exert explicit control on our model to generate comments to describe the strengths or weaknesses of inputs with a 91% success rate. We deploy the model at http://coai.cs.tsinghua.edu.cn/static/essayComment/. A demo video is available at https://youtu.be/IuFVk8dUxbI. Our code and data are available at https://github.com/thu-coai/EssayCommentGen",
    "checked": true,
    "id": "74c699375265f220f409e539005cae5686669bca",
    "semantic_title": "automatic comment generation for chinese student narrative essays",
    "citation_count": 3,
    "authors": [
      "Zhexin Zhang",
      "Jian Guan",
      "Guowei Xu",
      "Yixiang Tian",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.22": {
    "title": "MIC: A Multi-task Interactive Curation Tool",
    "volume": "demo",
    "abstract": "This paper introduces MIC, a Multi-task Interactive Curation tool, a human-machine collaborative curation tool for multiple NLP tasks. The tool aims to borrow recent advances in literature to solve pain-points in real NLP tasks. Firstly, it supports multiple projects with multiple users which enables collaborative annotations. Secondly, MIC allows easy integration of pre-trained models, rules, and dictionaries to auto label the text and speed up the labeling process. Thirdly, MIC supports annotation at different scales (span of characters and words, tokens and lines, or document) and different types (free text, sentence labels, entity labels, and relationship triplets) with easy GUI operations",
    "checked": true,
    "id": "49f1ca533c03dc3bfdf4aa4292e294d0cdeb2a51",
    "semantic_title": "mic: a multi-task interactive curation tool",
    "citation_count": 0,
    "authors": [
      "Shi Yu",
      "Mingfeng Yang",
      "Jerrod Parker",
      "Stephen Brock"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.23": {
    "title": "SUMMARY WORKBENCH: Unifying Application and Evaluation of Text Summarization Models",
    "volume": "demo",
    "abstract": "This paper presents Summary Workbench, a new tool for developing and evaluating text summarization models. New models and evaluation measures can be easily integrated as Docker-based plugins, allowing to examine the quality of their summaries against any input and to evaluate them using various evaluation measures. Visual analyses combining multiple measures provide insights into the models' strengths and weaknesses. The tool is hosted at https://tldr.demo.webis.de and also supports local deployment for private resources",
    "checked": true,
    "id": "361d25efdb55681b3925b38b7e298b54acbc3259",
    "semantic_title": "summary workbench: unifying application and evaluation of text summarization models",
    "citation_count": 0,
    "authors": [
      "Shahbaz Syed",
      "Dominik Schwabe",
      "Martin Potthast"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.24": {
    "title": "Arabic Word-level Readability Visualization for Assisted Text Simplification",
    "volume": "demo",
    "abstract": "This demo paper presents a Google Docs add-on for automatic Arabic word-level readability visualization. The add-on includes a lemmatization component that is connected to a five-level readability lexicon and Arabic WordNet-based substitution suggestions. The add-on can be used for assessing the reading difficulty of a text and identifying difficult words as part of the task of manual text simplification. We make our add-on and its code publicly available",
    "checked": true,
    "id": "0f5eb7469dccb9b2c451ff8ba74a5b644cbb2107",
    "semantic_title": "arabic word-level readability visualization for assisted text simplification",
    "citation_count": 2,
    "authors": [
      "Reem Hazim",
      "Hind Saddiki",
      "Bashar Alhafni",
      "Muhamed Al Khalil",
      "Nizar Habash"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.25": {
    "title": "LogiTorch: A PyTorch-based library for logical reasoning on natural language",
    "volume": "demo",
    "abstract": "Logical reasoning on natural language is one of the most challenging tasks for deep learning models. There has been an increasing interest in developing new benchmarks to evaluate the reasoning capabilities of language models such as BERT. In parallel, new models based on transformers have emerged to achieve ever better performance on these datasets. However, there is currently no library for logical reasoning that includes such benchmarks and models. This paper introduces LogiTorch, a PyTorch-based library that includes different logical reasoning benchmarks, different models, as well as utility functions such as co-reference resolution. This makes it easy to directly use the preprocessed datasets, to run the models, or to finetune them with different hyperparameters. LogiTorch is open source and can be found on GitHub",
    "checked": true,
    "id": "37b37b58c19f55c899e99eaa851f9fab0b19277e",
    "semantic_title": "logitorch: a pytorch-based library for logical reasoning on natural language",
    "citation_count": 6,
    "authors": [
      "Chadi Helwe",
      "Chloé Clavel",
      "Fabian Suchanek"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.26": {
    "title": "stopes - Modular Machine Translation Pipelines",
    "volume": "demo",
    "abstract": "Neural machine translation, as other natural language deep learning applications, is hungry for data. As research evolves, the data pipelines supporting that research evolve too, oftentimes re-implementing the same core components. Despite the potential of modular codebases, researchers have but little time to put code structure and reusability first. Unfortunately, this makes it very hard to publish clean, reproducible code to benefit a wider audience. In this paper, we motivate and describe stopes , a framework that addresses these issues while empowering scalability and versatility for research use cases. This library was a key enabler of the No Language Left Behind project, establishing new state of the art performance for a multilingual machine translation model covering 200 languages. stopes and the pipelines described are released under the MIT license at https://github.com/facebookresearch/stopes",
    "checked": true,
    "id": "43a3ba3611c8e059b1743d3e30cd44931ae09d70",
    "semantic_title": "stopes - modular machine translation pipelines",
    "citation_count": 5,
    "authors": [
      "Pierre Andrews",
      "Guillaume Wenzek",
      "Kevin Heffernan",
      "Onur Çelebi",
      "Anna Sun",
      "Ammar Kamran",
      "Yingzhe Guo",
      "Alexandre Mourachko",
      "Holger Schwenk",
      "Angela Fan"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.27": {
    "title": "GEMv2: Multilingual NLG Benchmarking in a Single Line of Code",
    "volume": "demo",
    "abstract": "Evaluations in machine learning rarely use the latest metrics, datasets, or human evaluation in favor of remaining compatible with prior work. The compatibility, often facilitated through leaderboards, thus leads to outdated but standardized evaluation practices. We pose that the standardization is taking place in the wrong spot. Evaluation infrastructure should enable researchers to use the latest methods and what should be standardized instead is how to incorporate these new evaluation advances. We introduce GEMv2, the new version of the Generation, Evaluation, and Metrics Benchmark which uses a modular infrastructure for dataset, model, and metric developers to benefit from each other's work. GEMv2 supports 40 documented datasets in 51 languages, ongoing online evaluation for all datasets, and our interactive tools make it easier to add new datasets to the living benchmark",
    "checked": true,
    "id": "9ed047bb4ef6ddc296d473bf4f3b55488aeba350",
    "semantic_title": "gemv2: multilingual nlg benchmarking in a single line of code",
    "citation_count": 27,
    "authors": [
      "Sebastian Gehrmann",
      "Abhik Bhattacharjee",
      "Abinaya Mahendiran",
      "Alex Wang",
      "Alexandros Papangelis",
      "Aman Madaan",
      "Angelina Mcmillan-major",
      "Anna Shvets",
      "Ashish Upadhyay",
      "Bernd Bohnet",
      "Bingsheng Yao",
      "Bryan Wilie",
      "Chandra Bhagavatula",
      "Chaobin You",
      "Craig Thomson",
      "Cristina Garbacea",
      "Dakuo Wang",
      "Daniel Deutsch",
      "Deyi Xiong",
      "Di Jin",
      "Dimitra Gkatzia",
      "Dragomir Radev",
      "Elizabeth Clark",
      "Esin Durmus",
      "Faisal Ladhak",
      "Filip Ginter",
      "Genta Indra Winata",
      "Hendrik Strobelt",
      "Hiroaki Hayashi",
      "Jekaterina Novikova",
      "Jenna Kanerva",
      "Jenny Chim",
      "Jiawei Zhou",
      "Jordan Clive",
      "Joshua Maynez",
      "João Sedoc",
      "Juraj Juraska",
      "Kaustubh Dhole",
      "Khyathi Raghavi Chandu",
      "Laura Perez Beltrachini",
      "Leonardo F . R. Ribeiro",
      "Lewis Tunstall",
      "Li Zhang",
      "Mahim Pushkarna",
      "Mathias Creutz",
      "Michael White",
      "Mihir Sanjay Kale",
      "Moussa Kamal Eddine",
      "Nico Daheim",
      "Nishant Subramani",
      "Ondrej Dusek",
      "Paul Pu Liang",
      "Pawan Sasanka Ammanamanchi",
      "Qi Zhu",
      "Ratish Puduppully",
      "Reno Kriz",
      "Rifat Shahriyar",
      "Ronald Cardenas",
      "Saad Mahamood",
      "Salomey Osei",
      "Samuel Cahyawijaya",
      "Sanja Štajner",
      "Sebastien Montella",
      "Shailza Jolly",
      "Simon Mille",
      "Tahmid Hasan",
      "Tianhao Shen",
      "Tosin Adewumi",
      "Vikas Raunak",
      "Vipul Raheja",
      "Vitaly Nikolaev",
      "Vivian Tsai",
      "Yacine Jernite",
      "Ying Xu",
      "Yisi Sang",
      "Yixin Liu",
      "Yufang Hou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.28": {
    "title": "KGI: An Integrated Framework for Knowledge Intensive Language Tasks",
    "volume": "demo",
    "abstract": "In this paper, we present a system to showcase the capabilities of the latest state-of-the-art retrieval augmented generation models trained on knowledge-intensive language tasks, such as slot filling, open domain question answering, dialogue, and fact-checking. Moreover, given a user query, we show how the output from these different models can be combined to cross-examine the outputs of each other. Particularly, we show how accuracy in dialogue can be improved using the question answering model. We are also releasing all models used in the demo as a contribution of this paper. A short video demonstrating the system is available at https://ibm.box.com/v/emnlp2022-demos",
    "checked": true,
    "id": "e6ce185330c00e3f05171bf107df03c88e2a4875",
    "semantic_title": "kgi: an integrated framework for knowledge intensive language tasks",
    "citation_count": 4,
    "authors": [
      "Md Faisal Mahbub Chowdhury",
      "Michael Glass",
      "Gaetano Rossiello",
      "Alfio Gliozzo",
      "Nandana Mihindukulasooriya"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.29": {
    "title": "Twitter-Demographer: A Flow-based Tool to Enrich Twitter Data",
    "volume": "demo",
    "abstract": "Twitter data have become essential to Natural Language Processing (NLP) and social science research, driving various scientific discoveries in recent years. However, the textual data alone are often not enough to conduct studies: especially, social scientists need more variables to perform their analysis and control for various factors. How we augment this information, such as users' location, age, or tweet sentiment, has ramifications for anonymity and reproducibility, and requires dedicated effort. This paper describes Twitter-Demographer, a simple, flow-based tool to enrich Twitter data with additional information about tweets and users. \\tool is aimed at NLP practitioners, psycho-linguists, and (computational) social scientists who want to enrich their datasets with aggregated information, facilitating reproducibility, and providing algorithmic privacy-by-design measures for pseudo-anonymity. We discuss our design choices, inspired by the flow-based programming paradigm, to use black-box components that can easily be chained together and extended. We also analyze the ethical issues related to the use of this tool, and the built-in measures to facilitate pseudo-anonymity",
    "checked": true,
    "id": "9a3cda628f6c1c854ae15c2b73b66d391d7066c5",
    "semantic_title": "twitter-demographer: a flow-based tool to enrich twitter data",
    "citation_count": 3,
    "authors": [
      "Federico Bianchi",
      "Vincenzo Cutrona",
      "Dirk Hovy"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.30": {
    "title": "Azimuth: Systematic Error Analysis for Text Classification",
    "volume": "demo",
    "abstract": "We present Azimuth, an open-source and easy-to-use tool to perform error analysis for text classification. Compared to other stages of the ML development cycle, such as model training and hyper-parameter tuning, the process and tooling for the error analysis stage are less mature. However, this stage is critical for the development of reliable and trustworthy AI systems. To make error analysis more systematic, we propose an approach comprising dataset analysis and model quality assessment, which Azimuth facilitates. We aim to help AI practitioners discover and address areas where the model does not generalize by leveraging and integrating a range of ML techniques, such as saliency maps, similarity, uncertainty, and behavioral analyses, all in one tool. Our code and documentation are available at github.com/servicenow/azimuth",
    "checked": true,
    "id": "3330e15c51b787e50e6778af152dffec022363ca",
    "semantic_title": "azimuth: systematic error analysis for text classification",
    "citation_count": 2,
    "authors": [
      "Gabrielle Gauthier-melancon",
      "Orlando Marquez Ayala",
      "Lindsay Brin",
      "Chris Tyler",
      "Frederic Branchaud-charron",
      "Joseph Marinier",
      "Karine Grande",
      "Di Le"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.31": {
    "title": "SynKB: Semantic Search for Synthetic Procedures",
    "volume": "demo",
    "abstract": "In this paper we present SynKB, an open-source, automatically extracted knowledge base of chemical synthesis protocols. Similar to proprietary chemistry databases such as Reaxsys, SynKB allows chemists to retrieve structured knowledge about synthetic procedures. By taking advantage of recent advances in natural language processing for procedural texts, SynKB supports more flexible queries about reaction conditions, and thus has the potential to help chemists search the literature for conditions used in relevant reactions as they design new synthetic routes. Using customized Transformer models to automatically extract information from 6 million synthesis procedures described in U.S. and EU patents, we show that for many queries, SynKB has higher recall than Reaxsys, while maintaining high precision. We plan to make SynKB available as an open-source tool; in contrast, proprietary chemistry databases require costly subscriptions",
    "checked": true,
    "id": "033909a3c80f17a38f0bb757ed9c63424b12053a",
    "semantic_title": "synkb: semantic search for synthetic procedures",
    "citation_count": 4,
    "authors": [
      "Fan Bai",
      "Alan Ritter",
      "Peter Madrid",
      "Dayne Freitag",
      "John Niekrasz"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.32": {
    "title": "Camelira: An Arabic Multi-Dialect Morphological Disambiguator",
    "volume": "demo",
    "abstract": "We present Camelira, a web-based Arabic multi-dialect morphological disambiguation tool that covers four major variants of Arabic: Modern Standard Arabic, Egyptian, Gulf, and Levantine.Camelira offers a user-friendly web interface that allows researchers and language learners to explore various linguistic information, such as part-of-speech, morphological features, and lemmas. Our system also provides an option to automatically choose an appropriate dialect-specific disambiguator based on the prediction of a dialect identification component. Camelira is publicly accessible at http://camelira.camel-lab.com",
    "checked": true,
    "id": "be6e03bf01b4da3a5c6798932c2c50771938082b",
    "semantic_title": "camelira: an arabic multi-dialect morphological disambiguator",
    "citation_count": 4,
    "authors": [
      "Ossama Obeid",
      "Go Inoue",
      "Nizar Habash"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.33": {
    "title": "POTATO: The Portable Text Annotation Tool",
    "volume": "demo",
    "abstract": "We present POTATO, the Portable text annotation tool, a free, fully open-sourced annotation system that 1) supports labeling many types of text and multimodal data; 2) offers easy-to-configure features to maximize the productivity of both deployers and annotators (convenient templates for common ML/NLP tasks, active learning, keypress shortcuts, keyword highlights, tooltips); and 3) supports a high degree of customization (editable UI, inserting pre-screening questions, attention and qualification tests). Experiments over two annotation tasks suggest that POTATO improves labeling speed through its specially-designed productivity features, especially for long documents and complex tasks. POTATO is available at https://github.com/davidjurgens/potato and will continue to be updated",
    "checked": true,
    "id": "adccf09dae168d24b2bd40473fa31f05bb05f978",
    "semantic_title": "potato: the portable text annotation tool",
    "citation_count": 22,
    "authors": [
      "Jiaxin Pei",
      "Aparna Ananthasubramaniam",
      "Xingyao Wang",
      "Naitian Zhou",
      "Apostolos Dedeloudis",
      "Jackson Sargent",
      "David Jurgens"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.34": {
    "title": "KGxBoard: Explainable and Interactive Leaderboard for Evaluation of Knowledge Graph Completion Models",
    "volume": "demo",
    "abstract": "Knowledge Graphs (KGs) store information in the form of (head, predicate, tail)-triples. To augment KGs with new knowledge, researchers proposed models for KG Completion (KGC) tasks such as link prediction; i.e., answering (h; p; ?) or (?; p; t) queries. Such models are usually evaluated with averaged metrics on a held-out test set. While useful for tracking progress, averaged single-score metrics cannotreveal what exactly a model has learned — or failed to learn. To address this issue, we propose KGxBoard: an interactive framework for performing fine-grained evaluation on meaningful subsets of the data, each of which tests individual and interpretable capabilities of a KGC model. In our experiments, we highlight the findings that we discovered with the use of KGxBoard, which would have been impossible to detect with standard averaged single-score metrics",
    "checked": true,
    "id": "c33e99e90d066319866de9e0768e01b83360d1ab",
    "semantic_title": "kgxboard: explainable and interactive leaderboard for evaluation of knowledge graph completion models",
    "citation_count": 5,
    "authors": [
      "Haris Widjaja",
      "Kiril Gashteovski",
      "Wiem Ben Rim",
      "Pengfei Liu",
      "Christopher Malon",
      "Daniel Ruffinelli",
      "Carolin Lawrence",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.35": {
    "title": "FALTE: A Toolkit for Fine-grained Annotation for Long Text Evaluation",
    "volume": "demo",
    "abstract": "A growing swath of NLP research is tackling problems related to generating long text, including tasks such as open-ended story generation, summarization, dialogue, and more. However, we currently lack appropriate tools to evaluate these long outputs of generation models: classic automatic metrics such as ROUGE have been shown to perform poorly, and newer learned metrics do not necessarily work wellfor all tasks and domains of text. Human rating and error analysis remains a crucial component for any evaluation of long text generation. In this paper, we introduce FALTE, a web-based annotation toolkit designed to address this shortcoming. Our tool allows researchers to collect fine-grained judgments of text quality from crowdworkers using an error taxonomy specific to the downstream task. Using the taskinterface, annotators can select and assign error labels to text span selections in an incremental paragraph-level annotation workflow. The latter functionality is designed to simplify the document-level task into smaller units and reduce cognitive load on the annotators. Our tool has previously been used to run a large-scale annotation study that evaluates the coherence of long generated summaries, demonstrating its utility",
    "checked": true,
    "id": "334fcce334b4bd7e12d1f9b72c20d4281855dcdb",
    "semantic_title": "falte: a toolkit for fine-grained annotation for long text evaluation",
    "citation_count": 4,
    "authors": [
      "Tanya Goyal",
      "Junyi Jessy Li",
      "Greg Durrett"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.36": {
    "title": "SEAL: Interactive Tool for Systematic Error Analysis and Labeling",
    "volume": "demo",
    "abstract": "With the advent of Transformers, large language models (LLMs) have saturated well-known NLP benchmarks and leaderboards with high aggregate performance. However, many times these models systematically fail on tail data or rare groups not obvious in aggregate evaluation. Identifying such problematic data groups is even more challenging when there are no explicit labels (e.g., ethnicity, gender, etc.) and further compounded for NLP datasets due to the lack of visual features to characterize failure modes (e.g., Asian males, animals indoors, waterbirds on land etc.). This paper introduces an interactive Systematic Error Analysis and Labeling (SEAL) tool that uses a two-step approach to first identify high-error slices of data and then, in the second step, introduce methods to give human-understandable semantics to those underperforming slices. We explore a variety of methods for coming up with coherent semantics for the error groups using language models for semantic labeling and a text-to-image model for generating visual features.SEAL is available at https://huggingface.co/spaces/nazneen/seal",
    "checked": true,
    "id": "37fdb4e482f3d92f802b304d22253e1025f6b7c8",
    "semantic_title": "seal : interactive tool for systematic error analysis and labeling",
    "citation_count": 16,
    "authors": [
      "Nazneen Rajani",
      "Weixin Liang",
      "Lingjiao Chen",
      "Margaret Mitchell",
      "James Zou"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.37": {
    "title": "Hands-On Interactive Neuro-Symbolic NLP with DRaiL",
    "volume": "demo",
    "abstract": "We recently introduced DRaiL, a declarative neural-symbolic modeling framework designed to support a wide variety of NLP scenarios. In this paper, we enhance DRaiL with an easy to use Python interface, equipped with methods to define, modify and augment DRaiL models interactively, as well as with methods to debug and visualize the predictions made. We demonstrate this interface with a challenging NLP task: predicting sentence and entity level moral sentiment in political tweets",
    "checked": true,
    "id": "ddc900f18f837cb90bf8474808bbeca2add33727",
    "semantic_title": "hands-on interactive neuro-symbolic nlp with drail",
    "citation_count": 0,
    "authors": [
      "Maria Leonor Pacheco",
      "Shamik Roy",
      "Dan Goldwasser"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.38": {
    "title": "Paraphrastic Representations at Scale",
    "volume": "demo",
    "abstract": "We present a system that allows users to train their own state-of-the-art paraphrastic sentence representations in a variety of languages. We release trained models for English, Arabic, German, Spanish, French, Russian, Turkish, and Chinese. We train these models on large amounts of data, achieving significantly improved performance from our original papers on a suite of monolingual semantic similarity, cross-lingual semantic similarity, and bitext mining tasks. Moreover, the resulting models surpass all prior work on efficient unsupervised semantic textual similarity, even significantly outperforming supervised BERT-based models like Sentence-BERT (Reimers and Gurevych, 2019). Most importantly, our models are orders of magnitude faster than other strong similarity models and can be used on CPU with little difference in inference speed (even improved speed over GPU when using more CPU cores), making these models an attractive choice for users without access to GPUs or for use on embedded devices. Finally, we add significantly increased functionality to the code bases for training paraphrastic sentence models, easing their use for both inference and for training them for any desired language with parallel data. We also include code to automatically download and preprocess training data",
    "checked": true,
    "id": "06d21b10e0f85ea38e23f99efd38a770e455863c",
    "semantic_title": "paraphrastic representations at scale",
    "citation_count": 13,
    "authors": [
      "John Wieting",
      "Kevin Gimpel",
      "Graham Neubig",
      "Taylor Berg-kirkpatrick"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.39": {
    "title": "Snoopy: An Online Interface for Exploring the Effect of Pretraining Term Frequencies on Few-Shot LM Performance",
    "volume": "demo",
    "abstract": "Current evaluation schemes for large language models often fail to consider the impact of the overlap between pretraining corpus and test data on model performance statistics. Snoopy is an online interface that allows researchers to study this impact in few-shot learning settings. Our demo provides term frequency statistics for the Pile, which is an 800 GB corpus, accompanied by the precomputed performance of EleutherAI/GPT models on more than 20 NLP benchmarks, including numerical, commonsense reasoning, natural language understanding, and question-answering tasks. Snoopy allows a user to interactively align specific terms in test instances with their frequency in the Pile, enabling exploratory analysis of how term frequency is related to the accuracy of the models, which are hard to discover through automated means. A user can look at correlations over various model sizes and numbers of in-context examples and visualize the result across multiple (potentially aggregated) datasets. Using Snoopy, we show that a researcher can quickly replicate prior analyses for numerical tasks, while simultaneously allowing for much more expansive exploration that was previously challenging. Snoopy is available at https://nlp.ics.uci.edu/snoopy",
    "checked": true,
    "id": "9715be0a94c9b05bafe299cbfb4f846453bfd2ab",
    "semantic_title": "snoopy: an online interface for exploring the effect of pretraining term frequencies on few-shot lm performance",
    "citation_count": 2,
    "authors": [
      "Yasaman Razeghi",
      "Raja Sekhar Reddy Mekala",
      "Robert L Logan Iv",
      "Matt Gardner",
      "Sameer Singh"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.40": {
    "title": "BMCook: A Task-agnostic Compression Toolkit for Big Models",
    "volume": "demo",
    "abstract": "Recently, pre-trained language models (PLMs) have achieved great success on various NLP tasks and have shown a trend of exponential growth in model size. To alleviate the unaffordable computational costs brought by the size growth, model compression has been widely explored. Existing efforts have achieved promising results in compressing medium-sized models for specific tasks, while task-agnostic compression for big models with over billions of parameters is rarely studied. Task-agnostic compression can provide an efficient and versatile big model for both prompting and delta tuning, leading to a more general impact than task-specific compression. Hence, we introduce a task-agnostic compression toolkit BMCook for big models. In BMCook, we implement four representative compression methods, including quantization, pruning, distillation, and MoEfication. Developers can easily combine these methods towards better efficiency. To evaluate BMCook, we apply it to compress T5-3B (a PLM with 3 billion parameters). We achieve nearly 12x efficiency improvement while maintaining over 97% of the original T5-3B performance on three typical NLP benchmarks. Moreover, the final compressed model also significantly outperforms T5-base (a PLM with 220 million parameters), which has a similar computational cost. BMCook is publicly available at https://github.com/OpenBMB/BMCook",
    "checked": true,
    "id": "3aa443baa063a4fb69df0deebdf24920ad1eb94a",
    "semantic_title": "bmcook: a task-agnostic compression toolkit for big models",
    "citation_count": 3,
    "authors": [
      "Zhengyan Zhang",
      "Baitao Gong",
      "Yingfa Chen",
      "Xu Han",
      "Guoyang Zeng",
      "Weilin Zhao",
      "Yanxu Chen",
      "Zhiyuan Liu",
      "Maosong Sun"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.41": {
    "title": "ALToolbox: A Set of Tools for Active Learning Annotation of Natural Language Texts",
    "volume": "demo",
    "abstract": "We present ALToolbox – an open-source framework for active learning (AL) annotation in natural language processing. Currently, the framework supports text classification, sequence tagging, and seq2seq tasks. Besides state-of-the-art query strategies, ALToolbox provides a set of tools that help to reduce computational overhead and duration of AL iterations and increase annotated data reusability. The framework aims to support data scientists and researchers by providing an easy-to-deploy GUI annotation tool directly in the Jupyter IDE and an extensible benchmark for novel AL methods. We prepare a small demonstration of ALToolbox capabilities available online. The code of the framework is published under the MIT license",
    "checked": true,
    "id": "e798a1f31c48a182e5ede208a821ff23c953d757",
    "semantic_title": "altoolbox: a set of tools for active learning annotation of natural language texts",
    "citation_count": 2,
    "authors": [
      "Akim Tsvigun",
      "Leonid Sanochkin",
      "Daniil Larionov",
      "Gleb Kuzmin",
      "Artem Vazhentsev",
      "Ivan Lazichny",
      "Nikita Khromov",
      "Danil Kireev",
      "Aleksandr Rubashevskii",
      "Olga Shahmatova",
      "Dmitry V. Dylov",
      "Igor Galitskiy",
      "Artem Shelmanov"
    ]
  },
  "https://aclanthology.org/2022.emnlp-demos.42": {
    "title": "TextBox 2.0: A Text Generation Library with Pre-trained Language Models",
    "volume": "demo",
    "abstract": "To facilitate research on text generation, this paper presents a comprehensive and unified library, TextBox 2.0, focusing on the use of pre-trained language models (PLMs). To be comprehensive, our library covers 13 common text generation tasks and their corresponding 83 datasets and further incorporates 45 PLMs covering general, translation, Chinese, dialogue, controllable, distilled, prompting, and lightweight PLMs. We also implement 4 efficient training strategies and provide 4 generation objectives for pre-training new PLMs from scratch. To be unified, we design the interfaces to support the entire research pipeline (from data loading to training and evaluation), ensuring that each step can be fulfilled in a unified way. Despite the rich functionality, it is easy to use our library, either through the friendly Python API or command line. To validate the effectiveness of our library, we conduct extensive experiments and exemplify four types of research scenarios. The project is released at the link: https://github.com/RUCAIBox/TextBox#2.0",
    "checked": true,
    "id": "de3e8a9bf62bfe52adcfea026393d9fc4c6e16c6",
    "semantic_title": "textbox 2.0: a text generation library with pre-trained language models",
    "citation_count": 5,
    "authors": [
      "Tianyi Tang",
      "Junyi Li",
      "Zhipeng Chen",
      "Yiwen Hu",
      "Zhuohao Yu",
      "Wenxun Dai",
      "Wayne Xin Zhao",
      "Jian-yun Nie",
      "Ji-rong Wen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.1": {
    "title": "LogicSolver: Towards Interpretable Math Word Problem Solving with Logical Prompt-enhanced Learning",
    "volume": "findings",
    "abstract": "Recently, deep learning models have made great progress in MWP solving on answer accuracy. However, they are uninterpretable since they mainly rely on shallow heuristics to achieve high performance without understanding and reasoning the grounded math logic. To address this issue and make a step towards interpretable MWP solving, we first construct a high-quality MWP dataset named InterMWP which consists of 11,495 MWPs and annotates interpretable logical formulas based on algebraic knowledge as the grounded linguistic logic of each solution equation. Different from existing MWP datasets, our InterMWP benchmark asks for a solver to not only output the solution expressions but also predict the corresponding logical formulas. We further propose a novel approach with logical prompt and interpretation generation, called LogicSolver. For each MWP, our LogicSolver first retrieves some highly-correlated algebraic knowledge and then passes them to the backbone model as prompts to improve the semantic representations of MWPs. With these improved semantic representations, our LogicSolver generates corresponding solution expressions and interpretable knowledge formulas in accord with the generated solution expressions, simultaneously. Experimental results show that our LogicSolver has stronger logical formula-based interpretability than baselines while achieving higher answer accuracy with the help of logical prompts, simultaneously. The source code and dataset will be available at https://github.com/yangzhch6/InterMWP",
    "checked": true,
    "id": "a560cb91061edac97053c9485f44eed176c1ed99",
    "semantic_title": "logicsolver: towards interpretable math word problem solving with logical prompt-enhanced learning",
    "citation_count": 19,
    "authors": [
      "Zhicheng Yang",
      "Jinghui Qin",
      "Jiaqi Chen",
      "Liang Lin",
      "Xiaodan Liang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.2": {
    "title": "Commonsense Knowledge Salience Evaluation with a Benchmark Dataset in E-commerce",
    "volume": "findings",
    "abstract": "In e-commerce, the salience of commonsense knowledge (CSK) is beneficial for widespread applications such as product search and recommendation. For example, when users search for \"running\" in e-commerce, they would like to find products highly related to running, such as \"running shoes\" rather than \"shoes\". Nevertheless, many existing CSK collections rank statements solely by confidence scores, and there is no information about which ones are salient from a human perspective. In this work, we define the task of supervised salience evaluation, where given a CSK triple, the model is required to learn whether the triple is salient or not. In addition to formulating the new task, we also release a new Benchmark dataset of Salience Evaluation in E-commerce (BSEE) and hope to promote related research on commonsense knowledge salience evaluation. We conduct experiments in the dataset with several representative baseline models. The experimental results show that salience evaluation is a hard task where models perform poorly on our evaluation set. We further propose a simple but effective approach, PMI-tuning, which shows promise for solving this novel problem. Code is available in https://github.com/OpenBGBenchmark/OpenBG-CSK",
    "checked": true,
    "id": "82daf49155c62391209eb741b8ccf3e82782cc36",
    "semantic_title": "commonsense knowledge salience evaluation with a benchmark dataset in e-commerce",
    "citation_count": 4,
    "authors": [
      "Yincen Qu",
      "Ningyu Zhang",
      "Hui Chen",
      "Zelin Dai",
      "Chengming Wang",
      "Xiaoyu Wang",
      "Qiang Chen",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.3": {
    "title": "Automatic Rule Induction for Efficient Semi-Supervised Learning",
    "volume": "findings",
    "abstract": "Semi-supervised learning has shown promise in allowing NLP models to generalize from small amounts of labeled data. Meanwhile, pretrained transformer models act as black-box correlation engines that are difficult to explain and sometimes behave unreliably. In this paper, we propose tackling both of these challenges via Automatic Rule Induction (ARI), a simple and general-purpose framework for the automatic discovery and integration of symbolic rules into pretrained transformer models. First, we extract weak symbolic rules from low-capacity machine learning models trained on small amounts of labeled data. Next, we use an attention mechanism to integrate these rules into high-capacity pretrained transformer models. Last, the rule-augmented system becomes part of a self-training framework to boost supervision signal on unlabeled data. These steps can be layered beneath a variety of existing weak supervision and semi-supervised NLP algorithms in order to improve performance and interpretability. Experiments across nine sequence classification and relation extraction tasks suggest that ARI can improve state-of-the-art methods with no manual effort and minimal computational overhead",
    "checked": true,
    "id": "46f34c48c3e0fa84a5fc257521f176d3ab046d88",
    "semantic_title": "automatic rule induction for efficient semi-supervised learning",
    "citation_count": 7,
    "authors": [
      "Reid Pryzant",
      "Ziyi Yang",
      "Yichong Xu",
      "Chenguang Zhu",
      "Michael Zeng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.4": {
    "title": "Improving Semantic Matching through Dependency-Enhanced Pre-trained Model with Adaptive Fusion",
    "volume": "findings",
    "abstract": "Transformer-based pre-trained models like BERT have achieved great progress on Semantic Sentence Matching. Meanwhile, dependency prior knowledge has also shown general benefits in multiple NLP tasks. However, how to efficiently integrate dependency prior structure into pre-trained models to better model complex semantic matching relations is still unsettled. In this paper, we propose the Dependency-Enhanced Adaptive Fusion Attention (DAFA), which explicitly introduces dependency structure into pre-trained models and adaptively fuses it with semantic information. Specifically, (i) DAFA first proposes a structure-sensitive paradigm to construct a dependency matrix for calibrating attention weights. (ii) It adopts an adaptive fusion module to integrate the obtained dependency information and the original semantic signals. Moreover, DAFA reconstructs the attention calculation flow and provides better interpretability. By applying it on BERT, our method achieves state-of-the-art or competitive performance on 10 public datasets, demonstrating the benefits of adaptively fusing dependency structure in semantic matching task",
    "checked": true,
    "id": "33e829764b6e51533f4fad274462032b3c34d6d5",
    "semantic_title": "improving semantic matching through dependency-enhanced pre-trained model with adaptive fusion",
    "citation_count": 6,
    "authors": [
      "Jian Song",
      "Di Liang",
      "Rumei Li",
      "Yuntao Li",
      "Sirui Wang",
      "Minlong Peng",
      "Wei Wu",
      "Yongxin Yu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.5": {
    "title": "Sparse Mixers: Combining MoE and Mixing to build a more efficient BERT",
    "volume": "findings",
    "abstract": "We combine the capacity of sparsely gated Mixture-of-Experts (MoE) with the speed and stability of linear, mixing transformations to design the Sparse Mixer encoder model. Sparse Mixer slightly outperforms BERT on GLUE and SuperGLUE, but more importantly trains 65% faster and runs inference 61% faster. We also present a faster variant, prosaically named Fast Sparse Mixer, that marginally underperforms BERT on SuperGLUE, but trains and runs nearly twice as fast. We justify the design of these two models by carefully ablating through various mixing mechanisms, MoE configurations, and hyperparameters. Sparse Mixer overcomes many of the latency and stability concerns of MoE models and offers the prospect of serving sparse student models, without resorting to distilling them to dense variants",
    "checked": true,
    "id": "7618f17179bb316002cb6cc472d61382776af6b7",
    "semantic_title": "sparse mixers: combining moe and mixing to build a more efficient bert",
    "citation_count": 9,
    "authors": [
      "James Lee-Thorp",
      "Joshua Ainslie"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.6": {
    "title": "KE-GCL: Knowledge Enhanced Graph Contrastive Learning for Commonsense Question Answering",
    "volume": "findings",
    "abstract": "Commonsense question answering (CQA) aims to choose the correct answers for commonsense questions. Most existing works focus on extracting and reasoning over external knowledge graphs (KG). However, the noise in KG prevents these models from learning effective representations. In this paper, we propose a Knowledge Enhanced Graph Contrastive Learning model (KE-GCL) by incorporating the contextual descriptions of entities and adopting a graph contrastive learning scheme. Specifically, for QA pairs we represent the knowledge from KG and contextual descriptions. Then, the representations of contextual descriptions as context nodes are inserted into KG, forming the knowledge-enhanced graphs. Moreover, we design a contrastive learning method on graphs. For knowledge-enhanced graphs, we build their augmented views with an adaptive sampling strategy. After that, we reason over graphs to update their representations by scattering edges and aggregating nodes. To further improve GCL, hard graph negatives are chosen based on incorrect answers. Extensive experiments on two benchmark datasets demonstrate the effectiveness of our proposed KE-GCL, which outperforms previous methods consistently",
    "checked": true,
    "id": "750441c769bcd1e70127a07ada9e622dadcdb0d0",
    "semantic_title": "ke-gcl: knowledge enhanced graph contrastive learning for commonsense question answering",
    "citation_count": 1,
    "authors": [
      "Lihui Zhang",
      "Ruifan Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.7": {
    "title": "Acceptability Judgements via Examining the Topology of Attention Maps",
    "volume": "findings",
    "abstract": "The role of the attention mechanism in encoding linguistic knowledge has received special interest in NLP. However, the ability of the attention heads to judge the grammatical acceptability of a sentence has been underexplored. This paper approaches the paradigm of acceptability judgments with topological data analysis (TDA), showing that the geometric properties of the attention graph can be efficiently exploited for two standard practices in linguistics: binary judgments and linguistic minimal pairs. Topological features enhance the BERT-based acceptability classifier scores by 8%-24% on CoLA in three languages (English, Italian, and Swedish). By revealing the topological discrepancy between attention maps of minimal pairs, we achieve the human-level performance on the BLiMP benchmark, outperforming nine statistical and Transformer LM baselines. At the same time, TDA provides the foundation for analyzing the linguistic functions of attention heads and interpreting the correspondence between the graph features and grammatical phenomena. We publicly release the code and other materials used in the experiments",
    "checked": true,
    "id": "53820a8aa03d1ba70e69eeb99e7cbb02f05736f4",
    "semantic_title": "acceptability judgements via examining the topology of attention maps",
    "citation_count": 10,
    "authors": [
      "Daniil Cherniavskii",
      "Eduard Tulchinskii",
      "Vladislav Mikhailov",
      "Irina Proskurina",
      "Laida Kushnareva",
      "Ekaterina Artemova",
      "Serguei Barannikov",
      "Irina Piontkovskaya",
      "Dmitri Piontkovski",
      "Evgeny Burnaev"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.8": {
    "title": "Clip-Tuning: Towards Derivative-free Prompt Learning with a Mixture of Rewards",
    "volume": "findings",
    "abstract": "Derivative-free prompt learning has emerged as a lightweight alternative to prompt tuning, which only requires model inference to optimize the prompts. However, existing work did not take full advantage of the over-parameterized characteristics of large pre-trained language models (PLMs). In this paper, we propose Clip-Tuning, a simple yet effective method that adopts diverse frozen \"thinned\" networks of PLMs to obtain *a mixture of rewards* and thus advance the derivative-free prompt learning. The thinned networks consist of all the hidden units that survive a stationary dropout strategy, whose inference predictions reflect an ensemble of partial views over prompted training samples. Our method outperforms previous gradient-free prompt learning methods and achieves parity with gradient-based counterparts on seven language understanding benchmarks under few-shot settings",
    "checked": true,
    "id": "aca584d4e5f4e80ef471cceefa8600b4daeddb2b",
    "semantic_title": "clip-tuning: towards derivative-free prompt learning with a mixture of rewards",
    "citation_count": 11,
    "authors": [
      "Yekun Chai",
      "Shuohuan Wang",
      "Yu Sun",
      "Hao Tian",
      "Hua Wu",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.9": {
    "title": "Soft-Labeled Contrastive Pre-Training for Function-Level Code Representation",
    "volume": "findings",
    "abstract": "Code contrastive pre-training has recently achieved significant progress on code-related tasks. In this paper, we present SCodeR, a Soft-labeled contrastive pre-training framework with two positive sample construction methods to learn functional-level Code Representation. Considering the relevance between codes in a large-scale code corpus, the soft-labeled contrastive pre-training can obtain fine-grained soft-labels through an iterative adversarial manner and use them to learn better code representation. The positive sample construction is another key for contrastive pre-training. Previous works use transformation-based methods like variable renaming to generate semantically equal positive codes. However, they usually result in the generated code with a highly similar surface form, and thus mislead the model to focus on superficial code structure instead of code semantics. To encourage SCodeR to capture semantic information from the code, we utilize code comments and abstract syntax sub-trees of the code to build positive samples. We conduct experiments on four code-related tasks over seven datasets. Extensive experimental results show that SCodeR achieves new state-of-the-art performance on all of them, which illustrates the effectiveness of the proposed pre-training method",
    "checked": true,
    "id": "8ffe7b7eeddbd4c22d642b0a48379d17e61c3bab",
    "semantic_title": "soft-labeled contrastive pre-training for function-level code representation",
    "citation_count": 9,
    "authors": [
      "Xiaonan Li",
      "Daya Guo",
      "Yeyun Gong",
      "Yun Lin",
      "Yelong Shen",
      "Xipeng Qiu",
      "Daxin Jiang",
      "Weizhu Chen",
      "Nan Duan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.10": {
    "title": "Conditioned Masked Language and Image Modeling for Image-Text Dense Retrieval",
    "volume": "findings",
    "abstract": "Image-text retrieval is a fundamental cross-modal task that takes image/text as a query to retrieve relevant data of another type. The large-scale two-stream pre-trained models like CLIP have achieved tremendous success in this area. They embed the images and texts into instance representations with two separate encoders, aligning them on the instance-level with contrastive learning. Beyond this, the following works adopt the fine-grained token-level interaction (Masked Language and Image Modeling) to boost performance further. However, the vanilla token-level objectives are not designed to aggregate the image-text alignment information into the instance representations, but the token representations, causing a gap between pre-training and application. To address this issue, we carefully design two novel conditioned token-level pre-training objectives, Conditioned Masked Language and Image Modeling (ConMLM and ConMIM), forcing models to aggregate the token-level alignment information into the instance representations. Combing with the instance-level contrastive learning, we propose our cross-modal dense retrieval framework, Conditioned Language-Image Pre-training (ConLIP). Experimental results on two popular cross-modal retrieval benchmarks (MSCOCO and Flickr30k) reveal the effectiveness of our methods",
    "checked": true,
    "id": "4fdc8a8d1256ba61b63daecbc2a06d4d7bbcf4cd",
    "semantic_title": "conditioned masked language and image modeling for image-text dense retrieval",
    "citation_count": 5,
    "authors": [
      "Ziyang Luo",
      "Yadong Xi",
      "Rongsheng Zhang",
      "GongZheng Li",
      "Zeng Zhao",
      "Jing Ma"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.11": {
    "title": "Does Simultaneous Speech Translation need Simultaneous Models?",
    "volume": "findings",
    "abstract": "In simultaneous speech translation (SimulST), finding the best trade-off between high output quality and low latency is a challenging task. To meet the latency constraints posed by different application scenarios, multiple dedicated SimulST models are usually trained and maintained, generating high computational costs. In this paper, also motivated by the increased sensitivity towards sustainable AI, we investigate whether a single model trained offline can serve both offline and simultaneous applications under different latency regimes without additional training or adaptation. Experiments on en->de, es show that, aside from facilitating the adoption of well-established offline architectures and training strategies without affecting latency, offline training achieves similar or better quality compared to the standard SimulST training protocol, also being competitive with the state-of-the-art system",
    "checked": true,
    "id": "2b05dc1f5a7a37c27e637e362a195370d141a23d",
    "semantic_title": "does simultaneous speech translation need simultaneous models?",
    "citation_count": 12,
    "authors": [
      "Sara Papi",
      "Marco Gaido",
      "Matteo Negri",
      "Marco Turchi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.12": {
    "title": "Utilizing Language-Image Pretraining for Efficient and Robust Bilingual Word Alignment",
    "volume": "findings",
    "abstract": "Word translation without parallel corpora has become feasible, rivaling the performance of supervised methods. Recent findings have shown the improvement in accuracy and robustness of unsupervised word translation (UWT) by utilizing visual observations, which are universal representations across languages. Our work investigates the potential of using not only visual observations but also pretrained language-image models for enabling a more efficient and robust UWT. We develop a novel UWT method dubbed Word Alignment using Language-Image Pretraining (WALIP), leveraging visual observations via the shared image-text embedding space of CLIPs (Radford et al., 2021). WALIP has a two-step procedure. First, we retrieve word pairs with high confidences of similarity, computed using our proposed image-based fingerprints, which define the initial pivot for the alignment. Second, we apply our robust Procrustes algorithm to estimate the linear mapping between two embedding spaces, which iteratively corrects and refines the estimated alignment. Our extensive experiments show that WALIP improves upon the state-of-the-art performance of bilingual word alignment for a few language pairs across different word embeddings and displays great robustness to the dissimilarity of language pairs or training corpora for two word embeddings",
    "checked": true,
    "id": "42d1bf3c14a28544e046fc02dcd7c0fffd238a1b",
    "semantic_title": "utilizing language-image pretraining for efficient and robust bilingual word alignment",
    "citation_count": 0,
    "authors": [
      "Tuan Dinh",
      "Jy-yong Sohn",
      "Shashank Rajput",
      "Timothy Ossowski",
      "Yifei Ming",
      "Junjie Hu",
      "Dimitris Papailiopoulos",
      "Kangwook Lee"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.13": {
    "title": "Grape: Knowledge Graph Enhanced Passage Reader for Open-domain Question Answering",
    "volume": "findings",
    "abstract": "A common thread of open-domain question answering (QA) models employs a retriever-reader pipeline that first retrieves a handful of relevant passages from Wikipedia and then peruses the passages to produce an answer. However, even state-of-the-art readers fail to capture the complex relationships between entities appearing in questions and retrieved passages, leading to answers that contradict the facts. In light of this, we propose a novel knowledge graph enhanced passage reader, namely Grape, to improve the reader performance for open-domain QA. Specifically, for each pair of question and retrieved passage, we first construct a localized bipartite graph, attributed to entity embeddings extracted from the intermediate layer of the reader model. Then, a graph neural network learns relational knowledge while fusing graph and contextual representations into the hidden states of the reader model. Experiments on three open-domain QA benchmarks show Grape can improve the state-of-the-art performance by up to 2.2 exact match score with a negligible overhead increase, with the same retriever and retrieved passages. Our code is publicly available at https://github.com/jumxglhf/GRAPE",
    "checked": true,
    "id": "397ea2e5e4dae1bc9250458cf7d696cdf3200e40",
    "semantic_title": "grape: knowledge graph enhanced passage reader for open-domain question answering",
    "citation_count": 18,
    "authors": [
      "Mingxuan Ju",
      "Wenhao Yu",
      "Tong Zhao",
      "Chuxu Zhang",
      "Yanfang Ye"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.14": {
    "title": "NarraSum: A Large-Scale Dataset for Abstractive Narrative Summarization",
    "volume": "findings",
    "abstract": "Narrative summarization aims to produce a distilled version of a narrative to describe its most salient events and characters. Writing a summary for a narrative is challenging as it requires an understanding of event causality and character behaviors. To encourage research in this direction, we propose NarraSum, a large-scale narrative summarization dataset. It contains 122K narratives, which are collected from the synopses of movies and TV episodes with diverse genres, and their corresponding abstractive summaries. Experiments show that there is a large performance gap between humans and the state-of-the-art summarization models on NarraSum. We hope that this dataset will promote future research in summarization, as well as broader studies of natural language understanding and generation. The dataset is available at https://github.com/zhaochaocs/narrasum",
    "checked": true,
    "id": "5fd9bc06b3a1ecc869166e7d4131079b8ec3e207",
    "semantic_title": "narrasum: a large-scale dataset for abstractive narrative summarization",
    "citation_count": 1,
    "authors": [
      "Chao Zhao",
      "Faeze Brahman",
      "Kaiqiang Song",
      "Wenlin Yao",
      "Dian Yu",
      "Snigdha Chaturvedi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.15": {
    "title": "NMTScore: A Multilingual Analysis of Translation-based Text Similarity Measures",
    "volume": "findings",
    "abstract": "Being able to rank the similarity of short text segments is an interesting bonus feature of neural machine translation. Translation-based similarity measures include direct and pivot translation probability, as well as translation cross-likelihood, which has not been studied so far. We analyze these measures in the common framework of multilingual NMT, releasing the NMTScore library. Compared to baselines such as sentence embeddings, translation-based measures prove competitive in paraphrase identification and are more robust against adversarial or multilingual input, especially if proper normalization is applied. When used for reference-based evaluation of data-to-text generation in 2 tasks and 17 languages, translation-based measures show a relatively high correlation to human judgments",
    "checked": true,
    "id": "8ab82ac0b80e67a63e19303db2342d29bfae003b",
    "semantic_title": "nmtscore: a multilingual analysis of translation-based text similarity measures",
    "citation_count": 8,
    "authors": [
      "Jannis Vamvas",
      "Rico Sennrich"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.16": {
    "title": "Language Models Understand Us, Poorly",
    "volume": "findings",
    "abstract": "Some claim language models understand us. Others won't hear it. To clarify, I investigate three views of human language understanding: as-mapping, as-reliability and as-representation. I argue that while behavioral reliability is necessary for understanding, internal representations are sufficient; they climb the right hill. I review state-of-the-art language and multi-modal models: they are pragmatically challenged by under-specification of form. I question the Scaling Paradigm: limits on resources may prohibit scaled-up models from approaching understanding. Last, I describe how as-representation advances a science of understanding. We need work which probes model internals, adds more of human language, and measures what models can learn",
    "checked": true,
    "id": "5c02d55fe14e2baf4b6b59a476ee6a20698397ef",
    "semantic_title": "language models understand us, poorly",
    "citation_count": 2,
    "authors": [
      "Jared Moore"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.17": {
    "title": "Dialogue Meaning Representation for Task-Oriented Dialogue Systems",
    "volume": "findings",
    "abstract": "Dialogue meaning representation formulates natural language utterance semantics in their conversational context in an explicit and machine-readable form. Previous work typically follows the intent-slot framework, which is easy for annotation yet limited in scalability for complex linguistic expressions. A line of works alleviates the representation issue by introducing hierarchical structures but challenging to express complex compositional semantics, such as negation and coreference. We propose Dialogue Meaning Representation (DMR), a pliable and easily extendable representation for task-oriented dialogue. Our representation contains a set of nodes and edges to represent rich compositional semantics. Moreover, we propose an inheritance hierarchy mechanism focusing on domain extensibility. Additionally, we annotated DMR-FastFood, a multi-turn dialogue dataset with more than 70k utterances, with DMR. We propose two evaluation tasks to evaluate different dialogue models and a novel coreference resolution model GNNCoref for the graph-based coreference resolution task. Experiments show that DMR can be parsed well with pre-trained Seq2Seq models, and GNNCoref outperforms the baseline models by a large margin. The dataset and code are available at https://github.com/amazon-research/dialogue-meaning-representation",
    "checked": true,
    "id": "e4eeffb8f9ba530347d98fd2c785d22e919c47a7",
    "semantic_title": "dialogue meaning representation for task-oriented dialogue systems",
    "citation_count": 3,
    "authors": [
      "Xiangkun Hu",
      "Junqi Dai",
      "Hang Yan",
      "Yi Zhang",
      "Qipeng Guo",
      "Xipeng Qiu",
      "Zheng Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.18": {
    "title": "Learning from the Dictionary: Heterogeneous Knowledge Guided Fine-tuning for Chinese Spell Checking",
    "volume": "findings",
    "abstract": "Chinese Spell Checking (CSC) aims to detect and correct Chinese spelling errors. Recent researches start from the pretrained knowledge of language models and take multimodal information into CSC models to improve the performance. However, they overlook the rich knowledge in the dictionary, the reference book where one can learn how one character should be pronounced, written, and used. In this paper, we propose the LEAD framework, which renders the CSC model to learn heterogeneous knowledge from the dictionary in terms of phonetics, vision, and meaning. LEAD first constructs positive and negative samples according to the knowledge of character phonetics, glyphs, and definitions in the dictionary. Then a unified contrastive learning-based training scheme is employed to refine the representations of the CSC models. Extensive experiments and detailed analyses on the SIGHAN benchmark datasets demonstrate the effectiveness of our proposed methods",
    "checked": true,
    "id": "0e4b8867274af148e4ea3777f5263a6119f91ecc",
    "semantic_title": "learning from the dictionary: heterogeneous knowledge guided fine-tuning for chinese spell checking",
    "citation_count": 19,
    "authors": [
      "Yinghui Li",
      "Shirong Ma",
      "Qingyu Zhou",
      "Zhongli Li",
      "Li Yangning",
      "Shulin Huang",
      "Ruiyang Liu",
      "Chao Li",
      "Yunbo Cao",
      "Haitao Zheng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.19": {
    "title": "Salient Phrase Aware Dense Retrieval: Can a Dense Retriever Imitate a Sparse One?",
    "volume": "findings",
    "abstract": "Despite their recent popularity and well-known advantages, dense retrievers still lag behind sparse methods such as BM25 in their ability to reliably match salient phrases and rare entities in the query and to generalize to out-of-domain data. It has been argued that this is an inherent limitation of dense models. We rebut this claim by introducing the Salient Phrase Aware Retriever (SPAR), a dense retriever with the lexical matching capacity of a sparse model. We show that a dense Lexical Model Λ can be trained to imitate a sparse one, and SPAR is built by augmenting a standard dense retriever with Λ. Empirically, SPAR shows superior performance on a range of tasks including five question answering datasets, MS MARCO passage retrieval, as well as the EntityQuestions and BEIR benchmarks for out-of-domain evaluation, exceeding the performance of state-of-the-art dense and sparse retrievers. The code and models of SPAR are available at: https://github.com/facebookresearch/dpr-scale/tree/main/spar",
    "checked": true,
    "id": "3f90c820417b4a770bbf74cd0bd7da0ded91f63b",
    "semantic_title": "salient phrase aware dense retrieval: can a dense retriever imitate a sparse one?",
    "citation_count": 49,
    "authors": [
      "Xilun Chen",
      "Kushal Lakhotia",
      "Barlas Oguz",
      "Anchit Gupta",
      "Patrick Lewis",
      "Stan Peshterliev",
      "Yashar Mehdad",
      "Sonal Gupta",
      "Wen-tau Yih"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.20": {
    "title": "SMARTAVE: Structured Multimodal Transformer for Product Attribute Value Extraction",
    "volume": "findings",
    "abstract": "Automatic product attribute value extraction refers to the task of identifying values of an attribute from the product information. Product attributes are essential in improving online shopping experience for customers. Most existing methods focus on extracting attribute values from product title and description. However, in many real-world applications, a product is usually represented by multiple modalities beyond title and description, such as product specifications, text and visual information from the product image, etc. In this paper, we propose SMARTAVE, a Structure Mltimodal trAnsformeR for producT Attribute Value Extraction, which jointly encodes the structured product information from multiple modalities. Specifically, in SMARTAVE encoder, we introduce hyper-tokens to represent the modality-level information, and local-tokens to represent the original text and visual inputs. Structured attention patterns are designed among the hyper-tokens and local-tokens for learning effective product representation. The attribute values are then extracted based on the learned embeddings. We conduct extensive experiments on two multimodal product datasets. Experimental results demonstrate the superior performance of the proposed approach over several state-of-the-art methods. Ablation studies validate the effectiveness of the structured attentions in modeling the multimodal product information",
    "checked": true,
    "id": "951de9dd230761d3c52bbd9a6f77229396521e37",
    "semantic_title": "smartave: structured multimodal transformer for product attribute value extraction",
    "citation_count": 7,
    "authors": [
      "Qifan Wang",
      "Li Yang",
      "Jingang Wang",
      "Jitin Krishnan",
      "Bo Dai",
      "Sinong Wang",
      "Zenglin Xu",
      "Madian Khabsa",
      "Hao Ma"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.21": {
    "title": "When Language Model Meets Private Library",
    "volume": "findings",
    "abstract": "With the rapid development of pre-training techniques, a number of language models have been pre-trained on large-scale code corpora and perform well in code generation. In this paper, we investigate how to equip pre-trained language models with the ability of code generation for private libraries. In practice, it is common for programmers to write code using private libraries. However, this is a challenge for language models since they have never seen private APIs during training. Motivated by the fact that private libraries usually come with elaborate API documentation, we propose a novel framework with two modules: the APIRetriever finds useful APIs, and then the APICoder generates code using these APIs. For APIRetriever, we present a dense retrieval system and also design a friendly interaction to involve uses. For APICoder, we can directly use off-the-shelf language models, or continually pre-train the base model on a code corpus containing API information. Both modules are trained with data from public libraries and can be generalized to private ones. Furthermore, we craft three benchmarks for private libraries, named TorchDataEval, MonkeyEval, and BeatNumEval. Experimental results demonstrate the impressive performance of our framework",
    "checked": true,
    "id": "4fbe0cb0777b228e39243692bf29e2829060b8de",
    "semantic_title": "when language model meets private library",
    "citation_count": 25,
    "authors": [
      "Daoguang Zan",
      "Bei Chen",
      "Zeqi Lin",
      "Bei Guan",
      "Wang Yongji",
      "Jian-Guang Lou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.22": {
    "title": "Cross-Domain Sentiment Classification using Semantic Representation",
    "volume": "findings",
    "abstract": "Previous studies on cross-domain sentiment classification depend on the pivot features or utilize the target data for representation learning, which ignore the semantic relevance between different domains. To this end, we exploit Abstract Meaning Representation (AMR) to help with cross-domain sentiment classification. Compared with the textual input, AMR reduces data sparsity and explicitly provides core semantic knowledge and correlations between different domains. In particular, we develop an algorithm to construct a sentiment-driven semantic graph from sentence-level AMRs. We further design two strategies to linearize the semantic graph and propose a text-graph interaction model to fuse the text and semantic graph representations for cross-domain sentiment classification. Empirical studies show the effectiveness of our proposed model over several strong baselines. The results also indicate the importance of the proposed sentiment-driven semantic graph for cross-domain sentiment classification",
    "checked": true,
    "id": "1da4dbbe38ae128dca23adef11cb918dee9cc97f",
    "semantic_title": "cross-domain sentiment classification using semantic representation",
    "citation_count": 2,
    "authors": [
      "Shichen Li",
      "Zhongqing Wang",
      "Xiaotong Jiang",
      "Guodong Zhou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.23": {
    "title": "Yes-Yes-Yes: Proactive Data Collection for ACL Rolling Review and Beyond",
    "volume": "findings",
    "abstract": "The shift towards publicly available text sources has enabled language processing at unprecedented scale, yet leaves under-serviced the domains where public and openly licensed data is scarce. Proactively collecting text data for research is a viable strategy to address this scarcity, but lacks systematic methodology taking into account the many ethical, legal and confidentiality-related aspects of data collection. Our work presents a case study on proactive data collection in peer review – a challenging and under-resourced NLP domain. We outline ethical and legal desiderata for proactive data collection and introduce \"Yes-Yes-Yes\", the first donation-based peer reviewing data collection workflow that meets these requirements. We report on the implementation of Yes-Yes-Yes at ACL Rolling Review and empirically study the implications of proactive data collection for the dataset size and the biases induced by the donation behavior on the peer reviewing platform",
    "checked": true,
    "id": "a5868a1823dd6dff8a551f31aeb1b555d258bb0a",
    "semantic_title": "yes-yes-yes: proactive data collection for acl rolling review and beyond",
    "citation_count": 4,
    "authors": [
      "Nils Dycke",
      "Ilia Kuznetsov",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.24": {
    "title": "AssistSR: Task-oriented Video Segment Retrieval for Personal AI Assistant",
    "volume": "findings",
    "abstract": "It is still a pipe dream that personal AI assistants on the phone and AR glasses can assist our daily life in addressing our questions like \"how to adjust the date for this watch?\" and \"how to set its heating duration? (while pointing at an oven)\". The queries used in conventional tasks (i.e. Video Question Answering, Video Retrieval, Moment Localization) are often factoid and based on pure text. In contrast, we present a new task called Task-oriented Question-driven Video Segment Retrieval (TQVSR). Each of our questions is an image-box-text query that focuses on affordance of items in our daily life and expects relevant answer segments to be retrieved from a corpus of instructional video-transcript segments. To support the study of this TQVSR task, we construct a new dataset called AssistSR. We design novel guidelines to create high-quality samples. This dataset contains 3.2k multimodal questions on 1.6k video segments from instructional videos on diverse daily-used items. To address TQVSR, we develop a simple yet effective model called Dual Multimodal Encoders (DME) that significantly outperforms several baseline methods while still having large room for improvement in the future. Moreover, we present detailed ablation analyses. Code and data are available at https://github.com/StanLei52/TQVSR",
    "checked": true,
    "id": "211f9cdb571b9ad3de070b84e76b7c747518031c",
    "semantic_title": "assistsr: task-oriented video segment retrieval for personal ai assistant",
    "citation_count": 3,
    "authors": [
      "Weixian Lei",
      "Difei Gao",
      "Yuxuan Wang",
      "Dongxing Mao",
      "Zihan Liang",
      "Lingmin Ran",
      "Mike Zheng Shou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.25": {
    "title": "Dim-Krum: Backdoor-Resistant Federated Learning for NLP with Dimension-wise Krum-Based Aggregation",
    "volume": "findings",
    "abstract": "Despite the potential of federated learning, it is known to be vulnerable to backdoor attacks. Many robust federated aggregation methods are proposed to reduce the potential backdoor risk. However, they are mainly validated in the CV field. In this paper, we find that NLP backdoors are hard to defend against than CV, and we provide a theoretical analysis that the malicious update detection error probabilities are determined by the relative backdoor strengths. NLP attacks tend to have small relative backdoor strengths, which may result in the failure of robust federated aggregation methods for NLP attacks. Inspired by the theoretical results, we can choose some dimensions with higher backdoor strengths to settle this issue. We propose a novel federated aggregation algorithm, Dim-Krum, for NLP tasks, and experimental results validate its effectiveness",
    "checked": true,
    "id": "a7304c75175fd350d43c6a0dd0e28f6c5033df45",
    "semantic_title": "dim-krum: backdoor-resistant federated learning for nlp with dimension-wise krum-based aggregation",
    "citation_count": 2,
    "authors": [
      "Zhiyuan Zhang",
      "Qi Su",
      "Xu Sun"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.26": {
    "title": "Fine-mixing: Mitigating Backdoors in Fine-tuned Language Models",
    "volume": "findings",
    "abstract": "Deep Neural Networks (DNNs) are known to be vulnerable to backdoor attacks. In Natural Language Processing (NLP), DNNs are often backdoored during the fine-tuning process of a large-scale Pre-trained Language Model (PLM) with poisoned samples. Although the clean weights of PLMs are readily available, existing methods have ignored this information in defending NLP models against backdoor attacks. In this work, we take the first step to exploit the pre-trained (unfine-tuned) weights to mitigate backdoors in fine-tuned language models. Specifically, we leverage the clean pre-trained weights via two complementary techniques: (1) a two-step Fine-mixing technique, which first mixes the backdoored weights (fine-tuned on poisoned data) with the pre-trained weights, then fine-tunes the mixed weights on a small subset of clean data; (2) an Embedding Purification (E-PUR) technique, which mitigates potential backdoors existing in the word embeddings. We compare Fine-mixing with typical backdoor mitigation methods on three single-sentence sentiment classification tasks and two sentence-pair classification tasks and show that it outperforms the baselines by a considerable margin in all scenarios. We also show that our E-PUR method can benefit existing mitigation methods. Our work establishes a simple but strong baseline defense for secure fine-tuned NLP models against backdoor attacks",
    "checked": true,
    "id": "1e69f7b278ba4ae61fdbeb3330d041107287bd20",
    "semantic_title": "fine-mixing: mitigating backdoors in fine-tuned language models",
    "citation_count": 12,
    "authors": [
      "Zhiyuan Zhang",
      "Lingjuan Lyu",
      "Xingjun Ma",
      "Chenguang Wang",
      "Xu Sun"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.27": {
    "title": "Language Models that Seek for Knowledge: Modular Search & Generation for Dialogue and Prompt Completion",
    "volume": "findings",
    "abstract": "Language models (LMs) have recently been shown to generate more factual responses by employing modularity (Zhou et al., 2022) in combination with retrieval (Adolphs et al., 2021). We extend the recent approach of Adolphs et al. (2021) to include internet search as a module. Our SeeKeR (Search engine->Knowledge->Response) method thus applies a single LM to three modular tasks in succession: search, generating knowledge, and generating a final response. We show that, when using SeeKeR as a dialogue model, it outperforms the state-of-the-art model BlenderBot 2 (Chen et al., 2021) on open-domain knowledge-grounded conversations for the same number of parameters, in terms of consistency, knowledge and per-turn engagingness. SeeKeR applied to topical prompt completions as a standard language model outperforms GPT2 (Radford et al., 2019) and GPT3 (Brown et al., 2020) in terms of factuality and topicality, despite GPT3 being a vastly larger model. Our code and models are made publicly available",
    "checked": true,
    "id": "f8292d4ddf7a6dfe240eeaa9685f5d18eed9a3f6",
    "semantic_title": "language models that seek for knowledge: modular search & generation for dialogue and prompt completion",
    "citation_count": 93,
    "authors": [
      "Kurt Shuster",
      "Mojtaba Komeili",
      "Leonard Adolphs",
      "Stephen Roller",
      "Arthur Szlam",
      "Jason Weston"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.28": {
    "title": "Stretching Sentence-pair NLI Models to Reason over Long Documents and Clusters",
    "volume": "findings",
    "abstract": "Natural Language Inference (NLI) has been extensively studied by the NLP community as a framework for estimating the semantic relation between sentence pairs. While early work identified certain biases in NLI models, recent advancements in modeling and datasets demonstrated promising performance. In this work, we further explore the direct zero-shot applicability of NLI models to real applications, beyond the sentence-pair setting they were trained on. First, we analyze the robustness of these models to longer and out-of-domain inputs. Then, we develop new aggregation methods to allow operating over full documents, reaching state-of-the-art performance on the ContractNLI dataset. Interestingly, we find NLI scores to provide strong retrieval signals, leading to more relevant evidence extractions compared to common similarity-based methods. Finally, we go further and investigate whole document clusters to identify both discrepancies and consensus among sources. In a test case, we find real inconsistencies between Wikipedia pages in different languages about the same topic",
    "checked": true,
    "id": "604e7988624b844a7ae04f0a91775c3a20e84f2b",
    "semantic_title": "stretching sentence-pair nli models to reason over long documents and clusters",
    "citation_count": 27,
    "authors": [
      "Tal Schuster",
      "Sihao Chen",
      "Senaka Buthpitiya",
      "Alex Fabrikant",
      "Donald Metzler"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.29": {
    "title": "Towards Realistic Low-resource Relation Extraction: A Benchmark with Empirical Baseline Study",
    "volume": "findings",
    "abstract": "This paper presents an empirical study to build relation extraction systems in low-resource settings. Based upon recent pre-trained language models, we comprehensively investigate three schemes to evaluate the performance in low-resource settings: (i) different types of prompt-based methods with few-shot labeled data; (ii) diverse balancing methods to address the long-tailed distribution issue; (iii) data augmentation technologies and self-training to generate more labeled in-domain data. We create a benchmark with 8 relation extraction (RE) datasets covering different languages, domains and contexts and perform extensive comparisons over the proposed schemes with combinations. Our experiments illustrate: (i) Though prompt-based tuning is beneficial in low-resource RE, there is still much potential for improvement, especially in extracting relations from cross-sentence contexts with multiple relational triples; (ii) Balancing methods are not always helpful for RE with long-tailed distribution; (iii) Data augmentation complements existing baselines and can bring much performance gain, while self-training may not consistently achieve advancement to low-resource RE. Code and datasets are in https://github.com/zjunlp/LREBench",
    "checked": true,
    "id": "325d6f5a823d07cebe9b0e7de9e42ddb8a4e5526",
    "semantic_title": "towards realistic low-resource relation extraction: a benchmark with empirical baseline study",
    "citation_count": 3,
    "authors": [
      "Xin Xu",
      "Xiang Chen",
      "Ningyu Zhang",
      "Xin Xie",
      "Xi Chen",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.30": {
    "title": "CLLE: A Benchmark for Continual Language Learning Evaluation in Multilingual Machine Translation",
    "volume": "findings",
    "abstract": "Continual Language Learning (CLL) in multilingual translation is inevitable when new languages are required to be translated. Due to the lack of unified and generalized benchmarks, the evaluation of existing methods is greatly influenced by experimental design which usually has a big gap from the industrial demands. In this work, we propose the first Continual Language Learning Evaluation benchmark CLLE in multilingual translation. CLLE consists of a Chinese-centric corpus — CN-25 and two CLL tasks — the close-distance language continual learning task and the language family continual learning task designed for real and disparate demands. Different from existing translation benchmarks, CLLE considers several restrictions for CLL, including domain distribution alignment, content overlap, language diversity, and the balance of corpus. Furthermore, we propose a novel framework COMETA based on Constrained Optimization and META-learning to alleviate catastrophic forgetting and dependency on history training data by using a meta-model to retain the important parameters for old languages. Our experiments prove that CLLE is a challenging CLL benchmark and that our proposed method is effective when compared with other strong baselines. Due to the construction of the corpus, the task designing and the evaluation method are independent of the centric language, we also construct and release the English-centric corpus EN-25 to facilitate academic research",
    "checked": true,
    "id": "48f819855ebcb7fc2ac0b9a825f91e23c1c83286",
    "semantic_title": "clle: a benchmark for continual language learning evaluation in multilingual machine translation",
    "citation_count": 3,
    "authors": [
      "Han Zhang",
      "Sheng Zhang",
      "Yang Xiang",
      "Bin Liang",
      "Jinsong Su",
      "Zhongjian Miao",
      "Hui Wang",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.31": {
    "title": "Lexicon-Enhanced Self-Supervised Training for Multilingual Dense Retrieval",
    "volume": "findings",
    "abstract": "Recent multilingual pre-trained models have shown better performance in various multilingual tasks. However, these models perform poorly on multilingual retrieval tasks due to lacking multilingual training data. In this paper, we propose to mine and generate self-supervised training data based on a large-scale unlabeled corpus. We carefully design a mining method which combines the sparse and dense models to mine the relevance of unlabeled queries and passages. And we introduce a query generator to generate more queries in target languages for unlabeled passages. Through extensive experiments on Mr. TYDI dataset and an industrial dataset from a commercial search engine, we demonstrate that our method performs better than baselines based on various pre-trained multilingual models. Our method even achieves on-par performance with the supervised method on the latter dataset",
    "checked": true,
    "id": "144c5a32cb51c7c2a5d7088c3010f0e85663f984",
    "semantic_title": "lexicon-enhanced self-supervised training for multilingual dense retrieval",
    "citation_count": 1,
    "authors": [
      "Houxing Ren",
      "Linjun Shou",
      "Jian Pei",
      "Ning Wu",
      "Ming Gong",
      "Daxin Jiang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.32": {
    "title": "Improve Interpretability of Neural Networks via Sparse Contrastive Coding",
    "volume": "findings",
    "abstract": "Although explainable artificial intelligence (XAI) has achieved remarkable developments in recent years, there are few efforts have been devoted to the following problems, namely, i) how to develop an explainable method that could explain the black-box in a model-agnostic way? and ii) how to improve the performance and interpretability of the black-box using such explanations instead of pre-collected important attributions? To explore the potential solution, we propose a model-agnostic explanation method termed as Sparse Contrastive Coding (SCC) and verify its effectiveness in text classification and natural language inference. In brief, SCC explains the feature attributions which characterize the importance of words based on the hidden states of each layer of the model. With such word-level explainability, SCC adaptively divides the input sentences into foregrounds and backgrounds in terms of task relevance. Through maximizing the similarity between the foregrounds and input sentences while minimizing the similarity between the backgrounds and input sentences, SSC employs a supervised contrastive learning loss to boost the interpretability and performance of the model. Extensive experiments show the superiority of our method over five state-of-the-art methods in terms of interpretability and classification measurements. The code is available at https://pengxi.me",
    "checked": true,
    "id": "aaf47f60b58ebbe804bb3e1e4ad8413b109ae4c9",
    "semantic_title": "improve interpretability of neural networks via sparse contrastive coding",
    "citation_count": 4,
    "authors": [
      "Junhong Liu",
      "Yijie Lin",
      "Liang Jiang",
      "Jia Liu",
      "Zujie Wen",
      "Xi Peng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.33": {
    "title": "LEMON: Language-Based Environment Manipulation via Execution-Guided Pre-training",
    "volume": "findings",
    "abstract": "Language-based environment manipulation requires agents to manipulate the environment following natural language instructions, which is challenging due to the huge space of the environments. To address this challenge, various approaches have been proposed in recent work. Although these approaches work well for their intended environments, they are difficult to generalize across environments. In this work, we propose LEMON, a general framework for language-based environment manipulation tasks. Specifically, we first specify a general approach for language-based environment manipulation tasks, which can deal with various environments using the same generative language model. Then we propose an execution-guided pre-training strategy to inject prior knowledge of environments to the language model with a pure synthetic pre-training corpus. Experimental results on tasks including Alchemy, Scene, Tangrams, ProPara and Recipes demonstrate the effectiveness of LEMON: it achieves new state-of-the-art results on four of the tasks, and the execution-guided pre-training strategy brings remarkable improvements on all experimental tasks",
    "checked": true,
    "id": "d6f9bd800d21ab71cb968cd48448530cdf8fff37",
    "semantic_title": "lemon: language-based environment manipulation via execution-guided pre-training",
    "citation_count": 8,
    "authors": [
      "Qi Shi",
      "Qian Liu",
      "Bei Chen",
      "Yu Zhang",
      "Ting Liu",
      "Jian-Guang Lou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.34": {
    "title": "CROP: Zero-shot Cross-lingual Named Entity Recognition with Multilingual Labeled Sequence Translation",
    "volume": "findings",
    "abstract": "Named entity recognition (NER) suffers from the scarcity of annotated training data, especially for low-resource languages without labeled data. Cross-lingual NER has been proposed to alleviate this issue by transferring knowledge from high-resource languages to low-resource languages via aligned cross-lingual representations or machine translation results. However, the performance of cross-lingual NER methods is severely affected by the unsatisfactory quality of translation or label projection. To address these problems, we propose a Cross-lingual Entity Projection framework (CROP) to enable zero-shot cross-lingual NER with the help of a multilingual labeled sequence translation model. Specifically, the target sequence is first translated into the source language and then tagged by a source NER model. We further adopt a labeled sequence translation model to project the tagged sequence back to the target language and label the target raw sentence. Ultimately, the whole pipeline is integrated into an end-to-end model by the way of self-training. Experimental results on two benchmarks demonstrate that our method substantially outperforms the previous strong baseline by a large margin of +3 7 F1 scores and achieves state-of-the-art performance",
    "checked": true,
    "id": "3e7d2160f58088297a8347a8273642ee484c7967",
    "semantic_title": "crop: zero-shot cross-lingual named entity recognition with multilingual labeled sequence translation",
    "citation_count": 13,
    "authors": [
      "Jian Yang",
      "Shaohan Huang",
      "Shuming Ma",
      "Yuwei Yin",
      "Li Dong",
      "Dongdong Zhang",
      "Hongcheng Guo",
      "Zhoujun Li",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.35": {
    "title": "Handling and Presenting Harmful Text in NLP Research",
    "volume": "findings",
    "abstract": "Text data can pose a risk of harm. However, the risks are not fully understood, and how to handle, present, and discuss harmful text in a safe way remains an unresolved issue in the NLP community. We provide an analytical framework categorising harms on three axes: (1) the harm type (e.g., misinformation, hate speech or racial stereotypes); (2) whether a harm is sought as a feature of the research design if explicitly studying harmful content (e.g., training a hate speech classifier), versus unsought if harmful content is encountered when working on unrelated problems (e.g., language generation or part-of-speech tagging); and (3) who it affects, from people (mis)represented in the data to those handling the data and those publishing on the data. We provide advice for practitioners, with concrete steps for mitigating harm in research and in publication. To assist implementation we introduce HarmCheck – a documentation standard for handling and presenting harmful text in research",
    "checked": true,
    "id": "d6404de05d99c416f06b0f8381acc7bb4260ff4f",
    "semantic_title": "handling and presenting harmful text in nlp research",
    "citation_count": 24,
    "authors": [
      "Hannah Kirk",
      "Abeba Birhane",
      "Bertie Vidgen",
      "Leon Derczynski"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.36": {
    "title": "Multimodal Contrastive Learning via Uni-Modal Coding and Cross-Modal Prediction for Multimodal Sentiment Analysis",
    "volume": "findings",
    "abstract": "Multimodal representation learning is a challenging task in which previous work mostly focus on either uni-modality pre-training or cross-modality fusion. In fact, we regard modeling multimodal representation as building a skyscraper, where laying stable foundation and designing the main structure are equally essential. The former is like encoding robust uni-modal representation while the later is like integrating interactive information among different modalities, both of which are critical to learning an effective multimodal representation. Recently, contrastive learning has been successfully applied in representation learning, which can be utilized as the pillar of the skyscraper and benefit the model to extract the most important features contained in the multimodal data. In this paper, we propose a novel framework named MultiModal Contrastive Learning (MMCL) for multimodal representation to capture intra- and inter-modality dynamics simultaneously. Specifically, we devise uni-modal contrastive coding with an efficient uni-modal feature augmentation strategy to filter inherent noise contained in acoustic and visual modality and acquire more robust uni-modality representations. Besides, a pseudo siamese network is presented to predict representation across different modalities, which successfully captures cross-modal dynamics. Moreover, we design two contrastive learning tasks, instance- and sentiment-based contrastive learning, to promote the process of prediction and learn more interactive information related to sentiment. Extensive experiments conducted on two public datasets demonstrate that our method surpasses the state-of-the-art methods",
    "checked": true,
    "id": "a91332878b9f47c9eede80f4d0c4d15f7089439e",
    "semantic_title": "multimodal contrastive learning via uni-modal coding and cross-modal prediction for multimodal sentiment analysis",
    "citation_count": 4,
    "authors": [
      "Ronghao Lin",
      "Haifeng Hu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.37": {
    "title": "Towards Unified Prompt Tuning for Few-shot Text Classification",
    "volume": "findings",
    "abstract": "Prompt-based fine-tuning has boosted the performance of Pre-trained Language Models (PLMs) on few-shot text classification by employing task-specific prompts. Yet, PLMs are unfamiliar with prompt-style expressions during pre-training, which limits the few-shot learning performance on downstream tasks. It would be desirable if the models can acquire some prompting knowledge before adapting to specific NLP tasks. We present the Unified Prompt Tuning (UPT) framework, leading to better few-shot text classification for BERT-style models by explicitly capturing prompting semantics from non-target NLP datasets. In UPT, a novel paradigm Prompt-Options-Verbalizer is proposed for joint prompt learning across different NLP tasks, forcing PLMs to capture task-invariant prompting knowledge. We further design a self-supervised task named Knowledge-enhanced Selective Masked Language Modeling to improve the PLM's generalization abilities for accurate adaptation to previously unseen tasks. After multi-task learning across multiple tasks, the PLM can be better prompt-tuned towards any dissimilar target tasks in low-resourced settings. Experiments over a variety of NLP tasks show that UPT consistently outperforms state-of-the-arts for prompt-based fine-tuning",
    "checked": true,
    "id": "a221def07d3cd4f29c38234e271faf8a523e0f5a",
    "semantic_title": "towards unified prompt tuning for few-shot text classification",
    "citation_count": 16,
    "authors": [
      "Jianing Wang",
      "Chengyu Wang",
      "Fuli Luo",
      "Chuanqi Tan",
      "Minghui Qiu",
      "Fei Yang",
      "Qiuhui Shi",
      "Songfang Huang",
      "Ming Gao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.38": {
    "title": "Can language models learn from explanations in context?",
    "volume": "findings",
    "abstract": "Language Models (LMs) can perform new tasks by adapting to a few in-context examples. For humans, explanations that connect examples to task principles can improve learning. We therefore investigate whether explanations of few-shot examples can help LMs. We annotate questions from 40 challenging tasks with answer explanations, and various matched control explanations. We evaluate how different types of explanations, instructions, and controls affect zero- and few-shot performance. We analyze these results using statistical multilevel modeling techniques that account for the nested dependencies among conditions, tasks, prompts, and models. We find that explanations can improve performance—even without tuning. Furthermore, explanations hand-tuned for performance on a small validation set offer substantially larger benefits, and building a prompt by selecting examples and explanations together substantially improves performance over selecting examples alone. Finally, even untuned explanations outperform carefully matched controls, suggesting that the benefits are due to the link between an example and its explanation, rather than lower-level features. However, only large models benefit. In summary, explanations can support the in-context learning of large LMs on challenging tasks",
    "checked": true,
    "id": "341bdbcfc3febef7691a97c216ad394653211095",
    "semantic_title": "can language models learn from explanations in context?",
    "citation_count": 187,
    "authors": [
      "Andrew Lampinen",
      "Ishita Dasgupta",
      "Stephanie Chan",
      "Kory Mathewson",
      "Mh Tessler",
      "Antonia Creswell",
      "James McClelland",
      "Jane Wang",
      "Felix Hill"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.39": {
    "title": "GNN-encoder: Learning a Dual-encoder Architecture via Graph Neural Networks for Dense Passage Retrieval",
    "volume": "findings",
    "abstract": "Recently, retrieval models based on dense representations are dominant in passage retrieval tasks, due to their outstanding ability in terms of capturing semantics of input text compared to the traditional sparse vector space models. A common practice of dense retrieval models is to exploit a dual-encoder architecture to represent a query and a passage independently. Though efficient, such a structure loses interaction between the query-passage pair, resulting in inferior accuracy. To enhance the performance of dense retrieval models without loss of efficiency, we propose a GNN-encoder model in which query (passage) information is fused into passage (query) representations via graph neural networks that are constructed by queries and their top retrieved passages. By this means, we maintain a dual-encoder structure, and retain some interaction information between query-passage pairs in their representations, which enables us to achieve both efficiency and efficacy in passage retrieval. Evaluation results indicate that our method significantly outperforms the existing models on MSMARCO, Natural Questions and TriviaQA datasets, and achieves the new state-of-the-art on these datasets",
    "checked": true,
    "id": "456ceaa05a4114458a82aa85010914da4e853563",
    "semantic_title": "gnn-encoder: learning a dual-encoder architecture via graph neural networks for dense passage retrieval",
    "citation_count": 3,
    "authors": [
      "Jiduan Liu",
      "Jiahao Liu",
      "Yang Yang",
      "Jingang Wang",
      "Wei Wu",
      "Dongyan Zhao",
      "Rui Yan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.40": {
    "title": "Linguistic Rules-Based Corpus Generation for Native Chinese Grammatical Error Correction",
    "volume": "findings",
    "abstract": "Chinese Grammatical Error Correction (CGEC) is both a challenging NLP task and a common application in human daily life. Recently, many data-driven approaches are proposed for the development of CGEC research. However, there are two major limitations in the CGEC field: First, the lack of high-quality annotated training corpora prevents the performance of existing CGEC models from being significantly improved. Second, the grammatical errors in widely used test sets are not made by native Chinese speakers, resulting in a significant gap between the CGEC models and the real application. In this paper, we propose a linguistic rules-based approach to construct large-scale CGEC training corpora with automatically generated grammatical errors. Additionally, we present a challenging CGEC benchmark derived entirely from errors made by native Chinese speakers in real-world scenarios. Extensive experiments and detailed analyses not only demonstrate that the training data constructed by our method effectively improves the performance of CGEC models, but also reflect that our benchmark is an excellent resource for further development of the CGEC field",
    "checked": true,
    "id": "090f0d79c35047881aab87d1b6ea313a3146ec33",
    "semantic_title": "linguistic rules-based corpus generation for native chinese grammatical error correction",
    "citation_count": 18,
    "authors": [
      "Shirong Ma",
      "Yinghui Li",
      "Rongyi Sun",
      "Qingyu Zhou",
      "Shulin Huang",
      "Ding Zhang",
      "Li Yangning",
      "Ruiyang Liu",
      "Zhongli Li",
      "Yunbo Cao",
      "Haitao Zheng",
      "Ying Shen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.41": {
    "title": "Rethinking the Video Sampling and Reasoning Strategies for Temporal Sentence Grounding",
    "volume": "findings",
    "abstract": "Temporal sentence grounding (TSG) aims to identify the temporal boundary of a specific segment from an untrimmed video by a sentence query. All existing works first utilize a sparse sampling strategy to extract a fixed number of video frames and then interact them with query for reasoning. However, we argue that these methods have overlooked two indispensable issues:1) Boundary-bias: The annotated target segment generally refers to two specific frames as corresponding start and end timestamps. The video downsampling process may lose these two frames and take the adjacent irrelevant frames as new boundaries.2) Reasoning-bias: Such incorrect new boundary frames also lead to the reasoning bias during frame-query interaction, reducing the generalization ability of model. To alleviate above limitations, in this paper, we propose a novel Siamese Sampling and Reasoning Network (SSRN) for TSG, which introduces a siamese sampling mechanism to generate additional contextual frames to enrich and refine the new boundaries. Specifically, a reasoning strategy is developed to learn the inter-relationship among these frames and generate soft labels on boundaries for more accurate frame-query reasoning. Such mechanism is also able to supplement the absent consecutive visual semantics to the sampled sparse frames for fine-grained activity understanding. Extensive experiments demonstrate the effectiveness of SSRN on three challenging datasets",
    "checked": true,
    "id": "caa4e1c5c4b72ab28a42310c744c9651b57c9660",
    "semantic_title": "rethinking the video sampling and reasoning strategies for temporal sentence grounding",
    "citation_count": 8,
    "authors": [
      "Jiahao Zhu",
      "Daizong Liu",
      "Pan Zhou",
      "Xing Di",
      "Yu Cheng",
      "Song Yang",
      "Wenzheng Xu",
      "Zichuan Xu",
      "Yao Wan",
      "Lichao Sun",
      "Zeyu Xiong"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.42": {
    "title": "System 1 + System 2 = Better World: Neural-Symbolic Chain of Logic Reasoning",
    "volume": "findings",
    "abstract": "Logical reasoning is a challenge for many current NLP neural network models since it requires more than the ability of learning informative representations from data. Inspired by the Dual Process Theory in cognitive science — which proposes that human cognition process involves two stages: an intuitive, unconscious and fast process relying on perception calledSystem 1, and a logical, conscious and slow process performing complex reasoning called System 2 — we leverage neural logic reasoning (System 2) on top of the representation learning models (System 1), which conducts explicit neural-based differentiable logical reasoning on top of the representations learned by the base neural models. Based on experiments on the commonsense knowledge graph completion task, we show that the two-system architecture always improves from its System 1 model alone. Experiments also show that both the rule-driven logical regularizer and the data-driven value regularizer are important and the performance improvement is marginal without the two regularizers, which indicates that learning from both logical prior and training data is important for reasoning tasks",
    "checked": true,
    "id": "6e3166d917b40dc6533b4c47885a2abdbbd34d2a",
    "semantic_title": "system 1 + system 2 = better world: neural-symbolic chain of logic reasoning",
    "citation_count": 5,
    "authors": [
      "Wenyue Hua",
      "Yongfeng Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.43": {
    "title": "Efficient Federated Learning on Knowledge Graphs via Privacy-preserving Relation Embedding Aggregation",
    "volume": "findings",
    "abstract": "Federated learning (FL) can be essential in knowledge representation, reasoning, and data mining applications over multi-source knowledge graphs (KGs). A recent study FedE first proposes an FL framework that shares entity embeddings of KGs across all clients. However, entity embedding sharing from FedE would incur a severe privacy leakage. Specifically, the known entity embedding can be used to infer whether a specific relation between two entities exists in a private client. In this paper, we introduce a novel attack method that aims to recover the original data based on the embedding information, which is further used to evaluate the vulnerabilities of FedE. Furthermore, we propose a Federated learning paradigm with privacy-preserving Relation embedding aggregation (FedR) to tackle the privacy issue in FedE. Besides, relation embedding sharing can significantly reduce the communication cost due to its smaller size of queries. We conduct extensive experiments to evaluate FedR with five different KG embedding models and three datasets. Compared to FedE, FedR achieves similar utility and significant improvements regarding privacy-preserving effect and communication efficiency on the link prediction task",
    "checked": true,
    "id": "da40ffc84a6188f64175387a6198f67647c6f088",
    "semantic_title": "efficient federated learning on knowledge graphs via privacy-preserving relation embedding aggregation",
    "citation_count": 13,
    "authors": [
      "Kai Zhang",
      "Yu Wang",
      "Hongyi Wang",
      "Lifu Huang",
      "Carl Yang",
      "Xun Chen",
      "Lichao Sun"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.44": {
    "title": "TextHacker: Learning based Hybrid Local Search Algorithm for Text Hard-label Adversarial Attack",
    "volume": "findings",
    "abstract": "Existing textual adversarial attacks usually utilize the gradient or prediction confidence to generate adversarial examples, making it hard to be deployed in real-world applications. To this end, we consider a rarely investigated but more rigorous setting, namely hard-label attack, in which the attacker can only access the prediction label. In particular, we find we can learn the importance of different words via the change on prediction label caused by word substitutions on the adversarial examples. Based on this observation, we propose a novel adversarial attack, termed Text Hard-label attacker (TextHacker). TextHacker randomly perturbs lots of words to craft an adversarial example. Then, TextHacker adopts a hybrid local search algorithm with the estimation of word importance from the attack history to minimize the adversarial perturbation. Extensive evaluations for text classification and textual entailment show that TextHacker significantly outperforms existing hard-label attacks regarding the attack performance as well as adversary quality",
    "checked": true,
    "id": "6c4ffabd326daa73fa12fea0614bf81e85fcde0e",
    "semantic_title": "texthacker: learning based hybrid local search algorithm for text hard-label adversarial attack",
    "citation_count": 5,
    "authors": [
      "Zhen Yu",
      "Xiaosen Wang",
      "Wanxiang Che",
      "Kun He"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.45": {
    "title": "Visualizing the Obvious: A Concreteness-based Ensemble Model for Noun Property Prediction",
    "volume": "findings",
    "abstract": "Neural language models encode rich knowledge about entities and their relationships which can be extracted from their representations using probing. Common properties of nouns (e.g., red strawberries, small ant) are, however, more challenging to extract compared to other types of knowledge because they are rarely explicitly stated in texts. We hypothesize this to mainly be the case for perceptual properties which are obvious to the participants in the communication. We propose to extract these properties from images and use them in an ensemble model, in order to complement the information that is extracted from language models. We consider perceptual properties to be more concrete than abstract properties (e.g., interesting, flawless). We propose to use the adjectives' concreteness score as a lever to calibrate the contribution of each source (text vs. images). We evaluate our ensemble model in a ranking task where the actual properties of a noun need to be ranked higher than other non-relevant properties. Our results show that the proposed combination of text and images greatly improves noun property prediction compared to powerful text-based language models",
    "checked": true,
    "id": "1209b23684ee76fe951551c07c72a3f73a99aa0d",
    "semantic_title": "visualizing the obvious: a concreteness-based ensemble model for noun property prediction",
    "citation_count": 1,
    "authors": [
      "Yue Yang",
      "Artemis Panagopoulou",
      "Marianna Apidianaki",
      "Mark Yatskar",
      "Chris Callison-Burch"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.46": {
    "title": "It's Better to Teach Fishing than Giving a Fish: An Auto-Augmented Structure-aware Generative Model for Metaphor Detection",
    "volume": "findings",
    "abstract": "Metaphor Detection aims to identify the metaphorical meaning of words in the sentence. Most existing work is discriminant models, which use the contextual semantic information extracted by transformers for classifications directly. Due to insufficient training data and corresponding paraphrases, recent methods focus on how to get external resources and utilize them to introduce more knowledge. Currently, contextual modeling and external data are two key issues in the field. In this paper, we propose **A**n **A**uto-**A**ugmented **S**tructure-aware generative model (**AAAS**) for metaphor detection, which transforms the classification task into a keywords-extraction task. Specifically, we propose the task of structure information extraction to allow the model to use the ‘structural language' to describe the whole sentence. Furthermore, without any other external resources, we design a simple but effective auto-augmented method to expand the limited datasets. Experimental results show that **AAAS** obtains competitive results compared with state-of-the-art methods",
    "checked": true,
    "id": "ce1bd0d4b318d0263fec51aedcf812ee181a13aa",
    "semantic_title": "it's better to teach fishing than giving a fish: an auto-augmented structure-aware generative model for metaphor detection",
    "citation_count": 2,
    "authors": [
      "Huawen Feng",
      "Qianli Ma"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.47": {
    "title": "Expose Backdoors on the Way: A Feature-Based Efficient Defense against Textual Backdoor Attacks",
    "volume": "findings",
    "abstract": "Natural language processing (NLP) models are known to be vulnerable to backdoor attacks, which poses a newly arisen threat to NLP models. Prior online backdoor defense methods for NLP models only focus on the anomalies at either the input or output level, still suffering from fragility to adaptive attacks and high computational cost. In this work, we take the first step to investigate the unconcealment of textual poisoned samples at the intermediate-feature level and propose a feature-based efficient online defense method. Through extensive experiments on existing attacking methods, we find that the poisoned samples are far away from clean samples in the intermediate feature space of a poisoned NLP model. Motivated by this observation, we devise a distance-based anomaly score (DAN) to distinguish poisoned samples from clean samples at the feature level. Experiments on sentiment analysis and offense detection tasks demonstrate the superiority of DAN, as it substantially surpasses existing online defense methods in terms of defending performance and enjoys lower inference costs. Moreover, we show that DAN is also resistant to adaptive attacks based on feature-level regularization. Our code is available at https://github.com/lancopku/DAN",
    "checked": true,
    "id": "989ef83ba28b4d5cc51d943d658698aa0b642db3",
    "semantic_title": "expose backdoors on the way: a feature-based efficient defense against textual backdoor attacks",
    "citation_count": 10,
    "authors": [
      "Sishuo Chen",
      "Wenkai Yang",
      "Zhiyuan Zhang",
      "Xiaohan Bi",
      "Xu Sun"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.48": {
    "title": "Diving Deep into Modes of Fact Hallucinations in Dialogue Systems",
    "volume": "findings",
    "abstract": "Knowledge Graph(KG) grounded conversations often use large pre-trained models and usually suffer from fact hallucination. Frequently entities with no references in knowledge sources and conversation history are introduced into responses, thus hindering the flow of the conversation—existing work attempt to overcome this issue by tweaking the training procedure or using a multi-step refining method. However, minimal effort is put into constructing an entity-level hallucination detection system, which would provide fine-grained signals that control fallacious content while generating responses. As a first step to address this issue, we dive deep to identify various modes of hallucination in KG-grounded chatbots through human feedback analysis. Secondly, we propose a series of perturbation strategies to create a synthetic dataset named FADE (FActual Dialogue Hallucination DEtection Dataset). Finally, we conduct comprehensive data analyses and create multiple baseline models for hallucination detection to compare against human-verified data and already established benchmarks",
    "checked": true,
    "id": "4cbdafe5aa262f259bf03003949bbb78ddb54dce",
    "semantic_title": "diving deep into modes of fact hallucinations in dialogue systems",
    "citation_count": 11,
    "authors": [
      "Souvik Das",
      "Sougata Saha",
      "Rohini Srihari"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.49": {
    "title": "Representation Learning for Resource-Constrained Keyphrase Generation",
    "volume": "findings",
    "abstract": "State-of-the-art keyphrase generation methods generally depend on large annotated datasets, limiting their performance in domains with limited annotated data. To overcome this challenge, we design a data-oriented approach that first identifies salient information using retrieval-based corpus-level statistics, and then learns a task-specific intermediate representation based on a pre-trained language model using large-scale unlabeled documents. We introduce salient span recovery and salient span prediction as denoising training objectives that condense the intra-article and inter-article knowledge essential for keyphrase generation. Through experiments on multiple keyphrase generation benchmarks, we show the effectiveness of the proposed approach for facilitating low-resource keyphrase generation and zero-shot domain adaptation. Our method especially benefits the generation of absent keyphrases, approaching the performance of models trained with large training sets",
    "checked": true,
    "id": "a761e7e9c731ccc98ac1ba60ead15713b077514a",
    "semantic_title": "representation learning for resource-constrained keyphrase generation",
    "citation_count": 11,
    "authors": [
      "Di Wu",
      "Wasi Ahmad",
      "Sunipa Dev",
      "Kai-Wei Chang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.50": {
    "title": "Systematicity in GPT-3's Interpretation of Novel English Noun Compounds",
    "volume": "findings",
    "abstract": "Levin et al. (2019) show experimentally that the interpretations of novel English noun compounds (e.g., stew skillet), while not fully compositional, are highly predictable based on whether the modifier and head refer to artifacts or natural kinds. Is the large language model GPT-3 governed by the same interpretive principles? To address this question, we first compare Levin et al.'s experimental data with GPT-3 generations, finding a high degree of similarity. However, this evidence is consistent with GPT-3 reasoning only about specific lexical items rather than the more abstract conceptual categories of Levin et al.'s theory. To probe more deeply, we construct prompts that require the relevant kind of conceptual reasoning. Here, we fail to find convincing evidence that GPT-3 is reasoning about more than just individual lexical items. These results highlight the importance of controlling for low-level distributional regularities when assessing whether a large language model latently encodes a deeper theory",
    "checked": true,
    "id": "74be37384adc9b643b0c0a2d3b26c1361c5d779b",
    "semantic_title": "systematicity in gpt-3's interpretation of novel english noun compounds",
    "citation_count": 6,
    "authors": [
      "Siyan Li",
      "Riley Carlson",
      "Christopher Potts"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.51": {
    "title": "CARE: Causality Reasoning for Empathetic Responses by Conditional Graph Generation",
    "volume": "findings",
    "abstract": "Recent approaches to empathetic response generation incorporate emotion causalities to enhance comprehension of both the user's feelings and experiences. However, these approaches suffer from two critical issues. First, they only consider causalities between the user's emotion and the user's experiences, and ignore those between the user's experiences. Second, they neglect interdependence among causalities and reason them independently. To solve the above problems, we expect to reason all plausible causalities interdependently and simultaneously, given the user's emotion, dialogue history, and future dialogue content. Then, we infuse these causalities into response generation for empathetic responses. Specifically, we design a new model, i.e., the Conditional Variational Graph Auto-Encoder (CVGAE), for the causality reasoning, and adopt a multi-source attention mechanism in the decoder for the causality infusion. We name the whole framework as CARE, abbreviated for CAusality Reasoning for Empathetic conversation. Experimental results indicate that our method achieves state-of-the-art performance",
    "checked": true,
    "id": "21265688922d2bf3764711b8c97ab32de7eadbcf",
    "semantic_title": "care: causality reasoning for empathetic responses by conditional graph generation",
    "citation_count": 5,
    "authors": [
      "Jiashuo Wang",
      "Yi Cheng",
      "Wenjie Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.52": {
    "title": "TransAdv: A Translation-based Adversarial Learning Framework for Zero-Resource Cross-Lingual Named Entity Recognition",
    "volume": "findings",
    "abstract": "Zero-Resource Cross-Lingual Named Entity Recognition aims at training an NER model of the target language using only labeled source language data and unlabeled target language data. Existing methods are mainly divided into three categories: model transfer based, data transfer based and knowledge transfer based. Each method has its own disadvantages, and combining more than one of them often leads to better performance. However, the performance of data transfer based methods is often limited by inevitable noise in the translation process. To handle the problem, we propose a framework named TransAdv to mitigate lexical and syntactic errors of word-by-word translated data, better utilizing the data by multi-level adversarial learning and multi-model knowledge distillation. Extensive experiments are conducted over 6 target languages with English as the source language, and the results show that TransAdv achieves competitive performance to the state-of-the-art models",
    "checked": true,
    "id": "2607bbdfd1974de539a5b1d0f57b2d59b550c92f",
    "semantic_title": "transadv: a translation-based adversarial learning framework for zero-resource cross-lingual named entity recognition",
    "citation_count": 0,
    "authors": [
      "Yichun Zhao",
      "Jintao Du",
      "Gongshen Liu",
      "Huijia Zhu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.53": {
    "title": "BARLE: Background-Aware Representation Learning for Background Shift Out-of-Distribution Detection",
    "volume": "findings",
    "abstract": "Machine learning models often suffer from a performance drop when they are applied to out-of-distribution (OOD) samples, i.e., those drawn far away from the training data distribution. Existing OOD detection work mostly focuses on identifying semantic-shift OOD samples, e.g., instances from unseen new classes. However, background-shift OOD detection, which identifies samples with domain or style-change, represents a more practical yet challenging task. In this paper, we propose Background-Aware Representation Learning (BARLE) for background-shift OOD detection in NLP. Specifically, we generate semantics-preserving background-shifted pseudo OOD samples from pretrained masked language models. We then contrast the in-distribution (ID) samples with their pseudo OOD counterparts. Unlike prior semantic-shift OOD detection work that often leverages an external text corpus, BARLE only uses ID data, which is more flexible and cost-efficient. In experiments across several text classification tasks, we demonstrate that BARLE is capable of improving background-shift OOD detection performance while maintaining ID classification accuracy. We further investigate the properties of the generated pseudo OOD samples, uncovering the working mechanism of BARLE",
    "checked": true,
    "id": "4eae7eb3cba36900f276986768c79fa5bc6410dd",
    "semantic_title": "barle: background-aware representation learning for background shift out-of-distribution detection",
    "citation_count": 3,
    "authors": [
      "Hanyu Duan",
      "Yi Yang",
      "Ahmed Abbasi",
      "Kar Yan Tam"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.54": {
    "title": "What Language Model to Train if You Have One Million GPU Hours?",
    "volume": "findings",
    "abstract": "The crystallization of modeling methods around the Transformer architecture has been a boon for practitioners. Simple, well-motivated architectural variations can transfer across tasks and scale, increasing the impact of modeling research. However, with the emergence of state-of-the-art 100B+ parameters models, large language models are increasingly expensive to accurately design and train. Notably, it can be difficult to evaluate how modeling decisions may impact emergent capabilities, given that these capabilities arise mainly from sheer scale alone. In the process of building BLOOM–the Big Science Large Open-science Open-access Multilingual language model–our goal is to identify an architecture and training setup that makes the best use of our 1,000,000 A100-GPU-hours budget. Specifically, we perform an ablation study at the billion-parameter scale comparing different modeling practices and their impact on zero-shot generalization. In addition, we study the impact of various popular pre-training corpora on zero-shot generalization. We also study the performance of a multilingual model and how it compares to the English-only one. Finally, we consider the scaling behaviour of Transformers to choose the target model size, shape, and training setup. All our models and code are open-sourced at https://huggingface.co/bigscience",
    "checked": true,
    "id": "bb15f3727f827a3cb88b5d3ca48415c09b40a88f",
    "semantic_title": "what language model to train if you have one million gpu hours?",
    "citation_count": 64,
    "authors": [
      "Teven Le Scao",
      "Thomas Wang",
      "Daniel Hesslow",
      "Stas Bekman",
      "M Saiful Bari",
      "Stella Biderman",
      "Hady Elsahar",
      "Niklas Muennighoff",
      "Jason Phang",
      "Ofir Press",
      "Colin Raffel",
      "Victor Sanh",
      "Sheng Shen",
      "Lintang Sutawika",
      "Jaesung Tae",
      "Zheng Xin Yong",
      "Julien Launay",
      "Iz Beltagy"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.55": {
    "title": "Enhancing Out-of-Distribution Detection in Natural Language Understanding via Implicit Layer Ensemble",
    "volume": "findings",
    "abstract": "Out-of-distribution (OOD) detection aims to discern outliers from the intended data distribution, which is crucial to maintaining high reliability and a good user experience. Most recent studies in OOD detection utilize the information from a single representation that resides in the penultimate layer to determine whether the input is anomalous or not. Although such a method is straightforward, the potential of diverse information in the intermediate layers is overlooked. In this paper, we propose a novel framework based on contrastive learning that encourages intermediate features to learn layer-specialized representations and assembles them implicitly into a single representation to absorb rich information in the pre-trained language model. Extensive experiments in various intent classification and OOD datasets demonstrate that our approach is significantly more effective than other works",
    "checked": true,
    "id": "2898f2ea955b7e1eaf9e7868a7c3602ca9a40403",
    "semantic_title": "enhancing out-of-distribution detection in natural language understanding via implicit layer ensemble",
    "citation_count": 6,
    "authors": [
      "Hyunsoo Cho",
      "Choonghyun Park",
      "Jaewook Kang",
      "Kang Min Yoo",
      "Taeuk Kim",
      "Sang-goo Lee"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.56": {
    "title": "Contrastive Demonstration Tuning for Pre-trained Language Models",
    "volume": "findings",
    "abstract": "Pretrained language models can be effectively stimulated by textual prompts or demonstrations, especially in low-data scenarios. Recent works have focused on automatically searching discrete or continuous prompts or optimized verbalizers, yet studies for the demonstration are still limited. Concretely, the demonstration examples are crucial for an excellent final performance of prompt-tuning. In this paper, we propose a novel pluggable, extensible, and efficient approach named contrastive demonstration tuning, which is free of demonstration sampling. Furthermore, the proposed approach can be: (i) Plugged into any previous prompt-tuning approaches; (ii) Extended to widespread classification tasks with a large number of categories. Experimental results on 16 datasets illustrate that our method integrated with previous approaches LM-BFF and P-tuning can yield better performance. Code is available in https://github.com/zjunlp/PromptKG/tree/main/research/Demo-Tuning",
    "checked": true,
    "id": "2c33191c45086c6d522580174dd8ab15e038fe3e",
    "semantic_title": "contrastive demonstration tuning for pre-trained language models",
    "citation_count": 9,
    "authors": [
      "Xiaozhuan Liang",
      "Ningyu Zhang",
      "Siyuan Cheng",
      "Zhenru Zhang",
      "Chuanqi Tan",
      "Huajun Chen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.57": {
    "title": "Detect-Localize-Repair: A Unified Framework for Learning to Debug with CodeT5",
    "volume": "findings",
    "abstract": "Automated software debugging is a crucial task for improving the productivity of software developers. Many neural-based techniques have been proven effective for debugging-related tasks such as bug localization and program repair (or bug fixing). However, these techniques often focus only on either one of them or approach them in a stage-wise manner, ignoring the mutual benefits between them. In this work, we propose a novel unified Detect-Localize-Repair framework based on a pretrained programming language model CodeT5 to seamlessly address these tasks, named CodeT5-DLR. Specifically, we propose three objectives to adapt the generic CodeT5 for debugging: a bug detection objective to determine whether a given code snippet is buggy or not, a bug localization objective to identify the buggy lines, and a program repair objective to translate the buggy code to its fixed version. We evaluate it on each of these tasks and their combined setting on two newly collected line-level debugging datasets in Java and Python. Extensive results show that our model significantly outperforms existing baselines from both NLP and software engineering domains",
    "checked": true,
    "id": "6f0bfec3a245f1aa203d16469ec313f2eb02e028",
    "semantic_title": "detect-localize-repair: a unified framework for learning to debug with codet5",
    "citation_count": 10,
    "authors": [
      "Nghi Bui",
      "Yue Wang",
      "Steven C.H. Hoi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.58": {
    "title": "Influence Functions for Sequence Tagging Models",
    "volume": "findings",
    "abstract": "Many standard tasks in NLP (e.g., Named Entity Recognition, Part-of-Speech tagging, and Semantic Role Labeling) are naturally framed as sequence tagging problems. However, there has been comparatively little work on interpretability methods for sequence tagging models. In this paper, we extend influence functions — which aim to trace predictions back to the training points that informed them — to sequence tagging tasks. We define the influence of a training instance segment as the effect that perturbing the labels within this segment has on a test segment level prediction. We provide an efficient approximation to compute this, and show that it tracks with the \"true\" segment influence (measured empirically). We show the practical utility of segment influence by using the method to identify noisy annotations in NER corpora",
    "checked": true,
    "id": "848e7de138eef6352d1066db783d0e66becf17f4",
    "semantic_title": "influence functions for sequence tagging models",
    "citation_count": 6,
    "authors": [
      "Sarthak Jain",
      "Varun Manjunatha",
      "Byron Wallace",
      "Ani Nenkova"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.59": {
    "title": "Impact of Pretraining Term Frequencies on Few-Shot Numerical Reasoning",
    "volume": "findings",
    "abstract": "Pretrained Language Models (LMs) have demonstrated ability to perform numerical reasoning by extrapolating from a few examples in few-shot settings. However, the extent to which this extrapolation relies on robust reasoning is unclear. In this paper, we investigate how well these models reason with terms that are less frequent in the pretraining data. In particular, we examine the correlations between the model performance on test instances and the frequency of terms from those instances in the pretraining data. We measure the strength of this correlation for a number of GPT-based language models (pretrained on the Pile dataset) on various numerical deduction tasks (e.g., arithmetic and unit conversion). Our results consistently demonstrate that models are more accurate on instances whose terms are more prevalent, in some cases above 70% (absolute) more accurate on the top 10% frequent terms in comparison to the bottom 10%. Overall, although LMs appear successful at few-shot numerical reasoning, our results raise the question of how much models actually generalize beyond pretraining data, and we encourage researchers to take the pretraining data into account when interpreting evaluation results",
    "checked": true,
    "id": "4578717d5593b88e1c10555ce67a14be312b84b2",
    "semantic_title": "impact of pretraining term frequencies on few-shot numerical reasoning",
    "citation_count": 63,
    "authors": [
      "Yasaman Razeghi",
      "Robert L Logan IV",
      "Matt Gardner",
      "Sameer Singh"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.60": {
    "title": "Syntactic and Semantic Uniformity for Semantic Parsing and Task-Oriented Dialogue Systems",
    "volume": "findings",
    "abstract": "This paper proposes a data representation framework for semantic parsing and task-oriented dialogue systems, aiming to achieve a uniform representation for syntactically and semantically diverse machine-readable formats. Current NLP systems heavily rely on adapting pre-trained language models to specific tasks, and this approach has been proven effective for modeling natural language texts. However, little attention has been paid to the representation of machine-readable formats, such as database queries and dialogue states. We present a method for converting original machine-readable formats of semantic parsing and task-oriented dialogue datasets into a syntactically and semantically uniform representation. We define a meta grammar for syntactically uniform representations and translate semantically equivalent functions into a uniform vocabulary. Empirical experiments on 13 datasets show that accuracy consistently improves over original formats, revealing the advantage of the proposed representation. Additionally, we show that the proposed representation allows for transfer learning across datasets",
    "checked": true,
    "id": "ff5ce86eb29aa0b2fc4f6f029dfe7fd154234d36",
    "semantic_title": "syntactic and semantic uniformity for semantic parsing and task-oriented dialogue systems",
    "citation_count": 0,
    "authors": [
      "Bowen Chen",
      "Yusuke Miyao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.61": {
    "title": "Knowledge-Rich Self-Supervision for Biomedical Entity Linking",
    "volume": "findings",
    "abstract": "Entity linking faces significant challenges such as prolific variations and prevalent ambiguities, especially in high-value domains with myriad entities. Standard classification approaches suffer from the annotation bottleneck and cannot effectively handle unseen entities. Zero-shot entity linking has emerged as a promising direction for generalizing to new entities, but it still requires example gold entity mentions during training and canonical descriptions for all entities, both of which are rarely available outside of Wikipedia. In this paper, we explore Knowledge-RIch Self-Supervision (KRISS) for biomedical entity linking, by leveraging readily available domain knowledge. In training, it generates self-supervised mention examples on unlabeled text using a domain ontology and trains a contextual encoder using contrastive learning. For inference, it samples self-supervised mentions as prototypes for each entity and conducts linking by mapping the test mention to the most similar prototype. Our approach can easily incorporate entity descriptions and gold mention labels if available. We conducted extensive experiments on seven standard datasets spanning biomedical literature and clinical notes. Without using any labeled information, our method produces KRISSBERT, a universal entity linker for four million UMLS entities that attains new state of the art, outperforming prior self-supervised methods by as much as 20 absolute points in accuracy. We released KRISSBERT at https://aka.ms/krissbert",
    "checked": true,
    "id": "4361c498f45cc6d1ef4e98b75b23af6c598da54d",
    "semantic_title": "knowledge-rich self-supervision for biomedical entity linking",
    "citation_count": 24,
    "authors": [
      "Sheng Zhang",
      "Hao Cheng",
      "Shikhar Vashishth",
      "Cliff Wong",
      "Jinfeng Xiao",
      "Xiaodong Liu",
      "Tristan Naumann",
      "Jianfeng Gao",
      "Hoifung Poon"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.62": {
    "title": "ARTIST: A Transformer-based Chinese Text-to-Image Synthesizer Digesting Linguistic and World Knowledge",
    "volume": "findings",
    "abstract": "Text-to-Image Synthesis (TIS) is a popular task to convert natural language texts into realistic images. Recently, transformer-based TIS models (such as DALL-E) have been proposed using the encoder-decoder architectures. Yet, these billion-scale TIS models are difficult to tune and deploy in resource-constrained environments. In addition, there is a lack of language-specific TIS benchmarks for Chinese, together with high-performing models with moderate sizes. In this work, we present ARTIST, A tRansformer-based Chinese Text-to-Image SynThesizer for high-resolution image generation. In ARTIST, the rich linguistic and relational knowledge facts are injected into the model to ensure better model performance without the usage of ultra-large models. We further establish a large-scale Chinese TIS benchmark with the re-production results of state-of-the-art transformer-based TIS models. Results show ARTIST outperforms previous approaches",
    "checked": true,
    "id": "c9faf77e8d1d9ad663fd9fef2dd36666ebc96af0",
    "semantic_title": "artist: a transformer-based chinese text-to-image synthesizer digesting linguistic and world knowledge",
    "citation_count": 2,
    "authors": [
      "Tingting Liu",
      "Chengyu Wang",
      "Xiangru Zhu",
      "Lei Li",
      "Minghui Qiu",
      "Jun Huang",
      "Ming Gao",
      "Yanghua Xiao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.63": {
    "title": "From Spelling to Grammar: A New Framework for Chinese Grammatical Error Correction",
    "volume": "findings",
    "abstract": "Chinese Grammatical Error Correction (CGEC) aims to generate a correct sentence from an erroneous sequence, where different kinds of errors are mixed. This paper divides the CGEC task into two steps, namely spelling error correction and grammatical error correction. We firstly propose a novel zero-shot approach for spelling error correction, which is simple but effective, obtaining a high precision to avoid error accumulation of the pipeline structure. To handle grammatical error correction, we design part-of-speech (POS) features and semantic class features to enhance the neural network model, and propose an auxiliary task to predict the POS sequence of the target sentence. Our proposed framework achieves a 42.11 F-0.5 score on CGEC dataset without using any synthetic data or data augmentation methods, which outperforms the previous state-of-the-art by a wide margin of 1.30 points. Moreover, our model produces meaningful POS representations that capture different POS words and convey reasonable POS transition rules",
    "checked": true,
    "id": "4cc73edaca5fc7e6e777525e030e1537f0292449",
    "semantic_title": "from spelling to grammar: a new framework for chinese grammatical error correction",
    "citation_count": 4,
    "authors": [
      "Xiuyu Wu",
      "Yunfang Wu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.64": {
    "title": "Language Models Are Poor Learners of Directional Inference",
    "volume": "findings",
    "abstract": "We examine LMs' competence of directional predicate entailments by supervised fine-tuning with prompts. Our analysis shows that contrary to their apparent success on standard NLI, LMs show limited ability to learn such directional inference; moreover, existing datasets fail to test directionality, and/or are infested by artefacts that can be learnt as proxy for entailments, yielding over-optimistic results. In response, we present BoOQA (Boolean Open QA), a robust multi-lingual evaluation benchmark for directional predicate entailments, extrinsic to existing training sets. On BoOQA, we establish baselines and show evidence of existing LM-prompting models being incompetent directional entailment learners, in contrast to entailment graphs, however limited by sparsity",
    "checked": true,
    "id": "4fb7010a8af2012324bb45a3c281b2ebf8dc44a7",
    "semantic_title": "language models are poor learners of directional inference",
    "citation_count": 6,
    "authors": [
      "Tianyi Li",
      "Mohammad Javad Hosseini",
      "Sabine Weber",
      "Mark Steedman"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.65": {
    "title": "Wish I Can Feel What You Feel: A Neural Approach for Empathetic Response Generation",
    "volume": "findings",
    "abstract": "Expressing empathy is important in everyday conversations, and exploring how empathy arises is crucial in automatic response generation. Most previous approaches consider only a single factor that affects empathy. However, in practice, empathy generation and expression is a very complex and dynamic psychological process. A listener needs to find out events which cause a speaker's emotions (emotion cause extraction), project the events into some experience (knowledge extension), and express empathy in the most appropriate way (communication mechanism).To this end, we propose a novel approach, which integrates the three components - emotion cause, knowledge graph, and communication mechanism for empathetic response generation. Experimental results on the benchmark dataset demonstrate the effectiveness of our method and show that incorporating the key components generates more informative and empathetic responses",
    "checked": true,
    "id": "23144960a4fab87d7ebe260c252909428c27c3a9",
    "semantic_title": "wish i can feel what you feel: a neural approach for empathetic response generation",
    "citation_count": 2,
    "authors": [
      "Yangbin Chen",
      "Chunfeng Liang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.66": {
    "title": "Measuring and Improving Semantic Diversity of Dialogue Generation",
    "volume": "findings",
    "abstract": "Response diversity has become an important criterion for evaluating the quality of open-domain dialogue generation models. However, current evaluation metrics for response diversity often fail to capture the semantic diversity of generated responses, as they mainly consider lexical aspects of the generated responses. In this paper, we introduce a new automatic evaluation metric to measure the semantic diversity of generated responses. Through human evaluation, we demonstrate that our proposed metric captures human judgments on response diversity better than existing lexical-level diversity metrics. Furthermore, motivated by analyzing an existing dialogue dataset, we propose a simple yet effective learning method that improves the semantic diversity of generated responses. Our learning method weights training samples based on the semantic distribution of the training set. We show that our learning method improves response diversity and coherency better than other baseline methods through automatic and human evaluation",
    "checked": true,
    "id": "99313c8af01ac3662d11edd705ba80851eb44f0c",
    "semantic_title": "measuring and improving semantic diversity of dialogue generation",
    "citation_count": 8,
    "authors": [
      "Seungju Han",
      "Beomsu Kim",
      "Buru Chang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.67": {
    "title": "Plug-and-Play VQA: Zero-shot VQA by Conjoining Large Pretrained Models with Zero Training",
    "volume": "findings",
    "abstract": "Visual question answering (VQA) is a hallmark of vision and language reasoningand a challenging task under the zero-shot setting. We propose Plug-and-Play VQA (PNP-VQA),a modular framework for zero-shot VQA.In contrast to most existing works, which require substantial adaptation of pretrained language models (PLMs) for the vision modality,PNP-VQA requires no additional training of the PLMs.Instead, we propose to use natural language and network interpretation as an intermediate representation that glues pretrained models together. We first generate question-guided informative image captions,and pass the captions to a PLM as context for question answering. Surpassing end-to-end trained baselines, PNP-VQA achieves state-of-the-art results on zero-shot VQAv2 and GQA. With 11B parameters, it outperforms the 80B-parameter Flamingo model by 8.5% on VQAv2. With 738M PLM parameters, PNP-VQA achieves an improvement of 9.1% on GQA over FewVLM with 740M PLM parameters",
    "checked": true,
    "id": "26fd105d0b5a458979c012cddb3ba2de943388c4",
    "semantic_title": "plug-and-play vqa: zero-shot vqa by conjoining large pretrained models with zero training",
    "citation_count": 52,
    "authors": [
      "Anthony Meng Huat Tiong",
      "Junnan Li",
      "Boyang Li",
      "Silvio Savarese",
      "Steven C.H. Hoi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.68": {
    "title": "TSGP: Two-Stage Generative Prompting for Unsupervised Commonsense Question Answering",
    "volume": "findings",
    "abstract": "Without training on labeled task data, unsupervised commonsense question answering seems challenging since it requires commonsense knowledge beyond the context of questions. Previous methods typically retrieved from traditional knowledge bases or used pre-trained language models (PrLMs) to generate fixed types of knowledge, which have poor generalization ability. In this paper, we aim to address the above limitation by leveraging the implicit knowledge stored in PrLMs and propose a two-stage prompt-based unsupervised commonsense question answering framework (TSGP). We first use knowledge generation prompts to generate the knowledge required for questions with unlimited types and possible candidate answers independent of specified choices. Then, we further utilize answer generation prompts to generate possible candidate answers independent of specified choices. Experimental results and analysis on three different commonsense reasoning tasks, CommonsenseQA, OpenBookQA, and SocialIQA, demonstrate that TSGP significantly improves the reasoning ability of language models in unsupervised settings",
    "checked": true,
    "id": "f0400fa702aeed850fb389752f18462a7e7c3b01",
    "semantic_title": "tsgp: two-stage generative prompting for unsupervised commonsense question answering",
    "citation_count": 5,
    "authors": [
      "Yueqing Sun",
      "Yu Zhang",
      "Le Qi",
      "Qi Shi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.69": {
    "title": "Subword-Delimited Downsampling for Better Character-Level Translation",
    "volume": "findings",
    "abstract": "Subword-level models have been the dominant paradigm in NLP. However, character-level models have the benefit of seeing each character individually, providing the model with more detailed information that ultimately could lead to better models. Recent works have shown character-level models to be competitive with subword models, but costly in terms of time and computation. Character-level models with a downsampling component alleviate this, but at the cost of quality, particularly for machine translation. This work analyzes the problems of previous downsampling methods and introduces a novel downsampling method which is informed by subwords.This new downsampling method not only outperforms existing downsampling methods, showing that downsampling characters can be done without sacrificing quality, but also leads to promising performance compared to subword models for translation",
    "checked": true,
    "id": "ac7a19bc7dd06fd2b6501d3ff7098a29793d7da6",
    "semantic_title": "subword-delimited downsampling for better character-level translation",
    "citation_count": 5,
    "authors": [
      "Lukas Edman",
      "Antonio Toral",
      "Gertjan van Noord"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.70": {
    "title": "Autoregressive Structured Prediction with Language Models",
    "volume": "findings",
    "abstract": "Recent years have seen a paradigm shift in NLP towards using pretrained language models (PLM) for a wide range of tasks. However, there are many difficult design decisions to represent structures (e.g. tagged text, coreference chains) in a way such that they can be captured by PLMs. Prior work on structured prediction with PLMs typically flattens the structured output into a sequence, which limits the quality of structural information being learned and leads to inferior performance compared to classic discriminative models. In this work, we describe an approach to model structures as sequences of actions in an autoregressive manner with PLMs, allowing in-structure dependencies to be learned without any loss. Our approach achieves the new state-of-the-art on all the structured prediction tasks we looked at, namely, named entity recognition, end-to-end relation extraction, and coreference resolution",
    "checked": true,
    "id": "9fc461d7f3981fb7fa8ed74f072746903875b08d",
    "semantic_title": "autoregressive structured prediction with language models",
    "citation_count": 26,
    "authors": [
      "Tianyu Liu",
      "Yuchen Eleanor Jiang",
      "Nicholas Monath",
      "Ryan Cotterell",
      "Mrinmaya Sachan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.71": {
    "title": "XDoc: Unified Pre-training for Cross-Format Document Understanding",
    "volume": "findings",
    "abstract": "The surge of pre-training has witnessed the rapid development of document understanding recently. Pre-training and fine-tuning framework has been effectively used to tackle texts in various formats, including plain texts, document texts, and web texts. Despite achieving promising performance, existing pre-trained models usually target one specific document format at one time, making it difficult to combine knowledge from multiple document formats. To address this, we propose XDoc, a unified pre-trained model which deals with different document formats in a single model. For parameter efficiency, we share backbone parameters for different formats such as the word embedding layer and the Transformer layers. Meanwhile, we introduce adaptive layers with lightweight parameters to enhance the distinction across different formats. Experimental results have demonstrated that with only 36.7% parameters, XDoc achieves comparable or even better performance on a variety of downstream tasks compared with the individual pre-trained models, which is cost effective for real-world deployment. The code and pre-trained models are publicly available at https://aka.ms/xdoc",
    "checked": true,
    "id": "e5b03c3165d3a056dc55ce18835be04f5f817f4b",
    "semantic_title": "xdoc: unified pre-training for cross-format document understanding",
    "citation_count": 9,
    "authors": [
      "Jingye Chen",
      "Tengchao Lv",
      "Lei Cui",
      "Cha Zhang",
      "Furu Wei"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.72": {
    "title": "A Few More Examples May Be Worth Billions of Parameters",
    "volume": "findings",
    "abstract": "We investigate the dynamics of increasing the number of model parameters versus the number of labeled examples across a wide variety of tasks. Our exploration reveals that while scaling parameters consistently yields performance improvements, the contribution of additional examples highly depends on the task's format. Specifically, in open question answering tasks, enlarging the training set does not improve performance. In contrast, classification, extractive question answering, and multiple choice tasks benefit so much from additional examples that collecting a few hundred examples is often \"worth\" billions of parameters. We hypothesize that unlike open question answering, which involves recalling specific information, solving strategies for tasks with a more restricted output space transfer across examples, and can therefore be learned with small amounts of labeled data",
    "checked": true,
    "id": "20e5561e3e576fbc10b0e97f8f64d8c875e17ad7",
    "semantic_title": "a few more examples may be worth billions of parameters",
    "citation_count": 15,
    "authors": [
      "Yuval Kirstain",
      "Patrick Lewis",
      "Sebastian Riedel",
      "Omer Levy"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.73": {
    "title": "MCP: Self-supervised Pre-training for Personalized Chatbots with Multi-level Contrastive Sampling",
    "volume": "findings",
    "abstract": "Personalized chatbots focus on endowing the chatbots with a consistent personality to behave like real users and further act as personal assistants. Previous studies have explored generating implicit user profiles from the user's dialogue history for building personalized chatbots. However, these studies only use the response generation loss to train the entire model, thus it is prone to suffer from the problem of data sparsity. Besides, they overemphasize the final generated response's quality while ignoring the correlations and fusions between the user's dialogue history, leading to rough data representations and performance degradation. To tackle these problems, we propose a self-supervised learning framework MCP for capturing better representations from users' dialogue history for personalized chatbots. Specifically, we apply contrastive sampling methods to leverage the supervised signals hidden in user dialog history, and generate the pre-training samples for enhancing the model. We design three pre-training tasks based on three types of contrastive pairs from user dialogue history, namely response pairs, sequence augmentation pairs, and user pairs. We pre-train the utterance encoder and the history encoder towards the contrastive objectives and use these pre-trained encoders for generating user profiles while personalized response generation. Experimental results on two real-world datasets show a significant improvement in our proposed model MCP compared with the existing methods",
    "checked": true,
    "id": "50e405cf242bf603cf43df9df803f5265557bfe1",
    "semantic_title": "mcp: self-supervised pre-training for personalized chatbots with multi-level contrastive sampling",
    "citation_count": 2,
    "authors": [
      "Zhaoheng Huang",
      "Zhicheng Dou",
      "Yutao Zhu",
      "Zhengyi Ma"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.74": {
    "title": "ExpertPLM: Pre-training Expert Representation for Expert Finding",
    "volume": "findings",
    "abstract": "Expert Finding is an important task in Community Question Answering (CQA) platforms, which could help route questions to potential users to answer. The key is to learn representations of experts based on their historical answered questions accurately. In this paper, inspired by the strong text understanding ability of Pretrained Language modelings (PLMs), we propose a pre-training and fine-tuning expert finding framework. The core is that we design an expert-level pre-training paradigm, that effectively integrates expert interest and expertise simultaneously. Specifically different from the typical corpus-level pre-training, we treat each expert as the basic pre-training unit including all the historical answered question titles of the expert, which could fully indicate the expert interests for questions. Besides, we integrate the vote score information along with each answer of the expert into the pre-training phrase to model the expert ability explicitly. Finally, we propose a novel reputation-augmented Masked Language Model (MLM) pre-training strategy to capture the expert reputation information. In this way, our method could learn expert representation comprehensively, which then will be adopted and fine-tuned in the down-streaming expert-finding task. Extensive experimental results on six real-world CQA datasets demonstrate the effectiveness of our method",
    "checked": true,
    "id": "fb6e3222809626069b7c6744d8080c0b92b07c21",
    "semantic_title": "expertplm: pre-training expert representation for expert finding",
    "citation_count": 2,
    "authors": [
      "Qiyao Peng",
      "Hongtao Liu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.75": {
    "title": "You Truly Understand What I Need : Intellectual and Friendly Dialog Agents grounding Persona and Knowledge",
    "volume": "findings",
    "abstract": "To build a conversational agent that interacts fluently with humans, previous studies blend knowledge or personal profile into the pre-trained language model. However, the model that considers knowledge and persona at the same time is still limited, leading to hallucination and a passive way of using personas. We propose an effective dialogue agent that grounds external knowledge and persona simultaneously. The agent selects the proper knowledge and persona to use for generating the answers with our candidate scoring implemented with a poly-encoder. Then, our model generates the utterance with lesser hallucination and more engagingness utilizing retrieval augmented generation with knowledge-persona enhanced query. We conduct experiments on the persona-knowledge chat and achieve state-of-the-art performance in grounding and generation tasks on the automatic metrics. Moreover, we validate the answers from the models regarding hallucination and engagingness through human evaluation and qualitative results. We show our retriever's effectiveness in extracting relevant documents compared to the other previous retrievers, along with the comparison of multiple candidate scoring methods. Code is available at https://github.com/dlawjddn803/INFO",
    "checked": true,
    "id": "5cb8bcf87567a286364c16402885ed2f5dcdd1f8",
    "semantic_title": "you truly understand what i need : intellectual and friendly dialog agents grounding persona and knowledge",
    "citation_count": 3,
    "authors": [
      "Jungwoo Lim",
      "Myugnhoon Kang",
      "Yuna Hur",
      "Seung Won Jeong",
      "Jinsung Kim",
      "Yoonna Jang",
      "Dongyub Lee",
      "Hyesung Ji",
      "DongHoon Shin",
      "Seungryong Kim",
      "Heuiseok Lim"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.76": {
    "title": "Faithful to the Document or to the World? Mitigating Hallucinations via Entity-Linked Knowledge in Abstractive Summarization",
    "volume": "findings",
    "abstract": "Existing abstractive summarization systems are hampered by content hallucinations in which models generate text that is not directly inferable from the source alone. Annotations from prior work have shown that some of these hallucinations, while being ‘unfaithful' to the source, are nonetheless factual. Our analysis in this paper suggests that these factual hallucinations occur as a result of the prevalence of factual yet unfaithful entities in summarization datasets. We find that these entities are not aberrations, but instead examples of additional world knowledge being readily used to latently connect entities and concepts – in this case connecting entities in the source document to those in the target summary. In our analysis and experiments, we demonstrate that connecting entities to an external knowledge base can lend provenance to many of these unfaithful yet factual entities, and further, this knowledge can be used to improve the factuality of summaries without simply making them more extractive",
    "checked": true,
    "id": "ae1e48a74cb2f313e8e99c82f0aa4487b0805002",
    "semantic_title": "faithful to the document or to the world? mitigating hallucinations via entity-linked knowledge in abstractive summarization",
    "citation_count": 15,
    "authors": [
      "Yue Dong",
      "John Wieting",
      "Pat Verga"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.77": {
    "title": "RL with KL penalties is better viewed as Bayesian inference",
    "volume": "findings",
    "abstract": "Reinforcement learning (RL) is frequently employed in fine-tuning large language models (LMs), such as GPT-3, to penalize them for undesirable features of generated sequences, such as offensiveness, social bias, harmfulness or falsehood. The RL formulation involves treating the LM as a policy and updating it to maximise the expected value of a reward function which captures human preferences, such as non-offensiveness. In this paper, we analyze challenges associated with treating a language model as an RL policy and show how avoiding those challenges requires moving beyond the RL paradigm. We start by observing that the standard RL approach is flawed as an objective for fine-tuning LMs because it leads to distribution collapse: turning the LM into a degenerate distribution. Then, we analyze KL-regularised RL, a widely used recipe for fine-tuning LMs, which additionally constrains the fine-tuned LM to stay close to its original distribution in terms of Kullback-Leibler (KL) divergence. We show that KL-regularised RL is equivalent to variational inference: approximating a Bayesian posterior which specifies how to update a prior LM to conform with evidence provided by the reward function. We argue that this Bayesian inference view of KL-regularised RL is more insightful than the typically employed RL perspective. The Bayesian inference view explains how KL-regularised RL avoids the distribution collapse problem and offers a first-principles derivation for its objective. While this objective happens to be equivalent to RL (with a particular choice of parametric reward), there exist other objectives for fine-tuning LMs which are no longer equivalent to RL. That observation leads to a more general point: RL is not an adequate formal framework for problems such as fine-tuning language models. These problems are best viewed as Bayesian inference: approximating a pre-defined target distribution",
    "checked": true,
    "id": "cf18a9f5a334e574f1d1f6ffdd64b6dac11fe9be",
    "semantic_title": "rl with kl penalties is better viewed as bayesian inference",
    "citation_count": 31,
    "authors": [
      "Tomasz Korbak",
      "Ethan Perez",
      "Christopher Buckley"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.78": {
    "title": "Evaluating Token-Level and Passage-Level Dense Retrieval Models for Math Information Retrieval",
    "volume": "findings",
    "abstract": "With the recent success of dense retrieval methods based on bi-encoders, studies have applied this approach to various interesting downstream retrieval tasks with good efficiency and in-domain effectiveness. Recently, we have also seen the presence of dense retrieval models in Math Information Retrieval (MIR) tasks,but the most effective systems remain classic retrieval methods that consider hand-crafted structure features. In this work, we try to combine the best of both worlds: a well-defined structure search method for effective formula search and efficient bi-encoder dense retrieval models to capture contextual similarities. Specifically, we have evaluated two representative bi-encoder models for token-level and passage-level dense retrieval on recent MIR tasks. Our results show that bi-encoder models are highly complementary to existing structure search methods, and we are able to advance the state-of-the-art on MIR datasets",
    "checked": true,
    "id": "859cbed6555319c3c31b84c1001a1df9a34889e2",
    "semantic_title": "evaluating token-level and passage-level dense retrieval models for math information retrieval",
    "citation_count": 13,
    "authors": [
      "Wei Zhong",
      "Jheng-Hong Yang",
      "Yuqing Xie",
      "Jimmy Lin"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.79": {
    "title": "Multi-View Reasoning: Consistent Contrastive Learning for Math Word Problem",
    "volume": "findings",
    "abstract": "Math word problem solver requires both precise relation reasoning about quantities in the text and reliable generation for the diverse equation. Current sequence-to-tree or relation extraction methods regard this only from a fixed view, struggling to simultaneously handle complex semantics and diverse equations. However, human solving naturally involves two consistent reasoning views: top-down and bottom-up, just as math equations also can be expressed in multiple equivalent forms: pre-order and post-order. We propose a multi-view consistent contrastive learning for a more complete semantics-to-equation mapping. The entire process is decoupled into two independent but consistent views: top-down decomposition and bottom-up construction, and the two reasoning views are aligned in multi-granularity for consistency, enhancing global generation and precise reasoning. Experiments on multiple datasets across two languages show our approach significantly outperforms the existing baselines, especially on complex problems. We also show after consistent alignment, multi-view can absorb the merits of both views and generate more diverse results consistent with the mathematical laws",
    "checked": true,
    "id": "b23a8493f384a52adf22d3c70c5827fd1a6ca42d",
    "semantic_title": "multi-view reasoning: consistent contrastive learning for math word problem",
    "citation_count": 7,
    "authors": [
      "Wenqi Zhang",
      "Yongliang Shen",
      "Yanna Ma",
      "Xiaoxia Cheng",
      "Zeqi Tan",
      "Qingpeng Nong",
      "Weiming Lu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.80": {
    "title": "Few-shot initializing of Active Learner via Meta-Learning",
    "volume": "findings",
    "abstract": "Despite the important evolutions in few-shot and zero-shot learning techniques, domain specific applications still require expert knowledge and significant effort in annotating and labeling a large volume of unstructured textual data. To mitigate this problem, active learning, and meta-learning attempt to reach a high performance with the least amount of labeled data. In this paper, we introduce a novel approach to combine both lines of work by initializing an active learner with meta-learned parameters obtained through meta-training on tasks similar to the target task during active learning. In this approach we use the pre-trained BERT as our text-encoder and meta-learn its parameters with LEOPARD, which extends the model-agnostic meta-learning method by generating task dependent softmax weights to enable learning across tasks with different number of classes. We demonstrate the effectiveness of our method by performing active learning on five natural language understanding tasks and six datasets with five different acquisition functions. We train two different meta-initializations, and we use the pre-trained BERT base initialization as baseline. We observe that our approach performs better than the baseline at low budget, especially when closely related tasks were present during meta-learning. Moreover, our results show that better performance in the initial phase, i.e., with fewer labeled samples, leads to better performance when larger acquisition batches are used. We also perform an ablation study of the proposed method, showing that active learning with only the meta-learned weights is beneficial and adding the meta-learned learning rates and generating the softmax have negative consequences for the performance",
    "checked": true,
    "id": "9dfad969304fa75ff8e612e9f051e1795ef22f66",
    "semantic_title": "few-shot initializing of active learner via meta-learning",
    "citation_count": 1,
    "authors": [
      "Zi Long Zhu",
      "Vikrant Yadav",
      "Zubair Afzal",
      "George Tsatsaronis"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.81": {
    "title": "Bootstrapping meaning through listening: Unsupervised learning of spoken sentence embeddings",
    "volume": "findings",
    "abstract": "Inducing semantic representations directly from speech signals is a highly challenging task but has many useful applications in speech mining and spoken language understanding. This study tackles the unsupervised learning of semantic representations for spoken utterances. Through converting speech signals into hidden units generated from acoustic unit discovery, we propose WavEmbed, a multimodal sequential autoencoder that predicts hidden units from a dense representation of speech. Secondly, we also propose S-HuBERT to induce meaning through knowledge distillation, in which a sentence embedding model is first trained on hidden units and passes its knowledge to a speech encoder through contrastive learning. The best performing model achieves a moderate correlation (0.5 0.6) with human judgments, without relying on any labels or transcriptions. Furthermore, these models can also be easily extended to leverage textual transcriptions of speech to learn much better speech embeddings that are strongly correlated with human annotations. Our proposed methods are applicable to the development of purely data-driven systems for speech mining, indexing and search",
    "checked": true,
    "id": "afcdfdcd3fc9d65470e18269acc5b49399c80e0f",
    "semantic_title": "bootstrapping meaning through listening: unsupervised learning of spoken sentence embeddings",
    "citation_count": 2,
    "authors": [
      "Jian Zhu",
      "Zuoyu Tian",
      "Yadong Liu",
      "Cong Zhang",
      "Chia-Wen Lo"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.82": {
    "title": "Progressive Sentiment Analysis for Code-Switched Text Data",
    "volume": "findings",
    "abstract": "Multilingual transformer language models have recently attracted much attention from researchers and are used in cross-lingual transfer learning for many NLP tasks such as text classification and named entity recognition. However, similar methods for transfer learning from monolingual text to code-switched text have not been extensively explored mainly due to the following challenges:(1) Code-switched corpus, unlike monolingual corpus, consists of more than one language and existing methods can't be applied efficiently,(2) Code-switched corpus is usually made of resource-rich and low-resource languages and upon using multilingual pre-trained language models, the final model might bias towards resource-rich language. In this paper, we focus on code-switched sentiment analysis where we have a labelled resource-rich language dataset and unlabelled code-switched data. We propose a framework that takes the distinction between resource-rich and low-resource language into account. Instead of training on the entire code-switched corpus at once, we create buckets based on the fraction of words in the resource-rich language and progressively train from resource-rich language dominated samples to low-resource language dominated samples. Extensive experiments across multiple language pairs demonstrate that progressive training helps low-resource language dominated samples",
    "checked": true,
    "id": "dd2fd1c27673eade4bc00bb857ab22477cf15c86",
    "semantic_title": "progressive sentiment analysis for code-switched text data",
    "citation_count": 0,
    "authors": [
      "Sudhanshu Ranjan",
      "Dheeraj Mekala",
      "Jingbo Shang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.83": {
    "title": "Knowledge Stimulated Contrastive Prompting for Low-Resource Stance Detection",
    "volume": "findings",
    "abstract": "Stance Detection Task (SDT) aims at identifying the stance of the sentence towards a specific target and is usually modeled as a classification problem. Backgound knowledge is often necessary for stance detection with respect to a specific target, especially when there is no target explicitly mentioned in text. This paper focuses on the knowledge stimulation for low-resource stance detection tasks. We firstly explore to formalize stance detection as a prompt based contrastive learning task. At the same time, to make prompt learning suit to stance detection, we design a template mechanism to incorporate corresponding target into instance representation. Furthermore, we propose a masked language prompt joint contrastive learning approach to stimulate the knowledge inherit from the pre-trained model. The experimental results on three benchmarks show that knowledge stimulation is effective in stance detection accompanied with our proposed mechanism",
    "checked": true,
    "id": "2ee496b125987f48fea5941b65a8d91f8572915f",
    "semantic_title": "knowledge stimulated contrastive prompting for low-resource stance detection",
    "citation_count": 4,
    "authors": [
      "Kai Zheng",
      "Qingfeng Sun",
      "Yaming Yang",
      "Fei Xu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.84": {
    "title": "WSpeller: Robust Word Segmentation for Enhancing Chinese Spelling Check",
    "volume": "findings",
    "abstract": "Chinese spelling check (CSC) detects and corrects spelling errors in Chinese texts. Previous approaches have combined character-level phonetic and graphic information, ignoring the importance of segment-level information. According to our pilot study, spelling errors are always associated with incorrect word segmentation. When appropriate word boundaries are provided, CSC performance is greatly enhanced. Based on these findings, we present WSpeller, a CSC model that takes into account word segmentation. A fundamental component of WSpeller is a W-MLM, which is trained by predicting visually and phonetically similar words. Through modification of the embedding layer's input, word segmentation information can be incorporated. Additionally, a robust module is trained to assist the W-MLM-based correction module by predicting the correct word segmentations from sentences containing spelling errors. We evaluate WSpeller on the widely used benchmark datasets SIGHAN13, SIGHAN14, and SIGHAN15. Our model is superior to state-of-the-art baselines on SIGHAN13 and SIGHAN15 and maintains equal performance on SIGHAN14",
    "checked": true,
    "id": "c78eb5f9bfb7597d9927b08f90a454f7700d919f",
    "semantic_title": "wspeller: robust word segmentation for enhancing chinese spelling check",
    "citation_count": 2,
    "authors": [
      "Fangfang Li",
      "Youran Shan",
      "Junwen Duan",
      "Xingliang Mao",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.85": {
    "title": "Extracting Trigger-sharing Events via an Event Matrix",
    "volume": "findings",
    "abstract": "A growing interest emerges in event extraction which aims to extract multiple events with triggers and arguments. Previous methods mitigate the problem of multiple events extraction by predicting the arguments conditioned on the event trigger and event type, assuming that these arguments belong to a single event. However, the assumption is invalid in general as there may be multiple events. Therefore, we present a unified framework called MatEE for trigger-sharing events extraction. It resolves the kernel bottleneck by effectively modeling the relations between arguments by an event matrix, where trigger-sharing events are represented by multiple cliques. We verify the proposed method on 3 widely-used benchmark datasets of event extraction. The experimental results show that it beats all the advanced competitors, significantly improving the state-of-the-art performances in event extraction",
    "checked": true,
    "id": "da2015316f2e456a934001aa08510a2de4f515e5",
    "semantic_title": "extracting trigger-sharing events via an event matrix",
    "citation_count": 2,
    "authors": [
      "Jun Xu",
      "Weidi Xu",
      "Mengshu Sun",
      "Taifeng Wang",
      "Wei Chu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.86": {
    "title": "TranS: Transition-based Knowledge Graph Embedding with Synthetic Relation Representation",
    "volume": "findings",
    "abstract": "Knowledge graph embedding (KGE) aims to learn continuous vector representations of relations and entities in knowledge graph (KG). Recently, transition-based KGE methods have become popular and achieved promising performance. However, scoring patterns like TransE are not suitable for complex scenarios where the same entity pair has different relations. Although some models attempt to employ entity-relation interaction or projection to improve entity representation for one-to-many/many-to-one/many-to-many complex relations, they still continue the traditional scoring pattern, where only a single relation vector in the relation part is used to translate the head entity to the tail entity or their variants. And recent research shows that entity representation only needs to consider entities and their interactions to achieve better performance. Thus, in this paper, we propose a novel transition-based method, TranS, for KGE. The single relation vector of the relation part in the traditional scoring pattern is replaced by the synthetic relation representation with entity-relation interactions to solve these issues. And the entity part still retains its independence through entity-entity interactions. Experiments on a large KG dataset, ogbl-wikikg2, show that our model achieves state-of-the-art results",
    "checked": true,
    "id": "b2d2ad9a458bdcb0523d22be659eb013ca2d3c67",
    "semantic_title": "trans: transition-based knowledge graph embedding with synthetic relation representation",
    "citation_count": 8,
    "authors": [
      "Xuanyu Zhang",
      "Qing Yang",
      "Dongliang Xu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.87": {
    "title": "Sequential Topic Selection Model with Latent Variable for Topic-Grounded Dialogue",
    "volume": "findings",
    "abstract": "Recently, topic-grounded dialogue system has attracted significant attention due to its effectiveness in predicting the next topic to yield better responses via the historical context and given topic sequence. However, almost all existing topic prediction solutions focus on only the current conversation and corresponding topic sequence to predict the next conversation topic, without exploiting other topic-guided conversations which may contain relevant topic-transitions to current conversation. To address the problem, in this paper we propose a novel approach, named Sequential Global Topic Attention (SGTA) to exploit topic transition over all conversations in a subtle way for better modeling post-to-response topic-transition and guiding the response generation to the current conversation. Specifically, we introduce a latent space modeled as a Multivariate Skew-Normal distribution with hybrid kernel functions to flexibly integrate the global-level information with sequence-level information, and predict the topic based on the distribution sampling results. We also leverage a topic-aware prior-posterior approach for secondary selection of predicted topics, which is utilized to optimize the response generation task. Extensive experiments demonstrate that our model outperforms competitive baselines on prediction and generation tasks",
    "checked": true,
    "id": "2cd38749aad5da8ba98c3fa21944d99609f00491",
    "semantic_title": "sequential topic selection model with latent variable for topic-grounded dialogue",
    "citation_count": 0,
    "authors": [
      "Xiao-Fei Wen",
      "Wei Wei",
      "Xian-Ling Mao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.88": {
    "title": "Robust Task-Oriented Dialogue Generation with Contrastive Pre-training and Adversarial Filtering",
    "volume": "findings",
    "abstract": "Data artifacts incentivize machine learning models to learn non-transferable generalizations by taking advantage of shortcuts in the data, andthere is growing evidence that data artifacts play a role for the strong results that deep learning models achieve in recent natural language processing benchmarks. In this paper, we focus on task-oriented dialogue and investigate whether popular datasets such as MultiWOZ contain such data artifacts. We found that by only keeping frequent phrases in the trainingexamples, state-of-the-art models perform similarly compared to the variant trained with full data, suggesting they exploit these spurious correlationsto solve the task. Motivated by this, we propose a contrastive learning based framework to encourage the model to ignore these cues and focus on learning generalisable patterns. We also experiment with adversarial filtering to remove easy training instances so that the model would focus on learning from the harder instances. We conduct a number of generalization experiments — e.g., cross-domain/dataset and adversarial tests — to assess the robustness of our approach and found that it works exceptionally well",
    "checked": true,
    "id": "58e132f2c0d624d2faec4a1a06302d1dc550fe0b",
    "semantic_title": "robust task-oriented dialogue generation with contrastive pre-training and adversarial filtering",
    "citation_count": 3,
    "authors": [
      "Shiquan Yang",
      "Xinting Huang",
      "Jey Han Lau",
      "Sarah Erfani"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.89": {
    "title": "STAR: SQL Guided Pre-Training for Context-dependent Text-to-SQL Parsing",
    "volume": "findings",
    "abstract": "In this paper, we propose a novel SQL guided pre-training framework STAR for context-dependent text-to-SQL parsing, which leverages contextual information to enrich natural language (NL) utterance and table schema representations for text-to-SQL conversations. Concretely, we propose two novel pre-training objectives which respectively explore the context-dependent interactions of NL utterances and SQL queries within each text-to-SQL conversation: (i) schema state tracking (SST) objective that tracks and explores the schema states of context-dependent SQL queries in the form of schema-states by predicting and updating the value of each schema slot during interaction; (ii) utterance dependency tracking (UDT) objective that employs weighted contrastive learning to pull together two semantically similar NL utterances and push away the representations of semantically dissimilar NL utterances within each conversation. In addition, we construct a high-quality large-scale context-dependent text-to-SQL conversation corpus to pre-train STAR. Extensive experiments show that STAR achieves new state-of-the-art performance on two downstream benchmarks (SParC and CoSQL), significantly outperforming previous pre-training methods and ranking first on the leaderboard. We believe the release of the constructed corpus, codebase and pre-trained STAR checkpoints would push forward the research in this area",
    "checked": true,
    "id": "6156d4258eba0fffad1c6a688963ed6e4de0c6af",
    "semantic_title": "star: sql guided pre-training for context-dependent text-to-sql parsing",
    "citation_count": 14,
    "authors": [
      "Zefeng Cai",
      "Xiangyu Li",
      "Binyuan Hui",
      "Min Yang",
      "Bowen Li",
      "Binhua Li",
      "Zheng Cao",
      "Weijie Li",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.90": {
    "title": "Is MultiWOZ a Solved Task? An Interactive TOD Evaluation Framework with User Simulator",
    "volume": "findings",
    "abstract": "Task-Oriented Dialogue (TOD) systems are drawing more and more attention in recent studies. Current methods focus on constructing pre-trained models or fine-tuning strategies while the evaluation of TOD is limited by a policy mismatch problem. That is, during evaluation, the user utterances are from the annotated dataset while these utterances should interact with previous responses which can have many alternatives besides annotated texts. Therefore, in this work, we propose an interactive evaluation framework for TOD. We first build a goal-oriented user simulator based on pre-trained models and then use the user simulator to interact with the dialogue system to generate dialogues. Besides, we introduce a sentence-level and a session-level score to measure the sentence fluency and session coherence in the interactive evaluation. Experimental results show that RL-based TOD systems trained by our proposed user simulator can achieve nearly 98% inform and success rates in the interactive evaluation of MultiWOZ dataset and the proposed scores measure the response quality besides the inform and success rates. We are hoping that our work will encourage simulator-based interactive evaluations in the TOD task",
    "checked": true,
    "id": "da83d8c19b1716b7a17eab9f675a5bdbe4518db5",
    "semantic_title": "is multiwoz a solved task? an interactive tod evaluation framework with user simulator",
    "citation_count": 7,
    "authors": [
      "Qinyuan Cheng",
      "Linyang Li",
      "Guofeng Quan",
      "Feng Gao",
      "Xiaofeng Mou",
      "Xipeng Qiu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.91": {
    "title": "Translating Hanja Historical Documents to Contemporary Korean and English",
    "volume": "findings",
    "abstract": "The Annals of Joseon Dynasty (AJD) contain the daily records of the Kings of Joseon, the 500-year kingdom preceding the modern nation of Korea.The Annals were originally written in an archaic Korean writing system, ‘Hanja', and were translated into Korean from 1968 to 1993.The resulting translation was however too literal and contained many archaic Korean words; thus, a new expert translation effort began in 2012. Since then, the records of only one king have been completed in a decade. In parallel, expert translators are working on English translation, also at a slow pace and produced only one king's records in English so far. Thus, we propose H2KE, a neural machine translation model, that translates historical documents in Hanja to more easily understandable Korean and to English.Built on top of multilingual neural machine translation, H2KE learns to translate a historical document written in Hanja, from both a full dataset of outdated Korean translation and a small dataset of more recently translated contemporary Korean and English.We compare our method against two baselines:a recent model that simultaneously learns to restore and translate Hanja historical documentand a Transformer based model trained only on newly translated corpora. The experiments reveal that our method significantly outperforms the baselines in terms of BLEU scores for both contemporary Korean and English translations. We further conduct extensive human evaluation which shows that our translation is preferred over the original expert translations by both experts and non-expert Korean speakers",
    "checked": true,
    "id": "934d64405a4f736a8676c64cf9fc96014b9d7a62",
    "semantic_title": "translating hanja historical documents to contemporary korean and english",
    "citation_count": 2,
    "authors": [
      "Juhee Son",
      "Jiho Jin",
      "Haneul Yoo",
      "JinYeong Bak",
      "Kyunghyun Cho",
      "Alice Oh"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.92": {
    "title": "Exploring Compositional Image Retrieval with Hybrid Compositional Learning and Heuristic Negative Mining",
    "volume": "findings",
    "abstract": "Compositional image retrieval (CIR) is a challenging retrieval task, where the query is composed of a reference image and a modification text, and the target is another image reflecting the modification to the reference image. Due to the great success of the pre-trained vision-and-language model CLIP and its favorable applicability to large-scale retrieval tasks, we propose a CIR model HyCoLe-HNM with CLIP as the backbone. In HyCoLe-HNM, we follow the contrastive pre-training method of CLIP to perform cross-modal representation learning. On this basis, we propose a hybrid compositional learning mechanism, which includes both image compositional learning and text compositional learning. In hybrid compositional learning, we borrow a gated fusion mechanism from a question answering model to perform compositional fusion, and propose a heuristic negative mining method to filter negative samples. Privileged information in the form of image-related texts is utilized in cross-modal representation learning and hybrid compositional learning. Experimental results show that HyCoLe-HNM achieves state-of-the-art performance on three CIR datasets, namely FashionIQ, Fashion200K, and MIT-States",
    "checked": true,
    "id": "aa76ba9225a5145d420f87432b08261928b7d434",
    "semantic_title": "exploring compositional image retrieval with hybrid compositional learning and heuristic negative mining",
    "citation_count": 2,
    "authors": [
      "Chao Wang",
      "Ehsan Nezhadarya",
      "Tanmana Sadhu",
      "Shengdong Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.93": {
    "title": "Outlier Dimensions that Disrupt Transformers are Driven by Frequency",
    "volume": "findings",
    "abstract": "While Transformer-based language models are generally very robust to pruning, there is the recently discovered outlier phenomenon: disabling only 48 out of 110M parameters in BERT-base drops its performance by nearly 30% on MNLI. We replicate the original evidence for the outlier phenomenon and we link it to the geometry of the embedding space. We find that in both BERT and RoBERTa the magnitude of hidden state coefficients corresponding to outlier dimensions correlate with the frequencies of encoded tokens in pre-training data, and they also contribute to the \"vertical\" self-attention pattern enabling the model to focus on the special tokens. This explains the drop in performance from disabling the outliers, and it suggests that to decrease anisotopicity in future models we need pre-training schemas that would better take into account the skewed token distributions",
    "checked": true,
    "id": "09171a3f87fcb94456eaabefc65731683374f983",
    "semantic_title": "outliers dimensions that disrupt transformers are driven by frequency",
    "citation_count": 18,
    "authors": [
      "Giovanni Puccetti",
      "Anna Rogers",
      "Aleksandr Drozd",
      "Felice Dell’Orletta"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.94": {
    "title": "MiST: a Large-Scale Annotated Resource and Neural Models for Functions of Modal Verbs in English Scientific Text",
    "volume": "findings",
    "abstract": "Modal verbs (e.g., can, should or must) occur highly frequently in scientific articles. Decoding their function is not straightforward: they are often used for hedging, but they may also denote abilities and restrictions. Understanding their meaning is important for accurate information extraction from scientific text. To foster research on the usage of modals in this genre, we introduce the MIST (Modals In Scientific Text) dataset, which contains 3737 modal instances in five scientific domains annotated for their semantic, pragmatic, or rhetorical function. We systematically evaluate a set of competitive neural architectures on MIST. Transfer experiments reveal that leveraging non-scientific data is of limited benefit for modeling the distinctions in MIST. Our corpus analysis provides evidence that scientific communities differ in their usage of modal verbs, yet, classifiers trained on scientific data generalize to some extent to unseen scientific domains",
    "checked": true,
    "id": "e69d408e4ce06f4315a982fb5d9315b01c87a716",
    "semantic_title": "mist: a large-scale annotated resource and neural models for functions of modal verbs in english scientific text",
    "citation_count": 0,
    "authors": [
      "Sophie Henning",
      "Nicole Macher",
      "Stefan Grünewald",
      "Annemarie Friedrich"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.95": {
    "title": "Late Prompt Tuning: A Late Prompt Could Be Better Than Many Prompts",
    "volume": "findings",
    "abstract": "Prompt tuning is a parameter-efficient tuning (PETuning) method for utilizing pre-trained models (PTMs) that simply prepends a soft prompt to the input and only optimizes the prompt to adapt PTMs to downstream tasks. Although it is parameter- and deployment-efficient, its performance still lags behind other state-of-the-art PETuning methods. Besides, the training cost of prompt tuning is not significantly reduced due to the back-propagation through the entire model. Through empirical analyses, we shed some light on the lagging performance of prompt tuning and recognize a trade-off between the propagation distance from label signals to the inserted prompt and the influence of the prompt on model outputs. Further, we present Late Prompt Tuning (LPT) that inserts a late prompt into an intermediate layer of the PTM instead of the input layer or all layers. The late prompt is obtained by a neural prompt generator conditioned on the hidden states before the prompt insertion layer and therefore is instance-dependent. Through extensive experimental results across various tasks and PTMs, we show that LPT can achieve competitive performance to full model tuning and other PETuning methods under both full-data and few-shot scenarios while possessing faster training speed and lower memory cost",
    "checked": true,
    "id": "a981a57848e19adb80c4a29471fbb798ac050a8f",
    "semantic_title": "late prompt tuning: a late prompt could be better than many prompts",
    "citation_count": 12,
    "authors": [
      "Xiangyang Liu",
      "Tianxiang Sun",
      "Xuanjing Huang",
      "Xipeng Qiu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.96": {
    "title": "MICO: A Multi-alternative Contrastive Learning Framework for Commonsense Knowledge Representation",
    "volume": "findings",
    "abstract": "Commonsense reasoning tasks such as commonsense knowledge graph completion and commonsense question answering require powerful representation learning. In this paper, we propose to learn commonsense knowledge representation by MICO, a Multi-alternative contrastIve learning framework on COmmonsense knowledge graphs (MICO). MICO generates the commonsense knowledge representation by contextual interaction between entity nodes and relations with multi-alternative contrastive learning. In MICO, the head and tail entities in an (h,r,t) knowledge triple are converted to two relation-aware sequence pairs (a premise and an alternative) in the form of natural language. Semantic representations generated by MICO can benefit the following two tasks by simply comparing the similarity score between the representations: 1) zero-shot commonsense question answering tasks; 2) inductive commonsense knowledge graph completion tasks. Extensive experiments show the effectiveness of our method",
    "checked": true,
    "id": "480e667c50eb71ba78bfde47e4686ca7b21148bd",
    "semantic_title": "mico: a multi-alternative contrastive learning framework for commonsense knowledge representation",
    "citation_count": 10,
    "authors": [
      "Ying Su",
      "Zihao Wang",
      "Tianqing Fang",
      "Hongming Zhang",
      "Yangqiu Song",
      "Tong Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.97": {
    "title": "Leveraging Only the Category Name for Aspect Detection through Prompt-based Constrained Clustering",
    "volume": "findings",
    "abstract": "Aspect category detection (ACD) aims to automatically identify user-concerned aspects from online reviews, which is of great value for evaluating the fine-grained performance of a product. The most recent solutions tackle this problem via weakly supervised methods, achieving remarkable improvement over unsupervised methods. However, a closer look at these methods reveals that the required human efforts are nontrivial and can sometimes be hard to obtain. In this study, we explore the possibility of minimizing human guidance while improving detection performance, with a deep clustering method that relies merely on the category name of each aspect and a pretrained language model (LM). The LM, combined with prompt techniques, is employed as a knowledge base to automatically generate constraints for clustering, as well as to provide a representation space to perform the clustering. Our method (1) extracts extensive keywords to expand our understanding of each aspect, (2) automatically generates instance-level and concept-level constraints for clustering, and (3) trains the clustering model with the above constraints. We demonstrate the capability of the proposed framework through extensive experiments on nine benchmark datasets. Our model not only performs noticeably better than existing unsupervised approaches but also considerably surpasses weakly supervised methods that require more human efforts",
    "checked": true,
    "id": "0234e3c2b3a8bcb0dadd3d5d3b572120a7886eb0",
    "semantic_title": "leveraging only the category name for aspect detection through prompt-based constrained clustering",
    "citation_count": 1,
    "authors": [
      "Yazheng Li",
      "Pengyun Wang",
      "Yasheng Wang",
      "Yong Dai",
      "Yadao Wang",
      "Lujia Pan",
      "Zenglin Xu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.98": {
    "title": "Controllable Factuality in Document-Grounded Dialog Systems Using a Noisy Channel Model",
    "volume": "findings",
    "abstract": "In this work, we present a model for document-grounded response generation in dialog that is decomposed into two components according to Bayes' theorem. One component is a traditional ungrounded response generation model and the other component models the reconstruction of the grounding document based on the dialog context and generated response. We propose different approximate decoding schemes and evaluate our approach on multiple open-domain and task-oriented document-grounded dialog datasets. Our experiments show that the model is more factual in terms of automatic factuality metrics than the baseline model. Furthermore, we outline how introducing scaling factors between the components allows for controlling the tradeoff between factuality and fluency in the model output. Finally, we compare our approach to a recently proposed method to control factuality in grounded dialog, CTRL (Rashkin et al., 2021), and show that both approaches can be combined to achieve additional improvements",
    "checked": true,
    "id": "10be7057efd37643a6aaf277ba4bfd8ab2a35775",
    "semantic_title": "controllable factuality in document-grounded dialog systems using a noisy channel model",
    "citation_count": 3,
    "authors": [
      "Nico Daheim",
      "David Thulke",
      "Christian Dugast",
      "Hermann Ney"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.99": {
    "title": "Transformer Language Models without Positional Encodings Still Learn Positional Information",
    "volume": "findings",
    "abstract": "Causal transformer language models (LMs), such as GPT-3, typically require some form of positional encoding, such as positional embeddings. However, we show that LMs without any explicit positional encoding are still competitive with standard models and that this phenomenon is robust across different datasets, model sizes, and sequence lengths. Probing experiments reveal that such models acquire an implicit notion of absolute positions throughout the network, effectively compensating for the missing information. We conjecture that causal attention enables the model to infer the number of predecessors that each token can attend to, thereby approximating its absolute position. Our findings indicate that causal LMs might derive positional awareness not only from the explicit positioning mechanism but also from the effects of the causal mask",
    "checked": true,
    "id": "a2fc77f075f666b462d9350e7576f0ba9845c61b",
    "semantic_title": "transformer language models without positional encodings still learn positional information",
    "citation_count": 49,
    "authors": [
      "Adi Haviv",
      "Ori Ram",
      "Ofir Press",
      "Peter Izsak",
      "Omer Levy"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.100": {
    "title": "Beyond Model Interpretability: On the Faithfulness and Adversarial Robustness of Contrastive Textual Explanations",
    "volume": "findings",
    "abstract": "Contrastive explanation methods go beyond transparency and address the contrastive aspect of explanations. Such explanations are emerging as an attractive option to provide actionable change to scenarios adversely impacted by classifiers' decisions. However, their extension to textual data is under-explored and there is little investigation on their vulnerabilities and limitations. This work motivates textual counterfactuals by highlighting the social limitations of non-contrastive explainability. We also lay the ground for a novel evaluation scheme inspired by the faithfulness of explanations. Accordingly, we extend the computation of three metrics, proximity, connectedness and stability, to textual data and we benchmark two successful contrastive methods, POLYJUICE and MiCE, on our suggested metrics. Experiments on sentiment analysis data show that the connectedness of counterfactuals to their original counterparts is not obvious in both models. More interestingly, the generated contrastive texts are more attainable with POLYJUICE which highlights the significance of latent representations in counterfactual search. Finally, we perform the first semantic adversarial attack on textual recourse methods. The results demonstrate the robustness of POLYJUICE and the role that latent input representations play in robustness and reliability",
    "checked": true,
    "id": "3426e5413932631e5260490ce686ebf303a961e4",
    "semantic_title": "beyond model interpretability: on the faithfulness and adversarial robustness of contrastive textual explanations",
    "citation_count": 0,
    "authors": [
      "Julia El Zini",
      "Mariette Awad"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.101": {
    "title": "How Much Does Attention Actually Attend? Questioning the Importance of Attention in Pretrained Transformers",
    "volume": "findings",
    "abstract": "The attention mechanism is considered the backbone of the widely-used Transformer architecture. It contextualizes the input by computing input-specific attention matrices. We find that this mechanism, while powerful and elegant, is not as important as typically thought for pretrained language models. We introduce PAPA, a new probing method that replaces the input-dependent attention matrices with constant ones—the average attention weights over multiple inputs. We use PAPA to analyze several established pretrained Transformers on six downstream tasks. We find that without any input-dependent attention, all models achieve competitive performance—an average relative drop of only 8% from the probing baseline. Further, little or no performance drop is observed when replacing half of the input-dependent attention matrices with constant (input-independent) ones. Interestingly, we show that better-performing models lose more from applying our method than weaker models, suggesting that the utilization of the input-dependent attention mechanism might be a factor in their success. Our results motivate research on simpler alternatives to input-dependent attention, as well as on methods for better utilization of this mechanism in the Transformer architecture",
    "checked": true,
    "id": "2537af99905a27d9b84ba9968715f4287f1d3359",
    "semantic_title": "how much does attention actually attend? questioning the importance of attention in pretrained transformers",
    "citation_count": 18,
    "authors": [
      "Michael Hassid",
      "Hao Peng",
      "Daniel Rotem",
      "Jungo Kasai",
      "Ivan Montero",
      "Noah A. Smith",
      "Roy Schwartz"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.102": {
    "title": "What Has Been Enhanced in my Knowledge-Enhanced Language Model?",
    "volume": "findings",
    "abstract": "A number of knowledge integration (KI) methods have recently been proposed to incorporate external knowledge into pretrained language models (LMs). Even though knowledge-enhanced LMs (KELMs) outperform base LMs on knowledge-intensive tasks, the inner-workings of these KI methods are not well-understood. For instance, it is unclear which knowledge is effectively integrated into KELMs and which is not; and if such integration led to catastrophic forgetting of already learned knowledge. We show that existing model interpretation methods such as linear probes and prompts have some key limitations in answering these questions. Then, we revisit KI from an information-theoretic view and propose a new theoretically sound probe model called Graph Convolution Simulator (GCS) for KI interpretation. GCS is eventually quite simple – it uses graph attention on the corresponding knowledge graph for interpretation. We conduct various experiments to verify that GCS provides reasonable interpretation results for two well-known KELMs: ERNIE and K-Adapter. Our experiments reveal that only little knowledge is successfully integrated in these models, and simply increasing the size of the KI corpus may not lead to better KELMs",
    "checked": true,
    "id": "1ab45eff6ca001ff421d740a22d3f736f3574aaa",
    "semantic_title": "what has been enhanced in my knowledge-enhanced language model?",
    "citation_count": 0,
    "authors": [
      "Yifan Hou",
      "Guoji Fu",
      "Mrinmaya Sachan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.103": {
    "title": "Towards Generalized Open Information Extraction",
    "volume": "findings",
    "abstract": "Open Information Extraction (OpenIE) facilitates the open-domain discovery of textual facts. However, the prevailing solutions evaluate OpenIE models on in-domain test sets aside from the training corpus, which certainly violates the initial task principle of domain-independence. In this paper, we propose to advance OpenIE towards a more realistic scenario: generalizing over unseen target domains with different data distributions from the source training domains, termed Generalized OpenIE. For this purpose, we first introduce GLOBE, a large-scale human-annotated multi-domain OpenIE benchmark, to examine the robustness of recent OpenIE models to domain shifts, and the relative performance degradation of up to 70% implies the challenges of generalized OpenIE. Then, we propose DragonIE, which explores a minimalist expression of textual fact: directed acyclic graph, to improve the OpenIE generalization ability. Extensive experiments demonstrate that DragonIE beats the previous methods in both in-domain and out-of-domain settings by as much as 6.0% in F1 score absolutely, but there is still ample room for improvement",
    "checked": true,
    "id": "130670cd2ffe6994ab4265f534de4aad74385c60",
    "semantic_title": "towards generalized open information extraction",
    "citation_count": 0,
    "authors": [
      "Bowen Yu",
      "Zhenyu Zhang",
      "Jingyang Li",
      "Haiyang Yu",
      "Tingwen Liu",
      "Jian Sun",
      "Yongbin Li",
      "Bin Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.104": {
    "title": "BioLORD: Learning Ontological Representations from Definitions for Biomedical Concepts and their Textual Descriptions",
    "volume": "findings",
    "abstract": "This work introduces BioLORD, a new pre-training strategy for producing meaningful representations for clinical sentences and biomedical concepts. State-of-the-art methodologies operate by maximizing the similarity in representation of names referring to the same concept, and preventing collapse through contrastive learning. However, because biomedical names are not always self-explanatory, it sometimes results in non-semantic representations. BioLORD overcomes this issue by grounding its concept representations using definitions, as well as short descriptions derived from a multi-relational knowledge graph consisting of biomedical ontologies. Thanks to this grounding, our model produces more semantic concept representations that match more closely the hierarchical structure of ontologies. BioLORD establishes a new state of the art for text similarity on both clinical sentences (MedSTS) and biomedical concepts (MayoSRS)",
    "checked": true,
    "id": "033ce949ded20600b7a770fda78853eb48c5ce89",
    "semantic_title": "biolord: learning ontological representations from definitions (for biomedical concepts and their textual descriptions)",
    "citation_count": 6,
    "authors": [
      "François Remy",
      "Kris Demuynck",
      "Thomas Demeester"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.105": {
    "title": "Improving the Extraction of Supertags for Constituency Parsing with Linear Context-Free Rewriting Systems",
    "volume": "findings",
    "abstract": "In parsing phrase structures, supertagging achieves a symbiosis between the interpretability of formal grammars and the accuracy and speed of more recent neural models. The approach was only recently transferred to parsing discontinuous constituency structures with linear context-free rewriting systems (LCFRS).We reformulate and parameterize the previously fixed extraction process for LCFRS supertags with the aim to improve the overall parsing quality. These parameters are set in the context of several steps in the extraction process and are used to control the granularity of extracted grammar rules as well as the association of lexical symbols with each supertag.We evaluate the influence of the parameters on the sets of extracted supertags and the parsing quality using three treebanks in the English and German language, and we compare the best-performing configurations to recent state-of-the-art parsers in the area. Our results show that some of our configurations and the slightly modified parsing process improve the quality and speed of parsing with our supertags over the previous approach. Moreover, we achieve parsing scores that either surpass or are among the state-of-the-art in discontinuous constituent parsing",
    "checked": true,
    "id": "9e0fe39a20baeb95c515f108f64fb209903725f1",
    "semantic_title": "improving the extraction of supertags for constituency parsing with linear context-free rewriting systems",
    "citation_count": 0,
    "authors": [
      "Thomas Ruprecht"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.106": {
    "title": "Mask More and Mask Later: Efficient Pre-training of Masked Language Models by Disentangling the [MASK] Token",
    "volume": "findings",
    "abstract": "The pre-training of masked language models (MLMs) consumes massive computation to achieve good results on downstream NLP tasks, resulting in a large carbon footprint. In the vanilla MLM, the virtual tokens, [MASK]s, act as placeholders and gather the contextualized information from unmasked tokens to restore the corrupted information. It raises the question of whether we can append [MASK]s at a later layer, to reduce the sequence length for earlier layers and make the pre-training more efficient. We show: (1) [MASK]s can indeed be appended at a later layer, being disentangled from the word embedding; (2) The gathering of contextualized information from unmasked tokens can be conducted with a few layers. By further increasing the masking rate from 15% to 50%, we can pre-train RoBERTa-base and RoBERTa-large from scratch with only 78% and 68% of the original computational budget without any degradation on the GLUE benchmark. When pre-training with the original budget, our method outperforms RoBERTa for 6 out of 8 GLUE tasks, on average by 0.4%",
    "checked": true,
    "id": "d6bba193989c3deda4e3701cee97bff1e8dd667e",
    "semantic_title": "mask more and mask later: efficient pre-training of masked language models by disentangling the [mask] token",
    "citation_count": 4,
    "authors": [
      "Baohao Liao",
      "David Thulke",
      "Sanjika Hewavitharana",
      "Hermann Ney",
      "Christof Monz"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.107": {
    "title": "SMSMix: Sense-Maintained Sentence Mixup for Word Sense Disambiguation",
    "volume": "findings",
    "abstract": "Word Sense Disambiguation (WSD) is an NLP task aimed at determining the correct sense of a word in a sentence from discrete sense choices. Although current systems have attained unprecedented performances for such tasks, the nonuniform distribution of word senses during training generally results in systems performing poorly on rare senses. To this end, we consider data augmentation to increase the frequency of these least frequent senses (LFS) to reduce the distributional bias of senses during training. We propose Sense-Maintained Sentence Mixup (SMSMix), a novel word-level mixup method that maintains the sense of a target word. SMSMix smoothly blends two sentences using mask prediction while preserving the relevant span determined by saliency scores to maintain a specific word's sense. To the best of our knowledge, this is the first attempt to apply mixup in NLP while preserving the meaning of a specific word. With extensive experiments, we validate that our augmentation method can effectively give more information about rare senses during training with maintained target sense label",
    "checked": true,
    "id": "d0670e634e1cc7fdc80a522b6c469c7487f7f6ad",
    "semantic_title": "smsmix: sense-maintained sentence mixup for word sense disambiguation",
    "citation_count": 3,
    "authors": [
      "Hee Suk Yoon",
      "Eunseop Yoon",
      "John Harvill",
      "Sunjae Yoon",
      "Mark Hasegawa-Johnson",
      "Chang Yoo"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.108": {
    "title": "On the Effectiveness of Automated Metrics for Text Generation Systems",
    "volume": "findings",
    "abstract": "A major challenge in the field of Text Generation is evaluation, because we lack a sound theory that can be leveraged to extract guidelines for evaluation campaigns. In this work, we propose a first step towards such a theory that incorporates different sources of uncertainty, such as imperfect automated metrics and insufficiently sized test sets. The theory has practical applications, such as determining the number of samples needed to reliably distinguish the performance of a set of Text Generation systems in a given setting. We showcase the application of the theory on the WMT 21 and Spot-The-Bot evaluation data and outline how it can be leveraged to improve the evaluation protocol regarding the reliability, robustness, and significance of the evaluation outcome",
    "checked": true,
    "id": "7a90b933aef61e73a84b1f37d8cde47abf481777",
    "semantic_title": "on the effectiveness of automated metrics for text generation systems",
    "citation_count": 2,
    "authors": [
      "Pius von Däniken",
      "Jan Deriu",
      "Don Tuggener",
      "Mark Cieliebak"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.109": {
    "title": "Residual Learning of Neural Text Generation with n-gram Language Model",
    "volume": "findings",
    "abstract": "N-gram language models (LM) has been largely superseded by neural LMs as the latter exhibits better performance. However, we find that n-gram models can achieve satisfactory performance on a large proportion of testing cases, indicating they have already captured abundant knowledge of the language with relatively low computational cost. With this observation, we propose to learn a neural LM that fits the residual between an n-gram LM and the real-data distribution. The combination of n-gram LMs and neural LMs not only allows the neural part to focus on deeper understanding of the language, but also provides a flexible way to customize a LM by switching the underlying n-gram model without changing the neural model. Experimental results on three typical language tasks (i.e., language modeling, machine translation, and summarization) demonstrate that our approach attains additional performance gains over popular standalone neural models consistently. We also show that our approach allows for effective domain adaptation by simply switching to a domain-specific n-gram model, without any extra training",
    "checked": true,
    "id": "8635734f65b38594d6b2fa3132b0a7f3a40a9d8f",
    "semantic_title": "residual learning of neural text generation with n-gram language model",
    "citation_count": 5,
    "authors": [
      "Huayang Li",
      "Deng Cai",
      "Jin Xu",
      "Taro Watanabe"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.110": {
    "title": "DiffG-RL: Leveraging Difference between Environment State and Common Sense",
    "volume": "findings",
    "abstract": "Taking into account background knowledge as the context has always been an important part of solving tasks that involve natural language. One representative example of such tasks is text-based games, where players need to make decisions based on both description text previously shown in the game, and their own background knowledge about the language and common sense. In this work, we investigate not simply giving common sense, as can be seen in prior research, but also its effective usage. We assume that a part of the environment states different from common sense should constitute one of the grounds for action selection. We propose a novel agent, DiffG-RL, which constructs a Difference Graph that organizes the environment states and common sense by means of interactive objects with a dedicated graph encoder. DiffG-RL also contains a framework for extracting the appropriate amount and representation of common sense from the source to support the construction of the graph. We validate DiffG-RL in experiments with text-based games that require common sense and show that it outperforms baselines by 17% of scores. We will make our code publicly available",
    "checked": true,
    "id": "8d5cf52c8ed8298d0cd0ac73e3b815f2e8943eae",
    "semantic_title": "diffg-rl: leveraging difference between environment state and common sense",
    "citation_count": 0,
    "authors": [
      "Tsunehiko Tanaka",
      "Daiki Kimura",
      "Michiaki Tatsubori"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.111": {
    "title": "Unsupervised Syntactically Controlled Paraphrase Generation with Abstract Meaning Representations",
    "volume": "findings",
    "abstract": "Syntactically controlled paraphrase generation has become an emerging research direction in recent years. Most existing approaches require annotated paraphrase pairs for training and are thus costly to extend to new domains. Unsupervised approaches, on the other hand, do not need paraphrase pairs but suffer from relatively poor performance in terms of syntactic control and quality of generated paraphrases. In this paper, we demonstrate that leveraging Abstract Meaning Representations (AMR) can greatly improve the performance of unsupervised syntactically controlled paraphrase generation. Our proposed model, AMR-enhanced Paraphrase Generator (AMRPG), separately encodes the AMR graph and the constituency parse of the input sentence into two disentangled semantic and syntactic embeddings. A decoder is then learned to reconstruct the input sentence from the semantic and syntactic embeddings. Our experiments show that AMRPG generates more accurate syntactically controlled paraphrases, both quantitatively and qualitatively, compared to the existing unsupervised approaches. We also demonstrate that the paraphrases generated by AMRPG can be used for data augmentation to improve the robustness of NLP models",
    "checked": true,
    "id": "2b5c66f07ba7253c75278978c7f150c9ab05a626",
    "semantic_title": "unsupervised syntactically controlled paraphrase generation with abstract meaning representations",
    "citation_count": 3,
    "authors": [
      "Kuan-Hao Huang",
      "Varun Iyer",
      "Anoop Kumar",
      "Sriram Venkatapathy",
      "Kai-Wei Chang",
      "Aram Galstyan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.112": {
    "title": "Can AMR Assist Legal and Logical Reasoning?",
    "volume": "findings",
    "abstract": "Abstract Meaning Representation (AMR) has been shown to be useful for many downstream tasks. In this work, we explore the use of AMR for legal and logical reasoning. Specifically, we investigate if AMR can help capture logical relationships on multiple choice question answering (MCQA) tasks. We propose neural architectures that utilize linearised AMR graphs in combination with pre-trained language models. While these models are not able to outperform text-only baselines, they correctly solve different instances than the text models, suggesting complementary abilities. Error analysis further reveals that AMR parsing quality is the most prominent challenge, especially regarding inputs with multiple sentences. We conduct a theoretical analysis of how logical relations are represented in AMR and conclude it might be helpful in some logical statements but not for others",
    "checked": true,
    "id": "334262a30d94ac9c269a5cd431ce76cec941c623",
    "semantic_title": "can amr assist legal and logical reasoning?",
    "citation_count": 1,
    "authors": [
      "Nikolaus Schrack",
      "Ruixiang Cui",
      "Hugo López",
      "Daniel Hershcovich"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.113": {
    "title": "Data Selection Curriculum for Neural Machine Translation",
    "volume": "findings",
    "abstract": "Neural Machine Translation (NMT) models are typically trained on heterogeneous data that are concatenated and randomly shuffled. However, not all of the training data are equally useful to the model. Curriculum training aims to present the data to the NMT models in a meaningful order. In this work, we introduce a two-stage training framework for NMT where we fine-tune a base NMT model on subsets of data, selected by both deterministic scoring using pre-trained methods and online scoring that considers prediction scores of the emerging NMT model. Through comprehensive experiments on six language pairs comprising low- and high-resource languages from WMT'21, we have shown that our curriculum strategies consistently demonstrate better quality (up to +2.2 BLEU improvement) and faster convergence (approximately 50% fewer updates)",
    "checked": true,
    "id": "d6c4b31958fe9e4ff4f83e049ed5c6881653eb03",
    "semantic_title": "data selection curriculum for neural machine translation",
    "citation_count": 7,
    "authors": [
      "Tasnim Mohiuddin",
      "Philipp Koehn",
      "Vishrav Chaudhary",
      "James Cross",
      "Shruti Bhosale",
      "Shafiq Joty"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.114": {
    "title": "Text Editing as Imitation Game",
    "volume": "findings",
    "abstract": "Text editing, such as grammatical error correction, arises naturally from imperfect textual data. Recent works frame text editing as a multi-round sequence tagging task, where operations – such as insertion and substitution – are represented as a sequence of tags. While achieving good results, this encoding is limited in flexibility as all actions are bound to token-level tags. In this work, we reformulate text editing as an imitation game using behavioral cloning. Specifically, we convert conventional sequence-to-sequence data into state-to-action demonstrations, where the action space can be as flexible as needed. Instead of generating the actions one at a time, we introduce a dual decoders structure to parallel the decoding while retaining the dependencies between action tokens, coupled with trajectory augmentation to alleviate the distribution shift that imitation learning often suffers. In experiments on a suite of Arithmetic Equation benchmarks, our model consistently outperforms the autoregressive baselines in terms of performance, efficiency, and robustness. We hope our findings will shed light on future studies in reinforcement learning applying sequence-level action generation to natural language processing",
    "checked": true,
    "id": "632c66f202c7b3abf488d7af0cea589694d6a875",
    "semantic_title": "text editing as imitation game",
    "citation_count": 1,
    "authors": [
      "Ning Shi",
      "Bin Tang",
      "Bo Yuan",
      "Longtao Huang",
      "Yewen Pu",
      "Jie Fu",
      "Zhouhan Lin"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.115": {
    "title": "Seeded Hierarchical Clustering for Expert-Crafted Taxonomies",
    "volume": "findings",
    "abstract": "Practitioners from many disciplines (e.g., political science) use expert-crafted taxonomies to make sense of large, unlabeled corpora. In this work, we study Seeded Hierarchical Clustering (SHC): the task of automatically fitting unlabeled data to such taxonomies using a small set of labeled examples. We propose HierSeed, a novel weakly supervised algorithm for this task that uses only a small set of labeled seed examples in a computation and data efficient manner. HierSeed assigns documents to topics by weighing document density against topic hierarchical structure. It outperforms unsupervised and supervised baselines for the SHC task on three real-world datasets",
    "checked": true,
    "id": "4e9e4403cb892a2c0facd257d832393793cbd5b4",
    "semantic_title": "seeded hierarchical clustering for expert-crafted taxonomies",
    "citation_count": 0,
    "authors": [
      "Anish Saha",
      "Amith Ananthram",
      "Emily Allaway",
      "Heng Ji",
      "Kathleen McKeown"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.116": {
    "title": "Knowledge Graph Generation From Text",
    "volume": "findings",
    "abstract": "In this work we propose a novel end-to-end multi-stage Knowledge Graph (KG) generation system from textual inputs, separating the overall process into two stages. The graph nodes are generated first using pretrained language model, followed by a simple edge construction head, enabling efficient KG extraction from the text. For each stage we consider several architectural choices that can be used depending on the available training resources. We evaluated the model on a recent WebNLG 2020 Challenge dataset, matching the state-of-the-art performance on text-to-RDF generation task, as well as on New York Times (NYT) and a large-scale TekGen datasets, showing strong overall performance, outperforming the existing baselines. We believe that the proposed system can serve as a viable KG construction alternative to the existing linearization or sampling-based graph generation approaches",
    "checked": true,
    "id": "3917602c6139811fe3c20bc32070d6cee474fe49",
    "semantic_title": "knowledge graph generation from text",
    "citation_count": 10,
    "authors": [
      "Igor Melnyk",
      "Pierre Dognin",
      "Payel Das"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.117": {
    "title": "DialogueGAT: A Graph Attention Network for Financial Risk Prediction by Modeling the Dialogues in Earnings Conference Calls",
    "volume": "findings",
    "abstract": "Financial risk prediction is an essential task for risk management in capital markets. While traditional prediction models are built based on the hard information of numerical data, recent studies have shown that the soft information of verbal cues in earnings conference calls is significant for predicting market risk due to its less constrained fashion and direct interaction between managers and analysts. However, most existing models mainly focus on extracting useful semantic information from the textual conference call transcripts but ignore their subtle yet important information of dialogue structures. To bridge this gap, we develop a graph attention network called DialogueGAT for financial risk prediction by simultaneously modeling the speakers and their utterances in dialogues in conference calls. Different from previous studies, we propose a new method for constructing the graph of speakers and utterances in a dialogue, and design contextual attention at both speaker and utterance levels for disentangling their effects on the downstream prediction task. For model evaluation, we extend an existing dataset of conference call transcripts by adding the dialogue structure and speaker information. Empirical results on our dataset of S&P1500 companies demonstrate the superiority of our proposed model over competitive baselines from the extant literature",
    "checked": true,
    "id": "e5d6aff63ba3a5223be23329f009b39f0fc697bc",
    "semantic_title": "dialoguegat: a graph attention network for financial risk prediction by modeling the dialogues in earnings conference calls",
    "citation_count": 2,
    "authors": [
      "Yunxin Sang",
      "Yang Bao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.118": {
    "title": "Investigating Ensemble Methods for Model Robustness Improvement of Text Classifiers",
    "volume": "findings",
    "abstract": "Large pre-trained language models have shown remarkable performance over the past few years. These models, however, sometimes learn superficial features from the dataset and cannot generalize to the distributions that are dissimilar to the training scenario. There have been several approaches proposed to reduce model's reliance on these bias features which can improve model robustness in the out-of-distribution setting. However, existing methods usually use a fixed low-capacity model to deal with various bias features, which ignore the learnability of those features. In this paper, we analyze a set of existing bias features and demonstrate there is no single model that works best for all the cases. We further show that by choosing an appropriate bias model, we can obtain a better robustness result than baselines with a more sophisticated model design",
    "checked": true,
    "id": "bb86ade4959e9d03e0c5321cde82d759759fd958",
    "semantic_title": "investigating ensemble methods for model robustness improvement of text classifiers",
    "citation_count": 2,
    "authors": [
      "Jieyu Zhao",
      "Xuezhi Wang",
      "Yao Qin",
      "Jilin Chen",
      "Kai-Wei Chang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.119": {
    "title": "Adaptive Ranking-based Sample Selection for Weakly Supervised Class-imbalanced Text Classification",
    "volume": "findings",
    "abstract": "To obtain a large amount of training labels inexpensively, researchers have recently adopted the weak supervision (WS) paradigm, which leverages labeling rules to synthesize training labels rather than using individual annotations to achieve competitive results for natural language processing (NLP) tasks. However, data imbalance is often overlooked in applying the WS paradigm, despite being a common issue in a variety of NLP tasks. To address this challenge, we propose Adaptive Ranking-based Sample Selection (ARS2), a model-agnostic framework to alleviate the data imbalance issue in the WS paradigm. Specifically, it calculates a probabilistic margin score based on the output of the current model to measure and rank the cleanliness of each data point. Then, the ranked data are sampled based on both class-wise and rule-aware ranking. In particular, the two sample strategies corresponds to our motivations: (1) to train the model with balanced data batches to reduce the data imbalance issue and (2) to exploit the expertise of each labeling rule for collecting clean samples. Experiments on four text classification datasets with four different imbalance ratios show that ARS2 outperformed the state-of-the-art imbalanced learning and WS methods, leading to a 2%-57.8% improvement on their F1-score",
    "checked": true,
    "id": "67d2979fb0c877a8c95194a7433db2e98b3a6d55",
    "semantic_title": "adaptive ranking-based sample selection for weakly supervised class-imbalanced text classification",
    "citation_count": 2,
    "authors": [
      "Linxin Song",
      "Jieyu Zhang",
      "Tianxiang Yang",
      "Masayuki Goto"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.120": {
    "title": "ComFact: A Benchmark for Linking Contextual Commonsense Knowledge",
    "volume": "findings",
    "abstract": "Understanding rich narratives, such as dialogues and stories, often requires natural language processing systems to access relevant knowledge from commonsense knowledge graphs. However, these systems typically retrieve facts from KGs using simple heuristics that disregard the complex challenges of identifying situationally-relevant commonsense knowledge (e.g., contextualization, implicitness, ambiguity).In this work, we propose the new task of commonsense fact linking, where models are given contexts and trained to identify situationally-relevant commonsense knowledge from KGs. Our novel benchmark, ComFact, contains ~293k in-context relevance annotations for commonsense triplets across four stylistically diverse dialogue and storytelling datasets. Experimental results confirm that heuristic fact linking approaches are imprecise knowledge extractors. Learned fact linking models demonstrate across-the-board performance improvements (~34.6% F1) over these heuristics. Furthermore, improved knowledge retrieval yielded average downstream improvements of 9.8% for a dialogue response generation task. However, fact linking models still significantly underperform humans, suggesting our benchmark is a promising testbed for research in commonsense augmentation of NLP systems",
    "checked": true,
    "id": "d1feb79f63ea52839f4a784fbd7d60bb73dd98dd",
    "semantic_title": "comfact: a benchmark for linking contextual commonsense knowledge",
    "citation_count": 10,
    "authors": [
      "Silin Gao",
      "Jena D. Hwang",
      "Saya Kanno",
      "Hiromi Wakaki",
      "Yuki Mitsufuji",
      "Antoine Bosselut"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.121": {
    "title": "Learning to Perform Complex Tasks through Compositional Fine-Tuning of Language Models",
    "volume": "findings",
    "abstract": "How to usefully encode compositional task structure has long been a core challenge in AI. Recent work in chain of thought prompting has shown that for very large neural language models (LMs), explicitly demonstrating the inferential steps involved in a target task may improve performance over end-to-end learning that focuses on the target task alone. However, chain of thought prompting has significant limitations due to its dependency on huge pretrained LMs. In this work, we present compositional fine-tuning (CFT): an approach based on explicitly decomposing a target task into component tasks, and then fine-tuning smaller LMs on a curriculum of such component tasks. We apply CFT to recommendation tasks in two domains, world travel and local dining, as well as a previously studied inferential task (sports understanding). We show that CFT outperforms end-to-end learning even with equal amounts of data, and gets consistently better as more component tasks are modeled via fine-tuning. Compared with chain of thought prompting, CFT performs at least as well using LMs only 7.4% of the size, and is moreover applicable to task domains for which data are not available during pretraining",
    "checked": true,
    "id": "798abf86efae9e37b9b6a694ef87b6c1dbaab263",
    "semantic_title": "learning to perform complex tasks through compositional fine-tuning of language models",
    "citation_count": 4,
    "authors": [
      "Victor Bursztyn",
      "David Demeter",
      "Doug Downey",
      "Larry Birnbaum"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.122": {
    "title": "Topic Taxonomy Expansion via Hierarchy-Aware Topic Phrase Generation",
    "volume": "findings",
    "abstract": "Topic taxonomies display hierarchical topic structures of a text corpus and provide topical knowledge to enhance various NLP applications. To dynamically incorporate new topic information, several recent studies have tried to expand (or complete) a topic taxonomy by inserting emerging topics identified in a set of new documents. However, existing methods focus only on frequent terms in documents and the local topic-subtopic relations in a taxonomy, which leads to limited topic term coverage and fails to model the global taxonomy structure. In this work, we propose a novel framework for topic taxonomy expansion, named TopicExpan, which directly generates topic-related terms belonging to new topics. Specifically, TopicExpan leverages the hierarchical relation structure surrounding a new topic and the textual content of an input document for topic term generation. This approach encourages newly-inserted topics to further cover important but less frequent terms as well as to keep their relation consistency within the taxonomy. Experimental results on two real-world text corpora show that TopicExpan significantly outperforms other baseline methods in terms of the quality of output taxonomies",
    "checked": true,
    "id": "cb2249f14414c31bd8617dfc76c20c8874ba0284",
    "semantic_title": "topic taxonomy expansion via hierarchy-aware topic phrase generation",
    "citation_count": 5,
    "authors": [
      "Dongha Lee",
      "Jiaming Shen",
      "Seonghyeon Lee",
      "Susik Yoon",
      "Hwanjo Yu",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.123": {
    "title": "Language as a fingerprint: Self-supervised learning of user encodings using transformers",
    "volume": "findings",
    "abstract": "The way we talk carries information about who we are. Demographics, personality, clinical conditions, political preferences influence what we speak about and how, suggesting that many individual attributes could be inferred from adequate encodings of linguistic behavior. Conversely, conditioning text representations on author attributes has been shown to improve model performance in many NLP tasks. Previous research on individual differences and language representations has mainly focused on predicting selected attributes from text, or on conditioning text representations on such attributes for author-based contextualization. Here, we present a self-supervised approach to learning language-based user encodings using transformers. Using a large corpus of Reddit submissions, we fine-tune DistilBERT on user-based triplet loss. We show that fine-tuned models can pick up on complex linguistic signatures of users, and that they are able to infer rich information about them. Through a series of intrinsic analyses and probing tasks, we provide evidence that fine-tuning enhances models' ability to abstract generalizable user information, which yields performance advantages for user-based downstream tasks. We discuss applications in language-based assessment and contextualized and personalized NLP",
    "checked": true,
    "id": "d8d176585614cd55ddcf123b85f3452cc3de83d9",
    "semantic_title": "language as a fingerprint: self-supervised learning of user encodings using transformers",
    "citation_count": 5,
    "authors": [
      "Roberta Rocca",
      "Tal Yarkoni"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.124": {
    "title": "Hyperdecoders: Instance-specific decoders for multi-task NLP",
    "volume": "findings",
    "abstract": "We investigate input-conditioned hypernetworks for multi-tasking in NLP, generating parameter-efficient adaptations for a decoder using a hypernetwork conditioned on the output of an encoder. This approach produces a unique decoder adaptation for every input instance, allowing the network a larger degree of flexibility than prior work that only produces one decoder adaptation per task. We apply our method to sequence classification tasks, extractive QA, and summarisation and find that it surpasses previous parameter efficient fine-tuning methods and often outperforms fully finetuning the underlying model. An analysis of the embeddings used by our hypernetwork shows that they are sensitive to output label and type, suggesting that our approach better maps from encoder representations to output labels. Our code is publicly available at https://github.com/allenai/hyperdecoders",
    "checked": true,
    "id": "9060d9408fda662f717de99b004045ec1168e581",
    "semantic_title": "hyperdecoders: instance-specific decoders for multi-task nlp",
    "citation_count": 12,
    "authors": [
      "Hamish Ivison",
      "Matthew Peters"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.125": {
    "title": "Evaluating the Faithfulness of Importance Measures in NLP by Recursively Masking Allegedly Important Tokens and Retraining",
    "volume": "findings",
    "abstract": "To explain NLP models a popular approach is to use importance measures, such as attention, which inform input tokens are important for making a prediction. However, an open question is how well these explanations accurately reflect a model's logic, a property called faithfulness. To answer this question, we propose Recursive ROAR, a new faithfulness metric. This works by recursively masking allegedly important tokens and then retraining the model. The principle is that this should result in worse model performance compared to masking random tokens. The result is a performance curve given a masking-ratio. Furthermore, we propose a summarizing metric using area-between-curves (ABC), which allows for easy comparison across papers, models, and tasks. We evaluate 4 different importance measures on 8 different datasets, using both LSTM-attention models and RoBERTa models. We find that the faithfulness of importance measures is both model-dependent and task-dependent. This conclusion contradicts previous evaluations in both computer vision and faithfulness of attention literature",
    "checked": true,
    "id": "e8243b2aafab80aac0be162f17a720c40fba180d",
    "semantic_title": "evaluating the faithfulness of importance measures in nlp by recursively masking allegedly important tokens and retraining",
    "citation_count": 24,
    "authors": [
      "Andreas Madsen",
      "Nicholas Meade",
      "Vaibhav Adlakha",
      "Siva Reddy"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.126": {
    "title": "Towards Explaining Subjective Ground of Individuals on Social Media",
    "volume": "findings",
    "abstract": "Large-scale language models have been reducing the gap between machines and humans in understanding the real world, yet understanding an individual's theory of mind and behavior from text is far from being resolved. This research proposes a neural model—Subjective Ground Attention—that learns subjective grounds of individuals and accounts for their judgments on situations of others posted on social media. Using simple attention modules as well as taking one's previous activities into consideration, we empirically show that our model provides human-readable explanations of an individual's subjective preference in judging social situations. We further qualitatively evaluate the explanations generated by the model and claim that our model learns an individual's subjective orientation towards abstract moral concepts",
    "checked": true,
    "id": "67d15e42745d21bb73e03f86012986a5fda7b44c",
    "semantic_title": "towards explaining subjective ground of individuals on social media",
    "citation_count": 0,
    "authors": [
      "Younghun Lee",
      "Dan Goldwasser"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.127": {
    "title": "Knowledge Injected Prompt Based Fine-tuning for Multi-label Few-shot ICD Coding",
    "volume": "findings",
    "abstract": "Automatic International Classification of Diseases (ICD) coding aims to assign multiple ICD codes to a medical note with average length of 3,000+ tokens. This task is challenging due to a high-dimensional space of multi-label assignment (tens of thousands of ICD codes) and the long-tail challenge: only a few codes (common diseases) are frequently assigned while most codes (rare diseases) are infrequently assigned. This study addresses the long-tail challenge by adapting a prompt-based fine-tuning technique with label semantics, which has been shown to be effective under few-shot setting. To further enhance the performance in medical domain, we propose a knowledge-enhanced longformer by injecting three domain-specific knowledge: hierarchy, synonym, and abbreviation with additional pretraining using contrastive learning. Experiments on MIMIC-III-full, a benchmark dataset of code assignment, show that our proposed method outperforms previous state-of-the-art method in 14.5% in marco F1 (from 10.3 to 11.8, P<0.001). To further test our model on few-shot setting, we created a new rare diseases coding dataset, MIMIC-III-rare50, on which our model improves marco F1 from 17.1 to 30.4 and micro F1 from 17.2 to 32.6 compared to previous method",
    "checked": true,
    "id": "0b80389b6ec62e0c03c822c2748f7c41d859bcb7",
    "semantic_title": "knowledge injected prompt based fine-tuning for multi-label few-shot icd coding",
    "citation_count": 26,
    "authors": [
      "Zhichao Yang",
      "Shufan Wang",
      "Bhanu Pratap Singh Rawat",
      "Avijit Mitra",
      "Hong Yu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.128": {
    "title": "Do Language Models Understand Measurements?",
    "volume": "findings",
    "abstract": "Recent success of pre-trained language models (PLMs) has stimulated interest in their ability to understand and work with numbers. Yet, the numerical reasoning over measurements has not been formally studied despite their importance. In this study, we show that PLMs lack the capability required for reasoning over measurements. Furthermore, we find that a language model trained on a measurement-rich corpus shows better performance on understanding measurements. We propose a simple embedding strategy to better distinguish between numbers and units, which leads to a significant improvement in the probing tasks",
    "checked": true,
    "id": "ff8f3dfd9e2f4a92310999722abefab202935521",
    "semantic_title": "do language models understand measurements?",
    "citation_count": 3,
    "authors": [
      "Sungjin Park",
      "Seungwoo Ryu",
      "Edward Choi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.129": {
    "title": "Reconciliation of Pre-trained Models and Prototypical Neural Networks in Few-shot Named Entity Recognition",
    "volume": "findings",
    "abstract": "Incorporating large-scale pre-trained models with the prototypical neural networks is a de-facto paradigm in few-shot named entity recognition. Existing methods, unfortunately, are not aware of the fact that embeddings from pre-trained models contain a prominently large amount of information regarding word frequencies, biasing prototypical neural networks against learning word entities. This discrepancy constrains the two models' synergy. Thus, we propose a one-line-code normalization method to reconcile such a mismatch with empirical and theoretical grounds. Our experiments based on nine benchmark datasets show the superiority of our method over the counterpart models and are comparable to the state-of-the-art methods. In addition to the model enhancement, our work also provides an analytical viewpoint for addressing the general problems in few-shot name entity recognition or other tasks that rely on pre-trained models or prototypical neural networks",
    "checked": true,
    "id": "5c4070cb73a3c2045d99773bc36ba6520c501662",
    "semantic_title": "reconciliation of pre-trained models and prototypical neural networks in few-shot named entity recognition",
    "citation_count": 2,
    "authors": [
      "Youcheng Huang",
      "Wenqiang Lei",
      "Jie Fu",
      "Jiancheng Lv"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.130": {
    "title": "HCL-TAT: A Hybrid Contrastive Learning Method for Few-shot Event Detection with Task-Adaptive Threshold",
    "volume": "findings",
    "abstract": "Event detection has been suffering from constantly emerging event types with lack of sufficient data. Existing works formulate the new problem as few-shot event detection (FSED), and employ two-stage or unified models based on meta-learning to address the problem. However, these methods fall far short of expectations due to: (i) insufficient learning of discriminative representations in low-resource scenarios, and (ii) representation overlap between triggers and non-triggers. To resolve the above issues, in this paper, we propose a novel Hybrid Contrastive Learning method with a Task-Adaptive Threshold (abbreviated as HCL-TAT), which enables discriminative representation learning with a two-view contrastive loss (support-support and prototype-query), and devises an easily-adapted threshold to alleviate misidentification of triggers. Extensive experiments on the benchmark dataset FewEvent demonstrate the superiority of our method to achieve better results compared to the state-of-the-arts. All the data and codes will be available to facilitate future research",
    "checked": true,
    "id": "e6f2d8eeca0796914e3a6bcc311e153c5ad79224",
    "semantic_title": "hcl-tat: a hybrid contrastive learning method for few-shot event detection with task-adaptive threshold",
    "citation_count": 7,
    "authors": [
      "Ruihan Zhang",
      "Wei Wei",
      "Xian-Ling Mao",
      "Rui Fang",
      "Dangyang Chen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.131": {
    "title": "Doc2Bot: Accessing Heterogeneous Documents via Conversational Bots",
    "volume": "findings",
    "abstract": "This paper introduces Doc2Bot, a novel dataset for building machines that help users seek information via conversations. This is of particular interest for companies and organizations that own a large number of manuals or instruction books. Despite its potential, the nature of our task poses several challenges: (1) documents contain various structures that hinder the ability of machines to comprehend, and (2) user information needs are often underspecified. Compared to prior datasets that either focus on a single structural type or overlook the role of questioning to uncover user needs, the Doc2Bot dataset is developed to target such challenges systematically. Our dataset contains over 100,000 turns based on Chinese documents from five domains, larger than any prior document-grounded dialog dataset for information seeking. We propose three tasks in Doc2Bot: (1) dialog state tracking to track user intentions, (2) dialog policy learning to plan system actions and contents, and (3) response generation which generates responses based on the outputs of the dialog policy. Baseline methods based on the latest deep learning models are presented, indicating that our proposed tasks are challenging and worthy of further research",
    "checked": true,
    "id": "c95a6c1ef62a40deb87f5bac170cc6484aa3a267",
    "semantic_title": "doc2bot: document grounded bot framework",
    "citation_count": 2,
    "authors": [
      "Haomin Fu",
      "Yeqin Zhang",
      "Haiyang Yu",
      "Jian Sun",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li",
      "Cam Tu Nguyen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.132": {
    "title": "DualNER: A Dual-Teaching framework for Zero-shot Cross-lingual Named Entity Recognition",
    "volume": "findings",
    "abstract": "We present DualNER, a simple and effective framework to make full use of both annotated source language corpus and unlabeled target language text for zero-shot cross-lingual named entity recognition (NER). In particular, we combine two complementary learning paradigms of NER, i.e., sequence labeling and span prediction, into a unified multi-task framework. After obtaining a sufficient NER model trained on the source data, we further train it on the target data in a dual-teaching manner, in which the pseudo-labels for one task are constructed from the prediction of the other task. Moreover, based on the span prediction, an entity-aware regularization is proposed to enhance the intrinsic cross-lingual alignment between the same entities in different languages. Experiments and analysis demonstrate the effectiveness of our DualNER",
    "checked": true,
    "id": "dfc4cb1cba0f1847013d9077867edcb5c9049c69",
    "semantic_title": "dualner: a dual-teaching framework for zero-shot cross-lingual named entity recognition",
    "citation_count": 0,
    "authors": [
      "Jiali Zeng",
      "Yufan Jiang",
      "Yongjing Yin",
      "Xu Wang",
      "Binghuai Lin",
      "Yunbo Cao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.133": {
    "title": "Knowledge-augmented Self-training of A Question Rewriter for Conversational Knowledge Base Question Answering",
    "volume": "findings",
    "abstract": "The recent rise of conversational applications such as online customer service systems and intelligent personal assistants has promoted the development of conversational knowledge base question answering (ConvKBQA). Different from the traditional single-turn KBQA, ConvKBQA usually explores multi-turn questions around a topic, where ellipsis and coreference pose great challenges to the single-turn KBQA systems which require self-contained questions. In this paper, we propose a rewrite-and-reason framework to first produce a full-fledged rewritten question based on the conversation history and then reason the answer by existing single-turn KBQA models. To overcome the absence of the rewritten supervision signals, we introduce a knowledge-augmented self-training mechanism to transfer the question rewriter from another dataset to adapt to the current knowledge base. Our question rewriter is decoupled from the subsequent QA process, which makes it easy to be united with either retrieval-based or semantic parsing-based KBQA models. Experiment results demonstrate the effectiveness of our method and a new state-of-the-art result is achieved. The code and dataset are available online now",
    "checked": true,
    "id": "8f0e5b9095f21f9408aa2d5ded3f520aa4b3b22f",
    "semantic_title": "knowledge-augmented self-training of a question rewriter for conversational knowledge base question answering",
    "citation_count": 4,
    "authors": [
      "Xirui Ke",
      "Jing Zhang",
      "Xin Lv",
      "Yiqi Xu",
      "Shulin Cao",
      "Cuiping Li",
      "Hong Chen",
      "Juanzi Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.134": {
    "title": "Extractive Summarization of Legal Decisions using Multi-task Learning and Maximal Marginal Relevance",
    "volume": "findings",
    "abstract": "Summarizing legal decisions requires the expertise of law practitioners, which is both time- and cost-intensive. This paper presents techniques for extractive summarization of legal decisions in a low-resource setting using limited expert annotated data. We test a set of models that locate relevant content using a sequential model and tackle redundancy by leveraging maximal marginal relevance to compose summaries. We also demonstrate an implicit approach to help train our proposed models generate more informative summaries. Our multi-task learning model variant leverages rhetorical role identification as an auxiliary task to further improve the summarizer. We perform extensive experiments on datasets containing legal decisions from the US Board of Veterans' Appeals and conduct quantitative and expert-ranked evaluations of our models. Our results show that the proposed approaches can achieve ROUGE scores vis-à-vis expert extracted summaries that match those achieved by inter-annotator comparison",
    "checked": true,
    "id": "ad2c314353ad96447acf030b9ac3f7326b56e51a",
    "semantic_title": "extractive summarization of legal decisions using multi-task learning and maximal marginal relevance",
    "citation_count": 10,
    "authors": [
      "Abhishek Agarwal",
      "Shanshan Xu",
      "Matthias Grabmair"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.135": {
    "title": "MovieUN: A Dataset for Movie Understanding and Narrating",
    "volume": "findings",
    "abstract": "Automatic movie narration generation and narration grounding are very important to provide a true movie experience for the blind and visually impaired. To tell the movie story well, it is necessary to mention plot-related details (such as character names) and keep the narrations in a plot coherent. Taking these two points into consideration, we construct a Chinese large-scale video benchmark from 101 movies for Movie Understanding and Narrating (MovieUN) to support the Movie Clip Narrating (MCN) task and Temporal Narration Grounding (TNG) task. We split movies in MovieUN into movie clips according to plots, and pair them with corresponding narrations provided by the movie narrators. Ultimately, the TNG task involves 3,253 long video clips totaling 179 hours. The MCN task contains 33,060 video clips totaling 105 hours. We benchmark state-of-the-art video captioning models and temporal grounding models in MCN and TNG tasks, respectively. Furthermore, to accurately comprehend plots of different characters, we propose methods to incorporate portraits of actors as external knowledge in both tasks. The experiment results demonstrate the effectiveness of our proposed methods. The dataset and codes are released at https://github.com/yuezih/MovieUN",
    "checked": true,
    "id": "8ad5bb0b465737968167f6eb6ac13f3cdba9ac36",
    "semantic_title": "movieun: a dataset for movie understanding and narrating",
    "citation_count": 0,
    "authors": [
      "Qi Zhang",
      "Zihao Yue",
      "Anwen Hu",
      "Ziheng Wang",
      "Qin Jin"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.136": {
    "title": "ASDOT: Any-Shot Data-to-Text Generation with Pretrained Language Models",
    "volume": "findings",
    "abstract": "Data-to-text generation is challenging due to the great variety of the input data in terms of domains (e.g., finance vs sports) or schemata (e.g., diverse predicates). Recent end-to-end neural methods thus require substantial training examples to learn to disambiguate and describe the data. Yet, real-world data-to-text problems often suffer from various data-scarce issues: one may have access to only a handful of or no training examples, and/or have to rely on examples in a different domain or schema. To fill this gap, we propose Any-Shot Data-to-Text (ASDOT), a new approach flexibly applicable to diverse settings by making efficient use of any given (or no) examples. ASDOT consists of two steps, data disambiguation and sentence fusion, both of which are amenable to be solved with off-the-shelf pretrained language models (LMs) with optional finetuning. In the data disambiguation stage, we employ the prompted GPT-3 model to understand possibly ambiguous triples from the input data and convert each into a short sentence with reduced ambiguity. The sentence fusion stage then uses an LM like T5 to fuse all the resulting sentences into a coherent paragraph as the final description. We evaluate extensively on various datasets in different scenarios, including the zero-/few-/full-shot settings, and generalization to unseen predicates and out-of-domain data. Experimental results show that ASDOT consistently achieves significant improvement over baselines, e.g., a 30.81 BLEU gain on the DART dataset under the zero-shot setting",
    "checked": true,
    "id": "0269664dbaebc427b1a0860526f5ea3aac811e31",
    "semantic_title": "asdot: any-shot data-to-text generation with pretrained language models",
    "citation_count": 12,
    "authors": [
      "Jiannan Xiang",
      "Zhengzhong Liu",
      "Yucheng Zhou",
      "Eric Xing",
      "Zhiting Hu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.137": {
    "title": "FCGEC: Fine-Grained Corpus for Chinese Grammatical Error Correction",
    "volume": "findings",
    "abstract": "Grammatical Error Correction (GEC) has been broadly applied in automatic correction and proofreading system recently. However, it is still immature in Chinese GEC due to limited high-quality data from native speakers in terms of category and scale. In this paper, we present FCGEC, a fine-grained corpus to detect, identify and correct the grammatical errors. FCGEC is a human-annotated corpus with multiple references, consisting of 41,340 sentences collected mainly from multi-choice questions in public school Chinese examinations. Furthermore, we propose a Switch-Tagger-Generator (STG) baseline model to correct the grammatical errors in low-resource settings. Compared to other GEC benchmark models, experimental results illustrate that STG outperforms them on our FCGEC. However, there exists a significant gap between benchmark models and humans that encourages future models to bridge it",
    "checked": true,
    "id": "c080f022c6f57d10dc8e8e44231c8995480b884d",
    "semantic_title": "fcgec: fine-grained corpus for chinese grammatical error correction",
    "citation_count": 8,
    "authors": [
      "Lvxiaowei Xu",
      "Jianwang Wu",
      "Jiawei Peng",
      "Jiayu Fu",
      "Ming Cai"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.138": {
    "title": "Audience-Centric Natural Language Generation via Style Infusion",
    "volume": "findings",
    "abstract": "Adopting contextually appropriate, audience-tailored linguistic styles is critical to the success of user-centric language generation systems (e.g., chatbots, computer-aided writing, dialog systems). While existing approaches demonstrate text style transfer (TST) with large volumes of parallel or non-parallel data, we argue that grounding style on audience-independent external factors is innately limiting for two reasons. First, it is difficult to collect large volumes of audience-specific stylistic data. Second, some stylistic objectives (e.g., persuasiveness, memorability, empathy) are hard to define without audience feedback. In this paper, we propose the novel task of style infusion - infusing the stylistic preferences of audiences in pretrained language generation models. Since humans are better at pairwise comparisons than direct scoring - i.e., is Sample-A more persuasive/polite/empathic than Sample-B - we leverage limited pairwise human judgments to bootstrap a style analysis model and augment our seed set of judgments. We then infuse the learned textual style in a GPT-2 based text generator while balancing fluency and style adoption. With quantitative and qualitative assessments, we show that our infusion approach can generate compelling stylized examples with generic text prompts. We make the anonymized code and data accessible",
    "checked": true,
    "id": "8378cf67ea255ed3bc1fd168e98baa841d6ce5ff",
    "semantic_title": "audience-centric natural language generation via style infusion",
    "citation_count": 1,
    "authors": [
      "Samraj Moorjani",
      "Adit Krishnan",
      "Hari Sundaram",
      "Ewa Maslowska",
      "Aravind Sankar"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.139": {
    "title": "DocFin: Multimodal Financial Prediction and Bias Mitigation using Semi-structured Documents",
    "volume": "findings",
    "abstract": "Financial prediction is complex due to the stochastic nature of the stock market. Semi-structured financial documents present comprehensive financial data in tabular formats, such as earnings, profit-loss statements, and balance sheets, and can often contain rich technical analysis along with a textual discussion of corporate history, and management analysis, compliance, and risks. Existing research focuses on the textual and audio modalities of financial disclosures from company conference calls to forecast stock volatility and price movement, but ignores the rich tabular data available in financial reports. Moreover, the economic realm is still plagued with a severe under-representation of various communities spanning diverse demographics, gender, and native speakers. In this work, we show that combining tabular data from financial semi-structured documents with text transcripts and audio recordings not only improves stock volatility and price movement prediction by 5-12% but also reduces gender bias caused due to audio-based neural networks by over 30%",
    "checked": true,
    "id": "2bff94593787c47a240dc438bef1498a1f02fb2f",
    "semantic_title": "docfin: multimodal financial prediction and bias mitigation using semi-structured documents",
    "citation_count": 2,
    "authors": [
      "Puneet Mathur",
      "Mihir Goyal",
      "Ramit Sawhney",
      "Ritik Mathur",
      "Jochen Leidner",
      "Franck Dernoncourt",
      "Dinesh Manocha"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.140": {
    "title": "Not Just Plain Text! Fuel Document-Level Relation Extraction with Explicit Syntax Refinement and Subsentence Modeling",
    "volume": "findings",
    "abstract": "Document-level relation extraction (DocRE) aims to identify semantic labels among entities within a single document. One major challenge of DocRE is to dig decisive details regarding a specific entity pair from long text. However, in many cases, only a fraction of text carries required information, even in the manually labeled supporting evidence. To better capture and exploit instructive information, we propose a novel expLicit syntAx Refinement and Subsentence mOdeliNg based framework (LARSON). By introducing extra syntactic information, LARSON can model subsentences of arbitrary granularity and efficiently screen instructive ones. Moreover, we incorporate refined syntax into text representations which further improves the performance of LARSON. Experimental results on three benchmark datasets (DocRED, CDR, and GDA) demonstrate that LARSON significantly outperforms existing methods",
    "checked": true,
    "id": "4a471dc74f55eeb1c1186be5a33e7ae907338044",
    "semantic_title": "not just plain text! fuel document-level relation extraction with explicit syntax refinement and subsentence modeling",
    "citation_count": 3,
    "authors": [
      "Zhichao Duan",
      "Xiuxing Li",
      "Zhenyu Li",
      "Zhuo Wang",
      "Jianyong Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.141": {
    "title": "Self-supervised Rewiring of Pre-trained Speech Encoders:Towards Faster Fine-tuning with Less Labels in Speech Processing",
    "volume": "findings",
    "abstract": "Pre-trained speech Transformers have facilitated great success across various speech processing tasks. However, fine-tuning these encoders for downstream tasks require sufficiently large training data to converge or to achieve state-of-the-art. In text domain this has been partly attributed to sub-optimality of the representation space in pre-trained Transformers. In this work, we take a sober look into pre-trained speech encoders and rewire their representation space without requiring any task-specific labels. Our method utilises neutrally synthesised version of audio inputs along with frame masking to construct positive pairs for contrastive self-supervised learning. When used for augmenting the wav2vec 2 encoder, we observe consistent improvement of isotropy in the representation space. Our experiments on 6 speech processing tasks, exhibit a significant convergence speedup during task fine-tuning as well as consistent task improvement, specially in low-resource settings",
    "checked": true,
    "id": "ea677fa717d9a9f97840e0d78ef87b734cb4a907",
    "semantic_title": "self-supervised rewiring of pre-trained speech encoders: towards faster fine-tuning with less labels in speech processing",
    "citation_count": 1,
    "authors": [
      "Hao Yang",
      "Jinming Zhao",
      "Gholamreza Haffari",
      "Ehsan Shareghi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.142": {
    "title": "RedApt: An Adaptor for wav2vec 2 EncodingFaster and Smaller Speech Translation without Quality Compromise",
    "volume": "findings",
    "abstract": "Pre-trained speech Transformers in speech translation (ST) have facilitated state-of-the-art (SotA) results; yet, using such encoders is computationally expensive. To improve this, we present a novel Reducer Adaptor block, RedApt, that could be seamlessly integrated within any Transformer-based speech encoding architecture. Integrating the pretrained wav2vec 2 speech encoder with RedAptbrings 41% speedup, 33% memory reduction with 24% fewer FLOPs at inference. To our positive surprise, our ST model with RedApt outperforms the SotA architecture by an average of 0.68 BLEU score on 8 language pairs from Must-C",
    "checked": true,
    "id": "8890487320f8e4d588cd344ab72a770042267b2b",
    "semantic_title": "redapt: an adaptor for wav2vec 2 encoding \\\\ faster and smaller speech translation without quality compromise",
    "citation_count": 2,
    "authors": [
      "Jinming Zhao",
      "Hao Yang",
      "Gholamreza Haffari",
      "Ehsan Shareghi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.143": {
    "title": "How sensitive are translation systems to extra contexts? Mitigating gender bias in Neural Machine Translation models through relevant contexts",
    "volume": "findings",
    "abstract": "Neural Machine Translation systems built on top of Transformer-based architectures are routinely improving the state-of-the-art in translation quality according to word-overlap metrics. However, a growing number of studies also highlight the inherent gender bias that these models incorporate during training, which reflects poorly in their translations. In this work, we investigate whether these models can be instructed to fix their bias during inference using targeted, guided instructions as contexts. By translating relevant contextual sentences during inference along with the input, we observe large improvements in reducing the gender bias in translations, across three popular test suites (WinoMT, BUG, SimpleGen). We further propose a novel metric to assess several large pre-trained models (OPUS-MT, M2M-100) on their sensitivity towards using contexts during translation to correct their biases. Our approach requires no fine-tuning, and thus can be used easily in production systems to de-bias translations from stereotypical gender-occupation bias. We hope our method, along with our metric, can be used to build better, bias-free translation systems",
    "checked": true,
    "id": "1ff7224423a72052eea7df484b3806e7bd6ec0a7",
    "semantic_title": "how sensitive are translation systems to extra contexts? mitigating gender bias in neural machine translation models through relevant contexts",
    "citation_count": 6,
    "authors": [
      "Shanya Sharma",
      "Manan Dey",
      "Koustuv Sinha"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.144": {
    "title": "PM2F2N: Patient Multi-view Multi-modal Feature Fusion Networks for Clinical Outcome Prediction",
    "volume": "findings",
    "abstract": "Clinical outcome prediction is critical to the condition prediction of patients and management of hospital capacities. There are two kinds of medical data, including time series signals recorded by various devices and clinical notes in electronic health records (EHR), which are used for two common prediction targets: mortality and length of stay. Traditional methods focused on utilizing time series data but ignored clinical notes. With the development of deep learning, natural language processing (NLP) and multi-modal learning methods are exploited to jointly model the time series and clinical notes with different modals. However, the existing methods failed to fuse the multi-modal features of patients from different views. Therefore, we propose the patient multi-view multi-modal feature fusion networks for clinical outcome prediction. Firstly, from patient inner view, we propose to utilize the co-attention module to enhance the fine-grained feature interaction between time series and clinical notes from each patient. Secondly, the patient outer view is the correlation between patients, which can be reflected by the structural knowledge in clinical notes. We exploit the structural information extracted from clinical notes to construct the patient correlation graph, and fuse patients' multi-modal features by graph neural networks (GNN). The experimental results on MIMIC-III benchmark demonstrate the superiority of our method",
    "checked": true,
    "id": "dd084562aeff4e565dbccc0954f65b00811e77d2",
    "semantic_title": "pm2f2n: patient multi-view multi-modal feature fusion networks for clinical outcome prediction",
    "citation_count": 3,
    "authors": [
      "Ying Zhang",
      "Baohang Zhou",
      "Kehui Song",
      "Xuhui Sui",
      "Guoqing Zhao",
      "Ning Jiang",
      "Xiaojie Yuan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.145": {
    "title": "Long Text and Multi-Table Summarization: Dataset and Method",
    "volume": "findings",
    "abstract": "Automatic document summarization aims to produce a concise summary covering the input document's salient information. Within a report document, the salient information can be scattered in the textual and non-textual content. However, existing document summarization datasets and methods usually focus on the text and filter out the non-textual content. Missing tabular data can limit produced summaries' informativeness, especially when summaries require covering quantitative descriptions of critical metrics in tables. Existing datasets and methods cannot meet the requirements of summarizing long text and multiple tables in each report. To deal with the scarcity of available data, we propose FINDSum, the first large-scale dataset for long text and multi-table summarization. Built on 21,125 annual reports from 3,794 companies, it has two subsets for summarizing each company's results of operations and liquidity. To summarize the long text and dozens of tables in each report, we present three types of summarization methods. Besides, we propose a set of evaluation metrics to assess the usage of numerical information in produced summaries. Dataset analyses and experimental results indicate the importance of jointly considering input textual and tabular data when summarizing report documents",
    "checked": true,
    "id": "7cf06701bb513e8f2a31fcea0cec6daa9926398b",
    "semantic_title": "long text and multi-table summarization: dataset and method",
    "citation_count": 4,
    "authors": [
      "Shuaiqi Liu",
      "Jiannong Cao",
      "Ruosong Yang",
      "Zhiyuan Wen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.146": {
    "title": "MatRank: Text Re-ranking by Latent Preference Matrix",
    "volume": "findings",
    "abstract": "Text ranking plays a key role in providing content that best answers user queries. It is usually divided into two sub-tasks to perform efficient information retrieval given a query: text retrieval and text re-ranking. Recent research on pretrained language models (PLM) has demonstrated efficiency and gain on both sub-tasks. However, while existing methods have benefited from pre-trained language models and achieved high recall rates on passage retrieval, the ranking performance still demands further improvement. In this paper, we propose MatRank, which learns to re-rank the text retrieved for a given query by learning to predict the most relevant passage based on a latent preference matrix. Specifically, MatRank uses a PLM to generate an asymmetric latent matrix of relative preference scores between all pairs of retrieved passages. Then, the latent matrix is aggregated row-wise and column-wise to obtain global preferences and predictions of the most relevant passage in two of these directions, respectively. We conduct extensive experiments on MS MACRO, WikiAQ, and SemEval datasets. Experimental results show that MatRank has achieved new state-of-the-art results on these datasets, outperforming all prior methods on ranking performance metrics",
    "checked": true,
    "id": "de998912dfac2a76c19c7758ef0a78cc689e97aa",
    "semantic_title": "matrank: text re-ranking by latent preference matrix",
    "citation_count": 0,
    "authors": [
      "Jinwen Luo",
      "Jiuding Yang",
      "Weidong Guo",
      "Chenglin Li",
      "Di Niu",
      "Yu Xu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.147": {
    "title": "Can Language Models Serve as Temporal Knowledge Bases?",
    "volume": "findings",
    "abstract": "Recent progress regarding the use of language models (LMs) as knowledge bases (KBs) has shown that language models can act as structured knowledge bases for storing relational facts. However, most existing works only considered the LM-as-KB paradigm in a static setting, which ignores the analysis of temporal dynamics of world knowledge. Furthermore, a basic function of KBs, i.e., the ability to store conflicting information (i.e., 1-N, N-1, and N-M relations), is underexplored. In this paper, we formulate two practical requirements for treating LMs as temporal KBs: (i) The capacity to store temporally-scoped knowledge that contains conflicting information and (ii) the ability to use stored knowledge for temporally-scoped knowledge queries. We introduce a new dataset called LAMA-TK which is aimed at probing temporally-scoped knowledge, and investigate the two above requirements to explore the LM-as-KB paradigm in the temporal domain. On the one hand, experiments show that LMs can memorize millions of temporally-scoped facts with relatively high accuracy and transfer stored knowledge to temporal knowledge queries, thereby expanding the LM-as-KB paradigm to the temporal domain. On the other hand, we show that memorizing conflicting information, which has been neglected by previous works, is still challenging for LMs and hinders the memorization of other unrelated one-to-one relationships",
    "checked": true,
    "id": "d1a1b713b7eb76bb8d1f58a50d8340dbb971cf36",
    "semantic_title": "can language models serve as temporal knowledge bases?",
    "citation_count": 3,
    "authors": [
      "Ruilin Zhao",
      "Feng Zhao",
      "Guandong Xu",
      "Sixiao Zhang",
      "Hai Jin"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.148": {
    "title": "Are Large Pre-Trained Language Models Leaking Your Personal Information?",
    "volume": "findings",
    "abstract": "Are Large Pre-Trained Language Models Leaking Your Personal Information? In this paper, we analyze whether Pre-Trained Language Models (PLMs) are prone to leaking personal information. Specifically, we query PLMs for email addresses with contexts of the email address or prompts containing the owner's name. We find that PLMs do leak personal information due to memorization. However, since the models are weak at association, the risk of specific personal information being extracted by attackers is low. We hope this work could help the community to better understand the privacy risk of PLMs and bring new insights to make PLMs safe",
    "checked": true,
    "id": "77d25889a59041629e8b2a81aad56544144c6878",
    "semantic_title": "are large pre-trained language models leaking your personal information?",
    "citation_count": 75,
    "authors": [
      "Jie Huang",
      "Hanyin Shao",
      "Kevin Chen-Chuan Chang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.149": {
    "title": "Self-Distillation with Meta Learning for Knowledge Graph Completion",
    "volume": "findings",
    "abstract": "In this paper, we propose a self-distillation framework with meta learning (MetaSD) for knowledge graph completion with dynamic pruning, which aims to learn compressed graph embeddings and tackle the long-tail samples. Specifically, we first propose a dynamic pruning technique to obtain a small pruned model from a large source model, where the pruning mask of the pruned model could be updated adaptively per epoch after the model weights are updated. The pruned model is supposed to be more sensitive to difficult-to-memorize samples (e.g., long-tail samples) than the source model. Then, we propose a one-step meta self-distillation method for distilling comprehensive knowledge from the source model to the pruned model, where the two models co-evolve in a dynamic manner during training. In particular, we exploit the performance of the pruned model, which is trained alongside the source model in one iteration, to improve the source model's knowledge transfer ability for the next iteration via meta learning. Extensive experiments show that MetaSD achieves competitive performance compared to strong baselines, while being 10x smaller than baselines",
    "checked": true,
    "id": "824a5b12c0454f32965fbdbb05c15a26d2cfc23d",
    "semantic_title": "self-distillation with meta learning for knowledge graph completion",
    "citation_count": 2,
    "authors": [
      "Yunshui Li",
      "Junhao Liu",
      "Min Yang",
      "Chengming Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.150": {
    "title": "CQR-SQL: Conversational Question Reformulation Enhanced Context-Dependent Text-to-SQL Parsers",
    "volume": "findings",
    "abstract": "Context-dependent text-to-SQL is the task of translating multi-turn questions into database-related SQL queries. Existing methods typically focus on making full use of history context or previously predicted SQL for currently SQL parsing, while neglecting to explicitly comprehend the schema and conversational dependency, such as co-reference, ellipsis and user focus change. In this paper, we propose CQR-SQL, which uses auxiliary Conversational Question Reformulation (CQR) learning to explicitly exploit schema and decouple contextual dependency for multi-turn SQL parsing. Specifically, we first present a schema enhanced recursive CQR method to produce domain-relevant self-contained questions. Secondly, we train CQR-SQL models to map the semantics of multi-turn questions and auxiliary self-contained questions into the same latent space through schema grounding consistency task and tree-structured SQL parsing consistency task, which enhances the abilities of SQL parsing by adequately contextual understanding. At the time of writing, our CQR-SQL achieves new state-of-the-art results on two context-dependent text-to-SQL benchmarks SParC and CoSQL",
    "checked": true,
    "id": "3fa26dac5909dd8b45c2fe1b430976ef2e8f5ff0",
    "semantic_title": "cqr-sql: conversational question reformulation enhanced context-dependent text-to-sql parsers",
    "citation_count": 9,
    "authors": [
      "Dongling Xiao",
      "LinZheng Chai",
      "Qian-Wen Zhang",
      "Zhao Yan",
      "Zhoujun Li",
      "Yunbo Cao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.151": {
    "title": "Assisting the Human Fact-Checkers: Detecting All Previously Fact-Checked Claims in a Document",
    "volume": "findings",
    "abstract": "Given the recent proliferation of false claims online, there has been a lot of manual fact-checking effort. As this is very time-consuming, human fact-checkers can benefit from tools that can support them and make them more efficient. Here, we focus on building a system that could provide such support. Given an input document, it aims to detect all sentences that contain a claim that can be verified by some previously fact-checked claims (from a given database). The output is a re-ranked list of the document sentences, so that those that can be verified are ranked as high as possible, together with corresponding evidence. Unlike previous work, which has looked into claim retrieval, here we take a document-level perspective. We create a new manually annotated dataset for the task, and we propose suitable evaluation measures. We further experiment with a learning-to-rank approach, achieving sizable performance gains over several strong baselines. Our analysis demonstrates the importance of modeling text similarity and stance, while also taking into account the veracity of the retrieved previously fact-checked claims. We believe that this research would be of interest to fact-checkers, journalists, media, and regulatory authorities",
    "checked": true,
    "id": "83329243f7d938368c1f87334bd08986affcc858",
    "semantic_title": "assisting the human fact-checkers: detecting all previously fact-checked claims in a document",
    "citation_count": 21,
    "authors": [
      "Shaden Shaar",
      "Nikola Georgiev",
      "Firoj Alam",
      "Giovanni Da San Martino",
      "Aisha Mohamed",
      "Preslav Nakov"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.152": {
    "title": "No Word Embedding Model Is Perfect: Evaluating the Representation Accuracy for Social Bias in the Media",
    "volume": "findings",
    "abstract": "News articles both shape and reflect public opinion across the political spectrum. Analyzing them for social bias can thus provide valuable insights, such as prevailing stereotypes in society and the media, which are often adopted by NLP models trained on respective data. Recent work has relied on word embedding bias measures, such as WEAT. However, several representation issues of embeddings can harm the measures' accuracy, including low-resource settings and token frequency differences. In this work, we study what kind of embedding algorithm serves best to accurately measure types of social bias known to exist in US online news articles. To cover the whole spectrum of political bias in the US, we collect 500k articles and review psychology literature with respect to expected social bias. We then quantify social bias using WEAT along with embedding algorithms that account for the aforementioned issues. We compare how models trained with the algorithms on news articles represent the expected social bias. Our results suggest that the standard way to quantify bias does not align well with knowledge from psychology. While the proposed algorithms reduce the gap, they still do not fully match the literature",
    "checked": true,
    "id": "a261dbc155c5bb5c99201f757e3d2dab1b3dcc58",
    "semantic_title": "no word embedding model is perfect: evaluating the representation accuracy for social bias in the media",
    "citation_count": 3,
    "authors": [
      "Maximilian Spliethöver",
      "Maximilian Keiff",
      "Henning Wachsmuth"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.153": {
    "title": "Scientific and Creative Analogies in Pretrained Language Models",
    "volume": "findings",
    "abstract": "This paper examines the encoding of analogy in large-scale pretrained language models, such as BERT and GPT-2. Existing analogy datasets typically focus on a limited set of analogical relations, with a high similarity of the two domains between which the analogy holds. As a more realistic setup, we introduce the Scientific and Creative Analogy dataset (SCAN), a novel analogy dataset containing systematic mappings of multiple attributes and relational structures across dissimilar domains. Using this dataset, we test the analogical reasoning capabilities of several widely-used pretrained language models (LMs). We find that state-of-the-art LMs achieve low performance on these complex analogy tasks, highlighting the challenges still posed by analogy understanding",
    "checked": true,
    "id": "933f60dda5847f208d9d3fd65e9b0df9cfed2403",
    "semantic_title": "scientific and creative analogies in pretrained language models",
    "citation_count": 7,
    "authors": [
      "Tamara Czinczoll",
      "Helen Yannakoudakis",
      "Pushkar Mishra",
      "Ekaterina Shutova"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.154": {
    "title": "Bitext Mining Using Distilled Sentence Representations for Low-Resource Languages",
    "volume": "findings",
    "abstract": "Scaling multilingual representation learning beyond the hundred most frequent languages is challenging, in particular to cover the long tail of low-resource languages. We move away from the popular one-for-all multilingual models and focus on training multiple language (family) specific representations, but most prominently enable all languages to still be encoded in the same representational space. We focus on teacher-student training, allowing all encoders to be mutually compatible for bitext mining, and enabling fast learning of new languages. We also combine supervised and self-supervised training, allowing encoders to take advantage of monolingual training data. Our approach significantly outperforms the original LASER encoder. We study very low-resource languages and handle 44 African languages, many of which are not covered by any other model. For these languages, we train sentence encoders and mine bitexts. Adding these mined bitexts yielded an improvement of 3.8 BLEU for NMT into English",
    "checked": true,
    "id": "2cacc556ca3f362b09e22b875abffc35a7073fee",
    "semantic_title": "bitext mining using distilled sentence representations for low-resource languages",
    "citation_count": 33,
    "authors": [
      "Kevin Heffernan",
      "Onur Çelebi",
      "Holger Schwenk"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.155": {
    "title": "Towards Generalizable and Robust Text-to-SQL Parsing",
    "volume": "findings",
    "abstract": "Text-to-SQL parsing tackles the problem of mapping natural language questions to executable SQL queries. In practice, text-to-SQL parsers often encounter various challenging scenarios, requiring them to be generalizable and robust. While most existing work addresses a particular generalization or robustness challenge, we aim to study it in a more comprehensive manner. In specific, we believe that text-to-SQL parsers should be (1) generalizable at three levels of generalization, namely i.i.d., zero-shot, and compositional, and (2) robust against input perturbations. To enhance these capabilities of the parser, we propose a novel TKK framework consisting of Task decomposition, Knowledge acquisition, and Knowledge composition to learn text-to-SQL parsing in stages. By dividing the learning process into multiple stages, our framework improves the parser's ability to acquire general SQL knowledge instead of capturing spurious patterns, making it more generalizable and robust. Experimental results under various generalization and robustness settings show that our framework is effective in all scenarios and achieves state-of-the-art performance on the Spider, SParC, and CoSQL datasets",
    "checked": true,
    "id": "7e942e813e3fb814f2d0b997ae849548a9e40638",
    "semantic_title": "towards generalizable and robust text-to-sql parsing",
    "citation_count": 5,
    "authors": [
      "Chang Gao",
      "Bowen Li",
      "Wenxuan Zhang",
      "Wai Lam",
      "Binhua Li",
      "Fei Huang",
      "Luo Si",
      "Yongbin Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.156": {
    "title": "EdiT5: Semi-Autoregressive Text Editing with T5 Warm-Start",
    "volume": "findings",
    "abstract": "We present EdiT5 - a novel semi-autoregressive text-editing approach designed to combine the strengths of non-autoregressive text-editing and autoregressive decoding. EdiT5 is faster at inference times than conventional sequence-to-sequence (seq2seq) models, while being capable of modeling flexible input-output transformations. This is achieved by decomposing the generation process into three sub-tasks: (1) tagging to decide on the subset of input tokens to be preserved in the output, (2) re-ordering to define their order in the output text, and (3) insertion to infill the missing tokens that are not present in the input. The tagging and re-ordering steps, which are responsible for generating the largest portion of the output, are non-autoregressive, while the insertion uses an autoregressive decoder. Depending on the task, EdiT5 requires significantly fewer autoregressive steps demonstrating speedups of up to 25x when compared to classic seq2seq models. Quality-wise, EdiT5 is initialized with a pre-trained T5 checkpoint yielding comparable performance to T5 in high-resource settings and clearly outperforms it on low-resource settings when evaluated on three NLG tasks: Sentence Fusion, Grammatical Error Correction, and Decontextualization",
    "checked": true,
    "id": "8ba66cb690ff3a37c63ff0f67b595f03dd78dc75",
    "semantic_title": "edit5: semi-autoregressive text-editing with t5 warm-start",
    "citation_count": 35,
    "authors": [
      "Jonathan Mallinson",
      "Jakub Adamek",
      "Eric Malmi",
      "Aliaksei Severyn"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.157": {
    "title": "A Critical Reflection and Forward Perspective on Empathy and Natural Language Processing",
    "volume": "findings",
    "abstract": "We review the state of research on empathy in natural language processing and identify the following issues: (1) empathy definitions are absent or abstract, which (2) leads to low construct validity and reproducibility. Moreover, (3) emotional empathy is overemphasized, skewing our focus to a narrow subset of simplified tasks. We believe these issues hinder research progress and argue that current directions will benefit from a clear conceptualization that includes operationalizing cognitive empathy components. Our main objectives are to provide insight and guidance on empathy conceptualization for NLP research objectives and to encourage researchers to pursue the overlooked opportunities in this area, highly relevant, e.g., for clinical and educational sectors",
    "checked": true,
    "id": "52944c0e4ffe8eb05eac366a2c111ad608abd8a8",
    "semantic_title": "a critical reflection and forward perspective on empathy and natural language processing",
    "citation_count": 4,
    "authors": [
      "Allison Lahnala",
      "Charles Welch",
      "David Jurgens",
      "Lucie Flek"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.158": {
    "title": "A Neural-Symbolic Approach to Natural Language Understanding",
    "volume": "findings",
    "abstract": "Deep neural networks, empowered by pre-trained language models, have achieved remarkable results in natural language understanding (NLU) tasks. However, their performances can drastically deteriorate when logical reasoning is needed. This is because NLU in principle depends on not only analogical reasoning, which deep neural networks are good at, but also logical reasoning. According to the dual-process theory, analogical reasoning and logical reasoning are respectively carried out by System 1 and System 2 in the human brain. Inspired by the theory, we present a novel framework for NLU called Neural-Symbolic Processor (NSP), which performs analogical reasoning based on neural processing and logical reasoning based on both neural and symbolic processing. As a case study, we conduct experiments on two NLU tasks, question answering (QA) and natural language inference (NLI), when numerical reasoning (a type of logical reasoning) is necessary. The experimental results show that our method significantly outperforms state-of-the-art methods in both tasks",
    "checked": true,
    "id": "51571ce19e5e5af308acfeb62320581440926a38",
    "semantic_title": "a neural-symbolic approach to natural language understanding",
    "citation_count": 3,
    "authors": [
      "Zhixuan Liu",
      "Zihao Wang",
      "Yuan Lin",
      "Hang Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.159": {
    "title": "Social-aware Sparse Attention Network for Session-based Social Recommendation",
    "volume": "findings",
    "abstract": "Session-based Social Recommendation (SSR) aims to use users' social networks and historical sessions to provide more personalized recommendations for the current session. Unfortunately, existing SSR methods have two limitations. First, they do not screen users' useless social relationships and noisy irrelevant interactions. However, user preferences are mainly affected by several close friends and key interactions. Second, when modeling the current session, they do not take full advantage of user preference information. To tackle these issues, we propose a novel Social-aware Sparse Attention Network for SSR, abbreviated as SSAN.It mainly consists of the Heterogeneous Graph Embedding (HGE) module and the Social-aware Encoder-decoder Network (SEN) module. In the HGE module, we adopt a modified heterogeneous graph neural network, which focuses more on close friends and key historical interactions, to enhance user/item representations. In the SEN module, we use the user representation as a bridge between the Encoder and Decoder to incorporate user preferences when modeling the current session. Extensive experiments on two benchmark datasets demonstrate the superiority of SSAN over the state-of-the-art models",
    "checked": true,
    "id": "2c68e93831082b53b4935654474d4265cd702f4a",
    "semantic_title": "social-aware sparse attention network for session-based social recommendation",
    "citation_count": 2,
    "authors": [
      "Kai Ouyang",
      "Xianghong Xu",
      "Chen Tang",
      "Wang Chen",
      "Haitao Zheng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.160": {
    "title": "SparseAdapter: An Easy Approach for Improving the Parameter-Efficiency of Adapters",
    "volume": "findings",
    "abstract": "Adapter Tuning, which freezes the pretrained language models (PLMs) and only fine-tunes a few extra modules, becomes an appealing efficient alternative to the full model fine-tuning. Although computationally efficient, the recent Adapters often increase parameters (e.g. bottleneck dimension) for matching the performance of full model fine-tuning, which we argue goes against their original intention. In this work, we re-examine the parameter-efficiency of Adapter through the lens of network pruning (we name such plug-in concept as SparseAdapter) and find that SparseAdapter can achieve comparable or better performance than standard Adapters when the sparse ratio reaches up to 80%. Based on our findings, we introduce an easy but effective setting \"Large-Sparse\" to improve the model capacity of Adapters under the same parameter budget. Experiments on five competitive Adapters upon three advanced PLMs show that with proper sparse method (e.g. SNIP) and ratio (e.g. 40%) SparseAdapter can consistently outperform their corresponding counterpart. Encouragingly, with the Large-Sparse setting, we can obtain further appealing gains, even outperforming the full fine-tuning by a large margin",
    "checked": true,
    "id": "7bd551537b67a31a733ac12a8de69968bc190f66",
    "semantic_title": "sparseadapter: an easy approach for improving the parameter-efficiency of adapters",
    "citation_count": 39,
    "authors": [
      "Shwai He",
      "Liang Ding",
      "Daize Dong",
      "Jeremy Zhang",
      "Dacheng Tao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.161": {
    "title": "Measurement Extraction with Natural Language Processing: A Review",
    "volume": "findings",
    "abstract": "Quantitative data is important in many domains. Information extraction methods draw structured data from documents. However, the extraction of quantities and their contexts has received little attention in the history of information extraction. In this review, an overview of prior work on measurement extraction is presented. We describe different approaches to measurement extraction and outline the challenges posed by this task. The review concludes with an outline of potential future research. Research strains in measurement extraction tend to be isolated and lack a common terminology. Improvements in numerical reasoning, more extensive datasets, and the consideration of wider contexts may lead to significant improvements in measurement extraction",
    "checked": true,
    "id": "5df55d94ab5026ff84ec01871592108fbadbddbe",
    "semantic_title": "measurement extraction with natural language processing: a review",
    "citation_count": 3,
    "authors": [
      "Jan Göpfert",
      "Patrick Kuckertz",
      "Jann Weinand",
      "Leander Kotzur",
      "Detlef Stolten"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.162": {
    "title": "Summarizing Procedural Text: Data and Approach",
    "volume": "findings",
    "abstract": "Procedural text is a widely used genre that contains many steps of instructions of how to cook a dish or how to conduct a chemical experiment and analyze the procedural text has become a popular task in the NLP field. Since the procedural text can be very long and contains many details, summarizing the whole procedural text or giving an overview for each complicated procedure step can save time for readers and help them to capture the core information in the text. In this paper, we propose the procedural text summarization task with two summarization granularity: step-view and global-view, which summarizes each step in the procedural text separately or gives an overall summary for all steps respectively. To tackle this task, we propose an Entity-State Graph-based Summarizer (ESGS) which is based on state-of-the-art entity state tracking methods and constructs a heterogeneous graph to aggregate contextual information for each procedure. In order to help the summarization model focus on the salient entities, we propose to use the contextualized procedure graph representation to predict the salient entities. Experiments conducted on two datasets verify the effectiveness of our proposed model. Our code and datasets will be released on https://github.com/gsh199449/procedural-summ",
    "checked": true,
    "id": "0c77388eebf63f3487f64f5204736f130618d46c",
    "semantic_title": "summarizing procedural text: data and approach",
    "citation_count": 1,
    "authors": [
      "Shen Gao",
      "Haotong Zhang",
      "Xiuying Chen",
      "Rui Yan",
      "Dongyan Zhao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.163": {
    "title": "Snapshot-Guided Domain Adaptation for ELECTRA",
    "volume": "findings",
    "abstract": "Discriminative pre-trained language models, such as ELECTRA, have achieved promising performances in a variety of general tasks. However, these generic pre-trained models struggle to capture domain-specific knowledge of domain-related tasks. In this work, we propose a novel domain-adaptation method for ELECTRA, which can dynamically select domain-specific tokens and guide the discriminator to emphasize them, without introducing new training parameters. We show that by re-weighting the losses of domain-specific tokens, ELECTRA can be effectively adapted to different domains. The experimental results in both computer science and biomedical domains show that the proposed method can achieve state-of-the-art results on the domain-related tasks",
    "checked": true,
    "id": "423a388c6b394eae2440d8b8c738db4550f2bb67",
    "semantic_title": "snapshot-guided domain adaptation for electra",
    "citation_count": 1,
    "authors": [
      "Daixuan Cheng",
      "Shaohan Huang",
      "Jianfeng Liu",
      "Yuefeng Zhan",
      "Hao Sun",
      "Furu Wei",
      "Denvy Deng",
      "Qi Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.164": {
    "title": "Exploiting Labeled and Unlabeled Data via Transformer Fine-tuning for Peer-Review Score Prediction",
    "volume": "findings",
    "abstract": "Automatic Peer-review Aspect Score Prediction (PASP) of academic papers can be a helpful assistant tool for both reviewers and authors. Most existing works on PASP utilize supervised learning techniques. However, the limited number of peer-review data deteriorates the performance of PASP. This paper presents a novel semi-supervised learning (SSL) method that incorporates the Transformer fine-tuning into the Γ-model, a variant of the Ladder network, to leverage contextual features from unlabeled data. Backpropagation simultaneously minimizes the sum of supervised and unsupervised cost functions, avoiding the need for layer-wise pre-training. The experimental results show that our model outperforms the supervised and naive semi-supervised learning baselines. Our source codes are available online",
    "checked": true,
    "id": "230748239d5c50f075d96fbd4b49f00d8fd5c72d",
    "semantic_title": "exploiting labeled and unlabeled data via transformer fine-tuning for peer-review score prediction",
    "citation_count": 2,
    "authors": [
      "Panitan Muangkammuen",
      "Fumiyo Fukumoto",
      "Jiyi Li",
      "Yoshimi Suzuki"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.165": {
    "title": "HARALD: Augmenting Hate Speech Data Sets with Real Data",
    "volume": "findings",
    "abstract": "The successful completion of the hate speech detection task hinges upon the availability of rich and variable labeled data, which is hard to obtain. In this work, we present a new approach for data augmentation that uses as input real unlabelled data, which is carefully selected from online platforms where invited hate speech is abundant. We show that by harvesting and processing this data (in an automatic manner), one can augment existing manually-labeled datasets to improve the classification performance of hate speech classification models. We observed an improvement in F1-score ranging from 2.7% and up to 9.5%, depending on the task (in- or cross-domain) and the model used",
    "checked": true,
    "id": "b8fe3ce6daa184bcc9df44c52ac83160ef1373a6",
    "semantic_title": "harald: augmenting hate speech data sets with real data",
    "citation_count": 2,
    "authors": [
      "Tal Ilan",
      "Dan Vilenchik"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.166": {
    "title": "Wait-info Policy: Balancing Source and Target at Information Level for Simultaneous Machine Translation",
    "volume": "findings",
    "abstract": "Simultaneous machine translation (SiMT) outputs the translation while receiving the source inputs, and hence needs to balance the received source information and translated target information to make a reasonable decision between waiting for inputs or outputting translation. Previous methods always balance source and target information at the token level, either directly waiting for a fixed number of tokens or adjusting the waiting based on the current token. In this paper, we propose a Wait-info Policy to balance source and target at the information level. We first quantify the amount of information contained in each token, named info. Then during simultaneous translation, the decision of waiting or outputting is made based on the comparison results between the total info of previous target outputs and received source inputs. Experiments show that our method outperforms strong baselines under and achieves better balance via the proposed info",
    "checked": true,
    "id": "902f4adc08bf44bfafb58cf69ce41deb8a061809",
    "semantic_title": "wait-info policy: balancing source and target at information level for simultaneous machine translation",
    "citation_count": 17,
    "authors": [
      "Shaolei Zhang",
      "Shoutao Guo",
      "Yang Feng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.167": {
    "title": "Turning Fixed to Adaptive: Integrating Post-Evaluation into Simultaneous Machine Translation",
    "volume": "findings",
    "abstract": "Simultaneous machine translation (SiMT) starts its translation before reading the whole source sentence and employs either fixed or adaptive policy to generate the target sentence. Compared to the fixed policy, the adaptive policy achieves better latency-quality tradeoffs by adopting a flexible translation policy. If the policy can evaluate rationality before taking action, the probability of incorrect actions will also decrease. However, previous methods lack evaluation of actions before taking them. In this paper, we propose a method of performing the adaptive policy via integrating post-evaluation into the fixed policy. Specifically, whenever a candidate token is generated, our model will evaluate the rationality of the next action by measuring the change in the source content. Our model will then take different actions based on the evaluation results. Experiments on three translation tasks show that our method can exceed strong baselines under all latency",
    "checked": true,
    "id": "4afef2ea406e6c789de1609100d2350bcd71c586",
    "semantic_title": "turning fixed to adaptive: integrating post-evaluation into simultaneous machine translation",
    "citation_count": 11,
    "authors": [
      "Shoutao Guo",
      "Shaolei Zhang",
      "Yang Feng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.168": {
    "title": "Alleviating Sparsity of Open Knowledge Graphs with Ternary Contrastive Learning",
    "volume": "findings",
    "abstract": "Sparsity of formal knowledge and roughness of non-ontological construction make sparsity problem particularly prominent in Open Knowledge Graphs (OpenKGs). Due to sparse links, learning effective representation for few-shot entities becomes difficult. We hypothesize that by introducing negative samples, a contrastive learning (CL) formulation could be beneficial in such scenarios. However, existing CL methods model KG triplets as binary objects of entities ignoring the relation-guided ternary propagation patterns and they are too generic, i.e., they ignore zero-shot, few-shot and synonymity problems that appear in OpenKGs. To address this, we propose TernaryCL, a CL framework based on ternary propagation patterns among head, relation and tail. TernaryCL designs Contrastive Entity and Contrastive Relation to mine ternary discriminative features with both negative entities and relations, introduces Contrastive Self to help zero- and few-shot entities learn discriminative features, Contrastive Synonym to model synonymous entities, and Contrastive Fusion to aggregate graph features from multiple paths. Extensive experiments on benchmarks demonstrate the superiority of TernaryCL over state-of-the-art models",
    "checked": true,
    "id": "a80cd69bec615984b4eab7f55026fabffd315d3b",
    "semantic_title": "alleviating sparsity of open knowledge graphs with ternary contrastive learning",
    "citation_count": 2,
    "authors": [
      "Qian Li",
      "Shafiq Joty",
      "Daling Wang",
      "Shi Feng",
      "Yifei Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.169": {
    "title": "Using Developer Discussions to Guide Fixing Bugs in Software",
    "volume": "findings",
    "abstract": "Automatically fixing software bugs is a challenging task. While recent work showed that natural language context is useful in guiding bug-fixing models, the approach required prompting developers to provide this context, which was simulated through commit messages written after the bug-fixing code changes were made. We instead propose using bug report discussions, which are available before the task is performed and are also naturally occurring, avoiding the need for any additional information from developers. For this, we augment standard bug-fixing datasets with bug report discussions. Using these newly compiled datasets, we demonstrate that various forms of natural language context derived from such discussions can aid bug-fixing, even leading to improved performance over using commit messages corresponding to the oracle bug-fixing commits",
    "checked": true,
    "id": "12dfc100cdd3bf44c0e63dcca83f1d2fff5d9ab0",
    "semantic_title": "using developer discussions to guide fixing bugs in software",
    "citation_count": 2,
    "authors": [
      "Sheena Panthaplackel",
      "Milos Gligoric",
      "Junyi Jessy Li",
      "Raymond Mooney"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.170": {
    "title": "AutoCAD: Automatically Generate Counterfactuals for Mitigating Shortcut Learning",
    "volume": "findings",
    "abstract": "Recent studies have shown the impressive efficacy of counterfactually augmented data (CAD) for reducing NLU models' reliance on spurious features and improving their generalizability. However, current methods still heavily rely on human efforts or task-specific designs to generate counterfactuals, thereby impeding CAD's applicability to a broad range of NLU tasks. In this paper, we present AutoCAD, a fully automatic and task-agnostic CAD generation framework. AutoCAD first leverages a classifier to unsupervisedly identify rationales as spans to be intervened, which disentangles spurious and causal features. Then, AutoCAD performs controllable generation enhanced by unlikelihood training to produce diverse counterfactuals. Extensive evaluations on multiple out-of-domain and challenge benchmarks demonstrate that AutoCAD consistently and significantly boosts the out-of-distribution performance of powerful pre-trained models across different NLU tasks, which is comparable or even better than previous state-of-the-art human-in-the-loop or task-specific CAD methods",
    "checked": true,
    "id": "9d297f865c3f3b5870825e1386d3671eb56d6917",
    "semantic_title": "autocad: automatically generating counterfactuals for mitigating shortcut learning",
    "citation_count": 2,
    "authors": [
      "Jiaxin Wen",
      "Yeshuang Zhu",
      "Jinchao Zhang",
      "Jie Zhou",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.171": {
    "title": "A Multi-Modal Knowledge Graph for Classical Chinese Poetry",
    "volume": "findings",
    "abstract": "Classical Chinese poetry has a long history and is a precious cultural heritage of humankind. Displaying the classical Chinese poetry in a visual way, helps to cross cultural barriers in different countries, making it enjoyable for all the people. In this paper, we construct a multi-modal knowledge graph for classical Chinese poetry (PKG), in which the visual information of words in the poetry are incorporated. Then a multi-modal pre-training language model, PKG-Bert, is proposed to obtain the poetry representation with visual information, which bridges the semantic gap between different modalities. PKG-Bert achieves the state-of-the-art performance on the poetry-image retrieval task, showing the effectiveness of incorporating the multi-modal knowledge. The large-scale multi-modal knowledge graph of classical Chinese poetry will be released to promote the researches in classical Chinese culture area",
    "checked": true,
    "id": "94acf4682bce44810c377be075c20dd6de96b8e5",
    "semantic_title": "a multi-modal knowledge graph for classical chinese poetry",
    "citation_count": 1,
    "authors": [
      "Yuqing Li",
      "Yuxin Zhang",
      "Bin Wu",
      "Ji-Rong Wen",
      "Ruihua Song",
      "Ting Bai"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.172": {
    "title": "Assessing Non-autoregressive Alignment in Neural Machine Translation via Word Reordering",
    "volume": "findings",
    "abstract": "Recent work on non-autoregressive neural machine translation (NAT) that leverages alignment information to explicitly reduce the modality of target distribution has reported comparable performance with counterparts that tackle multi-modality problem by implicitly modeling dependencies. Effectiveness in handling alignment is vital for models that follow this approach, where a token reordering mechanism is typically involved and plays a vital role. We review the reordering capability of the respective mechanisms in recent NAT models, and our experimental results show that their performance is sub-optimal. We propose to learn a non-autoregressive language model (NALM) based on transformer which can be combined with Viterbi decoding to achieve better reordering performance. We evaluate the proposed NALM using the PTB dataset where sentences with words permuted in different ways are expected to have their ordering recovered. Our empirical results show that the proposed method can outperform the state-of-the-art reordering mechanisms under different word permutation settings, with a 2-27 BLEU improvement, suggesting high potential for word alignment in NAT",
    "checked": true,
    "id": "bf7cf401cc67ce225f72238ac7f1377aa685df12",
    "semantic_title": "assessing non-autoregressive alignment in neural machine translation via word reordering",
    "citation_count": 0,
    "authors": [
      "Chun-Hin Tse",
      "Ester Leung",
      "William K. Cheung"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.173": {
    "title": "Syntax-guided Localized Self-attention by Constituency Syntactic Distance",
    "volume": "findings",
    "abstract": "Recent works have revealed that Transformers are implicitly learning the syntactic information in its lower layers from data, albeit is highly dependent on the quality and scale of the training data. However, learning syntactic information from data is not necessary if we can leverage an external syntactic parser, which provides better parsing quality with well-defined syntactic structures. This could potentially improve Transformer's performance and sample efficiency. In this work, we propose a syntax-guided localized self-attention for Transformer that allows directly incorporating grammar structures from an external constituency parser. It prohibits the attention mechanism to overweight the grammatically distant tokens over close ones. Experimental results show that our model could consistently improve translation performance on a variety of machine translation datasets, ranging from small to large dataset sizes, and with different source languages",
    "checked": true,
    "id": "50e6b4e452107799cd775b0b0f6726d44173d564",
    "semantic_title": "syntax-guided localized self-attention by constituency syntactic distance",
    "citation_count": 1,
    "authors": [
      "Shengyuan Hou",
      "Jushi Kai",
      "Haotian Xue",
      "Bingyu Zhu",
      "Bo Yuan",
      "Longtao Huang",
      "Xinbing Wang",
      "Zhouhan Lin"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.174": {
    "title": "CodeExp: Explanatory Code Document Generation",
    "volume": "findings",
    "abstract": "Developing models that can automatically generate detailed code explanation can greatly benefit software maintenance and programming education. However, existing code-to-text generation models often produce only high-level summaries of code that do not capture implementation-level choices essential for these scenarios. To fill in this gap, we propose the code explanation generation task. We first conducted a human study to identify the criteria for high-quality explanatory docstring for code. Based on that, we collected and refined a large-scale code docstring corpus and formulated automatic evaluation metrics that best match human assessments. Finally, we present a multi-stage fine-tuning strategy and baseline models for the task. Our experiments show that (1) our refined training dataset lets models achieve better performance in the explanation generation tasks compared to larger-scale unrefined data (15x larger), and (2) fine-tuned models can generate well-structured long docstrings comparable to human-written ones. We envision our training dataset, human-evaluation protocol, recommended metrics, and fine-tuning strategy can boost future code explanation research. The code and annotated data are available at https://github.com/subercui/CodeExp",
    "checked": true,
    "id": "8aa23a86603f7dd4eceda3d2e0337ba90dff7f4f",
    "semantic_title": "codeexp: explanatory code document generation",
    "citation_count": 1,
    "authors": [
      "Haotian Cui",
      "Chenglong Wang",
      "Junjie Huang",
      "Jeevana Priya Inala",
      "Todd Mytkowicz",
      "Bo Wang",
      "Jianfeng Gao",
      "Nan Duan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.175": {
    "title": "PAUQ: Text-to-SQL in Russian",
    "volume": "findings",
    "abstract": "Semantic parsing is an important task that allows to democratize human-computer interaction. One of the most popular text-to-SQL datasets with complex and diverse natural language (NL) questions and SQL queries is Spider. We construct and complement a Spider dataset for Russian, thus creating the first publicly available text-to-SQL dataset for this language. While examining its components - NL questions, SQL queries and databases content - we identify limitations of the existing database structure, fill out missing values for tables and add new requests for underrepresented categories. We select thirty functional test sets with different features that can be used for the evaluation of neural models' abilities. To conduct the experiments, we adapt baseline architectures RAT-SQL and BRIDGE and provide in-depth query component analysis. On the target language, both models demonstrate strong results with monolingual training and improved accuracy in multilingual scenario. In this paper, we also study trade-offs between machine-translated and manually-created NL queries. At present, Russian text-to-SQL is lacking in datasets as well as trained models, and we view this work as an important step towards filling this gap",
    "checked": true,
    "id": "9da122c8a3a3d754552cc0d2953658ce63b72060",
    "semantic_title": "pauq: text-to-sql in russian",
    "citation_count": 1,
    "authors": [
      "Daria Bakshandaeva",
      "Oleg Somov",
      "Ekaterina Dmitrieva",
      "Vera Davydova",
      "Elena Tutubalina"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.176": {
    "title": "Event-Centric Question Answering via Contrastive Learning and Invertible Event Transformation",
    "volume": "findings",
    "abstract": "Human reading comprehension often requires reasoning of event semantic relations in narratives, represented by Event-centric Question-Answering (QA). To address event-centric QA, we propose a novel QA model with contrastive learning and invertible event transformation, call TranCLR. Our proposed model utilizes an invertible transformation matrix to project semantic vectors of events into a common event embedding space, trained with contrastive learning, and thus naturally inject event semantic knowledge into mainstream QA pipelines. The transformation matrix is fine-tuned with the annotated event relation types between events that occurred in questions and those in answers, using event-aware question vectors. Experimental results on the Event Semantic Relation Reasoning (ESTER) dataset show significant improvements in both generative and extractive settings compared to the existing strong baselines, achieving over 8.4% gain in the token-level F1 score and 3.0% gain in Exact Match (EM) score under the multi-answer setting. Qualitative analysis reveals the high quality of the generated answers by TranCLR, demonstrating the feasibility of injecting event knowledge into QA model learning. Our code and models can be found at https://github.com/LuJunru/TranCLR",
    "checked": true,
    "id": "0b0fb5b834d16400b922110daeb02b764fb9ef6f",
    "semantic_title": "event-centric question answering via contrastive learning and invertible event transformation",
    "citation_count": 6,
    "authors": [
      "Junru Lu",
      "Xingwei Tan",
      "Gabriele Pergola",
      "Lin Gui",
      "Yulan He"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.177": {
    "title": "Label-Driven Denoising Framework for Multi-Label Few-Shot Aspect Category Detection",
    "volume": "findings",
    "abstract": "Multi-Label Few-Shot Aspect Category Detection (FS-ACD) is a new sub-task of aspect-based sentiment analysis, which aims to detect aspect categories accurately with limited training instances. Recently, dominant works use the prototypical network to accomplish this task, and employ the attention mechanism to extract keywords of aspect category from the sentences to produce the prototype for each aspect. However, they still suffer from serious noise problems: (1) due to lack of sufficient supervised data, the previous methods easily catch noisy words irrelevant to the current aspect category, which largely affects the quality of the generated prototype; (2) the semantically-close aspect categories usually generate similar prototypes, which are mutually noisy and confuse the classifier seriously. In this paper, we resort to the label information of each aspect to tackle the above problems, along with proposing a novel Label-Driven Denoising Framework (LDF). Extensive experimental results show that our framework achieves better performance than other state-of-the-art methods",
    "checked": true,
    "id": "1b40defa78efe53e90ef1b724b18a02405b4f653",
    "semantic_title": "label-driven denoising framework for multi-label few-shot aspect category detection",
    "citation_count": 6,
    "authors": [
      "Fei Zhao",
      "Yuchen Shen",
      "Zhen Wu",
      "Xinyu Dai"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.178": {
    "title": "Visual Named Entity Linking: A New Dataset and A Baseline",
    "volume": "findings",
    "abstract": "Visual Entity Linking (VEL) is a task to link regions of images with their corresponding entities in Knowledge Bases (KBs), which is beneficial for many computer vision tasks such as image retrieval, image caption, and visual question answering. While existing tasks in VEL either rely on textual data to complement a multi-modal linking or only link objects with general entities, which fails to perform named entity linking on large amounts of image data. In this paper, we consider a purely Visual-based Named Entity Linking (VNEL) task, where the input only consists of an image. The task is to identify objects of interest (i.e., visual entity mentions) in images and link them to corresponding named entities in KBs. Since each entity often contains rich visual and textual information in KBs, we thus propose three different sub-tasks, i.e., visual to visual entity linking (V2VEL), visual to textual entity linking (V2TEL), and visual to visual-textual entity linking (V2VTEL). In addition, we present a high-quality human-annotated visual person linking dataset, named WIKIPerson. Based on WIKIPerson, we establish a series of baseline algorithms for the solution of each sub-task, and conduct experiments to verify the quality of the proposed datasets and the effectiveness of baseline methods. We envision this work to be helpful for soliciting more works regarding VNEL in the future. The codes and datasets are publicly available at https: //github.com/ict-bigdatalab/VNEL",
    "checked": true,
    "id": "c0bb6496edb5ddf30713cdb425b7c3e4205f6ae3",
    "semantic_title": "visual named entity linking: a new dataset and a baseline",
    "citation_count": 8,
    "authors": [
      "Wen Sun",
      "Yixing Fan",
      "Jiafeng Guo",
      "Ruqing Zhang",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.179": {
    "title": "MAGMA – Multimodal Augmentation of Generative Models through Adapter-based Finetuning",
    "volume": "findings",
    "abstract": "Large-scale pretraining is fast becoming the norm in Vision-Language (VL) modeling. However, prevailing VL approaches are limited by the requirement for labeled data and the use of complex multi-step pretraining objectives. We present MAGMA - a simple method for augmenting generative language models with additional modalities using adapter-based finetuning. Building on Frozen, we train a series of VL models that autoregressively generate text from arbitrary combinations of visual and textual input. The pretraining is entirely end-to-end using a single language modeling objective, simplifying optimization compared to previous approaches. Importantly, the language model weights remain unchanged during training, allowing for transfer of encyclopedic knowledge and in-context learning abilities from language pretraining. MAGMA outperforms Frozen on open-ended generative tasks, achieving state of the art results on the OKVQA benchmark and competitive results on a range of other popular VL benchmarks, while pretraining on 0.2 % of the number of samples used to train SimVLM",
    "checked": true,
    "id": "bdea16e93fc70f316002e5f6aac8ce17388c6ee9",
    "semantic_title": "magma - multimodal augmentation of generative models through adapter-based finetuning",
    "citation_count": 76,
    "authors": [
      "Constantin Eichenberg",
      "Sidney Black",
      "Samuel Weinbach",
      "Letitia Parcalabescu",
      "Anette Frank"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.180": {
    "title": "Towards Tracing Knowledge in Language Models Back to the Training Data",
    "volume": "findings",
    "abstract": "Language models (LMs) have been shown to memorize a great deal of factual knowledge contained in their training data. But when an LM generates an assertion, it is often difficult to determine where it learned this information and whether it is true. In this paper, we propose the problem of fact tracing: identifying which training examples taught an LM to generate a particular factual assertion. Prior work on training data attribution (TDA) may offer effective tools for identifying such examples, known as \"proponents\". We present the first quantitative benchmark to evaluate this. We compare two popular families of TDA methods — gradient-based and embedding-based — and find that much headroom remains. For example, both methods have lower proponent-retrieval precision than an information retrieval baseline (BM25) that does not have access to the LM at all. We identify key challenges that may be necessary for further improvement such as overcoming the problem of gradient saturation, and also show how several nuanced implementation details of existing neural TDA methods can significantly improve overall fact tracing performance",
    "checked": true,
    "id": "d4e8835e29418fcffc7c52e7cdf63ca207a206db",
    "semantic_title": "towards tracing knowledge in language models back to the training data",
    "citation_count": 19,
    "authors": [
      "Ekin Akyurek",
      "Tolga Bolukbasi",
      "Frederick Liu",
      "Binbin Xiong",
      "Ian Tenney",
      "Jacob Andreas",
      "Kelvin Guu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.181": {
    "title": "ReaRev: Adaptive Reasoning for Question Answering over Knowledge Graphs",
    "volume": "findings",
    "abstract": "Knowledge Graph Question Answering (KGQA) involves retrieving entities as answers from a Knowledge Graph (KG) using natural language queries. The challenge is to learn to reason over question-relevant KG facts that traverse KG entities and lead to the question answers. To facilitate reasoning, the question is decoded into instructions, which are dense question representations used to guide the KG traversals. However, if the derived instructions do not exactly match the underlying KG information, they may lead to reasoning under irrelevant context. Our method, termed ReaRev, introduces a new way to KGQA reasoning with respectto both instruction decoding and execution. To improve instruction decoding, we perform reasoning in an adaptive manner, where KG-aware information is used to iteratively update the initial instructions. To improve instruction execution, we emulate breadth-first search (BFS) with graph neural networks (GNNs). The BFS strategy treats the instructions as a set and allows our method to decide on their execution order on the fly. Experimental results on three KGQA benchmarks demonstrate the ReaRev's effectiveness compared with previous state-of-the-art, especially when the KG is incomplete or when we tackle complex questions. Our code is publicly available at https://github.com/cmavro/ReaRev_KGQA",
    "checked": true,
    "id": "543cefea7ad2a94c6bb2d8f0d0d6384e1547a9e7",
    "semantic_title": "rearev: adaptive reasoning for question answering over knowledge graphs",
    "citation_count": 6,
    "authors": [
      "Costas Mavromatis",
      "George Karypis"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.182": {
    "title": "Understanding Social Media Cross-Modality Discourse in Linguistic Space",
    "volume": "findings",
    "abstract": "The multimedia communications with texts and images are popular on social media. However, limited studies concern how images are structured with texts to form coherent meanings in human cognition. To fill in the gap, we present a novel concept of cross-modality discourse, reflecting how human readers couple image and text understandings. Text descriptions are first derived from images (named as subtitles) in the multimedia contexts. Five labels – entity-level insertion, projection and concretization and scene-level restatement and extension — are further employed to shape the structure of subtitles and texts and present their joint meanings. As a pilot study, we also build the very first dataset containing over 16K multimedia tweets with manually annotated discourse labels. The experimental results show that trendy multimedia encoders based on multi-head attention (with captions) are unable to well understand cross-modality discourse and additionally modeling texts at the output layer helps yield the-state-of-the-art results",
    "checked": true,
    "id": "7b1b1be1fd17439da68d7cbf49cac992894c7342",
    "semantic_title": "understanding social media cross-modality discourse in linguistic space",
    "citation_count": 1,
    "authors": [
      "Chunpu Xu",
      "Hanzhuo Tan",
      "Jing Li",
      "Piji Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.183": {
    "title": "TAPE: Assessing Few-shot Russian Language Understanding",
    "volume": "findings",
    "abstract": "Recent advances in zero-shot and few-shot learning have shown promise for a scope of research and practical purposes. However, this fast-growing area lacks standardized evaluation suites for non-English languages, hindering progress outside the Anglo-centric paradigm. To address this line of research, we propose TAPE (Text Attack and Perturbation Evaluation), a novel benchmark that includes six more complex NLU tasks for Russian, covering multi-hop reasoning, ethical concepts, logic and commonsense knowledge. The TAPE's design focuses on systematic zero-shot and few-shot NLU evaluation: (i) linguistic-oriented adversarial attacks and perturbations for analyzing robustness, and (ii) subpopulations for nuanced interpretation. The detailed analysis of testing the autoregressive baselines indicates that simple spelling-based perturbations affect the performance the most, while paraphrasing the input has a more negligible effect. At the same time, the results demonstrate a significant gap between the neural and human baselines for most tasks. We publicly release TAPE (https://tape-benchmark.com) to foster research on robust LMs that can generalize to new tasks when little to no supervision is available",
    "checked": true,
    "id": "ce9d803168d64cd7caf0340041cb7bb8b0ac07f7",
    "semantic_title": "tape: assessing few-shot russian language understanding",
    "citation_count": 6,
    "authors": [
      "Ekaterina Taktasheva",
      "Alena Fenogenova",
      "Denis Shevelev",
      "Nadezhda Katricheva",
      "Maria Tikhonova",
      "Albina Akhmetgareeva",
      "Oleg Zinkevich",
      "Anastasiia Bashmakova",
      "Svetlana Iordanskaia",
      "Valentina Kurenshchikova",
      "Alena Spiridonova",
      "Ekaterina Artemova",
      "Tatiana Shavrina",
      "Vladislav Mikhailov"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.184": {
    "title": "A Hierarchical N-Gram Framework for Zero-Shot Link Prediction",
    "volume": "findings",
    "abstract": "Knowledge graphs typically contain a large number of entities but often cover only a fraction of all relations between them (i.e., incompleteness). Zero-shot link prediction (ZSLP) is a popular way to tackle the problem by automatically identifying unobserved relations between entities. Most recent approaches use textual features of relations (e.g., surface name or textual descriptions) as auxiliary information to improve the encoded representation. These methods lack robustness as they are bound to support only tokens from a fixed vocabulary and unable to model out-of-vocabulary (OOV) words. Subword units such as character n-grams have the capability of generating more expressive representations for OOV words. Hence, in this paper, we propose a Hierarchical N-gram framework for Zero-Shot Link Prediction (HNZSLP) that leverages character n-gram information for ZSLP. Our approach works by first constructing a hierarchical n-gram graph from the surface name of relations. Subsequently, a new Transformer-based network models the hierarchical n-gram graph to learn a relation embedding for ZSLP. Experimental results show that our proposed HNZSLP method achieves state-of-the-art performance on two standard ZSLP datasets",
    "checked": true,
    "id": "0b9e130c6305de7766697ba7655f56010aaffd61",
    "semantic_title": "a hierarchical n-gram framework for zero-shot link prediction",
    "citation_count": 9,
    "authors": [
      "Mingchen Li",
      "Junfan Chen",
      "Samuel Mensah",
      "Nikolaos Aletras",
      "Xiulong Yang",
      "Yang Ye"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.185": {
    "title": "Quadapter: Adapter for GPT-2 Quantization",
    "volume": "findings",
    "abstract": "Transformer language models such as GPT-2 are difficult to quantize because of outliers in the activations leading to a large quantization error. To adapt to the error, one must use quantization-aware training, which entails a fine-tuning process based on the dataset and the training pipeline identical to those for the original model. Pretrained language models, however, often do not grant access to their datasets and training pipelines, forcing us to rely on arbitrary ones for fine-tuning. In that case, it is observed that quantization-aware training overfits the model to the fine-tuning data. To this end introduced is a quantization adapter (Quadapter), a small set of parameters that are learned to make activations quantization-friendly by scaling them channel-wise. For quantization without overfitting, we introduce a quantization adapter (Quadapter), a small set of parameters that are learned to make activations quantization-friendly by scaling them channel-wise. It keeps the model parameters unchanged. By applying our method to the challenging task of quantizing GPT-2, we demonstrate that it effectively prevents the overfitting and improves the quantization performance",
    "checked": true,
    "id": "3d4923d3ccf09334023e2bad293cd84f91105ffe",
    "semantic_title": "quadapter: adapter for gpt-2 quantization",
    "citation_count": 6,
    "authors": [
      "Minseop Park",
      "Jaeseong You",
      "Markus Nagel",
      "Simyung Chang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.186": {
    "title": "BanglaRQA: A Benchmark Dataset for Under-resourced Bangla Language Reading Comprehension-based Question Answering with Diverse Question-Answer Types",
    "volume": "findings",
    "abstract": "High-resource languages, such as English, have access to a plethora of datasets with various question-answer types resembling real-world reading comprehension. However, there is a severe lack of diverse and comprehensive question-answering datasets in under-resourced languages like Bangla. The ones available are either translated versions of English datasets with a niche answer format or created by human annotations focusing on a specific domain, question type, or answer type. To address these limitations, this paper introduces BanglaRQA, a reading comprehension-based Bangla question-answering dataset with various question-answer types. BanglaRQA consists of 3,000 context passages and 14,889 question-answer pairs created from those passages. The dataset comprises answerable and unanswerable questions covering four unique categories of questions and three types of answers. In addition, this paper also implemented four different Transformer models for question-answering on the proposed dataset. The best-performing model achieved an overall 62.42% EM and 78.11% F1 score. However, detailed analyses showed that the performance varies across question-answer types, leaving room for substantial improvement of the model performance. Furthermore, we demonstrated the effectiveness of BanglaRQA as a training resource by showing strong results on the bn_squad dataset. Therefore, BanglaRQA has the potential to contribute to the advancement of future research by enhancing the capability of language models. The dataset and codes are available at https://github.com/sartajekram419/BanglaRQA",
    "checked": true,
    "id": "fab4df01e7efd8b3898c68d77ce0fa5530f7c365",
    "semantic_title": "banglarqa: a benchmark dataset for under-resourced bangla language reading comprehension-based question answering with diverse question-answer types",
    "citation_count": 3,
    "authors": [
      "Syed Mohammed Sartaj Ekram",
      "Adham Arik Rahman",
      "Md. Sajid Altaf",
      "Mohammed Saidul Islam",
      "Mehrab Mustafy Rahman",
      "Md Mezbaur Rahman",
      "Md Azam Hossain",
      "Abu Raihan Mostofa Kamal"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.187": {
    "title": "Chaining Simultaneous Thoughts for Numerical Reasoning",
    "volume": "findings",
    "abstract": "Given that rich information is hidden behind ubiquitous numbers in text, numerical reasoning over text should be an essential skill of AI systems. To derive precise equations to solve numerical reasoning problems, previous work focused on modeling the structures of equations, and has proposed various structured decoders. Though structure modeling proves to be effective, these structured decoders construct a single equation in a pre-defined autoregressive order, potentially placing an unnecessary restriction on how a model should grasp the reasoning process. Intuitively, humans may have numerous pieces of thoughts popping up in no pre-defined order; thoughts are not limited to the problem at hand, and can even be concerned with other related problems. By comparing diverse thoughts and chaining relevant pieces, humans are less prone to errors. In this paper, we take this inspiration and propose CANTOR, a numerical reasoner that models reasoning steps using a directed acyclic graph where we produce diverse reasoning steps simultaneously without pre-defined decoding dependencies, and compare and chain relevant ones to reach a solution. Extensive experiments demonstrated the effectiveness of CANTOR under both fully-supervised and weakly-supervised settings",
    "checked": true,
    "id": "5d10a5fcc943afab50bce6293eaaaf3d22815868",
    "semantic_title": "chaining simultaneous thoughts for numerical reasoning",
    "citation_count": 8,
    "authors": [
      "Zhihong Shao",
      "Fei Huang",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.188": {
    "title": "Inferring Implicit Relations in Complex Questions with Language Models",
    "volume": "findings",
    "abstract": "A prominent challenge for modern language understanding systems is the ability to answer implicit reasoning questions, where the required reasoning steps for answering the question are not mentioned in the text explicitly. In this work, we investigate why current models struggle with implicit reasoning question answering (QA) tasks, by decoupling inference of reasoning steps from their execution. We define a new task of implicit relation inference and construct a benchmark, IMPLICITRELATIONS, where given a question, a model should output a list of concept-relation pairs, where the relations describe the implicit reasoning steps required for answering the question. Using IMPLICITRELATIONS, we evaluate models from the GPT-3 family and find that, while these models struggle on the implicit reasoning QA task, they often succeed at inferring implicit relations. This suggests that the challenge in implicit reasoning questions does not stem from the need to plan a reasoning strategy alone, but to do it while also retrieving and reasoning over relevant information",
    "checked": true,
    "id": "aebfcdab42f10bbaaef1b4a61d9b35e4a91cc35e",
    "semantic_title": "inferring implicit relations in complex questions with language models",
    "citation_count": 8,
    "authors": [
      "Uri Katz",
      "Mor Geva",
      "Jonathan Berant"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.189": {
    "title": "Eliciting and Understanding Cross-task Skills with Task-level Mixture-of-Experts",
    "volume": "findings",
    "abstract": "Recent works suggest that transformer models are capable of multi-tasking on diverse NLP tasks and adapt to new tasks efficiently. However, the potential of these multi-task models may be limited as they use the same set of parameters for all tasks. In contrast, humans tackle tasks in a more flexible way, by making proper presumptions on what skills and knowledge are relevant and executing only the necessary computations. Inspired by this, we propose to use task-level mixture-of-expert models, which has a collection of transformer layers (i.e., experts) and a router component to choose among these experts dynamically and flexibly. We find that these models help improve the average performance gain (ARG) metric by 2.6% when adapting to unseen tasks in few-shot settings, and by 5.6% in zero-shot generalization settings. Further, we show that the learned routing decisions and experts partly rediscover human categorization of NLP tasks – certain experts are strongly associated with extractive tasks, some with classification tasks, and some with tasks requiring world knowledge",
    "checked": true,
    "id": "1da214f8f265445b5997f5d677452819b334bdfb",
    "semantic_title": "eliciting and understanding cross-task skills with task-level mixture-of-experts",
    "citation_count": 4,
    "authors": [
      "Qinyuan Ye",
      "Juan Zha",
      "Xiang Ren"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.190": {
    "title": "On the Curious Case of l2 norm of Sense Embeddings",
    "volume": "findings",
    "abstract": "We show that the l2 norm of a static sense embedding encodes information related to the frequency of that sense in the training corpus used to learn the sense embeddings. This finding can be seen as an extension of a previously known relationship for word embeddings to sense embeddings. Our experimental results show that in spite of its simplicity, the l2 norm of sense embeddings is a surprisingly effective feature for several word sense related tasks such as (a) most frequent sense prediction, (b) word-in-context (WiC), and (c) word sense disambiguation (WSD). In particular, by simply including the l2 norm of a sense embedding as a feature in a classifier, we show that we can improve WiC and WSD methods that use static sense embeddings",
    "checked": true,
    "id": "dfa4ec0e80db41f51d2311b35e55224d855e915f",
    "semantic_title": "on the curious case of l2 norm of sense embeddings",
    "citation_count": 1,
    "authors": [
      "Yi Zhou",
      "Danushka Bollegala"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.191": {
    "title": "Partially-Random Initialization: A Smoking Gun for Binarization Hypothesis of BERT",
    "volume": "findings",
    "abstract": "In the past few years, pre-trained BERT has become one of the most popular deep-learning language models due to their remarkable performance in natural language processing (NLP) tasks. However, the superior performance of BERT comes at the cost of high computational and memory complexity, hindering its envisioned widespread deployment in edge devices with limited computing resources. Binarization can alleviate these limitations by reducing storage requirements and improving computing performance. However, obtaining a comparable accuracy performance for binary BERT w.r.t. its full-precision counterpart is still a difficult task. We observe that direct binarization of pre-trained BERT provides a poor initialization during the fine-tuning phase, making the model incapable of achieving a decent accuracy on downstream tasks. Based on this observation, we put forward the following hypothesis: partially randomly-initialized BERT with binary weights and activations can reach to a decent accuracy performance by distilling knowledge from the its full-precision counterpart. We show that BERT with pre-trained embedding layer and randomly-initialized encoder is a smoking gun for this hypothesis. We identify the smoking gun through a series of experiments and show that it yields a new set of state-of-the-art results on the GLUE and SQuAD benchmarks",
    "checked": true,
    "id": "e1d7ea197d68fce62fb0c892919797ae99a6df3b",
    "semantic_title": "partially-random initialization: a smoking gun for binarization hypothesis of bert",
    "citation_count": 1,
    "authors": [
      "Arash Ardakani"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.192": {
    "title": "Prompt Consistency for Zero-Shot Task Generalization",
    "volume": "findings",
    "abstract": "One of the most impressive results of recent NLP history is the ability of pre-trained language models to solve new tasks in a zero-shot setting. To achieve this, NLP tasks are framed as natural language prompts, generating a response indicating the predicted output. Nonetheless, the performance in such settings often lags far behind its supervised counterpart, suggesting a large space for potential improvement. In this paper, we explore methods to utilize unlabeled data to improve zero-shot performance. Specifically, we take advantage of the fact that multiple prompts can be used to specify a single task, and propose to regularize prompt consistency, encouraging consistent predictions over this diverse set of prompts. Our method makes it possible to fine-tune the model either with extra unlabeled training data, or directly on test input at inference time in an unsupervised manner. In experiments, our approach outperforms the state-of-the-art zero-shot learner, T0, on 9 out of 11 datasets across 4 NLP tasks by up to 10.6 absolute points in terms of accuracy. The gains are often attained with a small number of unlabeled examples",
    "checked": true,
    "id": "07c70ca55793984ffdf31582a05170ef3d62381a",
    "semantic_title": "prompt consistency for zero-shot task generalization",
    "citation_count": 45,
    "authors": [
      "Chunting Zhou",
      "Junxian He",
      "Xuezhe Ma",
      "Taylor Berg-Kirkpatrick",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.193": {
    "title": "In-Context Learning for Few-Shot Dialogue State Tracking",
    "volume": "findings",
    "abstract": "Collecting and annotating task-oriented dialogues is time-consuming and costly. Thus, zero and few shot learning for dialogue tasks presents an exciting opportunity. In this work, we propose an in-context (IC) learning framework for zero-shot and few-shot learning dialogue state tracking (DST), where a large pretrained language model (LM) takes a test instance and a few exemplars as input, and directly decodes the dialogue state without any parameter updates. This approach is more flexible and scalable than prior DST work when adapting to new domains and scenarios. To better leverage a tabular domain description in the LM prompt, we reformulate DST into a text-to-SQL problem. We also propose a novel approach to retrieve annotated dialogues as exemplars. Empirical results on MultiWOZ show that our method IC-DST substantially outperforms previous fine-tuned state-of-the-art models in few-shot settings. In addition, we test IC-DST in zero-shot settings, in which the model only takes a fixed task instruction as input, finding that it outperforms previous zero-shot methods by a large margin",
    "checked": true,
    "id": "b645e706651391eca1f692e7f560051c21b3dea4",
    "semantic_title": "in-context learning for few-shot dialogue state tracking",
    "citation_count": 36,
    "authors": [
      "Yushi Hu",
      "Chia-Hsuan Lee",
      "Tianbao Xie",
      "Tao Yu",
      "Noah A. Smith",
      "Mari Ostendorf"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.194": {
    "title": "On Advances in Text Generation from Images Beyond Captioning: A Case Study in Self-Rationalization",
    "volume": "findings",
    "abstract": "Combining the visual modality with pretrained language models has been surprisingly effective for simple descriptive tasks such as image captioning. More general text generation however remains elusive. We take a step back and ask: How do these models work for more complex generative tasks, i.e. conditioning on both text and images? Are multimodal models simply visually adapted language models, or do they combine they reason jointly over modalities?We investigate these questions in the context of self-rationalization (jointly generating task labels/answers and free-text explanations) of three tasks: (i) visual question answering in VQA-X, (ii) visual commonsense reasoning in VCR, and (iii) visual-textual entailment in E-SNLI-VE. We show that recent unimodal advances, CLIP image representations and scaling of language models, do not consistently improveself-rationalization in multimodal tasks. We find that no single model type works universally best across tasks, datasets, and finetuning data sizes. Our findings motivate the need for novel general backbones that move text generation from images and text beyond image captioning",
    "checked": true,
    "id": "97ec7cf78c6f0b8a9cd9f4afdccc369ec3898f19",
    "semantic_title": "on advances in text generation from images beyond captioning: a case study in self-rationalization",
    "citation_count": 3,
    "authors": [
      "Shruti Palaskar",
      "Akshita Bhagia",
      "Yonatan Bisk",
      "Florian Metze",
      "Alan W Black",
      "Ana Marasovic"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.195": {
    "title": "The challenges of temporal alignment on Twitter during crises",
    "volume": "findings",
    "abstract": "Language use changes over time, and this impacts the effectiveness of NLP systems. This phenomenon is even more prevalent in social media data during crisis events where meaning and frequency of word usage may change over the course of days. Contextual language models fail to adapt temporally, emphasizing the need for temporal adaptation in models which need to be deployed over an extended period of time. While existing approaches consider data spanning large periods of time (from years to decades), shorter time spans are critical for crisis data. We quantify temporal degradation for this scenario and propose methods to cope with performance loss by leveraging techniques from domain adaptation. To the best of our knowledge, this is the first effort to explore effects of rapid language change driven by adversarial adaptations, particularly during natural and human-induced disasters. Through extensive experimentation on diverse crisis datasets, we analyze under what conditions our approaches outperform strong baselines while highlighting the current limitations of temporal adaptation methods in scenarios where access to unlabeled data is scarce",
    "checked": true,
    "id": "8a318ae057c2f7aaf3d939719d3cb100eff5b3c4",
    "semantic_title": "the challenges of temporal alignment on twitter during crises",
    "citation_count": 2,
    "authors": [
      "Aniket Pramanick",
      "Tilman Beck",
      "Kevin Stowe",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.196": {
    "title": "Experimental Standards for Deep Learning in Natural Language Processing Research",
    "volume": "findings",
    "abstract": "The field of Deep Learning (DL) has undergone explosive growth during the last decade, with a substantial impact on Natural Language Processing (NLP) as well. Yet, compared to more established disciplines, a lack of common experimental standards remains an open challenge to the field at large. Starting from fundamental scientific principles, we distill ongoing discussions on experimental standards in NLP into a single, widely-applicable methodology. Following these best practices is crucial to strengthen experimental evidence, improve reproducibility and enable scientific progress. These standards are further collected in a public repository to help them transparently adapt to future needs",
    "checked": true,
    "id": "77f06e3d1dfac471322392bd60b9d048152280a4",
    "semantic_title": "experimental standards for deep learning in natural language processing research",
    "citation_count": 3,
    "authors": [
      "Dennis Ulmer",
      "Elisa Bassignana",
      "Max Müller-Eberstein",
      "Daniel Varab",
      "Mike Zhang",
      "Rob van der Goot",
      "Christian Hardmeier",
      "Barbara Plank"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.197": {
    "title": "Few-Shot Anaphora Resolution in Scientific Protocols via Mixtures of In-Context Experts",
    "volume": "findings",
    "abstract": "Anaphora resolution is an important task for information extraction across a range of languages, text genres, and domains, motivating the need for methods that do not require large annotated datasets. In-context learning has emerged as a promising approach, yet there are a number of challenges in applying in-context learning to resolve anaphora. For example, encoding a single in-context demonstration that consists of: an anaphor, a paragraph-length context, and a list of corresponding antecedents, requires conditioning a language model on a long sequence of tokens, limiting the number of demonstrations per prompt. In this paper, we present Mice (Mixtures of In-Context Experts), which we demonstrate is effective for few-shot anaphora resolution in scientific protocols. Given only a handful of training examples, Mice combines the predictions of hundreds of in-context experts, yielding a 30% increase in F1 score over a competitive prompt retrieval baseline. Furthermore, we show Mice can be used to train compact student models without sacrificing performance. As far as we are aware, this is the first work to present experimental results demonstrating the effectiveness of in-context learning on the task of few-shot anaphora resolution in scientific protocols",
    "checked": true,
    "id": "fb1f7ffef65341aa5aee2bb0b240d4ef51680fce",
    "semantic_title": "few-shot anaphora resolution in scientific protocols via mixtures of in-context experts",
    "citation_count": 10,
    "authors": [
      "Nghia T. Le",
      "Fan Bai",
      "Alan Ritter"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.198": {
    "title": "Exploring Predictive Uncertainty and Calibration in NLP: A Study on the Impact of Method & Data Scarcity",
    "volume": "findings",
    "abstract": "We investigate the problem of determining the predictive confidence (or, conversely, uncertainty) of a neural classifier through the lens of low-resource languages. By training models on sub-sampled datasets in three different languages, we assess the quality of estimates from a wide array of approaches and their dependence on the amount of available data. We find that while approaches based on pre-trained models and ensembles achieve the best results overall, the quality of uncertainty estimates can surprisingly suffer with more data. We also perform a qualitative analysis of uncertainties on sequences, discovering that a model's total uncertainty seems to be influenced to a large degree by its data uncertainty, not model uncertainty. All model implementations are open-sourced in a software package",
    "checked": true,
    "id": "670a8db8e47cfe234558ed913242427a1b8b8348",
    "semantic_title": "exploring predictive uncertainty and calibration in nlp: a study on the impact of method & data scarcity",
    "citation_count": 9,
    "authors": [
      "Dennis Ulmer",
      "Jes Frellsen",
      "Christian Hardmeier"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.199": {
    "title": "Conditional Supervised Contrastive Learning for Fair Text Classification",
    "volume": "findings",
    "abstract": "Contrastive representation learning has gained much attention due to its superior performance in learning representations from both image and sequential data. However, the learned representations could potentially lead to performance disparities in downstream tasks, such as increased silencing of underrepresented groups in toxicity comment classification. In light of this challenge, in this work, we study learning fair representations that satisfy a notion of fairness known as equalized odds for text classification via contrastive learning. Specifically, we first theoretically analyze the connections between learning representations with a fairness constraint and conditional supervised contrastive objectives, and then propose to use conditional supervised contrastive objectives to learn fair representations for text classification. We conduct experiments on two text datasets to demonstrate the effectiveness of our approaches in balancing the trade-offs between task performance and bias mitigation among existing baselines for text classification. Furthermore, we also show that the proposed methods are stable in different hyperparameter settings",
    "checked": true,
    "id": "992a067ef40893607dfc5a412265bf70c4804952",
    "semantic_title": "conditional supervised contrastive learning for fair text classification",
    "citation_count": 10,
    "authors": [
      "Jianfeng Chi",
      "William Shand",
      "Yaodong Yu",
      "Kai-Wei Chang",
      "Han Zhao",
      "Yuan Tian"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.200": {
    "title": "SpaBERT: A Pretrained Language Model from Geographic Data for Geo-Entity Representation",
    "volume": "findings",
    "abstract": "Named geographic entities (geo-entities for short) are the building blocks of many geographic datasets. Characterizing geo-entities is integral to various application domains, such as geo-intelligence and map comprehension, while a key challenge is to capture the spatial-varying context of an entity. We hypothesize that we shall know the characteristics of a geo-entity by its surrounding entities, similar to knowing word meanings by their linguistic context. Accordingly, we propose a novel spatial language model, SpaBERT, which provides a general-purpose geo-entity representation based on neighboring entities in geospatial data. SpaBERT extends BERT to capture linearized spatial context, while incorporating a spatial coordinate embedding mechanism to preserve spatial relations of entities in the 2-dimensional space. SpaBERT is pretrained with masked language modeling and masked entity prediction tasks to learn spatial dependencies. We apply SpaBERT to two downstream tasks: geo-entity typing and geo-entity linking. Compared with the existing language models that do not use spatial context, SpaBERT shows significant performance improvement on both tasks. We also analyze the entity representation from SpaBERT in various settings and the effect of spatial coordinate embedding",
    "checked": true,
    "id": "8a5837b9245035972f97d6796f62790b6e7e9d71",
    "semantic_title": "spabert: a pretrained language model from geographic data for geo-entity representation",
    "citation_count": 10,
    "authors": [
      "Zekun Li",
      "Jina Kim",
      "Yao-Yi Chiang",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.201": {
    "title": "Self-training with Two-phase Self-augmentation for Few-shot Dialogue Generation",
    "volume": "findings",
    "abstract": "In task-oriented dialogue systems, response generation from meaning representations (MRs) often suffers from limited training examples, due to the high cost of annotating MR-to-Text pairs. Previous works on self-training leverage fine-tuned conversational models to automatically generate pseudo-labeled MR-to-Text pairs for further fine-tuning. However, some self-augmented data may be noisy or uninformative for the model to learn from. In this work, we propose a two-phase self-augmentation procedure to generate high-quality pseudo-labeled MR-to-Text pairs: the first phase selects the most informative MRs based on model's prediction uncertainty; with the selected MRs, the second phase generates accurate responses by aggregating multiple perturbed latent representations from each MR. Empirical experiments on two benchmark datasets, FewShotWOZ and FewShotSGD, show that our method generally outperforms existing self-training methods on both automatic and human evaluations",
    "checked": true,
    "id": "5c0544c74e4fb017d782d9754c6bd7f3fc28c9c7",
    "semantic_title": "self-training with two-phase self-augmentation for few-shot dialogue generation",
    "citation_count": 1,
    "authors": [
      "Wanyu Du",
      "Hanjie Chen",
      "Yangfeng Ji"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.202": {
    "title": "Is NLP Ready for Standardization?",
    "volume": "findings",
    "abstract": "While standardization is a well-established activity in other scientific fields such as telecommunications, networks or multimedia, in the field of AI and more specifically NLP it is still at its dawn. In this paper, we explore how various aspects of NLP (evaluation, data, tasks...) lack standards and how that can impact science, but also the society, the industry, and regulations. We argue that the numerous initiatives to rationalize the field and establish good practices are only the first step, and developing formal standards remains needed to bring further clarity to NLP research and industry, at a time where this community faces various crises regarding ethics or reproducibility. We thus encourage NLP researchers to contribute to existing and upcoming standardization projects, so that they can express their needs and concerns, while sharing their expertise",
    "checked": true,
    "id": "dae977770ad015ecca74cf46288e6a0f41cba5bd",
    "semantic_title": "is nlp ready for standardization?",
    "citation_count": 0,
    "authors": [
      "Lauriane Aufrant"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.203": {
    "title": "Probing for Incremental Parse States in Autoregressive Language Models",
    "volume": "findings",
    "abstract": "Next-word predictions from autoregressive neural language models show remarkable sensitivity to syntax. This work evaluates the extent to which this behavior arises as a result of a learned ability to maintain implicit representations of incremental syntactic structures. We extend work in syntactic probing to the incremental setting and present several probes for extracting incomplete syntactic structure (operationalized through parse states from a stack-based parser) from autoregressive language models. We find that our probes can be used to predict model preferences on ambiguous sentence prefixes and causally intervene on model representations and steer model behavior. This suggests implicit incremental syntactic inferences underlie next-word predictions in autoregressive neural language models",
    "checked": true,
    "id": "307d522c7bd7eafc21e67027b207ad9690243715",
    "semantic_title": "probing for incremental parse states in autoregressive language models",
    "citation_count": 10,
    "authors": [
      "Tiwalayo Eisape",
      "Vineet Gangireddy",
      "Roger Levy",
      "Yoon Kim"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.204": {
    "title": "Re-Examining Calibration: The Case of Question Answering",
    "volume": "findings",
    "abstract": "For users to trust model predictions, they need to understand model outputs, particularly their confidence — calibration aims to adjust (calibrate) models' confidence to match expected accuracy. We argue that the traditional calibration evaluation does not promote effective calibrations: for example, it can encourage always assigning a mediocre confidence score to all predictions, which does not help users distinguish correct predictions from wrong ones. Building on those observations, we propose a new calibration metric, MacroCE, that better captures whether the model assigns low confidence to wrong predictions and high confidence to correct predictions. Focusing on the practical application of open-domain question answering, we examine conventional calibration methods applied on the widely-used retriever-reader pipeline, all of which do not bring significant gains under our new MacroCE metric. Toward better calibration, we propose a new calibration method (ConsCal) that uses not just final model predictions but whether multiple model checkpoints make consistent predictions. Altogether, we provide an alternative view of calibration along with a new metric, re-evaluation of existing calibration methods on our metric, and proposal of a more effective calibration method",
    "checked": true,
    "id": "615671736f303f05a9f2a026a9e677788eef96b3",
    "semantic_title": "re-examining calibration: the case of question answering",
    "citation_count": 17,
    "authors": [
      "Chenglei Si",
      "Chen Zhao",
      "Sewon Min",
      "Jordan Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.205": {
    "title": "Accelerating Learned Sparse Indexes Via Term Impact Decomposition",
    "volume": "findings",
    "abstract": "Novel inverted index-based learned sparse ranking models provide more effective, but less efficient, retrieval performance compared to traditional ranking models like BM25. In this paper, we introduce a technique we call postings clipping to improve the query efficiency of learned representations. Our technique amplifies the benefit of dynamic pruning query processing techniques by accounting for changes in term importance distributions of learned ranking models. The new clipping mechanism accelerates top-k retrieval by up to 9.6X without any loss in effectiveness",
    "checked": true,
    "id": "0db1bb71fe91ca7dda1129dc0702735dda8951e6",
    "semantic_title": "accelerating learned sparse indexes via term impact decomposition",
    "citation_count": 9,
    "authors": [
      "Joel Mackenzie",
      "Antonio Mallia",
      "Alistair Moffat",
      "Matthias Petri"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.206": {
    "title": "Do Text-to-Text Multi-Task Learners Suffer from Task Conflict?",
    "volume": "findings",
    "abstract": "Traditional multi-task learning architectures learn a single model across multiple tasks through a shared encoder followed by task-specific decoders. Learning these models often requires specialized training algorithms that address task-conflict in the shared parameter updates, which otherwise can lead to negative transfer. A new type of multi-task learning within NLP homogenizes multi-task architectures as a shared encoder and language model decoder, which does surprisingly well across a range of diverse tasks. Does this new architecture suffer from task-conflicts that require specialized training algorithms? We study how certain factors in the shift towards text-to-text models affects multi-task conflict and negative transfer, finding that both directional conflict and transfer are surprisingly constant across architectures",
    "checked": true,
    "id": "2843661ee0d5fa159165beba50c345566cc44c57",
    "semantic_title": "do text-to-text multi-task learners suffer from task conflict?",
    "citation_count": 3,
    "authors": [
      "David Mueller",
      "Nicholas Andrews",
      "Mark Dredze"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.207": {
    "title": "MANTa: Efficient Gradient-Based Tokenization for End-to-End Robust Language Modeling",
    "volume": "findings",
    "abstract": "Static subword tokenization algorithms have been an essential component of recent works on language modeling. However, their static nature results in important flaws that degrade the models' downstream performance and robustness. In this work, we propose MANTa, a Module for Adaptive Neural TokenizAtion. MANTa is a differentiable tokenizer trained end-to-end with the language model. The resulting system offers a trade-off between the expressiveness of byte-level models and the speed of models trained using subword tokenization. In addition, our tokenizer is highly explainable since it produces an explicit segmentation of sequences into blocks. We evaluate our pre-trained model on several English datasets from different domains as well as on synthetic noise. We find that MANTa improves robustness to character perturbations and out-of-domain data. We then show that MANTa performs comparably to other models on the general-domain GLUE benchmark. Finally, we show that it is considerably faster than strictly byte-level models",
    "checked": true,
    "id": "6bfa1b07cb1f46294adac73afe33616cd919b603",
    "semantic_title": "manta: efficient gradient-based tokenization for end-to-end robust language modeling",
    "citation_count": 4,
    "authors": [
      "Nathan Godey",
      "Roman Castagné",
      "Éric de la Clergerie",
      "Benoît Sagot"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.208": {
    "title": "Towards Intelligent Clinically-Informed Language Analyses of People with Bipolar Disorder and Schizophrenia",
    "volume": "findings",
    "abstract": "NLP offers a myriad of opportunities to support mental health research. However, prior work has almost exclusively focused on social media data, for which diagnoses are difficult or impossible to validate. We present a first-of-its-kind dataset of manually transcribed interactions with people clinically diagnosed with bipolar disorder and schizophrenia, as well as healthy controls. Data was collected through validated clinical tasks and paired with diagnostic measures. We extract 100+ temporal, sentiment, psycholinguistic, emotion, and lexical features from the data and establish classification validity using a variety of models to study language differences between diagnostic groups. Our models achieve strong classification performance (maximum F1=0.93-0.96), and lead to the discovery of interesting associations between linguistic features and diagnostic class. It is our hope that this dataset will offer high value to clinical and NLP researchers, with potential for widespread broader impacts",
    "checked": true,
    "id": "c2ca8e3a1bba537fb3a3f1d18d55102accbf650f",
    "semantic_title": "towards intelligent clinically-informed language analyses of people with bipolar disorder and schizophrenia",
    "citation_count": 1,
    "authors": [
      "Ankit Aich",
      "Avery Quynh",
      "Varsha Badal",
      "Amy Pinkham",
      "Philip Harvey",
      "Colin Depp",
      "Natalie Parde"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.209": {
    "title": "Calibrating Trust of Multi-Hop Question Answering Systems with Decompositional Probes",
    "volume": "findings",
    "abstract": "Multi-hop Question Answering (QA) is a challenging task since it requires an accurate aggregation of information from multiple context paragraphs and a thorough understanding of the underlying reasoning chains. Recent work in multi-hop QA has shown that performance can be boosted by first decomposing the questions into simpler, single-hop questions. In this paper, we explore one additional utility of the multi-hop decomposition from the perspective of explainable NLP: to create explanation by probing a neural QA model with them. We hypothesize that in doing so, users will be better able to predict when the underlying QA system will give the correct answer. Through human participant studies, we verify that exposing the decomposition probes and answers to the probes to users can increase their ability to predict system performance on a question instance basis. We show that decomposition is an effective form of probing QA systems as well as a promising approach to explanation generation. In-depth analyses show the need for improvements in decomposition systems",
    "checked": true,
    "id": "b2e3b4e33cc4e409bd5ab54dd6e4a51d6cce524e",
    "semantic_title": "calibrating trust of multi-hop question answering systems with decompositional probes",
    "citation_count": 8,
    "authors": [
      "Kaige Xie",
      "Sarah Wiegreffe",
      "Mark Riedl"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.210": {
    "title": "CheckHARD: Checking Hard Labels for Adversarial Text Detection, Prediction Correction, and Perturbed Word Suggestion",
    "volume": "findings",
    "abstract": "An adversarial attack generates harmful text that fools a target model. More dangerously, this text is unrecognizable by humans. Existing work detects adversarial text and corrects a target's prediction by identifying perturbed words and changing them into their synonyms, but many benign words are also changed. In this paper, we directly detect adversarial text, correct the prediction, and suggest perturbed words by checking the change in the hard labels from the target's predictions after replacing a word with its transformation using a model that we call CheckHARD. The experiments demonstrate that CheckHARD outperforms existing work on various attacks, models, and datasets",
    "checked": true,
    "id": "52e1cb62cb764f24a3ac163d16ff73e835a4b6f5",
    "semantic_title": "checkhard: checking hard labels for adversarial text detection, prediction correction, and perturbed word suggestion",
    "citation_count": 0,
    "authors": [
      "Hoang-Quoc Nguyen-Son",
      "Huy Quang Ung",
      "Seira Hidano",
      "Kazuhide Fukushima",
      "Shinsaku Kiyomoto"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.211": {
    "title": "Mitigating Covertly Unsafe Text within Natural Language Systems",
    "volume": "findings",
    "abstract": "An increasingly prevalent problem for intelligent technologies is text safety, as uncontrolled systems may generate recommendations to their users that lead to injury or life-threatening consequences. However, the degree of explicitness of a generated statement that can cause physical harm varies. In this paper, we distinguish types of text that can lead to physical harm and establish one particularly underexplored category: covertly unsafe text. Then, we further break down this category with respect to the system's information and discuss solutions to mitigate the generation of text in each of these subcategories. Ultimately, our work defines the problem of covertly unsafe language that causes physical harm and argues that this subtle yet dangerous issue needs to be prioritized by stakeholders and regulators. We highlight mitigation strategies to inspire future researchers to tackle this challenging problem and help improve safety within smart systems",
    "checked": true,
    "id": "0b4681139e8a77a92207ed81233c16bb3772e238",
    "semantic_title": "mitigating covertly unsafe text within natural language systems",
    "citation_count": 8,
    "authors": [
      "Alex Mei",
      "Anisha Kabir",
      "Sharon Levy",
      "Melanie Subbiah",
      "Emily Allaway",
      "John Judge",
      "Desmond Patton",
      "Bruce Bimber",
      "Kathleen McKeown",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.212": {
    "title": "I Know Who You Are\": Character-Based Features for Conversational Humor Recognition in Chinese",
    "volume": "findings",
    "abstract": "Humor plays an important role in our daily life, as it is an essential and fascinating element in the communication between persons. Therefore, how to recognize punchlines from the dialogue, i.e. conversational humor recognition, has attracted much interest of computational linguistics communities. However, most existing work attempted to understand the conversational humor by analyzing the contextual information of the dialogue, but neglected the character of the interlocutor, such as age, gender, occupation, and so on. For instance, the same utterance could bring out humorous from a serious person, but may be a plain expression from a naive person. To this end, this paper proposes a Character Fusion Conversational Humor Recognition model (CFCHR) to explore character information to recognize conversational humor. CFCHR utilizes a multi-task learning framework that unifies two highly pertinent tasks, i.e., character extraction and punchline identification. Based on deep neural networks, we trained both tasks jointly by sharing weight to extract the common and task-invariant features while each task could still learn its task-specific features. Experiments were conducted on Chinese sitcoms corpus, which consisted of 12,677 utterances from 22 characters. The experimental results demonstrated that CFCHR could achieve 33.08% improvements in terms of F1-score over some strong baselines, and proved the effectiveness of the character information to identify the punchlines",
    "checked": true,
    "id": "ec389c245a8d5a4c1f47f48e16d0c1ef825676cc",
    "semantic_title": "i know who you are\": character-based features for conversational humor recognition in chinese",
    "citation_count": 0,
    "authors": [
      "Wenbo Shang",
      "Jiangjiang Zhao",
      "Zezhong Wang",
      "Binyang Li",
      "Fangchun Yang",
      "Kam-Fai Wong"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.213": {
    "title": "DebiasGAN: Eliminating Position Bias in News Recommendation with Adversarial Learning",
    "volume": "findings",
    "abstract": "Click behaviors are widely used for learning news recommendation models, but they are heavily affected by the biases brought by the news display positions. It is important to remove position biases to train unbiased recommendation model and capture unbiased user interest. In this paper, we propose a news recommendation method named DebiasGAN that can effectively alleviate position biases via adversarial learning. The core idea is modeling the personalized effect of position bias on click behaviors in a candidate-aware way, and learning debiased candidate-aware user embeddings from which the position information cannot be discriminated. More specifically, we use a bias-aware click model to capture the effect of position bias on click behaviors, and use a bias-invariant click model with random candidate positions to estimate the ideally unbiased click scores. We apply adversarial learning to the embeddings learned by the two models to help the bias-invariant click model capture debiased user interest. Experimental results on two real-world datasets show that DebiasGAN effectively improves news recommendation by eliminating position biases",
    "checked": true,
    "id": "8248c16165e7e9093365d0e1a7327bf6e70429ba",
    "semantic_title": "debiasgan: eliminating position bias in news recommendation with adversarial learning",
    "citation_count": 3,
    "authors": [
      "Chuhan Wu",
      "Fangzhao Wu",
      "Xiangnan He",
      "Yongfeng Huang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.214": {
    "title": "Generating Multiple-Length Summaries via Reinforcement Learning for Unsupervised Sentence Summarization",
    "volume": "findings",
    "abstract": "Sentence summarization shortens given texts while maintaining core contents of the texts. Unsupervised approaches have been studied to summarize texts without ground-truth summaries. However, recent unsupervised models are extractive, which remove words from texts and thus they are less flexible than abstractive summarization. In this work, we devise an abstractive model based on reinforcement learning without ground-truth summaries. We formulate the unsupervised summarization based on the Markov decision process with rewards representing the summary quality. To further enhance the summary quality, we develop a multi-summary learning mechanism that generates multiple summaries with varying lengths for a given text, while making the summaries mutually enhance each other. Experimental results show that the proposed model substantially outperforms both abstractive and extractive models, yet frequently generating new words not contained in input texts",
    "checked": true,
    "id": "03cefe16cf6abcabe4f702b69f84f30dd6c2cd6e",
    "semantic_title": "generating multiple-length summaries via reinforcement learning for unsupervised sentence summarization",
    "citation_count": 5,
    "authors": [
      "Dongmin Hyun",
      "Xiting Wang",
      "Chayoung Park",
      "Xing Xie",
      "Hwanjo Yu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.215": {
    "title": "Multilingual Sentence Transformer as A Multilingual Word Aligner",
    "volume": "findings",
    "abstract": "Multilingual pretrained language models (mPLMs) have shown their effectiveness in multilingual word alignment induction. However, these methods usually start from mBERT or XLM-R. In this paper, we investigate whether multilingual sentence Transformer LaBSE is a strong multilingual word aligner. This idea is non-trivial as LaBSE is trained to learn language-agnostic sentence-level embeddings, while the alignment extraction task requires the more fine-grained word-level embeddings to be language-agnostic. We demonstrate that the vanilla LaBSE outperforms other mPLMs currently used in the alignment task, and then propose to finetune LaBSE on parallel corpus for further improvement. Experiment results on seven language pairs show that our best aligner outperforms previous state-of-the-art models of all varieties. In addition, our aligner supports different language pairs in a single model, and even achieves new state-of-the-art on zero-shot language pairs that does not appear in the finetuning process",
    "checked": true,
    "id": "b9283599e628e839f9db36686d877f69cef5fa5b",
    "semantic_title": "multilingual sentence transformer as a multilingual word aligner",
    "citation_count": 4,
    "authors": [
      "Weikang Wang",
      "Guanhua Chen",
      "Hanqing Wang",
      "Yue Han",
      "Yun Chen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.216": {
    "title": "CORE: A Retrieve-then-Edit Framework for Counterfactual Data Generation",
    "volume": "findings",
    "abstract": "Counterfactual data augmentation (CDA) – i.e., adding minimally perturbed inputs during training – helps reduce model reliance on spurious correlations and improves generalization to out-of-distribution (OOD) data. Prior work on generating counterfactuals only considered restricted classes of perturbations, limiting their effectiveness. We present Counterfactual Generation via Retrieval and Editing (CORE), a retrieval-augmented generation framework for creating diverse counterfactual perturbations for CDA. For each training example, CORE first performs a dense retrieval over a task-related unlabeled text corpus using a learned bi-encoder and extracts relevant counterfactual excerpts. CORE then incorporates these into prompts to a large language model with few-shot learning capabilities, for counterfactual editing. Conditioning language model edits on naturally occurring data results in more diverse perturbations. Experiments on natural language inference and sentiment analysis benchmarks show that CORE counterfactuals are more effective at improving generalization to OOD data compared to other DA approaches. We also show that the CORE retrieval framework can be used to encourage diversity in manually authored perturbations",
    "checked": true,
    "id": "4989c08930e42d322b3bfed167d7ea434a698f2c",
    "semantic_title": "core: a retrieve-then-edit framework for counterfactual data generation",
    "citation_count": 7,
    "authors": [
      "Tanay Dixit",
      "Bhargavi Paranjape",
      "Hannaneh Hajishirzi",
      "Luke Zettlemoyer"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.217": {
    "title": "Conversation Disentanglement with Bi-Level Contrastive Learning",
    "volume": "findings",
    "abstract": "Conversation disentanglement aims to group utterances into detached sessions, which is a fundamental task in processing multi-party conversations. Existing methods have two main drawbacks. First, they overemphasize pairwise utterance relations but pay inadequate attention to the utterance-to-context relation modeling. Second, huge amount of human annotated data is required for training, which is expensive to obtain in practice. To address these issues, we propose a general disentangle model based on bi-level contrastive learning. It brings closer utterances in the same session while encourages each utterance to be near its clustered session prototypes in the representation space. Unlike existing approaches, our disentangle model works in both supervised setting with labeled data and unsupervised setting when no such data is available. The proposed method achieves new state-of-the-art performance on both settings across several public datasets",
    "checked": true,
    "id": "d07b5b01cf3530c3cf1997aa660da0c41562dc1c",
    "semantic_title": "conversation disentanglement with bi-level contrastive learning",
    "citation_count": 7,
    "authors": [
      "Chengyu Huang",
      "Zheng Zhang",
      "Hao Fei",
      "Lizi Liao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.218": {
    "title": "You can't pick your neighbors, or can you? When and How to Rely on Retrieval in the kNN-LM",
    "volume": "findings",
    "abstract": "Retrieval-enhanced language models (LMs), which condition their predictions on text retrieved from large external datastores, have recently shown significant perplexity improvements compared to standard LMs. One such approach, the kNN-LM, interpolates any existing LM's predictions with the output of a k-nearest neighbors model and requires no additional training. In this paper, we explore the importance of lexical and semantic matching in the context of items retrieved by kNN-LM. We find two trends: (1) the presence of large overlapping n-grams between the datastore and evaluation set plays an important factor in strong performance, even when the datastore is derived from the training data; and (2) the kNN-LM is most beneficial when retrieved items have high semantic similarity with the query. Based on our analysis, we define a new formulation of the kNN-LM that uses retrieval quality to assign the interpolation coefficient. We empirically measure the effectiveness of our approach on two English language modeling datasets, Wikitext-103 and PG-19. Our re-formulation of the kNN-LM is beneficial in both cases, and leads to nearly 4% improvement in perplexity on the Wikitext-103 test set",
    "checked": true,
    "id": "e832d22ca901346f50e8367afb99bd2bf6e29421",
    "semantic_title": "you can't pick your neighbors, or can you? when and how to rely on retrieval in the knn-lm",
    "citation_count": 10,
    "authors": [
      "Andrew Drozdov",
      "Shufan Wang",
      "Razieh Rahimi",
      "Andrew McCallum",
      "Hamed Zamani",
      "Mohit Iyyer"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.219": {
    "title": "StuBot: Learning by Teaching a Conversational Agent Through Machine Reading Comprehension",
    "volume": "findings",
    "abstract": "This paper proposes StuBot, a text-based conversational agent that provides adaptive feedback for learning by teaching. StuBot first asks the users to teach the learning content by summarizing and explaining it in their own words. After the users inputted the explanation text for teaching, StuBot uses a machine reading comprehension (MRC) engine to provide adaptive feedback with further questions about the insufficient parts of the explanation text. We conducted a within-subject study to evaluate the effectiveness of adaptive feedback by StuBot. Both the quantitative and qualitative results showed that learning by teaching with adaptive feedback can improve learning performance, immersion, and overall experience",
    "checked": true,
    "id": "9d91aee981eb7f0d2fc8e83195a0da34d3b7fb65",
    "semantic_title": "stubot: learning by teaching a conversational agent through machine reading comprehension",
    "citation_count": 1,
    "authors": [
      "Nayoung Jin",
      "Hana Lee"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.220": {
    "title": "Improved Universal Sentence Embeddings with Prompt-based Contrastive Learning and Energy-based Learning",
    "volume": "findings",
    "abstract": "Contrastive learning has been demonstrated to be effective in enhancing pre-trained language models (PLMs) to derive superior universal sentence embeddings. However, existing contrastive methods still have two limitations. Firstly, previous works may acquire poor performance under domain shift settings, thus hindering the application of sentence representations in practice. We attribute this low performance to the over-parameterization of PLMs with millions of parameters. To alleviate it, we propose PromCSE (Prompt-based Contrastive Learning for Sentence Embeddings), which only trains small-scale Soft Prompt (i.e., a set of trainable vectors) while keeping PLMs fixed. Secondly, the commonly used NT-Xent loss function of contrastive learning does not fully exploit hard negatives in supervised learning settings. To this end, we propose to integrate an Energy-based Hinge loss to enhance the pairwise discriminative power, inspired by the connection between the NT-Xent loss and the Energy-based Learning paradigm. Empirical results on seven standard semantic textual similarity (STS) tasks and a domain-shifted STS task both show the effectiveness of our method compared with the current state-of-the-art sentence embedding models",
    "checked": true,
    "id": "b6ae0600aaecf9c7501177fe5d99543b8e8b9823",
    "semantic_title": "improved universal sentence embeddings with prompt-based contrastive learning and energy-based learning",
    "citation_count": 29,
    "authors": [
      "Yuxin Jiang",
      "Linhan Zhang",
      "Wei Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.221": {
    "title": "RaP: Redundancy-aware Video-language Pre-training for Text-Video Retrieval",
    "volume": "findings",
    "abstract": "Video language pre-training methods have mainly adopted sparse sampling techniques to alleviate the temporal redundancy of videos. Though effective, sparse sampling still suffers inter-modal redundancy: visual redundancy and textual redundancy. Compared with highly generalized text, sparsely sampled frames usually contain text-independent portions, called visual redundancy. Sparse sampling is also likely to miss important frames corresponding to some text portions, resulting in textual redundancy. Inter-modal redundancy leads to a mismatch of video and text information, hindering the model from better learning the shared semantics across modalities. To alleviate it, we propose Redundancy-aware Video-language Pre-training. We design a redundancy measurement of video patches and text tokens by calculating the cross-modal minimum dis-similarity. Then, we penalize the high-redundant video patches and text tokens through a proposed redundancy-aware contrastive learning. We evaluate our method on four benchmark datasets, MSRVTT, MSVD, DiDeMo, and LSMDC, achieving a significant improvement over the previous state-of-the-art results",
    "checked": true,
    "id": "4aa9f132121c085441cb2bbb16f507d3a0f6327c",
    "semantic_title": "rap: redundancy-aware video-language pre-training for text-video retrieval",
    "citation_count": 4,
    "authors": [
      "Xing Wu",
      "Chaochen Gao",
      "Zijia Lin",
      "Zhongyuan Wang",
      "Jizhong Han",
      "Songlin Hu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.222": {
    "title": "FCGCL: Fine- and Coarse-Granularity Contrastive Learning for Speech Translation",
    "volume": "findings",
    "abstract": "It is notoriously difficult to implement end-to-end speech translation (E2E-ST) model because of the task complexity and data scarcity. Existing techniques often attempt to carry out implicit knowledge transfer from machine translation (MT) to ST model by imposing various constraints. However, in this transfer scenario, a significant problem is that the performance of the MT will drop significantly and the final transfer effect is also restricted. In this article, we recommend Fine and Coarse Granularity Contrastive Learning (FCGCL), which conduct explicit knowledge transfer from MT to ST model. Specially, we ensure through multi granularity contrastive learning that inputs with similar semantic between different modalities are encoded closely in the shared semantic space while inputs with different semantics are kept apart. Experiments on the MuST-C datasets on all 8 languages and further analysis show that our method can effectively improve the E2E-ST performance and achieves an average BLEU of 29.0",
    "checked": true,
    "id": "a09becf7a94e24f22fb3378e37904cf414ee6a9e",
    "semantic_title": "fcgcl: fine- and coarse-granularity contrastive learning for speech translation",
    "citation_count": 1,
    "authors": [
      "Hao Zhang",
      "Nianwen Si",
      "Yaqi Chen",
      "Zhen Li",
      "Tong Niu",
      "Xukui Yang",
      "Dan Qu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.223": {
    "title": "InfoCSE: Information-aggregated Contrastive Learning of Sentence Embeddings",
    "volume": "findings",
    "abstract": "Contrastive learning has been extensively studied in sentence embedding learning, which assumes that the embeddings of different views of the same sentence are closer. The constraint brought by this assumption is weak, and a good sentence representation should also be able to reconstruct the original sentence fragments. Therefore, this paper proposes an information-aggregated contrastive learning framework for learning unsupervised sentence embeddings, termed InfoCSE.InfoCSE forces the representation of [CLS] positions to aggregate denser sentence information by introducing an additional Masked language model task and a well-designed network. We evaluate the proposed InfoCSE on several benchmark datasets w.r.t the semantic text similarity (STS) task. Experimental results show that InfoCSE outperforms SimCSE by an average Spearman correlation of 2.60% on BERT-base, and 1.77% on BERT-large, achieving state-of-the-art results among unsupervised sentence representation learning methods",
    "checked": true,
    "id": "6e224434886c5cdeb4da4028702b32285cb4800f",
    "semantic_title": "infocse: information-aggregated contrastive learning of sentence embeddings",
    "citation_count": 24,
    "authors": [
      "Xing Wu",
      "Chaochen Gao",
      "Zijia Lin",
      "Jizhong Han",
      "Zhongyuan Wang",
      "Songlin Hu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.224": {
    "title": "Benchmarking Language Models for Code Syntax Understanding",
    "volume": "findings",
    "abstract": "Pre-trained language models have demonstrated impressive performance in both natural language processing and program understanding, which represent the input as a token sequence without explicitly modeling its structure. Some prior works show that pre-trained language models can capture the syntactic rules of natural languages without finetuning on syntax understanding tasks. However, there is limited understanding of how well pre-trained models understand the code structure so far. In this work, we perform the first thorough benchmarking of the state-of-the-art pre-trained models for identifying the syntactic structures of programs. Specifically, we introduce CodeSyntax, a large-scale dataset of programs annotated with the syntactic relationships in their corresponding abstract syntax trees. Our key observation is that pre-training on massive code data does not result in decent code syntax understanding. In fact, these pre-trained programming language models fail to match the performance of naive baselines based on positional offsets and keywords. We also present a natural language benchmark to highlight the differences between natural languages and programming languages in terms of understanding corresponding syntactic structures. Our findings point out key limitations of existing pre-training methods and suggest the importance of modeling syntactic structures for the programming language",
    "checked": true,
    "id": "a593ce5d2a93f3113be7717d08d1ba8e62fd7ddf",
    "semantic_title": "benchmarking language models for code syntax understanding",
    "citation_count": 9,
    "authors": [
      "Da Shen",
      "Xinyun Chen",
      "Chenguang Wang",
      "Koushik Sen",
      "Dawn Song"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.225": {
    "title": "Learning When and What to Quote: A Quotation Recommender System with Mutual Promotion of Recommendation and Generation",
    "volume": "findings",
    "abstract": "This work extends the current quotation recommendation task to a more realistic quotation recommender system that learns to predict when to quote and what to quote jointly. The system consists of three modules (tasks), a prediction module to predict whether to quote given conversation contexts, a recommendation module to recommend suitable quotations and a generation module generating quotations or sentences in ordinary language to continue the conversation. We benchmark several competitive models for the two newly introduced tasks (i.e., when-to-quote and what-to-continue). For quotation recommendation, compared with previous work that is either generation-based or ranking-based recommendation, we propose a novel framework with mutual promotion of generation module and ranking-based recommendation module. Experiments show that our framework achieves significantly better performance than baselines on two datasets. Further experiments and analyses validate the effectiveness of the proposed mechanisms and get a better understanding of the quotation recommendation task",
    "checked": true,
    "id": "fd4e3ccf44919ff2f03740e19bb5cd9a1e057ca5",
    "semantic_title": "learning when and what to quote: a quotation recommender system with mutual promotion of recommendation and generation",
    "citation_count": 2,
    "authors": [
      "Lingzhi Wang",
      "Xingshan Zeng",
      "Kam-Fai Wong"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.226": {
    "title": "Think Beyond Words: Exploring Context-Relevant Visual Commonsense for Diverse Dialogue Generation",
    "volume": "findings",
    "abstract": "Commonsense knowledge has been widely considered for building intelligent open-domain dialogue agents, aiming to generate meaningful and diverse responses. Previous works in this field usually lack the ability to effectively obtain and utilize auxiliary commonsense from the external visual world. In this paper, we argue that exploiting logical information in images related to context can be effective to enrich and steer the generation process. In view of this, we propose VICTOR, a context-relevant VIsual Commonsense enhanced dialogue generaTOR for generating coherent and informative responses. To obtain the associated visual commonsense, we devise a novel approach that expands topic words on the knowledge graph and maps them into daily scenarios. During the generation, the model adopts multimodal fusion mechanism to integrate visual and textual information, and adaptively combine their decoding distributions for better response generation. The experimental results on two public datasets show that our proposed method outperforms the latest competitive methods in terms of coherence and diversity",
    "checked": true,
    "id": "a6e6627f7391949ad9aaa0c0c875ac7d4e4a5f8b",
    "semantic_title": "think beyond words: exploring context-relevant visual commonsense for diverse dialogue generation",
    "citation_count": 4,
    "authors": [
      "Yiting Liu",
      "Liang Li",
      "Beichen Zhang",
      "Qingming Huang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.227": {
    "title": "Gender Bias in Meta-Embeddings",
    "volume": "findings",
    "abstract": "Different methods have been proposed to develop meta-embeddings from a given set of source embeddings. However, the source embeddings can contain unfair gender-related biases, and how these influence the meta-embeddings has not been studied yet. We study the gender bias in meta-embeddings created under three different settings:(1) meta-embedding multiple sources without performing any debiasing (Multi-Source No-Debiasing),(2) meta-embedding multiple sources debiased by a single method (Multi-Source Single-Debiasing), and(3) meta-embedding a single source debiased by different methods (Single-Source Multi-Debiasing).Our experimental results show that meta-embedding amplifies the gender biases compared to input source embeddings.We find that debiasing not only the sources but also their meta-embedding is needed to mitigate those biases. Moreover, we propose a novel debiasing method based on meta-embedding learning where we use multiple debiasing methods on a single source embedding and then create a single unbiased meta-embedding",
    "checked": true,
    "id": "2b145c1eec51ae2d8cf95361cddfa784b7a80e59",
    "semantic_title": "gender bias in meta-embeddings",
    "citation_count": 5,
    "authors": [
      "Masahiro Kaneko",
      "Danushka Bollegala",
      "Naoaki Okazaki"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.228": {
    "title": "Third-Party Aligner for Neural Word Alignments",
    "volume": "findings",
    "abstract": "Word alignment is to find translationally equivalent words between source and target sentences. Previous work has demonstrated that self-training can achieve competitive word alignment results. In this paper, we propose to use word alignments generated by a third-party word aligner to supervise the neural word alignment training. Specifically, source word and target word of each word pair aligned by the third-party aligner are trained to be close neighbors to each other in the contextualized embedding space when fine-tuning a pre-trained cross-lingual language model. Experiments on the benchmarks of various language pairs show that our approach can surprisingly do self-correction over the third-party supervision by finding more accurate word alignments and deleting wrong word alignments, leading to better performance than various third-party word aligners, including the currently best one. When we integrate all supervisions from various third-party aligners, we achieve state-of-the-art word alignment performances, with averagely more than two points lower alignment error rates than the best third-party aligner. We released our code at https://github.com/sdongchuanqi/Third-Party-Supervised-Aligner",
    "checked": true,
    "id": "766eced3fccccbc8c9fd3ad8ffb4350747dc5362",
    "semantic_title": "third-party aligner for neural word alignments",
    "citation_count": 0,
    "authors": [
      "Jinpeng Zhang",
      "Chuanqi Dong",
      "Xiangyu Duan",
      "Yuqi Zhang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.229": {
    "title": "QaDialMoE: Question-answering Dialogue based Fact Verification with Mixture of Experts",
    "volume": "findings",
    "abstract": "Fact verification is an essential tool to mitigate the spread of false information online, which has gained a widespread attention recently. However, a fact verification in the question-answering dialogue is still underexplored. In this paper, we propose a neural network based approach called question-answering dialogue based fact verification with mixture of experts (QaDialMoE). It exploits questions and evidence effectively in the verification process and can significantly improve the performance of fact verification. Specifically, we exploit the mixture of experts to focus on various interactions among responses, questions and evidence. A manager with an attention guidance module is implemented to guide the training of experts and assign a reasonable attention score to each expert. A prompt module is developed to generate synthetic questions that make our approach more generalizable. Finally, we evaluate the QaDialMoE and conduct a comparative study on three benchmark datasets. The experimental results demonstrate that our QaDialMoE outperforms previous approaches by a large margin and achieves new state-of-the-art results on all benchmarks. This includes the accuracy improvements on the HEALTHVER as 84.26%, the FAVIQ A dev set as 78.7%, the FAVIQ R dev set as 86.1%, test set as 86.0%, and the COLLOQUIAL as 89.5%. To our best knowledge, this is the first work to investigate a question-answering dialogue based fact verification, and achieves new state-of-the-art results on various benchmark datasets",
    "checked": true,
    "id": "d5789c54cb35b2cea39553f5794dc0f0e5a7e8b9",
    "semantic_title": "qadialmoe: question-answering dialogue based fact verification with mixture of experts",
    "citation_count": 1,
    "authors": [
      "Longzheng Wang",
      "Peng Zhang",
      "Xiaoyu Lu",
      "Lei Zhang",
      "Chaoyang Yan",
      "Chuang Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.230": {
    "title": "Multimodal Knowledge Learning for Named Entity Disambiguation",
    "volume": "findings",
    "abstract": "With the popularity of online social media, massive-scale multimodal information has brought new challenges to traditional Named Entity Disambiguation (NED) tasks. Recently, Multimodal Named Entity Disambiguation (MNED) has been proposed to link ambiguous mentions with the textual and visual contexts to a predefined knowledge graph. Existing attempts usually perform MNED by annotating multimodal mentions and adding multimodal features to traditional NED models. However, these studies may suffer from 1) failing to model multimodal information at the knowledge level, and 2) lacking multimodal annotation data against the large-scale unlabeled corpus. In this paper, we explore a pioneer study on leveraging multimodal knowledge learning to address the MNED task. Specifically, we first harvest multimodal knowledge in the Meta-Learning way, which is much easier than collecting ambiguous mention corpus. Then we design a knowledge-guided transfer learning strategy to extract unified representation from different modalities. Finally, we propose an Interactive Multimodal Learning Network (IMN) to fully utilize the multimodal information on both the mention and knowledge sides. Extensive experiments conducted on two public MNED datasets demonstrate that the proposed method achieves improvements over the state-of-the-art multimodal methods",
    "checked": true,
    "id": "90d36d4dd8d92c7d6f61b09151459aa1bd4a0b3b",
    "semantic_title": "multimodal knowledge learning for named entity disambiguation",
    "citation_count": 4,
    "authors": [
      "Zhang Dongjie",
      "Longtao Huang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.231": {
    "title": "Generative Prompt Tuning for Relation Classification",
    "volume": "findings",
    "abstract": "Using prompts to explore the knowledge contained within pre-trained language models for downstream tasks has now become an active topic. Current prompt tuning methods mostly convert the downstream tasks to masked language modeling problems by adding cloze-style phrases and mapping all labels to verbalizations with fixed length, which has proven effective for tasks with simple label spaces. However, when applied to relation classification exhibiting complex label spaces, vanilla prompt tuning methods may struggle with label verbalizations with arbitrary lengths due to rigid prompt restrictions. Inspired by the text infilling task for pre-training generative models that can flexibly predict missing spans, we propose a novel generative prompt tuning method to reformulate relation classification as an infilling problem, which frees our approach from limitations of current prompt based approaches and thus fully exploits rich semantics of entity and relation types. In addition, we design entity-guided decoding and discriminative relation scoring to generate and align relations effectively and efficiently during inference. Extensive experiments under fully supervised settings and low-resource settings demonstrate the effectiveness of our approach",
    "checked": true,
    "id": "aedc11b5d0e3f7c4547b845e109afcd7bd14f1c4",
    "semantic_title": "generative prompt tuning for relation classification",
    "citation_count": 9,
    "authors": [
      "Jiale Han",
      "Shuai Zhao",
      "Bo Cheng",
      "Shengkun Ma",
      "Wei Lu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.232": {
    "title": "Formulating Few-shot Fine-tuning Towards Language Model Pre-training: A Pilot Study on Named Entity Recognition",
    "volume": "findings",
    "abstract": "Fine-tuning pre-trained language models is a common practice in building NLP models for various tasks, including the case with less supervision. We argue that under the few-shot setting, formulating fine-tuning closer to the pre-training objective shall be able to unleash more benefits from the pre-trained language models. In this work, we take few-shot named entity recognition (NER) for a pilot study, where existing fine-tuning strategies are much different from pre-training. We propose a novel few-shot fine-tuning framework for NER, FFF-NER. Specifically, we introduce three new types of tokens, \"is-entity\", \"which-type\" and \"bracket\", so we can formulate the NER fine-tuning as (masked) token prediction or generation, depending on the choice of the pre-training objective. In our experiments, we apply to fine-tune both BERT and BART for few-shot NER on several benchmark datasets and observe significant improvements over existing fine-tuning strategies, including sequence labeling, prototype meta-learning, and prompt-based approaches. We further perform a series of ablation studies, showing few-shot NER performance is strongly correlated with the similarity between fine-tuning and pre-training",
    "checked": true,
    "id": "57063498396aeba8d22039348e1ef6d12ee414a5",
    "semantic_title": "formulating few-shot fine-tuning towards language model pre-training: a pilot study on named entity recognition",
    "citation_count": 4,
    "authors": [
      "Zihan Wang",
      "Kewen Zhao",
      "Zilong Wang",
      "Jingbo Shang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.233": {
    "title": "Masked Language Models Know Which are Popular: A Simple Ranking Strategy for Commonsense Question Answering",
    "volume": "findings",
    "abstract": "We propose a simple ranking strategy to solve a generative commonsense question answering (QA) problem. Compared with multiple-choice QA, it is challenging because the answers to a question are not unique and they are supposed to be popular and diverse. Our strategy exploits the dataset itself and negative samples that we collect from WordNet to train a ranker that picks out the most popular answers for commonsense questions. The effectiveness of our strategy is verified on different pre-trained masked language models (MLMs) in a pipeline framework, where an MLM reranks the generated answers. Further, we explore an end-to-end framework where MLMs are utilized to guide the generation of generative language models (GLMs). Taking advantage of reinforcement learning, we apply policy gradient to train a GLM with the rewards fed back by an MLM. Empirical results on ProtoQA dataset demonstrate that MLMs can acquire the ability to distinguish the popular answers and improve the typical answer generation of GLMs as well",
    "checked": true,
    "id": "5d2cd79dd3512113c3b57b6d107351f479248f5d",
    "semantic_title": "masked language models know which are popular: a simple ranking strategy for commonsense question answering",
    "citation_count": 2,
    "authors": [
      "Xuan Luo",
      "Chuang Fan",
      "Yice Zhang",
      "Wanguo Jiang",
      "Bing Qin",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.234": {
    "title": "DialogUSR: Complex Dialogue Utterance Splitting and Reformulation for Multiple Intent Detection",
    "volume": "findings",
    "abstract": "While interacting with chatbots, users may elicit multiple intents in a single dialogue utterance. Instead of training a dedicated multi-intent detection model, we propose DialogUSR, a dialogue utterance splitting and reformulation task that first splits multi-intent user query into several single-intent sub-queries and then recovers all the coreferred and omitted information in the sub-queries. DialogUSR can serve as a plug-in and domain-agnostic module that empowers the multi-intent detection for the deployed chatbots with minimal efforts. We collect a high-quality naturally occurring dataset that covers 23 domains with a multi-step crowd-souring procedure. To benchmark the proposed dataset, we propose multiple action-based generative models that involve end-to-end and two-stage training, and conduct in-depth analyses on the pros and cons of the proposed baselines",
    "checked": true,
    "id": "7085ee996d58bb0b53dd2fc394144996d4b93d69",
    "semantic_title": "dialogusr: complex dialogue utterance splitting and reformulation for multiple intent detection",
    "citation_count": 4,
    "authors": [
      "Haoran Meng",
      "Zheng Xin",
      "Tianyu Liu",
      "Zizhen Wang",
      "He Feng",
      "Binghuai Lin",
      "Xuemin Zhao",
      "Yunbo Cao",
      "Zhifang Sui"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.235": {
    "title": "Low-resource Interactive Active Labeling for Fine-tuning Language Models",
    "volume": "findings",
    "abstract": "Recently, active learning (AL) methods have been used to effectively fine-tune pre-trained language models for various NLP tasks such as sentiment analysis and document classification. However, given the task of fine-tuning language models, understanding the impact of different aspects on AL methods such as labeling cost, sample acquisition latency, and the diversity of the datasets necessitates a deeper investigation. This paper examines the performance of existing AL methods within a low-resource, interactive labeling setting. We observe that existing methods often underperform in such a setting while exhibiting higher latency and a lack of generalizability. To overcome these challenges, we propose a novel active learning method TYROUGE that employs a hybrid sampling strategy to minimize labeling cost and acquisition latency while providing a framework for adapting to dataset diversity via user guidance. Through our experiments, we observe that compared to SOTA methods, TYROUGE reduces the labeling cost by up to 43% and the acquisition latency by as much as 11X, while achieving comparable accuracy. Finally, we discuss the strengths and weaknesses of TYROUGE by exploring the impact of dataset characteristics",
    "checked": true,
    "id": "1ca1a371f8cbfb714126350afd5225eafe7f65ce",
    "semantic_title": "low-resource interactive active labeling for fine-tuning language models",
    "citation_count": 6,
    "authors": [
      "Seiji Maekawa",
      "Dan Zhang",
      "Hannah Kim",
      "Sajjadur Rahman",
      "Estevam Hruschka"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.236": {
    "title": "Getting the Most out of Simile Recognition",
    "volume": "findings",
    "abstract": "Simile recognition involves two subtasks: simile sentence classification that discriminates whether a sentence contains simile, and simile component extraction that locates the corresponding objects (i.e., tenors and vehicles).Recent work ignores features other than surface strings and suffers from the data hunger issue. We explore expressive features for this task to help achieve more effective data utilization. In particular, we study two types of features: 1) input-side features that include POS tags, dependency trees and word definitions, and 2) decoding features that capture the interdependence among various decoding decisions. We further construct a model named HGSR, which merges the input-side features as a heterogeneous graph and leverages decoding features via distillation. Experiments show that HGSR significantly outperforms the current state-of-the-art systems and carefully designed baselines, verifying the effectiveness of introduced features. We will release our code upon paper acceptance",
    "checked": true,
    "id": "45373297e00227e4559dc2e63a76021f4c8ab4fd",
    "semantic_title": "getting the most out of simile recognition",
    "citation_count": 0,
    "authors": [
      "Xiaoyue Wang",
      "Linfeng Song",
      "Xin Liu",
      "Chulun Zhou",
      "Hualin Zeng",
      "Jinsong Su"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.237": {
    "title": "A Unified Framework for Pun Generation with Humor Principles",
    "volume": "findings",
    "abstract": "We propose a unified framework to generate both homophonic and homographic puns to resolve the split-up in existing works. Specifically, we incorporate three linguistic attributes of puns to the language models: ambiguity, distinctiveness, and surprise. Our framework consists of three parts: 1) a context words/phrases selector to promote the aforementioned attributes, 2) a generation model trained on non-pun sentences to incorporate the context words/phrases into the generation output, and 3) a label predictor that learns the structure of puns which is used to steer the generation model at inference time. Evaluation results on both pun types demonstrate the efficacy of our model over strong baselines",
    "checked": true,
    "id": "af2ecdbd0252c8815512382dbab8b3fb47178d48",
    "semantic_title": "a unified framework for pun generation with humor principles",
    "citation_count": 9,
    "authors": [
      "Yufei Tian",
      "Divyanshu Sheth",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.238": {
    "title": "Improving English-Arabic Transliteration with Phonemic Memories",
    "volume": "findings",
    "abstract": "Transliteration is an important task in natural language processing (NLP) which aims to convert a name in the source language to the target language without changing its pronunciation. Particularly, transliteration from English to Arabic is highly needed in many applications, especially in countries (e.g., United Arab Emirates (UAE)) whose most citizens are foreigners but the official language is Arabic. In such a task-oriented scenario, namely transliterating the English names to the corresponding Arabic ones, the performance of the transliteration model is highly important. However, most existing neural approaches mainly apply a universal transliteration model with advanced encoders and decoders to the task, where limited attention is paid to leveraging the phonemic association between English and Arabic to further improve model performance. In this paper, we focus on transliteration of people's names from English to Arabic for the general public. In doing so, we collect a corpus named EANames by extracting high quality name pairs from online resources which better represent the names in the general public than linked Wikipedia entries that are always names of famous people). We propose a model for English-Arabic transliteration, where a memory module modeling the phonemic association between English and Arabic is used to guide the transliteration process. We run experiments on the collected data and the results demonstrate the effectiveness of our approach for English-Arabic transliteration",
    "checked": true,
    "id": "5ed6d4dfe04d3a7d042974410fda367dd070ab35",
    "semantic_title": "improving english-arabic transliteration with phonemic memories",
    "citation_count": 2,
    "authors": [
      "Yuanhe Tian",
      "Renze Lou",
      "Xiangyu Pang",
      "Lianxi Wang",
      "Shengyi Jiang",
      "Yan Song"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.239": {
    "title": "Mix-and-Match: Scalable Dialog Response Retrieval using Gaussian Mixture Embeddings",
    "volume": "findings",
    "abstract": "Embedding-based approaches for dialog response retrieval embed the context-response pairs as points in the embedding space. These approaches are scalable, but fail to account for the complex, many-to-many relationships that exist between context-response pairs. On the other end of the spectrum, there are approaches that feed the context-response pairs jointly through multiple layers of neural networks. These approaches can model the complex relationships between context-response pairs, but fail to scale when the set of responses is moderately large (>1000). In this paper, we propose a scalable model that can learn complex relationships between context-response pairs. Specifically, the model maps the contexts as well as responses to probability distributions over the embedding space. We train the models by optimizing the Kullback-Leibler divergence between the distributions induced by context-response pairs in the training data. We show that the resultant model achieves better performance as compared to other embedding-based approaches on publicly available conversation data",
    "checked": true,
    "id": "8708ffb9e983fad5455761db107104224cedb0af",
    "semantic_title": "mix-and-match: scalable dialog response retrieval using gaussian mixture embeddings",
    "citation_count": 0,
    "authors": [
      "Gaurav Pandey",
      "Danish Contractor",
      "Sachindra Joshi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.240": {
    "title": "AlphaTuning: Quantization-Aware Parameter-Efficient Adaptation of Large-Scale Pre-Trained Language Models",
    "volume": "findings",
    "abstract": "There are growing interests in adapting large-scale language models using parameter-efficient fine-tuning methods. However, accelerating the model itself and achieving better inference efficiency through model compression has not been thoroughly explored yet. Model compression could provide the benefits of reducing memory footprints, enabling low-precision computations, and ultimately achieving cost-effective inference. To combine parameter-efficient adaptation and model compression, we propose AlphaTuning consisting of post-training quantization of the pre-trained language model and fine-tuning only some parts of quantized parameters for a target task. Specifically, AlphaTuning works by employing binary-coding quantization, which factorizes the full-precision parameters into binary parameters and a separate set of scaling factors. During the adaptation phase, the binary values are frozen for all tasks, while the scaling factors are fine-tuned for the downstream task. We demonstrate that AlphaTuning, when applied to GPT-2 and OPT, performs competitively with full fine-tuning on a variety of downstream tasks while achieving >10x compression ratio under 4-bit quantization and >1,000x reduction in the number of trainable parameters",
    "checked": true,
    "id": "dcff38de0e5fb47bdb31d472c21b0c2d88cbc4fc",
    "semantic_title": "alphatuning: quantization-aware parameter-efficient adaptation of large-scale pre-trained language models",
    "citation_count": 15,
    "authors": [
      "Se Jung Kwon",
      "Jeonghoon Kim",
      "Jeongin Bae",
      "Kang Min Yoo",
      "Jin-Hwa Kim",
      "Baeseong Park",
      "Byeongwook Kim",
      "Jung-Woo Ha",
      "Nako Sung",
      "Dongsoo Lee"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.241": {
    "title": "Learning Invariant Representation Improves Robustness for MRC Models",
    "volume": "findings",
    "abstract": "The prosperity of Pretrained Language Models(PLM) has greatly promoted the development of Machine Reading Comprehension (MRC). However, these models are vulnerable and not robust to adversarial examples. In this paper, we propose Stable and Contrastive Question Answering (SCQA) to improve invariance of representation to alleviate these robustness issues. Specifically, we first construct positive example pairs which have same answer through data augmentation. Then SCQA learns enhanced representations with better alignment between positive pairs by introducing stability and contrastive loss. Experimental results show that our approach can boost the robustness of QA models cross different MRC tasks and attack sets significantly and consistently",
    "checked": true,
    "id": "91f917f341a5c7d7f3bccb598e5b297f981dc700",
    "semantic_title": "learning invariant representation improves robustness for mrc models",
    "citation_count": 0,
    "authors": [
      "Yu Hai",
      "Liang Wen",
      "Haoran Meng",
      "Tianyu Liu",
      "Houfeng Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.242": {
    "title": "ER-Test: Evaluating Explanation Regularization Methods for Language Models",
    "volume": "findings",
    "abstract": "By explaining how humans would solve a given task, human rationales can provide strong learning signal for neural language models (NLMs). Explanation regularization (ER) aims to improve NLM generalization by pushing the NLM's machine rationales (Which input tokens did the NLM focus on?) to align with human rationales (Which input tokens would humans focus on). Though prior works primarily study ER via in-distribution (ID) evaluation, out-of-distribution (OOD) generalization is often more critical in real-world scenarios, yet ER's effect on OOD generalization has been underexplored.In this paper, we introduce ER-Test, a framework for evaluating ER models' OOD generalization along three dimensions: unseen datasets, contrast set tests, and functional tests. Using ER-Test, we comprehensively analyze how ER models' OOD generalization varies with the rationale alignment criterion (loss function), human rationale type (instance-level v/s task-level), number and choice of rationale-annotated instances, and time budget for rationale annotation. Across two tasks and six datasets, we show that ER has little impact on ID performance but yields large OOD performance gains, with the best ER criterion being task-dependent. Also, ER can improve OOD performance even with task-level or few human rationales. Finally, we find that rationale annotation is more time-efficient than label annotation for improving OOD performance. Our results with ER-Test help demonstrate ER's utility and establish best practices for using ER effectively",
    "checked": true,
    "id": "60c7c46a6adccc1e8965c0c8dff40d00f573ddc2",
    "semantic_title": "er-test: evaluating explanation regularization methods for language models",
    "citation_count": 4,
    "authors": [
      "Brihi Joshi",
      "Aaron Chan",
      "Ziyi Liu",
      "Shaoliang Nie",
      "Maziar Sanjabi",
      "Hamed Firooz",
      "Xiang Ren"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.243": {
    "title": "Learning Cooperative Interactions for Multi-Overlap Aspect Sentiment Triplet Extraction",
    "volume": "findings",
    "abstract": "Aspect sentiment triplet extraction (ASTE) is an essential task, which aims to extract triplets(aspect, opinion, sentiment). However, overlapped triplets, especially multi-overlap triplets,make ASTE a challenge. Most existing methods suffer from multi-overlap triplets becausethey focus on the single interactions between an aspect and an opinion. To solve the aboveissues, we propose a novel multi-overlap triplet extraction method, which decodes the complexrelations between multiple aspects and opinions by learning their cooperative interactions. Overall, the method is based on an encoder-decoder architecture. During decoding, we design ajoint decoding mechanism, which employs a multi-channel strategy to generate aspects andopinions through the cooperative interactions between them jointly. Furthermore, we constructa correlation-enhanced network to reinforce the interactions between related aspectsand opinions for sentiment prediction. Besides, a relation-wise calibration scheme is adoptedto further improve performance. Experiments show that our method outperforms baselines,especially multi-overlap triplets",
    "checked": true,
    "id": "58475a3c1624d8033d7d75017e20e05d21c683f1",
    "semantic_title": "learning cooperative interactions for multi-overlap aspect sentiment triplet extraction",
    "citation_count": 1,
    "authors": [
      "Shiman Zhao",
      "Wei Chen",
      "Tengjiao Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.244": {
    "title": "Different Tunes Played with Equal Skill: Exploring a Unified Optimization Subspace for Parameter-Efficient Tuning",
    "volume": "findings",
    "abstract": "Delta tuning (DET, also known as parameter-efficient tuning) is deemed as the new paradigm for using pre-trained language models (PLMs). Up to now, various DETs with distinct design elements have been proposed, achieving performance on par with fine-tuning. However, the mechanisms behind the above success are still under-explored, especially the connections among various DETs. To fathom the mystery, we hypothesize that the adaptations of different DETs could all be reparameterized as low-dimensional optimizations in a unified optimization subspace, which could be found by jointly decomposing independent solutions of different DETs. Then we explore the connections among different DETs by conducting optimization within the subspace. In experiments, we find that, for a certain DET, conducting optimization simply in the subspace could achieve comparable performance to its original space, and the found solution in the subspace could be transferred to another DET and achieve non-trivial performance. We also visualize the performance landscape of the subspace, and find that, there exists a substantial region where different DETs all perform well. Finally, we extend our analysis and show the strong connections between fine-tuning and DETs. The codes are publicly available at https://github.com/thunlp/Unified-DeltaTuning",
    "checked": true,
    "id": "28a5a6358fe6d5a8290a2ac6dd7a61f814c4586b",
    "semantic_title": "different tunes played with equal skill: exploring a unified optimization subspace for parameter-efficient tuning",
    "citation_count": 0,
    "authors": [
      "Jing Yi",
      "Weize Chen",
      "Yujia Qin",
      "Yankai Lin",
      "Ning Ding",
      "Xu Han",
      "Zhiyuan Liu",
      "Maosong Sun",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.245": {
    "title": "Explainable Slot Type Attentions to Improve Joint Intent Detection and Slot Filling",
    "volume": "findings",
    "abstract": "Joint intent detection and slot filling is a key research topic in natural language understanding (NLU). Existing joint intent and slot filling systems analyze and compute features collectively for all slot types, and importantly, have no way to explain the slot filling model decisions. In this work, we propose a novel approach that: (i) learns to generate additional slot type specific features in order to improve accuracy and (ii) provides explanations for slot filling decisions for the first time in a joint NLU model. We perform an additional constrained supervision using a set of binary classifiers for the slot type specific feature learning, thus ensuring appropriate attention weights are learned in the process to explain slot filling decisions for utterances. Our model is inherently explainable and does not need any post-hoc processing. We evaluate our approach on two widely used datasets and show accuracy improvements. Moreover, a detailed analysis is also provided for the exclusive slot explainability",
    "checked": true,
    "id": "f48543f11a1235a5ca0383ce1d191e5acb9f62a3",
    "semantic_title": "explainable slot type attentions to improve joint intent detection and slot filling",
    "citation_count": 3,
    "authors": [
      "Kalpa Gunaratna",
      "Vijay Srinivasan",
      "Akhila Yerukola",
      "Hongxia Jin"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.246": {
    "title": "PseudoReasoner: Leveraging Pseudo Labels for Commonsense Knowledge Base Population",
    "volume": "findings",
    "abstract": "Commonsense Knowledge Base (CSKB) Population aims at reasoning over unseen entities and assertions on CSKBs, and is an important yet hard commonsense reasoning task. One challenge is that it requires out-of-domain generalization ability as the source CSKB for training is of a relatively smaller scale (1M) while the whole candidate space for population is way larger (200M). We propose PseudoReasoner, a semi-supervised learning framework for CSKB population that uses a teacher model pre-trained on CSKBs to provide pseudo labels on the unlabeled candidate dataset for a student model to learn from. The teacher can be a generative model rather than restricted to discriminative models as previous works. In addition, we design a new filtering procedure for pseudo labels based on influence function and the student model's prediction to further improve the performance. The framework can improve the backbone model KG-BERT (RoBERTa-large) by 3.3 points on the overall performance and especially, 5.3 points on the out-of-domain performance, and achieves the state-of-the-art. The codes will be made public on acceptance. Codes and data are available at https://github.com/HKUST-KnowComp/PseudoReasoner",
    "checked": true,
    "id": "ffa3ed87563fad0369078314d329cc3d59001ac7",
    "semantic_title": "pseudoreasoner: leveraging pseudo labels for commonsense knowledge base population",
    "citation_count": 8,
    "authors": [
      "Tianqing Fang",
      "Quyet V. Do",
      "Hongming Zhang",
      "Yangqiu Song",
      "Ginny Y. Wong",
      "Simon See"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.247": {
    "title": "History-Aware Hierarchical Transformer for Multi-session Open-domain Dialogue System",
    "volume": "findings",
    "abstract": "With the evolution of pre-trained language models, current open-domain dialogue systems have achieved great progress in conducting one-session conversations. In contrast, Multi-Session Conversation (MSC), which consists of multiple sessions over a long term with the same user, is under-investigated. In this paper, we propose History-Aware Hierarchical Transformer (HAHT) for multi-session open-domain dialogue. HAHT maintains a long-term memory of history conversations and utilizes history information to understand current conversation context and generate well-informed and context-relevant responses. Specifically, HAHT first encodes history conversation sessions hierarchically into a history memory. Then, HAHT leverages historical information to facilitate the understanding of the current conversation context by encoding the history memory together with the current context with attention-based mechanisms. Finally, to explicitly utilize historical information, HAHT uses a history-aware response generator that switches between a generic vocabulary and a history-aware vocabulary. Experimental results on a large-scale MSC dataset suggest that the proposed HAHT model consistently outperforms baseline models. Human evaluation results support that HAHT generates more human-like, context-relevant, and history-relevant responses than baseline models",
    "checked": true,
    "id": "7b5cf0af000639de2f3ad16f83b145a87b3d015a",
    "semantic_title": "history-aware hierarchical transformer for multi-session open-domain dialogue system",
    "citation_count": 7,
    "authors": [
      "Tong Zhang",
      "Yong Liu",
      "Boyang Li",
      "Zhiwei Zeng",
      "Pengwei Wang",
      "Yuan You",
      "Chunyan Miao",
      "Lizhen Cui"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.248": {
    "title": "Guiding Abstractive Dialogue Summarization with Content Planning",
    "volume": "findings",
    "abstract": "Abstractive dialogue summarization has recently been receiving more attention. We propose a coarse-to-fine model for generating abstractive dialogue summaries, and introduce a fact-aware reinforcement learning (RL) objective that improves the fact consistency between the dialogue and the generated summary. Initially, the model generates the predicate-argument spans of the dialogue, and then generates the final summary through a fact-aware RL objective. Extensive experiments and analysis on two benchmark datasets demonstrate that our proposed method effectively improves the quality of the generated summary, especially in coherence and consistency",
    "checked": true,
    "id": "64a00ef08015d73dbe041d76a17fff7cb26fe075",
    "semantic_title": "guiding abstractive dialogue summarization with content planning",
    "citation_count": 1,
    "authors": [
      "Ye Wang",
      "Xiaojun Wan",
      "Zhiping Cai"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.249": {
    "title": "Truncation Sampling as Language Model Desmoothing",
    "volume": "findings",
    "abstract": "Long samples of text from neural language models can be of poor quality. Truncation sampling algorithms–like top-p or top-k—address this by setting some words' probabilities to zero at each step. This work investigates why these methods are important, and how to improve them. We propose thinking of a neural language model as a mixture of a true distribution and a smoothing distribution that avoids infinite perplexity. In this light, truncation algorithms aim to perform desmoothing, estimating a subset of the support of the true distribution. Finding a good subset is crucial: we show that top-p unnecessarily truncates high-probability words, for example causing it to truncate all words but Trump for a document that starts with Donald. We introduce eta-sampling, which truncates words below an entropy-dependent probability threshold. Compared to previous algorithms, our eta-sampling generates more plausible long documents according to humans, is better at breaking out of repetition, and behaves more reasonably on a battery of test distributions",
    "checked": true,
    "id": "21f0b7d4d4163e7a06fb420599b586958e9168a3",
    "semantic_title": "truncation sampling as language model desmoothing",
    "citation_count": 38,
    "authors": [
      "John Hewitt",
      "Christopher Manning",
      "Percy Liang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.250": {
    "title": "Knowledge-grounded Dialog State Tracking",
    "volume": "findings",
    "abstract": "Knowledge (including structured knowledge such as schema and ontology and unstructured knowledge such as web corpus) is a critical part of dialog understanding, especially for unseen tasks and domains. Traditionally, such domain-specific knowledge is encoded implicitly into model parameters for the execution of downstream tasks, which makes training inefficient. In addition , such models are not easily transferable to new tasks with different schemas. In this work, we propose to perform dialog state tracking grounded on knowledge encoded externally. We query relevant knowledge of various forms based on the dialog context where such information can grounds the prediction of dialog states. We demonstrate superior performance of our proposed method over strong baselines, especially in the few-shot learning setting",
    "checked": true,
    "id": "c1614ab718dad97018ee34fd57864bb58b6ecaba",
    "semantic_title": "knowledge-grounded dialog state tracking",
    "citation_count": 3,
    "authors": [
      "Dian Yu",
      "Mingqiu Wang",
      "Yuan Cao",
      "Laurent El Shafey",
      "Izhak Shafran",
      "Hagen Soltau"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.251": {
    "title": "Context-aware Information-theoretic Causal De-biasing for Interactive Sequence Labeling",
    "volume": "findings",
    "abstract": "Supervised training of existing deep learning models for sequence labeling relies on large scale labeled datasets. Such datasets are generally created with crowd-source labeling. However, crowd-source labeling for tasks of sequence labeling can be expensive and time-consuming. Further, crowd-source labeling by external annotators may not be appropriate for data that contains user private information. Considering the above limitations of crowd-source labeling, we study interactive sequence labeling that allows training directly with the user feedback, which alleviates the annotation cost and maintains the user privacy. We identify two bias, namely, context bias and feedback bias, by formulating interactive sequence labeling via a Structural Causal Model (SCM). To alleviate the context and feedback bias based on the SCM, we identify the frequent context tokens as confounders in the backdoor adjustment and further propose an entropy-based modulation that is inspired by information theory. entities more sample-efficiently. With extensive experiments, we validate that our approach can effectively alleviate the biases and our models can be efficiently learnt with the user feedback",
    "checked": true,
    "id": "6977cd193eb360c3271cc0c6dd7efc10493d0387",
    "semantic_title": "context-aware information-theoretic causal de-biasing for interactive sequence labeling",
    "citation_count": 3,
    "authors": [
      "Junda Wu",
      "Rui Wang",
      "Tong Yu",
      "Ruiyi Zhang",
      "Handong Zhao",
      "Shuai Li",
      "Ricardo Henao",
      "Ani Nenkova"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.252": {
    "title": "Simple but Challenging: Natural Language Inference Models Fail on Simple Sentences",
    "volume": "findings",
    "abstract": "Natural language inference (NLI) is a task to infer the relationship between a premise and a hypothesis (e.g., entailment, neutral, or contradiction), and transformer-based models perform well on current NLI datasets such as MNLI and SNLI. Nevertheless, given the linguistic complexity of the large-scale datasets, it remains controversial whether these models can truly infer the relationship between sentences or they simply guess the answer via shallow heuristics. Here, we introduce a controlled evaluation set called Simple Pair to test the basic sentence inference ability of NLI models using sentences with syntactically simple structures. Three popular transformer-based models, i.e., BERT, RoBERTa, and DeBERTa, are employed. We find that these models fine-tuned on MNLI or SNLI perform very poorly on Simple Pair (< 35.4% accuracy). Further analyses reveal event coreference and compositional binding problems in these models. To improve the model performance, we augment the training set, i.e., MNLI or SNLI, with a few examples constructed based on Simple Pair ( 1% of the size of the original SNLI/MNLI training sets). Models fine-tuned on the augmented training set maintain high performance on MNLI/SNLI and perform very well on Simple Pair (~100% accuracy). Furthermore, the positive performance of the augmented training models can transfer to more complex examples constructed based on sentences from MNLI and SNLI. Taken together, the current work shows that (1) models achieving high accuracy on mainstream large-scale datasets still lack the capacity to draw accurate inferences on simple sentences, and (2) augmenting mainstream datasets with a small number of target simple sentences can effectively improve model performance",
    "checked": true,
    "id": "7275e95bc7a5f63f58c575f953491c4459fec5ed",
    "semantic_title": "simple but challenging: natural language inference models fail on simple sentences",
    "citation_count": 0,
    "authors": [
      "Cheng Luo",
      "Wei Liu",
      "Jieyu Lin",
      "Jiajie Zou",
      "Ming Xiang",
      "Nai Ding"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.253": {
    "title": "DORE: Document Ordered Relation Extraction based on Generative Framework",
    "volume": "findings",
    "abstract": "In recent years, there is a surge of generation-based information extraction work, which allows a more direct use of pre-trained language models and efficiently captures output dependencies. However, previous generative methods using lexical representation do not naturally fit document-level relation extraction (DocRE) where there are multiple entities and relational facts. In this paper, we investigate the root cause of the underwhelming performance of the existing generative DocRE models and discover that the culprit is the inadequacy of the training paradigm, instead of the capacities of the models. We propose to generate a symbolic and ordered sequence from the relation matrix which is deterministic and easier for model to learn. Moreover, we design a parallel row generation method to process overlong target sequences. Besides, we introduce several negative sampling strategies to improve the performance with balanced signals. Experimental results on four datasets show that our proposed method can improve the performance of the generative DocRE models",
    "checked": true,
    "id": "744ebaadb521be2c7a0f0af97ad2c8d2f77a796e",
    "semantic_title": "dore: document ordered relation extraction based on generative framework",
    "citation_count": 2,
    "authors": [
      "Qipeng Guo",
      "Yuqing Yang",
      "Hang Yan",
      "Xipeng Qiu",
      "Zheng Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.254": {
    "title": "Explicit Role Interaction Network for Event Argument Extraction",
    "volume": "findings",
    "abstract": "Event argument extraction is a challenging subtask of event extraction, aiming to identify and assign roles to arguments under a certain event. Existing methods extract arguments of each role independently, ignoring the relationship between different roles. Such an approach hinders the model from learning explicit interactions between different roles to improve the performance of individual argument extraction. As a solution, we design a neural model that we refer to as the Explicit Role Interaction Network (ERIN) which allows for dynamically capturing the correlations between different argument roles within an event. Extensive experiments on the benchmark dataset ACE2005 demonstrate the superiority of our proposed model to existing approaches",
    "checked": true,
    "id": "78be0503feac6cefbb928b7cf63e558af11cb389",
    "semantic_title": "explicit role interaction network for event argument extraction",
    "citation_count": 2,
    "authors": [
      "Nan Ding",
      "Chunming Hu",
      "Kai Sun",
      "Samuel Mensah",
      "Richong Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.255": {
    "title": "Few-Shot Out-of-Domain Transfer Learning of Natural Language Explanations in a Label-Abundant Setup",
    "volume": "findings",
    "abstract": "Training a model to provide natural language explanations (NLEs) for its predictions usually requires the acquisition of task-specific NLEs, which is time- and resource-consuming. A potential solution is the few-shot out-of-domain transfer of NLEs from a parent task with many NLEs to a child task. In this work, we examine the setup in which the child task has few NLEs but abundant labels. We establish four few-shot transfer learning methods that cover the possible fine-tuning combinations of the labels and NLEs for the parent and child tasks. We transfer explainability from a large natural language inference dataset (e-SNLI) separately to two child tasks: (1) hard cases of pronoun resolution, where we introduce the small-e-WinoGrande dataset of NLEs on top of the WinoGrande dataset, and (2) commonsense validation (ComVE). Our results demonstrate that the parent task helps with NLE generation and we establish the best methods for this setup",
    "checked": true,
    "id": "0bc8eae192dbd489f8857c0f6c03cc491f72d396",
    "semantic_title": "few-shot out-of-domain transfer learning of natural language explanations",
    "citation_count": 11,
    "authors": [
      "Yordan Yordanov",
      "Vid Kocijan",
      "Thomas Lukasiewicz",
      "Oana-Maria Camburu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.256": {
    "title": "RoChBert: Towards Robust BERT Fine-tuning for Chinese",
    "volume": "findings",
    "abstract": "Despite of the superb performance on a wide range of tasks, pre-trained language models (e.g., BERT) have been proved vulnerable to adversarial texts. In this paper, we present RoChBERT, a framework to build more Robust BERT-based models by utilizing a more comprehensive adversarial graph to fuse Chinese phonetic and glyph features into pre-trained representations during fine-tuning. Inspired by curriculum learning, we further propose to augment the training dataset with adversarial texts in combination with intermediate samples. Extensive experiments demonstrate that RoChBERT outperforms previous methods in significant ways: (i) robust – RoChBERT greatly improves the model robustness without sacrificing accuracy on benign texts. Specifically, the defense lowers the success rates of unlimited and limited attacks by 59.43% and 39.33% respectively, while remaining accuracy of 93.30%; (ii) flexible – RoChBERT can easily extend to various language models to solve different downstream tasks with excellent performance; and (iii) efficient – RoChBERT can be directly applied to the fine-tuning stage without pre-training language model from scratch, and the proposed data augmentation method is also low-cost",
    "checked": true,
    "id": "fe3e66445d364b54b677e4d05b36ed6abdc057f2",
    "semantic_title": "rochbert: towards robust bert fine-tuning for chinese",
    "citation_count": 3,
    "authors": [
      "Zihan Zhang",
      "Jinfeng Li",
      "Ning Shi",
      "Bo Yuan",
      "Xiangyu Liu",
      "Rong Zhang",
      "Hui Xue",
      "Donghong Sun",
      "Chao Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.257": {
    "title": "Lexical Entailment with Hierarchy Representations by Deep Metric Learning",
    "volume": "findings",
    "abstract": "In this paper, we introduce a novel method for lexical entailment tasks, which detects a hyponym-hypernym relation among words. Existing lexical entailment studies are lacking in generalization performance, as they cannot be applied to words that are not included in the training dataset. Moreover, existing work evaluates the performance by using the dataset that contains words used for training. This study proposes a method that learns a mapping from word embeddings to the hierarchical embeddings in order to predict the hypernymy relations of any input words. To validate the generalization performance, we conduct experiments using a train dataset that does not overlap with the evaluation dataset. As a result, our method achieved state-of-the-art performance and showed robustness for unknown words",
    "checked": true,
    "id": "d80013d167522bdf30e8ebde30ee8198a2454f2e",
    "semantic_title": "lexical entailment with hierarchy representations by deep metric learning",
    "citation_count": 0,
    "authors": [
      "Naomi Sato",
      "Masaru Isonuma",
      "Kimitaka Asatani",
      "Shoya Ishizuka",
      "Aori Shimizu",
      "Ichiro Sakata"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.258": {
    "title": "Improving the Sample Efficiency of Prompt Tuning with Domain Adaptation",
    "volume": "findings",
    "abstract": "Prompt tuning, or the conditioning of a frozen pretrained language model (PLM) with soft prompts learned from data, has demonstrated impressive performance on a wide range of NLP tasks. However, prompt tuning requires a large training dataset to be effective and is outperformed by finetuning the entire PLM in data-scarce regimes. Previous work (Gu et al., 2022, Vu et al., 2022) proposed to transfer soft prompts pretrained on the source domain to the target domain. In this paper, we explore domain adaptation for prompt tuning, a problem setting where unlabeled data from the target domain are available during pretraining. We propose bOosting Prompt TunIng with doMain Adaptation (OPTIMA), which regularizes the decision boundary to be smooth around regions where source and target data distributions are similar. Extensive experiments demonstrate that OPTIMA significantly enhances the transferability and sample-efficiency of prompt tuning compared to strong baselines. Moreover, in few-shot settings, OPTIMA exceeds full-model tuning by a large margin",
    "checked": true,
    "id": "a046c4ca678ab402ac380ed171caa0e48fc51378",
    "semantic_title": "improving the sample efficiency of prompt tuning with domain adaptation",
    "citation_count": 13,
    "authors": [
      "Xu Guo",
      "Boyang Li",
      "Han Yu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.259": {
    "title": "McPhraSy: Multi-Context Phrase Similarity and Clustering",
    "volume": "findings",
    "abstract": "Phrase similarity is a key component of many NLP applications. Current phrase similarity methods focus on embedding the phrase itself and use the phrase context only during training of the pretrained model. To better leverage the information in the context, we propose McPhraSy (Multi-context Phrase Similarity), a novel algorithm for estimating the similarity of phrases based on multiple contexts. At inference time, McPhraSy represents each phrase by considering multiple contexts in which it appears and computes the similarity of two phrases by aggregating the pairwise similarities between the contexts of the phrases. Incorporating context during inference enables McPhraSy to outperform current state-of-the-art models on two phrase similarity datasets by up to 13.3%. Finally, we also present a new downstream task that relies on phrase similarity – keyphrase clustering – and create a new benchmark for it in the product reviews domain. We show that McPhraSy surpasses all other baselines for this task",
    "checked": true,
    "id": "01a22ae0acf2387adb15e03cb3d91323681c0e40",
    "semantic_title": "mcphrasy: multi-context phrase similarity and clustering",
    "citation_count": 2,
    "authors": [
      "Amir Cohen",
      "Hila Gonen",
      "Ori Shapira",
      "Ran Levy",
      "Yoav Goldberg"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.260": {
    "title": "CANarEx: Contextually Aware Narrative Extraction for Semantically Rich Text-as-data Applications",
    "volume": "findings",
    "abstract": "Narrative modelling is an area of active research, motivated by the acknowledgement of narratives as drivers of societal decision making. These research efforts conceptualize narratives as connected entity chains, and modeling typically focuses on the identification of entities and their connections within a text. An emerging approach to narrative modelling is the use of semantic role labeling (SRL) to extract Entity-Verb-Entity (E-V-Es) tuples from a text, followed by dimensionality reduction to reduce the space of entities and connections separately. This process penalises the semantic richness of narratives and discards much contextual information along the way. Here, we propose an alternate narrative extraction approach - CANarEx, incorporating a pipeline of common contextual constructs through co-reference resolution, micro-narrative generation and clustering of these narratives through sentence embeddings. We evaluate our approach through testing the recovery of \"narrative time-series clusters\", mimicking a desirable text-as-data task. The evaluation framework leverages synthetic data generated using a GPT-3 model. The GPT-3 model is trained to generate similar sentences using a large dataset of news articles. The synthetic data maps to three topics in the news dataset. We then generate narrative time-series document cluster representations by mapping the synthetic data to three distinct signals synthetically injected into the testing corpus. Evaluation results demonstrate the superior ability of CANarEx to recover narrative time-series through reduced MSE and improved precision/recall relative to existing methods. The validity is further reinforced through ablation studies and qualitative analysis",
    "checked": true,
    "id": "28782b8feb97c09882607c1a1b99b15779481ca8",
    "semantic_title": "canarex: contextually aware narrative extraction for semantically rich text-as-data applications",
    "citation_count": 3,
    "authors": [
      "Nandini Anantharama",
      "Simon Angus",
      "Lachlan O’Neill"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.261": {
    "title": "Narrate Dialogues for Better Summarization",
    "volume": "findings",
    "abstract": "Dialogue summarization models aim to generate a concise and accurate summary for multi-party dialogue. The complexity of dialogue, including coreference, dialogue acts, and inter-speaker interactions bring unique challenges to dialogue summarization. Most recent neural models achieve state-of-art performance following the pretrain-then-finetune recipe, where the large-scale language model (LLM) is pretrained on large-scale single-speaker written text, but later finetuned on multi-speaker dialogue text. To mitigate the gap between pretraining and finetuning, we propose several approaches to convert the dialogue into a third-person narrative style and show that the narration serves as a valuable annotation for LLMs. Empirical results on three benchmark datasets show our simple approach achieves higher scores on the ROUGE and a factual correctness metric",
    "checked": true,
    "id": "ff57d24642a5bcaaa4e1b06be10088d04537051b",
    "semantic_title": "narrate dialogues for better summarization",
    "citation_count": 2,
    "authors": [
      "Ruochen Xu",
      "Chenguang Zhu",
      "Michael Zeng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.262": {
    "title": "Towards Identifying Social Bias in Dialog Systems: Framework, Dataset, and Benchmark",
    "volume": "findings",
    "abstract": "Among all the safety concerns that hinder the deployment of open-domain dialog systems (e.g., offensive languages, biases, and toxic behaviors), social bias presents an insidious challenge. Addressing this challenge requires rigorous analyses and normative reasoning. In this paper, we focus our investigation on social bias measurement to facilitate the development of unbiased dialog systems. We first propose a novel Dial-Bias Framework for analyzing the social bias in conversations using a holistic method beyond bias lexicons or dichotomous annotations. Leveraging the proposed framework, we further introduce the CDial-Bias Dataset which is, to the best of our knowledge, the first annotated Chinese social bias dialog dataset. We also establish a fine-grained dialog bias measurement benchmark and conduct in-depth ablation studies to shed light on the utility of the detailed annotations in the proposed dataset. Finally, we evaluate representative Chinese generative models with our classifiers to unveil the presence of social bias in these systems",
    "checked": true,
    "id": "64acb0084c9dd8f454421ccc9289c1e389d7fcb8",
    "semantic_title": "towards identifying social bias in dialog systems: framework, dataset, and benchmark",
    "citation_count": 17,
    "authors": [
      "Jingyan Zhou",
      "Jiawen Deng",
      "Fei Mi",
      "Yitong Li",
      "Yasheng Wang",
      "Minlie Huang",
      "Xin Jiang",
      "Qun Liu",
      "Helen Meng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.263": {
    "title": "CrossRE: A Cross-Domain Dataset for Relation Extraction",
    "volume": "findings",
    "abstract": "Relation Extraction (RE) has attracted increasing attention, but current RE evaluation is limited to in-domain evaluation setups. Little is known on how well a RE system fares in challenging, but realistic out-of-distribution evaluation setups. To address this gap, we propose CrossRE, a new, freely-available cross-domain benchmark for RE, which comprises six distinct text domains and includes multi-label annotations. An additional innovation is that we release meta-data collected during annotation, to include explanations and flags of difficult instances. We provide an empirical evaluation with a state-of-the-art model for relation classification. As the meta-data enables us to shed new light on the state-of-the-art model, we provide a comprehensive analysis on the impact of difficult cases and find correlations between model and human annotations. Overall, our empirical investigation highlights the difficulty of cross-domain RE. We release our dataset, to spur more research in this direction",
    "checked": true,
    "id": "e80a95215a32d08d27d7d62aa6ad87ae8a007553",
    "semantic_title": "crossre: a cross-domain dataset for relation extraction",
    "citation_count": 10,
    "authors": [
      "Elisa Bassignana",
      "Barbara Plank"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.264": {
    "title": "Probing Structural Knowledge from Pre-trained Language Model for Argumentation Relation Classification",
    "volume": "findings",
    "abstract": "Extracting fine-grained structural information between argumentation component (AC) pairs is essential for argumentation relation classification (ARC). However, most previous studies attempt to model the relationship between AC pairs using AC level similarity or semantically relevant features. They ignore the complex interaction between AC pairs and cannot effectively reason the argumentation relation deeply. Therefore, in this paper, we propose a novel dual prior graph neural network (DPGNN) to jointly explore the probing knowledge derived from pre-trained language models (PLMs) and the syntactical information for comprehensively modeling the relationship between AC pairs. Specifically, we construct a probing graph by using probing knowledge derived from PLMs to recognize and align the relational information within and across the argumentation components. In addition, we propose a mutual dependency graph for the AC pair to reason the fine-grained syntactic structural information, in which the syntactical correlation between words is set by the dependency information within AC and mutual attention mechanism across ACs. The knowledge learned from the probing graph and the dependency graph are combined to comprehensively capture the aligned relationships of AC pairs for improving the results of ARC. Experimental results on three public datasets show that DPGNN outperforms the state-of-the-art baselines by a noticeable margin",
    "checked": true,
    "id": "b986497235021497d06e3f4933ab9229b5041a8f",
    "semantic_title": "probing structural knowledge from pre-trained language model for argumentation relation classification",
    "citation_count": 2,
    "authors": [
      "Yang Sun",
      "Bin Liang",
      "Jianzhu Bao",
      "Min Yang",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.265": {
    "title": "LogicNMR: Probing the Non-monotonic Reasoning Ability of Pre-trained Language Models",
    "volume": "findings",
    "abstract": "The logical reasoning capabilities of pre-trained language models have recently received much attention. As one of the vital reasoning paradigms, non-monotonic reasoning refers to the fact that conclusions may be invalidated with new information. Existing work has constructed a non-monotonic inference dataset 𝛿-NLI and explored the performance of language models on it. However, the 𝛿-NLI dataset is entangled with commonsense reasoning. In this paper, we explore the pure non-monotonic reasoning ability of pre-trained language models. We build a non-monotonic reasoning benchmark, named LogicNMR, with explicit default rules and iterative updates. In the experimental part, the performance of popular language models on LogicNMR is explored from the perspectives of accuracy, generalization, proof-based traceability and robustness. The experimental results show that even though the fine-tuned language models achieve an accuracy of more than 94.4% on LogicNMR, they perform unsatisfactorily, with a significant drop, in generalization and proof-based traceability",
    "checked": true,
    "id": "cb9f74be6f257ebcfad1fa0dbc9f9c00be1d6b68",
    "semantic_title": "logicnmr: probing the non-monotonic reasoning ability of pre-trained language models",
    "citation_count": 1,
    "authors": [
      "Yeliang Xiu",
      "Zhanhao Xiao",
      "Yongmei Liu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.266": {
    "title": "Cheater's Bowl: Human vs. Computer Search Strategies for Open-Domain QA",
    "volume": "findings",
    "abstract": "For humans and computers, the first step in answering an open-domain question is retrieving a set of relevant documents from a large corpus. However, the strategies that computers use fundamentally differ from those of humans. To better understand these differences, we design a gamified interface for data collection—Cheater's Bowl—where a human answers complex questions with access to both traditional and modern search tools. We collect a dataset of human search sessions, analyze human search strategies, and compare them to state-of-the-art multi-hop QA models. Humans query logically, apply dynamic search chains, and use world knowledge to boost searching. We demonstrate how human queries can improve the accuracy of existing systems and propose improving the future design of QA models",
    "checked": true,
    "id": "381ea5e5b2a5ad6982f62e07622f35f69810a247",
    "semantic_title": "cheater's bowl: human vs. computer search strategies for open-domain qa",
    "citation_count": 2,
    "authors": [
      "Wanrong He",
      "Andrew Mao",
      "Jordan Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.267": {
    "title": "FRSUM: Towards Faithful Abstractive Summarization via Enhancing Factual Robustness",
    "volume": "findings",
    "abstract": "Despite being able to generate fluent and grammatical text, current Seq2Seq summarization models still suffering from the unfaithful generation problem. In this paper, we study the faithfulness of existing systems from a new perspective of factual robustness which is the ability to correctly generate factual information over adversarial unfaithful information. We first measure a model'sfactual robustness by its success rate to defend against adversarial attacks when generating factual information. The factual robustness analysis on a wide range of current systems shows its good consistency with human judgments on faithfulness. Inspired by these findings, we propose to improve the faithfulness of a model by enhancing its factual robustness. Specifically, we propose a novel training strategy, namely FRSUM, which teaches the model to defend against both explicit adversarial samples and implicit factual adversarial perturbations. Extensive automatic and human evaluation results show that FRSUM consistently improves the faithfulness of various Seq2Seq models, such as T5, BART",
    "checked": true,
    "id": "3e9cdebeba86a290d815d57d8af04a48f4e30df6",
    "semantic_title": "frsum: towards faithful abstractive summarization via enhancing factual robustness",
    "citation_count": 4,
    "authors": [
      "Wenhao Wu",
      "Wei Li",
      "Jiachen Liu",
      "Xinyan Xiao",
      "Ziqiang Cao",
      "Sujian Li",
      "Hua Wu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.268": {
    "title": "PoeLM: A Meter- and Rhyme-Controllable Language Model for Unsupervised Poetry Generation",
    "volume": "findings",
    "abstract": "Formal verse poetry imposes strict constraints on the meter and rhyme scheme of poems. Most prior work on generating this type of poetry uses existing poems for supervision, which are difficult to obtain for most languages and poetic forms. In this work, we propose an unsupervised approach to generate poems that follow any given meter and rhyme scheme, without requiring any poetic text for training. Our method works by splitting a regular, non-poetic corpus into phrases, prepending control codes that describe the length and end rhyme of each phrase, and training a transformer language model in the augmented corpus. The transformer learns to link the structure descriptor with the control codes to the number of lines, their length and their end rhyme. During inference, we build control codes for the desired meter and rhyme scheme, and condition our language model on them to generate formal verse poetry. Experiments in Spanish and Basque show that our approach is able to generate valid poems, which are often comparable in quality to those written by humans",
    "checked": true,
    "id": "8cc1d839276a8d97d922f57e36f44ecf3f31cbf2",
    "semantic_title": "poelm: a meter- and rhyme-controllable language model for unsupervised poetry generation",
    "citation_count": 9,
    "authors": [
      "Aitor Ormazabal",
      "Mikel Artetxe",
      "Manex Agirrezabal",
      "Aitor Soroa",
      "Eneko Agirre"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.269": {
    "title": "ProGen: Progressive Zero-shot Dataset Generation via In-context Feedback",
    "volume": "findings",
    "abstract": "Recently, dataset-generation-based zero-shot learning has shown promising results by training a task-specific model with a dataset synthesized from large pre-trained language models (PLMs). The final task-specific model often achieves compatible or even better performance than PLMs under the zero-shot setting, with orders of magnitude fewer parameters. However, synthetic datasets have their drawbacks. They have long being suffering from the low-quality issue (e.g., low informativeness, redundancy). This explains why the massive synthetic data does not lead to better performance – a scenario we would expect in the human-labeled data. To improve the quality in dataset synthesis, we propose a progressive zero-shot dataset generation framework, ProGen, which leverages the feedback from the task-specific model to guide the generation of new training data via in-context examples. Extensive experiments on five text classification datasets demonstrate the effectiveness of the proposed approach. We also show ProGen achieves on-par or superior performance with only 1% synthetic dataset size, when comparing to baseline methods without in-context feedback",
    "checked": true,
    "id": "95d54e3ce577f7d91ab4b2c52c73b501245e484d",
    "semantic_title": "progen: progressive zero-shot dataset generation via in-context feedback",
    "citation_count": 24,
    "authors": [
      "Jiacheng Ye",
      "Jiahui Gao",
      "Zhiyong Wu",
      "Jiangtao Feng",
      "Tao Yu",
      "Lingpeng Kong"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.270": {
    "title": "Constructing Highly Inductive Contexts for Dialogue Safety through Controllable Reverse Generation",
    "volume": "findings",
    "abstract": "Large pretrained language models can easily produce toxic or biased content, which is prohibitive for practical use. In order to detect such toxic generations, existing methods rely on templates, real-world data extraction, crowdsourcing workers or automatic generation to construct adversarial contexts that are likely to induce toxic generations. However, what type of context is more likely to induce unsafe responses is still under-explored. In this paper, we identify that context toxicity and context category (e.g., profanity, insult, drugs, etc.) are two important factors to cause safety issues in response generation. Hence, we propose a method called reverse generation to construct adversarial contexts conditioned on a given response, with the flexibility to control category, toxicity level and inductivity of the generated contexts. Via reverse generation, we augment the existing BAD dataset and construct a new dataset BAD+ which contains more than 120K diverse and highly inductive contexts in 12 categories. We test three popular pretrained dialogue models (Blender, DialoGPT and Plato2) and find that BAD+ can largely expose their safety problems. Furthermore, we show that BAD+ can greatly enhance the safety of generation, and we reveal the key factors of safety improvement. Our code and dataset is available at https://github.com/thu-coai/Reverse_Generation",
    "checked": true,
    "id": "ef3b5106b0af18ebb9e7a4ed8901351061315227",
    "semantic_title": "constructing highly inductive contexts for dialogue safety through controllable reverse generation",
    "citation_count": 4,
    "authors": [
      "Zhexin Zhang",
      "Jiale Cheng",
      "Hao Sun",
      "Jiawen Deng",
      "Fei Mi",
      "Yasheng Wang",
      "Lifeng Shang",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.271": {
    "title": "Language Prior Is Not the Only Shortcut: A Benchmark for Shortcut Learning in VQA",
    "volume": "findings",
    "abstract": "Visual Question Answering (VQA) models are prone to learn the shortcut solution formed by dataset biases rather than the intended solution. To evaluate the VQA models' reasoning ability beyond shortcut learning, the VQA-CP v2 dataset introduces a distribution shift between the training and test set given a question type. In this way, the model cannot use the training set shortcut (from question type to answer) to perform well on the test set. However, VQA-CP v2 only considers one type of shortcut and thus still cannot guarantee that the model relies on the intended solution rather than a solution specific to this shortcut. To overcome this limitation, we propose a new dataset that considers varying types of shortcuts by constructing different distribution shifts in multiple OOD test sets. In addition, we overcome the three troubling practices in the use of VQA-CP v2, e.g., selecting models using OOD test sets, and further standardize OOD evaluation procedure. Our benchmark provides a more rigorous and comprehensive testbed for shortcut learning in VQA. We benchmark recent methods and find that methods specifically designed for particular shortcuts fail to simultaneously generalize to our varying OOD test sets. We also systematically study the varying shortcuts and provide several valuable findings, which may promote the exploration of shortcut learning in VQA",
    "checked": true,
    "id": "6a38a5a85d8405a11171876126eb9c7633005b03",
    "semantic_title": "language prior is not the only shortcut: a benchmark for shortcut learning in vqa",
    "citation_count": 8,
    "authors": [
      "Qingyi Si",
      "Fandong Meng",
      "Mingyu Zheng",
      "Zheng Lin",
      "Yuanxin Liu",
      "Peng Fu",
      "Yanan Cao",
      "Weiping Wang",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.272": {
    "title": "Bridging the Training-Inference Gap for Dense Phrase Retrieval",
    "volume": "findings",
    "abstract": "Building dense retrievers requires a series of standard procedures, including training and validating neural models and creating indexes for efficient search. However, these procedures are often misaligned in that training objectives do not exactly reflect the retrieval scenario at inference time. In this paper, we explore how the gap between training and inference in dense retrieval can be reduced, focusing on dense phrase retrieval (Lee et al., 2021) where billions of representations are indexed at inference. Since validating every dense retriever with a large-scale index is practically infeasible, we propose an efficient way of validating dense retrievers using a small subset of the entire corpus. This allows us to validate various training strategies including unifying contrastive loss terms and using hard negatives for phrase retrieval, which largely reduces the training-inference discrepancy. As a result, we improve top-1 phrase retrieval accuracy by 2 3 points and top-20 passage retrieval accuracy by 2 4 points for open-domain question answering. Our work urges modeling dense retrievers with careful consideration of training and inference via efficient validation while advancing phrase retrieval as a general solution for dense retrieval",
    "checked": true,
    "id": "0c171148052476b059611dd70eca29c72c121f6a",
    "semantic_title": "bridging the training-inference gap for dense phrase retrieval",
    "citation_count": 1,
    "authors": [
      "Gyuwan Kim",
      "Jinhyuk Lee",
      "Barlas Oguz",
      "Wenhan Xiong",
      "Yizhe Zhang",
      "Yashar Mehdad",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.273": {
    "title": "Beyond Counting Datasets: A Survey of Multilingual Dataset Construction and Necessary Resources",
    "volume": "findings",
    "abstract": "While the NLP community is generally aware of resource disparities among languages, we lack research that quantifies the extent and types of such disparity. Prior surveys estimating the availability of resources based on the number of datasets can be misleading as dataset quality varies: many datasets are automatically induced or translated from English data. To provide a more comprehensive picture of language resources, we examine the characteristics of 156 publicly available NLP datasets. We manually annotate how they are created, including input text and label sources and tools used to build them, and what they study, tasks they address and motivations for their creation. After quantifying the qualitative NLP resource gap across languages, we discuss how to improve data collection in low-resource languages. We survey language-proficient NLP researchers and crowd workers per language, finding that their estimated availability correlates with dataset availability. Through crowdsourcing experiments, we identify strategies for collecting high-quality multilingual data on the Mechanical Turk platform. We conclude by making macro and micro-level suggestions to the NLP community and individual researchers for future multilingual data development",
    "checked": true,
    "id": "32cdcf593fef78dcf9e1b6aba7f2345310d7cc60",
    "semantic_title": "beyond counting datasets: a survey of multilingual dataset construction and necessary resources",
    "citation_count": 10,
    "authors": [
      "Xinyan Yu",
      "Trina Chatterjee",
      "Akari Asai",
      "Junjie Hu",
      "Eunsol Choi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.274": {
    "title": "ERNIE-Layout: Layout Knowledge Enhanced Pre-training for Visually-rich Document Understanding",
    "volume": "findings",
    "abstract": "Recent years have witnessed the rise and success of pre-training techniques in visually-rich document understanding. However, most existing methods lack the systematic mining and utilization of layout-centered knowledge, leading to sub-optimal performances. In this paper, we propose ERNIE-Layout, a novel document pre-training solution with layout knowledge enhancement in the whole workflow, to learn better representations that combine the features from text, layout, and image. Specifically, we first rearrange input sequences in the serialization stage, and then present a correlative pre-training task, reading order prediction, to learn the proper reading order of documents. To improve the layout awareness of the model, we integrate a spatial-aware disentangled attention into the multi-modal transformer and a replaced regions prediction task into the pre-training phase. Experimental results show that ERNIE-Layout achieves superior performance on various downstream tasks, setting new state-of-the-art on key information extraction, document image classification, and document question answering datasets. The code and models are publicly available at PaddleNLP",
    "checked": true,
    "id": "334116d685096d8fd2aedd66fc17e2a90d1f9a9d",
    "semantic_title": "ernie-layout: layout knowledge enhanced pre-training for visually-rich document understanding",
    "citation_count": 45,
    "authors": [
      "Qiming Peng",
      "Yinxu Pan",
      "Wenjin Wang",
      "Bin Luo",
      "Zhenyu Zhang",
      "Zhengjie Huang",
      "Yuhui Cao",
      "Weichong Yin",
      "Yongfeng Chen",
      "Yin Zhang",
      "Shikun Feng",
      "Yu Sun",
      "Hao Tian",
      "Hua Wu",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.275": {
    "title": "Do Charge Prediction Models Learn Legal Theory?",
    "volume": "findings",
    "abstract": "The charge prediction task aims to predict the charge for a case given its fact description. Recent models have already achieved impressive accuracy in this task, however, little is understood about the mechanisms they use to perform the judgment. For practical applications, a charge prediction model should conform to the certain legal theory in civil law countries, as under the framework of civil law, all cases are judged according to certain local legal theories. In China, for example, nearly all criminal judges make decisions based on the Four Elements Theory (FET).In this paper, we argue that trustworthy charge prediction models should take legal theories into consideration, and standing on prior studies in model interpretation, we propose three principles for trustworthy models should follow in this task, which are sensitive, selective, and presumption of innocence. We further design a new framework to evaluate whether existing charge prediction models learn legal theories. Our findings indicate that, while existing charge prediction models meet the selective principle on a benchmark dataset, most of them are still not sensitive enough and do not satisfy the presumption of innocence. Our code and dataset are released at https://github.com/ZhenweiAn/EXP_LJP",
    "checked": true,
    "id": "43dd7b85caf3c832c741b99d4b71e71a9c32d84c",
    "semantic_title": "do charge prediction models learn legal theory?",
    "citation_count": 3,
    "authors": [
      "Zhenwei An",
      "Quzhe Huang",
      "Cong Jiang",
      "Yansong Feng",
      "Dongyan Zhao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.276": {
    "title": "Keep Me Updated! Memory Management in Long-term Conversations",
    "volume": "findings",
    "abstract": "Remembering important information from the past and continuing to talk about it in the present are crucial in long-term conversations. However, previous literature does not deal with cases where the memorized information is outdated, which may cause confusion in later conversations. To address this issue, we present a novel task and a corresponding dataset of memory management in long-term conversations, in which bots keep track of and bring up the latest information about users while conversing through multiple sessions. In order to support more precise and interpretable memory, we represent memory as unstructured text descriptions of key information and propose a new mechanism of memory management that selectively eliminates invalidated or redundant information. Experimental results show that our approach outperforms the baselines that leave the stored memory unchanged in terms of engagingness and humanness, with larger performance gap especially in the later sessions",
    "checked": true,
    "id": "1d8f36b95f51af99fd5c7c4527b9b7ad598b15f4",
    "semantic_title": "keep me updated! memory management in long-term conversations",
    "citation_count": 19,
    "authors": [
      "Sanghwan Bae",
      "Donghyun Kwak",
      "Soyoung Kang",
      "Min Young Lee",
      "Sungdong Kim",
      "Yuin Jeong",
      "Hyeri Kim",
      "Sang-Woo Lee",
      "Woomyoung Park",
      "Nako Sung"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.277": {
    "title": "A Unified Dialogue User Simulator for Few-shot Data Augmentation",
    "volume": "findings",
    "abstract": "Pre-trained language models have shown superior performance in task-oriented dialogues. However, existing datasets are on limited scales, which cannot support large-scale pre-training. Fortunately, various data augmentation methods have been developed to augment large-scale task-oriented dialogue corpora. However, they heavily rely on annotated data in the target domain, which require a tremendous amount of data collection and human labeling work. In this paper, we build a unified dialogue user simulation model by pre-training on several publicly available datasets. The model can then be tuned on a target domain with few-shot data. The experiments on a target dataset across multiple domains show that our proposed model brings remarkable performance increases through data augmentation",
    "checked": true,
    "id": "cb3a9f7004ac261dd60b1c2f6d63173dd3064c0e",
    "semantic_title": "a unified dialogue user simulator for few-shot data augmentation",
    "citation_count": 9,
    "authors": [
      "Dazhen Wan",
      "Zheng Zhang",
      "Qi Zhu",
      "Lizi Liao",
      "Minlie Huang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.278": {
    "title": "An Error-Guided Correction Model for Chinese Spelling Error Correction",
    "volume": "findings",
    "abstract": "Although existing neural network approaches have achieved great progress on Chinese spelling correction, there is still room to improve. The model is required to avoid over-correction and to distinguish a correct token from its phonological and visual similar ones. In this paper, we propose an error-guided correction model to address these issues. By borrowing the powerful ability of the pre-trained BERT model, we propose a novel zero-shot error detection method to do a preliminary detection, which guides our model to attend more on the probably wrong tokens in encoding and to avoid modifying the correct tokens in generating. Furthermore, we introduce a new loss function to integrate the error confusion set, which enables our model to distinguish similar tokens. Moreover, our model supports highly parallel decoding to meet real applications. Experiments are conducted on widely used benchmarks. Our model achieves superior performance against state-of-the-art approaches by a remarkable margin, on both the quality and computation speed",
    "checked": true,
    "id": "55bb3b68aafa120d88c354817a62c1461d998a90",
    "semantic_title": "an error-guided correction model for chinese spelling error correction",
    "citation_count": 3,
    "authors": [
      "Rui Sun",
      "Xiuyu Wu",
      "Yunfang Wu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.279": {
    "title": "Describing Sets of Images with Textual-PCA",
    "volume": "findings",
    "abstract": "We seek to semantically describe a set of images, capturing both the attributes of single images and the variations within the set. Our procedure is analogous to Principle Component Analysis, in which the role of projection vectors is replaced with generated phrases. First, a centroid phrase that has the largest average semantic similarity to the images in the set is generated, where both the computation of the similarity and the generation are based on pretrained vision-language models. Then, the phrase that generates the highest variation among the similarity scores is generated, using the same models. The next phrase maximizes the variance subject to being orthogonal, in the latent space, to the highest-variance phrase, and the process continues. Our experiments show that our method is able to convincingly capture the essence of image sets and describe the individual elements in a semantically meaningful way within the context of the entire set. Our code is available at: https://github.com/OdedH/textual-pca",
    "checked": true,
    "id": "5808bda70e06a414e9970dff6946f007e942ac8e",
    "semantic_title": "describing sets of images with textual-pca",
    "citation_count": 1,
    "authors": [
      "Oded Hupert",
      "Idan Schwartz",
      "Lior Wolf"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.280": {
    "title": "Learning to Model Editing Processes",
    "volume": "findings",
    "abstract": "Most existing sequence generation models produce outputs in one pass, usually left-to-right. However, this is in contrast with a more natural approach that humans use in generating content; iterative refinement and editing. Recent work has introduced edit-based models for various tasks (such as neural machine translation and text style transfer), but these generally model a single edit step. In this work, we propose modeling editing processes, modeling the whole process of iteratively generating sequences. We form a conceptual framework to describe the likelihood of multi-step edits, and describe neural models that can learn a generative model of sequences based on these multistep edits. We introduce baseline results and metrics on this task, finding that modeling editing processes improves performance on a variety of axes on both our proposed task and related downstream tasks compared to previous single-step models of edits",
    "checked": true,
    "id": "60bff5a4527141599d8e05904baf96410541f8a9",
    "semantic_title": "learning to model editing processes",
    "citation_count": 29,
    "authors": [
      "Machel Reid",
      "Graham Neubig"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.281": {
    "title": "PALT: Parameter-Lite Transfer of Language Models for Knowledge Graph Completion",
    "volume": "findings",
    "abstract": "This paper presents a parameter-lite transfer learning approach of pretrained language models (LM) for knowledge graph (KG) completion. Instead of finetuning, which modifies all LM parameters, we only tune a few new parameters while keeping the original LM parameters fixed. We establish this via reformulating KG completion as a \"fill-in-the-blank\" task, and introducing a parameter-lite encoder on top of the original LMs. We show that, by tuning far fewer parameters than finetuning, LMs transfer non-trivially to most tasks and reach competitiveness with prior state-of-the-art approaches. For instance, we outperform the fully finetuning approaches on a KG completion benchmark by tuning only 1% of the parameters",
    "checked": true,
    "id": "b32f967c0a5777a5045d4fd59f2cda9be68dc3bb",
    "semantic_title": "palt: parameter-lite transfer of language models for knowledge graph completion",
    "citation_count": 5,
    "authors": [
      "Jianhao Shen",
      "Chenguang Wang",
      "Ye Yuan",
      "Jiawei Han",
      "Heng Ji",
      "Koushik Sen",
      "Ming Zhang",
      "Dawn Song"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.282": {
    "title": "Prompt-based Connective Prediction Method for Fine-grained Implicit Discourse Relation Recognition",
    "volume": "findings",
    "abstract": "Due to the absence of connectives, implicit discourse relation recognition (IDRR) is still a challenging and crucial task in discourse analysis. Most of the current work adopted multitask learning to aid IDRR through explicit discourse relation recognition (EDRR) or utilized dependencies between discourse relation labels to constrain model predictions. But these methods still performed poorly on fine-grained IDRR and even utterly misidentified on most of the few-shot discourse relation classes. To address these problems, we propose a novel Prompt-based Connective Prediction (PCP) method for IDRR. Our method instructs large-scale pre-trained models to use knowledge relevant to discourse relation and utilizes the strong correlation between connectives and discourse relation to help the model recognize implicit discourse relations. Experimental results show that our method surpasses the current state-of-the-art model and achieves significant improvements on those fine-grained few-shot discourse relation. Moreover, our approach is able to be transferred to EDRR and obtain acceptable results. Our code is released in https://github.com/zh-i9/PCP-for-IDRR",
    "checked": true,
    "id": "f1946808a9eaddf7bdfe9821be31285342b6be54",
    "semantic_title": "prompt-based connective prediction method for fine-grained implicit discourse relation recognition",
    "citation_count": 13,
    "authors": [
      "Hao Zhou",
      "Man Lan",
      "Yuanbin Wu",
      "Yuefeng Chen",
      "Meirong Ma"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.283": {
    "title": "On Utilizing Constituent Language Resources to Improve Downstream Tasks in Hinglish",
    "volume": "findings",
    "abstract": "Performance of downstream NLP tasks on code-switched Hindi-English (aka ) continues to remain a significant challenge. Intuitively, Hindi and English corpora should aid improve task performance on Hinglish. We show that meta-learning framework can effectively utilize the the labelled resources of the downstream tasks in the constituent languages. The proposed approach improves the performance on downstream tasks on code-switched language. We experiment with code-switching benchmark GLUECoS and report significant improvements",
    "checked": true,
    "id": "015f29a14518b42e10d5589a39d08dfac79efa4e",
    "semantic_title": "on utilizing constituent language resources to improve downstream tasks in hinglish",
    "citation_count": 0,
    "authors": [
      "Vishwajeet Kumar",
      "Rudra Murthy",
      "Tejas Dhamecha"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.284": {
    "title": "SYGMA: A System for Generalizable and Modular Question Answering Over Knowledge Bases",
    "volume": "findings",
    "abstract": "Knowledge Base Question Answering (KBQA) involving complex reasoning is emerging as an important research direction. However, most KBQA systems struggle with generalizability, particularly on two dimensions: (a) across multiple knowledge bases, where existing KBQA approaches are typically tuned to a single knowledge base, and (b) across multiple reasoning types, where majority of datasets and systems have primarily focused on multi-hop reasoning. In this paper, we present SYGMA, a modular KBQA approach developed with goal of generalization across multiple knowledge bases and multiple reasoning types. To facilitate this, SYGMA is designed as two high level modules: 1) KB-agnostic question understanding module that remain common across KBs, and generates logic representation of the question with high level reasoning constructs that are extensible, and 2) KB-specific question mapping and answering module to address the KB-specific aspects of the answer extraction. We evaluated SYGMA on multiple datasets belonging to distinct knowledge bases (DBpedia and Wikidata) and distinct reasoning types (multi-hop and temporal). State-of-the-art or competitive performances achieved on those datasets demonstrate its generalization capability",
    "checked": true,
    "id": "618a87d0d43474b7f0a44b91b0023cc3ada59158",
    "semantic_title": "sygma: a system for generalizable and modular question answering over knowledge bases",
    "citation_count": 4,
    "authors": [
      "Sumit Neelam",
      "Udit Sharma",
      "Hima Karanam",
      "Shajith Ikbal",
      "Pavan Kapanipathi",
      "Ibrahim Abdelaziz",
      "Nandana Mihindukulasooriya",
      "Young-Suk Lee",
      "Santosh Srivastava",
      "Cezar Pendus",
      "Saswati Dana",
      "Dinesh Garg",
      "Achille Fokoue",
      "G P Shrivatsa Bhargav",
      "Dinesh Khandelwal",
      "Srinivas Ravishankar",
      "Sairam Gurajada",
      "Maria Chang",
      "Rosario Uceda-Sosa",
      "Salim Roukos",
      "Alexander Gray",
      "Guilherme Lima",
      "Ryan Riegel",
      "Francois Luus",
      "L V Subramaniam"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.285": {
    "title": "Instance-Guided Prompt Learning for Few-Shot Text Matching",
    "volume": "findings",
    "abstract": "Few-shot text matching is a more practical technique in natural language processing (NLP) to determine whether two texts are semantically identical. They primarily design patterns to reformulate text matching into a pre-trained task with uniform prompts across all instances. But they fail to take into account the connection between prompts and instances. This paper argues that dynamically strengthening the correlation between particular instances and the prompts is necessary because fixed prompts cannot adequately fit all diverse instances in inference. We suggest IGATE: Instance-Guided prompt leArning for few-shoT tExt matching, a novel pluggable prompt learning method. The gate mechanism used by IGATE, which is between the embedding and the PLM encoders, makes use of the semantics of instances to regulate the effects of the gate on the prompt tokens. The experimental findings show that IGATE achieves SOTA performance on MRPC and QQP, outperforming strong baselines. GitHub will host the release of codes",
    "checked": true,
    "id": "5e8615534d19dc2c52ac328dd5cc0127948f1ab2",
    "semantic_title": "instance-guided prompt learning for few-shot text matching",
    "citation_count": 1,
    "authors": [
      "Jia Du",
      "Xuanyu Zhang",
      "Siyi Wang",
      "Kai Wang",
      "Yanquan Zhou",
      "Lei Li",
      "Qing Yang",
      "Dongliang Xu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.286": {
    "title": "M3: Multi-level dataset for Multi-document summarisation of Medical studies",
    "volume": "findings",
    "abstract": "We present M3 (Multi-level dataset for Multi-document summarisation of Medical studies), a benchmark dataset for evaluating the quality of summarisation systems in the biomedical domain. The dataset contains sets of multiple input documents and target summaries of three levels of complexity: documents, sentences, and propositions. The dataset also includes several levels of annotation, including biomedical entities, direction, and strength of relations between them, and the discourse relationships between the input documents (\"contradiction\" or \"agreement\"). We showcase usage scenarios of the dataset by testing 10 generic and domain-specific summarisation models in a zero-shot setting, and introduce a probing task based on counterfactuals to test if models are aware of the direction and strength of the conclusions generated from input studies",
    "checked": true,
    "id": "7553569ce4469346557673d5778a5862bc5d54f0",
    "semantic_title": "m3: multi-level dataset for multi-document summarisation of medical studies",
    "citation_count": 3,
    "authors": [
      "Yulia Otmakhova",
      "Karin Verspoor",
      "Timothy Baldwin",
      "Antonio Jimeno Yepes",
      "Jey Han Lau"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.287": {
    "title": "Adapters for Enhanced Modeling of Multilingual Knowledge and Text",
    "volume": "findings",
    "abstract": "Large language models appear to learn facts from the large text corpora they are trained on. Such facts are encoded implicitly within their many parameters, making it difficult to verify or manipulate what knowledge has been learned. Language models have recently been extended to multilingual language models (MLLMs), enabling knowledge to be learned across hundreds of languages. Meanwhile, knowledge graphs contain facts in an explicit triple format, which require careful and costly curation and are only available in a few high-resource languages, restricting their research and application. To address these issues, we propose to enhance MLLMs with knowledge from multilingual knowledge graphs (MLKGs) so as to tackle language and knowledge graph tasks across many languages, including low-resource ones. Specifically, we introducea lightweight adapter set to enhance MLLMs with cross-lingual entity alignment and facts from MLKGs for many languages. Experiments on common benchmarks show that such enhancement benefits both MLLMs and MLKGs, achieving: (1) comparable or improved performance for knowledge graph completion and entity alignment relative to baselines, especially for low-resource languages (for which knowledge graphs are unavailable); and (2) improved MLLM performance on language understanding tasks that require multilingual factual knowledge; all while maintaining performance on other general language tasks",
    "checked": true,
    "id": "9519b1cdad21528632819e9ecece00f987e3fd8c",
    "semantic_title": "adapters for enhanced modeling of multilingual knowledge and text",
    "citation_count": 5,
    "authors": [
      "Yifan Hou",
      "Wenxiang Jiao",
      "Meizhen Liu",
      "Carl Allen",
      "Zhaopeng Tu",
      "Mrinmaya Sachan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.288": {
    "title": "SepLL: Separating Latent Class Labels from Weak Supervision Noise",
    "volume": "findings",
    "abstract": "In the weakly supervised learning paradigm, labeling functions automatically assign heuristic, often noisy, labels to data samples. In this work, we provide a method for learning from weak labels by separating two types of complementary information associated with the labeling functions: information related to the target label and information specific to one labeling function only. Both types of information are reflected to different degrees by all labeled instances. In contrast to previous works that aimed at correcting or removing wrongly labeled instances, we learn a branched deep model that uses all data as-is, but splits the labeling function information in the latent space. Specifically, we propose the end-to-end model SepLL which extends a transformer classifier by introducing a latent space for labeling function specific and task-specific information. The learning signal is only given by the labeling functions matches, no pre-processing or label model is required for our method. Notably, the task prediction is made from the latent layer without any direct task signal. Experiments on Wrench text classification tasks show that our model is competitive with the state-of-the-art, and yields a new best average performance",
    "checked": true,
    "id": "51b795ae752dbd185281aae29671492b29b6ba83",
    "semantic_title": "sepll: separating latent class labels from weak supervision noise",
    "citation_count": 4,
    "authors": [
      "Andreas Stephan",
      "Vasiliki Kougia",
      "Benjamin Roth"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.289": {
    "title": "Probing Relational Knowledge in Language Models via Word Analogies",
    "volume": "findings",
    "abstract": "Understanding relational knowledge plays an integral part in natural language comprehension. When it comes to pre-trained language models (PLM), prior work has been focusing on probing relational knowledge this by filling the blanks in pre-defined prompts such as \"The capital of France is —\". However, these probes may be affected by the co-occurrence of target relation words and entities (e.g. \"capital\", \"France\" and \"Paris\") in the pre-training corpus. In this work, we extend these probing methodologies leveraging analogical proportions as a proxy to probe relational knowledge in transformer-based PLMs without directly presenting the desired relation. In particular, we analysed the ability of PLMs to understand (1) the directionality of a given relation (e.g. Paris-France is not the same as France-Paris); (2) the ability to distinguish types on a given relation (both France and Japan are countries); and (3) the relation itself (Paris is the capital of France, but not Rome). Our results show how PLMs are extremely accurate at (1) and (2), but have clear room for improvement for (3). To better understand the reasons behind this behaviour and mistakes made by PLMs, we provide an extended quantitative analysis based on relevant factors such as frequency",
    "checked": true,
    "id": "88303a4171c68f678c5d7ec5a4b51865d8bb1dad",
    "semantic_title": "probing relational knowledge in language models via word analogies",
    "citation_count": 4,
    "authors": [
      "Kiamehr Rezaee",
      "Jose Camacho-Collados"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.290": {
    "title": "Semi-Supervised Lifelong Language Learning",
    "volume": "findings",
    "abstract": "Lifelong learning aims to accumulate knowledge and alleviate catastrophic forgetting when learning tasks sequentially. However, existing lifelong language learning methods only focus on the supervised learning setting. Unlabeled data, which can be easily accessed in real-world scenarios, are underexplored. In this paper, we explore a novel setting, semi-supervised lifelong language learning (SSLL), where a model learns sequentially arriving language tasks with both labeled and unlabeled data. We propose an unlabeled data enhanced lifelong learner to explore SSLL. Specially, we dedicate task-specific modules to alleviate catastrophic forgetting and design two modules to exploit unlabeled data: (1) a virtual supervision enhanced task solver is constructed on a teacher-student framework to mine the underlying knowledge from unlabeled data; and (2) a backward augmented learner is built to encourage knowledge transfer from newly arrived unlabeled data to previous tasks. Experimental results on various language tasks demonstrate our model's effectiveness and superiority over competitive baselines under the new setting SSLL",
    "checked": true,
    "id": "992a366671b6dc591e9254690c22332fe1a76497",
    "semantic_title": "semi-supervised lifelong language learning",
    "citation_count": 2,
    "authors": [
      "Yingxiu Zhao",
      "Yinhe Zheng",
      "Bowen Yu",
      "Zhiliang Tian",
      "Dongkyu Lee",
      "Jian Sun",
      "Yongbin Li",
      "Nevin L. Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.291": {
    "title": "Parameter-free Automatically Prompting: A Latent Pseudo Label Mapping Model for Prompt-based Learning",
    "volume": "findings",
    "abstract": "Prompt-based learning has achieved excellent performance in few-shot learning by mapping the outputs of the pre-trained language model to the labels with the help of a label mapping component. Existing manual label mapping (MLM) methods achieve good results but heavily rely on expensive human knowledge. Automatic label mapping (ALM) methods that learn the mapping functions with extra parameters have shown their potentiality. However, no effective ALM model comparable to MLM methods is developed yet due to the limited data. In this paper, we propose a Latent Pseudo Label Mapping (LPLM) method that optimizes the label mapping without human knowledge and extra parameters. LPLM is built upon a probabilistic latent model and is iteratively self-improved with the EM-style algorithm. The empirical results demonstrate that our LPLM method is superior to the mainstream ALM methods and significantly outperforms the SOTA method in few-shot classification tasks. Moreover, LPLM also shows impressively better performance than the vanilla MLM method which requires extra task-specific prior knowledge",
    "checked": true,
    "id": "21666ebc63260d4dd46623431facf38cefaf2f27",
    "semantic_title": "parameter-free automatically prompting: a latent pseudo label mapping model for prompt-based learning",
    "citation_count": 0,
    "authors": [
      "Jirui Qi",
      "Richong Zhang",
      "Junfan Chen",
      "Jaein Kim",
      "Yongyi Mao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.292": {
    "title": "Exploring Logographic Image for Chinese Aspect-based Sentiment Classification",
    "volume": "findings",
    "abstract": "In logographic languages like Chinese, word meanings are constructed using specific character formations, which can help to disambiguate word senses and are beneficial for sentiment classification. However, such knowledge is rarely explored in previous sentiment analysis methods. In this paper, we focus on exploring the logographic information for aspect-based sentiment classification in Chinese text. Specifically, we employ a logographic image to capture an internal morphological structure from the character sequence. The logographic image is also used to learn the external relations among context and aspect words. Furthermore, we propose a multimodal language model to explicitly incorporate a logographic image with review text for aspect-based sentiment classification in Chinese. Experimental results show that our method brings substantial performance improvement over strong baselines. The results also indicate that the logographic image is very important for exploring the internal structure and external relations from the character sequence",
    "checked": true,
    "id": "42d819ee6a762a1eb90844a004b5b8e63a889b39",
    "semantic_title": "exploring logographic image for chinese aspect-based sentiment classification",
    "citation_count": 0,
    "authors": [
      "Xiabing Zhou",
      "Renjie Feng",
      "Xiaotong Jiang",
      "Zhongqing Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.293": {
    "title": "On the Role of Bidirectionality in Language Model Pre-Training",
    "volume": "findings",
    "abstract": "Prior work on language model pre-training has explored different architectures and learning objectives, but differences in data, hyperparameters and evaluation make a principled comparison difficult. In this work, we focus on bidirectionality as a key factor that differentiates existing approaches, and present a comprehensive study of its role in next token prediction, text infilling, zero-shot priming and fine-tuning. We propose a new framework that generalizes prior approaches, including fully unidirectional models like GPT, fully bidirectional models like BERT, and hybrid models like CM3 and prefix LM. Our framework distinguishes between two notions of bidirectionality (bidirectional context and bidirectional attention) and allows us to control each of them separately. We find that the optimal configuration is largely application-dependent (e.g., bidirectional attention is beneficial for fine-tuning and infilling, but harmful for next token prediction and zero-shot priming). We train models with up to 6.7B parameters, and find differences to remain consistent at scale. While prior work on scaling has focused on left-to-right autoregressive models, our results suggest that this approach comes with some trade-offs, and it might be worthwhile to develop very large bidirectional models",
    "checked": true,
    "id": "8ce9b1e527c4d9d15239621ec4e3ef3fbbe32202",
    "semantic_title": "on the role of bidirectionality in language model pre-training",
    "citation_count": 15,
    "authors": [
      "Mikel Artetxe",
      "Jingfei Du",
      "Naman Goyal",
      "Luke Zettlemoyer",
      "Veselin Stoyanov"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.294": {
    "title": "You Are What You Talk About: Inducing Evaluative Topics for Personality Analysis",
    "volume": "findings",
    "abstract": "Expressing attitude or stance toward entities and concepts is an integral part of human behavior and personality. Recently, evaluative language data has become more accessible with social media's rapid growth, enabling large-scale opinion analysis. However, surprisingly little research examines the relationship between personality and evaluative language. To bridge this gap, we introduce the notion of evaluative topics, obtained by applying topic models to pre-filtered evaluative text from social media. We then link evaluative topics to individual text authors to build their evaluative profiles. We apply evaluative profiling to Reddit comments labeled with personality scores and conduct an exploratory study on the relationship between evaluative topics and Big Five personality facets, aiming for a more interpretable, facet-level analysis. Finally, we validate our approach by observing correlations consistent with prior research in personality psychology",
    "checked": true,
    "id": "d098e69ad92d5f1ce2e4b81913d4403285f53713",
    "semantic_title": "you are what you talk about: inducing evaluative topics for personality analysis",
    "citation_count": 1,
    "authors": [
      "Josip Jukić",
      "Iva Vukojević",
      "Jan Snajder"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.295": {
    "title": "CAT-probing: A Metric-based Approach to Interpret How Pre-trained Models for Programming Language Attend Code Structure",
    "volume": "findings",
    "abstract": "Code pre-trained models (CodePTMs) have recently demonstrated significant success in code intelligence. To interpret these models, some probing methods have been applied. However, these methods fail to consider the inherent characteristics of codes. In this paper, to address the problem, we propose a novel probing method CAT-probing to quantitatively interpret how CodePTMs attend code structure. We first denoise the input code sequences based on the token types pre-defined by the compilers to filter those tokens whose attention scores are too small. After that, we define a new metric CAT-score to measure the commonality between the token-level attention scores generated in CodePTMs and the pair-wise distances between corresponding AST nodes. The higher the CAT-score, the stronger the ability of CodePTMs to capture code structure. We conduct extensive experiments to integrate CAT-probing with representative CodePTMs for different programming languages. Experimental results show the effectiveness of CAT-probing in CodePTM interpretation. Our codes and data are publicly available at https://github.com/nchen909/CodeAttention",
    "checked": true,
    "id": "9466834caa0c918b262d4e0da2101e09c45930a5",
    "semantic_title": "cat-probing: a metric-based approach to interpret how pre-trained models for programming language attend code structure",
    "citation_count": 3,
    "authors": [
      "Nuo Chen",
      "Qiushi Sun",
      "Renyu Zhu",
      "Xiang Li",
      "Xuesong Lu",
      "Ming Gao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.296": {
    "title": "Learning to Revise References for Faithful Summarization",
    "volume": "findings",
    "abstract": "In real-world scenarios with naturally occurring datasets, reference summaries are noisy and may contain information that cannot be inferred from the source text. On large news corpora, removing low quality samples has been shown to reduce model hallucinations. Yet, for smaller, and/or noisier corpora, filtering is detrimental to performance. To improve reference quality while retaining all data, we propose a new approach: to selectively re-write unsupported reference sentences to better reflect source data. We automatically generate a synthetic dataset of positive and negative revisions by corrupting supported sentences and learn to revise reference sentences with contrastive learning. The intensity of revisions is treated as a controllable attribute so that, at inference, diverse candidates can be over-generated-then-rescored to balance faithfulness and abstraction. To test our methods, we extract noisy references from publicly available MIMIC-III discharge summaries for the task of hospital-course summarization, and vary the data on which models are trained. According to metrics and human evaluation, models trained on revised clinical references are much more faithful, informative, and fluent than models trained on original or filtered data",
    "checked": true,
    "id": "933d1d4f18e721160ddbf8dab25c33f8e3d2cec7",
    "semantic_title": "learning to revise references for faithful summarization",
    "citation_count": 24,
    "authors": [
      "Griffin Adams",
      "Han-Chin Shing",
      "Qing Sun",
      "Christopher Winestock",
      "Kathleen McKeown",
      "Noémie Elhadad"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.297": {
    "title": "Towards Intention Understanding in Suicidal Risk Assessment with Natural Language Processing",
    "volume": "findings",
    "abstract": "Recent applications of natural language processing techniques to suicidal ideation detection and risk assessment frame the detection or assessment task as a text classification problem. Recent advances have developed many models, especially deep learning models, to boost predictive performance. Though the performance (in terms of aggregated evaluation scores) is improving, this position paper urges that better intention understanding is required for reliable suicidal risk assessment with computational methods. This paper reflects the state of natural language processing applied to suicide-associated text classification tasks, differentiates suicidal risk assessment and intention understanding, and points out potential limitations of sentiment features and pretrained language models in suicidal intention understanding. Besides, it urges the necessity for sequential intention understanding and risk assessment, discusses some critical issues in evaluation such as uncertainty, and studies the lack of benchmarks",
    "checked": true,
    "id": "72c8a8ddf7651dbb7c749eb400464e7ed1ef4bb0",
    "semantic_title": "towards intention understanding in suicidal risk assessment with natural language processing",
    "citation_count": 5,
    "authors": [
      "Shaoxiong Ji"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.298": {
    "title": "On the Impact of Temporal Concept Drift on Model Explanations",
    "volume": "findings",
    "abstract": "Explanation faithfulness of model predictions in natural language processing is typically evaluated on held-out data from the same temporal distribution as the training data (i.e. synchronous settings). While model performance often deteriorates due to temporal variation (i.e. temporal concept drift), it is currently unknown how explanation faithfulness is impacted when the time span of the target data is different from the data used to train the model (i.e. asynchronous settings). For this purpose, we examine the impact of temporal variation on model explanations extracted by eight feature attribution methods and three select-then-predict models across six text classification tasks. Our experiments show that (i) faithfulness is not consistent under temporal variations across feature attribution methods (e.g. it decreases or increases depending on the method), with an attention-based method demonstrating the most robust faithfulness scores across datasets; and (ii) select-then-predict models are mostly robust in asynchronous settings with only small degradation in predictive performance. Finally, feature attribution methods show conflicting behavior when used in FRESH (i.e. a select-and-predict model) and for measuring sufficiency/comprehensiveness (i.e. as post-hoc methods), suggesting that we need more robust metrics to evaluate post-hoc explanation faithfulness. Code will be made publicly available",
    "checked": true,
    "id": "eae0fdca3762311b9cbd6a668f1ef632cbe2a1b1",
    "semantic_title": "on the impact of temporal concept drift on model explanations",
    "citation_count": 7,
    "authors": [
      "Zhixue Zhao",
      "George Chrysostomou",
      "Kalina Bontcheva",
      "Nikolaos Aletras"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.299": {
    "title": "Text-Only Training for Image Captioning using Noise-Injected CLIP",
    "volume": "findings",
    "abstract": "We consider the task of image-captioning using only the CLIP model and additional text data at training time and no additional captioned images. Our approach relies on the fact that CLIP is trained to make visual and textual embeddings similar. Therefore, we only need to learn how to translate CLIP textual embeddings back into text, and we can learn how to do this by learning a decoder for the frozen CLIP text encoder using only text. We argue that this intuition is \"almost correct\" because of a gap between the embedding spaces, and propose to rectify this via noise injection during training. We demonstrate the effectiveness of our approach by showing SOTA zero-shot image captioning across four benchmarks, including style transfer. Code, data, and models are available at https://github.com/DavidHuji/CapDec",
    "checked": true,
    "id": "40187d7c30b666e3c45337eb36ff86871d8347a7",
    "semantic_title": "text-only training for image captioning using noise-injected clip",
    "citation_count": 50,
    "authors": [
      "David Nukrai",
      "Ron Mokady",
      "Amir Globerson"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.300": {
    "title": "Improving Sharpness-Aware Minimization with Fisher Mask for Better Generalization on Language Models",
    "volume": "findings",
    "abstract": "Fine-tuning large pretrained language models on a limited training corpus usually suffers from poor generalization. Prior works show that the recently-proposed sharpness-aware minimization (SAM) optimization method can improve the model generalization. However, SAM adds a perturbation to each model parameter equally (but not all parameters contribute equally to the optimization of training), which we argue is sub-optimal and will lead to excessive computation. In this paper, we propose a novel optimization procedure, namely FSAM, which introduces a Fisher mask to improve the efficiency and performance of SAM. In short, instead of adding perturbation to all parameters, FSAM uses the Fisher information to identity the important parameters and formulates a Fisher mask to obtain the sparse perturbation, i.e., making the optimizer focus on these important parameters. Experiments on various tasks in GLUE and SuperGLUE benchmarks show that FSAM consistently outperforms the vanilla SAM by 0.67 1.98 average score among four different pretrained models. We also empirically show that FSAM works well in other complex scenarios, e.g., fine-tuning on generation tasks or limited training data. Encouragingly, when training data is limited, FSAM improves the SAM by a large margin, i.e., up to 15.1",
    "checked": true,
    "id": "15292ec8582514311e4460629361d0ec76882343",
    "semantic_title": "improving sharpness-aware minimization with fisher mask for better generalization on language models",
    "citation_count": 36,
    "authors": [
      "Qihuang Zhong",
      "Liang Ding",
      "Li Shen",
      "Peng Mi",
      "Juhua Liu",
      "Bo Du",
      "Dacheng Tao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.301": {
    "title": "TINA: Textual Inference with Negation Augmentation",
    "volume": "findings",
    "abstract": "Transformer-based language models achieve state-of-the-art results on several natural language processing tasks. One of these is textual entailment, i.e., the task of determining whether a premise logically entails a hypothesis. However, the models perform poorly on this task when the examples contain negations. In this paper, we propose a new definition of textual entailment that captures also negation. This allows us to develop TINA (Textual Inference with Negation Augmentation), a principled technique for negated data augmentation that can be combined with the unlikelihood loss function. Our experiments with different transformer-based models show that our method can significantly improve the performance of the models on textual entailment datasets with negation – without sacrificing performance on datasets without negation",
    "checked": true,
    "id": "21ba26e871560d7101613125628af98cf32a78c8",
    "semantic_title": "tina: textual inference with negation augmentation",
    "citation_count": 3,
    "authors": [
      "Chadi Helwe",
      "Simon Coumes",
      "Chloé Clavel",
      "Fabian Suchanek"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.302": {
    "title": "Improving Bilingual Lexicon Induction with Cross-Encoder Reranking",
    "volume": "findings",
    "abstract": "Bilingual lexicon induction (BLI) with limited bilingual supervision is a crucial yet challenging task in multilingual NLP. Current state-of-the-art BLI methods rely on the induction of cross-lingual word embeddings (CLWEs) to capture cross-lingual word similarities; such CLWEs are obtained 1) via traditional static models (e.g., VecMap), or 2) by extracting type-level CLWEs from multilingual pretrained language models (mPLMs), or 3) through combining the former two options. In this work, we propose a novel semi-supervised post-hoc reranking method termed BLICEr (BLI with Cross-Encoder Reranking), applicable to any precalculated CLWE space, which improves their BLI capability. The key idea is to ‘extract' cross-lingual lexical knowledge from mPLMs, and then combine it with the original CLWEs. This crucial step is done via 1) creating a word similarity dataset, comprising positive word pairs (i.e., true translations) and hard negative pairs induced from the original CLWE space, and then 2) fine-tuning an mPLM (e.g., mBERT or XLM-R) in a cross-encoder manner to predict the similarity scores. At inference, we 3) combine the similarity score from the original CLWE space with the score from the BLI-tuned cross-encoder. BLICEr establishes new state-of-the-art results on two standard BLI benchmarks spanning a wide spectrum of diverse languages: it substantially outperforms a series of strong baselines across the board. We also validate the robustness of BLICEr with different CLWEs",
    "checked": true,
    "id": "8f5176137e87a9d47b9be3c3c09002660ad725ac",
    "semantic_title": "improving bilingual lexicon induction with cross-encoder reranking",
    "citation_count": 6,
    "authors": [
      "Yaoyiran Li",
      "Fangyu Liu",
      "Ivan Vulić",
      "Anna Korhonen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.303": {
    "title": "Mixed-modality Representation Learning and Pre-training for Joint Table-and-Text Retrieval in OpenQA",
    "volume": "findings",
    "abstract": "Retrieving evidences from tabular and textual resources is essential for open-domain question answering (OpenQA), which provides more comprehensive information. However, training an effective dense table-text retriever is difficult due to the challenges of table-text discrepancy and data sparsity problem. To address the above challenges, we introduce an optimized OpenQA Table-Text Retriever (OTTeR) to jointly retrieve tabular and textual evidences. Firstly, we propose to enhance mixed-modality representation learning via two mechanisms: modality-enhanced representation and mixed-modality negative sampling strategy. Secondly, to alleviate data sparsity problem and enhance the general retrieval ability, we conduct retrieval-centric mixed-modality synthetic pre-training. Experimental results demonstrate that OTTeR substantially improves the performance of table-and-text retrieval on the OTT-QA dataset. Comprehensive analyses examine the effectiveness of all the proposed mechanisms. Besides, equipped with OTTeR, our OpenQA system achieves the state-of-the-art result on the downstream QA task, with 10.1% absolute improvement in terms of the exact match over the previous best system",
    "checked": true,
    "id": "6f8ffdf8493323baadb2eb4b8c70f2d7084474f8",
    "semantic_title": "mixed-modality representation learning and pre-training for joint table-and-text retrieval in openqa",
    "citation_count": 9,
    "authors": [
      "Junjie Huang",
      "Wanjun Zhong",
      "Qian Liu",
      "Ming Gong",
      "Daxin Jiang",
      "Nan Duan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.304": {
    "title": "The Effects of Corpus Choice and Morphosyntax on Multilingual Space Induction",
    "volume": "findings",
    "abstract": "In an effort to study the inductive biases of language models, numerous studies have attempted to use linguistically motivated tasks as a proxy of sorts, wherein performance on these tasks would imply an inductive bias towards a specific linguistic phenomenon. In this study, we attempt to analyse the inductive biases of language models with respect to natural language phenomena, in the context of building multilingual embedding spaces. We sample corpora from 2 sources in 15 languages and train language models on pseudo-bilingual variants of each corpus, created by duplicating each corpus and shifting token indices for half the resulting corpus. We evaluate the cross-lingual capabilities of these LMs, and show that while correlations with language families tend to be weak, other corpus-level characteristics, such as type-token ratio, tend to be more strongly correlated. Finally, we show that multilingual spaces can be built, albeit less effectively, even when additional destructive perturbations are applied to the training corpora, implying that (effectively) bag-of-words models also have an inductive bias that is sufficient for inducing multilingual spaces",
    "checked": true,
    "id": "50464791ebb5adce5f06f8572a7de01c35475ec3",
    "semantic_title": "the effects of corpus choice and morphosyntax on multilingual space induction",
    "citation_count": 2,
    "authors": [
      "Vinit Ravishankar",
      "Joakim Nivre"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.305": {
    "title": "Modeling Complex Dialogue Mappings via Sentence Semantic Segmentation Guided Conditional Variational Auto-Encoder",
    "volume": "findings",
    "abstract": "Complex dialogue mappings (CDM), including one-to-many and many-to-one mappings, tend to make dialogue models generate incoherent or dull responses, and modeling these mappings remains a huge challenge for neural dialogue systems. To alleviate these problems, methods like introducing external information, reconstructing the optimization function, and manipulating data samples are proposed, while they primarily focus on avoiding training with CDM, inevitably weakening the model's ability of understanding CDM in human conversations and limiting further improvements in model performance. This paper proposes a Sentence Semantic Segmentation guided Conditional Variational Auto-Encoder (SegCVAE) method which can model and take advantages of the CDM data. Specifically, to tackle the incoherent problem caused by one-to-many, SegCVAE uses response-related prominent semantics to constrained the latent variable. To mitigate the non-diverse problem brought by many-to-one, SegCVAE segments multiple prominent semantics to enrich the latent variables. Three novel components, Internal Separation, External Guidance, and Semantic Norms, are proposed to achieve SegCVAE. On dialogue generation tasks, both the automatic and human evaluation results show that SegCVAE achieves new state-of-the-art performance",
    "checked": true,
    "id": "def71a0a2728ea4af3c1491cb2902e604402212b",
    "semantic_title": "modeling complex dialogue mappings via sentence semantic segmentation guided conditional variational auto-encoder",
    "citation_count": 1,
    "authors": [
      "Bin Sun",
      "Shaoxiong Feng",
      "Yiwei Li",
      "Weichao Wang",
      "Fei Mi",
      "Yitong Li",
      "Kan Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.306": {
    "title": "Graph Embeddings for Argumentation Quality Assessment",
    "volume": "findings",
    "abstract": "Argumentation is used by people both internally, by evaluating arguments and counterarguments to make sense of a situation and take a decision, and externally, e.g., in a debate, by exchanging arguments to reach an agreement or to promote an individual position. In this context, the assessment of the quality of the arguments is of extreme importance, as it strongly influences the evaluation of the overall argumentation, impacting on the decision making process. The automatic assessment of the quality of natural language arguments is recently attracting interest in the Argument Mining field. However, the issue of automatically assessing the quality of an argumentation largely remains a challenging unsolved task. Our contribution is twofold: first, we present a novel resource of 402 student persuasive essays, where three main quality dimensions (i.e., cogency, rhetoric, and reasonableness) have been annotated, leading to 1908 arguments tagged with quality facets; second, we address this novel task of argumentation quality assessment proposing a novel neural architecture based on graph embeddings, that combines both the textual features of the natural language arguments and the overall argument graph, i.e., considering also the support and attack relations holding among the arguments. Results on the persuasive essays dataset outperform state-of-the-art and standard baselines' performance",
    "checked": true,
    "id": "f2b93fa29a948b7699ed35e80889b74e70ca7b4c",
    "semantic_title": "graph embeddings for argumentation quality assessment",
    "citation_count": 7,
    "authors": [
      "Santiago Marro",
      "Elena Cabrio",
      "Serena Villata"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.307": {
    "title": "SMiLE: Schema-augmented Multi-level Contrastive Learning for Knowledge Graph Link Prediction",
    "volume": "findings",
    "abstract": "Link prediction is the task of inferring missing links between entities in knowledge graphs. Embedding-based methods have shown effectiveness in addressing this problem by modeling relational patterns in triples. However, the link prediction task often requires contextual information in entity neighborhoods, while most existing embedding-based methods fail to capture it. Additionally, little attention is paid to the diversity of entity representations in different contexts, which often leads to false prediction results. In this situation, we consider that the schema of knowledge graph contains the specific contextual information, and it is beneficial for preserving the consistency of entities across contexts. In this paper, we propose a novel Schema-augmented Multi-level contrastive LEarning framework (SMiLE) to conduct knowledge graph link prediction. Specifically, we first exploit network schema as the prior constraint to sample negatives and pre-train our model by employing a multi-level contrastive learning method to yield both prior schema and contextual information. Then we fine-tune our model under the supervision of individual triples to learn subtler representations for link prediction. Extensive experimental results on four knowledge graph datasets with thorough analysis of each component demonstrate the effectiveness of our proposed framework against state-of-the-art baselines. The implementation of SMiLE is available at https://github.com/GKNL/SMiLE",
    "checked": true,
    "id": "82e99fede80b7e97883a69e3609929d2713f8333",
    "semantic_title": "smile: schema-augmented multi-level contrastive learning for knowledge graph link prediction",
    "citation_count": 5,
    "authors": [
      "Miao Peng",
      "Ben Liu",
      "Qianqian Xie",
      "Wenjie Xu",
      "Hua Wang",
      "Min Peng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.308": {
    "title": "Multilingual Multimodal Learning with Machine Translated Text",
    "volume": "findings",
    "abstract": "Most vision-and-language pretraining research focuses on English tasks. However, the creation of multilingual multimodal evaluation datasets (e.g. Multi30K, xGQA, XVNLI, and MaRVL) poses a new challenge in finding high-quality training data that is both multilingual and multimodal. In this paper, we investigate whether machine translating English multimodal data can be an effective proxy for the lack of readily available multilingual data. We call this framework TD-MML: Translated Data for Multilingual Multimodal Learning, and it can be applied to any multimodal dataset and model. We apply it to both pretraining and fine-tuning data with a state-of-the-art model. In order to prevent models from learning from low-quality translated text, we propose two metrics for automatically removing such translations from the resulting datasets. In experiments on five tasks across 20 languages in the IGLUE benchmark, we show that translated data can provide a useful signal for multilingual multimodal learning, both at pretraining and fine-tuning",
    "checked": true,
    "id": "d3cf1287d2ae2c1102f6d1bc83d39d87e7159dfe",
    "semantic_title": "multilingual multimodal learning with machine translated text",
    "citation_count": 6,
    "authors": [
      "Chen Qiu",
      "Dan Oneață",
      "Emanuele Bugliarello",
      "Stella Frank",
      "Desmond Elliott"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.309": {
    "title": "Learning From the Source Document: Unsupervised Abstractive Summarization",
    "volume": "findings",
    "abstract": "Most of the state-of-the-art methods for abstractive text summarization are under supervised learning settings, while heavily relying on high-quality and large-scale parallel corpora. In this paper, we remove the need for reference summaries and present an unsupervised learning method SCR (Summarize, Contrast and Review) for abstractive summarization, which leverages contrastive learning and is the first work to apply contrastive learning for unsupervised abstractive summarization. Particularly, we use the true source documents as positive source document examples, and strategically generated fake source documents as negative source document examples to train the model to generate good summaries. Furthermore, we consider and improve the writing quality of the generated summaries by guiding them to be similar to human-written texts. The promising results on extensive experiments show that SCR outperforms other unsupervised abstractive summarization baselines, which demonstrates its effectiveness",
    "checked": true,
    "id": "1acedc6f203d6230133cc33bf41d23492809bc2a",
    "semantic_title": "learning from the source document: unsupervised abstractive summarization",
    "citation_count": 1,
    "authors": [
      "Haojie Zhuang",
      "Wei Emma Zhang",
      "Jian Yang",
      "Congbo Ma",
      "Yutong Qu",
      "Quan Z. Sheng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.310": {
    "title": "How to Do Things without Words: Modeling Semantic Drift of Emoji",
    "volume": "findings",
    "abstract": "Emoji have become a significant part of our informal textual communication. Previous work, addressing the societal and linguistic functions of emoji, overlooked the relation between the semantics and the visual variations of the symbols. In this paper we model and analyze the semantic drift of emoji and discuss the features that may be contributing to the drift, some are unique to emoji and some are more general. Specifically, we explore the relations between graphical changes and semantic changes",
    "checked": true,
    "id": "e34abd57de0b8d7ca3141a15826c3b6696cacc9c",
    "semantic_title": "how to do things without words: modeling semantic drift of emoji",
    "citation_count": 0,
    "authors": [
      "Eyal Arviv",
      "Oren Tsur"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.311": {
    "title": "Mind Your Bias: A Critical Review of Bias Detection Methods for Contextual Language Models",
    "volume": "findings",
    "abstract": "The awareness and mitigation of biases are of fundamental importance for the fair and transparent use of contextual language models, yet they crucially depend on the accurate detection of biases as a precursor. Consequently, numerous bias detection methods have been proposed, which vary in their approach, the considered type of bias, and the data used for evaluation. However, while most detection methods are derived from the word embedding association test for static word embeddings, the reported results are heterogeneous, inconsistent, and ultimately inconclusive. To address this issue, we conduct a rigorous analysis and comparison of bias detection methods for contextual language models. Our results show that minor design and implementation decisions (or errors) have a substantial and often significant impact on the derived bias scores. Overall, we find the state of the field to be both worse than previously acknowledged due to systematic and propagated errors in implementations, yet better than anticipated since divergent results in the literature homogenize after accounting for implementation errors. Based on our findings, we conclude with a discussion of paths towards more robust and consistent bias detection methods",
    "checked": true,
    "id": "f11f6066a92f20b71a8bc5c8a738ad78f073d095",
    "semantic_title": "mind your bias: a critical review of bias detection methods for contextual language models",
    "citation_count": 1,
    "authors": [
      "Silke Husse",
      "Andreas Spitz"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.312": {
    "title": "ZeroPrompt: Scaling Prompt-Based Pretraining to 1,000 Tasks Improves Zero-Shot Generalization",
    "volume": "findings",
    "abstract": "We propose a multitask pretraining approach ZeroPrompt for zero-shot generalization, focusing on task scaling and zero-shot prompting. While previous models are trained on only a few dozen tasks, we scale to 1,000 tasks for the first time using real-world data. This leads to a crucial discovery that task scaling can be an efficient alternative to model scaling; i.e., the model size has less impact on performance with an extremely large number of tasks. Our results show that task scaling can improve training efficiency by 30 times in FLOPs.Empirically, ZeroPrompt substantially improves both the efficiency and the performance of zero-shot learning across a variety of academic and production datasets",
    "checked": true,
    "id": "842104ef0575823498f26cdd57b4b4dba655df9e",
    "semantic_title": "zeroprompt: scaling prompt-based pretraining to 1, 000 tasks improves zero-shot generalization",
    "citation_count": 56,
    "authors": [
      "Hanwei Xu",
      "Yujun Chen",
      "Yulun Du",
      "Nan Shao",
      "Wang Yanggang",
      "Haiyu Li",
      "Zhilin Yang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.313": {
    "title": "Semantic Role Labeling Meets Definition Modeling: Using Natural Language to Describe Predicate-Argument Structures",
    "volume": "findings",
    "abstract": "One of the common traits of past and present approaches for Semantic Role Labeling (SRL) is that they rely upon discrete labels drawn from a predefined linguistic inventory to classify predicate senses and their arguments. However, we argue this need not be the case. In this paper, we present an approach that leverages Definition Modeling to introduce a generalized formulation of SRL as the task of describing predicate-argument structures using natural language definitions instead of discrete labels. Our novel formulation takes a first step towards placing interpretability and flexibility foremost, and yet our experiments and analyses on PropBank-style and FrameNet-style, dependency-based and span-based SRL also demonstrate that a flexible model with an interpretable output does not necessarily come at the expense of performance. We release our software for research purposes at https://github.com/SapienzaNLP/dsrl",
    "checked": true,
    "id": "8f75fe2a7b32f241f0d2c7a3a811b304c643e183",
    "semantic_title": "semantic role labeling meets definition modeling: using natural language to describe predicate-argument structures",
    "citation_count": 3,
    "authors": [
      "Simone Conia",
      "Edoardo Barba",
      "Alessandro Scirè",
      "Roberto Navigli"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.314": {
    "title": "Is anisotropy really the cause of BERT embeddings not being semantic?",
    "volume": "findings",
    "abstract": "In this paper we conduct a set of experiments aimed to improve our understanding of the lack of semantic isometry in BERT, i.e. the lack of correspondence between the embedding and meaning spaces of its contextualized word representations. Our empirical results show that, contrary to popular belief, the anisotropy is not the root cause of the poor performance of these contextual models' embeddings in semantic tasks. What does affect both the anisotropy and semantic isometry is a set of known biases: frequency, subword, punctuation, and case. For each one of them, we measure its magnitude and the effect of its removal, showing that these biases contribute but do not completely explain the phenomenon of anisotropy and lack of semantic isometry of these contextual language models",
    "checked": true,
    "id": "dfafe3e12fef5e60301e717dd0160d1e513879f9",
    "semantic_title": "is anisotropy really the cause of bert embeddings not being semantic?",
    "citation_count": 3,
    "authors": [
      "Alejandro Fuster Baggetto",
      "Victor Fresno"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.315": {
    "title": "m4 Adapter: Multilingual Multi-Domain Adaptation for Machine Translation with a Meta-Adapter",
    "volume": "findings",
    "abstract": "Multilingual neural machine translation models (MNMT) yield state-of-the-art performance when evaluated on data from a domain and language pair seen at training time. However, when a MNMT model is used to translate under domain shift or to a new language pair, performance drops dramatically. We consider a very challenging scenario: adapting the MNMT model both to a new domain and to a new language pair at the same time. In this paper, we propose m^4Adapter (Multilingual Multi-Domain Adaptation for Machine Translation with a Meta-Adapter), which combines domain and language knowledge using meta-learning with adapters. We present results showing that our approach is a parameter-efficient solution which effectively adapts a model to both a new language pair and a new domain, while outperforming other adapter methods. An ablation study also shows that our approach more effectively transfers domain knowledge across different languages and language information across different domains",
    "checked": true,
    "id": "7304ad770aff487dc97ceec49ee0951c04e65ad6",
    "semantic_title": "m^4 adapter: multilingual multi-domain adaptation for machine translation with a meta-adapter",
    "citation_count": 8,
    "authors": [
      "Wen Lai",
      "Alexandra Chronopoulou",
      "Alexander Fraser"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.316": {
    "title": "Textual Enhanced Contrastive Learning for Solving Math Word Problems",
    "volume": "findings",
    "abstract": "Solving math word problems is the task that analyses the relation of quantities and requires an accurate understanding of contextual natural language information. Recent studies show that current models rely on shallow heuristics to predict solutions and could be easily misled by small textual perturbations. To address this problem, we propose a Textual Enhanced Contrastive Learning framework, which enforces the models to distinguish semantically similar examples while holding different mathematical logic. We adopt a self-supervised manner strategy to enrich examples with subtle textual variance by textual reordering or problem re-construction. We then retrieve the hardest to differentiate samples from both equation and textual perspectives and guide the model to learn their representations. Experimental results show that our method achieves state-of-the-art on both widely used benchmark datasets and also exquisitely designed challenge datasets in English and Chinese",
    "checked": true,
    "id": "3a3100001bdca4b094345263fd2aafebd5e93555",
    "semantic_title": "textual enhanced contrastive learning for solving math word problems",
    "citation_count": 2,
    "authors": [
      "Yibin Shen",
      "Qianying Liu",
      "Zhuoyuan Mao",
      "Fei Cheng",
      "Sadao Kurohashi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.317": {
    "title": "What Do Compressed Multilingual Machine Translation Models Forget?",
    "volume": "findings",
    "abstract": "Recently, very large pre-trained models achieve state-of-the-art results in various natural language processing (NLP) tasks, but their size makes it more challenging to apply them in resource-constrained environments. Compression techniques allow to drastically reduce the size of the models and therefore their inference time with negligible impact on top-tier metrics. However, the general performance averaged across multiple tasks and/or languages may hide a drastic performance drop on under-represented features, which could result in the amplification of biases encoded by the models. In this work, we assess the impact of compression methods on Multilingual Neural Machine Translation models (MNMT) for various language groups, gender, and semantic biases by extensive analysis of compressed models on different machine translation benchmarks, i.e. FLORES-101, MT-Gender, and DiBiMT. We show that the performance of under-represented languages drops significantly, while the average BLEU metric only slightly decreases. Interestingly, the removal of noisy memorization with compression leads to a significant improvement for some medium-resource languages. Finally, we demonstrate that compression amplifies intrinsic gender and semantic biases, even in high-resource languages",
    "checked": true,
    "id": "2f408bd39fd02fab77b30afc029ad08aa20a6dda",
    "semantic_title": "what do compressed multilingual machine translation models forget?",
    "citation_count": 8,
    "authors": [
      "Alireza Mohammadshahi",
      "Vassilina Nikoulina",
      "Alexandre Berard",
      "Caroline Brun",
      "James Henderson",
      "Laurent Besacier"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.318": {
    "title": "Controllable Dialogue Simulation with In-context Learning",
    "volume": "findings",
    "abstract": "Building dialogue systems requires a large corpus of annotated dialogues. Such datasets are usually created via crowdsourcing, which is expensive and time-consuming. In this paper, we propose Dialogic, a novel dialogue simulation method based on large language model in-context learning to automate dataset creation. Seeded with a few annotated dialogues, Dialogic automatically selects in-context examples for demonstration and prompts GPT-3 to generate new dialogues and annotations in a controllable way. Our method can rapidly expand a small set of dialogue data with minimum or zero human involvement and parameter update and is thus much more cost-efficient and time-saving than crowdsourcing. Experimental results on the MultiWOZ dataset demonstrate that training a model on the simulated dialogues leads to even better performance than using the same amount of human-generated dialogues under the challenging low-resource settings, with as few as 85 dialogues as a seed. When the full training set is given, our method can still serve as an effective data augmentation method to further improve performance. Human evaluation results also show that our simulated dialogues have near-human fluency and annotation accuracy. The code and data are available at https://github.com/Leezekun/dialogic",
    "checked": true,
    "id": "8add69e155596bc128df70e1ddd5a41c68698399",
    "semantic_title": "controllable dialogue simulation with in-context learning",
    "citation_count": 20,
    "authors": [
      "Zekun Li",
      "Wenhu Chen",
      "Shiyang Li",
      "Hong Wang",
      "Jing Qian",
      "Xifeng Yan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.319": {
    "title": "Improving the Factual Correctness of Radiology Report Generation with Semantic Rewards",
    "volume": "findings",
    "abstract": "Neural image-to-text radiology report generation systems offer the potential to improve radiology reporting by reducing the repetitive process of report drafting and identifying possible medical errors. These systems have achieved promising performance as measured by widely used NLG metrics such as BLEU and CIDEr. However, the current systems face important limitations. First, they present an increased complexity in architecture that offers only marginal improvements on NLG metrics. Secondly, these systems that achieve high performance on these metrics are not always factually complete or consistent due to both inadequate training and evaluation. Recent studies have shown the systems can be substantially improved by using new methods encouraging 1) the generation of domain entities consistent with the reference and 2) describing these entities in inferentially consistent ways. So far, these methods rely on weakly-supervised approaches (rule-based) and named entity recognition systems that are not specific to the chest X-ray domain. To overcome this limitation, we propose a new method, the RadGraph reward, to further improve the factual completeness and correctness of generated radiology reports. More precisely, we leverage the RadGraph dataset containing annotated chest X-ray reports with entities and relations between entities. On two open radiology report datasets, our system substantially improves the scores up to 14.2% and 25.3% on metrics evaluating the factual correctness and completeness of reports",
    "checked": true,
    "id": "9a3ecfc83662476cd6d7a3f41ca628e9d8d9f9fd",
    "semantic_title": "improving the factual correctness of radiology report generation with semantic rewards",
    "citation_count": 30,
    "authors": [
      "Jean-Benoit Delbrouck",
      "Pierre Chambon",
      "Christian Bluethgen",
      "Emily Tsai",
      "Omar Almusa",
      "Curtis Langlotz"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.320": {
    "title": "Recursive Neural Networks with Bottlenecks Diagnose (Non-)Compositionality",
    "volume": "findings",
    "abstract": "A recent line of work in NLP focuses on the (dis)ability of models to generalise compositionally for artificial languages. However, when considering natural language tasks, the data involved is not strictly, or locally, compositional. Quantifying the compositionality of data is a challenging task, which has been investigated primarily for short utterances. We use recursive neural models (Tree-LSTMs) with bottlenecks that limit the transfer of information between nodes. We illustrate that comparing data's representations in models with and without the bottleneck can be used to produce a compositionality metric. The procedure is applied to the evaluation of arithmetic expressions using synthetic data, and sentiment classification using natural language data. We demonstrate that compression through a bottleneck impacts non-compositional examples disproportionatelyand then use the bottleneck compositionality metric (BCM) to distinguish compositional from non-compositional samples, yielding a compositionality ranking over a dataset",
    "checked": true,
    "id": "8d591175f8d034812c928c70f68e2757eb22689d",
    "semantic_title": "recursive neural networks with bottlenecks diagnose (non-)compositionality",
    "citation_count": 2,
    "authors": [
      "Verna Dankers",
      "Ivan Titov"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.321": {
    "title": "HumSet: Dataset of Multilingual Information Extraction and Classification for Humanitarian Crises Response",
    "volume": "findings",
    "abstract": "Timely and effective response to humanitarian crises requires quick and accurate analysis of large amounts of text data – a process that can highly benefit from expert-assisted NLP systems trained on validated and annotated data in the humanitarian response domain. To enable creation of such NLP systems, we introduce and release HumSet, a novel and rich multilingual dataset of humanitarian response documents annotated by experts in the humanitarian response community. The dataset provides documents in three languages (English, French, Spanish) and covers a variety of humanitarian crises from 2018 to 2021 across the globe. For each document, HUMSET provides selected snippets (entries) as well as assigned classes to each entry annotated using common humanitarian information analysis frameworks. HUMSET also provides novel and challenging entry extraction and multi-label entry classification tasks. In this paper, we take a first step towards approaching these tasks and conduct a set of experiments on Pre-trained Language Models (PLM) to establish strong baselines for future research in this domain. The dataset is available at https://blog.thedeep.io/humset/",
    "checked": true,
    "id": "199b2d3e76c8237e38572f1b74dc2081723db526",
    "semantic_title": "humset: dataset of multilingual information extraction and classification for humanitarian crisis response",
    "citation_count": 4,
    "authors": [
      "Selim Fekih",
      "Nicolo’ Tamagnone",
      "Benjamin Minixhofer",
      "Ranjan Shrestha",
      "Ximena Contla",
      "Ewan Oglethorpe",
      "Navid Rekabsaz"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.322": {
    "title": "Viterbi Decoding of Directed Acyclic Transformer for Non-Autoregressive Machine Translation",
    "volume": "findings",
    "abstract": "Non-autoregressive models achieve significant decoding speedup in neural machine translation but lack the ability to capture sequential dependency. Directed Acyclic Transformer (DA-Transformer) was recently proposed to model sequential dependency with a directed acyclic graph. Consequently, it has to apply a sequential decision process at inference time, which harms the global translation accuracy. In this paper, we present a Viterbi decoding framework for DA-Transformer, which guarantees to find the joint optimal solution for the translation and decoding path under any length constraint. Experimental results demonstrate that our approach consistently improves the performance of DA-Transformer while maintaining a similar decoding speedup",
    "checked": true,
    "id": "8d5388f4c3c3345b9a89cce3e358a06fb3847d6a",
    "semantic_title": "viterbi decoding of directed acyclic transformer for non-autoregressive machine translation",
    "citation_count": 10,
    "authors": [
      "Chenze Shao",
      "Zhengrui Ma",
      "Yang Feng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.323": {
    "title": "Lexical Generalization Improves with Larger Models and Longer Training",
    "volume": "findings",
    "abstract": "While fine-tuned language models perform well on many language tasks, they were also shown to rely on superficial surface features such as lexical overlap. Excessive utilization of such heuristics can lead to failure on challenging inputs. We analyze the use of lexical overlap heuristics in natural language inference, paraphrase detection, and reading comprehension (using a novel contrastive dataset),and find that larger models are much less susceptible to adopting lexical overlap heuristics. We also find that longer training leads models to abandon lexical overlap heuristics. Finally, We provide evidence that the disparity between models size has its source in the pre-trained model",
    "checked": true,
    "id": "4a9a8ea5a25842bdc2aff0df23094d622e612673",
    "semantic_title": "lexical generalization improves with larger models and longer training",
    "citation_count": 5,
    "authors": [
      "Elron Bandel",
      "Yoav Goldberg",
      "Yanai Elazar"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.324": {
    "title": "Realistic Data Augmentation Framework for Enhancing Tabular Reasoning",
    "volume": "findings",
    "abstract": "Existing approaches to constructing training data for Natural Language Inference (NLI) tasks, such as for semi-structured table reasoning, are either via crowdsourcing or fully automatic methods. However, the former is expensive and time consuming and thus limits scale, and the latter often produces naive examples that may lack complex reasoning. This paper develops a realistic semi-automated framework for data augmentation for tabular inference. Instead of manually generating a hypothesis for each table, our methodology generates hypothesis templates transferable to similar tables. In addition, our framework entails the creation of rational counterfactual tables based on human written logical constraints and premise paraphrasing. For our case study, we use the INFOTABS (Gupta et al., 2020), which is an entity centric tabular inference dataset. We observed that our framework could generate human-like tabular inference examples, which could benefit training data augmentation, especially in the scenario with limited supervision",
    "checked": true,
    "id": "2a5de8118bf4871b13197d85d8858d875a6106a6",
    "semantic_title": "realistic data augmentation framework for enhancing tabular reasoning",
    "citation_count": 3,
    "authors": [
      "Dibyakanti Kumar",
      "Vivek Gupta",
      "Soumya Sharma",
      "Shuo Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.325": {
    "title": "Inducing Generalizable and Interpretable Lexica",
    "volume": "findings",
    "abstract": "Lexica – words and associated scores – are widely used as simple, interpretable, generalizable language features to predict sentiment, emotions, mental health, and personality. They also provide insight into the psychological features behind those moods and traits. Such lexica, historically created by human experts, are valuable to linguists, psychologists, and social scientists, but they take years of refinement and have limited coverage. In this paper, we investigate how the lexica that provide psycholinguistic insights could be computationally induced and how they should be assessed. We identify generalizability and interpretability as two essential properties of such lexica. We induce lexica using both context-oblivious and context-aware approaches, compare their predictive performance both within the training corpus and across various corpora, and evaluate their quality using crowd-worker assessment. We find that lexica induced from context-oblivious models are more generalizable and interpretable than those from more accurate context-aware transformer models. In addition, lexicon scores can identify explanatory words more reliably than a high performing transformer with feature-importance measures like SHAP",
    "checked": true,
    "id": "30e4780541b172a6a405740b32508944ef4ef576",
    "semantic_title": "inducing generalizable and interpretable lexica",
    "citation_count": 0,
    "authors": [
      "Yilin Geng",
      "Zetian Wu",
      "Roshan Santhosh",
      "Tejas Srivastava",
      "Lyle Ungar",
      "João Sedoc"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.326": {
    "title": "The Curious Case of Absolute Position Embeddings",
    "volume": "findings",
    "abstract": "Transformer language models encode the notion of word order using positional information. Most commonly, this positional information is represented by absolute position embeddings (APEs), that are learned from the pretraining data. However, in natural language, it is not absolute position that matters, but relative position, and the extent to which APEs can capture this type of information has not been studied. In this work, we observe that models trained with APE over-rely on positional information to the point that they break-down when subjected to sentences with shifted position information. Specifically, when models are subjected to sentences starting from a non-zero position (excluding the effect of priming), they exhibit noticeably degraded performance on zero- to full-shot tasks, across a range of model families and model sizes. Our findings raise questions about the efficacy of APEs to model the relativity of position information, and invite further introspection on the sentence and word order processing strategies employed by these models",
    "checked": true,
    "id": "97833e2aa0da5240e62436373b58af988a4ab6ab",
    "semantic_title": "the curious case of absolute position embeddings",
    "citation_count": 8,
    "authors": [
      "Koustuv Sinha",
      "Amirhossein Kazemnejad",
      "Siva Reddy",
      "Joelle Pineau",
      "Dieuwke Hupkes",
      "Adina Williams"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.327": {
    "title": "Goal-oriented Vision-and-Dialog Navigation via Reinforcement Learning",
    "volume": "findings",
    "abstract": "Vision-and-dialog navigation is a recent benchmark for evaluating the AI capabilities of perception, interaction, and decision making. While existing methods developed for this benchmark have demonstrated great successes, they mostly rely on large datasets, where data collection can be a challenge, and the learned policies are not adaptive to domain changes. In this paper, we focus on a new problem, referred to as goal-oriented vision-and-dialog navigation (GVDN), where an agent uses reinforcement learning techniques to compute dialog-navigation policies from trial and error. A robot conducts visual navigation to locate target objects, and can talk to a remote human operator as needed. Our remote human is able to provide guidance on navigation only if the robot correctly conveys its location through dialog. Experiments have been conducted using photo-realistic simulation environments. Results suggest that, our agent outperforms competitive baselines in success rate",
    "checked": true,
    "id": "f4350ba7aee4c48d5ac70357012454e399c33673",
    "semantic_title": "goal-oriented vision-and-dialog navigation via reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Yan Cao",
      "Keting Lu",
      "David DeFazio",
      "Shiqi Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.328": {
    "title": "Leveraging Data Recasting to Enhance Tabular Reasoning",
    "volume": "findings",
    "abstract": "Creating challenging tabular inference data is essential for learning complex reasoning. Prior work has mostly relied on two data generation strategies. The first is human annotation, which yields linguistically diverse data but is difficult to scale. The second category for creation is synthetic generation, which is scalable and cost effective but lacks inventiveness. In this research, we present a framework for semi-automatically recasting existing tabular data to make use of the benefits of both approaches. We utilize our framework to build tabular NLI instances from five datasets that were initially intended for tasks like table2text creation, tabular Q/A, and semantic parsing. We demonstrate that recasted data could be used as evaluation benchmarks as well as augmentation data to enhance performance on tabular NLI tasks. Furthermore, we investigate the effectiveness of models trained on recasted data in the zero-shot scenario, and analyse trends in performance across different recasted datasets types",
    "checked": true,
    "id": "f9780413a1142407122b5e78a74c5eb46a4ee39c",
    "semantic_title": "leveraging data recasting to enhance tabular reasoning",
    "citation_count": 3,
    "authors": [
      "Aashna Jena",
      "Vivek Gupta",
      "Manish Shrivastava",
      "Julian Eisenschlos"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.329": {
    "title": "Thinking about GPT-3 In-Context Learning for Biomedical IE? Think Again",
    "volume": "findings",
    "abstract": "Large pre-trained language models (PLMs) such as GPT-3 have shown strong in-context learning capabilities, which are highly appealing for domains such as biomedicine that feature high and diverse demands of language technologies but also high data annotation costs. In this paper, we present the first systematic and comprehensive study to compare the few-shot performance of GPT-3 in-context learning with fine-tuning smaller (i.e., BERT-sized) PLMs on two representative biomedical information extraction (IE) tasks: named entity recognition and relation extraction. We follow the true few-shot setting to avoid overestimating models' few-shot performance by model selection over a large validation set. We also optimize GPT-3's performance with known techniques such as contextual calibration and dynamic in-context example retrieval. However, our results show that GPT-3 still significantly underperforms compared to simply fine-tuning a smaller PLM. In addition, GPT-3 in-context learning also yields smaller gains in accuracy when more training data becomes available. More in-depth analyses further reveal issues of in-context learning that may be detrimental to IE tasks in general. Given the high cost of experimenting with GPT-3, we hope our study provides helpful guidance for biomedical researchers and practitioners towards more practical solutions such as fine-tuning small PLMs before better in-context learning is available for biomedical IE",
    "checked": true,
    "id": "cfc12c38a4d848ff3c4225488a2c72e7d4300f4b",
    "semantic_title": "thinking about gpt-3 in-context learning for biomedical ie? think again",
    "citation_count": 85,
    "authors": [
      "Bernal Jimenez Gutierrez",
      "Nikolas McNeal",
      "Clayton Washington",
      "You Chen",
      "Lang Li",
      "Huan Sun",
      "Yu Su"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.330": {
    "title": "Attention weights accurately predict language representations in the brain",
    "volume": "findings",
    "abstract": "In Transformer-based language models (LMs) the attention mechanism converts token embeddings into contextual embeddings that incorporate information from neighboring words. The resulting contextual hidden state embeddings have enabled highly accurate models of brain responses, suggesting that the attention mechanism constructs contextual embeddings that carry information reflected in language-related brain representations. However, it is unclear whether the attention weights that are used to integrate information across words are themselves related to language representations in the brain. To address this question we analyzed functional magnetic resonance imaging (fMRI) recordings of participants reading English language narratives. We provided the narrative text as input to two LMs (BERT and GPT-2) and extracted their corresponding attention weights. We then used encoding models to determine how well attention weights can predict recorded brain responses. We find that attention weights accurately predict brain responses in much of the frontal and temporal cortices. Our results suggest that the attention mechanism itself carries information that is reflected in brain representations. Moreover, these results indicate cortical areas in which context integration may occur",
    "checked": true,
    "id": "46c87b00d9ad2f69eb282fc2faa908dcf94eb77d",
    "semantic_title": "attention weights accurately predict language representations in the brain",
    "citation_count": 5,
    "authors": [
      "Mathis Lamarre",
      "Catherine Chen",
      "Fatma Deniz"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.331": {
    "title": "Improving HowNet-Based Chinese Word Sense Disambiguation with Translations",
    "volume": "findings",
    "abstract": "Word sense disambiguation (WSD) is the task of identifying the intended sense of a word in context. While prior work on unsupervised WSD has leveraged lexical knowledge bases, such as WordNet and BabelNet, these resources have proven to be less effective for Chinese. Instead, the most widely used lexical knowledge base for Chinese is HowNet. Previous HowNet-based WSD methods have not exploited contextual translation information. In this paper, we present the first HowNet-based WSD system which combines monolingual contextual information from a pretrained neural language model with bilingual information obtained via machine translation and sense translation information from HowNet. The results of our evaluation experiment on a test set from prior work demonstrate that our new method achieves a new state of the art for unsupervised Chinese WSD",
    "checked": true,
    "id": "ffce61ff4d5ec1a099706dd63554a960de212631",
    "semantic_title": "improving hownet-based chinese word sense disambiguation with translations",
    "citation_count": 2,
    "authors": [
      "Xiang Zhang",
      "Bradley Hauer",
      "Grzegorz Kondrak"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.332": {
    "title": "Mask-then-Fill: A Flexible and Effective Data Augmentation Framework for Event Extraction",
    "volume": "findings",
    "abstract": "We present Mask-then-Fill, a flexible and effective data augmentation framework for event extraction. Our approach allows for more flexible manipulation of text and thus can generate more diverse data while keeping the original event structure unchanged as much as possible. Specifically, it first randomly masks out an adjunct sentence fragment and then infills a variable-length text span with a fine-tuned infilling model. The main advantage lies in that it can replace a fragment of arbitrary length in the text with another fragment of variable length, compared to the existing methods which can only replace a single word or a fixed-length fragment. On trigger and argument extraction tasks, the proposed framework is more effective than baseline methods and it demonstrates particularly strong results in the low-resource setting. Our further analysis shows that it achieves a good balance between diversity and distributional similarity",
    "checked": true,
    "id": "a955a5a6d2fd7740375b6f22d2ac9719ce02d17f",
    "semantic_title": "mask-then-fill: a flexible and effective data augmentation framework for event extraction",
    "citation_count": 17,
    "authors": [
      "Jun Gao",
      "Changlong Yu",
      "Wei Wang",
      "Huan Zhao",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.333": {
    "title": "MOBA-E2C: Generating MOBA Game Commentaries via Capturing Highlight Events from the Meta-Data",
    "volume": "findings",
    "abstract": "MOBA (Multiplayer Online Battle Arena) games such as Dota2 are currently one of the most popular e-sports gaming genres. Following professional commentaries is a great way to understand and enjoy a MOBA game. However, massive game competitions lack commentaries because of the shortage of professional human commentators. As an alternative, employing machine commentators that can work at any time and place is a feasible solution. Considering the challenges in modeling MOBA games, we propose a data-driven MOBA commentary generation framework, MOBA-E2C, allowing a model to generate commentaries based on the game meta-data. Subsequently, to alleviate the burden of collecting supervised data, we propose a MOBA-FuseGPT generator to generate MOBA game commentaries by fusing the power of a rule-based generator and a generative GPT generator. Finally, in the experiments, we take a popular MOBA game Dota2 as our case and construct a Chinese Dota2 commentary generation dataset Dota2-Commentary. Experimental results demonstrate the superior performance of our approach. To the best of our knowledge, this work is the first Dota2 machine commentator and Dota2-Commentary is the first dataset",
    "checked": true,
    "id": "a488b0968071c5a06f5be430e5863225657221c2",
    "semantic_title": "moba-e2c: generating moba game commentaries via capturing highlight events from the meta-data",
    "citation_count": 0,
    "authors": [
      "Dawei Zhang",
      "Sixing Wu",
      "Yao Guo",
      "Xiangqun Chen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.334": {
    "title": "Enhancing Automatic Readability Assessment with Pre-training and Soft Labels for Ordinal Regression",
    "volume": "findings",
    "abstract": "The readability assessment task aims to assign a difficulty grade to a text. While neural models have recently demonstrated impressive performance, most do not exploit the ordinal nature of the difficulty grades, and make little effort for model initialization to facilitate fine-tuning. We address these limitations with soft labels for ordinal regression, and with model pre-training through prediction of pairwise relative text difficulty. We incorporate these two components into a model based on hierarchical attention networks, and evaluate its performance on both English and Chinese datasets. Experimental results show that our proposed model outperforms competitive neural models and statistical classifiers on most datasets",
    "checked": true,
    "id": "0716e20adf8ac8d58669f9dd8a6089327a080b03",
    "semantic_title": "enhancing automatic readability assessment with pre-training and soft labels for ordinal regression",
    "citation_count": 1,
    "authors": [
      "Jinshan Zeng",
      "Yudong Xie",
      "Xianglong Yu",
      "John Lee",
      "Ding-Xuan Zhou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.335": {
    "title": "Opening up Minds with Argumentative Dialogues",
    "volume": "findings",
    "abstract": "Recent research on argumentative dialogues has focused on persuading people to take some action, changing their stance on the topic of discussion, or winning debates. In this work, we focus on argumentative dialogues that aim to open up (rather than change) people's minds to help them become more understanding to views that are unfamiliar or in opposition to their own convictions. To this end, we present a dataset of 183 argumentative dialogues about 3 controversial topics: veganism, Brexit and COVID-19 vaccination. The dialogues were collected using the Wizard of Oz approach, where wizards leverage a knowledge-base of arguments to converse with participants. Open-mindedness is measured before and after engaging in the dialogue using a questionnaire from the psychology literature, and success of the dialogue is measured as the change in the participant's stance towards those who hold opinions different to theirs. We evaluate two dialogue models: a Wikipedia-based and an argument-based model. We show that while both models perform closely in terms of opening up minds, the argument-based model is significantly better on other dialogue properties such as engagement and clarity",
    "checked": true,
    "id": "276bb33cf4f31f2656b6b974d85e691efdb6ef3c",
    "semantic_title": "opening up minds with argumentative dialogues",
    "citation_count": 3,
    "authors": [
      "Youmna Farag",
      "Charlotte Brand",
      "Jacopo Amidei",
      "Paul Piwek",
      "Tom Stafford",
      "Svetlana Stoyanchev",
      "Andreas Vlachos"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.336": {
    "title": "You Are My Type! Type Embeddings for Pre-trained Language Models",
    "volume": "findings",
    "abstract": "One reason for the positive impact of Pre-trained Language Models (PLMs) in NLP tasks is their ability to encode semantic types, such as ‘European City' or ‘Woman'. While previous work has analyzed such information in the context of interpretability, it is not clear how to use types to steer the PLM output. For example, in a cloze statement, it is desirable to steer the model to generate a token that satisfies a user-specified type, e.g., predict a date rather than a location. In this work, we introduce Type Embeddings (TEs), an input embedding that promotes desired types in a PLM. Our proposal is to define a type by a small set of word examples. We empirically study the ability of TEs both in representing types and in steering masking predictions without changes to the prompt text in BERT. Finally, using the LAMA datasets, we show how TEs highly improve the precision in extracting facts from PLMs",
    "checked": true,
    "id": "1434629ba010dcf26aec2c402273388a5ef6ef0c",
    "semantic_title": "you are my type! type embeddings for pre-trained language models",
    "citation_count": 3,
    "authors": [
      "Mohammed Saeed",
      "Paolo Papotti"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.337": {
    "title": "Generating Textual Adversaries with Minimal Perturbation",
    "volume": "findings",
    "abstract": "Many word-level adversarial attack approaches for textual data have been proposed in recent studies. However, due to the massive search space consisting of combinations of candidate words, the existing approaches face the problem of preserving the semantics of texts when crafting adversarial counterparts. In this paper, we develop a novel attack strategy to find adversarial texts with high similarity to the original texts while introducing minimal perturbation. The rationale is that we expect the adversarial texts with small perturbation can better preserve the semantic meaning of original texts. Experiments show that, compared with state-of-the-art attack approaches, our approach achieves higher success rates and lower perturbation rates in four benchmark datasets",
    "checked": true,
    "id": "064ccc5c41e13ab468d8ce0569333c8acd4f641a",
    "semantic_title": "generating textual adversaries with minimal perturbation",
    "citation_count": 0,
    "authors": [
      "Xingyi Zhao",
      "Lu Zhang",
      "Depeng Xu",
      "Shuhan Yuan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.338": {
    "title": "SensePOLAR: Word sense aware interpretability for pre-trained contextual word embeddings",
    "volume": "findings",
    "abstract": "Adding interpretability to word embeddings represents an area of active research in textrepresentation. Recent work has explored the potential of embedding words via so-called polardimensions (e.g. good vs. bad, correct vs. wrong). Examples of such recent approachesinclude SemAxis, POLAR, FrameAxis, and BiImp. Although these approaches provide interpretabledimensions for words, they have not been designed to deal with polysemy, i.e. they can not easily distinguish between different senses of words. To address this limitation, we present SensePOLAR, an extension of the original POLAR framework that enables wordsense aware interpretability for pre-trained contextual word embeddings. The resulting interpretable word embeddings achieve a level ofperformance that is comparable to original contextual word embeddings across a variety ofnatural language processing tasks including the GLUE and SQuAD benchmarks. Our workremoves a fundamental limitation of existing approaches by offering users sense aware interpretationsfor contextual word embeddings",
    "checked": true,
    "id": "a11bbf3bf84db7a809d9523c1c1d1166f5abdb60",
    "semantic_title": "sensepolar: word sense aware interpretability for pre-trained contextual word embeddings",
    "citation_count": 2,
    "authors": [
      "Jan Engler",
      "Sandipan Sikdar",
      "Marlene Lutz",
      "Markus Strohmaier"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.339": {
    "title": "Contextualizing Language Models for Norms Diverging from Social Majority",
    "volume": "findings",
    "abstract": "To comprehensibly contextualize decisions, artificial systems in social situations need a high degree of awareness of the rules of conduct of human behavior. Especially transformer-based language models have recently been shown to exhibit some such awareness. But what if norms in some social setting do not adhere to or even blatantly deviate from the mainstream? In this paper, we introduce a novel mechanism based on deontic logic to allow for a flexible adaptation of individual norms by de-biasing training data sets and a task-reduction to textual entailment. Building on the popular ‘Moral Stories' dataset we on the one hand highlight the intrinsic bias of current language models, on the other hand characterize the adaptability of pre-trained models to deviating norms in fine-tuning settings",
    "checked": true,
    "id": "40accf927b75c49dad0f08199c390d1158ef202b",
    "semantic_title": "contextualizing language models for norms diverging from social majority",
    "citation_count": 3,
    "authors": [
      "Niklas Kiehne",
      "Hermann Kroll",
      "Wolf-Tilo Balke"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.340": {
    "title": "Empathetic Dialogue Generation via Sensitive Emotion Recognition and Sensible Knowledge Selection",
    "volume": "findings",
    "abstract": "Empathy, which is widely used in psychological counseling, is a key trait of everyday human conversations. Equipped with commonsense knowledge, current approaches to empathetic response generation focus on capturing implicit emotion within dialogue context, where the emotions are treated as a static variable throughout the conversations. However, emotions change dynamically between utterances, which makes previous works difficult to perceive the emotion flow and predict the correct emotion of the target response, leading to inappropriate response. Furthermore, simply importing commonsense knowledge without harmonization may trigger the conflicts between knowledge and emotion, which confuse the model to choose the correct information to guide the generation process. To address the above problems, we propose a Serial Encoding and Emotion-Knowledge interaction (SEEK) method for empathetic dialogue generation. We use a fine-grained encoding strategy which is more sensitive to the emotion dynamics (emotion flow) in the conversations to predict the emotion-intent characteristic of response. Besides, we design a novel framework to model the interaction between knowledge and emotion to solve the conflicts generate more sensible response. Extensive experiments on the utterance-level annotated EMPATHETICDIALOGUES demonstrate that SEEK outperforms the strong baseline in both automatic and manual evaluations",
    "checked": true,
    "id": "7f6a790ad82960cfb282542efe0fac1a8db0e9dd",
    "semantic_title": "empathetic dialogue generation via sensitive emotion recognition and sensible knowledge selection",
    "citation_count": 11,
    "authors": [
      "Lanrui Wang",
      "Jiangnan Li",
      "Zheng Lin",
      "Fandong Meng",
      "Chenxu Yang",
      "Weiping Wang",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.341": {
    "title": "Joint Multilingual Knowledge Graph Completion and Alignment",
    "volume": "findings",
    "abstract": "Knowledge graph (KG) alignment and completion are usually treated as two independent tasks. While recent work has leveraged entity and relation alignments from multiple KGs, such as alignments between multilingual KGs with common entities and relations, a deeper understanding of the ways in which multilingual KG completion (MKGC) can aid the creation of multilingual KG alignments (MKGA) is still limited. Motivated by the observation that structural inconsistencies – the main challenge for MKGA models – can be mitigated through KG completion methods, we propose a novel model for jointly completing and aligning knowledge graphs. The proposed model combines two components that jointly accomplish KG completion and alignment. These two components employ relation-aware graph neural networks that we propose to encode multi-hop neighborhood structures into entity and relation representations. Moreover, we also propose (i) a structural inconsistency reduction mechanism to incorporate information from the completion into the alignment component, and (ii) an alignment seed enlargement and triple transferring mechanism to enlarge alignment seeds and transfer triples during KGs alignment. Extensive experiments on a public multilingual benchmark show that our proposed model outperforms existing competitive baselines, obtaining new state-of-the-art results on both MKGC and MKGA tasks",
    "checked": true,
    "id": "7e7569c064ea64c023ca429b083fcd574fcfa3a8",
    "semantic_title": "joint multilingual knowledge graph completion and alignment",
    "citation_count": 3,
    "authors": [
      "Vinh Tong",
      "Dat Quoc Nguyen",
      "Trung Thanh Huynh",
      "Tam Thanh Nguyen",
      "Quoc Viet Hung Nguyen",
      "Mathias Niepert"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.342": {
    "title": "A Framework for Automatic Generation of Spoken Question-Answering Data",
    "volume": "findings",
    "abstract": "This paper describes a framework to automatically generate a spoken question answering (QA) dataset. The framework consists of a question generation (QG) module to generate questions automatically from given text documents, a text-to-speech (TTS) module to convert the text documents into spoken form and an automatic speech recognition (ASR) module to transcribe the spoken content. The final dataset contains question-answer pairs for both the reference text and ASR transcriptions as well as the audio files corresponding to each reference text. For QG and ASR systems we used pre-trained multilingual encoder-decoder transformer models and fine-tuned these models using a limited amount of manually generated QA data and TTS-based speech data, respectively. As a proof of concept, we investigated the proposed framework for Turkish and generated the Turkish Question Answering (TurQuAse) dataset using Wikipedia articles. Manual evaluation of the automatically generated question- answer pairs and QA performance evaluation with state of-the-art models on TurQuAse show that the proposed framework is efficient for automatically generating spoken QA datasets. To the best of our knowledge, TurQuAse is the first publicly available spoken question answering dataset for Turkish. The proposed framework can be easily extended to other languages where a limited amount of QA data is available",
    "checked": true,
    "id": "7b2a5d6c2ba0ca13c5e110fec3781c7c2b4b4189",
    "semantic_title": "a framework for automatic generation of spoken question-answering data",
    "citation_count": 1,
    "authors": [
      "Merve Ünlü Menevşe",
      "Yusufcan Manav",
      "Ebru Arisoy",
      "Arzucan Özgür"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.343": {
    "title": "Readability Controllable Biomedical Document Summarization",
    "volume": "findings",
    "abstract": "Different from general documents, it is recognised that the ease with which people can understand a biomedical text is eminently varied, owing to the highly technical nature of biomedical documents and the variance of readers' domain knowledge. However, existing biomedical document summarization systems have paid little attention to readability control, leaving users with summaries that are incompatible with their levels of expertise. In recognition of this urgent demand, we introduce a new task of readability controllable summarization for biomedical documents, which aims to recognise users' readability demands and generate summaries that better suit their needs: technical summaries for experts and plain language summaries (PLS) for laymen. To establish this task, we construct a corpus consisting of biomedical papers with technical summaries and PLSs written by the authors, and benchmark multiple advanced controllable abstractive and extractive summarization models based on pre-trained language models (PLMs) with prevalent controlling and generation techniques. Moreover, we propose a novel masked language model (MLM) based metric and its variant to effectively evaluate the readability discrepancy between lay and technical summaries. Experimental results from automated and human evaluations show that though current control techniques allow for a certain degree of readability adjustment during generation, the performance of existing controllable summarization methods is far from desirable in this task",
    "checked": true,
    "id": "8a9e7290d403dd2098e5ce80d6338ae03071cf85",
    "semantic_title": "readability controllable biomedical document summarization",
    "citation_count": 29,
    "authors": [
      "Zheheng Luo",
      "Qianqian Xie",
      "Sophia Ananiadou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.344": {
    "title": "Beyond Additive Fusion: Learning Non-Additive Multimodal Interactions",
    "volume": "findings",
    "abstract": "Multimodal fusion addresses the problem of analyzing spoken words in the multimodal context, including visual expressions and prosodic cues. Even when multimodal models lead to performance improvements, it is often unclear whether bimodal and trimodal interactions are learned or whether modalities are processed independently of each other. We propose Multimodal Residual Optimization (MRO) to separate unimodal, bimodal, and trimodal interactions in a multimodal model. This improves interpretability as the multimodal interaction can be quantified. Inspired by Occam's razor, the main intuition of MRO is that (simpler) unimodal contributions should be learned before learning (more complex) bimodal and trimodal interactions. For example, bimodal predictions should learn to correct the mistakes (residuals) of unimodal predictions, thereby letting the bimodal predictions focus on the remaining bimodal interactions. Empirically, we observe that MRO successfully separates unimodal, bimodal, and trimodal interactions while not degrading predictive performance. We complement our empirical results with a human perception study and observe that MRO learns multimodal interactions that align with human judgments",
    "checked": true,
    "id": "4e957c880425fd521db26f61852a1e6b5989f5c2",
    "semantic_title": "beyond additive fusion: learning non-additive multimodal interactions",
    "citation_count": 4,
    "authors": [
      "Torsten Wörtwein",
      "Lisa Sheeber",
      "Nicholas Allen",
      "Jeffrey Cohn",
      "Louis-Philippe Morency"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.345": {
    "title": "Generalization Differences between End-to-End and Neuro-Symbolic Vision-Language Reasoning Systems",
    "volume": "findings",
    "abstract": "For vision-and-language reasoning tasks, both fully connectionist, end-to-end methods and hybrid, neuro-symbolic methods have achieved high in-distribution performance. In which out-of-distribution settings does each paradigm excel? We investigate this question on both single-image and multi-image visual question-answering through four types of generalization tests: a novel segment-combine test for multi-image queries, contrast set, compositional generalization, and cross-benchmark transfer. Vision-and-language end-to-end trained systems exhibit sizeable performance drops across all these tests. Neuro-symbolic methods suffer even more on cross-benchmark transfer from GQA to VQA, but they show smaller accuracy drops on the other generalization tests and their performance quickly improves by few-shot training. Overall, our results demonstrate the complementary benefits of these two paradigms, and emphasize the importance of using a diverse suite of generalization tests to fully characterize model robustness to distribution shift",
    "checked": true,
    "id": "59daaebe48d5d23e7ea682e2ddee0ae171c87a7e",
    "semantic_title": "generalization differences between end-to-end and neuro-symbolic vision-language reasoning systems",
    "citation_count": 1,
    "authors": [
      "Wang Zhu",
      "Jesse Thomason",
      "Robin Jia"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.346": {
    "title": "Learning to Model Multimodal Semantic Alignment for Story Visualization",
    "volume": "findings",
    "abstract": "Story visualization aims to generate a sequence of images to narrate each sentence in a multi-sentence story, where the images should be realistic and keep global consistency across dynamic scenes and characters. Current works face the problem of semantic misalignment because of their fixed architecture and diversity of input modalities. To address this problem, we explore the semantic alignment between text and image representations by learning to match their semantic levels in the GAN-based generative model. More specifically, we introduce dynamic interactions according to learning to dynamically explore various semantic depths and fuse the different-modal information at a matched semantic level, which thus relieves the text-image semantic misalignment problem. Extensive experiments on different datasets demonstrate the improvements of our approach, neither using segmentation masks nor auxiliary captioning networks, on image quality and story consistency, compared with state-of-the-art methods",
    "checked": true,
    "id": "6be8bc2b5fecd2fc361799980800e74fb2e38ac4",
    "semantic_title": "learning to model multimodal semantic alignment for story visualization",
    "citation_count": 0,
    "authors": [
      "Bowen Li",
      "Thomas Lukasiewicz"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.347": {
    "title": "SciFact-Open: Towards open-domain scientific claim verification",
    "volume": "findings",
    "abstract": "While research on scientific claim verification has led to the development of powerful systems that appear to approach human performance, these approaches have yet to be tested in a realistic setting against large corpora of scientific literature. Moving to this open-domain evaluation setting, however, poses unique challenges; in particular, it is infeasible to exhaustively annotate all evidence documents. In this work, we present SciFact-Open, a new test collection designed to evaluate the performance of scientific claim verification systems on a corpus of 500K research abstracts. Drawing upon pooling techniques from information retrieval, we collect evidence for scientific claims by pooling and annotating the top predictions of four state-of-the-art scientific claim verification models. We find that systems developed on smaller corpora struggle to generalize to SciFact-Open, exhibiting performance drops of at least 15 F1. In addition, analysis of the evidence in SciFact-Open reveals interesting phenomena likely to appear when claim verification systems are deployed in practice, e.g., cases where the evidence supports only a special case of the claim. Our dataset is available at https://github.com/dwadden/scifact-open",
    "checked": true,
    "id": "f13b251c8346bc3be19b71b840449831e9716999",
    "semantic_title": "scifact-open: towards open-domain scientific claim verification",
    "citation_count": 23,
    "authors": [
      "David Wadden",
      "Kyle Lo",
      "Bailey Kuehl",
      "Arman Cohan",
      "Iz Beltagy",
      "Lucy Lu Wang",
      "Hannaneh Hajishirzi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.348": {
    "title": "COMET-QE and Active Learning for Low-Resource Machine Translation",
    "volume": "findings",
    "abstract": "Active learning aims to deliver maximum benefit when resources are scarce. We use COMET-QE, a reference-free evaluation metric, to select sentences for low-resource neural machine translation. Using Swahili, Kinyarwanda and Spanish for our experiments, we show that COMET-QE significantly outperforms two variants of Round Trip Translation Likelihood (RTTL) and random sentence selection by up to 5 BLEU points for 20k sentences selected by Active Learning on a 30k baseline. This suggests that COMET-QE is a powerful tool for sentence selection in the very low-resource limit",
    "checked": true,
    "id": "40b2b5ea3fb43874fff960723000f43c2174eb7d",
    "semantic_title": "comet-qe and active learning for low-resource machine translation",
    "citation_count": 3,
    "authors": [
      "Everlyn Chimoto",
      "Bruce Bassett"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.349": {
    "title": "MedicalSum: A Guided Clinical Abstractive Summarization Model for Generating Medical Reports from Patient-Doctor Conversations",
    "volume": "findings",
    "abstract": "We introduce MedicalSum, a transformer-based sequence-to-sequence architecture for summarizing medical conversations by integrating medical domain knowledge from the Unified Medical Language System (UMLS). The novel knowledge augmentation is performed in three ways: (i) introducing a guidance signal that consists of the medical words in the input sequence, (ii) leveraging semantic type knowledge in UMLS to create clinically meaningful input embeddings, and (iii) making use of a novel weighted loss function that provides a stronger incentive for the model to correctly predict words with a medical meaning. By applying these three strategies, MedicalSum takes clinical knowledge into consideration during the summarization process and achieves state-of-the-art ROUGE score improvements of 0.8-2.1 points (including 6.2% ROUGE-1 error reduction in the PE section) when producing medical summaries of patient-doctor conversations",
    "checked": true,
    "id": "2e45b3f9d6eb5a79bc5dc532cbdaf712fb565f28",
    "semantic_title": "medicalsum: a guided clinical abstractive summarization model for generating medical reports from patient-doctor conversations",
    "citation_count": 20,
    "authors": [
      "George Michalopoulos",
      "Kyle Williams",
      "Gagandeep Singh",
      "Thomas Lin"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.350": {
    "title": "Leveraging Training Dynamics and Self-Training for Text Classification",
    "volume": "findings",
    "abstract": "The effectiveness of pre-trained language models in downstream tasks is highly dependent on the amount of labeled data available for training. Semi-supervised learning (SSL) is a promising technique that has seen wide attention recently due to its effectiveness in improving deep learning models when training data is scarce. Common approaches employ a teacher-student self-training framework, where a teacher network generates pseudo-labels for unlabeled data, which are then used to iteratively train a student network. In this paper, we propose a new self-training approach for text classification that leverages training dynamics of unlabeled data. We evaluate our approach on a wide range of text classification tasks, including emotion detection, sentiment analysis, question classification and gramaticality, which span a variety of domains, e.g, Reddit, Twitter, and online forums. Notably, our method is successful on all benchmarks, obtaining an average increase in F1 score of 3.5% over strong baselines in low resource settings",
    "checked": true,
    "id": "0126701a553205847e308703e1960b8efbfbc98b",
    "semantic_title": "leveraging training dynamics and self-training for text classification",
    "citation_count": 5,
    "authors": [
      "Tiberiu Sosea",
      "Cornelia Caragea"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.351": {
    "title": "Learning to Infer from Unlabeled Data: A Semi-supervised Learning Approach for Robust Natural Language Inference",
    "volume": "findings",
    "abstract": "Natural Language Inference (NLI) or Recognizing Textual Entailment (RTE) aims at predicting the relation between a pair of sentences (premise and hypothesis) as entailment, contradiction or semantic independence. Although deep learning models have shown promising performance for NLI in recent years, they rely on large scale expensive human-annotated datasets. Semi-supervised learning (SSL) is a popular technique for reducing the reliance on human annotation by leveraging unlabeled data for training. However, despite its substantial success on single sentence classification tasks where the challenge in making use of unlabeled data is to assign \"good enough\" pseudo-labels, for NLI tasks, the nature of unlabeled data is more complex: one of the sentences in the pair (usually the hypothesis) along with the class label are missing from the data and require human annotations, which makes SSL for NLI more challenging. In this paper, we propose a novel way to incorporate unlabeled data in SSL for NLI where we use a conditional language model, BART to generate the hypotheses for the unlabeled sentences (used as premises). Our experiments show that our SSL framework successfully exploits unlabeled data and substantially improves the performance of four NLI datasets in low-resource settings. We release our code here: https://github.com/msadat3/SSL_for_NLI",
    "checked": true,
    "id": "20b76171bf81c684a3a877b72af5f9a673c46fd6",
    "semantic_title": "learning to infer from unlabeled data: a semi-supervised learning approach for robust natural language inference",
    "citation_count": 0,
    "authors": [
      "Mobashir Sadat",
      "Cornelia Caragea"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.352": {
    "title": "Unsupervised Text Deidentification",
    "volume": "findings",
    "abstract": "Deidentification seeks to anonymize textual data prior to distribution. Automatic deidentification primarily uses supervised named entity recognition from human-labeled data points. We propose an unsupervised deidentification method that masks words that leak personally-identifying information. The approach utilizes a specially trained reidentification model to identify individuals from redacted personal documents. Motivated by K-anonymity based privacy, we generate redactions that ensure a minimum reidentification rank for the correct profile of the document. To evaluate this approach, we consider the task of deidentifying Wikipedia Biographies, and evaluate using an adversarial reidentification metric. Compared to a set of unsupervised baselines, our approach deidentifies documents more completely while removing fewer words. Qualitatively, we see that the approach eliminates many identifying aspects that would fall outside of the common named entity based approach",
    "checked": true,
    "id": "c3e846a906f2bd7cb1ac39068a4f95e7adc1818b",
    "semantic_title": "unsupervised text deidentification",
    "citation_count": 1,
    "authors": [
      "John Morris",
      "Justin Chiu",
      "Ramin Zabih",
      "Alexander Rush"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.353": {
    "title": "Federated Continual Learning for Text Classification via Selective Inter-client Transfer",
    "volume": "findings",
    "abstract": "In this work, we combine the two paradigms: Federated Learning (FL) and Continual Learning (CL) for text classification task in cloud-edge continuum. The objective of Federated Continual Learning (FCL) is to improve deep learning models over life time at each client by (relevant and efficient) knowledge transfer without sharing data. Here, we address challenges in minimizing inter-client interference while knowledge sharing due to heterogeneous tasks across clients in FCL setup. In doing so, we propose a novel framework, Federated Selective Inter-client Transfer (FedSeIT) which selectively combines model parameters of foreign clients. To further maximize knowledge transfer, we assess domain overlap and select informative tasks from the sequence of historical tasks at each foreign client while preserving privacy. Evaluating against the baselines, we show improved performance, a gain of (average) 12.4% in text classification over a sequence of tasks using five datasets from diverse domains. To the best of our knowledge, this is the first work that applies FCL to NLP",
    "checked": true,
    "id": "1d5dc2d2ef0c047c1d0ef1abc236798f2b678323",
    "semantic_title": "federated continual learning for text classification via selective inter-client transfer",
    "citation_count": 6,
    "authors": [
      "Yatin Chaudhary",
      "Pranav Rai",
      "Matthias Schubert",
      "Hinrich Schütze",
      "Pankaj Gupta"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.354": {
    "title": "DOROTHIE: Spoken Dialogue for Handling Unexpected Situations in Interactive Autonomous Driving Agents",
    "volume": "findings",
    "abstract": "In the real world, autonomous driving agents navigate in highly dynamic environments full of unexpected situations where pre-trained models are unreliable. In these situations, what is immediately available to vehicles is often only human operators. Empowering autonomous driving agents with the ability to navigate in a continuous and dynamic environment and to communicate with humans through sensorimotor-grounded dialogue becomes critical. To this end, we introduce Dialogue On the ROad To Handle Irregular Events (DOROTHIE), a novel interactive simulation platform that enables the creation of unexpected situations on the fly to support empirical studies on situated communication with autonomous driving agents. Based on this platform, we created the Situated Dialogue Navigation (SDN), a navigation benchmark of 183 trials with a total of 8415 utterances, around 18.7 hours of control streams, and 2.9 hours of trimmed audio. SDN is developed to evaluate the agent's ability to predict dialogue moves from humans as well as generate its own dialogue moves and physical navigation actions. We further developed a transformer-based baseline model for these SDN tasks. Our empirical results indicate that language guided-navigation in a highly dynamic environment is an extremely difficult task for end-to-end models. These results will provide insight towards future work on robust autonomous driving agents",
    "checked": true,
    "id": "3dbe1b13c7fb234a72861e1614a188b5a5fbbef2",
    "semantic_title": "dorothie: spoken dialogue for handling unexpected situations in interactive autonomous driving agents",
    "citation_count": 0,
    "authors": [
      "Ziqiao Ma",
      "Benjamin VanDerPloeg",
      "Cristian-Paul Bara",
      "Yidong Huang",
      "Eui-In Kim",
      "Felix Gervits",
      "Matthew Marge",
      "Joyce Chai"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.355": {
    "title": "He Said, She Said: Style Transfer for Shifting the Perspective of Dialogues",
    "volume": "findings",
    "abstract": "In this work, we define a new style transfer task: perspective shift, which reframes a dialouge from informal first person to a formal third person rephrasing of the text. This task requires challenging coreference resolution, emotion attribution, and interpretation of informal text. We explore several baseline approaches and discuss further directions on this task when applied to short dialogues. As a sample application, we demonstrate that applying perspective shifting to a dialogue summarization dataset (SAMSum) substantially improves the zero-shot performance of extractive news summarization models on this data. Additionally, supervised extractive models perform better when trained on perspective shifted data than on the original dialogues. We release our code publicly",
    "checked": true,
    "id": "9eea41c0341e15e97062dd771515378cfba29019",
    "semantic_title": "he said, she said: style transfer for shifting the perspective of dialogues",
    "citation_count": 3,
    "authors": [
      "Amanda Bertsch",
      "Graham Neubig",
      "Matthew R. Gormley"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.356": {
    "title": "Dynamic Augmentation Data Selection for Few-shot Text Classification",
    "volume": "findings",
    "abstract": "Data augmentation has been a popular method for fine-tuning pre-trained language models to increase model robustness and performance. With augmentation data coming from modifying gold train data (in-sample augmentation) or being harvested from general domain unlabeled data (out-of-sample augmentation), the quality of such data is the key to successful fine-tuning. In this paper, we propose a dynamic data selection method to select effective augmentation data from different augmentation sources according to the model's learning stage, by identifying a set of augmentation samples that optimally facilitates the learning process of the most current model. The method firstly filters out augmentation samples with noisy pseudo labels through a curriculum learning strategy, then estimates the effectiveness of reserved augmentation data by its influence scores on the current model at every update, allowing the data selection process tightly tailored to model parameters. And the two-stage augmentation strategy considers in-sample augmentation and out-of-sample augmentation in different learning stages. Experiments with both kinds of augmentation data on a variety of sentence classification tasks show that our method outperforms strong baselines, proving the effectiveness of our method. Analysis confirms the dynamic nature of the data effectiveness and the importance of model learning stages in utilization of augmentation data",
    "checked": true,
    "id": "5945469a2a1e918848defe4054eb555197072a08",
    "semantic_title": "dynamic augmentation data selection for few-shot text classification",
    "citation_count": 1,
    "authors": [
      "Guangliang Liu",
      "Lifeng Jin",
      "Owen Yuan",
      "Jiayu Zhou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.357": {
    "title": "KPDROP: Improving Absent Keyphrase Generation",
    "volume": "findings",
    "abstract": "Keyphrase generation is the task of generating phrases (keyphrases) that summarize the main topics of a given document. Keyphrases can be either present or absent from the given document. While the extraction of present keyphrases has received much attention in the past, only recently a stronger focus has been placed on the generation of absent keyphrases. However, generating absent keyphrases is challenging; even the best methods show only a modest degree of success. In this paper, we propose a model-agnostic approach called keyphrase dropout (or KPDrop) to improve absent keyphrase generation. In this approach, we randomly drop present keyphrases from the document and turn them into artificial absent keyphrases during training. We test our approach extensively and show that it consistently improves the absent performance of strong baselines in both supervised and resource-constrained semi-supervised settings",
    "checked": true,
    "id": "13ee5541d2197cab6bd76e519d19ab232bdf400d",
    "semantic_title": "kpdrop: improving absent keyphrase generation",
    "citation_count": 5,
    "authors": [
      "Jishnu Ray Chowdhury",
      "Seo Yeon Park",
      "Tuhin Kundu",
      "Cornelia Caragea"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.358": {
    "title": "Natural Language Deduction through Search over Statement Compositions",
    "volume": "findings",
    "abstract": "In settings from fact-checking to question answering, we frequently want to know whether a collection of evidence (premises) entails a hypothesis. Existing methods primarily focus on the end-to-end discriminative version of this task, but less work has treated the generative version in which a model searches over the space of statements entailed by the premises to constructively derive the hypothesis. We propose a system for doing this kind of deductive reasoning in natural language by decomposing the task into separate steps coordinated by a search procedure, producing a tree of intermediate conclusions that faithfully reflects the system's reasoning process. Our experiments on the EntailmentBank dataset (Dalvi et al., 2021) demonstrate that the proposed system can successfully prove true statements while rejecting false ones. Moreover, it produces natural language explanations with a 17% absolute higher step validity than those produced by an end-to-end T5 model",
    "checked": true,
    "id": "e5aa2a1e36a2c68fa4aa59afdb8b6e1c419f547c",
    "semantic_title": "natural language deduction through search over statement compositions",
    "citation_count": 37,
    "authors": [
      "Kaj Bostrom",
      "Zayne Sprague",
      "Swarat Chaudhuri",
      "Greg Durrett"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.359": {
    "title": "EnDex: Evaluation of Dialogue Engagingness at Scale",
    "volume": "findings",
    "abstract": "We propose EnDex, the first human-reaction based model to evaluate dialogue engagingness. EnDex is trained on 80k Reddit-based Engagement Dataset (RED) curated using a novel distant-supervision framework. Engagingness is a key measure that captures high-level quality of AI dialogue systems and closely reflects actual user experience. However, data shortage, plus the abstract and extensive definition of engagingness makes it challenging to develop an automatic metric. Our work departs from mainstream approaches that use synthetic negative examples to train binary classifiers, and instead, proposes a solution using distant-supervision from human-reaction feedback. To support the soundness of our EnDex metric, we offer a theoretical foundation for engagement, an extensive ablation study, and empirical evidence of high correlation on five engagingness related datasets. We will release code, off-the-shelf EnDex model, and a large-scale dataset upon paper publication to facilitate future research",
    "checked": true,
    "id": "0a722a62375b5542e838d04fbefd27e1917328bd",
    "semantic_title": "endex: evaluation of dialogue engagingness at scale",
    "citation_count": 3,
    "authors": [
      "Guangxuan Xu",
      "Ruibo Liu",
      "Fabrice Harel-Canada",
      "Nischal Reddy Chandra",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.360": {
    "title": "LOPS: Learning Order Inspired Pseudo-Label Selection for Weakly Supervised Text Classification",
    "volume": "findings",
    "abstract": "Weakly supervised text classification methods typically train a deep neural classifier based on pseudo-labels. The quality of pseudo-labels is crucial to final performance but they are inevitably noisy due to their heuristic nature, so selecting the correct ones has a huge potential for performance boost. One straightforward solution is to select samples based on the softmax probability scores in the neural classifier corresponding to their pseudo-labels. However, we show through our experiments that such solutions are ineffective and unstable due to the erroneously high-confidence predictions from poorly calibrated models. Recent studies on the memorization effects of deep neural models suggest that these models first memorize training samples with clean labels and then those with noisy labels. Inspired by this observation, we propose a novel pseudo-label selection method LOPS that takes learning order of samples into consideration. We hypothesize that the learning order reflects the probability of wrong annotation in terms of ranking, and therefore, propose to select the samples that are learnt earlier. LOPS can be viewed as a strong performance-boost plug-in to most existing weakly-supervised text classification methods, as confirmed in extensive experiments on four real-world datasets",
    "checked": true,
    "id": "a1ccfb5bf4a5666b0f5dd4c1d81d2aa176d74202",
    "semantic_title": "lops: learning order inspired pseudo-label selection for weakly supervised text classification",
    "citation_count": 11,
    "authors": [
      "Dheeraj Mekala",
      "Chengyu Dong",
      "Jingbo Shang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.361": {
    "title": "Train Flat, Then Compress: Sharpness-Aware Minimization Learns More Compressible Models",
    "volume": "findings",
    "abstract": "Model compression by way of parameter pruning, quantization, or distillation has recently gained popularity as an approach for reducing the computational requirements of modern deep neural network models for NLP. Inspired by prior works suggesting a connection between simpler, more generalizable models and those that lie within wider loss basins, we hypothesize that optimizing for flat minima should lead to simpler parameterizations and thus more compressible models. We propose to combine sharpness-aware minimization (SAM) with various task-specific model compression methods, including iterative magnitude pruning (IMP), structured pruning with a distillation objective, and post-training dynamic quantization. Empirically, we show that optimizing for flatter minima consistently leads to greater compressibility of parameters compared to vanilla Adam when fine-tuning BERT models, with little to no loss in accuracy on the GLUE text classification and SQuAD question answering benchmarks. Moreover, SAM finds superior winning tickets during IMP that 1) are amenable to vanilla Adam optimization, and 2) transfer more effectively across tasks",
    "checked": true,
    "id": "e1f8fec943544d4079ae6556d9c07a88b203da4a",
    "semantic_title": "train flat, then compress: sharpness-aware minimization learns more compressible models",
    "citation_count": 16,
    "authors": [
      "Clara Na",
      "Sanket Vaibhav Mehta",
      "Emma Strubell"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.362": {
    "title": "Structural Contrastive Representation Learning for Zero-shot Multi-label Text Classification",
    "volume": "findings",
    "abstract": "Zero-shot multi-label text classification (ZMTC) is a fundamental task in natural language processing with applications in the cold start problem of recommendation systems. Ideally, one would learn an expressive representation of both input text and label features so that ZMTC is transformed into a nearest neighbor search problem. However, the existing representation learning approaches for ZMTC struggle with accuracy as well as poor training efficiency. Firstly, the input text is structural, consisting of both short title sentences and long content paragraphs. It is challenging to model the correlation between short label descriptions and long structural input documents. Secondly, the enormous label space in ZMTC forces the existing approaches to perform multi-stage learning with label engineering. As a result, the training overhead is significant. In this paper, we address both problems by introducing an end-to-end structural contrastive representation learning approach. We propose a randomized text segmentation (RTS) technique to generate high-quality contrastive pairs. This RTS technique allows us to model title-content correlation. Additionally, we simplify the multi-stage ZMTC learning strategy by avoiding label engineering. Extensive experiments demonstrate that our approach leads to up to 2.33% improvement in precision@1 and 5.94x speedup in training time on publicly available datasets. Our code is available publicly",
    "checked": true,
    "id": "38ae2bbd6cdb68632445e747d664d16a83839425",
    "semantic_title": "structural contrastive representation learning for zero-shot multi-label text classification",
    "citation_count": 1,
    "authors": [
      "Tianyi Zhang",
      "Zhaozhuo Xu",
      "Tharun Medini",
      "Anshumali Shrivastava"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.363": {
    "title": "Improving Generalization of Pre-trained Language Models via Stochastic Weight Averaging",
    "volume": "findings",
    "abstract": "Knowledge Distillation (KD) is a commonly used technique for improving the generalization of compact Pre-trained Language Models (PLMs) on downstream tasks. However, such methods impose the additional burden of training a separate teacher model for every new dataset. Alternatively, one may directly work on the improvement of the optimization procedure of the compact model towards better generalization. Recent works observe that the flatness of the local minimum correlates well with better generalization. In this work, we adapt Stochastic Weight Averaging (SWA), a method encouraging convergence to a flatter minimum, to fine-tuning PLMs. We conduct extensive experiments on various NLP tasks (text classification, question answering, and generation) and different model architectures and demonstrate that our adaptation improves the generalization without extra computation cost. Moreover, we observe that this simple optimization technique is able to outperform the state-of-the-art KD methods for compact models",
    "checked": true,
    "id": "8255b71fae79c92d1b3d72caa1e563c80dc36a0b",
    "semantic_title": "improving generalization of pre-trained language models via stochastic weight averaging",
    "citation_count": 6,
    "authors": [
      "Peng Lu",
      "Ivan Kobyzev",
      "Mehdi Rezagholizadeh",
      "Ahmad Rashid",
      "Ali Ghodsi",
      "Phillippe Langlais"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.364": {
    "title": "Learn What Is Possible, Then Choose What Is Best: Disentangling One-To-Many Relations in Language Through Text-based Games",
    "volume": "findings",
    "abstract": "Language models pre-trained on large self-supervised corpora, followed by task-specific fine-tuning has become the dominant paradigm in NLP. These pre-training datasets often have a one-to-many structure—e.g. in dialogue there are many valid responses for a given context. However, only some of these responses will be desirable in our downstream task. This raises the question of how we should train the model such that it can emulate the desirable behaviours, but not the undesirable ones. Current approaches train in a one-to-one setup—only a single target response is given for a single dialogue context—leading to models only learning to predict the average response, while ignoring the full range of possible responses. Using text-based games as a testbed, our approach, PASA, uses discrete latent variables to capture the range of different behaviours represented in our larger pre-training dataset. We then use knowledge distillation to distil the posterior probability distribution into a student model. This probability distribution is far richer than learning from only the hard targets of the dataset, and thus allows the student model to benefit from the richer range of actions the teacher model has learned. Results show up to 49% empirical improvement over the previous state-of-the-art model on the Jericho Walkthroughs dataset",
    "checked": true,
    "id": "ffd53613590f434a08fbdbdf9c13ef067256f82e",
    "semantic_title": "learn what is possible, then choose what is best: disentangling one-to-many relations in language through text-based games",
    "citation_count": 2,
    "authors": [
      "Benjamin Towle",
      "Ke Zhou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.365": {
    "title": "Structurally Diverse Sampling for Sample-Efficient Training and Comprehensive Evaluation",
    "volume": "findings",
    "abstract": "A growing body of research has demonstrated the inability of NLP models to generalize compositionally and has tried to alleviate it through specialized architectures, training schemes, and data augmentation, among other approaches. In this work, we study a different approach: training on instances with diverse structures. We propose a model-agnostic algorithm for subsampling such sets of instances from a labeled instance pool with structured outputs. Evaluating on both compositional template splits and traditional IID splits of 5 semantic parsing datasets of varying complexity, we show that structurally diverse training using our algorithm leads to comparable or better generalization than prior algorithms in 9 out of 10 dataset-split type pairs. In general, we find structural diversity to consistently improve sample efficiency compared to random train sets. Moreover, we show that structurally diverse sampling yields comprehensive test sets that are a lot more challenging than IID test sets. Finally, we provide two explanations for improved generalization from diverse train sets: 1) improved coverage of output substructures, and 2) a reduction in spurious correlations between these substructures",
    "checked": true,
    "id": "6913d3f23d13416407b7fcd03bea3231b268a20a",
    "semantic_title": "structurally diverse sampling for sample-efficient training and comprehensive evaluation",
    "citation_count": 6,
    "authors": [
      "Shivanshu Gupta",
      "Sameer Singh",
      "Matt Gardner"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.366": {
    "title": "Unsupervised Multi-Granularity Summarization",
    "volume": "findings",
    "abstract": "Text summarization is a user-preference based task, i.e., for one document, users often have different priorities for the summary. As a key aspect of customization in summarization, granularity is used to measure the semantic coverage between the summary and source document. However, developing systems that can generate summaries with customizable semantic coverage is still an under-explored topic. In this paper, we propose the first unsupervised multi-granularity summarization framework, GranuSum. We take events as the basic semantic units of the source documents and propose to rank these events by their salience. We also develop a model to summarize input documents with given events as anchors and hints. By inputting different numbers of events, GranuSum is capable of producing multi-granular summaries in an unsupervised manner. Meanwhile, we annotate a new benchmark GranuDUC that contains multiple summaries at different granularities for each document cluster. Experimental results confirm the substantial superiority of GranuSum on multi-granularity summarization over strong baselines. Furthermore, by exploiting the event information, GranuSum also exhibits state-of-the-art performance under the conventional unsupervised abstractive setting",
    "checked": true,
    "id": "7d787b9c0fb93091c31720dc35eef29b63478c06",
    "semantic_title": "unsupervised multi-granularity summarization",
    "citation_count": 6,
    "authors": [
      "Ming Zhong",
      "Yang Liu",
      "Suyu Ge",
      "Yuning Mao",
      "Yizhu Jiao",
      "Xingxing Zhang",
      "Yichong Xu",
      "Chenguang Zhu",
      "Michael Zeng",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.367": {
    "title": "HeLo: Learning-Free Lookahead Decoding for Conversation Infilling",
    "volume": "findings",
    "abstract": "We propose Heuristic Guided Lookahead Decoding (HeLo), a novel decoding strategy for conversation infilling. Conversation infilling aims to generate a seamless bridge of utterances connecting a given pair of source and target utterances. HeLo does not require fine-tuning or extra models – only the generating model itself. Instead, HeLo leverages a greedy lookahead phase before committing to any token. The HeLo framework is simple and can augment conventional decoding strategies paired with any autoregressive language model. Smooth transitions between utterances are encouraged with an annealing schedule. Our experiments show HeLo outperforms several baselines when evaluated with both automatic and human evaluation metrics, which, we argue, are appropriate for the task",
    "checked": true,
    "id": "4118fbc990fb535c96bdb2ca80e93a35f2d815c0",
    "semantic_title": "helo: learning-free lookahead decoding for conversation infilling",
    "citation_count": 1,
    "authors": [
      "Ivan Lee",
      "Taylor Berg-Kirkpatrick"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.368": {
    "title": "Invernet: An Inversion Attack Framework to Infer Fine-Tuning Datasets through Word Embeddings",
    "volume": "findings",
    "abstract": "Word embedding aims to learn the dense representation of words and has become a regular input preparation in many NLP tasks. Due to the data and computation intensive nature of learning embeddings from scratch, a more affordable way is to borrow the pretrained embedding available in public and fine-tune the embedding through a domain specific downstream dataset. A privacy concern can arise if a malicious owner of the pretrained embedding gets access to the fine-tuned embedding and tries to infer the critical information from the downstream datasets. In this study, we propose a novel embedding inversion framework called Invernet that materializes the privacy concern by inferring the context distribution in the downstream dataset, which can lead to key information breach. With extensive experimental studies on two real-world news datasets: Antonio Gulli's News and New York Times, we validate the feasibility of proposed privacy attack and demonstrate the effectiveness of Invernet on inferring downstream datasets based on multiple word embedding methods",
    "checked": true,
    "id": "9e39e0d195bd7de7ed9c5f0f5e0911d7bac12889",
    "semantic_title": "invernet: an inversion attack framework to infer fine-tuning datasets through word embeddings",
    "citation_count": 2,
    "authors": [
      "Ishrak Hayet",
      "Zijun Yao",
      "Bo Luo"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.369": {
    "title": "LawngNLI: A Long-Premise Benchmark for In-Domain Generalization from Short to Long Contexts and for Implication-Based Retrieval",
    "volume": "findings",
    "abstract": "Natural language inference has trended toward studying contexts beyond the sentence level. An important application area is law: past cases often do not foretell how they apply to new situations and implications must be inferred. This paper introduces LawngNLI, constructed from U.S. legal opinions with automatic labels with high human-validated accuracy. Premises are long and multigranular. Experiments show two use cases. First, LawngNLI can benchmark for in-domain generalization from short to long contexts. It has remained unclear if large-scale long-premise NLI datasets actually need to be constructed: near-top performance on long premises could be achievable by fine-tuning using short premises. Without multigranularity, benchmarks cannot distinguish lack of fine-tuning on long premises versus domain shift between short and long datasets. In contrast, our long and short premises share the same examples and domain. Models fine-tuned using several past NLI datasets and/or our short premises fall short of top performance on our long premises. So for at least certain domains (such as ours), large-scale long-premise datasets are needed. Second, LawngNLI can benchmark for implication-based retrieval. Queries are entailed or contradicted by target documents, allowing users to move between arguments and evidence. Leading retrieval models perform reasonably zero shot on a LawngNLI-derived retrieval task. We compare different systems for re-ranking, including lexical overlap and cross-encoders fine-tuned using a modified LawngNLI or past NLI datasets. LawngNLI can train and test systems for implication-based case retrieval and argumentation",
    "checked": true,
    "id": "09b9b5463d562548ce8d5a3a5ff5dc3685ad3156",
    "semantic_title": "lawngnli: a long-premise benchmark for in-domain generalization from short to long contexts and for implication-based retrieval",
    "citation_count": 2,
    "authors": [
      "William Bruno",
      "Dan Roth"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.370": {
    "title": "Distillation-Resistant Watermarking for Model Protection in NLP",
    "volume": "findings",
    "abstract": "How can we protect the intellectual property of trained NLP models? Modern NLP models are prone to stealing by querying and distilling from their publicly exposed APIs. However, existing protection methods such as watermarking only work for images but are not applicable to text. We propose Distillation-Resistant Watermarking (DRW), a novel technique to protect NLP models from being stolen via distillation. DRW protects a model by injecting watermarks into the victim's prediction probability corresponding to a secret key and is able to detect such a key by probing a suspect model. We prove that a protected model still retains the original accuracy within a certain bound. We evaluate DRW on a diverse set of NLP tasks including text classification, part-of-speech tagging, and named entity recognition. Experiments show that DRW protects the original model and detects stealing suspects at 100% mean average precision for all four tasks while the prior method fails on two",
    "checked": true,
    "id": "c7bdd6c7b786fba60ff8a6e656cc14c3f7b57b78",
    "semantic_title": "distillation-resistant watermarking for model protection in nlp",
    "citation_count": 10,
    "authors": [
      "Xuandong Zhao",
      "Lei Li",
      "Yu-Xiang Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.371": {
    "title": "NeuroCounterfactuals: Beyond Minimal-Edit Counterfactuals for Richer Data Augmentation",
    "volume": "findings",
    "abstract": "While counterfactual data augmentation offers a promising step towards robust generalization in natural language processing, producing a set of counterfactuals that offer valuable inductive bias for models remains a challenge. Most existing approaches for producing counterfactuals, manual or automated, rely on small perturbations via minimal edits, resulting in simplistic changes. We introduce NeuroCounterfactuals, designed as loose counterfactuals, allowing for larger edits which result in naturalistic generations containing linguistic diversity, while still bearing similarity to the original document. Our novel generative approach bridges the benefits of constrained decoding, with those of language model adaptation for sentiment steering. Training data augmentation with our generations results in both in-domain and out-of-domain improvements for sentiment classification, outperforming even manually curated counterfactuals, under select settings. We further present detailed analyses to show the advantages of NeuroCounterfactuals over approaches involving simple, minimal edits",
    "checked": true,
    "id": "39880b887c19ae80d71643b37d6fc89aba8ec0c4",
    "semantic_title": "neurocounterfactuals: beyond minimal-edit counterfactuals for richer data augmentation",
    "citation_count": 17,
    "authors": [
      "Phillip Howard",
      "Gadi Singer",
      "Vasudev Lal",
      "Yejin Choi",
      "Swabha Swayamdipta"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.372": {
    "title": "Don't Just Clean It, Proxy Clean It: Mitigating Bias by Proxy in Pre-Trained Models",
    "volume": "findings",
    "abstract": "Transformer-based pre-trained models are known to encode societal biases not only in their contextual representations, but also in downstream predictions when fine-tuned on task-specific data. We present D-Bias, an approach that selectively eliminates stereotypical associations (e.g, co-occurrence statistics) at fine-tuning, such that the model doesn't learn to excessively rely on those signals.D-Bias attenuates biases from both identity words and frequently co-occurring proxies, which we select using pointwise mutual information. We apply D-Bias to a) occupation classification, and b) toxicity classification and find that our approach substantially reduces downstream biases (e.g. by > 60% in toxicity classification, for identities that are most frequently flagged as toxic on online platforms).In addition, we show that D-Bias dramatically improves upon scrubbing, i.e., removing only the identity words in question. We also demonstrate that D-Bias easily extends to multiple identities, and achieves competitive performance with two recently proposed debiasing approaches: R-LACE and INLP",
    "checked": true,
    "id": "12a4c9ed5ac0e602b25e315078346f3d025cf10e",
    "semantic_title": "don't just clean it, proxy clean it: mitigating bias by proxy in pre-trained models",
    "citation_count": 3,
    "authors": [
      "Swetasudha Panda",
      "Ari Kobren",
      "Michael Wick",
      "Qinlan Shen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.373": {
    "title": "The Undesirable Dependence on Frequency of Gender Bias Metrics Based on Word Embeddings",
    "volume": "findings",
    "abstract": "Numerous works use word embedding-based metrics to quantify societal biases and stereotypes in texts. Recent studies have found that word embeddings can capture semantic similarity but may be affected by word frequency. In this work we study the effect of frequency when measuring female vs. male gender bias with word embedding-based bias quantification methods. We find that Skip-gram with negative sampling and GloVe tend to detect male bias in high frequency words, while GloVe tends to return female bias in low frequency words. We show these behaviors still exist when words are randomly shuffled. This proves that the frequency-based effect observed in unshuffled corpora stems from properties of the metric rather than from word associations. The effect is spurious and problematic since bias metrics should depend exclusively on word co-occurrences and not individual word frequencies. Finally, we compare these results with the ones obtained with an alternative metric based on Pointwise Mutual Information. We find that this metric does not show a clear dependence on frequency, even though it is slightly skewed towards male bias across all frequencies",
    "checked": true,
    "id": "ccf340560dfda477764c74dfa21de510bbdddf07",
    "semantic_title": "the undesirable dependence on frequency of gender bias metrics based on word embeddings",
    "citation_count": 7,
    "authors": [
      "Francisco Valentini",
      "Germán Rosati",
      "Diego Fernandez Slezak",
      "Edgar Altszyler"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.374": {
    "title": "BioNLI: Generating a Biomedical NLI Dataset Using Lexico-semantic Constraints for Adversarial Examples",
    "volume": "findings",
    "abstract": "Natural language inference (NLI) is critical in many domains requiring complex decision-making, such as the biomedical domain. We introduce a novel semi-supervised procedure that bootstraps biomedical NLI datasets from positive entailment examples present in abstracts of biomedical publications. We focus on challenging texts where the hypothesis includes mechanistic information such as biochemical interactions between two entities. A key contribution of this work is automating the creation of negative examples that are informative without being simplistic. We generate a range of negative examples using nine strategies that manipulate the structure of the underlying mechanisms both with rules, e.g., flip the roles of the entities in the interaction, and, more importantly, by imposing the perturbed conditions as logical constraints in a neuro-logical decoding system (CITATION).We use this procedure to create a novel dataset for NLI in the biomedical domain, called . The accuracy of neural classifiers on this dataset is in the mid 70s F1, which indicates that this NLI task remains to be solved. Critically, we observe that the performance on the different classes of negative examples varies widely, from 97% F1 on the simple negative examples that change the role of the entities in the hypothesis, to barely better than chance on the negative examples generated using neuro-logic decoding",
    "checked": true,
    "id": "acd076a09b49e16d71b60ee919b47945d20ac1da",
    "semantic_title": "bionli: generating a biomedical nli dataset using lexico-semantic constraints for adversarial examples",
    "citation_count": 4,
    "authors": [
      "Mohaddeseh Bastan",
      "Mihai Surdeanu",
      "Niranjan Balasubramanian"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.375": {
    "title": "Self-supervised Cross-modal Pretraining for Speech Emotion Recognition and Sentiment Analysis",
    "volume": "findings",
    "abstract": "Multimodal speech emotion recognition (SER) and sentiment analysis (SA) are important techniques for human-computer interaction. Most existing multimodal approaches utilize either shallow cross-modal fusion of pretrained features, or deep cross-modal fusion with raw features. Recently, attempts have been made to fuse pretrained feature representations in a deep fusion manner during fine-tuning stage. However those approaches have not led to improved results, partially due to their relatively simple fusion mechanisms and lack of proper cross-modal pretraining. In this work, leveraging single-modal pretrained models (RoBERTa and HuBERT), we propose a novel deeply-fused audio-text bi-modal transformer with carefully designed cross-modal fusion mechanism and a stage-wise cross-modal pretraining scheme to fully facilitate the cross-modal learning. Our experiment results show that the proposed method achieves state-of-the-art results on the public IEMOCAP emotion and CMU-MOSEI sentiment datasets, exceeding the previous benchmarks by a large margin",
    "checked": true,
    "id": "7ae23b535f7f4ed7f5bdaea4b7827a5a7993eb31",
    "semantic_title": "self-supervised cross-modal pretraining for speech emotion recognition and sentiment analysis",
    "citation_count": 2,
    "authors": [
      "Iek-Heng Chu",
      "Ziyi Chen",
      "Xinlu Yu",
      "Mei Han",
      "Jing Xiao",
      "Peng Chang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.376": {
    "title": "Multimodal Conversation Modelling for Topic Derailment Detection",
    "volume": "findings",
    "abstract": "Conversations on social media tend to go off-topic and turn into different and sometimes toxic exchanges. Previous work focuses on analysing textual dialogues that have derailed into toxic content, but the range of derailment types is much broader, including spam or bot content, tangential comments, etc. In addition, existing work disregards conversations that involve visual information (i.e. images or videos), which are prevalent on most platforms. In this paper, we take a broader view of conversation derailment and propose a new challenge: detecting derailment based on the \"change of conversation topic\", where the topic is defined by an initial post containing both a text and an image. For that, we (i) create the first Multimodal Conversation Derailment (MCD) dataset, and (ii) introduce a new multimodal conversational architecture (MMConv) that utilises visual and conversational contexts to classify comments for derailment. Experiments show that MMConv substantially outperforms previous text-based approaches to detect conversation derailment, as well as general multimodal classifiers. MMConv is also more robust to textual noise, since it relies on richer contextual information",
    "checked": true,
    "id": "18bf0ad338709a0fe7e689a71102f32e6e510612",
    "semantic_title": "multimodal conversation modelling for topic derailment detection",
    "citation_count": 0,
    "authors": [
      "Zhenhao Li",
      "Marek Rei",
      "Lucia Specia"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.377": {
    "title": "Active Learning for Abstractive Text Summarization",
    "volume": "findings",
    "abstract": "Construction of human-curated annotated datasets for abstractive text summarization (ATS) is very time-consuming and expensive because creating each instance requires a human annotator to read a long document and compose a shorter summary that would preserve the key information relayed by the original document. Active Learning (AL) is a technique developed to reduce the amount of annotation required to achieve a certain level of machine learning model performance. In information extraction and text classification, AL can reduce the amount of labor up to multiple times. Despite its potential for aiding expensive annotation, as far as we know, there were no effective AL query strategies for ATS. This stems from the fact that many AL strategies rely on uncertainty estimation, while as we show in our work, uncertain instances are usually noisy, and selecting them can degrade the model performance compared to passive annotation. We address this problem by proposing the first effective query strategy for AL in ATS based on diversity principles. We show that given a certain annotation budget, using our strategy in AL annotation helps to improve the model performance in terms of ROUGE and consistency scores. Additionally, we analyze the effect of self-learning and show that it can additionally increase the performance of the model",
    "checked": true,
    "id": "5cc03744805af1168748f02e229e46fabd9eea12",
    "semantic_title": "active learning for abstractive text summarization",
    "citation_count": 5,
    "authors": [
      "Akim Tsvigun",
      "Ivan Lysenko",
      "Danila Sedashov",
      "Ivan Lazichny",
      "Eldar Damirov",
      "Vladimir Karlov",
      "Artemy Belousov",
      "Leonid Sanochkin",
      "Maxim Panov",
      "Alexander Panchenko",
      "Mikhail Burtsev",
      "Artem Shelmanov"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.378": {
    "title": "Finding Memo: Extractive Memorization in Constrained Sequence Generation Tasks",
    "volume": "findings",
    "abstract": "Memorization presents a challenge for several constrained Natural Language Generation (NLG) tasks such as Neural Machine Translation (NMT), wherein the proclivity of neural models to memorize noisy and atypical samples reacts adversely with the noisy (web crawled) datasets. However, previous studies of memorization in constrained NLG tasks have only focused on counterfactual memorization, linking it to the problem of hallucinations. In this work, we propose a new, inexpensive algorithm for extractive memorization (exact training data generation under insufficient context) in constrained sequence generation tasks and use it to study extractive memorization and its effects in NMT. We demonstrate that extractive memorization poses a serious threat to NMT reliability by qualitatively and quantitatively characterizing the memorized samples as well as the model behavior in their vicinity. Based on empirical observations, we develop a simple algorithm which elicits non-memorized translations of memorized samples from the same model, for a large fraction of such samples. Finally, we show that the proposed algorithm could also be leveraged to mitigate memorization in the model through finetuning. We have released the code to reproduce our results at https://github.com/vyraun/Finding-Memo",
    "checked": true,
    "id": "6ab78343ab82fa9d7baa68027f9f7e8cd9863737",
    "semantic_title": "finding memo: extractive memorization in constrained sequence generation tasks",
    "citation_count": 10,
    "authors": [
      "Vikas Raunak",
      "Arul Menezes"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.379": {
    "title": "SALTED: A Framework for SAlient Long-tail Translation Error Detection",
    "volume": "findings",
    "abstract": "Traditional machine translation (MT) metrics provide an average measure of translation quality that is insensitive to the long tail of behavioral problems. Examples include translation of numbers, physical units, dropped content and hallucinations. These errors, which occur rarely and unpredictably in Neural Machine Translation (NMT), greatly undermine the reliability of state-of-the-art MT systems. Consequently, it is important to have visibility into these problems during model development. Towards this end, we introduce SALTED, a specifications-based framework for behavioral testing of NMT models. At the core of our approach is the use of high-precision detectors that flag errors (or alternatively, verify output correctness) between a source sentence and a system output. These detectors provide fine-grained measurements of long-tail errors, providing a trustworthy view of problems that were previously invisible. We demonstrate that such detectors could be used not just to identify salient long-tail errors in MT systems, but also for higher-recall filtering of the training data, fixing targeted errors with model fine-tuning in NMT and generating novel data for metamorphic testing to elicit further bugs in models",
    "checked": true,
    "id": "a349bcb86ba80ef543e5deaadbb7e0ff5daef5e7",
    "semantic_title": "salted: a framework for salient long-tail translation error detection",
    "citation_count": 19,
    "authors": [
      "Vikas Raunak",
      "Matt Post",
      "Arul Menezes"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.380": {
    "title": "Discord Questions: A Computational Approach To Diversity Analysis in News Coverage",
    "volume": "findings",
    "abstract": "There are many potential benefits to news readers accessing diverse sources. Modern news aggregators do the hard work of organizing the news, offering readers a plethora of source options, but choosing which source to read remains challenging. We propose a new framework to assist readers in identifying source differences and gaining an understanding of news coverage diversity. The framework is based on the generation of Discord Questions: questions with a diverse answer pool, explicitly illustrating source differences. To assemble a prototype of the framework, we focus on two components: (1) discord question generation, the task of generating questions answered differently by sources, for which we propose an automatic scoring method, and create a model that improves performance from current question generation (QG) methods by 5%, (2) answer consolidation, the task of grouping answers to a question that are semantically similar, for which we collect data and repurpose a method that achieves 81% balanced accuracy on our realistic test set. We illustrate the framework's feasibility through a prototype interface. Even though model performance at discord QG still lags human performance by more than 15%, generated questions are judged to be more interesting than factoid questions and can reveal differences in the level of detail, sentiment, and reasoning of sources in news coverage. Code is available at https://github.com/Salesforce/discord_questions",
    "checked": true,
    "id": "ef194ab52031cde7c6119c7701499c1fd9bc9d65",
    "semantic_title": "discord questions: a computational approach to diversity analysis in news coverage",
    "citation_count": 4,
    "authors": [
      "Philippe Laban",
      "Chien-Sheng Wu",
      "Lidiya Murakhovs’ka",
      "Xiang Chen",
      "Caiming Xiong"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.381": {
    "title": "FocusQA: Open-Domain Question Answering with a Context in Focus",
    "volume": "findings",
    "abstract": "We introduce question answering with a cotext in focus, a task that simulates a free interaction with a QA system. The user reads on a screen some information about a topic, and they can follow-up with questions that can be either related or not to the topic; and the answer can be found in the document containing the screen content or from other pages. We call such information context. To study the task, we construct FocusQA, a dataset for answer sentence selection (AS2) with 12,165011unique question/context pairs, and a total of 109,940 answers. To build the dataset, we developed a novel methodology that takes existing questions and pairs them with relevant contexts. To show the benefits of this approach, we present a comparative analysis with a set of questions written by humans after reading the context, showing that our approach greatly helps in eliciting more realistic question/context pairs. Finally, we show that the task poses several challenges for incorporating contextual information. In this respect, we introduce strong baselines for answer sentence selection that outperform the precision of state-of-the-art models for AS2 up to 21.3% absolute points",
    "checked": true,
    "id": "4fd4afac9926e959a9bd89a46118e55994c37049",
    "semantic_title": "focusqa: open-domain question answering with a context in focus",
    "citation_count": 2,
    "authors": [
      "Gianni Barlacchi",
      "Ivano Lauriola",
      "Alessandro Moschitti",
      "Marco Del Tredici",
      "Xiaoyu Shen",
      "Thuy Vu",
      "Bill Byrne",
      "Adrià de Gispert"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.382": {
    "title": "Challenges and Opportunities in Information Manipulation Detection: An Examination of Wartime Russian Media",
    "volume": "findings",
    "abstract": "NLP research on public opinion manipulation campaigns has primarily focused on detecting overt strategies such as fake news and disinformation. However, information manipulation in the ongoing Russia-Ukraine war exemplifies how governments and media also employ more nuanced strategies. We release a new dataset, VoynaSlov, containing 38M+ posts from Russian media outlets on Twitter and VKontakte, as well as public activity and responses, immediately preceding and during the 2022 Russia-Ukraine war. We apply standard and recently-developed NLP models on VoynaSlov to examine agenda setting, framing, and priming, several strategies underlying information manipulation, and reveal variation across media outlet control, social media platform, and time. Our examination of these media effects and extensive discussion of current approaches' limitations encourage further development of NLP models for understanding information manipulation in emerging crises, as well as other real-world and interdisciplinary tasks",
    "checked": true,
    "id": "b616154578751e156b21561e1a5d5ed833a3506f",
    "semantic_title": "challenges and opportunities in information manipulation detection: an examination of wartime russian media",
    "citation_count": 12,
    "authors": [
      "Chan Young Park",
      "Julia Mendelsohn",
      "Anjalie Field",
      "Yulia Tsvetkov"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.383": {
    "title": "Disentangling Task Relations for Few-shot Text Classification via Self-Supervised Hierarchical Task Clustering",
    "volume": "findings",
    "abstract": "Few-Shot Text Classification (FSTC) imitates humans to learn a new text classifier efficiently with only few examples, by leveraging prior knowledge from historical tasks. However, most prior works assume that all the tasks are sampled from a single data source, which cannot adapt to real-world scenarios where tasks are heterogeneous and lie in different distributions. As such, existing methods may suffer from their globally knowledge-shared mechanisms to handle the task heterogeneity. On the other hand, inherent task relationships are not explicitly captured, making task knowledge unorganized and hard to transfer to new tasks. Thus, we explore a new FSTC setting where tasks can come from a diverse range of data sources. To address the task heterogeneity, we propose a self-supervised hierarchical task clustering (SS-HTC) method. SS-HTC not only customizes the cluster-specific knowledge by dynamically organizing heterogeneous tasks into different clusters in hierarchical levels but also disentangles the underlying relations between tasks to improve the interpretability. Empirically, extensive experiments on five public FSTC benchmark datasets demonstrate the effectiveness of SS-HTC",
    "checked": true,
    "id": "26527955d4603f4af05610453228ebfc2404b269",
    "semantic_title": "disentangling task relations for few-shot text classification via self-supervised hierarchical task clustering",
    "citation_count": 3,
    "authors": [
      "Juan Zha",
      "Zheng Li",
      "Ying Wei",
      "Yu Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.384": {
    "title": "XRICL: Cross-lingual Retrieval-Augmented In-Context Learning for Cross-lingual Text-to-SQL Semantic Parsing",
    "volume": "findings",
    "abstract": "In-context learning using large language models has recently shown surprising results for semantic parsing tasks such as Text-to-SQL translation. Prompting GPT-3 or Codex using several examples of question-SQL pairs can produce excellent results, comparable to state-of-the-art finetuning-based models. However, existing work primarily focuses on English datasets, and it is unknown whether large language models can serve as competitive semantic parsers for other languages. To bridge this gap, our work focuses on cross-lingual Text-to-SQL semantic parsing for translating non-English utterances into SQL queries based on an English schema. We consider a zero-shot transfer learning setting with the assumption that we do not have any labeled examples in the target language (but have annotated examples in English).This work introduces the XRICL framework, which learns to retrieve relevant English exemplars for a given query to construct prompts. We also include global translation exemplars for a target language to facilitate the translation process for large language models. To systematically evaluate our model, we construct two new benchmark datasets, XSpider and XKaggle-dbqa, which include questions in Chinese, Vietnamese, Farsi, and Hindi.Our experiments show that XRICL effectively leverages large pre-trained language models to outperform existing baselines. Data and code are publicly available at https://github.com/Impavidity/XRICL",
    "checked": true,
    "id": "38e1a9c5599fc7597b7c5ffd37951ba5f528094c",
    "semantic_title": "xricl: cross-lingual retrieval-augmented in-context learning for cross-lingual text-to-sql semantic parsing",
    "citation_count": 18,
    "authors": [
      "Peng Shi",
      "Rui Zhang",
      "He Bai",
      "Jimmy Lin"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.385": {
    "title": "Continuation KD: Improved Knowledge Distillation through the Lens of Continuation Optimization",
    "volume": "findings",
    "abstract": "Knowledge Distillation (KD) has been extensively used for natural language understanding (NLU) tasks to improve a small model's (a student) generalization by transferring the knowledge from a larger model (a teacher). Although KD methods achieve state-of-the-art performance in numerous settings, they suffer from several problems limiting their performance. It is shown in the literature that the capacity gap between the teacher and the student networks can make KD ineffective. Additionally, existing KD techniques do not mitigate the noise in the teacher's output: modeling the noisy behaviour of the teacher can distract the student from learning more useful features. We propose a new KD method that addresses these problems and facilitates the training compared to previous techniques. Inspired by continuation optimization, we design a training procedure that optimizes the highly non-convex KD objective by starting with the smoothed version of this objective and making it more complex as the training proceeds. Our method (Continuation-KD) achieves state-of-the-art performance across various compact architectures on NLU (GLUE benchmark) and computer vision tasks (CIFAR-10 and CIFAR-100)",
    "checked": true,
    "id": "103a09de20ffc37111933d6ea750f4e01a98b649",
    "semantic_title": "continuation kd: improved knowledge distillation through the lens of continuation optimization",
    "citation_count": 3,
    "authors": [
      "Aref Jafari",
      "Ivan Kobyzev",
      "Mehdi Rezagholizadeh",
      "Pascal Poupart",
      "Ali Ghodsi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.386": {
    "title": "Detecting Dementia from Long Neuropsychological Interviews",
    "volume": "findings",
    "abstract": "Neuropsychological exams are commonly used to diagnose various kinds of cognitive impairment. They typically involve a trained examiner who conducts a series of cognitive tests with a subject. In recent years, there has been growing interest in developing machine learning methods to extract speech and language biomarkers from exam recordings to provide automated input for cognitive assessment. Inspired by recent findings suggesting that the examiner's language can influence cognitive impairment classifications, in this paper, we study the influence of the examiner on automatic dementia identification decisions in real-world neuropsychological exams. To mitigate the influence of the examiner, we propose a systematic three-stage pipeline for detecting dementia from exam recordings. In the first stage, we perform audio-based speaker diarization (i.e., estimating who spoke when?) by incorporating speaker discriminative features. In the second stage, we employ text-based language models to identify the role of the speaker (i.e., examiner or subject). Finally, in the third stage, we employ text- and audio-based models to detect cognitive impairment from hypothesized subject segments. Our studies suggest that incorporating audio-based diarization followed by text-based role identification helps mitigate the influences from the examiner's segments. Further, we found that the text and audio modalities complement each other, and the performance improves when we use both modalities. We also perform several carefully designed experimental studies to assess the performance of each stage",
    "checked": true,
    "id": "25ee5c1e24ac8407b72b27d4f1c9be3ed2f17e2d",
    "semantic_title": "detecting dementia from long neuropsychological interviews",
    "citation_count": 1,
    "authors": [
      "Nauman Dawalatabad",
      "Yuan Gong",
      "Sameer Khurana",
      "Rhoda Au",
      "James Glass"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.387": {
    "title": "Sarcasm Detection is Way Too Easy! An Empirical Comparison of Human and Machine Sarcasm Detection",
    "volume": "findings",
    "abstract": "Recently, author-annotated sarcasm datasets, which focus on intended, rather than perceived sarcasm, have been introduced. Although datasets collected using first-party annotation have important benefits, there is no comparison of human and machine performance on these new datasets. In this paper, we collect new annotations to provide human-level benchmarks for these first-party annotated sarcasm tasks in both English and Arabic, and compare the performance of human annotators to that of state-of-the-art sarcasm detection systems. Our analysis confirms that sarcasm detection is extremely challenging, with individual humans performing close to or slightly worse than the best trained models. With majority voting, however, humans are able to achieve the best results on all tasks. We also perform error analysis, finding that some of the most challenging examples are those that require additional context. We also highlight common features and patterns used to express sarcasm in English and Arabic such as idioms and proverbs. We suggest that to better capture sarcasm, future sarcasm detection datasets and models should focus on representing conversational and cultural context while leveraging world knowledge and common sense",
    "checked": true,
    "id": "da83df871c7500275ab7da2f6d848a39a68ff033",
    "semantic_title": "sarcasm detection is way too easy! an empirical comparison of human and machine sarcasm detection",
    "citation_count": 3,
    "authors": [
      "Ibrahim Abu Farha",
      "Steven Wilson",
      "Silviu Oprea",
      "Walid Magdy"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.388": {
    "title": "Cross-lingual Text-to-SQL Semantic Parsing with Representation Mixup",
    "volume": "findings",
    "abstract": "We focus on the cross-lingual Text-to-SQL semantic parsing task,where the parsers are expected to generate SQL for non-English utterances based on English database schemas. Intuitively, English translation as side information is an effective way to bridge the language gap,but noise introduced by the translation system may affect parser effectiveness. In this work, we propose a Representation Mixup Framework (Rex) for effectively exploiting translations in the cross-lingual Text-to-SQL task. Particularly, it uses a general encoding layer, a transition layer, and a target-centric layer to properly guide the information flow of the English translation. Experimental results on CSpider and VSpider show that our framework can benefit from cross-lingual training and improve the effectiveness of semantic parsers, achieving state-of-the-art performance",
    "checked": true,
    "id": "603c11bc7d00c50fd66687a1dda8181e2b593e03",
    "semantic_title": "cross-lingual text-to-sql semantic parsing with representation mixup",
    "citation_count": 2,
    "authors": [
      "Peng Shi",
      "Linfeng Song",
      "Lifeng Jin",
      "Haitao Mi",
      "He Bai",
      "Jimmy Lin",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.389": {
    "title": "JamPatoisNLI: A Jamaican Patois Natural Language Inference Dataset",
    "volume": "findings",
    "abstract": "JamPatoisNLI provides the first dataset for natural language inference in a creole language, Jamaican Patois.Many of the most-spoken low-resource languages are creoles. These languages commonly have a lexicon derived from a major world language and a distinctive grammar reflecting the languages of the original speakers and the process of language birth by creolization. This gives them a distinctive place in exploring the effectiveness of transfer from large monolingual or multilingual pretrained models. While our work, along with previous work, shows that transfer from these models to low-resource languages that are unrelated to languages in their training set is not very effective, we would expect stronger results from transfer to creoles. Indeed, our experiments show considerably better results from few-shot learning of JamPatoisNLI than for such unrelated languages, and help us begin to understand how the unique relationship between creoles and their high-resource base languages affect cross-lingual transfer. JamPatoisNLI, which consists of naturally-occurring premises and expert-written hypotheses, is a step towards steering research into a traditionally underserved language and a useful benchmark for understanding cross-lingual NLP",
    "checked": true,
    "id": "356633ba77851f4a9f8e2ba713ca83a4ef2c140e",
    "semantic_title": "jampatoisnli: a jamaican patois natural language inference dataset",
    "citation_count": 7,
    "authors": [
      "Ruth-Ann Armstrong",
      "John Hewitt",
      "Christopher Manning"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.390": {
    "title": "Are Neural Topic Models Broken?",
    "volume": "findings",
    "abstract": "Recently, the relationship between automated and human evaluation of topic models has been called into question. Method developers have staked the efficacy of new topic model variants on automated measures, and their failure to approximate human preferences places these models on uncertain ground. Moreover, existing evaluation paradigms are often divorced from real-world use. Motivated by content analysis as a dominant real-world use case for topic modeling, we analyze two related aspects of topic models that affect their effectiveness and trustworthiness in practice for that purpose: the stability of their estimates and the extent to which the model's discovered categories align with human-determined categories in the data. We find that neural topic models fare worse in both respects compared to an established classical method. We take a step toward addressing both issues in tandem by demonstrating that a straightforward ensembling method can reliably outperform the members of the ensemble",
    "checked": true,
    "id": "d3d563126a7915f09f955b430b912e24a9ef5d1c",
    "semantic_title": "are neural topic models broken?",
    "citation_count": 3,
    "authors": [
      "Alexander Miserlis Hoyle",
      "Rupak Sarkar",
      "Pranav Goel",
      "Philip Resnik"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.391": {
    "title": "Know Thy Strengths: Comprehensive Dialogue State Tracking Diagnostics",
    "volume": "findings",
    "abstract": "Recent works that revealed the vulnerability of dialogue state tracking (DST) models to distributional shifts have made holistic comparisons on robustness and qualitative analyses increasingly important for understanding their relative performance. We present our findings from standardized and comprehensive DST diagnoses, which have previously been sparse and uncoordinated, using our toolkit, CheckDST, a collection of robustness tests and failure mode analytics. We discover that different classes of DST models have clear strengths and weaknesses, where generation models are more promising for handling language variety while span-based classification models are more robust to unseen entities. Prompted by this discovery, we also compare checkpoints from the same model and find that the standard practice of selecting checkpoints using validation loss/accuracy is prone to overfitting and each model class has distinct patterns of failure. Lastly, we demonstrate how our diagnoses motivate a pre-finetuning procedure with non-dialogue data that offers comprehensive improvements to generation models by alleviating the impact of distributional shifts through transfer learning",
    "checked": true,
    "id": "c586320be1b7178893e7fe4d87e4527b73f0f250",
    "semantic_title": "know thy strengths: comprehensive dialogue state tracking diagnostics",
    "citation_count": 7,
    "authors": [
      "Hyundong Cho",
      "Chinnadhurai Sankar",
      "Christopher Lin",
      "Kaushik Ram Sadagopan",
      "Shahin Shayandeh",
      "Asli Celikyilmaz",
      "Jonathan May",
      "Ahmad Beirami"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.392": {
    "title": "Open-domain Question Answering via Chain of Reasoning over Heterogeneous Knowledge",
    "volume": "findings",
    "abstract": "We propose a novel open-domain question answering (ODQA) framework for answering single/multi-hop questions across heterogeneous knowledge sources. The key novelty of our method is the introduction of the intermediary modules into the current retriever-reader pipeline. Unlike previous methods that solely rely on the retriever for gathering all evidence in isolation,our intermediary performs a chain of reasoning over the retrieved set. Specifically, our method links the retrieved evidence with its related global context into graphs and organizes them into a candidate list of evidence chains. Built upon pretrained language models, our system achieves competitive performance on two ODQA datasets, OTT-QA and NQ, against tables and passages from Wikipedia.In particular, our model substantially outperforms the previous state-of-the-art on OTT-QA with an exact match score of 47.3 (45% relative gain)",
    "checked": true,
    "id": "fff24425c8eaa3af4422261b9e108374ded678f0",
    "semantic_title": "open-domain question answering via chain of reasoning over heterogeneous knowledge",
    "citation_count": 8,
    "authors": [
      "Kaixin Ma",
      "Hao Cheng",
      "Xiaodong Liu",
      "Eric Nyberg",
      "Jianfeng Gao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.393": {
    "title": "Detecting Languages Unintelligible to Multilingual Models through Local Structure Probes",
    "volume": "findings",
    "abstract": "Providing better language tools for low-resource and endangered languages is imperative for equitable growth. Recent progress with massively multilingual pretrained models has proven surprisingly effective at performing zero-shot transfer to a wide variety of languages. However, this transfer is not universal, with many languages not currently understood by multilingual approaches. It is estimated that only 72 languages possess a \"small set of labeled datasets\" on which we could test a model's performance, the vast majority of languages not having the resources available to simply evaluate performances on. In this work, we attempt to clarify which languages do and do not currently benefit from such transfer. To that end, we develop a general approach that requires only unlabelled text to detect which languages are not well understood by a cross-lingual model. Our approach is derived from the hypothesis that if a model's understanding is insensitive to perturbations to text in a language, it is likely to have a limited understanding of that language. We construct a cross-lingual sentence similarity task to evaluate our approach empirically on 350, primarily low-resource, languages",
    "checked": true,
    "id": "fc78d652c4d395ba2737ab0406bc53fd025d4aad",
    "semantic_title": "detecting languages unintelligible to multilingual models through local structure probes",
    "citation_count": 2,
    "authors": [
      "Louis Clouatre",
      "Prasanna Parthasarathi",
      "Amal Zouaq",
      "Sarath Chandar"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.394": {
    "title": "Cards Against AI: Predicting Humor in a Fill-in-the-blank Party Game",
    "volume": "findings",
    "abstract": "Humor is an inherently social phenomenon, with humorous utterances shaped by what is socially and culturally accepted. Understanding humor is an important NLP challenge, with many applications to human-computer interactions. In this work we explore humor in the context of Cards Against Humanity – a party game where players complete fill-in-the-blank statements using cards that can be offensive or politically incorrect. We introduce a novel dataset of 300,000 online games of Cards Against Humanity, including 785K unique jokes, analyze it and provide insights. We trained machine learning models to predict the winning joke per game, achieving performance twice as good (20%) as random, even without any user information. On the more difficult task of judging novel cards, we see the models' ability to generalize is moderate. Interestingly, we find that our models are primarily focused on punchline card, with the context having little impact. Analyzing feature importance, we observe that short, crude, juvenile punchlines tend to win",
    "checked": true,
    "id": "b79bbf6404f02eed49d24799205c8e45c0f8bef6",
    "semantic_title": "cards against ai: predicting humor in a fill-in-the-blank party game",
    "citation_count": 5,
    "authors": [
      "Dan Ofer",
      "Dafna Shahaf"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.395": {
    "title": "Open-Vocabulary Argument Role Prediction For Event Extraction",
    "volume": "findings",
    "abstract": "The argument role in event extraction refers to the relation between an event and an argument participating in it. Despite the great progress in event extraction, existing studies still depend on roles pre-defined by domain experts. These studies expose obvious weakness when extending to emerging event types or new domains without available roles. Therefore, more attention and effort needs to be devoted to automatically customizing argument roles. In this paper, we define this essential but under-explored task: open-vocabulary argument role prediction. The goal of this task is to infer a set of argument roles for a given event type. We propose a novel unsupervised framework, RolePred for this task. Specifically, we formulate the role prediction problem as an in-filling task and construct prompts for a pre-trained language model to generate candidate roles. By extracting and analyzing the candidate arguments, the event-specific roles are further merged and selected. To standardize the research of this task, we collect a new human-annotated event extraction dataset including 143 customized argument roles with rich semantics. On this dataset, RolePred outperforms the existing methods by a large margin",
    "checked": true,
    "id": "433e052ed37dd7fd43bf1bfd9e07419deb690814",
    "semantic_title": "open-vocabulary argument role prediction for event extraction",
    "citation_count": 7,
    "authors": [
      "Yizhu Jiao",
      "Sha Li",
      "Yiqing Xie",
      "Ming Zhong",
      "Heng Ji",
      "Jiawei Han"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.396": {
    "title": "Token-level Sequence Labeling for Spoken Language Understanding using Compositional End-to-End Models",
    "volume": "findings",
    "abstract": "End-to-end spoken language understanding (SLU) systems are gaining popularity over cascaded approaches due to their simplicity and ability to avoid error propagation. However, these systems model sequence labeling as a sequence prediction task causing a divergence from its well-established token-level tagging formulation. We build compositional end-to-end SLU systems that explicitly separate the added complexity of recognizing spoken mentions in SLU from the NLU task of sequence labeling. By relying on intermediate decoders trained for ASR, our end-to-end systems transform the input modality from speech to token-level representations that can be used in the traditional sequence labeling framework. This composition of ASR and NLU formulations in our end-to-end SLU system offers direct compatibility with pre-trained ASR and NLU systems, allows performance monitoring of individual components and enables the use of globally normalized losses like CRF, making them attractive in practical scenarios. Our models outperform both cascaded and direct end-to-end models on a labeling task of named entity recognition across SLU benchmarks",
    "checked": true,
    "id": "10672baf790962195677c7581a2fe984032e7f98",
    "semantic_title": "token-level sequence labeling for spoken language understanding using compositional end-to-end models",
    "citation_count": 6,
    "authors": [
      "Siddhant Arora",
      "Siddharth Dalmia",
      "Brian Yan",
      "Florian Metze",
      "Alan W Black",
      "Shinji Watanabe"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.397": {
    "title": "Baked-in State Probing",
    "volume": "findings",
    "abstract": "Neural language models have been analyzed for their linguistic and extra-linguistic knowledge via probing. Of particular interest has been the following question: how much can a language model trained only on form learn about meaning? Recent work has demonstrated via probing classifiers that in the setting of simple procedural text, where by \"meaning\" we mean the underlying world state, language models have a non-trivial performance on world state tracking. However, our proposed evaluation based on model predictions shows differing results, suggesting that these models are either not capturing the world state or not using it. How do these results change if the model has access to the world state? We explore this alternate setting with access to the underlying world state only during training and investigate ways of \"baking in\" the state knowledge along with the primary task of language modeling. Our proposed approaches allow for state probing during inference simply via text prompts, avoiding any probing classifier machinery. In terms of performance, we show that baking in the state knowledge during training leads to significant improvements in state tracking performance and text generation quality,",
    "checked": true,
    "id": "850cdb11903cbadceb0c7e919d81b1eb64618ab4",
    "semantic_title": "baked-in state probing",
    "citation_count": 0,
    "authors": [
      "Shubham Toshniwal",
      "Sam Wiseman",
      "Karen Livescu",
      "Kevin Gimpel"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.398": {
    "title": "ClinicalT5: A Generative Language Model for Clinical Text",
    "volume": "findings",
    "abstract": "In the past few years, large pre-trained language models (PLMs) have been widely adopted in different areas and have made fundamental improvements over a variety of downstream tasks in natural language processing (NLP). Meanwhile, domain-specific variants of PLMs are being proposed to address the needs of domains that demonstrate a specific pattern of writing and vocabulary, e.g., BioBERT for the biomedical domain and ClinicalBERT for the clinical domain. Recently, generative language models like BART and T5 are gaining popularity with their competitive performance on text generation as well as on tasks cast as generative problems. However, in the clinical domain, such domain-specific generative variants are still underexplored. To address this need, our work introduces a T5-based text-to-text transformer model pre-trained on clinical text, i.e., ClinicalT5. We evaluate the proposed model both intrinsically and extrinsically over a diverse set of tasks across multiple datasets, and show that ClinicalT5 dramatically outperforms T5 in the domain-specific tasks and compares favorably with its close baselines",
    "checked": true,
    "id": "d3c3280e4e91632395e8c9523c91d2972c03fe73",
    "semantic_title": "clinicalt5: a generative language model for clinical text",
    "citation_count": 18,
    "authors": [
      "Qiuhao Lu",
      "Dejing Dou",
      "Thien Nguyen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.399": {
    "title": "Find Someone Who: Visual Commonsense Understanding in Human-Centric Grounding",
    "volume": "findings",
    "abstract": "From a visual scene containing multiple people, human is able to distinguish each individual given the context descriptions about what happened before, their mental/physical states or intentions, etc. Above ability heavily relies on human-centric commonsense knowledge and reasoning. For example, if asked to identify the \"person who needs healing\" in an image, we need to first know that they usually have injuries or suffering expressions, then find the corresponding visual clues before finally grounding the person. We present a new commonsense task, Human-centric Commonsense Grounding, that tests the models' ability to ground individuals given the context descriptions about what happened before, and their mental/physical states or intentions. We further create a benchmark, HumanCog, a dataset with 130k grounded commonsensical descriptions annotated on 67k images, covering diverse types of commonsense and visual scenes. We set up a context-object-aware method as a strong baseline that outperforms previous pre-trained and non-pretrained models. Further analysis demonstrates that rich visual commonsense and powerful integration of multi-modal commonsense are essential, which sheds light on future works. Data and code will be available at https://github.com/Hxyou/HumanCog",
    "checked": true,
    "id": "842317cafa296629f09f4afc2725405ae239e871",
    "semantic_title": "find someone who: visual commonsense understanding in human-centric grounding",
    "citation_count": 3,
    "authors": [
      "Haoxuan You",
      "Rui Sun",
      "Zhecan Wang",
      "Kai-Wei Chang",
      "Shih-Fu Chang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.400": {
    "title": "CrisisLTLSum: A Benchmark for Local Crisis Event Timeline Extraction and Summarization",
    "volume": "findings",
    "abstract": "Social media has increasingly played a key role in emergency response: first responders can use public posts to better react to ongoing crisis events and deploy the necessary resources where they are most needed. Timeline extraction and abstractive summarization are critical technical tasks to leverage large numbers of social media posts about events. Unfortunately, there are few datasets for benchmarking technical approaches for those tasks. This paper presents , the largest dataset of local crisis event timelines available to date. contains 1,000 crisis event timelines across four domains: wildfires, local fires, traffic, and storms. We built using a semi-automated cluster-then-refine approach to collect data from the public Twitter stream. Our initial experiments indicate a significant gap between the performance of strong baselines compared to the human performance on both tasks. Our dataset, code, and models are publicly available (https://github.com/CrisisLTLSum/CrisisTimelines)",
    "checked": true,
    "id": "bfb31e3572c37f4de88c89ab5c2acebf67c43a9e",
    "semantic_title": "crisisltlsum: a benchmark for local crisis event timeline extraction and summarization",
    "citation_count": 3,
    "authors": [
      "Hossein Rajaby Faghihi",
      "Bashar Alhafni",
      "Ke Zhang",
      "Shihao Ran",
      "Joel Tetreault",
      "Alejandro Jaimes"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.401": {
    "title": "Prompt-Tuning Can Be Much Better Than Fine-Tuning on Cross-lingual Understanding With Multilingual Language Models",
    "volume": "findings",
    "abstract": "Pre-trained multilingual language models show significant performance gains for zero-shot cross-lingual model transfer on a wide range of natural language understanding (NLU) tasks. Previously, for zero-shot cross-lingual evaluation, pre-trained models are only fine-tuned on English data and tested on a variety of target languages. In this paper, we do cross-lingualevaluation on various NLU tasks (sentence classification, sequence labeling, question answering) using prompt-tuning and compare it with fine-tuning. The results show that prompt tuning achieves much better cross-lingual transfer than fine-tuning across datasets, with only 0.1% to 0.3% tuned parameters. Additionally, we demonstrate through the analysis that prompt tuning can have better cross-lingual transfer-ability of representations on downstream tasks with better aligned decision boundaries",
    "checked": true,
    "id": "aa9cda8e13dc60bde7531245c3d878bec8fdccad",
    "semantic_title": "prompt-tuning can be much better than fine-tuning on cross-lingual understanding with multilingual language models",
    "citation_count": 15,
    "authors": [
      "Lifu Tu",
      "Caiming Xiong",
      "Yingbo Zhou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.402": {
    "title": "BERT Meets CTC: New Formulation of End-to-End Speech Recognition with Pre-trained Masked Language Model",
    "volume": "findings",
    "abstract": "This paper presents BERT-CTC, a novel formulation of end-to-end speech recognition that adapts BERT for connectionist temporal classification (CTC). Our formulation relaxes the conditional independence assumptions used in conventional CTC and incorporates linguistic knowledge through the explicit output dependency obtained by BERT contextual embedding. BERT-CTC attends to the full contexts of the input and hypothesized output sequences via the self-attention mechanism. This mechanism encourages a model to learn inner/inter-dependencies between the audio and token representations while maintaining CTC's training efficiency. During inference, BERT-CTC combines a mask-predict algorithm with CTC decoding, which iteratively refines an output sequence. The experimental results reveal that BERT-CTC improves over conventional approaches across variations in speaking styles and languages. Finally, we show that the semantic representations in BERT-CTC are beneficial towards downstream spoken language understanding tasks",
    "checked": true,
    "id": "3bb913986a9f9b7e76f5646535c3f07f30b9cfb2",
    "semantic_title": "bert meets ctc: new formulation of end-to-end speech recognition with pre-trained masked language model",
    "citation_count": 16,
    "authors": [
      "Yosuke Higuchi",
      "Brian Yan",
      "Siddhant Arora",
      "Tetsuji Ogawa",
      "Tetsunori Kobayashi",
      "Shinji Watanabe"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.403": {
    "title": "EtriCA: Event-Triggered Context-Aware Story Generation Augmented by Cross Attention",
    "volume": "findings",
    "abstract": "One of the key challenges of automatic story generation is how to generate a long narrative that can maintain fluency, relevance, and coherence. Despite recent progress, current story generation systems still face the challenge of how to effectively capture contextual and event features, which has a profound impact on a model's generation performance. To address these challenges, we present EtriCA, a novel neural generation model, which improves the relevance and coherence of the generated stories through residually mapping context features to event sequences with a cross-attention mechanism. Such a feature capturing mechanism allows our model to better exploit the logical relatedness between events when generating stories. Extensive experiments based on both automatic and human evaluations show that our model significantly outperforms state-of-the-art baselines, demonstrating the effectiveness of our model in leveraging context and event features",
    "checked": true,
    "id": "58b8da3821affc426895a85dbac5556322e6e2a9",
    "semantic_title": "etrica: event-triggered context-aware story generation augmented by cross attention",
    "citation_count": 14,
    "authors": [
      "Chen Tang",
      "Chenghua Lin",
      "Henglin Huang",
      "Frank Guerin",
      "Zhihao Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.404": {
    "title": "LADIS: Language Disentanglement for 3D Shape Editing",
    "volume": "findings",
    "abstract": "Natural language interaction is a promising direction for democratizing 3D shape design. However, existing methods for text-driven 3D shape editing face challenges in producing decoupled, local edits to 3D shapes. We address this problem by learning disentangled latent representations that ground language in 3D geometry. To this end, we propose a complementary tool set including a novel network architecture, a disentanglement loss, and a new editing procedure. Additionally, to measure edit locality, we define a new metric that we call part-wise edit precision. We show that our method outperforms existing SOTA methods by 20% in terms of edit locality, and up to 6.6% in terms of language reference resolution accuracy. Human evaluations additionally show that compared to the existing SOTA, our method produces shape edits that are more local, more semantically accurate, and more visually obvious. Our work suggests that by solely disentangling language representations, downstream 3D shape editing can become more local to relevant parts, even if the model was never given explicit part-based supervision",
    "checked": true,
    "id": "0ac2fcfb0f6b7837bfd8fec4e83f8813d2e7f7b3",
    "semantic_title": "ladis: language disentanglement for 3d shape editing",
    "citation_count": 9,
    "authors": [
      "Ian Huang",
      "Panos Achlioptas",
      "Tianyi Zhang",
      "Sergei Tulyakov",
      "Minhyuk Sung",
      "Leonidas Guibas"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.405": {
    "title": "Effective Pretraining Objectives for Transformer-based Autoencoders",
    "volume": "findings",
    "abstract": "In this paper, we study trade-offs between efficiency, cost and accuracy when pre-training Transformer encoders with different pre-training objectives. For this purpose, we analyze features of common objectives and combine them to create new effective pre-training approaches. Specifically, we designed light token generators based on a straightforward statistical approach, which can replace ELECTRA computationally heavy generators, thus highly reducing cost. Our experiments also show that (i) there are more efficient alternatives to BERT's MLM, and (ii) it is possible to efficiently pre-train Transformer-based models using lighter generators without a significant drop in performance",
    "checked": true,
    "id": "3a4f61e87d8d6e24e5dbdbe59483d6a250a64607",
    "semantic_title": "effective pre-training objectives for transformer-based autoencoders",
    "citation_count": 3,
    "authors": [
      "Luca Di Liello",
      "Matteo Gabburo",
      "Alessandro Moschitti"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.406": {
    "title": "Language Model Detoxification in Dialogue with Contextualized Stance Control",
    "volume": "findings",
    "abstract": "To reduce the toxic degeneration in a pretrained Language Model (LM), previous work on Language Model detoxification has focused on reducing the toxicity of the generation itself (self-toxicity) without consideration of the context. As a result, a type of implicit offensive language where the generations support the offensive language in the context is ignored. Different from the LM controlling tasks in previous work, where the desired attributes are fixed for generation, the desired stance of the generation depends on the offensiveness of the context. Therefore, we propose a novel control method to do context-dependent detoxification with the stance taken into consideration. We introduce meta prefixes to learn the contextualized stance control strategy and to generate the stance control prefix according to the input context. The generated stance prefix is then combined with the toxicity control prefix to guide the response generation. Experimental results show that our proposed method can effectively learn the context-dependent stance control strategies while keeping a low self-toxicity of the underlying LM",
    "checked": true,
    "id": "9f102146a8c6fe6ba4910be96d54331aa7b491d9",
    "semantic_title": "language model detoxification in dialogue with contextualized stance control",
    "citation_count": 1,
    "authors": [
      "Jing Qian",
      "Xifeng Yan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.407": {
    "title": "Multilingual SubEvent Relation Extraction: A Novel Dataset and Structure Induction Method",
    "volume": "findings",
    "abstract": "Subevent Relation Extraction (SRE) is a task in Information Extraction that aims to recognize spatial and temporal containment relations between event mentions in text. Recent methods have utilized pre-trained language models to represent input texts for SRE. However, a key issue in existing SRE methods is the employment of sequential order of words in texts to feed into representation learning methods, thus unable to explicitly focus on important context words and their interactions to enhance representations. In this work, we introduce a new method for SRE that learns to induce effective graph structures for input texts to boost representation learning. Our method features a word alignment framework with dependency paths and optimal transport to identify important context words to form effective graph structures for SRE. In addition, to enable SRE research on non-English languages, we present a new multilingual SRE dataset for five typologically different languages. Extensive experiments reveal the state-of-the-art performance for our method on different datasets and languages",
    "checked": true,
    "id": "539f9e406753ac77b1cb4532cb98ff8ac3580bca",
    "semantic_title": "multilingual subevent relation extraction: a novel dataset and structure induction method",
    "citation_count": 4,
    "authors": [
      "Viet Lai",
      "Hieu Man",
      "Linh Ngo",
      "Franck Dernoncourt",
      "Thien Nguyen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.408": {
    "title": "A Two-Stage Approach towards Generalization in Knowledge Base Question Answering",
    "volume": "findings",
    "abstract": "Most existing approaches for Knowledge Base Question Answering (KBQA) focus on a specific underlying knowledge base either because of inherent assumptions in the approach, or because evaluating it on a different knowledge base requires non-trivial changes. However, many popular knowledge bases share similarities in their underlying schemas that can be leveraged to facilitate generalization across knowledge bases. To achieve this generalization, we introduce a KBQA framework based on a 2-stage architecture that explicitly separates semantic parsing from the knowledge base interaction, facilitating transfer learning across datasets and knowledge graphs. We show that pretraining on datasets with a different underlying knowledge base can nevertheless provide significant performance gains and reduce sample complexity. Our approach achieves comparable or state-of-the-art performance for LC-QuAD (DBpedia), WebQSP (Freebase), SimpleQuestions (Wikidata) and MetaQA (Wikimovies-KG)",
    "checked": true,
    "id": "b2a7b03a3c403b7c7d01a5f52dfdbd845323ab66",
    "semantic_title": "a two-stage approach towards generalization in knowledge base question answering",
    "citation_count": 17,
    "authors": [
      "Srinivas Ravishankar",
      "Dung Thai",
      "Ibrahim Abdelaziz",
      "Nandana Mihindukulasooriya",
      "Tahira Naseem",
      "Pavan Kapanipathi",
      "Gaetano Rossiello",
      "Achille Fokoue"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.409": {
    "title": "Few-Shot (Dis)Agreement Identification in Online Discussions with Regularized and Augmented Meta-Learning",
    "volume": "findings",
    "abstract": "Online discussions are abundant with opinions towards a common topic, and identifying (dis)agreement between a pair of comments enables many opinion mining applications. Realizing the increasing needs to analyze opinions for emergent new topics that however tend to lack annotations, we present the first meta-learning approach for few-shot (dis)agreement identification that can be quickly applied to analyze opinions for new topics with few labeled instances. Furthermore, we enhance the meta-learner's domain generalization ability from two perspectives. The first is domain-invariant regularization, where we design a lexicon-based regularization loss to enable the meta-learner to learn domain-invariant cues. The second is domain-aware augmentation, where we propose domain-aware task augmentation for meta-training to learn domain-specific expressions. In addition to using an existing dataset, we also evaluate our approach on two very recent new topics, mask mandate and COVID vaccine, using our newly annotated datasets containing 1.5k and 1.4k SubReddits comment pairs respectively. Extensive experiments on three domains/topics demonstrate the effectiveness of our meta-learning approach",
    "checked": true,
    "id": "a334264ed4d2d83d204fcfd528269aa3da917035",
    "semantic_title": "few-shot (dis)agreement identification in online discussions with regularized and augmented meta-learning",
    "citation_count": 8,
    "authors": [
      "Yuanyuan Lei",
      "Ruihong Huang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.410": {
    "title": "Data Cartography for Low-Resource Neural Machine Translation",
    "volume": "findings",
    "abstract": "While collecting or generating more parallel data is necessary to improve machine translation (MT) in low-resource settings, we lack an understanding of how the limited amounts of existing data are actually used to help guide the collection of further resources. In this paper, we apply data cartography techniques (Swayamdipta et al., 2020) to characterize the contribution of training samples in two low-resource MT tasks (Swahili-English and Turkish-English) throughout the training of standard neural MT models. Our empirical study shows that, unlike in prior work for classification tasks, most samples contribute to model training in low-resource MT, albeit not uniformly throughout the training process. Furthermore, uni-dimensional characterizations of samples – e.g., based on dual cross-entropy or word frequency – do not suffice to characterize to what degree they are hard or easy to learn. Taken together, our results suggest that data augmentation strategies for low-resource MT would benefit from model-in-the-loop strategies to maximize improvements",
    "checked": true,
    "id": "9482c9791ad4926ef43ee70f075c2028cf2a32a9",
    "semantic_title": "data cartography for low-resource neural machine translation",
    "citation_count": 1,
    "authors": [
      "Aquia Richburg",
      "Marine Carpuat"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.411": {
    "title": "Augmenting Multi-Turn Text-to-SQL Datasets with Self-Play",
    "volume": "findings",
    "abstract": "The task of context-dependent text-to-SQL aims to convert multi-turn user utterances to formal SQL queries. This is a challenging task due to both the scarcity of training data from which to learn complex contextual dependencies and to generalize to unseen databases. In this paper we explore augmenting the training datasets using self-play, which leverages contextual information to synthesize new interactions to adapt the model to new databases. We first design a SQL-to-text model conditioned on a sampled goal query, which represents a user's intent, that then converses with a text-to-SQL semantic parser to generate new interactions. We then filter the synthesized interactions and retrain the models with the augmented data. We find that self-play improves the accuracy of a strong baseline on SParC and CoSQL, two widely used cross-domain text-to-SQL datasets. Our analysis shows that self-play simulates various conversational thematic relations, enhances cross-domain generalization and improves beam-search",
    "checked": true,
    "id": "891db4adb6d10a51882430ab1266f51e6e3408c5",
    "semantic_title": "augmenting multi-turn text-to-sql datasets with self-play",
    "citation_count": 5,
    "authors": [
      "Qi Liu",
      "Zihuiwen Ye",
      "Tao Yu",
      "Linfeng Song",
      "Phil Blunsom"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.412": {
    "title": "Prompt Compression and Contrastive Conditioning for Controllability and Toxicity Reduction in Language Models",
    "volume": "findings",
    "abstract": "We explore the idea of compressing the prompts used to condition language models, and show that compressed prompts can retain a substantive amount of information about the original prompt. For severely compressed prompts, while fine-grained information is lost, abstract information and general sentiments can be retained with surprisingly few parameters, which can be useful in the context of decode-time algorithms for controllability and toxicity reduction. We find that some complex prompts can be effectively compressed into a single token to guide generation. We also show that compressed prompts are largely compositional, and can be constructed such that they can be used to control independent aspects of generated text",
    "checked": true,
    "id": "4afda39036206dcb3f97829dccb897f1fc80f459",
    "semantic_title": "prompt compression and contrastive conditioning for controllability and toxicity reduction in language models",
    "citation_count": 22,
    "authors": [
      "David Wingate",
      "Mohammad Shoeybi",
      "Taylor Sorensen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.413": {
    "title": "NaturalAdversaries: Can Naturalistic Adversaries Be as Effective as Artificial Adversaries?",
    "volume": "findings",
    "abstract": "While a substantial body of prior work has explored adversarial example generation for natural language understanding tasks, these examples are often unrealistic and diverge from the real-world data distributions. In this work, we introduce a two-stage adversarial example generation framework (NaturalAdversaries), for designing adversaries that are effective at fooling a given classifier and demonstrate natural-looking failure cases that could plausibly occur during in-the-wild deployment of the models. At the first stage a token attribution method is used to summarize a given classifier's behavior as a function of the key tokens in the input. In the second stage a generative model is conditioned on the key tokens from the first stage. NaturalAdversaries is adaptable to both black-box and white-box adversarial attacks based on the level of access to the model parameters. Our results indicate these adversaries generalize across domains, and offer insights for future research on improving robustness of neural text classification models",
    "checked": true,
    "id": "337ad42b01d0ff764aa46a1ac9e3a93e2830e06c",
    "semantic_title": "naturaladversaries: can naturalistic adversaries be as effective as artificial adversaries?",
    "citation_count": 1,
    "authors": [
      "Saadia Gabriel",
      "Hamid Palangi",
      "Yejin Choi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.414": {
    "title": "Multi-Path Transformer is Better: A Case Study on Neural Machine Translation",
    "volume": "findings",
    "abstract": "For years the model performance in machine learning obeyed a power-law relationship with the model size. For the consideration of parameter efficiency, recent studies focus on increasing model depth rather than width to achieve better performance. In this paper, we study how model width affects the Transformer model through a parameter-efficient multi-path structure. To better fuse features extracted from different paths, we add three additional operations to each sublayer: a normalization at the end of each path, a cheap operation to produce more features, and a learnable weighted mechanism to fuse all features flexibly. Extensive experiments on 12 WMT machine translation tasks show that, with the same number of parameters, the shallower multi-path model can achieve similar or even better performance than the deeper model. It reveals that we should pay more attention to the multi-path structure, and there should be a balance between the model depth and width to train a better large-scale Transformer",
    "checked": true,
    "id": "91312cadef8f1aa1ce7db3a90e7db01ff5f7e73c",
    "semantic_title": "multi-path transformer is better: a case study on neural machine translation",
    "citation_count": 0,
    "authors": [
      "Ye Lin",
      "Shuhan Zhou",
      "Yanyang Li",
      "Anxiang Ma",
      "Tong Xiao",
      "Jingbo Zhu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.415": {
    "title": "Unsupervised Learning of Hierarchical Conversation Structure",
    "volume": "findings",
    "abstract": "Human conversations can evolve in many different ways, creating challenges for automatic understanding and summarization. Goal-oriented conversations often have meaningful sub-dialogue structure, but it can be highly domain-dependent. This work introduces an unsupervised approach to learning hierarchical conversation structure, including turn and sub-dialogue segment labels, corresponding roughly to dialogue acts and sub-tasks, respectively. The decoded structure is shown to be useful in enhancing neural models of language for three conversation-level understanding tasks. Further, the learned finite-state sub-dialogue network is made interpretable through automatic summarization",
    "checked": true,
    "id": "42b3982331aa3dbd233d6c45bf34577223e2ecc9",
    "semantic_title": "unsupervised learning of hierarchical conversation structure",
    "citation_count": 0,
    "authors": [
      "Bo-Ru Lu",
      "Yushi Hu",
      "Hao Cheng",
      "Noah A. Smith",
      "Mari Ostendorf"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.416": {
    "title": "Task Compass: Scaling Multi-task Pre-training with Task Prefix",
    "volume": "findings",
    "abstract": "Leveraging task-aware annotated data as supervised signals to assist with self-supervised learning on large-scale unlabeled data has become a new trend in pre-training language models. Existing studies show that multi-task learning with large-scale supervised tasks suffers from negative effects across tasks. To tackle the challenge, we propose a task prefix guided multi-task pre-training framework to explore the relationships among tasks. We conduct extensive experiments on 40 datasets, which show that our model can not only serve as the strong foundation backbone for a wide range of tasks but also be feasible as a probing tool for analyzing task relationships. The task relationships reflected by the prefixes align transfer learning performance between tasks. They also suggest directions for data augmentation with complementary tasks, which help our model achieve human-parity results on commonsense reasoning leaderboards. Code is available at https://github.com/cooelf/CompassMTL",
    "checked": true,
    "id": "0979695b5d74016e97ab8f306f632114e98bd6d9",
    "semantic_title": "task compass: scaling multi-task pre-training with task prefix",
    "citation_count": 11,
    "authors": [
      "Zhuosheng Zhang",
      "Shuohang Wang",
      "Yichong Xu",
      "Yuwei Fang",
      "Wenhao Yu",
      "Yang Liu",
      "Hai Zhao",
      "Chenguang Zhu",
      "Michael Zeng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.417": {
    "title": "Sharpness-Aware Minimization with Dynamic Reweighting",
    "volume": "findings",
    "abstract": "Deep neural networks are often overparameterized and may not easily achieve model generalization. Adversarial training has shown effectiveness in improving generalization by regularizing the change of loss on top of adversarially chosen perturbations. The recently proposed sharpness-aware minimization (SAM) algorithm conducts adversarial weight perturbation, encouraging the model to converge to a flat minima. SAM finds a common adversarial weight perturbation per-batch. Although per-instance adversarial weight perturbations are stronger adversaries and can potentially lead to better generalization performance, their computational cost is very high and thus it is impossible to use per-instance perturbations efficiently in SAM. In this paper, we tackle this efficiency bottleneck and propose sharpness-aware minimization with dynamic reweighting (delta-SAM). Our theoretical analysis motivates that it is possible to approach the stronger, per-instance adversarial weight perturbations using reweighted per-batch weight perturbations. delta-SAM dynamically reweights perturbation within each batch according to the theoretically principled weighting factors, serving as a good approximation to per-instance perturbation. Experiments on various natural language understanding tasks demonstrate the effectiveness of delta-SAM",
    "checked": true,
    "id": "5f950dce58eff1cd4a0c69f6df641e8443d6bfb3",
    "semantic_title": "sharpness-aware minimization with dynamic reweighting",
    "citation_count": 5,
    "authors": [
      "Wenxuan Zhou",
      "Fangyu Liu",
      "Huan Zhang",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.418": {
    "title": "Predicting Long-Term Citations from Short-Term Linguistic Influence",
    "volume": "findings",
    "abstract": "A standard measure of the influence of a research paper is the number of times it is cited. However, papers may be cited for many reasons, and citation count is not informative about the extent to which a paper affected the content of subsequent publications. We therefore propose a novel method to quantify linguistic influence in timestamped document collections. There are two main steps: first, identify lexical and semantic changes using contextual embeddings and word frequencies; second, aggregate information about these changes into per-document influence parameters by estimating a high-dimensional Hawkes process with a low-rank parameter matrix. The resulting measures of linguistic influence are predictive of future citations. Specifically, the estimate of linguistic influence from the two years after a paper's publication is correlated with and predictive of its citation count in the following three years. This is demonstrated using an online evaluation with incremental temporal training/test splits, in comparison with a strong baseline that includes predictors for initial citation counts, topics, and lexical features",
    "checked": true,
    "id": "6744b490c49db0945b5eb1aa7358097393d4c185",
    "semantic_title": "predicting long-term citations from short-term linguistic influence",
    "citation_count": 1,
    "authors": [
      "Sandeep Soni",
      "David Bamman",
      "Jacob Eisenstein"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.419": {
    "title": "Joint Audio/Text Training for Transformer Rescorer of Streaming Speech Recognition",
    "volume": "findings",
    "abstract": "Recently, there has been an increasing interest in two-pass streaming end-to-end speech recognition (ASR) that incorporates a 2nd-pass rescoring model on top of the conventional 1st-pass streaming ASR model to improve recognition accuracy while keeping latency low. One of the latest 2nd-pass rescoring model, Transformer Rescorer, takes the n-best initial outputs and audio embeddings from the 1st-pass model, and then choose the best output by re-scoring the n-best initial outputs. However, training this Transformer Rescorer requires expensive paired audio-text training data because the model uses audio embeddings as input. In this work, we present our Joint Audio/Text training method for Transformer Rescorer, to leverage unpaired text-only data which is relatively cheaper than paired audio-text data. We evaluate Transformer Rescorer with our Joint Audio/Text training on Librispeech dataset as well as our large-scale in-house dataset and show that our training method can improve word error rate (WER) significantly compared to standard Transformer Rescorer without requiring any extra model parameters or latency",
    "checked": true,
    "id": "a6c80f38f085dcade0f28d262962c30c24b9c362",
    "semantic_title": "joint audio/text training for transformer rescorer of streaming speech recognition",
    "citation_count": 5,
    "authors": [
      "Suyoun Kim",
      "Ke Li",
      "Lucas Kabela",
      "Ron Huang",
      "Jiedan Zhu",
      "Ozlem Kalinli",
      "Duc Le"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.420": {
    "title": "TyDiP: A Dataset for Politeness Classification in Nine Typologically Diverse Languages",
    "volume": "findings",
    "abstract": "We study politeness phenomena in nine typologically diverse languages. Politeness is an important facet of communication and is sometimes argued to be cultural-specific, yet existing computational linguistic study is limited to English. We create TyDiP, a dataset containing three-way politeness annotations for 500 examples in each language, totaling 4.5K examples. We evaluate how well multilingual models can identify politeness levels – they show a fairly robust zero-shot transfer ability, yet fall short of estimated human accuracy significantly. We further study mapping the English politeness strategy lexicon into nine languages via automatic translation and lexicon induction, analyzing whether each strategy's impact stays consistent across languages. Lastly, we empirically study the complicated relationship between formality and politeness through transfer experiments. We hope our dataset will support various research questions and applications, from evaluating multilingual models to constructing polite multilingual agents",
    "checked": true,
    "id": "803bd8daffb6b4483d82958fb6539d49f726579c",
    "semantic_title": "tydip: a dataset for politeness classification in nine typologically diverse languages",
    "citation_count": 5,
    "authors": [
      "Anirudh Srinivasan",
      "Eunsol Choi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.421": {
    "title": "Probing Cross-modal Semantics Alignment Capability from the Textual Perspective",
    "volume": "findings",
    "abstract": "In recent years, vision and language pre-training (VLP) models have advanced the state-of-the-art results in a variety of cross-modal downstream tasks. Aligning cross-modal semantics is claimed to be one of the essential capabilities of VLP models. However, it still remains unclear about the inner working mechanism of alignment in VLP models. In this paper, we propose a new probing method that is based on image captioning to first empirically study the cross-modal semantics alignment of VLP models. Our probing method is built upon the fact that given an image-caption pair, the VLP models will give a score, indicating how well two modalities are aligned; maximizing such scores will generate sentences that VLP models believe are of good alignment. Analyzing these sentences thus will reveal in what way different modalities are aligned and how well these alignments are in VLP models. We apply our probing method to five popular VLP models, including UNITER, ROSITA, ViLBERT, CLIP, and LXMERT, and provide a comprehensive analysis of the generated captions guided by these models. Our results show that VLP models (1) focus more on just aligning objects with visual words, while neglecting global semantics; (2) prefer fixed sentence patterns, thus ignoring more important textual information including fluency and grammar; and (3) deem the captions with more visual words are better aligned with images. These findings indicate that VLP models still have weaknesses in cross-modal semantics alignment and we hope this work will draw researchers' attention to such problems when designing a new VLP model",
    "checked": true,
    "id": "3171d9252ffae34a671c8c98f99fe99ead96e458",
    "semantic_title": "probing cross-modal semantics alignment capability from the textual perspective",
    "citation_count": 2,
    "authors": [
      "Zheng Ma",
      "Shi Zong",
      "Mianzhi Pan",
      "Jianbing Zhang",
      "Shujian Huang",
      "Xinyu Dai",
      "Jiajun Chen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.422": {
    "title": "Hidden State Variability of Pretrained Language Models Can Guide Computation Reduction for Transfer Learning",
    "volume": "findings",
    "abstract": "While transferring a pretrained language model, common approaches conventionally attach their task-specific classifiers to the top layer and adapt all the pretrained layers. We investigate whether one could make a task-specific selection on which subset of the layers to adapt and where to place the classifier. The goal is to reduce the computation cost of transfer learning methods (e.g. fine-tuning or adapter-tuning) without sacrificing its performance. We propose to select layers based on the variability of their hidden states given a task-specific corpus. We say a layer is already \"well-specialized\" in a task if the within-class variability of its hidden states is low relative to the between-class variability. Our variability metric is cheap to compute and doesn't need any training or hyperparameter tuning. It is robust to data imbalance and data scarcity. Extensive experiments on the GLUE benchmark demonstrate that selecting layers based on our metric can yield significantly stronger performance than using the same number of top layers and often match the performance of fine-tuning or adapter-tuning the entire language model",
    "checked": true,
    "id": "1c7ddec500b12a39040057758e3b972bd02c4758",
    "semantic_title": "hidden state variability of pretrained language models can guide computation reduction for transfer learning",
    "citation_count": 14,
    "authors": [
      "Shuo Xie",
      "Jiahao Qiu",
      "Ankita Pasad",
      "Li Du",
      "Qing Qu",
      "Hongyuan Mei"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.423": {
    "title": "Language Models as Agent Models",
    "volume": "findings",
    "abstract": "Language models (LMs) are trained on collections of documents, written by individual human agents to achieve specific goals in the outside world. During training, LMs have access only to text of these documents, with no direct evidence of the internal states of the agents that produced them—a fact often used to argue that LMs are incapable of modeling goal-directed aspects of human language production and comprehension. Can LMs trained on text learn anything at all about the relationship between language and use? I argue that LMs are models of communicative intentions in a specific, narrow sense. When performing next word prediction given a textual context, an LM can infer and represent properties of an agent likely to have produced that context. These representations can in turn influence subsequent LM generation in the same way that agents' communicative intentions influence their language. I survey findings from the recent literature showing that—even in today's non-robust and error-prone models—LMs infer and use representations of fine-grained communicative intentions and high-level beliefs and goals. Despite the limited nature of their training data, they can thus serve as building blocks for systems that communicate and act intentionally",
    "checked": true,
    "id": "4596139b28c3ceacbd7e3c34dc0df079dbf4e96b",
    "semantic_title": "language models as agent models",
    "citation_count": 79,
    "authors": [
      "Jacob Andreas"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.424": {
    "title": "Combinatory Grammar Tells Underlying Relevance among Entities",
    "volume": "findings",
    "abstract": "Relation extraction (RE) is an important task in natural language processing which aims to annotate the relation between two given entities, which requires a deep understanding of the running text. To import model performance, existing approaches leverage syntactic information to facilitate the relation extraction process, where they mainly focus on dependencies among words while paying limited attention to other types of syntactic structure. Considering that combinatory categorial grammar (CCG) is a lexicalized grammatical formalism that carries the syntactic and semantic knowledge for text understanding, we propose an alternative solution for RE that takes advantage of CCG to detect the relation between entities. In doing so, we perform a multi-task learning process to learn from RE and auto-annotated CCG supertags, where an attention mechanism is performed over all input words to distinguish the important ones for RE with the attention weights guided by the supertag decoding process. We evaluate our model on two widely used English benchmark datasets (i.e., ACE2005EN and SemEval 2010 Task 8 datasets) for RE, where the effectiveness of our approach is demonstrated by the experimental results with our approach achieving state-of-the-art performance on both datasets",
    "checked": true,
    "id": "8553fd00727f64ce6ebd7a12c145f30b5206b324",
    "semantic_title": "combinatory grammar tells underlying relevance among entities",
    "citation_count": 1,
    "authors": [
      "Yuanhe Tian",
      "Yan Song"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.425": {
    "title": "Leveraging Open Data and Task Augmentation to Automated Behavioral Coding of Psychotherapy Conversations in Low-Resource Scenarios",
    "volume": "findings",
    "abstract": "In psychotherapy interactions, the quality of a session is assessed by codifying the communicative behaviors of participants during the conversation through manual observation and annotation. Developing computational approaches for automated behavioral coding can reduce the burden on human coders and facilitate the objective evaluation of the intervention. In the real world, however, implementing such algorithms is associated with data sparsity challenges since privacy concerns lead to limited available in-domain data. In this paper, we leverage a publicly available conversation-based dataset and transfer knowledge to the low-resource behavioral coding task by performing an intermediate language model training via meta-learning. We introduce a task augmentation method to produce a large number of \"analogy tasks\" — tasks similar to the target one — and demonstrate that the proposed framework predicts target behaviors more accurately than all the other baseline models",
    "checked": true,
    "id": "9b76c99ae13e0b6d578e2302f27c083e41a18f7b",
    "semantic_title": "leveraging open data and task augmentation to automated behavioral coding of psychotherapy conversations in low-resource scenarios",
    "citation_count": 1,
    "authors": [
      "Zhuohao Chen",
      "Nikolaos Flemotomos",
      "Zac Imel",
      "David Atkins",
      "Shrikanth Narayanan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.426": {
    "title": "Learning to Detect Noisy Labels Using Model-Based Features",
    "volume": "findings",
    "abstract": "Label noise is ubiquitous in various machine learning scenarios such as self-labeling with model predictions and erroneous data annotation. Many existing approaches are based on heuristics such as sample losses, which might not be flexible enough to achieve optimal solutions. Meta learning based methods address this issue by learning a data selection function, but can be hard to optimize. In light of these pros and cons, we propose SENT (Selection-Enhanced Noisy label Training) that does not rely on meta learning while having the flexibility of being data-driven. SENT transfers the noise distribution to a clean set and trains a model to distinguish noisy labels from clean ones using model-based features. Empirically, on a wide range of tasks including text classification and speech recognition, SENT improves performance over strong baselines under the settings of self-training and label corruption",
    "checked": true,
    "id": "dfdd5746f2212aae09c408d9320dd562f8a6cf52",
    "semantic_title": "learning to detect noisy labels using model-based features",
    "citation_count": 0,
    "authors": [
      "Zhihao Wang",
      "Zongyu Lin",
      "Junjie Wen",
      "Xianxin Chen",
      "Peiqi Liu",
      "Guidong Zheng",
      "Yujun Chen",
      "Zhilin Yang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.427": {
    "title": "Keyphrase Generation Beyond the Boundaries of Title and Abstract",
    "volume": "findings",
    "abstract": "Keyphrase generation aims at generating important phrases (keyphrases) that best describe a given document. In scholarly domains, current approaches have largely used only the title and abstract of the articles to generate keyphrases. In this paper, we comprehensively explore whether the integration of additional information from the full text of a given article or from semantically similar articles can be helpful for a neural keyphrase generation model or not. We discover that adding sentences from the full text, particularly in the form of the extractive summary of the article can significantly improve the generation of both types of keyphrases that are either present or absent from the text. Experimental results with three widely used models for keyphrase generation along with one of the latest transformer models suitable for longer documents, Longformer Encoder-Decoder (LED) validate the observation. We also present a new large-scale scholarly dataset FullTextKP for keyphrase generation. Unlike prior large-scale datasets, FullTextKP includes the full text of the articles along with the title and abstract. We release the source code at https://github.com/kgarg8/FullTextKP",
    "checked": true,
    "id": "c2b11dfa7f94127893279df950756d3bedf7f599",
    "semantic_title": "keyphrase generation beyond the boundaries of title and abstract",
    "citation_count": 9,
    "authors": [
      "Krishna Garg",
      "Jishnu Ray Chowdhury",
      "Cornelia Caragea"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.428": {
    "title": "Composition, Attention, or Both?",
    "volume": "findings",
    "abstract": "In this paper, we propose a novel architecture called Composition Attention Grammars (CAGs) that recursively compose subtrees into a single vector representation with a composition function, and selectively attend to previous structural information with a self-attention mechanism. We investigate whether these components—the composition function and the self-attention mechanism—can both induce human-like syntactic generalization. Specifically, we train language models (LMs) with and without these two components with the model sizes carefully controlled, and evaluate their syntactic generalization performance against six test circuits on the SyntaxGym benchmark. The results demonstrated that the composition function and the self-attention mechanism both play an important role to make LMs more human-like, and closer inspection of linguistic phenomenon implied that the composition function allowed syntactic features, but not semantic features, to percolate into subtree representations",
    "checked": true,
    "id": "9c6358c7bd02f5a8538f7f17c19dba1c95a1dda8",
    "semantic_title": "composition, attention, or both?",
    "citation_count": 0,
    "authors": [
      "Ryo Yoshida",
      "Yohei Oseki"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.429": {
    "title": "CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model",
    "volume": "findings",
    "abstract": "Manually designing cloze test consumes enormous time and efforts. The major challenge lies in wrong option (distractor) selection. Having carefully-design distractors improves the effectiveness of learner ability assessment. As a result, the idea of automatically generating cloze distractor is motivated. In this paper, we investigate cloze distractor generation by exploring the employment of pre-trained language models (PLMs) as an alternative for candidate distractor generation. Experiments show that the PLM-enhanced model brings a substantial performance improvement. Our best performing model advances the state-of-the-art result from 14.94 to 34.17 (NDCG@10 score). Our code and dataset is available at https://github.com/AndyChiangSH/CDGP",
    "checked": true,
    "id": "975620e31d43bc5ff38e6f9b370f54df7926d145",
    "semantic_title": "CDGP: Automatic Cloze Distractor Generation based on Pre-trained Language Model",
    "citation_count": 7,
    "authors": [
      "Shang-Hsuan Chiang",
      "Ssu-Cheng Wang",
      "Yao-Chung Fan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.430": {
    "title": "G3: Geolocation via Guidebook Grounding",
    "volume": "findings",
    "abstract": "We demonstrate how language can improve geolocation: the task of predicting the location where an image was taken. Here we study explicit knowledge from human-written guidebooks that describe the salient and class-discriminative visual features humans use for geolocation. We propose the task of Geolocation via Guidebook Grounding that uses a dataset of StreetView images from a diverse set of locations and an associated textual guidebook for GeoGuessr, a popular interactive geolocation game. Our approach predicts a country for each image by attending over the clues automatically extracted from the guidebook. Supervising attention with country-level pseudo labels achieves the best performance. Our approach substantially outperforms a state-of-the-art image-only geolocation method, with an improvement of over 5% in Top-1 accuracy. Our dataset and code can be found at https://github.com/g-luo/geolocation_via_guidebook_grounding",
    "checked": true,
    "id": "876b68517e09aecffc77a04e39e2a3206435310f",
    "semantic_title": "g^3: geolocation via guidebook grounding",
    "citation_count": 2,
    "authors": [
      "Grace Luo",
      "Giscard Biamby",
      "Trevor Darrell",
      "Daniel Fried",
      "Anna Rohrbach"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.431": {
    "title": "Controlling Bias Exposure for Fair Interpretable Predictions",
    "volume": "findings",
    "abstract": "Recent work on reducing bias in NLP models usually focuses on protecting or isolating information related to a sensitive attribute (like gender or race). However, when sensitive information is semantically entangled with the task information of the input, e.g., gender information is predictive for a profession, a fair trade-off between task performance and bias mitigation is difficult to achieve. Existing approaches perform this trade-off by eliminating bias information from the latent space, lacking control over how much bias is necessarily required to be removed. We argue that a favorable debiasing method should use sensitive information ‘fairly', rather than blindly eliminating it (Caliskan et al., 2017; Sun et al., 2019; Bogen et al., 2020). In this work, we provide a novel debiasing algorithm by adjustingthe predictive model's belief to (1) ignore the sensitive information if it is not useful for the task; (2) use sensitive information minimally as necessary for the prediction (while also incurring a penalty). Experimental results on two text classification tasks (influenced by gender) and an open-ended generation task (influenced by race) indicate that our model achieves a desirable trade-off between debiasing and task performance along with producing debiased rationales as evidence",
    "checked": true,
    "id": "6ee75df901a5b8f9e048402bb41cffdd1f6b178f",
    "semantic_title": "controlling bias exposure for fair interpretable predictions",
    "citation_count": 15,
    "authors": [
      "Zexue He",
      "Yu Wang",
      "Julian McAuley",
      "Bodhisattwa Prasad Majumder"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.432": {
    "title": "Investigating the Benefits of Free-Form Rationales",
    "volume": "findings",
    "abstract": "Free-form rationales aim to aid model interpretability by supplying the background knowledge that can help understand model decisions. Crowdsourced rationales are provided for commonsense QA instances in popular datasets such as CoS-E and ECQA, but their utility remains under-investigated. We present human studies which show that ECQA rationales indeed provide additional background information to understand a decision, while over 88% of CoS-E rationales do not. Inspired by this finding, we ask: can the additional context provided by free-form rationales benefit models, similar to human users? We investigate the utility of rationales as an additional source of supervision, by varying the quantity and quality of rationales during training. After controlling for instances where rationales leak the correct answer while not providing additional background knowledge, we find that incorporating only 5% of rationales during training can boost model performance by 47.22% for CoS-E and 57.14% for ECQA during inference. Moreover, we also show that rationale quality matters: compared to crowdsourced rationales, T5-generated rationales provide not only weaker supervision to models, but are also not helpful for humans in aiding model interpretability",
    "checked": true,
    "id": "a9c3677f3f82817c402ed06040067860785188f4",
    "semantic_title": "investigating the benefits of free-form rationales",
    "citation_count": 9,
    "authors": [
      "Jiao Sun",
      "Swabha Swayamdipta",
      "Jonathan May",
      "Xuezhe Ma"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.433": {
    "title": "Data-Efficient Concept Extraction from Pre-trained Language Models for Commonsense Explanation Generation",
    "volume": "findings",
    "abstract": "Predicting the key explanation concept is essential for generating commonsense explanations. This paper introduces a method to predict the concept from pre-trained language models for commonsense explanation generation. Our experiment found that adopting a language model as the concept extractor and fine-tuning it with 20% training data can improve the quality and accuracy of the generated explanations over multiple evaluation metrics. Compared with conventional methods that search concepts over knowledge graphs, our method does not require the preparation and training models to search through knowledge graphs. To better understand the results from pre-trained language models, we also designed a metric to evaluate the retrieved concepts. Through analysis and experiments, we show the correlation between this metric and the performance of the generators, and we also show the importance of attaching concepts for generating high-quality sentences",
    "checked": true,
    "id": "af7503c8afb957edbf6f196f3821a8cd79bfadf6",
    "semantic_title": "data-efficient concept extraction from pre-trained language models for commonsense explanation generation",
    "citation_count": 2,
    "authors": [
      "Yanbo Fang",
      "Yongfeng Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.434": {
    "title": "Unsupervised Domain Adaptation for Joint Information Extraction",
    "volume": "findings",
    "abstract": "Joint Information Extraction (JIE) aims to jointly solve multiple tasks in the Information Extraction pipeline (e.g., entity mention, event trigger, relation, and event argument extraction). Due to their ability to leverage task dependencies and avoid error propagation, JIE models have presented state-of-the-art performance for different IE tasks. However, an issue with current JIE methods is that they only focus on standard supervised learning setting where training and test data comes from the same domain. Cross-domain/domain adaptation learning with training and test data in different domains have not been explored for JIE, thus hindering the application of this technology to different domains in practice. To address this issue, our work introduces the first study to evaluate performance of JIE models in unsupervised domain adaptation setting. In addition, we present a novel method to induce domain-invariant representations for the tasks in JIE, called Domain Adaptation for Joint Information Extraction (DA4JIE). In DA4JIE, we propose an Instance-relational Domain Adaptation mechanism that seeks to align representations of task instances in JIE across domains through a generalized version of domain-adversarial learning approach. We further devise a Context-invariant Structure Learning technique to filter domain-specialized contextual information from induced representations to boost performance of JIE models in new domains. Extensive experiments and analyses demonstrate that DA4JIE can significantly improve out-of-domain performance for current state-of-the-art JIE systems for all IE tasks",
    "checked": true,
    "id": "60c5f0ea4a2fa5fefe1284fb7d64866e5b1fbfd0",
    "semantic_title": "unsupervised domain adaptation for joint information extraction",
    "citation_count": 1,
    "authors": [
      "Nghia Ngo",
      "Bonan Min",
      "Thien Nguyen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.435": {
    "title": "Foiling Training-Time Attacks on Neural Machine Translation Systems",
    "volume": "findings",
    "abstract": "Neural machine translation (NMT) systems are vulnerable to backdoor attacks, whereby an attacker injects poisoned samples into training such that a trained model produces malicious translations. Nevertheless, there is little research on defending against such backdoor attacks in NMT. In this paper, we first show that backdoor attacks that have been successful in text classification are also effective against machine translation tasks. We then present a novel defence method that exploits a key property of most backdoor attacks: namely the asymmetry between the source and target language sentences, which is used to facilitate malicious text insertions, substitutions and suchlike. Our technique uses word alignment coupled with language model scoring to detect outlier tokens, and thus can find and filter out training instances which may contain backdoors. Experimental results demonstrate that our technique can significantly reduce the success of various attacks by up to 89.0%, while not affecting predictive accuracy",
    "checked": true,
    "id": "5ed7a9bd4ab29b1610e6766c26a0e0476cc8ae30",
    "semantic_title": "foiling training-time attacks on neural machine translation systems",
    "citation_count": 0,
    "authors": [
      "Jun Wang",
      "Xuanli He",
      "Benjamin Rubinstein",
      "Trevor Cohn"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.436": {
    "title": "Learning Action-Effect Dynamics for Hypothetical Vision-Language Reasoning Task",
    "volume": "findings",
    "abstract": "‘Actions' play a vital role in how humans interact with the world. Thus, autonomous agents that would assist us in everyday tasks also require the capability to perform ‘Reasoning about Actions & Change' (RAC). This has been an important research direction in Artificial Intelligence (AI) in general, but the study of RAC with visual and linguistic inputs is relatively recent. The CLEVR_HYP (Sampat et. al., 2021) is one such testbed for hypothetical vision-language reasoning with actions as the key focus. In this work, we propose a novel learning strategy that can improve reasoning about the effects of actions. We implement an encoder-decoder architecture to learn the representation of actions as vectors. We combine the aforementioned encoder-decoder architecture with existing modality parsers and a scene graph question answering model to evaluate our proposed system on the CLEVR_HYP dataset. We conduct thorough experiments to demonstrate the effectiveness of our proposed approach and discuss its advantages over previous baselines in terms of performance, data efficiency, and generalization capability",
    "checked": true,
    "id": "233c0974c5499036b2e9e41be7b9ebc68e58707a",
    "semantic_title": "learning action-effect dynamics for hypothetical vision-language reasoning task",
    "citation_count": 2,
    "authors": [
      "Shailaja Keyur Sampat",
      "Pratyay Banerjee",
      "Yezhou Yang",
      "Chitta Baral"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.437": {
    "title": "Named Entity and Relation Extraction with Multi-Modal Retrieval",
    "volume": "findings",
    "abstract": "Multi-modal named entity recognition (NER) and relation extraction (RE) aim to leverage relevant image information to improve the performance of NER and RE. Most existing efforts largely focused on directly extracting potentially useful information from images (such as pixel-level features, identified objects, and associated captions).However, such extraction processes may not be knowledge aware, resulting in information that may not be highly relevant. In this paper, we propose a novel Multi-modal Retrieval based framework (MoRe).MoRe contains a text retrieval module and an image-based retrieval module, which retrieve related knowledge of the input text and image in the knowledge corpus respectively. Next, the retrieval results are sent to the textual and visual models respectively for predictions. Finally, a Mixture of Experts (MoE) module combines the predictions from the two models to make the final decision. Our experiments show that both our textual model and visual model can achieve state-of-the-art performance on four multi-modal NER datasets and one multi-modal RE dataset. With MoE, the model performance can be further improved and our analysis demonstrates the benefits of integrating both textual and visual cues for such tasks",
    "checked": true,
    "id": "3697f22c3a6e6781ae72b2cae43cd64c5f7087e7",
    "semantic_title": "named entity and relation extraction with multi-modal retrieval",
    "citation_count": 24,
    "authors": [
      "Xinyu Wang",
      "Jiong Cai",
      "Yong Jiang",
      "Pengjun Xie",
      "Kewei Tu",
      "Wei Lu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.438": {
    "title": "Calibrating Factual Knowledge in Pretrained Language Models",
    "volume": "findings",
    "abstract": "Previous literature has proved that Pretrained Language Models (PLMs) can store factual knowledge. However, we find that facts stored in the PLMs are not always correct. It motivates us to explore a fundamental question: How do we calibrate factual knowledge in PLMs without re-training from scratch? In this work, we propose a simple and lightweight method CaliNet to achieve this goal. To be specific, we first detect whether PLMs can learn the right facts via a contrastive score between right and fake facts. If not, we then use a lightweight method to add and adapt new parameters to specific factual texts. Experiments on the knowledge probing task show the calibration effectiveness and efficiency. In addition, through closed-book question answering, we find that the calibrated PLM possesses knowledge generalization ability after finetuning.Beyond the calibration performance, we further investigate and visualize the knowledge calibration mechanism",
    "checked": true,
    "id": "7471cb40a33e9d971a922b5dff5ca9b4a73ca609",
    "semantic_title": "calibrating factual knowledge in pretrained language models",
    "citation_count": 39,
    "authors": [
      "Qingxiu Dong",
      "Damai Dai",
      "Yifan Song",
      "Jingjing Xu",
      "Zhifang Sui",
      "Lei Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.439": {
    "title": "MCPG: A Flexible Multi-Level Controllable Framework for Unsupervised Paraphrase Generation",
    "volume": "findings",
    "abstract": "We present MCPG: a simple and effectiveapproach for controllable unsupervised paraphrase generation, which is also flexible toadapt to specific domains without extra training. MCPG is controllable in different levels: local lexicons, global semantics, and universal styles. The unsupervised paradigm ofMCPG combines factual keywords and diversified semantic embeddings as local lexical andglobal semantic constraints. The semantic embeddings are diversified by standard dropout,which is exploited for the first time to increaseinference diversity by us. Moreover, MCPGis qualified with good domain adaptability byadding a transfer vector as a universal style constraint, which is refined from the exemplars retrieved from the corpus of the target domain in atraining-free way. Extensive experiments showthat MCPG outperforms state-of-the-art unsupervised baselines by a margin. Meanwhile,our domain-adapted MCPG also achieves competitive performance with strong supervisedbaselines even without training",
    "checked": true,
    "id": "211229221fd6c7ad711b5c10aba50bedc140aa13",
    "semantic_title": "mcpg: a flexible multi-level controllable framework for unsupervised paraphrase generation",
    "citation_count": 5,
    "authors": [
      "Yi Chen",
      "Haiyun Jiang",
      "Lemao Liu",
      "Rui Wang",
      "Shuming Shi",
      "Ruifeng Xu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.440": {
    "title": "WordTies: Measuring Word Associations in Language Models via Constrained Sampling",
    "volume": "findings",
    "abstract": "Word associations are widely used in psychology to provide insights on how humans perceive and understand concepts. Comparing word associations in language models (LMs) to those generated by human subjects can serve as a proxy to uncover embedded lexical and commonsense knowledge in language models. While much helpful work has been done applying direct metrics, such as cosine similarity, to help understand latent spaces, these metrics are symmetric, while human word associativity is asymmetric. We propose WordTies, an algorithm based on constrained sampling from LMs, which allows an asymmetric measurement of associated words, given a cue word as the input. Comparing to existing methods, word associations found by this method share more overlap with associations provided by humans, and observe the asymmetric property of human associations. To examine possible reasons behind associations, we analyze the knowledge and reasoning behind the word pairings as they are linked to lexical and commonsense knowledge graphs. When the knowledge about the nature of the word pairings is combined with a probability that the LM has learned that information, we have a new way to examine what information is captured in LMs",
    "checked": true,
    "id": "f434156f23afc7157b960e7de1746e2829445494",
    "semantic_title": "wordties: measuring word associations in language models via constrained sampling",
    "citation_count": 0,
    "authors": [
      "Peiran Yao",
      "Tobias Renwick",
      "Denilson Barbosa"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.441": {
    "title": "Exploring The Landscape of Distributional Robustness for Question Answering Models",
    "volume": "findings",
    "abstract": "We conduct a large empirical evaluation to investigate the landscape of distributional robustness in question answering. Our investigation spans over 350 models and 16 question answering datasets, including a diverse set of architectures, model sizes, and adaptation methods (e.g., fine-tuning, adapter tuning, in-context learning, etc.). We find that, in many cases, model variations do not affect robustness and in-distribution performance alone determines out-of-distribution performance. Moreover, our findings indicate thati) zero-shot and in-context learning methods are more robust to distribution shifts than fully fine-tuned models;ii) few-shot prompt fine-tuned models exhibit better robustness than few-shot fine-tuned span prediction models;iii) parameter-efficient and robustness enhancing training methods provide no significant robustness improvements. In addition, we publicly release all evaluations to encourage researchers to further analyze robustness trends for question answering models",
    "checked": true,
    "id": "7cf4f8cb8b4a373d869e785b79160dda7a49a250",
    "semantic_title": "exploring the landscape of distributional robustness for question answering models",
    "citation_count": 12,
    "authors": [
      "Anas Awadalla",
      "Mitchell Wortsman",
      "Gabriel Ilharco",
      "Sewon Min",
      "Ian Magnusson",
      "Hannaneh Hajishirzi",
      "Ludwig Schmidt"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.442": {
    "title": "Collaborative Reasoning on Multi-Modal Semantic Graphs for Video-Grounded Dialogue Generation",
    "volume": "findings",
    "abstract": "We study video-grounded dialogue generation, where a response is generated based on the dialogue context and the associated video. The primary challenges of this task lie in (1) the difficulty of integrating video data into pre-trained language models (PLMs) which presents obstacles to exploiting the power of large-scale pre-training; and (2) the necessity of taking into account the complementarity of various modalities throughout the reasoning process. Although having made remarkable progress in video-grounded dialogue generation, existing methods still fall short when it comes to integrating with PLMs in a way that allows information from different modalities to complement each other. To alleviate these issues, we first propose extracting pertinent information from videos and turning it into reasoning paths that are acceptable to PLMs. Additionally, we propose a multi-agent reinforcement learning method to collaboratively perform reasoning on different modalities (i.e., video and dialogue context). Empirical experiment results on two public datasets indicate that the proposed model can significantly outperform state-of-the-art models by large margins on both automatic and human evaluations",
    "checked": true,
    "id": "256fd60c692ebe12fe2bbf65d46722f511aa3117",
    "semantic_title": "collaborative reasoning on multi-modal semantic graphs for video-grounded dialogue generation",
    "citation_count": 3,
    "authors": [
      "Xueliang Zhao",
      "Yuxuan Wang",
      "Chongyang Tao",
      "Chenshuo Wang",
      "Dongyan Zhao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.443": {
    "title": "Partitioned Gradient Matching-based Data Subset Selection for Compute-Efficient Robust ASR Training",
    "volume": "findings",
    "abstract": "Training state-of-the-art ASR systems such as RNN-T often has a high associated financial and environmental cost. Training with a subset of training data could mitigate this problem if the subset selected could achieve on-par performance with training with the entire dataset. Although there are many data subset selection(DSS) algorithms, direct application to the RNN-T is difficult, especially the DSS algorithms that are adaptive and use learning dynamics such as gradients, as RNN-T tend to have gradients with a significantly larger memory footprint. In this paper, we propose Partitioned Gradient Matching (PGM) a novel distributable DSS algorithm, suitable for massive datasets like those used to train RNN-T. Through extensive experiments on Librispeech 100H and Librispeech 960H, we show that PGM achieves between 3x to 6x speedup with only a very small accuracy degradation (under 1% absolute WER difference). In addition, we demonstrate similar results for PGM even in settings where the training data is corrupted with noise",
    "checked": true,
    "id": "e320bded2fdcec07f9926cd3104a4a2cad7432ad",
    "semantic_title": "partitioned gradient matching-based data subset selection for compute-efficient robust asr training",
    "citation_count": 3,
    "authors": [
      "Ashish Mittal",
      "Durga Sivasubramanian",
      "Rishabh Iyer",
      "Preethi Jyothi",
      "Ganesh Ramakrishnan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.444": {
    "title": "Adaptive Graph Convolutional Network for Knowledge Graph Entity Alignment",
    "volume": "findings",
    "abstract": "Entity alignment (EA) aims to identify equivalent entities from different Knowledge Graphs (KGs), which is a fundamental task for integrating KGs. Throughout its development, Graph Convolutional Network (GCN) has become one of the mainstream methods for EA. These GCN-based methods learn the representations of entities from two KGs by message passing mechanism and then make alignments via measuring the similarity between entity embeddings. The key idea that GCN works in EA is that entities with similar neighbor structures are highly likely to be aligned. However, the noisy neighbors of entities transfer invalid information, drown out equivalent information, lead to inaccurate entity embeddings, and finally reduce the performance of EA. Based on the Sinkhorn algorithm, we design a reliability measure for potential equivalent entities and propose Adaptive Graph Convolutional Network to deal with neighbor noises in GCN. During the training, the network dynamically updates the adaptive weights of relation triples to weaken the propagation of noises. While calculating entity similarity, it comprehensively considers the self-similarity and neighborhood similarity of the entity pair to alleviate the influence of noises. Furthermore, we design a straightforward but efficient strategy to construct pseudo alignments for unsupervised EA. Extensive experiments on benchmark datasets demonstrate that our framework outperforms the state-of-the-art methods in both supervised and unsupervised settings",
    "checked": true,
    "id": "2cdebf9a19d32db7e15830ef823db2144372b133",
    "semantic_title": "adaptive graph convolutional network for knowledge graph entity alignment",
    "citation_count": 1,
    "authors": [
      "Renbo Zhu",
      "Xukun Luo",
      "Meng Ma",
      "Ping Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.445": {
    "title": "Towards Robust NLG Bias Evaluation with Syntactically-diverse Prompts",
    "volume": "findings",
    "abstract": "We present a robust methodology for evaluating biases in natural language generation(NLG) systems. Previous works use fixed hand-crafted prefix templates with mentions of various demographic groups to prompt models to generate continuations for bias analysis. These fixed prefix templates could themselves be specific in terms of styles or linguistic structures, which may lead to unreliable fairness conclusions that are not representative of the general trends from tone varying prompts. To study this problem, we paraphrase the prompts with different syntactic structures and use these to evaluate demographic bias in NLG systems. Our results suggest similar overall bias trends but some syntactic structures lead to contradictory conclusions compared to past works. We show that our methodology is more robust and that some syntactic structures prompt more toxic content while others could prompt less biased generation. This suggests the importance of not relying on a fixed syntactic structure and using tone-invariant prompts. Introducing syntactically-diverse prompts can achieve more robust NLG (bias) evaluation",
    "checked": true,
    "id": "4284c0ff47dc1c360dd9186f532e7e1716d2aa51",
    "semantic_title": "towards robust nlg bias evaluation with syntactically-diverse prompts",
    "citation_count": 3,
    "authors": [
      "Arshiya Aggarwal",
      "Jiao Sun",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.446": {
    "title": "PcMSP: A Dataset for Scientific Action Graphs Extraction from Polycrystalline Materials Synthesis Procedure Text",
    "volume": "findings",
    "abstract": "Scientific action graphs extraction from materials synthesis procedures is important for reproducible research, machine automation, and material prediction. But the lack of annotated data has hindered progress in this field. We demonstrate an effort to annotate Polycrystalline Materials Synthesis Procedures PcMSP from 305 open access scientific articles for the construction of synthesis action graphs. This is a new dataset for material science information extraction that simultaneously contains the synthesis sentences extracted from the experimental paragraphs, as well as the entity mentions and intra-sentence relations. A two-step human annotation and inter-annotator agreement study guarantee the high quality of the PcMSP corpus. We introduce four natural language processing tasks: sentence classification, named entity recognition, relation classification, and joint extraction of entities and relations. Comprehensive experiments validate the effectiveness of several state-of-the-art models for these challenges while leaving large space for improvement. We also perform the error analysis and point out some unique challenges that require further investigation. We will release our annotation scheme, the corpus, and codes to the research community to alleviate the scarcity of labeled data in this domain",
    "checked": true,
    "id": "36790bd387ccc069d3c1a8986bb0cb166d056672",
    "semantic_title": "pcmsp: a dataset for scientific action graphs extraction from polycrystalline materials synthesis procedure text",
    "citation_count": 4,
    "authors": [
      "Xianjun Yang",
      "Ya Zhuo",
      "Julia Zuo",
      "Xinlu Zhang",
      "Stephen Wilson",
      "Linda Petzold"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.447": {
    "title": "Validity Assessment of Legal Will Statements as Natural Language Inference",
    "volume": "findings",
    "abstract": "This work introduces a natural language inference (NLI) dataset that focuses on the validity of statements in legal wills. This dataset is unique because: (a) each entailment decision requires three inputs: the statement from the will, the law, and the conditions that hold at the time of the testator's death; and (b) the included texts are longer than the ones in current NLI datasets. We trained eight neural NLI models in this dataset. All the models achieve more than 80% macro F1 and accuracy, which indicates that neural approaches can handle this task reasonably well. However, group accuracy, a stricter evaluation measure that is calculated with a group of positive and negative examples generated from the same statement as a unit, is in mid 80s at best, which suggests that the models' understanding of the task remains superficial. Further ablative analyses and explanation experiments indicate that all three text segments are used for prediction, but some decisions rely on semantically irrelevant tokens. This indicates that overfitting on these longer texts likely happens, and that additional research is required for this task to be solved",
    "checked": true,
    "id": "9e6d3cb1249f17a419b3b6140d30a9e1e4b8314d",
    "semantic_title": "validity assessment of legal will statements as natural language inference",
    "citation_count": 2,
    "authors": [
      "Alice Kwak",
      "Jacob Israelsen",
      "Clayton Morrison",
      "Derek Bambauer",
      "Mihai Surdeanu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.448": {
    "title": "AdaPrompt: Adaptive Model Training for Prompt-based NLP",
    "volume": "findings",
    "abstract": "Prompt-based learning, with its capability to tackle zero-shot and few-shot NLP tasks, has gained much attention in the community. The main idea is to bridge the gap between NLP downstream tasks and language modeling (LM), by mapping these tasks into natural language prompts, which are then filled by pre-trained language models (PLMs).However, for prompt learning, there are still two salient gaps between NLP tasks and pretraining. First, prompt information is not necessarily sufficiently present during LM pre-training. Second, task-specific data are not necessarily well represented during pre-training. We address these two issues by proposing AdaPrompt, adaptively retrieving external data for continual pretraining of PLMs by making use of both task and prompt characteristics. In addition, we make use of knowledge in Natural Language Inference models for deriving adaptive verbalizers.Experimental results on five NLP benchmarks show that AdaPrompt can improve over standard PLMs in few-shot settings. In addition, in zero-shot settings, our method outperforms standard prompt-based methods by up to 26.35% relative error reduction",
    "checked": true,
    "id": "d235a9085e0543fcbe502fbc269f9a8ee01dcbab",
    "semantic_title": "adaprompt: adaptive model training for prompt-based nlp",
    "citation_count": 33,
    "authors": [
      "Yulong Chen",
      "Yang Liu",
      "Li Dong",
      "Shuohang Wang",
      "Chenguang Zhu",
      "Michael Zeng",
      "Yue Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.449": {
    "title": "Code Generation From Flowcharts with Texts: A Benchmark Dataset and An Approach",
    "volume": "findings",
    "abstract": "Currently, researchers focus on generating codes from the requirement documents. However, current approaches still perform poorly on some requirements needing complex problem-solving skills. In reality, to tackle such complex requirements, instead of directly translating requirement documents into codes, software engineers write codes via unified modeling language diagrams, such as flowcharts, an intermediate tool to analyze and visualize the system. Therefore, we propose a new source code generation task, that is, to generate source code from flowcharts with texts. We manually construct a benchmark dataset containing 320 flowcharts with their corresponding source codes. Obviously, it is not straightforward to employ the current approaches for the new source code generation task since (1) the flowchart is a graph that contains various structures, including loop, selection, and others which is different from texts; (2) the connections between nodes in the flowchart are abundant and diverse which need to be carefully handled. To solve the above problems, we propose a two-stage code generation model. In the first stage, a structure recognition algorithm is employed to transform the flowchart into pseudo-code containing the structural conventions of a typical programming language such as while, if. In the second stage, a code generation model is employed to convert the pseudo-code into code. Experimental results show that the proposed approach can achieve some improvement over the baselines",
    "checked": true,
    "id": "f6c47d6902d0941a6cf489ee971643bf1d50275e",
    "semantic_title": "code generation from flowcharts with texts: a benchmark dataset and an approach",
    "citation_count": 1,
    "authors": [
      "Zejie Liu",
      "Xiaoyu Hu",
      "Deyu Zhou",
      "Lin Li",
      "Xu Zhang",
      "Yanzheng Xiang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.450": {
    "title": "Focus! Relevant and Sufficient Context Selection for News Image Captioning",
    "volume": "findings",
    "abstract": "News Image Captioning requires describing an image by leveraging additional context derived from a news article. Previous works only coarsely leverage the article to extract the necessary context, which makes it challenging for models to identify relevant events and named entities. In our paper, we first demonstrate that by combining more fine-grained context that captures the key named entities (obtained via an oracle) and the global context that summarizes the news, we can dramatically improve the model's ability to generate accurate news captions. This begs the question, how to automatically extract such key entities from an image? We propose to use pre-trained vision and language retrieval model CLIP to localize the visually grounded entities in the news article, and then capture the non-visual entities via a open relation extraction model. Our experiments demonstrate that by simply selecting better context from the article, we can significantly improve the performance of existing models and achieve the new state-of-the-art performance on multiple benchmarks",
    "checked": true,
    "id": "7ec49b2cb2cd31541de39d9cac82120ffc3455b9",
    "semantic_title": "focus! relevant and sufficient context selection for news image captioning",
    "citation_count": 4,
    "authors": [
      "Mingyang Zhou",
      "Grace Luo",
      "Anna Rohrbach",
      "Zhou Yu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.451": {
    "title": "Generative Aspect-Based Sentiment Analysis with Contrastive Learning and Expressive Structure",
    "volume": "findings",
    "abstract": "Generative models have demonstrated impressive results on Aspect-based Sentiment Analysis (ABSA) tasks, particularly for the emerging task of extracting Aspect-Category-Opinion-Sentiment (ACOS) quadruples. However, these models struggle with implicit sentiment expressions, which are commonly observed in opinionated content such as online reviews. In this work, we introduce GEN-SCL-NAT, which consists of two techniques for improved structured generation for ACOS quadruple extraction. First, we propose GEN-SCL, a supervised contrastive learning objective that aids quadruple prediction by encouraging the model to produce input representations that are discriminable across key input attributes, such as sentiment polarity and the existence of implicit opinions and aspects. Second, we introduce GEN-NAT, a new structured generation format that better adapts pre-trained autoregressive encoder-decoder models to extract quadruples in a generative fashion. Experimental results show that GEN-SCL-NAT achieves top performance across three ACOS datasets, averaging 1.48% F1 improvement, with a maximum 1.73% increase on the LAPTOP-L1 dataset. Additionally, we see significant gains on implicit aspect and opinion splits that have been shown as challenging for existing ACOS approaches",
    "checked": true,
    "id": "34c6b66ef95bb041795c13eb23b8af1c17d13975",
    "semantic_title": "generative aspect-based sentiment analysis with contrastive learning and expressive structure",
    "citation_count": 12,
    "authors": [
      "Joseph Peper",
      "Lu Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.452": {
    "title": "Semantic Dependency Parsing with Edge GNNs",
    "volume": "findings",
    "abstract": "Second-order neural parsers have obtained high accuracy in semantic dependency parsing. Inspired by the factor graph representation of second-order parsing, we propose edge graph neural networks (E-GNNs). In an E-GNN, each node corresponds to a dependency edge, and the neighbors are defined in terms of sibling, co-parent, and grandparent relationships. We conduct experiments on SemEval 2015 Task 18 English datasets, showing the superior performance of E-GNNs",
    "checked": true,
    "id": "1ca272c92e23f0be14f43d208853806b6548d591",
    "semantic_title": "semantic dependency parsing with edge gnns",
    "citation_count": 2,
    "authors": [
      "Songlin Yang",
      "Kewei Tu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.453": {
    "title": "Explore Unsupervised Structures in Pretrained Models for Relation Extraction",
    "volume": "findings",
    "abstract": "Syntactic trees have been widely applied in relation extraction (RE). However, since parsing qualities are not stable on different text domains and a pre-defined grammar may not well fit the target relation schema, the introduction of syntactic structures sometimes fails to improve RE performances consistently. In this work, we study RE models with various unsupervised structures mined from pre-trained language models (e.g., BERT). We show that, similar to syntactic trees, unsupervised structures are quite informative for RE task: they are able to obtain competitive (even the best) performance scores on benchmark RE datasets (ACE05, WebNLG, SciERC). We also conduct detailed analyses on their abilities of adapting new RE domains and influence of noise links in those structures. The results suggest that unsupervised structures are reasonable alternatives of commonly used syntactic structures in relation extraction models",
    "checked": true,
    "id": "314ef35fc6c02596887524f384010519cbcd613c",
    "semantic_title": "explore unsupervised structures in pretrained models for relation extraction",
    "citation_count": 0,
    "authors": [
      "Xi Yang",
      "Tao Ji",
      "Yuanbin Wu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.454": {
    "title": "Identifying Human Strategies for Generating Word-Level Adversarial Examples",
    "volume": "findings",
    "abstract": "Adversarial examples in NLP are receiving increasing research attention. One line of investigation is the generation of word-level adversarial examples against fine-tuned Transformer models that preserve naturalness and grammaticality. Previous work found that human- and machine-generated adversarial examples are comparable in their naturalness and grammatical correctness. Most notably, humans were able to generate adversarial examples much more effortlessly than automated attacks. In this paper, we provide a detailed analysis of exactly how humans create these adversarial examples. By exploring the behavioural patterns of human workers during the generation process, we identify statistically significant tendencies based on which words humans prefer to select for adversarial replacement (e.g., word frequencies, word saliencies, sentiment) as well as where and when words are replaced in an input sequence. With our findings, we seek to inspire efforts that harness human strategies for more robust NLP models",
    "checked": true,
    "id": "ec09a2233b8f42388875af500dd868ec91f8495e",
    "semantic_title": "identifying human strategies for generating word-level adversarial examples",
    "citation_count": 0,
    "authors": [
      "Maximilian Mozes",
      "Bennett Kleinberg",
      "Lewis Griffin"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.455": {
    "title": "Refinement Matters: Textual Description Needs to be Refined for Zero-shot Learning",
    "volume": "findings",
    "abstract": "Zero-Shot Learning (ZSL) has shown great promise at the intersection of vision and language, and generative methods for ZSL are predominant owing to their efficiency. Moreover, textual description or attribute plays a critical role in transferring knowledge from the seen to unseen classes in ZSL. Such generative approaches for ZSL are very costly to train and require the class description of the unseen classes during training. In this work, we propose a non-generative gating-based attribute refinement network for ZSL, which achieves similar accuracies to generative methods of ZSL, at a much lower computational cost. The refined attributes are mapped into the visual domain through an attribute embedder, and the whole network is guided by the circle loss and the well-known softmax cross-entropy loss to obtain a robust class embedding. We refer to our approach as Circle loss guided gating-based Attribute-Refinement Network (CARNet). We perform extensive experiments on the five benchmark datasets over the various challenging scenarios viz., Generalized ZSL (GZSL), Continual GZSL (CGZSL), and conventional ZSL. We observe that the CARNet significantly outperforms recent non-generative ZSL methods and most generative ZSL methods in all three settings by a significant margin. Our extensive ablation study disentangles the performance of various components and justifies their importance. The source code is available at https://github.com/Sethup123/CARNet",
    "checked": true,
    "id": "46548d417772ddf30efd76c96872f23c9ef21ea1",
    "semantic_title": "refinement matters: textual description needs to be refined for zero-shot learning",
    "citation_count": 2,
    "authors": [
      "Chandan Gautam",
      "Sethupathy Parameswaran",
      "Vinay Verma",
      "Suresh Sundaram",
      "Savitha Ramasamy"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.456": {
    "title": "SAT: Improving Semi-Supervised Text Classification with Simple Instance-Adaptive Self-Training",
    "volume": "findings",
    "abstract": "Self-training methods have been explored in recent years and have exhibited great performance in improving semi-supervised learning. This work presents a simple instance-adaptive self-training method (SAT) for semi-supervised text classification. SAT first generates two augmented views for each unlabeled data, and then trains a meta learner to automatically identify the relative strength of augmentations based on the similarity between the original view and the augmented views. The weakly-augmented view is fed to the model to produce a pseudo-label and the strongly-augmented view is used to train the model to predict the same pseudo-label. We conducted extensive experiments and analyses on three text classification datasets and found that with varying sizes of labeled training data, SAT consistently shows competitive performance compared to existing semi-supervised learning methods",
    "checked": true,
    "id": "449e78b387f6dec6aae1ae629eb7ae4e28ee79a4",
    "semantic_title": "sat: improving semi-supervised text classification with simple instance-adaptive self-training",
    "citation_count": 4,
    "authors": [
      "Hui Chen",
      "Wei Han",
      "Soujanya Poria"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.457": {
    "title": "Answer Quality Aware Aggregation for Extractive QA Crowdsourcing",
    "volume": "findings",
    "abstract": "Quality control is essential for creating extractive question answering (EQA) datasets via crowdsourcing. Aggregation across answers, i.e. word spans within passages annotated, by different crowd workers is one major focus for ensuring its quality. However, crowd workers cannot reach a consensus on a considerable portion of questions. We introduce a simple yet effective answer aggregation method that takes into account the relations among the answer, question, and context passage. We evaluate answer quality from both the view of question answering model to determine how confident the QA model is about each answer and the view of the answer verification model to determine whether the answer is correct. Then we compute aggregation scores with each answer's quality and its contextual embedding produced by pre-trained language models. The experiments on a large real crowdsourced EQA dataset show that our framework outperforms baselines by around 16% on precision and effectively conduct answer aggregation for extractive QA task",
    "checked": true,
    "id": "fa43816c8ca3f796f9c7a42bcba0b0993baec22f",
    "semantic_title": "answer quality aware aggregation for extractive qa crowdsourcing",
    "citation_count": 0,
    "authors": [
      "Peide Zhu",
      "Zhen Wang",
      "Claudia Hauff",
      "Jie Yang",
      "Avishek Anand"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.458": {
    "title": "Search to Pass Messages for Temporal Knowledge Graph Completion",
    "volume": "findings",
    "abstract": "Completing missing facts is a fundamental task for temporal knowledge graphs (TKGs).Recently, graph neural network (GNN) based methods, which can simultaneously explore topological and temporal information, have become the state-of-the-art (SOTA) to complete TKGs. However, these studies are based on hand-designed architectures and fail to explore the diverse topological and temporal properties of TKG.To address this issue, we propose to use neural architecture search (NAS) to design data-specific message passing architecture for TKG completion. In particular, we develop a generalized framework to explore topological and temporal information in TKGs.Based on this framework, we design an expressive search space to fully capture various properties of different TKGs. Meanwhile, we adopt a search algorithm, which trains a supernet structure by sampling single path for efficient search with less cost. We further conduct extensive experiments on three benchmark datasets. The results show that the searched architectures by our method achieve the SOTA performances. Besides, the searched models can also implicitly reveal diverse properties in different TKGs.Our code is released in https://github.com/striderdu/SPA",
    "checked": true,
    "id": "e3323ec83a4dc3292673c9f38afaaa2bc44f510a",
    "semantic_title": "search to pass messages for temporal knowledge graph completion",
    "citation_count": 5,
    "authors": [
      "Zhen Wang",
      "Haotong Du",
      "Quanming Yao",
      "Xuelong Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.459": {
    "title": "Code Vulnerability Detection via Nearest Neighbor Mechanism",
    "volume": "findings",
    "abstract": "Code vulnerability detection is a fundamental and challenging task in the software security field. Existing research works aim to learn semantic information from the source code by utilizing NLP technologies. However, in vulnerability detection tasks, some vulnerable samples are very similar to non-vulnerable samples, which are difficult to identify. To address this issue and improve detection performance, we introduce the k-nearest neighbor mechanism which retrieves multiple neighbor samples and utilizes label information of retrieved neighbor samples to provide help for model predictions. Besides, we use supervised contrastive learning to make the model learn the discriminative representation and ensure that label information of retrieved neighbor samples is as consistent as possible with the label information of testing samples. Extensive experiments show that our method can achieve obvious performance improvements compared to baseline models",
    "checked": true,
    "id": "e809760fc5f60d9ad5fb729fad3df6a368eab73d",
    "semantic_title": "code vulnerability detection via nearest neighbor mechanism",
    "citation_count": 0,
    "authors": [
      "Qianjin Du",
      "Xiaohui Kuang",
      "Gang Zhao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.460": {
    "title": "Robust Question Answering against Distribution Shifts with Test-Time Adaption: An Empirical Study",
    "volume": "findings",
    "abstract": "A deployed question answering (QA) model can easily fail when the test data has a distribution shift compared to the training data. Robustness tuning (RT) methods have been widely studied to enhance model robustness against distribution shifts before model deployment. However, can we improve a model after deployment? To answer this question, we evaluate test-time adaptation (TTA) to improve a model after deployment. We first introduce ColdQA, a unified evaluation benchmark for robust QA against text corruption and changes in language and domain. We then evaluate previous TTA methods on ColdQA and compare them to RT methods. We also propose a novel TTA method called online imitation learning (OIL). Through extensive experiments, we find that TTA is comparable to RT methods, and applying TTA after RT can significantly boost the performance on ColdQA. Our proposed OIL improves TTA to be more robust to variation in hyper-parameters and test distributions over time",
    "checked": true,
    "id": "420b63b3c0252b405820d1d937398d825c53ff76",
    "semantic_title": "robust question answering against distribution shifts with test-time adaption: an empirical study",
    "citation_count": 5,
    "authors": [
      "Hai Ye",
      "Yuyang Ding",
      "Juntao Li",
      "Hwee Tou Ng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.461": {
    "title": "ParaMac: A General Unsupervised Paraphrase Generation Framework Leveraging Semantic Constraints and Diversifying Mechanisms",
    "volume": "findings",
    "abstract": "Paraphrase generation reflects the ability to understand the meaning from the language surface form and rephrase it to other expressions. Recent paraphrase generation works have paid attention to unsupervised approaches based on Pre-trained Language Models (PLMs) to avoid heavy reliance on parallel data by utilizing PLMs' generation ability. However, the generated pairs of existing unsupervised methods are usually weak either in semantic equivalence or expression diversity. In this paper, we present a novel unsupervised paraphrase generation framework called Paraphrase Machine. By employing multi-aspect equivalence constraints and multi-granularity diversifying mechanisms, Paraphrase Machine is able to achieve good semantic equivalence and expressive diversity, producing a high-quality unsupervised paraphrase dataset. Based on this dataset, we train a general paraphrase model, which can be directly applied to rewrite the input sentence of various domains without any fine-tuning, and achieves substantial gains of 9.1% and 3.3% absolutely in BLEU score over previous SOTA on Quora and MSCOCO. By further fine-tuning our model with domain-specific training sets, the improvement can be increased to even 18.0% and 4.6%. Most importantly, by applying it to language understanding and generation tasks under the low-resource setting, we demonstrate that our model can serve as a universal data augmentor to boost the few-shot performance (e.g., average 2.0% gain on GLUE)",
    "checked": true,
    "id": "4175e843806d10709cd3476b9e41f0fc59a61f7b",
    "semantic_title": "paramac: a general unsupervised paraphrase generation framework leveraging semantic constraints and diversifying mechanisms",
    "citation_count": 1,
    "authors": [
      "Jinxin Liu",
      "Jiaxin Shi",
      "Ji Qi",
      "Lei Hou",
      "Juanzi Li",
      "Qi Tian"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.462": {
    "title": "Semi-supervised New Slot Discovery with Incremental Clustering",
    "volume": "findings",
    "abstract": "Discovering new slots is critical to the success of dialogue systems. Most existing methods rely on automatic slot induction in unsupervised fashion or perform domain adaptation across zero or few-shot scenarios. They have difficulties in providing high-quality supervised signals to learn clustering-friendly features, and are limited in effectively transferring the prior knowledge from known slots to new slots. In this work, we propose a Semi-supervised Incremental Clustering method (SIC), to discover new slots with the aid of existing linguistic annotation models and limited known slot data. Specifically, we harvest slot value candidates with NLP model cues and innovatively formulate the slot discovery task under an incremental clustering framework. The model gradually calibrate slot representations under the supervision of generated pseudo-labels, and automatically learns to terminate when no more salient slot remains. Our thorough evaluation on five public datasets demonstrates that it significantly outperforms state-of-the-art models",
    "checked": true,
    "id": "9ed2c409d71b6e824f55a5390c42d4af0e68682e",
    "semantic_title": "semi-supervised new slot discovery with incremental clustering",
    "citation_count": 3,
    "authors": [
      "Yuxia Wu",
      "Lizi Liao",
      "Xueming Qian",
      "Tat-Seng Chua"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.463": {
    "title": "Con-NAT: Contrastive Non-autoregressive Neural Machine Translation",
    "volume": "findings",
    "abstract": "Inspired by the success of contrastive learning in natural language processing, we incorporate contrastive learning into the conditional masked language model which is extensively used in non-autoregressive neural machine translation (NAT). Accordingly, we propose a Contrastive Non-autoregressive Neural Machine Translation (Con-NAT) model. Con-NAT optimizes the similarity of several different representations of the same token in the same sentence. We propose two methods to obtain various representations: Contrastive Common Mask and Contrastive Dropout. Positive pairs are various different representations of the same token, while negative pairs are representations of different tokens. In the feature space, the model with contrastive loss pulls positive pairs together and pushes negative pairs away. We conduct extensive experiments on six translation directions with different data sizes. The results demonstrate that Con-NAT showed a consistent and significant improvement in fully and iterative NAT. Con-NAT is state-of-the-art on WMT'16 Ro-En (34.18 BLEU)",
    "checked": true,
    "id": "23b7c657fd3320075e22610bb3f7b1c3ca3a69bc",
    "semantic_title": "con-nat: contrastive non-autoregressive neural machine translation",
    "citation_count": 1,
    "authors": [
      "Hao Cheng",
      "Zhihua Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.464": {
    "title": "Improved Knowledge Distillation for Pre-trained Language Models via Knowledge Selection",
    "volume": "findings",
    "abstract": "Knowledge distillation addresses the problem of transferring knowledge from a teacher model to a student model. In this process, we typically have multiple types of knowledge extracted from the teacher model. The problem is to make full use of them to train the student model. Our preliminary study shows that: (1) not all of the knowledge is necessary for learning a good student model, and (2) knowledge distillation can benefit from certain knowledge at different training steps. In response to these, we propose an actor-critic approach to selecting appropriate knowledge to transfer during the process of knowledge distillation. In addition, we offer a refinement of the training algorithm to ease the computational burden. Experimental results on the GLUE datasets show that our method outperforms several strong knowledge distillation baselines significantly",
    "checked": true,
    "id": "71a8cf9781ac17b3c2ae89f0f2965a05fe1872c3",
    "semantic_title": "improved knowledge distillation for pre-trained language models via knowledge selection",
    "citation_count": 3,
    "authors": [
      "Chenglong Wang",
      "Yi Lu",
      "Yongyu Mu",
      "Yimin Hu",
      "Tong Xiao",
      "Jingbo Zhu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.465": {
    "title": "Syntactically Robust Training on Partially-Observed Data for Open Information Extraction",
    "volume": "findings",
    "abstract": "Open Information Extraction models have shown promising results with sufficient supervision. However, these models face a fundamental challenge that the syntactic distribution of training data is partially observable in comparison to the real world. In this paper, we propose a syntactically robust training framework that enables models to be trained on a syntactic-abundant distribution based on diverse paraphrase generation. To tackle the intrinsic problem of knowledge deformation of paraphrasing, two algorithms based on semantic similarity matching and syntactic tree walking are used to restore the expressionally transformed knowledge. The training framework can be generally applied to other syntactic partial observable domains. Based on the proposed framework, we build a new evaluation set called CaRB-AutoPara, a syntactically diverse dataset consistent with the real-world setting for validating the robustness of the models. Experiments including a thorough analysis show that the performance of the model degrades with the increase of the difference in syntactic distribution, while our framework gives a robust boundary",
    "checked": true,
    "id": "bdb32ea23986f6dfe436c5dba0d13e95dea07c92",
    "semantic_title": "syntactically robust training on partially-observed data for open information extraction",
    "citation_count": 4,
    "authors": [
      "Ji Qi",
      "Yuxiang Chen",
      "Lei Hou",
      "Juanzi Li",
      "Bin Xu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.466": {
    "title": "A Benchmark and Dataset for Post-OCR text correction in Sanskrit",
    "volume": "findings",
    "abstract": "Sanskrit is a classical language with about 30 million extant manuscripts fit for digitisation, available in written, printed or scanned-image forms. However, it is still considered to be a low-resource language when it comes to available digital resources. In this work, we release a post-OCR text correction dataset containing around 218,000 sentences, with 1.5 million words, from 30 different books. Texts in Sanskrit are known to be diverse in terms of their linguistic and stylistic usage since Sanskrit was the ‘lingua francua' for discourse in the Indian subcontinent for about 3 millennia. Keeping this in mind, we release a multi-domain dataset, from areas as diverse as astronomy, medicine and mathematics, with some of them as old as 18 centuries. Further, we release multiple strong baselines as benchmarks for the task, based on pre-trained Seq2Seq language models. We find that our best-performing model, consisting of byte level tokenization in conjunction with phonetic encoding (Byt5+SLP1), yields a 23% point increase over the OCR output in terms of word and character error rates. Moreover, we perform extensive experiments in evaluating these models on their performance and analyse common causes of mispredictions both at the graphemic and lexical levels. Our code and dataset is publicly available at https://github.com/ayushbits/pe-ocr-sanskrit",
    "checked": true,
    "id": "d50b9db750ded246bde13e2c263e341bcbd8a335",
    "semantic_title": "a benchmark and dataset for post-ocr text correction in sanskrit",
    "citation_count": 5,
    "authors": [
      "Ayush Maheshwari",
      "Nikhil Singh",
      "Amrith Krishna",
      "Ganesh Ramakrishnan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.467": {
    "title": "Knowledge-Enhanced Self-Supervised Prototypical Network for Few-Shot Event Detection",
    "volume": "findings",
    "abstract": "Prototypical network based joint methods have attracted much attention in few-shot event detection, which carry out event detection in a unified sequence tagging framework. However, these methods suffer from the inaccurate prototype representation problem, due to two main reasons: the number of instances for calculating prototypes is limited; And, they do not well capture the relationships among event prototypes. To deal with this problem, we propose a Knowledge-Enhanced self-supervised Prototypical Network, called KE-PN, for few-shot event detection. KE-PN adopts hybrid rules, which can automatically align event types to an external knowledge base, i.e., FrameNet, to obtain more instances. It proposes a self-supervised learning method to filter out noisy data from enhanced instances. KE-PN is further equipped with an auxiliary event type relationship classification module, which injects the relationship information into representations of event prototypes. Extensive experiments on three benchmark datasets, i.e., FewEvent, MAVEN, and ACE2005 demonstrate the state-of-the-art performance of KE-PN",
    "checked": true,
    "id": "22c7cff794093cfd14123fb2c3bc3aaa2713ebe3",
    "semantic_title": "knowledge-enhanced self-supervised prototypical network for few-shot event detection",
    "citation_count": 9,
    "authors": [
      "Kailin Zhao",
      "Xiaolong Jin",
      "Long Bai",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.468": {
    "title": "VarMAE: Pre-training of Variational Masked Autoencoder for Domain-adaptive Language Understanding",
    "volume": "findings",
    "abstract": "Pre-trained language models have been widely applied to standard benchmarks. Due to the flexibility of natural language, the available resources in a certain domain can be restricted to support obtaining precise representation. To address this issue, we propose a novel Transformer-based language model named VarMAE for domain-adaptive language understanding. Under the masked autoencoding objective, we design a context uncertainty learning module to encode the token's context into a smooth latent distribution. The module can produce diverse and well-formed contextual representations. Experiments on science- and finance-domain NLU tasks demonstrate that VarMAE can be efficiently adapted to new domains with limited resources",
    "checked": true,
    "id": "7e0fda71cc2e561385c0a2e29f5a81654a11157f",
    "semantic_title": "varmae: pre-training of variational masked autoencoder for domain-adaptive language understanding",
    "citation_count": 5,
    "authors": [
      "Dou Hu",
      "Xiaolong Hou",
      "Xiyang Du",
      "Mengyuan Zhou",
      "Lianxin Jiang",
      "Yang Mo",
      "Xiaofeng Shi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.469": {
    "title": "Exploring Methods for Building Dialects-Mandarin Code-Mixing Corpora: A Case Study in Taiwanese Hokkien",
    "volume": "findings",
    "abstract": "In natural language processing (NLP), code-mixing (CM) is a challenging task, especially when the mixed languages include dialects. In Southeast Asian countries such as Singapore, Indonesia, and Malaysia, Hokkien-Mandarin is the most widespread code-mixed language pair among Chinese immigrants, and it is also common in Taiwan. However, dialects such as Hokkien often have a scarcity of resources and the lack of an official writing system, limiting the development of dialect CM research. In this paper, we propose a method to construct a Hokkien-Mandarin CM dataset to mitigate the limitation, overcome the morphological issue under the Sino-Tibetan language family, and offer an efficient Hokkien word segmentation method through a linguistics-based toolkit. Furthermore, we use our proposed dataset and employ transfer learning to train the XLM (cross-lingual language model) for translation tasks. To fit the code-mixing scenario, we adapt XLM slightly. We found that by using linguistic knowledge, rules, and language tags, the model produces good results on CM data translation while maintaining monolingual translation quality",
    "checked": true,
    "id": "d61fa07c5a7cbaab5723acbe433fab68d4ada56e",
    "semantic_title": "exploring methods for building dialects-mandarin code-mixing corpora: a case study in taiwanese hokkien",
    "citation_count": 3,
    "authors": [
      "Sin-En Lu",
      "Bo-Han Lu",
      "Chao-Yi Lu",
      "Richard Tzong-Han Tsai"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.470": {
    "title": "Recurrence Boosts Diversity! Revisiting Recurrent Latent Variable in Transformer-Based Variational AutoEncoder for Diverse Text Generation",
    "volume": "findings",
    "abstract": "Variational Auto-Encoder (VAE) has been widely adopted in text generation. Among many variants, recurrent VAE learns token-wise latent variables with each conditioned on the preceding ones, which captures sequential variability better in the era of RNN. However, it is unclear how to incorporate such recurrent dynamics into the recently dominant Transformer due to its parallelism. In this work, we propose TRACE, a Transformer-based recurrent VAE structure. TRACE imposes recurrence on segment-wise latent variables with arbitrarily separated text segments and constructs the posterior distribution with residual parameterization. Besides, we design an acceleration method by approximating idempotent matrices, which allows parallelism while maintaining the conditional dependence of latent variables. We demonstrate that TRACE could deduce a non-zero lower bound of the KL term and enhance the entanglement of each segment and preceding latent variables, providing a theoretical guarantee of generation diversity. Experiments on two unconditional and one conditional generation task show that TRACE achieves significantly improved diversity while maintaining satisfactory generation quality",
    "checked": true,
    "id": "503ae39c110d298a453259b1b72ee831a9bb0488",
    "semantic_title": "recurrence boosts diversity! revisiting recurrent latent variable in transformer-based variational autoencoder for diverse text generation",
    "citation_count": 0,
    "authors": [
      "Jinyi Hu",
      "Xiaoyuan Yi",
      "Wenhao Li",
      "Maosong Sun",
      "Xing Xie"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.471": {
    "title": "Tweet Based Reach Aware Temporal Attention Network for NFT Valuation",
    "volume": "findings",
    "abstract": "Non-Fungible Tokens (NFTs) are a relatively unexplored class of assets. Designing strategies to forecast NFT trends is an intricate task due to its extremely volatile nature. The market is largely driven by public sentiment and \"hype\", which in turn has a high correlation with conversations taking place on social media platforms like Twitter. Prior work done for modelling stock market data does not take into account the extent of impact certain highly influential tweets and their authors can have on the market. Building on these limitations and the nature of the NFT market, we propose a novel reach-aware temporal learning approach to make predictions for forecasting future trends in the NFT market. We perform experiments on a new dataset consisting of over 1.3 million tweets and 180 thousand NFT transactions spanning over 15 NFT collections curated by us. Our model (TA-NFT) outperforms other state-of-the-art methods by an average of 36%. Through extensive quantitative and ablative analysis, we demonstrate the ability of our approach as a practical method for predicting NFT trends",
    "checked": true,
    "id": "2009939f7f8adff27164debdb3c6f0455076b266",
    "semantic_title": "tweet based reach aware temporal attention network for nft valuation",
    "citation_count": 6,
    "authors": [
      "Ramit Sawhney",
      "Megh Thakkar",
      "Ritesh Soun",
      "Atula Neerkaje",
      "Vasu Sharma",
      "Dipanwita Guhathakurta",
      "Sudheer Chava"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.472": {
    "title": "Entity Embedding Completion for Wide-Coverage Entity Disambiguation",
    "volume": "findings",
    "abstract": "Entity disambiguation (ED) is typically solved by learning to classify a given mention into one of the entities in the model's entity vocabulary by referring to their embeddings. However, this approach cannot address mentions of entities that are not covered by the entity vocabulary. Aiming to enhance the applicability of ED models, we propose a method of extending a state-of-the-art ED model by dynamically computing embeddings of out-of-vocabulary entities. Specifically, our method computes embeddings from entity descriptions and mention contexts. Experiments with standard benchmark datasets show that the extended model performs comparable to or better than existing models whose entity embeddings are trained for all candidate entities as well as embedding-free models. We release our source code and model checkpoints at https://github.com/studio-ousia/steel",
    "checked": true,
    "id": "976014b9c061fdc89d950e989be44e71d575cb5b",
    "semantic_title": "entity embedding completion for wide-coverage entity disambiguation",
    "citation_count": 1,
    "authors": [
      "Daisuke Oba",
      "Ikuya Yamada",
      "Naoki Yoshinaga",
      "Masashi Toyoda"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.473": {
    "title": "Entity-level Interaction via Heterogeneous Graph for Multimodal Named Entity Recognition",
    "volume": "findings",
    "abstract": "Multimodal Named Entity Recognition (MNER) faces two specific challenges: 1) How to capture useful entity-related visual information. 2) How to alleviate the interference of visual noise. Previous works have gained progress by improving interacting mechanisms or seeking for better visual features. However, existing methods neglect the integrity of entity semantics and conduct cross-modal interaction at token-level, which cuts apart the semantics of entities and makes non-entity tokens easily interfered with by irrelevant visual noise. Thus in this paper, we propose an end-to-end heterogeneous Graph-based Entity-level Interacting model (GEI) for MNER. GEI first utilizes a span detection subtask to obtain entity representations, which serve as the bridge between two modalities. Then, the heterogeneous graph interacting network interacts entity with object nodes to capture entity-related visual information, and fuses it into only entity-associated tokens to rid non-entity tokens of the visual noise. Experiments on two widely used datasets demonstrate the effectiveness of our method. Our code will be available at https://github.com/GangZhao98/GEI",
    "checked": true,
    "id": "0ad6b20b68b4fb06037c773c1115c56e0bbd5bfa",
    "semantic_title": "entity-level interaction via heterogeneous graph for multimodal named entity recognition",
    "citation_count": 9,
    "authors": [
      "Gang Zhao",
      "Guanting Dong",
      "Yidong Shi",
      "Haolong Yan",
      "Weiran Xu",
      "Si Li"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.474": {
    "title": "Status Biases in Deliberation Online: Evidence from a Randomized Experiment on ChangeMyView",
    "volume": "findings",
    "abstract": "Status is widely used to incentivize user engagement online. However, visible status indicators could inadvertently bias online deliberation to favor high-status users. In this work, we design and deploy a randomized experiment on the ChangeMyView platform to quantify status biases in deliberation online. We find strong evidence of status bias: hiding status on ChangeMyView increases the persuasion rate of moderate-status users by 84% and decreases the persuasion rate of high-status users by 41% relative to the control group. We also find that the persuasive power of status is moderated by verbosity, suggesting that status is used as an information-processing heuristic under cognitive load. Finally, we find that a user's status influences the argumentation behavior of other users they interact with in a manner that disadvantages low and moderate-status users",
    "checked": true,
    "id": "403e266f378fd6a84d72da85c4e761d3fd18e12c",
    "semantic_title": "status biases in deliberation online: evidence from a randomized experiment on changemyview",
    "citation_count": 0,
    "authors": [
      "Emaad Manzoor",
      "Yohan Jo",
      "Alan Montgomery"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.475": {
    "title": "Empathetic and Emotionally Positive Conversation Systems with an Emotion-specific Query-Response Memory",
    "volume": "findings",
    "abstract": "Emotional conversation systems generate responses for the input queries considering the speaker's emotions in a conversation. Existing emotional conversation systems output emotional responses according to either a given emotion or the user's emotion reflected in the input queries. Following a given emotion may lead to an emotional drift between the given emotion and the conversation state, and following only the user's emotion may aggravate the user's negative feelings if users suffer from a negative mood. In this paper, we propose to generate empathetic responses catering to the user's emotions while leading the conversation to be emotionally positive. Particularly, by abstracting the conversation corpus, we extract and store the different responding strategies for different users' emotions and conversational topics into a memory. We encourage positive emotions in conversation via a sentiment evaluator. We model the memory outputs with a Gaussian mixture distribution and sample a final responding strategy from the distribution. The strategy acts as a condition to a transformer model to generate responses. The experiments verify our model surpasses the baseline methods in appropriateness, diversity, and generating emotionally positive responses",
    "checked": true,
    "id": "b17156d31c36c4a7d81b99fe1c2390a33f0e594a",
    "semantic_title": "empathetic and emotionally positive conversation systems with an emotion-specific query-response memory",
    "citation_count": 2,
    "authors": [
      "Zhiliang Tian",
      "Yinliang Wang",
      "Yiping Song",
      "Chi Zhang",
      "Dongkyu Lee",
      "Yingxiu Zhao",
      "Dongsheng Li",
      "Nevin L. Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.476": {
    "title": "Trial2Vec: Zero-Shot Clinical Trial Document Similarity Search using Self-Supervision",
    "volume": "findings",
    "abstract": "Clinical trials are essential for drug development but are extremely expensive and time-consuming to conduct. It is beneficial to study similar historical trials when designing a clinical trial. However, lengthy trial documents and lack of labeled data make trial similarity search difficult. We propose a zero-shotclinical trial retrieval method, called Trial2Vec, which learns through self-supervision without the need for annotating similar clinical trials. Specifically, the meta-structure of trial documents (e.g., title, eligibility criteria, target disease) along with clinical knowledge (e.g., UMLS knowledge base) are leveraged to automatically generate contrastive samples. Besides, encodes trial documents considering meta-structure thus producing compact embeddings aggregating multi-aspect information from the whole document. We show that our method yields medically interpretable embeddings by visualization and it gets 15% average improvement over the best baselines on precision/recall for trial retrieval, which is evaluated on our labeled 1600 trial pairs. In addition, we prove the pretrained embeddings benefit the downstream trial outcome prediction task over 240k trials. Software is available at https://github.com/RyanWangZf/Trial2Vec",
    "checked": true,
    "id": "ee9f79f0f652011f7df2548b8fca62cb5c48ba66",
    "semantic_title": "trial2vec: zero-shot clinical trial document similarity search using self-supervision",
    "citation_count": 11,
    "authors": [
      "Zifeng Wang",
      "Jimeng Sun"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.477": {
    "title": "From Mimicking to Integrating: Knowledge Integration for Pre-Trained Language Models",
    "volume": "findings",
    "abstract": "Investigating better ways to reuse the released pre-trained language models (PLMs) can significantly reduce the computational cost and the potential environmental side-effects. This paper explores a novel PLM reuse paradigm, Knowledge Integration (KI). Without human annotations available, KI aims to merge the knowledge from different teacher-PLMs, each of which specializes in a different classification problem, into a versatile student model. To achieve this, we first derive the correlation between virtual golden supervision and teacher predictions. We then design a Model Uncertainty–aware Knowledge Integration (MUKI) framework to recover the golden supervision for the student. Specifically, MUKI adopts Monte-Carlo Dropout to estimate model uncertainty for the supervision integration. An instance-wise re-weighting mechanism based on the margin of uncertainty scores is further incorporated, to deal with the potential conflicting supervision from teachers. Experimental results demonstrate that MUKI achieves substantial improvements over baselines on benchmark datasets. Further analysis shows that MUKI can generalize well for merging teacher models with heterogeneous architectures, and even teachers major in cross-lingual datasets",
    "checked": true,
    "id": "347cb88984f55de9d51bafeb55f340ae189b795a",
    "semantic_title": "from mimicking to integrating: knowledge integration for pre-trained language models",
    "citation_count": 0,
    "authors": [
      "Lei Li",
      "Yankai Lin",
      "Xuancheng Ren",
      "Guangxiang Zhao",
      "Peng Li",
      "Jie Zhou",
      "Xu Sun"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.478": {
    "title": "Model and Data Transfer for Cross-Lingual Sequence Labelling in Zero-Resource Settings",
    "volume": "findings",
    "abstract": "Zero-resource cross-lingual transfer approaches aim to apply supervised modelsfrom a source language to unlabelled target languages. In this paper we performan in-depth study of the two main techniques employed so far for cross-lingualzero-resource sequence labelling, based either on data or model transfer. Although previous research has proposed translation and annotation projection(data-based cross-lingual transfer) as an effective technique for cross-lingualsequence labelling, in this paper we experimentally demonstrate that highcapacity multilingual language models applied in a zero-shot (model-basedcross-lingual transfer) setting consistently outperform data-basedcross-lingual transfer approaches. A detailed analysis of our results suggeststhat this might be due to important differences in language use. Morespecifically, machine translation often generates a textual signal which isdifferent to what the models are exposed to when using gold standard data,which affects both the fine-tuning and evaluation processes. Our results alsoindicate that data-based cross-lingual transfer approaches remain a competitiveoption when high-capacity multilingual language models are not available",
    "checked": true,
    "id": "7334799f3dbe8b1531cd2cda4514fc6e62b5834a",
    "semantic_title": "model and data transfer for cross-lingual sequence labelling in zero-resource settings",
    "citation_count": 11,
    "authors": [
      "Iker García-Ferrero",
      "Rodrigo Agerri",
      "German Rigau"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.479": {
    "title": "Early Guessing for Dialect Identification",
    "volume": "findings",
    "abstract": "This paper deals with the problem of incre-mental dialect identification. Our goal is toreliably determine the dialect before the fullutterance is given as input. The major partof the previous research on dialect identification has been model-centric, focusing on performance. We address a new question: How much input is needed to identify a dialect? Ourapproach is a data-centric analysis that resultsin general criteria for finding the shortest inputneeded to make a plausible guess. Workingwith three sets of language dialects (Swiss German, Indo-Aryan and Arabic languages), weshow that it is possible to generalize across dialects and datasets with two input shorteningcriteria: model confidence and minimal inputlength (adjusted for the input type). The sourcecode for experimental analysis can be found atGithub",
    "checked": true,
    "id": "f23fee5b33c0f482e56cd1c05f51f05a47ed5c2f",
    "semantic_title": "early guessing for dialect identification",
    "citation_count": 0,
    "authors": [
      "Vani Kanjirangat",
      "Tanja Samardzic",
      "Fabio Rinaldi",
      "Ljiljana Dolamic"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.480": {
    "title": "R-AT: Regularized Adversarial Training for Natural Language Understanding",
    "volume": "findings",
    "abstract": "Currently, adversarial training has become a popular and powerful regularization method in the natural language domain. In this paper, we Regularized Adversarial Training (R-AT) via dropout, which forces the output probability distributions of different sub-models generated by dropout to be consistent under the same adversarial samples. Specifically, we generate adversarial samples by perturbing the word embeddings. For each adversarial sample fed to the model, R-AT minimizes both the adversarial risk and the bidirectional KL-divergence between the adversarial output distributions of two sub-models sampled by dropout. Through extensive experiments on 13 public natural language understanding datasets, we found that R-AT has improvements for many models (e.g., rnn-based, cnn-based, and transformer-based models). For the GLUE benchmark, when R-AT is only applied to the fine-tuning stage, it is able to improve the overall test score of the BERT-base model from 78.3 to 79.6 and the RoBERTa-large model from 88.1 to 88.6. Theoretical analysis reveals that R-AT has potential gradient regularization during the training process. Furthermore, R-AT can reduce the inconsistency between training and testing of models with dropout",
    "checked": true,
    "id": "0406e89a7da137b6cf05741d299de45d6cd5d6ab",
    "semantic_title": "r-at: regularized adversarial training for natural language understanding",
    "citation_count": 0,
    "authors": [
      "Shiwen Ni",
      "Jiawen Li",
      "Hung-Yu Kao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.481": {
    "title": "Multi-View Active Learning for Short Text Classification in User-Generated Data",
    "volume": "findings",
    "abstract": "Mining user-generated data often suffers from the lack of enough labeled data, short document lengths, and the informal user language. In this paper, we propose a novel active learning model to overcome these obstacles in the tasks tailored for query phrases–e.g., detecting positive reports of natural disasters. Our model has three novelties: 1) It is the first approach to employ multi-view active learning in this domain. 2) It uses the Parzen-Rosenblatt window method to integrate the representativeness measure into multi-view active learning. 3) It employs a query-by-committee strategy, based on the agreement between predictors, to address the usually noisy language of the documents in this domain. We evaluate our model in four publicly available Twitter datasets with distinctly different applications. We also compare our model with a wide range of baselines including those with multiple classifiers. The experiments testify that our model is highly consistent and outperforms existing models",
    "checked": true,
    "id": "ab60af93aeb33e7d95878c210c12159d160735f6",
    "semantic_title": "multi-view active learning for short text classification in user-generated data",
    "citation_count": 2,
    "authors": [
      "Payam Karisani",
      "Negin Karisani",
      "Li Xiong"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.482": {
    "title": "Forging Multiple Training Objectives for Pre-trained Language Models via Meta-Learning",
    "volume": "findings",
    "abstract": "Multiple pre-training objectives fill the vacancy of the understanding capability of single-objective language modeling, which serves the ultimate purpose of pre-trained language models (PrLMs), generalizing well on a mass of scenarios. However, learning multiple training objectives in a single model is challenging due to the unknown relative significance as well as the potential contrariety between them. Empirical studies have shown that the current objective sampling in an ad-hoc manual setting makes the learned language representation barely converge to the desired optimum. Thus, we propose MOMETAS, a novel adaptive sampler based on meta-learning, which learns the latent sampling pattern on arbitrary pre-training objectives. Such a design is lightweight with negligible additional training overhead. To validate our approach, we adopt five objectives and conduct continual pre-training with BERT-base and BERT-large models, where MOMETAS demonstrates universal performance gain over other rule-based sampling strategies on 14 natural language processing tasks",
    "checked": true,
    "id": "3a021e1acc7588897df3f58e3ad928122846122f",
    "semantic_title": "forging multiple training objectives for pre-trained language models via meta-learning",
    "citation_count": 7,
    "authors": [
      "Hongqiu Wu",
      "Ruixue Ding",
      "Hai Zhao",
      "Boli Chen",
      "Pengjun Xie",
      "Fei Huang",
      "Min Zhang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.483": {
    "title": "ConGen: Unsupervised Control and Generalization Distillation For Sentence Representation",
    "volume": "findings",
    "abstract": "Sentence representations are essential in many NLP tasks operating at the sentence level. Recently, research attention has shifted towards learning how to represent sentences without any annotations, i.e., unsupervised representation learning. Despite the benefit of training without supervised data, there is still a performance penalty compared to supervised methods. Furthermore, the supervised-unsupervised performance gap widens as we reduce the model size. In this paper, we propose an unsupervised sentence representation method to reduce the supervised-unsupervised performance gap, especially for smaller models. Utilizing the concept for knowledge distillation, we derive a distillation framework comprising two training objectives, control and generalize, called ConGen. Experiments on semantic textual similarity (STS), text classification (transfer), and natural language inference (NLI) tasks show that ConGen is on par with supervised training even on smaller models. Furthermore, our method consistently outperformed competitors on multilingual STS.The code and models are available at https://github.com/KornWtp/ConGen",
    "checked": true,
    "id": "153b4cb95eb4c779f54e2dc36e6846c371fea05e",
    "semantic_title": "congen: unsupervised control and generalization distillation for sentence representation",
    "citation_count": 3,
    "authors": [
      "Peerat Limkonchotiwat",
      "Wuttikorn Ponwitayarat",
      "Lalita Lowphansirikul",
      "Can Udomcharoenchaikit",
      "Ekapol Chuangsuwanich",
      "Sarana Nutanong"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.484": {
    "title": "Large-Scale Differentially Private BERT",
    "volume": "findings",
    "abstract": "In this work, we study the large-scale pretraining of BERT-Large (Devlin et al., 2019) with differentially private SGD (DP-SGD). We show that combined with a careful implementation, scaling up the batch size to millions (i.e., mega-batches) improves the utility of the DP-SGD step for BERT; we also enhance the training efficiency by using an increasing batch size schedule. Our implementation builds on the recent work of Subramani et al (2020), who demonstrated that the overhead of a DP-SGD step is minimized with effective use of JAX (Bradbury et al., 2018; Frostig et al., 2018) primitives in conjunction with the XLA compiler (XLA team and collaborators, 2017). Our implementation achieves a masked language model accuracy of 60.5% at a batch size of 2M, for epsilon=5, which is a reasonable privacy setting. To put this number in perspective, non-private BERT models achieve an accuracy of ∼70%",
    "checked": true,
    "id": "2cbf8688cbaddb28eac94fafb01251178f664dc7",
    "semantic_title": "large-scale differentially private bert",
    "citation_count": 90,
    "authors": [
      "Rohan Anil",
      "Badih Ghazi",
      "Vineet Gupta",
      "Ravi Kumar",
      "Pasin Manurangsi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.485": {
    "title": "Improving Zero-Shot Multilingual Translation with Universal Representations and Cross-Mapping",
    "volume": "findings",
    "abstract": "The many-to-many multilingual neural machine translation can translate between language pairs unseen during training, i.e., zero-shot translation. Improving zero-shot translation requires the model to learn universal representations and cross-mapping relationships to transfer the knowledge learned on the supervised directions to the zero-shot directions. In this work, we propose the state mover's distance based on the optimal theory to model the difference of the representations output by the encoder. Then, we bridge the gap between the semantic-equivalent representations of different languages at the token level by minimizing the proposed distance to learn universal representations. Besides, we propose an agreement-based training scheme, which can help the model make consistent predictions based on the semantic-equivalent sentences to learn universal cross-mapping relationships for all translation directions. The experimental results on diverse multilingual datasets show that our method can improve consistently compared with the baseline system and other contrast methods. The analysis proves that our method can better align the semantic space and improve the prediction consistency",
    "checked": true,
    "id": "0e73943b315e0737e3c0be8d9a0edeb13459662a",
    "semantic_title": "improving zero-shot multilingual translation with universal representations and cross-mappings",
    "citation_count": 6,
    "authors": [
      "Shuhao Gu",
      "Yang Feng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.486": {
    "title": "Controllable Fake Document Infilling for Cyber Deception",
    "volume": "findings",
    "abstract": "Recent works in cyber deception study how to deter malicious intrusion by generating multiple fake versions of a critical document to impose costs on adversaries who need to identify the correct information. However, existing approaches are context-agnostic, resulting in sub-optimal and unvaried outputs. We propose a novel context-aware model, Fake Document Infilling (FDI), by converting the problem to a controllable mask-then-infill procedure. FDI masks important concepts of varied lengths in the document, then infills a realistic but fake alternative considering both the previous and future contexts. We conduct comprehensive evaluations on technical documents and news stories. Results show that FDI outperforms the baselines in generating highly believable fakes with moderate modification to protect critical information and deceive adversaries",
    "checked": true,
    "id": "1948447570f236338dd771a692a478b0fd091931",
    "semantic_title": "controllable fake document infilling for cyber deception",
    "citation_count": 3,
    "authors": [
      "Yibo Hu",
      "Yu Lin",
      "Erick Skorupa Parolin",
      "Latifur Khan",
      "Kevin Hamlen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.487": {
    "title": "Weakly Supervised Headline Dependency Parsing",
    "volume": "findings",
    "abstract": "English news headlines form a register with unique syntactic properties that have been documented in linguistics literature since the 1930s. However, headlines have received surprisingly little attention from the NLP syntactic parsing community. We aim to bridge this gap by providing the first news headline corpus of Universal Dependencies annotated syntactic dependency trees, which enables us to evaluate existing state-of-the-art dependency parsers on news headlines. To improve English news headline parsing accuracies, we develop a projection method to bootstrap silver training data from unlabeled news headline-article lead sentence pairs. Models trained on silver headline parses demonstrate significant improvements in performance over models trained solely on gold-annotated long-form texts. Ultimately, we find that, although projected silver training data improves parser performance across different news outlets, the improvement is moderated by constructions idiosyncratic to outlet",
    "checked": true,
    "id": "234b09da8b9fbacdb408249de30aaddf9ef9a8dc",
    "semantic_title": "weakly supervised headline dependency parsing",
    "citation_count": 1,
    "authors": [
      "Adrian Benton",
      "Tianze Shi",
      "Ozan İrsoy",
      "Igor Malioutov"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.488": {
    "title": "BOOKSUM: A Collection of Datasets for Long-form Narrative Summarization",
    "volume": "findings",
    "abstract": "The majority of existing text summarization datasets include short-form source documents that lack long-range causal and temporal dependencies, and often contain strong layout and stylistic biases. While relevant, such datasets will offer limited challenges for future text summarization systems. We address these issues by introducing BOOKSUM, a collection of datasets for long-form narrative summarization. Our dataset covers documents from the literature domain, such as novels, plays and stories, and includes highly abstractive, human written summaries on three levels of granularity of increasing difficulty: paragraph-, chapter-, and book-level. The domain and structure of our dataset poses a unique set of challenges for summarization systems, which include: processing very long documents, non-trivial causal and temporal dependencies, and rich discourse structures. To facilitate future work, we trained and evaluated multiple extractive and abstractive summarization models as baselines for our dataset",
    "checked": true,
    "id": "a4ffce66918cfb33150a60bf8e26419199e63b01",
    "semantic_title": "booksum: a collection of datasets for long-form narrative summarization",
    "citation_count": 77,
    "authors": [
      "Wojciech Kryscinski",
      "Nazneen Rajani",
      "Divyansh Agarwal",
      "Caiming Xiong",
      "Dragomir Radev"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.489": {
    "title": "Not All Errors are Equal: Learning Text Generation Metrics using Stratified Error Synthesis",
    "volume": "findings",
    "abstract": "Is it possible to build a general and automatic natural language generation (NLG) evaluation metric? Existing learned metrics either perform unsatisfactorily or are restricted to tasks where large human rating data is already available. We introduce SESCORE, a model-based metric that is highly correlated with human judgements without requiring human annotation, by utilizing a novel, iterative error synthesis and severity scoring pipeline. This pipeline applies a series of plausible errors to raw text and assigns severity labels by simulating human judgements with entailment. We evaluate SESCORE against existing metrics by comparing how their scores correlate with human ratings. SESCORE outperforms all prior unsupervised metrics on multiple diverse NLG tasks including machine translation, image captioning, and WebNLG text generation. For WMT 20/21En-De and Zh-En, SESCORE improve the average Kendall correlation with human judgement from 0.154 to 0.195. SESCORE even achieves comparable performance to the best supervised metric COMET, despite receiving no human annotated training data",
    "checked": true,
    "id": "8eac7b9318e186cc2708845d669a7a759565c452",
    "semantic_title": "not all errors are equal: learning text generation metrics using stratified error synthesis",
    "citation_count": 17,
    "authors": [
      "Wenda Xu",
      "Yi-Lin Tuan",
      "Yujie Lu",
      "Michael Saxon",
      "Lei Li",
      "William Yang Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.490": {
    "title": "Summarization as Indirect Supervision for Relation Extraction",
    "volume": "findings",
    "abstract": "Relation extraction (RE) models have been challenged by their reliance on training data with expensive annotations. Considering that summarization tasks aim at acquiring concise expressions of synoptical information from the longer context, these tasks naturally align with the objective of RE, i.e., extracting a kind of synoptical information that describes the relation of entity mentions. We present SuRE, which converts RE into a summarization formulation. SuRE leads to more precise and resource-efficient RE based on indirect supervision from summarization tasks. To achieve this goal, we develop sentence and relation conversion techniques that essentially bridge the formulation of summarization and RE tasks. We also incorporate constraint decoding techniques with Trie scoring to further enhance summarization-based RE with robust inference. Experiments on three RE datasets demonstrate the effectiveness of SuRE in both full-dataset and low-resource settings, showing that summarization is a promising source of indirect supervision signals to improve RE models",
    "checked": true,
    "id": "11fc7b4e459479ec5facb344b42a9bad940da37a",
    "semantic_title": "summarization as indirect supervision for relation extraction",
    "citation_count": 37,
    "authors": [
      "Keming Lu",
      "I-Hung Hsu",
      "Wenxuan Zhou",
      "Mingyu Derek Ma",
      "Muhao Chen"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.491": {
    "title": "DIGAT: Modeling News Recommendation with Dual-Graph Interaction",
    "volume": "findings",
    "abstract": "News recommendation (NR) is essential for online news services. Existing NR methods typically adopt a news-user representation learning framework, facing two potential limitations. First, in news encoder, single candidate news encoding suffers from an insufficient semantic information problem. Second, existing graph-based NR methods are promising but lack effective news-user feature interaction, rendering the graph-based recommendation suboptimal. To overcome these limitations, we propose dual-interactive graph attention networks (DIGAT) consisting of news- and user-graph channels. In the news-graph channel, we enrich the semantics of single candidate news by incorporating the semantically relevant news information with a semantic-augmented graph (SAG). In the user-graph channel, multi-level user interests are represented with a news-topic graph. Most notably, we design a dual-graph interaction process to perform effective feature interaction between the news and user graphs, which facilitates accurate news-user representation matching. Experiment results on the benchmark dataset MIND show that DIGAT outperforms existing news recommendation methods. Further ablation studies and analyses validate the effectiveness of (1) semantic-augmented news graph modeling and (2) dual-graph interaction",
    "checked": true,
    "id": "922f58be48fa45e0e8d8efb81044cc037bdba1fa",
    "semantic_title": "digat: modeling news recommendation with dual-graph interaction",
    "citation_count": 4,
    "authors": [
      "Zhiming Mao",
      "Jian Li",
      "Hongru Wang",
      "Xingshan Zeng",
      "Kam-Fai Wong"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.492": {
    "title": "SMASH: Improving SMAll Language Models' Few-SHot Ability with Prompt-Based Distillation",
    "volume": "findings",
    "abstract": "Large-scale language models coupled with prompts have shown remarkable performance on few-shot learning. However, through systematic experiments, we find that the few-shot performance of small language models is poor, and using prompts on them brings fewer improvements than on larger ones. In this paper, we propose SMASH, an approach to improve SMAll language models' few-SHot ability by training on intermediate tasks before prompt-based fine-tuning on downstream tasks. We design intermediate tasks for sentence-pair tasks and sentiment classification tasks by creating training examples with prompt templates similar to downstream tasks using sentences sampled from a large-scale unsupervised corpus, and apply knowledge distillation to distill from outputs of larger pre-trained models as the training objective. We conduct extensive experiments and show that SMASH can make a 6-layer DistilRoBRETa-base achieve comparable performance on few-shot datasets with a 12-layer RoBERTa-base at a low cost",
    "checked": true,
    "id": "55b557f3f266f5c545ce2bc610f92125b7e4c155",
    "semantic_title": "smash: improving small language models' few-shot ability with prompt-based distillation",
    "citation_count": 2,
    "authors": [
      "Yueqian Wang",
      "Chang Liu",
      "Kai Chen",
      "Xi Wang",
      "Dongyan Zhao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.493": {
    "title": "Consecutive Question Generation via Dynamic Multitask Learning",
    "volume": "findings",
    "abstract": "In this paper, we propose the task of consecutive question generation (CQG), which generates a set of logically related question-answer pairs to understand a whole passage, with a comprehensive consideration of the aspects including accuracy, coverage, and informativeness. To achieve this, we first examine the four key elements of CQG, i.e., question, answer, rationale, and context history, and propose a novel dynamic multitask framework with one main task generating a question-answer pair, and four auxiliary tasks generating other elements. It directly helps the model generate good questions through both joint training and self-reranking. At the same time, to fully explore the worth-asking information in a given passage, we make use of the reranking losses to sample the rationales and search for the best question series globally. Finally, we measure our strategy by QA data augmentation and manual evaluation, as well as a novel application of generated question-answer pairs on DocNLI. We prove that our strategy can improve question generation significantly and benefit multiple related NLP tasks",
    "checked": true,
    "id": "bd61f0258fc77378e366083aea1d988bf33bd118",
    "semantic_title": "consecutive question generation via dynamic multitask learning",
    "citation_count": 1,
    "authors": [
      "Yunji Li",
      "Sujian Li",
      "Xing Shi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.494": {
    "title": "Subword Segmental Language Modelling for Nguni Languages",
    "volume": "findings",
    "abstract": "Subwords have become the standard units of text in NLP, enabling efficient open-vocabulary models. With algorithms like byte-pair encoding (BPE), subword segmentation is viewed as a preprocessing step applied to the corpus before training. This can lead to sub-optimal segmentations for low-resource languages with complex morphologies. We propose a subword segmental language model (SSLM) that learns how to segment words while being trained for autoregressive language modelling. By unifying subword segmentation and language modelling, our model learns subwords that optimise LM performance. We train our model on the 4 Nguni languages of South Africa. These are low-resource agglutinative languages, so subword information is critical. As an LM, SSLM outperforms existing approaches such as BPE-based models on average across the 4 languages. Furthermore, it outperforms standard subword segmenters on unsupervised morphological segmentation. We also train our model as a word-level sequence model, resulting in an unsupervised morphological segmenter that outperforms existing methods by a large margin for all 4 languages. Our results show that learning subword segmentation is an effective alternative to existing subword segmenters, enabling the model to discover morpheme-like subwords that improve its LM capabilities",
    "checked": true,
    "id": "379722c04fb3b54215f82512eb86398cb02d42dd",
    "semantic_title": "subword segmental language modelling for nguni languages",
    "citation_count": 4,
    "authors": [
      "Francois Meyer",
      "Jan Buys"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.495": {
    "title": "Towards Robust Visual Question Answering: Making the Most of Biased Samples via Contrastive Learning",
    "volume": "findings",
    "abstract": "Models for Visual Question Answering (VQA) often rely on the spurious correlations, i.e., the language priors, that appear in the biased samples of training set, which make them brittle against the out-of-distribution (OOD) test data. Recent methods have achieved promising progress in overcoming this problem by reducing the impact of biased samples on model training. However, these models reveal a trade-off that the improvements on OOD data severely sacrifice the performance on the in-distribution (ID) data (which is dominated by the biased samples). Therefore, we propose a novel contrastive learning approach, MMBS, for building robust VQA models by Making the Most of Biased Samples. Specifically, we construct positive samples for contrastive learning by eliminating the information related to spurious correlation from the original training samples and explore several strategies to use the constructed positive samples for training. Instead of undermining the importance of biased samples in model training, our approach precisely exploits the biased samples for unbiased information that contributes to reasoning. The proposed method is compatible with various VQA backbones. We validate our contributions by achieving competitive performance on the OOD dataset VQA-CP v2 while preserving robust performance on the ID dataset VQA v2",
    "checked": true,
    "id": "42d020473915136cb4fff4f5c133e2970951c00c",
    "semantic_title": "towards robust visual question answering: making the most of biased samples via contrastive learning",
    "citation_count": 9,
    "authors": [
      "Qingyi Si",
      "Yuanxin Liu",
      "Fandong Meng",
      "Zheng Lin",
      "Peng Fu",
      "Yanan Cao",
      "Weiping Wang",
      "Jie Zhou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.496": {
    "title": "P3LM: Probabilistically Permuted Prophet Language Modeling for Generative Pre-Training",
    "volume": "findings",
    "abstract": "Conventional autoregressive left-to-right (L2R) sequence generation faces two issues during decoding: limited to unidirectional target sequence modeling, and constrained on strong local dependencies. To address the aforementioned problem, we propose P3LM, a probabilistically permuted prophet language model, which strengthens the modeling of bidirectional information and long token dependencies for sequence generation. Specifically, P3LM learns to generate tokens in permuted order upon an order-aware transformer decoder, as well as to generate the corresponding future N tokens with a multi-stream attention mechanism. Extensive experiments are conducted on the GLGE benchmark, which includes four datasets for summarization, two for question generation, one for conversational question answering, and one for dialog response generation, where P3LM achieves state-of-the-art results compared with strong publicly available generative pre-training methods",
    "checked": true,
    "id": "2ae0c69cac7bb2ba386faf6e9702db54b2ca594d",
    "semantic_title": "p3lm: probabilistically permuted prophet language modeling for generative pre-training",
    "citation_count": 1,
    "authors": [
      "Junwei Bao",
      "Yifan Wang",
      "Ying Jiangyong",
      "Yeyun Gong",
      "Jing Zhao",
      "Youzheng Wu",
      "Xiaodong He"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.497": {
    "title": "Holistic Sentence Embeddings for Better Out-of-Distribution Detection",
    "volume": "findings",
    "abstract": "Detecting out-of-distribution (OOD) instances is significant for the safe deployment of NLP models. Among recent textual OOD detection works based on pretrained language models (PLMs), distance-based methods have shown superior performance. However, they estimate sample distance scores in the last-layer CLS embedding space and thus do not make full use of linguistic information underlying in PLMs. To address the issue, we propose to boost OOD detection by deriving more holistic sentence embeddings. On the basis of the observations that token averaging and layer combination contribute to improving OOD detection, we propose a simple embedding approach named Avg-Avg, which averages all token representations from each intermediate layer as the sentence embedding and significantly surpasses the state-of-the-art on a comprehensive suite of benchmarks by a 9.33% FAR95 margin. Furthermore, our analysis demonstrates that it indeed helps preserve general linguistic knowledge in fine-tuned PLMs and substantially benefits detecting background shifts. The simple yet effective embedding method can be applied to fine-tuned PLMs with negligible extra costs, providing a free gain in OOD detection. Our code is available at https://github.com/lancopku/Avg-Avg",
    "checked": true,
    "id": "020b0c80270af27cd28899f2711eeed7a88b95cd",
    "semantic_title": "holistic sentence embeddings for better out-of-distribution detection",
    "citation_count": 3,
    "authors": [
      "Sishuo Chen",
      "Xiaohan Bi",
      "Rundong Gao",
      "Xu Sun"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.498": {
    "title": "MuGER2: Multi-Granularity Evidence Retrieval and Reasoning for Hybrid Question Answering",
    "volume": "findings",
    "abstract": "Hybrid question answering (HQA) aims to answer questions over heterogeneous data, including tables and passages linked to table cells. The heterogeneous data can provide different granularity evidence to HQA models, e.t., column, row, cell, and link. Conventional HQA models usually retrieve coarse- or fine-grained evidence to reason the answer. Through comparison, we find that coarse-grained evidence is easier to retrieve but contributes less to the reasoner, while fine-grained evidence is the opposite. To preserve the advantage and eliminate the disadvantage of different granularity evidence, we propose MuGER2, a Multi-Granularity Evidence Retrieval and Reasoning approach. In evidence retrieval, a unified retriever is designed to learn the multi-granularity evidence from the heterogeneous data. In answer reasoning, an evidence selector is proposed to navigate the fine-grained evidence for the answer reader based on the learned multi-granularity evidence. Experiment results on the HybridQA dataset show that MuGER2 significantly boosts the HQA performance. Further ablation analysis verifies the effectiveness of both the retrieval and reasoning designs",
    "checked": true,
    "id": "c63296d9907dd522271cb60cf525a7d66aa1c25e",
    "semantic_title": "muger2: multi-granularity evidence retrieval and reasoning for hybrid question answering",
    "citation_count": 9,
    "authors": [
      "Yingyao Wang",
      "Junwei Bao",
      "Chaoqun Duan",
      "Youzheng Wu",
      "Xiaodong He",
      "Tiejun Zhao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.499": {
    "title": "EntityCS: Improving Zero-Shot Cross-lingual Transfer with Entity-Centric Code Switching",
    "volume": "findings",
    "abstract": "Accurate alignment between languages is fundamental for improving cross-lingual pre-trained language models (XLMs). Motivated by the natural phenomenon of code-switching (CS) in multilingual speakers, CS has been used as an effective data augmentation method that offers language alignment at word- or phrase-level, in contrast to sentence-level via parallel instances. Existing approaches either use dictionaries or parallel sentences with word-alignment to generate CS data by randomly switching words in a sentence. However, such methods can be suboptimal as dictionaries disregard semantics, and syntax might become invalid after random word switching. In this work, we propose EntityCS, a method that focuses on Entity-level Code-Switching to capture fine-grained cross-lingual semantics without corrupting syntax. We use Wikidata and the English Wikipedia to construct an entity-centric CS corpus by switching entities to their counterparts in other languages. We further propose entity-oriented masking strategies during intermediate model training on the EntityCS corpus for improving entity prediction. Evaluation of the trained models on four entity-centric downstream tasks shows consistent improvements over the baseline with a notable increase of 10% in Fact Retrieval. We release the corpus and models to assist research on code-switching and enriching XLMs with external knowledge",
    "checked": true,
    "id": "71f305a5779b791339f13725a362fd339ee7f3ba",
    "semantic_title": "entitycs: improving zero-shot cross-lingual transfer with entity-centric code switching",
    "citation_count": 6,
    "authors": [
      "Chenxi Whitehouse",
      "Fenia Christopoulou",
      "Ignacio Iacobacci"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.500": {
    "title": "MBTI Personality Prediction for Fictional Characters Using Movie Scripts",
    "volume": "findings",
    "abstract": "An NLP model that understands stories should be able to understand the characters in them. To support the development of neural models for this purpose, we construct a benchmark, Story2Personality. The task is to predict a movie character's MBTI or Big 5 personality types based on the narratives of the character. Experiments show that our task is challenging for the existing text classification models, as none is able to largely outperform random guesses. We further proposed a multi-view model for personality prediction using both verbal and non-verbal descriptions, which gives improvement compared to using only verbal descriptions. The uniqueness and challenges in our dataset call for the development of narrative comprehension techniques from the perspective of understanding characters",
    "checked": true,
    "id": "c1fdff2943289250a2eac036ef81402f408d8b47",
    "semantic_title": "mbti personality prediction for fictional characters using movie scripts",
    "citation_count": 5,
    "authors": [
      "Yisi Sang",
      "Xiangyang Mou",
      "Mo Yu",
      "Dakuo Wang",
      "Jing Li",
      "Jeffrey Stanton"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.501": {
    "title": "A Simple and Strong Baseline for End-to-End Neural RST-style Discourse Parsing",
    "volume": "findings",
    "abstract": "To promote and further develop RST-style discourse parsing models, we need a strong baseline that can be regarded as a reference for reporting reliable experimental results. This paper explores a strong baseline by integrating existing simple parsing strategies, top-down and bottom-up, with various transformer-based pre-trained language models. The experimental results obtained from two benchmark datasets demonstrate that the parsing performance strongly relies on the pre-trained language models rather than the parsing strategies. In particular, the bottom-up parser achieves large performance gains compared to the current best parser when employing DeBERTa.We further reveal that language models with a span-masking scheme especially boost the parsing performance through our analysis within intra- and multi-sentential parsing, and nuclearity prediction",
    "checked": true,
    "id": "0cb346ccbd338517789db9abafe9fd93549f7893",
    "semantic_title": "a simple and strong baseline for end-to-end neural rst-style discourse parsing",
    "citation_count": 7,
    "authors": [
      "Naoki Kobayashi",
      "Tsutomu Hirao",
      "Hidetaka Kamigaito",
      "Manabu Okumura",
      "Masaaki Nagata"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.502": {
    "title": "Probing for Constituency Structure in Neural Language Models",
    "volume": "findings",
    "abstract": "In this paper, we investigate to which extent contextual neural language models (LMs) implicitly learn syntactic structure. More concretely, we focus on constituent structure as represented in the Penn Treebank (PTB). Using standard probing techniques based on diagnostic classifiers, we assess the accuracy of representing constituents of different categories within the neuron activations of a LM such as RoBERTa. In order to make sure that our probe focuses on syntactic knowledge and not on implicit semantic generalizations, we also experiment on a PTB version that is obtained by randomly replacing constituents with each other while keeping syntactic structure, i.e., a semantically ill-formed but syntactically well-formed version of the PTB. We find that 4 pretrained transfomer LMs obtain high performance on our probing tasks even on manipulated data, suggesting that semantic and syntactic knowledge in their representations can be separated and that constituency information is in fact learned by the LM. Moreover, we show that a complete constituency tree can be linearly separated from LM representations",
    "checked": true,
    "id": "b7e66de289baad3f013b77a96de58e419721873e",
    "semantic_title": "probing for constituency structure in neural language models",
    "citation_count": 10,
    "authors": [
      "David Arps",
      "Younes Samih",
      "Laura Kallmeyer",
      "Hassan Sajjad"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.503": {
    "title": "Table-To-Text generation and pre-training with TabT5",
    "volume": "findings",
    "abstract": "Encoder-only transformer models have been successfully applied to different table understanding tasks, as in TAPAS. A major limitation of these architectures is that they are constrained to classification-like tasks such as cell selection or entailment detection. We present TabT5, an encoder-decoder model that generates natural language text based on tables and textual inputs. TabT5 overcomes the encoder-only limitation by incorporating a decoder component and leverages the input structure with table specific embeddings and pre-training. TabT5 achieves new state-of-the-art results on several domains, including spreadsheet formula prediction with a 15% increase in sequence accuracy, QA with a 2.5% increase in sequence accuracy and data-to-text generation with a 2.5% increase in BLEU",
    "checked": true,
    "id": "3ba45e2885f3603c7c51c7b60547a3f0258bda91",
    "semantic_title": "table-to-text generation and pre-training with tabt5",
    "citation_count": 22,
    "authors": [
      "Ewa Andrejczuk",
      "Julian Eisenschlos",
      "Francesco Piccinno",
      "Syrine Krichene",
      "Yasemin Altun"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.504": {
    "title": "A POMDP Dialogue Policy with 3-way Grounding and Adaptive Sensing for Learning through Communication",
    "volume": "findings",
    "abstract": "Agents to assist with rescue, surgery, and similar activities could collaborate better with humans if they could learn new strategic behaviors through communication. We introduce a novel POMDP dialogue policy for learning from people. The policy has 3-way grounding of language in the shared physical context, the dialogue context, and persistent knowledge. It can learn distinct but related games, and can continue learning across dialogues for complex games. A novel sensing component supports adaptation to information-sharing differences across people. The single policy performs better than oracle policies customized to specific games and information behavior",
    "checked": true,
    "id": "223285b5a11e3aefcb6c60828b897b4edd936dcc",
    "semantic_title": "a pomdp dialogue policy with 3-way grounding and adaptive sensing for learning through communication",
    "citation_count": 1,
    "authors": [
      "Maryam Zare",
      "Alan Wagner",
      "Rebecca Passonneau"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.505": {
    "title": "PaCo: Preconditions Attributed to Commonsense Knowledge",
    "volume": "findings",
    "abstract": "Humans can seamlessly reason with circumstantial preconditions of commonsense knowledge. We understand that a glass is used for drinking water, unless the glass is broken or the water is toxic. Despite state-of-the-art (SOTA) language models' (LMs) impressive performance on inferring commonsense knowledge, it is unclear whether they understand the circumstantial preconditions. To address this gap, we propose a novel challenge of reasoning with circumstantial preconditions. We collect a dataset, called PaCo, consisting of 12.4 thousand preconditions of commonsense statements expressed in natural language. Based on this dataset, we create three canonical evaluation tasks and use them to examine the capability of existing LMs to understand situational preconditions. Our results reveal a 10-30% gap between machine and human performance on our tasks, which shows that reasoning with preconditions is an open challenge",
    "checked": true,
    "id": "67420f099e2dddd2d6976d319b5fec65c678c5dd",
    "semantic_title": "paco: preconditions attributed to commonsense knowledge",
    "citation_count": 5,
    "authors": [
      "Ehsan Qasemi",
      "Filip Ilievski",
      "Muhao Chen",
      "Pedro Szekely"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.506": {
    "title": "Improving Few-Shot Domain Transfer for Named Entity Disambiguation with Pattern Exploitation",
    "volume": "findings",
    "abstract": "Named entity disambiguation (NED) is a critical subtask of entity linking, which seeks to connect knowledge base entities with textual mentions of those entities. Naturally, the performance of a model depends on the domain it was trained on; thus, reducing the amount of data required to train models is advantageous. In this work, we leverage recent research on pattern exploitation for NED and explore whether it can reduce the amount of data required for domain adaptation by reformulating the disambiguation task as a masked language modeling problem. Using ADAPET (Tam et al., 2021), which implements a new approach for few-shot learning using fine-tuned transformer-based language models, we produce an NED model which yields, without any sacrifice of in-domain accuracy, a 7% improvement in zero-shot cross-domain performance as evaluated on NEDMed, a new NED dataset of mental health news which we release with this work",
    "checked": true,
    "id": "b8df5bcabd43a1b9e8a159bc8249e33408112faa",
    "semantic_title": "improving few-shot domain transfer for named entity disambiguation with pattern exploitation",
    "citation_count": 1,
    "authors": [
      "Philip Blair",
      "Kfir Bar"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.507": {
    "title": "Capturing Topic Framing via Masked Language Modeling",
    "volume": "findings",
    "abstract": "Differential framing of issues can lead to divergent world views on important issues. This is especially true in domains where the information presented can reach a large audience, such as traditional and social media. Scalable and reliable measurement of such differential framing is an important first step in addressing them. In this work, based on the intuition that framing affects the tone and word choices in written language, we propose a framework for modeling the differential framing of issues through masked token prediction via large-scale fine-tuned language models (LMs). Specifically, we explore three key factors for our framework: 1) prompt generation methods for the masked token prediction; 2) methods for normalizing the output of fine-tuned LMs; 3) robustness to the choice of pre-trained LMs used for fine-tuning. Through experiments on a dataset of articles from traditional media outlets covering five diverse and politically polarized topics, we show that our framework can capture differential framing of these topics with high reliability",
    "checked": true,
    "id": "5cad61bd6388aa540cf2215a3fc5d5a250a2984e",
    "semantic_title": "capturing topic framing via masked language modeling",
    "citation_count": 0,
    "authors": [
      "Xiaobo Guo",
      "Weicheng Ma",
      "Soroush Vosoughi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.508": {
    "title": "WANLI: Worker and AI Collaboration for Natural Language Inference Dataset Creation",
    "volume": "findings",
    "abstract": "A recurring challenge of crowdsourcing NLP datasets at scale is that human writers often rely on repetitive patterns when crafting examples, leading to a lack of linguistic diversity. We introduce a novel approach for dataset creation based on worker and AI collaboration, which brings together the generative strength of language models and the evaluative strength of humans. Starting with an existing dataset, MultiNLI for natural language inference (NLI), our approach uses dataset cartography to automatically identify examples that demonstrate challenging reasoning patterns, and instructs GPT-3 to compose new examples with similar patterns. Machine generated examples are then automatically filtered, and finally revised and labeled by human crowdworkers. The resulting dataset, WANLI, consists of 107,885 NLI examples and presents unique empirical strengths over existing NLI datasets. Remarkably, training a model on WANLI improves performance on eight out-of-domain test sets we consider, including by 11% on HANS and 9% on Adversarial NLI, compared to training on the 4x larger MultiNLI. Moreover, it continues to be more effective than MultiNLI augmented with other NLI datasets. Our results demonstrate the promise of leveraging natural language generation techniques and re-imagining the role of humans in the dataset creation process",
    "checked": true,
    "id": "5e8d3c2dc0fc53949794fc00600e25558c4a2441",
    "semantic_title": "wanli: worker and ai collaboration for natural language inference dataset creation",
    "citation_count": 148,
    "authors": [
      "Alisa Liu",
      "Swabha Swayamdipta",
      "Noah A. Smith",
      "Yejin Choi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.509": {
    "title": "Sequentially Controlled Text Generation",
    "volume": "findings",
    "abstract": "While GPT-2 generates sentences that are remarkably human-like, longer documents can ramble and do not follow human-like writing structure. We study the problem of imposing structure on long-range text. We propose a novel controlled text generation task, sequentially controlled text generation, and identify a dataset, NewsDiscourse as a starting point for this task. We develop a sequential controlled text generation pipeline with generation and editing. We test different degrees of structural awareness and show that, in general, more structural awareness results in higher control- accuracy, grammaticality, coherency and topicality, approaching human-level writing performance",
    "checked": true,
    "id": "6ffa6ec8a39605b9768127c97f425ffc4edc1c1b",
    "semantic_title": "sequentially controlled text generation",
    "citation_count": 6,
    "authors": [
      "Alexander Spangher",
      "Yao Ming",
      "Xinyu Hua",
      "Nanyun Peng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.510": {
    "title": "Revisiting the Roles of \"Text\" in Text Games",
    "volume": "findings",
    "abstract": "Text games present opportunities for natural language understanding (NLU) methods to tackle reinforcement learning (RL) challenges. However, recent work has questioned the necessity of NLU by showing random text hashes could perform decently. In this paper, we pursue a fine-grained investigation into the roles of text in the face of different RL challenges, and reconcile that semantic and non-semantic language representations could be complementary rather than contrasting. Concretely, we propose a simple scheme to extract relevant contextual information into an approximate state hash as extra input for an RNN-based text agent. Such a lightweight plug-in achieves competitive performance with state-of-the-art text agents using advanced NLU techniques such as knowledge graph and passage retrieval, suggesting non-NLU methods might suffice to tackle the challenge of partial observability. However, if we remove RNN encoders and use approximate or even ground-truth state hash alone, the model performs miserably, which confirms the importance of semantic function approximation to tackle the challenge of combinatorially large observation and action spaces. Our findings and analysis provide new insights for designing better text game task setups and agents",
    "checked": true,
    "id": "43925c81027be1fc54543f8893db3bee30251a8b",
    "semantic_title": "revisiting the roles of \"text\" in text games",
    "citation_count": 3,
    "authors": [
      "Yi Gu",
      "Shunyu Yao",
      "Chuang Gan",
      "Josh Tenenbaum",
      "Mo Yu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.511": {
    "title": "FPT: Improving Prompt Tuning Efficiency via Progressive Training",
    "volume": "findings",
    "abstract": "Recently, prompt tuning (PT) has gained increasing attention as a parameter-efficient way of tuning pre-trained language models (PLMs). Despite extensively reducing the number of tunable parameters and achieving satisfying performance, PT is training-inefficient due to its slow convergence. To improve PT's training efficiency, we first make some novel observations about the prompt transferability of \"partial PLMs\", which are defined by compressing a PLM in depth or width. We observe that the soft prompts learned by different partial PLMs of various sizes are similar in the parameter space, implying that these soft prompts could potentially be transferred among partial PLMs. Inspired by these observations, we propose Fast Prompt Tuning (FPT), which starts by conducting PT using a small-scale partial PLM, and then progressively expands its depth and width until the full-model size. After each expansion, we recycle the previously learned soft prompts as initialization for the enlarged partial PLM and then proceed PT. We demonstrate the feasibility of FPT on 5 tasks and show that FPT could save over 30% training computations while achieving comparable performance. The codes are publicly available at https://github.com/thunlp/FastPromptTuning",
    "checked": true,
    "id": "3f88eb2abbf54f043c50de9b33530ddbe9f02b87",
    "semantic_title": "fpt: improving prompt tuning efficiency via progressive training",
    "citation_count": 6,
    "authors": [
      "Yufei Huang",
      "Yujia Qin",
      "Huadong Wang",
      "Yichun Yin",
      "Maosong Sun",
      "Zhiyuan Liu",
      "Qun Liu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.512": {
    "title": "Prompt-learning for Fine-grained Entity Typing",
    "volume": "findings",
    "abstract": "As an effective approach to adapting pre-trained language models (PLMs) for specific tasks, prompt-learning has recently attracted much attention from researchers. By using cloze-style language prompts to stimulate the versatile knowledge of PLMs, prompt-learning can achieve promising results on a series of NLP tasks, such as natural language inference, sentiment classification, and knowledge probing. In this work, we investigate the application of prompt-learning on fine-grained entity typing in fully supervised, few-shot, and zero-shot scenarios. We first develop a simple and effective prompt-learning pipeline by constructing entity-oriented verbalizers and templates and conducting masked language modeling. Further, to tackle the zero-shot regime, we propose a self-supervised strategy that carries out distribution-level optimization in prompt-learning to automatically summarize the information of entity types. Extensive experiments on four fine-grained entity typing benchmarks under fully supervised, few-shot, and zero-shot settings show the effectiveness of the prompt-learning paradigm and further make a powerful alternative to vanilla fine-tuning",
    "checked": true,
    "id": "bf722dc893ddaad5045fca5646212ec3badf3c5a",
    "semantic_title": "prompt-learning for fine-grained entity typing",
    "citation_count": 110,
    "authors": [
      "Ning Ding",
      "Yulin Chen",
      "Xu Han",
      "Guangwei Xu",
      "Xiaobin Wang",
      "Pengjun Xie",
      "Haitao Zheng",
      "Zhiyuan Liu",
      "Juanzi Li",
      "Hong-Gee Kim"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.513": {
    "title": "TransLIST: A Transformer-Based Linguistically Informed Sanskrit Tokenizer",
    "volume": "findings",
    "abstract": "Sanskrit Word Segmentation (SWS) is essential in making digitized texts available and in deploying downstream tasks. It is, however, non-trivial because of the sandhi phenomenon that modifies the characters at the word boundaries, and needs special treatment. Existing lexicon driven approaches for SWS make use of Sanskrit Heritage Reader, a lexicon-driven shallow parser, to generate the complete candidate solution space, over which various methods are applied to produce the most valid solution. However, these approaches fail while encountering out-of-vocabulary tokens. On the other hand, purely engineering methods for SWS have made use of recent advances in deep learning, but cannot make use of the latent word information on availability. To mitigate the shortcomings of both families of approaches, we propose Transformer based Linguistically Informed Sanskrit Tokenizer (TransLIST) consisting of (1) a module that encodes the character input along with latent-word information, which takes into account the sandhi phenomenon specific to SWS and is apt to work with partial or no candidate solutions, (2) a novel soft-masked attention to prioritize potential candidate words and (3) a novel path ranking algorithm to rectify the corrupted predictions. Experiments on the benchmark datasets for SWS show that TransLIST outperforms the current state-of-the-art system by an average 7.2 points absolute gain in terms of perfect match (PM) metric",
    "checked": true,
    "id": "abc2280a8ea693643960cebbd687edd0ea57a928",
    "semantic_title": "translist: a transformer-based linguistically informed sanskrit tokenizer",
    "citation_count": 3,
    "authors": [
      "Jivnesh Sandhan",
      "Rathin Singha",
      "Narein Rao",
      "Suvendu Samanta",
      "Laxmidhar Behera",
      "Pawan Goyal"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.514": {
    "title": "Fair NLP Models with Differentially Private Text Encoders",
    "volume": "findings",
    "abstract": "Encoded text representations often capture sensitive attributes about individuals (e.g., race or gender), which raise privacy concerns and can make downstream models unfair to certain groups. In this work, we propose FEDERATE, an approach that combines ideas from differential privacy and adversarial training to learn private text representations which also induces fairer models. We empirically evaluate the trade-off between the privacy of the representations and the fairness and accuracy of the downstream model on four NLP datasets. Our results show that FEDERATE consistently improves upon previous methods, and thus suggest that privacy and fairness can positively reinforce each other",
    "checked": true,
    "id": "9b78140aa26f738a7a225d505ad34023ff3b6d61",
    "semantic_title": "fair nlp models with differentially private text encoders",
    "citation_count": 5,
    "authors": [
      "Gaurav Maheshwari",
      "Pascal Denis",
      "Mikaela Keller",
      "Aurélien Bellet"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.515": {
    "title": "Modeling Context With Linear Attention for Scalable Document-Level Translation",
    "volume": "findings",
    "abstract": "Document-level machine translation leverages inter-sentence dependencies to produce more coherent and consistent translations. However, these models, predominantly based on transformers, are difficult to scale to long documents as their attention layers have quadratic complexity in the sequence length. Recent efforts on efficient attention improve scalability, but their effect on document translation remains unexplored. In this work, we investigate the efficacy of a recent linear attention model by Peng et al. (2021) on document translation and augment it with a sentential gate to promote a recency inductive bias. We evaluate the model on IWSLT 2015 and OpenSubtitles 2018 against the transformer, demonstrating substantially increased decoding speed on long sequences with similar or better BLEU scores. We show that sentential gating further improves translation quality on IWSLT",
    "checked": true,
    "id": "296c4ff39184fb7787954bc4e1a5bde89e16c16e",
    "semantic_title": "modeling context with linear attention for scalable document-level translation",
    "citation_count": 3,
    "authors": [
      "Zhaofeng Wu",
      "Hao Peng",
      "Nikolaos Pappas",
      "Noah A. Smith"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.516": {
    "title": "What do Large Language Models Learn beyond Language?",
    "volume": "findings",
    "abstract": "Large language models (LMs) have rapidly become a mainstay in Natural Language Processing. These models are known to acquire rich linguistic knowledge from training on large amounts of text. In this paper, we investigate if pre-training on text also confers these models with helpful ‘inductive biases' for non-linguistic reasoning. On a set of 19 diverse non-linguistic tasks involving quantitative computations, recognizing regular expressions and reasoning over strings. We find that pretrained models significantly outperform comparable non-pretrained neural models. This remains true also in experiments with training non-pretrained models with fewer parameters to account for model regularization effects. We further explore the effect of text domain on LMs by pretraining models from text from different domains and provenances. Our experiments surprisingly reveal that the positive effects of pre-training persist even when pretraining on multi-lingual text or computer code, and even for text generated from synthetic languages. Our findings suggest a hithertho unexplored deep connection between pre-training and inductive learning abilities of language models",
    "checked": true,
    "id": "5efab88c0cdb11c795fa8f44a5d31b40e2a1c261",
    "semantic_title": "what do large language models learn beyond language?",
    "citation_count": 4,
    "authors": [
      "Avinash Madasu",
      "Shashank Srivastava"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.517": {
    "title": "CONSISTENT: Open-Ended Question Generation From News Articles",
    "volume": "findings",
    "abstract": "Recent work on question generation has largely focused on factoid questions such as who, what,where, when about basic facts. Generating open-ended why, how, what, etc. questions thatrequire long-form answers have proven more difficult. To facilitate the generation of openended questions, we propose CONSISTENT, a new end-to-end system for generating openended questions that are answerable from and faithful to the input text. Using news articles asa trustworthy foundation for experimentation, we demonstrate our model's strength over several baselines using both automatic and human based evaluations. We contribute an evaluationdataset of expert-generated open-ended questions. We discuss potential downstream applications for news media organizations",
    "checked": true,
    "id": "91eb2e73f8f3574c00dc6787a3e277eedaf33531",
    "semantic_title": "consistent: open-ended question generation from news articles",
    "citation_count": 6,
    "authors": [
      "Tuhin Chakrabarty",
      "Justin Lewis",
      "Smaranda Muresan"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.518": {
    "title": "Efficient (Soft) Q-Learning for Text Generation with Limited Good Data",
    "volume": "findings",
    "abstract": "Maximum likelihood estimation (MLE) is the predominant algorithm for training text generation models. This paradigm relies on direct supervision examples, which is not applicable to many emerging applications, such as generating adversarial attacks or generating prompts to control language models. Reinforcement learning (RL) on the other hand offers a more flexible solution by allowing users to plug in arbitrary task metrics as reward. Yet previous RL algorithms for text generation, such as policy gradient (on-policy RL) and Q-learning (off-policy RL), are often notoriously inefficient or unstable to train due to the large sequence space and the sparse reward received only at the end of sequences. In this paper, we introduce a new RL formulation for text generation from the soft Q-learning (SQL) perspective. It enables us to draw from the latest RL advances, such as path consistency learning, to combine the best of on-/off-policy updates, and learn effectively from sparse reward. We apply the approach to a wide range of novel text generation tasks, including learning from noisy/negative examples, adversarial attacks, and prompt generation. Experiments show our approach consistently outperforms both task-specialized algorithms and the previous RL methods",
    "checked": true,
    "id": "f3a2bc491bb9c96e14a728de0b0adf9228569ffd",
    "semantic_title": "efficient (soft) q-learning for text generation with limited good data",
    "citation_count": 14,
    "authors": [
      "Han Guo",
      "Bowen Tan",
      "Zhengzhong Liu",
      "Eric Xing",
      "Zhiting Hu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.519": {
    "title": "Lexi: Self-Supervised Learning of the UI Language",
    "volume": "findings",
    "abstract": "Humans can learn to operate the user interface (UI) of an application by reading an instruction manual or how-to guide. Along with text, these resources include visual content such as UI screenshots and images of application icons referenced in the text. We explore how to leverage this data to learn generic visio-linguistic representations of UI screens and their components. These representations are useful in many real applications, such as accessibility, voice navigation, and task automation. Prior UI representation models rely on UI metadata (UI trees and accessibility labels), which is often missing, incompletely defined, or not accessible. We avoid such a dependency, and propose Lexi, a pre-trained vision and language model designed to handle the unique features of UI screens, including their text richness and context sensitivity. To train Lexi we curate the UICaption dataset consisting of 114k UI images paired with descriptions of their functionality. We evaluate Lexi on four tasks: UI action entailment, instruction-based UI image retrieval, grounding referring expressions, and UI entity recognition",
    "checked": true,
    "id": "6651201d8662e2c845c1ee211d0405029a5cd840",
    "semantic_title": "lexi: self-supervised learning of the ui language",
    "citation_count": 5,
    "authors": [
      "Pratyay Banerjee",
      "Shweti Mahajan",
      "Kushal Arora",
      "Chitta Baral",
      "Oriana Riva"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.520": {
    "title": "Inferring the Reader: Guiding Automated Story Generation with Commonsense Reasoning",
    "volume": "findings",
    "abstract": "Transformer-based language model approaches to automated story generation currently provide state-of-the-art results. However, they still suffer from plot incoherence when generatingnarratives over time, and critically lack basiccommonsense reasoning. Furthermore, existing methods generally focus only on single-character stories, or fail to track charactersat all. To improve the coherence of generated narratives and to expand the scope ofcharacter-centric narrative generation, we introduce Commonsense-inference Augmentedneural StoryTelling (CAST), a framework forintroducing commonsense reasoning into thegeneration process with the option to model theinteraction between multiple characters. Wefind that our CAST method produces significantly more coherent, on-topic, enjoyable andfluent stories than existing models in both thesingle-character and two-character settings inthree storytelling domains",
    "checked": true,
    "id": "a791712371ed865cb6debe9cb4d5fd59a3405b85",
    "semantic_title": "inferring the reader: guiding automated story generation with commonsense reasoning",
    "citation_count": 28,
    "authors": [
      "Xiangyu Peng",
      "Siyan Li",
      "Sarah Wiegreffe",
      "Mark Riedl"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.521": {
    "title": "How to Stop an Avalanche? JoDeM: Joint Decision Making through Compare and Contrast for Dialog State Tracking",
    "volume": "findings",
    "abstract": "Dialog state tracking (DST) is a core component in task-oriented dialog systems. Existing state-of-the-art DST model incorporates insight and intuition from the human experience into design of supplementary labels, which greatly assisted the training process of turn-by-turn DST model. Though the turn-by-turn scheme and supplementary labels enabled satisfactory performance on the task, most of the DST models of this fashion label or process the raw dialogue data on the premise that the last turn dialogue state is always correct, which is usually not the case. In this paper, we address the negative impact resulted from the premise above as the avalanche phenomenon. After that, we propose JoDeM, a state-of-the-art DST model which can tackle the Avalanche phenomenon with two mechanisms. First mechanism is a jointly decision making method to extract key information from the dialogue. Second mechanism is a compare and contrast dialogue update technique to prevent error accumulation. Example study and graph analysis are presented to support our claim about the harmfulness of avalanche phenomenon. We also conduct quantitative and qualitative experiments on the high quality MultiWOZ2.3 corpus dataset to demonstrate that the proposed model not only outperforms the existing state-of-the-art methods, but also proves the validity of solving avalanche degradation problem",
    "checked": true,
    "id": "8139abed3d73727e6ba7ad8f513f7640174fee88",
    "semantic_title": "how to stop an avalanche? jodem: joint decision making through compare and contrast for dialog state tracking",
    "citation_count": 1,
    "authors": [
      "Haoming Wang",
      "Wang Xin"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.522": {
    "title": "Contrastive Learning with Prompt-derived Virtual Semantic Prototypes for Unsupervised Sentence Embedding",
    "volume": "findings",
    "abstract": "Contrastive learning has become a new paradigm for unsupervised sentence embeddings.Previous studies focus on instance-wise contrastive learning, attempting to construct positive pairs with textual data augmentation. In this paper, we propose a novel Contrastive learning method with Prompt-derived Virtual semantic Prototypes (ConPVP). Specifically, with the help of prompts, we construct virtual semantic prototypes to each instance, and derive negative prototypes by using the negative form of the prompts. Using a prototypical contrastive loss, we enforce the anchor sentence embedding to be close to its corresponding semantic prototypes, and far apart from the negative prototypes as well as the prototypes of other sentences. Extensive experimental results on semantic textual similarity, transfer, and clustering tasks demonstrate the effectiveness of our proposed model compared to strong baselines. Code is available at https://github.com/lemon0830/promptCSE",
    "checked": true,
    "id": "795a1de1c4c8b9cb3a354a474c2d9a8179cb8191",
    "semantic_title": "contrastive learning with prompt-derived virtual semantic prototypes for unsupervised sentence embedding",
    "citation_count": 8,
    "authors": [
      "Jiali Zeng",
      "Yongjing Yin",
      "Yufan Jiang",
      "Shuangzhi Wu",
      "Yunbo Cao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.523": {
    "title": "Weight Perturbation as Defense against Adversarial Word Substitutions",
    "volume": "findings",
    "abstract": "The existence and pervasiveness of textual adversarial examples have raised serious concerns to security-critical applications. Many methods have been developed to defend against adversarial attacks for neural natural language processing (NLP) models. Adversarial training is one of the most successful defense methods by adding some random or intentional perturbations to the original input texts and making the models robust to the perturbed examples. In this study, we explore the feasibility of improving the adversarial robustness of NLP models by performing perturbations in the parameter space rather than the input feature space. The weight perturbation helps to find a better solution (i.e., the values of weights) that minimizes the adversarial loss among other feasible solutions. We found that the weight perturbation can significantly improve the robustness of NLP models when it is combined with the perturbation in the input embedding space, yielding the highest accuracy on both clean and adversarial examples across different datasets",
    "checked": true,
    "id": "5cb2d3e086d16db4756daa713966f4daf34bc8b2",
    "semantic_title": "weight perturbation as defense against adversarial word substitutions",
    "citation_count": 0,
    "authors": [
      "Jianhan Xu",
      "Linyang Li",
      "Jiping Zhang",
      "Xiaoqing Zheng",
      "Kai-Wei Chang",
      "Cho-Jui Hsieh",
      "Xuanjing Huang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.524": {
    "title": "CORT: A New Baseline for Comparative Opinion Classification by Dual Prompts",
    "volume": "findings",
    "abstract": "Comparative opinion is a common linguistic phenomenon. The opinion is expressed by comparing multiple targets on a shared aspect, e.g., \"camera A is better than camera B in picture quality\". Among the various subtasks in opinion mining, comparative opinion classification is relatively less studied. Current solutions use rules or classifiers to identify opinions, i.e., better, worse, or same, through feature engineering. Because the features are directly derived from the input sentence, these solutions are sensitive to the order of the targets mentioned in the sentence. For example, \"camera A is better than camera B\" means the same as \"camera B is worse than camera A\"; but the features of these two sentences are completely different. In this paper, we approach comparative opinion classification through prompt learning, taking the advantage of embedded knowledge in pre-trained language model. We design a twin framework with dual prompts, named CORT. This extremely simple model delivers state-of-the-art and robust performance on all benchmark datasets for comparative opinion classification. We believe CORT well serves as a new baseline for comparative opinion classification",
    "checked": true,
    "id": "98c8555b8999fa5df058b21a48de31364cb51363",
    "semantic_title": "cort: a new baseline for comparative opinion classification by dual prompts",
    "citation_count": 4,
    "authors": [
      "Yequan Wang",
      "Hengran Zhang",
      "Aixin Sun",
      "Xuying Meng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.525": {
    "title": "APEACH: Attacking Pejorative Expressions with Analysis on Crowd-Generated Hate Speech Evaluation Datasets",
    "volume": "findings",
    "abstract": "In hate speech detection, developing training and evaluation datasets across various domains is the critical issue. Whereas, major approaches crawl social media texts and hire crowd-workers to annotate the data. Following this convention often restricts the scope of pejorative expressions to a single domain lacking generalization. Sometimes domain overlap between training corpus and evaluation set overestimate the prediction performance when pretraining language models on low-data language. To alleviate these problems in Korean, we propose APEACH that asks unspecified users to generate hate speech examples followed by minimal post-labeling. We find that APEACH can collect useful datasets that are less sensitive to the lexical overlaps between the pretraining corpus and the evaluation set, thereby properly measuring the model performance",
    "checked": true,
    "id": "4ec9e75af8046ba664e14d761befebe8713cc790",
    "semantic_title": "apeach: attacking pejorative expressions with analysis on crowd-generated hate speech evaluation datasets",
    "citation_count": 12,
    "authors": [
      "Kichang Yang",
      "Wonjun Jang",
      "Won Ik Cho"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.526": {
    "title": "Guiding Neural Story Generation with Reader Models",
    "volume": "findings",
    "abstract": "Automated storytelling has long captured the attention of researchers for the ubiquity of narratives in everyday life. However, it is challenging to maintain coherence and stay on-topictoward a specific ending when generating narratives with neural language models. In this paper, we introduce Story generation with ReaderModels (StoRM), a framework in which areader model is used to reason about the storyshould progress. A reader model infers whata human reader believes about the concepts,entities, and relations about the fictional storyworld. We show how an explicit reader modelrepresented as a knowledge graph affords the storycoherence and provides controllability in theform of achieving a given story world stategoal. Experiments show that our model produces significantly more coherent and on-topicstories, outperforming baselines in dimensionsincluding plot plausibility and staying on topic",
    "checked": true,
    "id": "03f079c0d6d5b14a3948e55de0f40677d9634338",
    "semantic_title": "guiding neural story generation with reader models",
    "citation_count": 8,
    "authors": [
      "Xiangyu Peng",
      "Kaige Xie",
      "Amal Alabdulkarim",
      "Harshith Kayam",
      "Samihan Dani",
      "Mark Riedl"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.527": {
    "title": "Reason first, then respond: Modular Generation for Knowledge-infused Dialogue",
    "volume": "findings",
    "abstract": "Large language models can produce fluent dialogue but often hallucinate factual inaccuracies. While retrieval-augmented models help alleviate this issue, they still face a difficult challenge of both reasoning to provide correct knowledge and generating conversation simultaneously. In this work, we propose a modular model, Knowledge to Response (K2R), for incorporating knowledge into conversational agents, which breaks down this problem into two easier steps. K2R first generates a knowledge sequence, given a dialogue context, as an intermediate step. After this \"reasoning step\", the model then attends to its own generated knowledge sequence, as well as the dialogue context, to produce a final response. In detailed experiments, we find that such a model hallucinates less in knowledge-grounded dialogue tasks, and has advantages in terms of interpretability and modularity. In particular, it can be used to fuse QA and dialogue systems together to enable dialogue agents to give knowledgeable answers, or QA models to give conversational responses in a zero-shot setting",
    "checked": true,
    "id": "d15d96517370c9ed0658d176b979bcf92d1373ea",
    "semantic_title": "reason first, then respond: modular generation for knowledge-infused dialogue",
    "citation_count": 29,
    "authors": [
      "Leonard Adolphs",
      "Kurt Shuster",
      "Jack Urbanek",
      "Arthur Szlam",
      "Jason Weston"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.528": {
    "title": "Adapting Multilingual Models for Code-Mixed Translation",
    "volume": "findings",
    "abstract": "The scarcity of gold standard code-mixed to pure language parallel data makes it difficult to train translation models reliably. Prior work has addressed the paucity of parallel data with data augmentation techniques. Such methods rely heavily on external resources making systems difficult to train and scale effectively for multiple languages. We present a simple yet highly effective two-stage back-translation based training scheme for adapting multilingual models to the task of code-mixed translation which eliminates dependence on external resources. We show a substantial improvement in translation quality (measured through BLEU), beating existing prior work by up to +3.8 BLEU on code-mixed Hi→En, Mr→En, and Bn→En tasks. On the LinCE Machine Translation leader board, we achieve the highest score for code-mixed Es→En, beating existing best baseline by +6.5 BLEU, and our own stronger baseline by +1.1 BLEU",
    "checked": true,
    "id": "bec12266cf14fafe8d26a66e11d3d5281b5214ea",
    "semantic_title": "adapting multilingual models for code-mixed translation",
    "citation_count": 0,
    "authors": [
      "Aditya Vavre",
      "Abhirut Gupta",
      "Sunita Sarawagi"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.529": {
    "title": "LPC: A Logits and Parameter Calibration Framework for Continual Learning",
    "volume": "findings",
    "abstract": "When we execute the typical fine-tuning paradigm on continuously sequential tasks, the model will suffer from the catastrophic forgetting problem (i.e., the model tends to adjust old parameters according to the new knowledge, which leads to the loss of previously acquired concepts). People proposed replay-based methods by accessing old data from extra storage and maintaining the parameters of old concepts, which actually raise the privacy issue and larger memory requirements. In this work, we aim to achieve the sequential/continual learning of knowledge without accessing the old data. The core idea is to calibrate the parameters and logits (output) so that preserving old parameters and generalized learning on new concepts can be solved simultaneously. Our proposed framework includes two major components, Logits Calibration (LC) and Parameter Calibration (PC). The LC focuses on calibrating the learning of novel models with old models, and PC aims to preserve the parameters of old models. These two operations can maintain the old knowledge while learning new tasks without storing previous data. We conduct experiments on various scenarios of the GLUE (the General Language Understanding Evaluation) benchmark. The experimental results show that our model achieves state-of-the-art performance in all scenarios",
    "checked": true,
    "id": "c3aa4b96e20fec0872f75f2b227b4b12cb43fdf2",
    "semantic_title": "lpc: a logits and parameter calibration framework for continual learning",
    "citation_count": 3,
    "authors": [
      "Xiaodi Li",
      "Zhuoyi Wang",
      "Dingcheng Li",
      "Latifur Khan",
      "Bhavani Thuraisingham"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.530": {
    "title": "SlovakBERT: Slovak Masked Language Model",
    "volume": "findings",
    "abstract": "We introduce a new Slovak masked language model called SlovakBERT. This is to our best knowledge the first paper discussing Slovak transformers-based language models. We evaluate our model on several NLP tasks and achieve state-of-the-art results. This evaluation is likewise the first attempt to establish a benchmark for Slovak language models. We publish the masked language model, as well as the fine-tuned models for part-of-speech tagging, sentiment analysis and semantic textual similarity",
    "checked": true,
    "id": "09ed8c5a4b9b9e516c61415ce99ccd9b3170a1f7",
    "semantic_title": "slovakbert: slovak masked language model",
    "citation_count": 16,
    "authors": [
      "Matúš Pikuliak",
      "Štefan Grivalský",
      "Martin Konôpka",
      "Miroslav Blšták",
      "Martin Tamajka",
      "Viktor Bachratý",
      "Marian Simko",
      "Pavol Balážik",
      "Michal Trnka",
      "Filip Uhlárik"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.531": {
    "title": "Efficient Zero-shot Event Extraction with Context-Definition Alignment",
    "volume": "findings",
    "abstract": "Event extraction (EE) is the task of identifying interested event mentions from text. Conventional efforts mainly focus on the supervised setting. However, these supervised models cannot generalize to event types out of the pre-defined ontology. To fill this gap, many efforts have been devoted to the zero-shot EE problem. This paper follows the trend of modeling event-type semantics but moves one step further. We argue that using the static embedding of the event type name might not be enough because a single word could be ambiguous, and we need a sentence to define the type semantics accurately. To model the definition semantics, we use two separate transformer models to project the contextualized event mentions and corresponding definitions into the same embedding space and then minimize their embedding distance via contrastive learning. On top of that, we also propose a warming phase to help the model learn the minor difference between similar definitions. We name our approach Zero-shot Event extraction with Definition (ZED). Experiments on the MAVEN dataset show that our model significantly outperforms all previous zero-shot EE methods with fast inference speed due to the disjoint design. Further experiments also show that can be easily applied to the few-shot setting when the annotation is available and consistently outperforms baseline supervised methods",
    "checked": true,
    "id": "9a2cab90038c22f35ccb40e9af90cfe33ccfa650",
    "semantic_title": "efficient zero-shot event extraction with context-definition alignment",
    "citation_count": 8,
    "authors": [
      "Hongming Zhang",
      "Wenlin Yao",
      "Dong Yu"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.532": {
    "title": "Logical Fallacy Detection",
    "volume": "findings",
    "abstract": "Reasoning is central to human intelligence. However, fallacious arguments are common, and some exacerbate problems such as spreading misinformation about climate change. In this paper, we propose the task of logical fallacy detection, and provide a new dataset (Logic) of logical fallacies generally found in text, together with an additional challenge set for detecting logical fallacies in climate change claims (LogicClimate). Detecting logical fallacies is a hard problem as the model must understand the underlying logical structure of the argument. We find that existing pretrained large language models perform poorly on this task. In contrast, we show that a simple structure-aware classifier outperforms the best language model by 5.46% F1 scores on Logic and 4.51% on LogicClimate. We encourage future work to explore this task since (a) it can serve as a new reasoning challenge for language models, and (b) it can have potential applications in tackling the spread of misinformation. Our dataset and code are available at https://github.com/causalNLP/logical-fallacy",
    "checked": true,
    "id": "faaa21f4c2062d4099e4d24997a189f1c1400304",
    "semantic_title": "logical fallacy detection",
    "citation_count": 18,
    "authors": [
      "Zhijing Jin",
      "Abhinav Lalwani",
      "Tejas Vaidhya",
      "Xiaoyu Shen",
      "Yiwen Ding",
      "Zhiheng Lyu",
      "Mrinmaya Sachan",
      "Rada Mihalcea",
      "Bernhard Schoelkopf"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.533": {
    "title": "Topic-Aware Response Generation in Task-Oriented Dialogue with Unstructured Knowledge Access",
    "volume": "findings",
    "abstract": "To alleviate the problem of structured databases' limited coverage, recent task-oriented dialogue systems incorporate external unstructured knowledge to guide the generation of system responses. However, these usually use word or sentence level similarities to detect the relevant knowledge context, which only partially capture the topical level relevance. In this paper, we examine how to better integrate topical information in knowledge grounded task-oriented dialogue and propose \"Topic-Aware Response Generation\" (TARG), an end-to-end response generation model. TARG incorporates multiple topic-aware attention mechanisms to derive the importance weighting scheme over dialogue utterances and external knowledge sources towards a better understanding of the dialogue history. Experimental results indicate that TARG achieves state-of-the-art performance in knowledge selection and response generation, outperforming previous state-of-the-art by 3.2, 3.6, and 4.2 points in EM, F1 and BLEU-4 respectively on Doc2Dial, and performing comparably with previous work on DSTC9; both being knowledge-grounded task-oriented dialogue datasets",
    "checked": true,
    "id": "8dbd8cf8d6e37237f58809e5844ee565640aa95a",
    "semantic_title": "topic-aware response generation in task-oriented dialogue with unstructured knowledge access",
    "citation_count": 2,
    "authors": [
      "Yue Feng",
      "Gerasimos Lampouras",
      "Ignacio Iacobacci"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.534": {
    "title": "Revisiting Transformer-based Models for Long Document Classification",
    "volume": "findings",
    "abstract": "The recent literature in text classification is biased towards short text sequences (e.g., sentences or paragraphs). In real-world applications, multi-page multi-paragraph documents are common and they cannot be efficiently encoded by vanilla Transformer-based models. We compare different Transformer-based Long Document Classification (TrLDC) approaches that aim to mitigate the computational overhead of vanilla transformers to encode much longer text, namely sparse attention and hierarchical encoding methods. We examine several aspects of sparse attention (e.g., size of local attention window, use of global attention) and hierarchical (e.g., document splitting strategy) transformers on four document classification datasets covering different domains. We observe a clear benefit from being able to process longer text, and, based on our results, we derive practical advice of applying Transformer-based models on long document classification tasks",
    "checked": true,
    "id": "cc2d1a66c701e9be9124eb95431b6c3dd79a61d3",
    "semantic_title": "revisiting transformer-based models for long document classification",
    "citation_count": 44,
    "authors": [
      "Xiang Dai",
      "Ilias Chalkidis",
      "Sune Darkner",
      "Desmond Elliott"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.535": {
    "title": "Time-aware Prompting for Text Generation",
    "volume": "findings",
    "abstract": "In this paper, we study the effects of incorporating timestamps, such as document creation dates, into generation systems. Two types of time-aware prompts are investigated: (1) textual prompts that encode document timestamps in natural language sentences; and (2) linear prompts that convert timestamps into continuous vectors. To explore extrapolation to future data points, we further introduce a new data-to-text generation dataset, TempWikiBio, containing more than 4 millions of chronologically ordered revisions of biographical articles from English Wikipedia, each paired with structured personal profiles. Through data-to-text generation on TempWikiBio, text-to-text generation on the content transfer dataset, and summarization on XSum,we show that linear prompts on encoder and textual prompts improve the generation quality on all datasets. Despite having less performance drop when testing on data drawn from a later time, linear prompts focus more on non-temporal information and are less sensitive to the given timestamps, according to human evaluations and sensitivity analyses. Meanwhile, textual prompts establish the association between the given timestamps and the output dates, yielding more factual temporal information in the output",
    "checked": true,
    "id": "c36ab572b5be7a470b725b87e369038295d5e7ab",
    "semantic_title": "time-aware prompting for text generation",
    "citation_count": 8,
    "authors": [
      "Shuyang Cao",
      "Lu Wang"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.536": {
    "title": "Improving Scheduled Sampling with Elastic Weight Consolidation for Neural Machine Translation",
    "volume": "findings",
    "abstract": "Despite strong performance in many sequence-to-sequence tasks, autoregressive models trained with maximum likelihood estimation suffer from exposure bias, i.e. the discrepancy between the ground-truth prefixes used during training and the model-generated prefixes used at inference time. Scheduled sampling is a simple and empirically successful approach which addresses this issue by incorporating model-generated prefixes into training. However, it has been argued that it is an inconsistent training objective leading to models ignoring the prefixes altogether. In this paper, we conduct systematic experiments and find that scheduled sampling, while it ameliorates exposure bias by increasing model reliance on the input sequence, worsens performance when the prefix at inference time is correct, a form of catastrophic forgetting. We propose to use Elastic Weight Consolidation to better balance mitigating exposure bias with retaining performance. Experiments on four IWSLT'14 and WMT'14 translation datasets demonstrate that our approach alleviates catastrophic forgetting and significantly outperforms maximum likelihood estimation and scheduled sampling baselines",
    "checked": true,
    "id": "6c2ef65cb0c3d204ca557d83c78b8d17657bdeca",
    "semantic_title": "improving scheduled sampling with elastic weight consolidation for neural machine translation",
    "citation_count": 0,
    "authors": [
      "Michalis Korakakis",
      "Andreas Vlachos"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.537": {
    "title": "Ensemble Transformer for Efficient and Accurate Ranking Tasks: an Application to Question Answering Systems",
    "volume": "findings",
    "abstract": "Large transformer models can highly improve Answer Sentence Selection (AS2) tasks, but their high computational costs prevent their use in many real-world applications. In this paper, we explore the following research question: How can we make the AS2 models more accurate without significantly increasing their model complexity? To address the question, we propose a Multiple Heads Student architecture (named CERBERUS), an efficient neural network designed to distill an ensemble of large transformers into a single smaller model. CERBERUS consists of two components: a stack of transformer layers that is used to encode inputs, and a set of ranking heads; unlike traditional distillation technique, each of them is trained by distilling a different large transformer architecture in a way that preserves the diversity of the ensemble members. The resulting model captures the knowledge of heterogeneous transformer models by using just a few extra parameters. We show the effectiveness of CERBERUS on three English datasets for AS2; our proposed approach outperforms all single-model distillations we consider, rivaling the state-of-the-art large AS2 models that have 2.7× more parameters and run 2.5× slower. Code for our model is available at https://github.com/amazon-research/wqa-cerberus",
    "checked": true,
    "id": "df36065bbf5041cb06d066591a87e813cb7ade09",
    "semantic_title": "ensemble transformer for efficient and accurate ranking tasks: an application to question answering systems",
    "citation_count": 5,
    "authors": [
      "Yoshitomo Matsubara",
      "Luca Soldaini",
      "Eric Lind",
      "Alessandro Moschitti"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.538": {
    "title": "Uncertainty Quantification with Pre-trained Language Models: A Large-Scale Empirical Analysis",
    "volume": "findings",
    "abstract": "Pre-trained language models (PLMs) have gained increasing popularity due to their compelling prediction performance in diverse natural language processing (NLP) tasks. When formulating a PLM-based prediction pipeline for NLP tasks, it is also crucial for the pipeline to minimize the calibration error, especially in safety-critical applications. That is, the pipeline should reliably indicate when we can trust its predictions. In particular, there are various considerations behind the pipeline: (1) the choice and (2) the size of PLM, (3) the choice of uncertainty quantifier, (4) the choice of fine-tuning loss, and many more. Although prior work has looked into some of these considerations, they usually draw conclusions based on a limited scope of empirical studies. There still lacks a holistic analysis on how to compose a well-calibrated PLM-based prediction pipeline. To fill this void, we compare a wide range of popular options for each consideration based on three prevalent NLP classification tasks and the setting of domain shift. In response, we recommend the following: (1) use ELECTRA for PLM encoding, (2) use larger PLMs if possible, (3) use Temp Scaling as the uncertainty quantifier, and (4) use Focal Loss for fine-tuning",
    "checked": true,
    "id": "551b05734eb2181c4ca009a411144e8447ed1606",
    "semantic_title": "uncertainty quantification with pre-trained language models: a large-scale empirical analysis",
    "citation_count": 34,
    "authors": [
      "Yuxin Xiao",
      "Paul Pu Liang",
      "Umang Bhatt",
      "Willie Neiswanger",
      "Ruslan Salakhutdinov",
      "Louis-Philippe Morency"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.539": {
    "title": "How to Represent Context Better? An Empirical Study on Context Modeling for Multi-turn Response Selection",
    "volume": "findings",
    "abstract": "Building retrieval-based dialogue models that can predict appropriate responses based on the understanding of multi-turn context messages is a challenging problem. Early models usually concatenate all utterances or independently encode each dialogue turn, which may lead to an inadequate understanding of dialogue status. Although a few researchers have noticed the importance of context modeling in multi-turn response prediction, there is no systematic comparison to analyze how to model context effectively and no framework to unify those methods. In this paper, instead of configuring new architectures, we investigate how to improve existing models with a better context modeling method. Specifically, we heuristically summarize three categories of turn-aware context modeling strategies which model the context messages from the perspective of sequential relationship, local relationship, and query-aware manner respectively. A Turn-Aware Context Modeling (TACM) layer is explored to flexibly adapt and unify these context modeling strategies to several advanced response selection models. Evaluation results on three public data sets indicate that employing each individual context modeling strategy or multiple strategies can consistently improve the performance of existing models",
    "checked": true,
    "id": "c541a403facebd93dcf7f18e10a595a35360e845",
    "semantic_title": "how to represent context better? an empirical study on context modeling for multi-turn response selection",
    "citation_count": 2,
    "authors": [
      "Jiazhan Feng",
      "Chongyang Tao",
      "Chang Liu",
      "Rui Yan",
      "Dongyan Zhao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.540": {
    "title": "CHIA: CHoosing Instances to Annotate for Machine Translation",
    "volume": "findings",
    "abstract": "Neural machine translation (MT) systems have been shown to perform poorly on low-resource language pairs, for which large-scale parallel data is unavailable. Making the data annotation process faster and cheaper is therefore important to ensure equitable access to MT systems. To make optimal use of a limited annotation budget, we present CHIA (choosing instances to annotate), a method for selecting instances to annotate for machine translation. Using an existing multi-way parallel dataset of high-resource languages, we first identify instances, based on model training dynamics, that are most informative for training MT models for high-resource languages. We find that there are cross-lingual commonalities in instances that are useful for MT model training, which we use to identify instances that will be useful to train models on a new target language. Evaluating on 20 languages from two corpora, we show that training on instances selected using our method provides an average performance improvement of 1.59 BLEU over training on randomly selected instances of the same size",
    "checked": true,
    "id": "75fbf14e8be711552bd1e7e2eec966fc6874cd54",
    "semantic_title": "chia: choosing instances to annotate for machine translation",
    "citation_count": 4,
    "authors": [
      "Rajat Bhatnagar",
      "Ananya Ganesh",
      "Katharina Kann"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.541": {
    "title": "Guiding Neural Machine Translation with Semantic Kernels",
    "volume": "findings",
    "abstract": "Machine Translation task has made great progress with the help of auto-regressive decoding paradigm and Transformer architecture. In this paradigm, though the encoder can obtain global source representations, the decoder can only use translation history to determine the current word. Previous promising works attempted to address this issue by applying a draft or a fixed-length semantic embedding as target-side global information. However, these methods either degrade model efficiency or show limitations in expressing semantics. Motivated by Functional Equivalence Theory, we extract several semantic kernels from a source sentence, each of which can express one semantic segment of the original sentence. Together, these semantic kernels can capture global semantic information, and we project them into target embedding space to guide target sentence generation. We further force our model to use semantic kernels at each decoding step through an adaptive mask algorithm. Empirical studies on various machine translation benchmarks show that our approach gains approximately an improvement of 1 BLEU score on most benchmarks over the Transformer baseline and about 1.7 times faster than previous works on average at inference time",
    "checked": true,
    "id": "da424ae00f53f0376a6aad67d83c70802af0db47",
    "semantic_title": "guiding neural machine translation with semantic kernels",
    "citation_count": 1,
    "authors": [
      "Ping Guo",
      "Yue Hu",
      "Xiangpeng Wei",
      "Yubing Ren",
      "Yunpeng Li",
      "Luxi Xing",
      "Yuqiang Xie"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.542": {
    "title": "HiSMatch: Historical Structure Matching based Temporal Knowledge Graph Reasoning",
    "volume": "findings",
    "abstract": "A Temporal Knowledge Graph (TKG) is a sequence of KGs with respective timestamps, which adopts quadruples in the form of (subject, relation, object, timestamp) to describe dynamic facts. TKG reasoning has facilitated many real-world applications via answering such queries as (query entity, query relation, ?, future timestamp) about future. This is actually a matching task between a query and candidate entities based on their historical structures, which reflect behavioral trends of the entities at different timestamps. In addition, recent KGs provide background knowledge of all the entities, which is also helpful for the matching. Thus, in this paper, we propose the Historical Structure Matching (HiSMatch) model. It applies two structure encoders to capture the semantic information contained in the historical structures of the query and candidate entities. Besides, it adopts another encoder to integrate the background knowledge into the model. TKG reasoning experiments on six benchmark datasets demonstrate the significant improvement of the proposed HiSMatch model, with up to 5.6% performance improvement in MRR, compared to the state-of-the-art baselines",
    "checked": true,
    "id": "7e17da15c878a448174372385dfd775cf9472e00",
    "semantic_title": "hismatch: historical structure matching based temporal knowledge graph reasoning",
    "citation_count": 11,
    "authors": [
      "Zixuan Li",
      "Zhongni Hou",
      "Saiping Guan",
      "Xiaolong Jin",
      "Weihua Peng",
      "Long Bai",
      "Yajuan Lyu",
      "Wei Li",
      "Jiafeng Guo",
      "Xueqi Cheng"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.543": {
    "title": "Dependency Parsing via Sequence Generation",
    "volume": "findings",
    "abstract": "Dependency parsing aims to extract syntactic dependency structure or semantic dependency structure for sentences. Existing methods for dependency parsing include transition-based method, graph-based method and sequence-to-sequence method. These methods obtain excellent performance and we notice them belong to labeling method. Therefore, it may be very valuable and interesting to explore the possibility of using generative method to implement dependency parsing. In this paper, we propose to achieve Dependency Parsing (DP) via Sequence Generation (SG) by utilizing only the pre-trained language model without any auxiliary structures. We first explore different serialization designing strategies for converting parsing structures into sequences. Then we design dependency units and concatenate these units into the sequence for DPSG.We verify the DPSG is capable of parsing on widely used DP benchmarks, i.e., PTB, UD2.2, SDP15 and SemEval16.In addition, we also investigate the astonishing low-resource applicability of DPSG, which includes unsupervised cross-domain conducted on CODT and few-shot cross-task conducted on SDP15.Our research demonstrates that sequence generation is one of the effective methods to achieve dependency parsing. Our codes are available now",
    "checked": true,
    "id": "1f8754d87fbf70398e3ffb95fe2eafbdd16dad1f",
    "semantic_title": "dependency parsing via sequence generation",
    "citation_count": 4,
    "authors": [
      "Boda Lin",
      "Zijun Yao",
      "Jiaxin Shi",
      "Shulin Cao",
      "Binghao Tang",
      "Si Li",
      "Yong Luo",
      "Juanzi Li",
      "Lei Hou"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.544": {
    "title": "Scaling Laws Under the Microscope: Predicting Transformer Performance from Small Scale Experiments",
    "volume": "findings",
    "abstract": "Neural scaling laws define a predictable relationship between a model's parameter count and its performance after training in the form of a power law. However, most research to date has not explicitly investigated whether scaling laws can be used to accelerate model development. In this work, we perform such an empirical investigation across a wide range of language understanding tasks, starting from models with as few as 10K parameters, and evaluate downstream performance across 9 language understanding tasks. We find that scaling laws emerge at finetuning time in some NLP tasks, and that they can also be exploited for debugging convergence when training large models. Moreover, for tasks where scaling laws exist, they can be used to predict the performance of larger models, which enables effective model selection. However, revealing scaling lawsrequires careful hyperparameter tuning and multiple runs for the purpose of uncertainty estimation, which incurs additional overhead, partially offsetting the computational benefits",
    "checked": true,
    "id": "e404bdfaa858b3c25540aa5d2c5dfe20c16ead37",
    "semantic_title": "scaling laws under the microscope: predicting transformer performance from small scale experiments",
    "citation_count": 11,
    "authors": [
      "Maor Ivgi",
      "Yair Carmon",
      "Jonathan Berant"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.545": {
    "title": "Analyzing the Limits of Self-Supervision in Handling Bias in Language",
    "volume": "findings",
    "abstract": "Prompting inputs with natural language task descriptions has emerged as a popular mechanism to elicit reasonably accurate outputs from large-scale generative language models with little to no in-context supervision. This also helps gain insight into how well language models capture the semantics of a wide range of downstream tasks purely from self-supervised pre-training on massive corpora of unlabeled text. Such models have naturally also been exposed to a lot of undesirable content like racist and sexist language and there is only some work on awareness of models along these dimensions. In this paper, we define and comprehensively evaluate how well such language models capture the semantics of four tasks for bias: diagnosis, identification, extraction and rephrasing. We define three broad classes of task descriptions for these tasks: statement, question, and completion, with numerous lexical variants within each class. We study the efficacy of prompting for each task using these classes and the null task description across several decoding methods and few-shot examples. Our analyses indicate that language models are capable of performing these tasks to widely varying degrees across different bias dimensions, such as gender and political affiliation. We believe our work is an important step towards unbiased language models by quantifying the limits of current self-supervision objectives at accomplishing such sociologically challenging tasks",
    "checked": true,
    "id": "e69afacfd13fa992483b4dbbdc6db2c63fdb0d8d",
    "semantic_title": "analyzing the limits of self-supervision in handling bias in language",
    "citation_count": 1,
    "authors": [
      "Lisa Bauer",
      "Karthik Gopalakrishnan",
      "Spandana Gella",
      "Yang Liu",
      "Mohit Bansal",
      "Dilek Hakkani-Tur"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.546": {
    "title": "Multiple Instance Learning for Offensive Language Detection",
    "volume": "findings",
    "abstract": "Automatic offensive language detection has become a crucial issue in recent years. Existing researches on this topic are usually based on a large amount of data annotated at sentence level to train a robust model. However, sentence-level annotations are expensive in practice as the scenario expands, while there exist a large amount of natural labels from historical information on online platforms such as reports and punishments. Notably, these natural labels are usually in bag-level corresponding to the whole documents (articles, user profiles, conversations, etc.). Therefore, we target at proposing an approach capable of utilizing the bag-level labeled data for offensive language detection in this study. For this purpose, we formalize this task into a multiple instance learning (MIL) problem. We break down the design of existing MIL methods and propose a hybrid fusion MIL model with mutual-attention mechanism. In order to verify the validity of the proposed method, we present two new bag-level labeled datasets for offensive language detection: OLID-bags and MINOR. Experimental results based on the proposed datasets demonstrate the effectiveness of the mutual-attention method at both sentence level and bag level",
    "checked": true,
    "id": "1bba3037e08baa527dffbf76ae6ea2959904f8c5",
    "semantic_title": "multiple instance learning for offensive language detection",
    "citation_count": 3,
    "authors": [
      "Jiexi Liu",
      "Dehan Kong",
      "Longtao Huang",
      "Dinghui Mao",
      "Hui Xue"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.547": {
    "title": "Grounded Keys-to-Text Generation: Towards Factual Open-Ended Generation",
    "volume": "findings",
    "abstract": "Large pre-trained language models have recently enabled open-ended generation frameworks (e.g., prompt-to-text NLG) to tackle a variety of tasks going beyond the traditional data-to-text generation. While this framework is more general, it is under-specified and often leads to a lack of controllability restricting their real-world usage. We propose a new grounded keys-to-text generation task: the task is to generate a factual description about an entity given a set of guiding keys, and grounding passages. To address this task, we introduce a new dataset, called EntDeGen. Inspired by recent QA-based evaluation measures, we propose an automatic metric, MAFE, for factual correctness of generated descriptions. Our EntDescriptor model is equipped with strong rankers to fetch helpful passages and generate entity descriptions. Experimental result shows a good correlation (60.14) between our proposed metric and human judgments of factuality. Our rankers significantly improved the factual correctness of generated descriptions (15.95% and 34.51% relative gains in recall and precision). Finally, our ablation study highlights the benefit of combining keys and groundings",
    "checked": true,
    "id": "32b3b990b00e890c44d769ac297889a7c75a394f",
    "semantic_title": "grounded keys-to-text generation: towards factual open-ended generation",
    "citation_count": 2,
    "authors": [
      "Faeze Brahman",
      "Baolin Peng",
      "Michel Galley",
      "Sudha Rao",
      "Bill Dolan",
      "Snigdha Chaturvedi",
      "Jianfeng Gao"
    ]
  },
  "https://aclanthology.org/2022.findings-emnlp.548": {
    "title": "Human-in-the-Loop Hate Speech Classification in a Multilingual Context",
    "volume": "findings",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ana Kotarcic",
      "Dominik Hangartner",
      "Fabrizio Gilardi",
      "Selina Kurer",
      "Karsten Donnay"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.1": {
    "title": "A Minimal Model for Compositional Generalization on gSCAN",
    "volume": "workshop",
    "abstract": "Whether neural networks are capable of compositional generalization has been a topic of much debate. Most previous studies on this subject investigate the generalization capabilities of state-of-the-art deep learning architectures. We here take a more bottom-up approach and design a minimal model that displays generalization on a compositional benchmark, namely, the gSCAN dataset. The model is a hybrid architecture that combines layers trained with gradient descent and a selective attention mechanism optimized with an evolutionary strategy. The architecture has around 60 times fewer trainable parameters than models previously tested on gSCAN, and achieves comparable accuracies on most test splits, even when trained only on a fraction of the dataset. On adverb to verb generalization accuracy, it outperforms previous approaches by 65 to 86%. Through ablation studies, neuron pruning, and error analyses, we show that weight decay and attention mechanisms facilitate compositional generalization by encouraging sparse representations divorced from irrelevant context. We find that the model's sample efficiency can mainly be attributed to its selective attention mechanism",
    "checked": true,
    "id": "16da1d05fdb859861d41a311d0460df6f5fe5838",
    "semantic_title": "a minimal model for compositional generalization on gscan",
    "citation_count": 0,
    "authors": [
      "Alice Hein",
      "Klaus Diepold"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.2": {
    "title": "Sparse Interventions in Language Models with Differentiable Masking",
    "volume": "workshop",
    "abstract": "There has been a lot of interest in understanding what information is captured by hidden representations of language models (LMs). Typically, interpretation methods i) do not guarantee that the model actually uses the information found to be encoded, and ii) do not discover small subsets of neurons responsible for a considered phenomenon. Inspired by causal mediation analysis, we propose a method that discovers a small subset of neurons within a neural LM responsible for a particular linguistic phenomenon, i.e., subsets causing a change in the corresponding token emission probabilities. We use a differentiable relaxation to approximately search through the combinatorial space. An L0 regularization term ensures that the search converges to discrete and sparse solutions. We apply our method to analyze subject-verb number agreement and gender bias detection in LSTMs. We observe that it is fast and finds better solutions than alternatives such as REINFORCE and Integrated Gradients. Our experiments confirm that each of these phenomena is mediated through a small subset of neurons that do not play any other discernible role",
    "checked": true,
    "id": "62394648facd628a87021a7ef803d0e6efeddee5",
    "semantic_title": "sparse interventions in language models with differentiable masking",
    "citation_count": 18,
    "authors": [
      "Nicola De Cao",
      "Leon Schmid",
      "Dieuwke Hupkes",
      "Ivan Titov"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.3": {
    "title": "Where's the Learning in Representation Learning for Compositional Semantics and the Case of Thematic Fit",
    "volume": "workshop",
    "abstract": "Observing that for certain NLP tasks, such as semantic role prediction or thematic fit estimation, random embeddings perform as well as pre-trained embeddings, we explore what settings allow for this, and examine where most of the learning is encoded: the word embeddings, the semantic role embeddings, or \"the network\". We find nuanced answers, depending on the task and its relation to the training objective. We examine these representation learning aspects in multi-task learning, where role prediction and role-filling are supervised tasks, while several thematic fit tasks are outside the models' direct supervision. We observe a non-monotonous relation between some tasks' quality scores and the training data size. In order to better understand this observation, we analyze these results using easier, per-verb versions of these tasks",
    "checked": true,
    "id": "9e66e8a78b3da148fd747db5a59d234a88591041",
    "semantic_title": "where's the learning in representation learning for compositional semantics and the case of thematic fit",
    "citation_count": 1,
    "authors": [
      "Mughilan Muthupari",
      "Samrat Halder",
      "Asad Sayeed",
      "Yuval Marton"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.4": {
    "title": "Sentence Ambiguity, Grammaticality and Complexity Probes",
    "volume": "workshop",
    "abstract": "It is unclear whether, how and where large pre-trained language models capture subtle linguistic traits like ambiguity, grammaticality and sentence complexity. We present results of automatic classification of these traits and compare their viability and patterns across representation types. We demonstrate that template-based datasets with surface-level artifacts should not be used for probing, careful comparisons with baselines should be done and that t-SNE plots should not be used to determine the presence of a feature among dense vectors representations. We also show how features might be highly localized in the layers for these models and get lost in the upper layers",
    "checked": true,
    "id": "a35520a1ac0fd6ac8ad1f406bfafb796830acf81",
    "semantic_title": "sentence ambiguity, grammaticality and complexity probes",
    "citation_count": 0,
    "authors": [
      "Sunit Bhattacharya",
      "Vilém Zouhar",
      "Ondrej Bojar"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.5": {
    "title": "Post-Hoc Interpretation of Transformer Hyperparameters with Explainable Boosting Machines",
    "volume": "workshop",
    "abstract": "Hyperparameter tuning is important for achieving high accuracy in deep learning models, yet little interpretability work has focused on hyperparameters. We propose to use the Explainable Boosting Machine (EBM), a glassbox method, as a post-hoc analysis tool for understanding how hyperparameters influence model accuracy. We present a case study on Transformer models in machine translation to illustrate the kinds of insights that may be gleaned, and perform extensive analysis to test the robustness of EBM under different data conditions",
    "checked": true,
    "id": "3e7cf804e6a57030368e7d01386738dc8852df50",
    "semantic_title": "post-hoc interpretation of transformer hyperparameters with explainable boosting machines",
    "citation_count": 1,
    "authors": [
      "Kiron Deb",
      "Xuan Zhang",
      "Kevin Duh"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.6": {
    "title": "Revisit Systematic Generalization via Meaningful Learning",
    "volume": "workshop",
    "abstract": "Humans can systematically generalize to novel compositions of existing concepts. Recent studies argue that neural networks appear inherently ineffective in such cognitive capacity, leading to a pessimistic view and a lack of attention to optimistic results. We revisit this controversial topic from the perspective of meaningful learning, an exceptional capability of humans to learn novel concepts by connecting them with known ones. We reassess the compositional skills of sequence-to-sequence models conditioned on the semantic links between new and old concepts. Our observations suggest that models can successfully one-shot generalize to novel concepts and compositions through semantic linking, either inductively or deductively. We demonstrate that prior knowledge plays a key role as well. In addition to synthetic tests, we further conduct proof-of-concept experiments in machine translation and semantic parsing, showing the benefits of meaningful learning in applications. We hope our positive findings will encourage excavating modern neural networks' potential in systematic generalization through more advanced learning schemes",
    "checked": true,
    "id": "6f0be1f9bda7530b1fa654cac84d595ca9d53740",
    "semantic_title": "revisit systematic generalization via meaningful learning",
    "citation_count": 0,
    "authors": [
      "Ning Shi",
      "Boxin Wang",
      "Wei Wang",
      "Xiangyu Liu",
      "Zhouhan Lin"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.7": {
    "title": "Is It Smaller Than a Tennis Ball? Language Models Play the Game of Twenty Questions",
    "volume": "workshop",
    "abstract": "Researchers often use games to analyze the abilities of Artificial Intelligence models. In this work, we use the game of Twenty Questions to study the world knowledge of language models. Despite its simplicity for humans, this game requires a broad knowledge of the world to answer yes/no questions. We evaluate several language models on this task and find that only the largest model has enough world knowledge to play it well, although it still has difficulties with the shape and size of objects. We also present a new method to improve the knowledge of smaller models by leveraging external information from the web. Finally, we release our dataset and Twentle, a website to interactively test the knowledge of language models by playing Twenty Questions",
    "checked": true,
    "id": "5c8cb5d39aa8531fcb5962821ac404e4a0e109d1",
    "semantic_title": "is it smaller than a tennis ball? language models play the game of twenty questions",
    "citation_count": 1,
    "authors": [
      "Maxime De Bruyn",
      "Ehsan Lotfi",
      "Jeska Buhmann",
      "Walter Daelemans"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.8": {
    "title": "Post-hoc analysis of Arabic transformer models",
    "volume": "workshop",
    "abstract": "Arabic is a Semitic language which is widely spoken with many dialects. Given the success of pre-trained language models, many transformer models trained on Arabic and its dialects have surfaced. While there have been an extrinsic evaluation of these models with respect to downstream NLP tasks, no work has been carried out to analyze and compare their internal representations. We probe how linguistic information is encoded in the transformer models, trained on different Arabic dialects. We perform a layer and neuron analysis on the models using morphological tagging tasks for different dialects of Arabic and a dialectal identification task. Our analysis enlightens interesting findings such as: i) word morphology is learned at the lower and middle layers, ii) while syntactic dependencies are predominantly captured at the higher layers, iii) despite a large overlap in their vocabulary, the MSA-based models fail to capture the nuances of Arabic dialects, iv) we found that neurons in embedding layers are polysemous in nature, while the neurons in middle layers are exclusive to specific properties",
    "checked": true,
    "id": "9a9eff68eacc844b6495779d404faa7251a8cd07",
    "semantic_title": "post-hoc analysis of arabic transformer models",
    "citation_count": 1,
    "authors": [
      "Ahmed Abdelali",
      "Nadir Durrani",
      "Fahim Dalvi",
      "Hassan Sajjad"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.9": {
    "title": "Universal Evasion Attacks on Summarization Scoring",
    "volume": "workshop",
    "abstract": "The automatic scoring of summaries is important as it guides the development of summarizers. Scoring is also complex, as it involves multiple aspects such as the fluency, grammar, and even textual entailment with the source text. However, summary scoring has not been considered as a machine learning task to study its accuracy and robustness. In this study, we place automatic scoring in the context of regression machine learning tasks and perform evasion attacks to explore its robustness. Attack systems predict a non-summary string from each input, and these non-summary strings achieve competitive scores with good summarizers on the most popular metrics: ROUGE, METEOR, and BERTScore. Attack systems also \"outperform\" state-of-the-art summarization methods on ROUGE-1 and ROUGE-L, and score the second-highest on METEOR. Furthermore, a BERTScore backdoor is observed: a simple trigger can score higher than any automatic summarization method. The evasion attacks in this work indicate the low robustness of current scoring systems at the system level. We hope that our highlighting of these proposed attack will facilitate the development of summary scores",
    "checked": true,
    "id": "75a843259ab9a1dd5c8fd0f25c7a74d5327e1bdd",
    "semantic_title": "universal evasion attacks on summarization scoring",
    "citation_count": 0,
    "authors": [
      "Wenchuan Mu",
      "Kwan Hui Lim"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.10": {
    "title": "How (Un)Faithful is Attention?",
    "volume": "workshop",
    "abstract": "Although attention weights have been commonly used as a means to provide explanations for deep learning models, the approach has been widely criticized due to its lack of faithfulness. In this work, we present a simple approach to compute the newly proposed metric AtteFa, which can quantitatively represent the degree of faithfulness of the attention weights. Using this metric, we further validate the effect of the frequency of informative input elements and the use of contextual vs. non-contextual encoders on the faithfulness of the attention mechanism. Finally, we apply the approach on several real-life binary classification datasets to measure the faithfulness of attention weights in real-life settings",
    "checked": true,
    "id": "e2216806be6e2c300e2333226a553b7bd9783152",
    "semantic_title": "how (un)faithful is attention?",
    "citation_count": 0,
    "authors": [
      "Hessam Amini",
      "Leila Kosseim"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.11": {
    "title": "Are Multilingual Sentiment Models Equally Right for the Right Reasons?",
    "volume": "workshop",
    "abstract": "Multilingual NLP models provide potential solutions to the digital language divide, i.e., cross-language performance disparities. Early analyses of such models have indicated good performance across training languages and good generalization to unseen, related languages. This work examines whether, between related languages, multilingual models are equally right for the right reasons, i.e., if interpretability methods reveal that the models put emphasis on the same words as humans. To this end, we provide a new trilingual, parallel corpus of rationale annotations for English, Danish, and Italian sentiment analysis models and use it to benchmark models and interpretability methods. We propose rank-biased overlap as a better metric for comparing input token attributions to human rationale annotations. Our results show: (i) models generally perform well on the languages they are trained on, and align best with human rationales in these languages; (ii) performance is higher on English, even when not a source language, but this performance is not accompanied by higher alignment with human rationales, which suggests that language models favor English, but do not facilitate successful transfer of rationales",
    "checked": true,
    "id": "02ef976bc4aedceca2a6d7577975113db1e0e26d",
    "semantic_title": "are multilingual sentiment models equally right for the right reasons?",
    "citation_count": 3,
    "authors": [
      "Rasmus Jørgensen",
      "Fiammetta Caccavale",
      "Christian Igel",
      "Anders Søgaard"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.12": {
    "title": "Probing for Understanding of English Verb Classes and Alternations in Large Pre-trained Language Models",
    "volume": "workshop",
    "abstract": "We investigate the extent to which verb alternation classes, as described by Levin (1993), are encoded in the embeddings of Large Pre-trained Language Models (PLMs) such as BERT, RoBERTa, ELECTRA, and DeBERTa using selectively constructed diagnostic classifiers for word and sentence-level prediction tasks. We follow and expand upon the experiments of Kann et al. (2019), which aim to probe whether static embeddings encode frame-selectional properties of verbs. At both the word and sentence level, we find that contextual embeddings from PLMs not only outperform non-contextual embeddings, but achieve astonishingly high accuracies on tasks across most alternation classes. Additionally, we find evidence that the middle-to-upper layers of PLMs achieve better performance on average than the lower layers across all probing tasks",
    "checked": true,
    "id": "ad34a576900d78e6280a1ac1ecaeea19dbb3ed06",
    "semantic_title": "probing for understanding of english verb classes and alternations in large pre-trained language models",
    "citation_count": 0,
    "authors": [
      "David Yi",
      "James Bruno",
      "Jiayu Han",
      "Peter Zukerman",
      "Shane Steinert-Threlkeld"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.13": {
    "title": "Analyzing Gender Translation Errors to Identify Information Flows between the Encoder and Decoder of a NMT System",
    "volume": "workshop",
    "abstract": "Multiple studies have shown that existing NMT systems demonstrate some kind of \"gender bias\". As a result, MT output appears to err more often for feminine forms and to amplify social gender misrepresentations, which is potentially harmful to users and practioners of these technologies. This paper continues this line of investigations and reports results obtained with a new test set in strictly controlled conditions. This setting allows us to better understand the multiple inner mechanisms that are causing these biases, which include the linguistic expressions of gender, the unbalanced distribution of masculine and feminine forms in the language, the modelling of morphological variation and the training process dynamics. To counterbalance these effects, we formulate several proposals and notably show that modifying the training loss can effectively mitigate such biases",
    "checked": true,
    "id": "97caab3dfecf6234519d254e250767b62db56f4d",
    "semantic_title": "analyzing gender translation errors to identify information flows between the encoder and decoder of a nmt system",
    "citation_count": 1,
    "authors": [
      "Guillaume Wisniewski",
      "Lichao Zhu",
      "Nicolas Ballier",
      "François Yvon"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.14": {
    "title": "Human Ratings Do Not Reflect Downstream Utility: A Study of Free-Text Explanations for Model Predictions",
    "volume": "workshop",
    "abstract": "Models able to generate free-text rationales that explain their output have been proposed as an important step towards interpretable NLP for \"reasoning\" tasks such as natural language inference and commonsense question answering. However, the relative merits of different architectures and types of rationales are not well understood and hard to measure. In this paper, we contribute two insights to this line of research: First, we find that models trained on gold explanations learn to rely on these but, in the case of the more challenging question answering data set we use, fail when given generated explanations at test time. However, additional fine-tuning on generated explanations teaches the model to distinguish between reliable and unreliable information in explanations. Second, we compare explanations by a generation-only model to those generated by a self-rationalizing model and find that, while the former score higher in terms of validity, factual correctness, and similarity to gold explanations, they are not more useful for downstream classification. We observe that the self-rationalizing model is prone to hallucination, which is punished by most metrics but may add useful context for the classification step",
    "checked": true,
    "id": "d3b6fee3c6d900abc257633ee82ee25b622ca408",
    "semantic_title": "human ratings do not reflect downstream utility: a study of free-text explanations for model predictions",
    "citation_count": 2,
    "authors": [
      "Jenny Kunz",
      "Martin Jirenius",
      "Oskar Holmström",
      "Marco Kuhlmann"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.15": {
    "title": "Analyzing the Representational Geometry of Acoustic Word Embeddings",
    "volume": "workshop",
    "abstract": "Acoustic word embeddings (AWEs) are fixed-dimensionality vector representations in a vector space such that different acoustic exemplars of the same word are projected nearby in the embedding space. In addition to their use in speech technology applications such as spoken term discovery and keyword spotting, AWE models have been adopted as models of spoken-word processing in several cognitively motivated studies and they have shown to exhibit a human-like performance in some auditory processing tasks. Nevertheless, the representation geometry of AWEs remains an under-explored topic that has not been studied in the literature. In this paper, we take a closer analytical look at AWEs and study how the choice of the learning objective and the architecture shapes their representational profile. Our main findings highlight the prominent role of the learning objective on the representational geometry over the architecture",
    "checked": true,
    "id": "55df518e164221619acff2efd8a5356e36076b27",
    "semantic_title": "analyzing the representational geometry of acoustic word embeddings",
    "citation_count": 1,
    "authors": [
      "Badr Abdullah",
      "Dietrich Klakow"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.16": {
    "title": "Understanding Domain Learning in Language Models Through Subpopulation Analysis",
    "volume": "workshop",
    "abstract": "We investigate how different domains are encoded in modern neural network architectures. We analyze the relationship between natural language domains, model size, and the amount of training data used. The primary analysis tool we develop is based on subpopulation analysis with Singular Vector Canonical Correlation Analysis (SVCCA), which we apply to Transformer-based language models (LMs). We compare the latent representations of such a language model at its different layers from a pair of models: a model trained on multiple domains (an experimental model) and a model trained on a single domain (a control model). Through our method, we find that increasing the model capacity impacts how domain information is stored in upper and lower layers differently. In addition, we show that larger experimental models simultaneously embed domain-specific information as if they were conjoined control models. These findings are confirmed qualitatively, demonstrating the validity of our method",
    "checked": true,
    "id": "18c0751db3689ffe3ea62805c131824773d454c6",
    "semantic_title": "understanding domain learning in language models through subpopulation analysis",
    "citation_count": 3,
    "authors": [
      "Zheng Zhao",
      "Yftah Ziser",
      "Shay Cohen"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.17": {
    "title": "Intermediate Entity-based Sparse Interpretable Representation Learning",
    "volume": "workshop",
    "abstract": "Interpretable entity representations (IERs) are sparse embeddings that are \"human-readable\" in that dimensions correspond to fine-grained entity types and values are predicted probabilities that a given entity is of the corresponding type. These methods perform well in zero-shot and low supervision settings. Compared to standard dense neural embeddings, such interpretable representations may permit analysis and debugging. However, while fine-tuning sparse, interpretable representations improves accuracy on downstream tasks, it destroys the semantics of the dimensions which were enforced in pre-training. Can we maintain the interpretable semantics afforded by IERs while improving predictive performance on downstream tasks? Toward this end, we propose Intermediate enTity-based Sparse Interpretable Representation Learning (ItsIRL). ItsIRL realizes improved performance over prior IERs on biomedical tasks, while maintaining \"interpretability\" generally and their ability to support model debugging specifically. The latter is enabled in part by the ability to perform \"counterfactual\" fine-grained entity type manipulation, which we explore in this work. Finally, we propose a method to construct entity type based class prototypes for revealing global semantic properties of classes learned by our model. Code for pre-training and experiments will be made publicly available",
    "checked": true,
    "id": "2440c6a399c391106c69af1ed27780f5302d50e6",
    "semantic_title": "intermediate entity-based sparse interpretable representation learning",
    "citation_count": 1,
    "authors": [
      "Diego Garcia-Olano",
      "Yasumasa Onoe",
      "Joydeep Ghosh",
      "Byron Wallace"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.18": {
    "title": "Towards Procedural Fairness: Uncovering Biases in How a Toxic Language Classifier Uses Sentiment Information",
    "volume": "workshop",
    "abstract": "Previous works on the fairness of toxic language classifiers compare the output of models with different identity terms as input features but do not consider the impact of other important concepts present in the context. Here, besides identity terms, we take into account high-level latent features learned by the classifier and investigate the interaction between these features and identity terms. For a multi-class toxic language classifier, we leverage a concept-based explanation framework to calculate the sensitivity of the model to the concept of sentiment, which has been used before as a salient feature for toxic language detection. Our results show that although for some classes, the classifier has learned the sentiment information as expected, this information is outweighed by the influence of identity terms as input features. This work is a step towards evaluating procedural fairness, where unfair processes lead to unfair outcomes. The produced knowledge can guide debiasing techniques to ensure that important concepts besides identity terms are well-represented in training datasets",
    "checked": true,
    "id": "041194726df0a18cc31df3aafe246d94709da2ea",
    "semantic_title": "towards procedural fairness: uncovering biases in how a toxic language classifier uses sentiment information",
    "citation_count": 2,
    "authors": [
      "Isar Nejadgholi",
      "Esma Balkir",
      "Kathleen Fraser",
      "Svetlana Kiritchenko"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.19": {
    "title": "Investigating the Characteristics of a Transformer in a Few-Shot Setup: Does Freezing Layers in RoBERTa Help?",
    "volume": "workshop",
    "abstract": "Transformer based language models have been widely adopted by industrial and research organisations in developing machine learning applications in the presence of limited annotated data. While these models show remarkable results, their functioning in few-shot settings is still poorly understood. Hence, we perform an investigative study to understand the characteristics of such models fine-tuned in few-shot setups. Specifically, we compare the intermediate layer representations obtained from a few-shot model and a pre-trained language model. We observe that pre-trained and few-shot models show similar representations over initial layers, whereas the later layers show a stark deviation. Based on these observations, we propose to freeze the initial Transformer layers to fine-tune the model in a constrained text classification setup with K annotated data points per class, where K ranges from 8 to 64. In our experiments across six benchmark sentence classification tasks, we discover that freezing initial 50% Transformer layers not only reduces training time but also surprisingly improves Macro F1 (upto 8%) when compared to fully trainable layers in few-shot setup. We also observe that this idea of layer freezing can very well be generalized to state-of-the-art few-shot text classification techniques, like DNNC and LM-BFF, leading to significant reduction in training time while maintaining comparable performance",
    "checked": true,
    "id": "382826f569fea7778803f141e9db368cb067a0a0",
    "semantic_title": "investigating the characteristics of a transformer in a few-shot setup: does freezing layers in roberta help?",
    "citation_count": 1,
    "authors": [
      "Digvijay Ingle",
      "Rishabh Tripathi",
      "Ayush Kumar",
      "Kevin Patel",
      "Jithendra Vepa"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.20": {
    "title": "It Is Not Easy To Detect Paraphrases: Analysing Semantic Similarity With Antonyms and Negation Using the New SemAntoNeg Benchmark",
    "volume": "workshop",
    "abstract": "We investigate to what extent a hundred publicly available, popular neural language models capture meaning systematically. Sentence embeddings obtained from pretrained or fine-tuned language models can be used to perform particular tasks, such as paraphrase detection, semantic textual similarity assessment or natural language inference. Common to all of these tasks is that paraphrastic sentences, that is, sentences that carry (nearly) the same meaning, should have (nearly) the same embeddings regardless of surface form. We demonstrate that performance varies greatly across different language models when a specific type of meaning-preserving transformation is applied: two sentences should be identified as paraphrastic if one of them contains a negated antonym in relation to the other one, such as \"I am not guilty\" versus \"I am innocent\".We introduce and release SemAntoNeg, a new test suite containing 3152 entries for probing paraphrasticity in sentences incorporating negation and antonyms. Among other things, we show that language models fine-tuned for natural language inference outperform other types of models, especially the ones fine-tuned to produce general-purpose sentence embeddings, on the test suite. Furthermore, we show that most models designed explicitly for paraphrasing are rather mediocre in our task",
    "checked": true,
    "id": "5f58a1c84a4c251ae85f9beab39992c3d76f94c9",
    "semantic_title": "it is not easy to detect paraphrases: analysing semantic similarity with antonyms and negation using the new semantoneg benchmark",
    "citation_count": 6,
    "authors": [
      "Teemu Vahtola",
      "Mathias Creutz",
      "Jörg Tiedemann"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.21": {
    "title": "Controlling for Stereotypes in Multimodal Language Model Evaluation",
    "volume": "workshop",
    "abstract": "We propose a methodology and design two benchmark sets for measuring to what extent language-and-vision language models use the visual signal in the presence or absence of stereotypes. The first benchmark is designed to test for stereotypical colors of common objects, while the second benchmark considers gender stereotypes. The key idea is to compare predictions when the image conforms to the stereotype to predictions when it does not. Our results show that there is significant variation among multimodal models: the recent Transformer-based FLAVA seems to be more sensitive to the choice of image and less affected by stereotypes than older CNN-based models such as VisualBERT and LXMERT. This effect is more discernible in this type of controlled setting than in traditional evaluations where we do not know whether the model relied on the stereotype or the visual signal",
    "checked": true,
    "id": "2b764b71ba02f69b2f4dc3f87c2cc6e41dc0ce3e",
    "semantic_title": "controlling for stereotypes in multimodal language model evaluation",
    "citation_count": 0,
    "authors": [
      "Manuj Malik",
      "Richard Johansson"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.22": {
    "title": "On the Compositional Generalization Gap of In-Context Learning",
    "volume": "workshop",
    "abstract": "Pretrained large generative language models have shown great performance on many tasks, but exhibit low compositional generalization abilities. Scaling such models has been shown to improve their performance on various NLP tasks even just by conditioning them on a few examples to solve the task without any fine-tuning (also known as in-context learning). In this work, we look at the gap between the in-distribution (ID) and out-of-distribution (OOD) performance of such models in semantic parsing tasks with in-context learning. In the ID settings, the demonstrations are from the same split (test or train) that the model is being evaluated on, and in the OOD settings, they are from the other split. We look at how the relative generalization gap of in-context learning evolves as models are scaled up. We evaluate four model families, OPT, BLOOM, CodeGen and Codex on three semantic parsing datasets, CFQ, SCAN and GeoQuery with different number of exemplars, and observe a trend of decreasing relative generalization gap as models are scaled up",
    "checked": true,
    "id": "95915aa592fdfc73f039c13472a21d3e4220f129",
    "semantic_title": "on the compositional generalization gap of in-context learning",
    "citation_count": 14,
    "authors": [
      "Arian Hosseini",
      "Ankit Vani",
      "Dzmitry Bahdanau",
      "Alessandro Sordoni",
      "Aaron Courville"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.23": {
    "title": "Explaining Translationese: why are Neural Classifiers Better and what do they Learn?",
    "volume": "workshop",
    "abstract": "Recent work has shown that neural feature- and representation-learning, e.g. BERT, achieves superior performance over traditional manual feature engineering based approaches, with e.g. SVMs, in translationese classification tasks. Previous research did not show (i) whether the difference is because of the features, the classifiers or both, and (ii) what the neural classifiers actually learn. To address (i), we carefully design experiments that swap features between BERT- and SVM-based classifiers. We show that an SVM fed with BERT representations performs at the level of the best BERT classifiers, while BERT learning and using handcrafted features performs at the level of an SVM using handcrafted features. This shows that the performance differences are due to the features. To address (ii) we use integrated gradients and find that (a) there is indication that information captured by hand-crafted features is only a subset of what BERT learns, and (b) part of BERT's top performance results are due to BERT learning topic differences and spurious correlations with translationese",
    "checked": true,
    "id": "935fb385a04270904f9ac20f5211b46029f6f04f",
    "semantic_title": "explaining translationese: why are neural classifiers better and what do they learn?",
    "citation_count": 3,
    "authors": [
      "Kwabena Amponsah-Kaakyire",
      "Daria Pylypenko",
      "Josef Genabith",
      "Cristina España-Bonet"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.24": {
    "title": "Probing GPT-3's Linguistic Knowledge on Semantic Tasks",
    "volume": "workshop",
    "abstract": "GPT-3 has attracted much attention from both academia and industry. However, it is still unclear what GPT-3 has understood or learned especially in linguistic knowledge. Some studies have shown linguistic phenomena including negation and tense are hard to be recognized by language models such as BERT. In this study, we conduct probing tasks focusing on semantic information. Specifically, we investigate GPT-3's linguistic knowledge on semantic tasks to identify tense, the number of subjects, and the number of objects for a given sentence. We also experiment with different prompt designs and temperatures of the decoding method. Our experiment results suggest that GPT-3 has acquired linguistic knowledge to identify certain semantic information in most cases, but still fails when there are some types of disturbance happening in the sentence. We also perform error analysis to summarize some common types of mistakes that GPT-3 has made when dealing with certain semantic information",
    "checked": true,
    "id": "cfa37731c5d269c2ea15eb56cb6c13a008404134",
    "semantic_title": "probing gpt-3's linguistic knowledge on semantic tasks",
    "citation_count": 11,
    "authors": [
      "Lining Zhang",
      "Mengchen Wang",
      "Liben Chen",
      "Wenxin Zhang"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.25": {
    "title": "Garden Path Traversal in GPT-2",
    "volume": "workshop",
    "abstract": "In recent years, large-scale transformer decoders such as the GPT-x family of models have become increasingly popular. Studies examining the behavior of these models tend to focus only on the output of the language modeling head and avoid analysis of the internal states of the transformer decoder. In this study, we present a collection of methods to analyze the hidden states of GPT-2 and use the model's navigation of garden path sentences as a case study. To enable this, we compile the largest currently available dataset of garden path sentences. We show that Manhattan distances and cosine similarities provide more reliable insights compared to established surprisal methods that analyze next-token probabilities computed by a language modeling head. Using these methods, we find that negating tokens have minimal impacts on the model's representations for unambiguous forms of sentences with ambiguity solely over what the object of a verb is, but have a more substantial impact of representations for unambiguous sentences whose ambiguity would stem from the voice of a verb. Further, we find that analyzing the decoder model's hidden states reveals periods of ambiguity that might conclude in a garden path effect but happen not to, whereas surprisal analyses routinely miss this detail",
    "checked": true,
    "id": "aaef50dfd54bbe89912e1e6144c07eac33bc0f92",
    "semantic_title": "garden path traversal in gpt-2",
    "citation_count": 3,
    "authors": [
      "William Jurayj",
      "William Rudman",
      "Carsten Eickhoff"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.26": {
    "title": "Testing Pre-trained Language Models' Understanding of Distributivity via Causal Mediation Analysis",
    "volume": "workshop",
    "abstract": "To what extent do pre-trained language models grasp semantic knowledge regarding the phenomenon of distributivity? In this paper, we introduce DistNLI, a new diagnostic dataset for natural language inference that targets the semantic difference arising from distributivity, and employ the causal mediation analysis framework to quantify the model behavior and explore the underlying mechanism in this semantically-related task. We find that the extent of models' understanding is associated with model size and vocabulary size. We also provide insights into how models encode such high-level semantic knowledge",
    "checked": true,
    "id": "78d88428074f83abf5bec2a015e886665f3deeb8",
    "semantic_title": "testing pre-trained language models' understanding of distributivity via causal mediation analysis",
    "citation_count": 3,
    "authors": [
      "Pangbo Ban",
      "Yifan Jiang",
      "Tianran Liu",
      "Shane Steinert-Threlkeld"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.27": {
    "title": "Using Roark-Hollingshead Distance to Probe BERT's Syntactic Competence",
    "volume": "workshop",
    "abstract": "Probing BERT's general ability to reason about syntax is no simple endeavour, primarily because of the uncertainty surrounding how large language models represent syntactic structure. Many prior accounts of BERT's agility as a syntactic tool (Clark et al., 2013; Lau et al., 2014; Marvin and Linzen, 2018; Chowdhury and Zamparelli, 2018; Warstadt et al., 2019, 2020; Hu et al., 2020) have therefore confined themselves to studying very specific linguistic phenomena, and there has still been no definitive answer as to whether BERT \"knows\" syntax. The advent of perturbed masking (Wu et al., 2020) would then seem to be significant, because this is a parameter-free probing method that directly samples syntactic trees from BERT's embeddings. These sampled trees outperform a right-branching baseline, thus providing preliminary evidence that BERT's syntactic competence bests a simple baseline. This baseline is underwhelming, however, and our reappraisal below suggests that this result, too, is inconclusive. We propose RH Probe, an encoder-decoder probing architecture that operates on two probing tasks. We find strong empirical evidence confirming the existence of important syntactic information in BERT, but this information alone appears not to be enough to reproduce syntax in its entirety. Our probe makes crucial use of a conjecture made by Roark and Holling-shead (2008) that a particular lexical annotation that we shall call RH distance is a sufficient encoding of unlabelled binary syntactic trees, and we prove this conjecture",
    "checked": true,
    "id": "b85c476fb1218f927aa6edc3e5ceed6512c068f5",
    "semantic_title": "using roark-hollingshead distance to probe bert's syntactic competence",
    "citation_count": 1,
    "authors": [
      "Jingcheng Niu",
      "Wenjie Lu",
      "Eric Corlett",
      "Gerald Penn"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.28": {
    "title": "DALLE-2 is Seeing Double: Flaws in Word-to-Concept Mapping in Text2Image Models",
    "volume": "workshop",
    "abstract": "We study the way DALLE-2 maps symbols (words) in the prompt to their references (entities or properties of entities in the generated image). We show that in stark contrast to the way human process language, DALLE-2 does not follow the constraint that each word has a single role in the interpretation, and sometimes re-use the same symbol for different purposes. We collect a set of stimuli that reflect the phenomenon: we show that DALLE-2 depicts both senses of nouns with multiple senses at once; and that a given word can modify the properties of two distinct entities in the image, or can be depicted as one object and also modify the properties of another object, creating a semantic leakage of properties between entities. Taken together, our study highlights the differences between DALLE-2 and human language processing and opens an avenue for future study on the inductive biases of text-to-image models",
    "checked": true,
    "id": "f638d8027d7db7338b3cb0c521e0aded68f3560c",
    "semantic_title": "dalle-2 is seeing double: flaws in word-to-concept mapping in text2image models",
    "citation_count": 31,
    "authors": [
      "Royi Rassin",
      "Shauli Ravfogel",
      "Yoav Goldberg"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.29": {
    "title": "Practical Benefits of Feature Feedback Under Distribution Shift",
    "volume": "workshop",
    "abstract": "In attempts to develop sample-efficient and interpretable algorithms, researcher have explored myriad mechanisms for collecting and exploiting feature feedback, auxiliary annotations provided for training (but not test) instances that highlight salient evidence. Examples include bounding boxes around objects and salient spans in text. Despite its intuitive appeal, feature feedback has not delivered significant gains in practical problems as assessed on iid holdout sets. However, recent works on counterfactually augmented data suggest an alternative benefit of supplemental annotations, beyond interpretability: lessening sensitivity to spurious patterns and consequently delivering gains in out-of-domain evaluations. We speculate that while existing methods for incorporating feature feedback have delivered negligible in-sample performance gains, they may nevertheless provide out-of-domain benefits. Our experiments addressing sentiment analysis, show that feature feedback methods perform significantly better on various natural out-of-domain datasets despite comparable in-domain evaluations. By contrast, performance on natural language inference remains comparable. Finally, we compare those tasks where feature feedback does (and does not) help",
    "checked": true,
    "id": "7f637c8ce8f64d0b83be7bf0b061d8e8f04ca298",
    "semantic_title": "practical benefits of feature feedback under distribution shift",
    "citation_count": 4,
    "authors": [
      "Anurag Katakkar",
      "Clay H. Yoo",
      "Weiqin Wang",
      "Zachary Lipton",
      "Divyansh Kaushik"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.30": {
    "title": "Identifying the Source of Vulnerability in Explanation Discrepancy: A Case Study in Neural Text Classification",
    "volume": "workshop",
    "abstract": "Some recent works observed the instability of post-hoc explanations when input side perturbations are applied to the model. This raises the interest and concern in the stability of post-hoc explanations. However, the remaining question is: is the instability caused by the neural network model or the post-hoc explanation method? This work explores the potential source that leads to unstable post-hoc explanations. To separate the influence from the model, we propose a simple output probability perturbation method. Compared to prior input side perturbation methods, the output probability perturbation method can circumvent the neural model's potential effect on the explanations and allow the analysis on the explanation method. We evaluate the proposed method with three widely-used post-hoc explanation methods (LIME (Ribeiro et al., 2016), Kernel Shapley (Lundberg and Lee, 2017a), and Sample Shapley (Strumbelj and Kononenko, 2010)). The results demonstrate that the post-hoc methods are stable, barely producing discrepant explanations under output probability perturbations. The observation suggests that neural network models may be the primary source of fragile explanations",
    "checked": true,
    "id": "8664038c68f12b3e6f6742379c05f115a69d31e7",
    "semantic_title": "identifying the source of vulnerability in explanation discrepancy: a case study in neural text classification",
    "citation_count": 1,
    "authors": [
      "Ruixuan Tang",
      "Hanjie Chen",
      "Yangfeng Ji"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.31": {
    "title": "Probing Pretrained Models of Source Codes",
    "volume": "workshop",
    "abstract": "Deep learning models are widely used for solving challenging code processing tasks, such as code generation or code summarization. Traditionally, a specific model architecture was carefully built to solve a particular code processing task. However, recently general pretrained models such as CodeBERT or CodeT5 have been shown to outperform task-specific models in many applications. While pretrained models are known to learn complex patterns from data, they may fail to understand some properties of source code. To test diverse aspects of code understanding, we introduce a set of diagnostic probing tasks. We show that pretrained models of code indeed contain information about code syntactic structure, the notions of identifiers, and namespaces, but they may fail to recognize more complex code properties such as semantic equivalence. We also investigate how probing results are affected by using code-specific pretraining objectives, varying the model size, or finetuning",
    "checked": true,
    "id": "6aae3ddbe142f7ae28f0f18bb6248dc7b3f41c00",
    "semantic_title": "probing pretrained models of source codes",
    "citation_count": 20,
    "authors": [
      "Sergey Troshin",
      "Nadezhda Chirkova"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.32": {
    "title": "Probing the representations of named entities in Transformer-based Language Models",
    "volume": "workshop",
    "abstract": "In this work we analyze the named entity representations learned by Transformer-based language models. We investigate the role entities play in two tasks: a language modeling task, and a sequence classification task. For this purpose we collect a novel news topic classification dataset with 12 topics called RefNews-12. We perform two complementary methods of analysis. First, we use diagnostic models allowing us to quantify to what degree entity information is present in the hidden representations. Second, we perform entity mention substitution to measure how substitute-entities with different properties impact model performance. By controlling for model uncertainty we are able to show that entities are identified, and depending on the task, play a measurable role in the model's predictions. Additionally, we show that the entities' types alone are not enough to account for this. Finally, we find that the the frequency with which entities occur are important for the masked language modeling task, and that the entities' distributions over topics are important for topic classification",
    "checked": true,
    "id": "0488a5ee7a85ea9ab93f40bb6324dbf8c36a825b",
    "semantic_title": "probing the representations of named entities in transformer-based language models",
    "citation_count": 1,
    "authors": [
      "Stefan Schouten",
      "Peter Bloem",
      "Piek Vossen"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.33": {
    "title": "Decomposing Natural Logic Inferences for Neural NLI",
    "volume": "workshop",
    "abstract": "In the interest of interpreting neural NLI models and their reasoning strategies, we carry out a systematic probing study which investigates whether these modelscapture the crucial semantic features central to natural logic: monotonicity and concept inclusion. Correctly identifying valid inferences in downward-monotone contexts is a known stumbling block for NLI performance,subsuming linguistic phenomena such as negation scope and generalized quantifiers. To understand this difficulty, we emphasize monotonicity as a property of a context and examine the extent to which models capture relevant monotonicity information in the vector representations which are intermediate to their decision making process. Drawing on the recent advancement of the probing paradigm,we compare the presence of monotonicity features across various models. We find that monotonicity information is notably weak in the representations of popularNLI models which achieve high scores on benchmarks, and observe that previous improvements to these models based on fine-tuning strategies have introduced stronger monotonicity features together with their improved performance on challenge sets",
    "checked": true,
    "id": "51f4eb5d91f65bbfeff0a9a015092fe8f64f6873",
    "semantic_title": "decomposing natural logic inferences for neural nli",
    "citation_count": 1,
    "authors": [
      "Julia Rozanova",
      "Deborah Ferreira",
      "Mokanarangan Thayaparan",
      "Marco Valentino",
      "Andre Freitas"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.34": {
    "title": "Probing with Noise: Unpicking the Warp and Weft of Embeddings",
    "volume": "workshop",
    "abstract": "Improving our understanding of how information is encoded in vector space can yield valuable interpretability insights. Alongside vector dimensions, we argue that it is possible for the vector norm to also carry linguistic information. We develop a method to test this: an extension of the probing framework which allows for relative intrinsic interpretations of probing results. It relies on introducing noise that ablates information encoded in embeddings, grounded in random baselines and confidence intervals. We apply the method to well-established probing tasks and find evidence that confirms the existence of separate information containers in English GloVe and BERT embeddings. Our correlation analysis aligns with the experimental findings that different encoders use the norm to encode different kinds of information: GloVe stores syntactic and sentence length information in the vector norm, while BERT uses it to encode contextual incongruity",
    "checked": true,
    "id": "cb9db3681e86f1f93f51b8bbfd51f3c594dbb926",
    "semantic_title": "probing with noise: unpicking the warp and weft of embeddings",
    "citation_count": 4,
    "authors": [
      "Filip Klubicka",
      "John Kelleher"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.35": {
    "title": "Look to the Right: Mitigating Relative Position Bias in Extractive Question Answering",
    "volume": "workshop",
    "abstract": "Extractive question answering (QA) models tend to exploit spurious correlations to make predictions when a training set has unintended biases. This tendency results in models not being generalizable to examples where the correlations do not hold. Determining the spurious correlations QA models can exploit is crucial in building generalizable QA models in real-world applications; moreover, a method needs to be developed that prevents these models from learning the spurious correlations even when a training set is biased. In this study, we discovered that the relative position of an answer, which is defined as the relative distance from an answer span to the closest question-context overlap word, can be exploited by QA models as superficial cues for making predictions. Specifically, we find that when the relative positions in a training set are biased, the performance on examples with relative positions unseen during training is significantly degraded. To mitigate the performance degradation for unseen relative positions, we propose an ensemble-based debiasing method that does not require prior knowledge about the distribution of relative positions. We demonstrate that the proposed method mitigates the models' reliance on relative positions using the biased and full SQuAD dataset. We hope that this study can help enhance the generalization ability of QA models in real-world applications",
    "checked": true,
    "id": "fe680e78f6d8f963080150ddccc4c6aa157b63fe",
    "semantic_title": "look to the right: mitigating relative position bias in extractive question answering",
    "citation_count": 6,
    "authors": [
      "Kazutoshi Shinoda",
      "Saku Sugawara",
      "Akiko Aizawa"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.36": {
    "title": "A Continuum of Generation Tasks for Investigating Length Bias and Degenerate Repetition",
    "volume": "workshop",
    "abstract": "Language models suffer from various degenerate behaviors. These differ between tasks: machine translation (MT) exhibits length bias, while tasks like story generation exhibit excessive repetition. Recent work has attributed the difference to task constrainedness, but evidence for this claim has always involved many confounding variables. To study this question directly, we introduce a new experimental framework that allows us to smoothly vary task constrainedness, from MT at one end to fully open-ended generation at the other, while keeping all other aspects fixed. We find that: (1) repetition decreases smoothly with constrainedness, explaining the difference in repetition across tasks; (2) length bias surprisingly also decreases with constrainedness, suggesting some other cause for the difference in length bias; (3) across the board, these problems affect the mode, not the whole distribution; (4) the differences cannot be attributed to a change in the entropy of the distribution, since another method of changing the entropy, label smoothing, does not produce the same effect",
    "checked": true,
    "id": "b6d98839dfae708d845ba482665f3e6343f4f173",
    "semantic_title": "a continuum of generation tasks for investigating length bias and degenerate repetition",
    "citation_count": 4,
    "authors": [
      "Darcey Riley",
      "David Chiang"
    ]
  },
  "https://aclanthology.org/2022.blackboxnlp-1.37": {
    "title": "Universal and Independent: Multilingual Probing Framework for Exhaustive Model Interpretation and Evaluation",
    "volume": "workshop",
    "abstract": "Linguistic analysis of language models is one of the ways to explain and describe their reasoning, weaknesses, and limitations. In the probing part of the model interpretability research, studies concern individual languages as well as individual linguistic structures. The question arises: are the detected regularities linguistically coherent, or on the contrary, do they dissonate at the typological scale? Moreover, the majority of studies address the inherent set of languages and linguistic structures, leaving the actual typological diversity knowledge out of scope. In this paper, we present and apply the GUI-assisted framework allowing us to easily probe massive amounts of languages for all the morphosyntactic features present in the Universal Dependencies data. We show that reflecting the anglo-centric trend in NLP over the past years, most of the regularities revealed in the mBERT model are typical for the western-European languages. Our framework can be integrated with the existing probing toolboxes, model cards, and leaderboards, allowing practitioners to use and share their familiar probing methods to interpret multilingual models. Thus we propose a toolkit to systematize the multilingual flaws in multilingual models, providing a reproducible experimental setup for 104 languages and 80 morphosyntactic features",
    "checked": true,
    "id": "a93a11e0b6bb8b01379b8b442780f7aad82540f8",
    "semantic_title": "universal and independent: multilingual probing framework for exhaustive model interpretation and evaluation",
    "citation_count": 2,
    "authors": [
      "Oleg Serikov",
      "Vitaly Protasov",
      "Ekaterina Voloshina",
      "Viktoria Knyazkova",
      "Tatiana Shavrina"
    ]
  },
  "https://aclanthology.org/2022.case-1.1": {
    "title": "A Multi-Modal Dataset for Hate Speech Detection on Social Media: Case-study of Russia-Ukraine Conflict",
    "volume": "workshop",
    "abstract": "This paper presents a new multi-modal dataset for identifying hateful content on social media, consisting of 5,680 text-image pairs collected from Twitter, labeled across two labels. Experimental analysis of the presented dataset has shown that understanding both modalities is essential for detecting these techniques. It is confirmed in our experiments with several state-of-the-art multi-modal models. In future work, we plan to extend the dataset in size. We further plan to develop new multi-modal models tailored explicitly to hate-speech detection, aiming for a deeper understanding of the text and image relation. It would also be interesting to perform experiments in a direction that explores what social entities the given hate speech tweet targets",
    "checked": true,
    "id": "52f924d2889a1343adb1faeea3ff8475978f5992",
    "semantic_title": "a multi-modal dataset for hate speech detection on social media: case-study of russia-ukraine conflict",
    "citation_count": 28,
    "authors": [
      "Surendrabikram Thapa",
      "Aditya Shah",
      "Farhan Jafri",
      "Usman Naseem",
      "Imran Razzak"
    ]
  },
  "https://aclanthology.org/2022.case-1.2": {
    "title": "EventGraph: Event Extraction as Semantic Graph Parsing",
    "volume": "workshop",
    "abstract": "Event extraction involves the detection and extraction of both the event triggers and the corresponding arguments. Existing systems often decompose event extraction into multiple subtasks, without considering their possible interactions. In this paper, we propose EventGraph, a joint framework for event extraction, which encodes events as graphs. We represent event triggers and arguments as nodes in a semantic graph. Event extraction therefore becomes a graph parsing problem, which provides the following advantages: 1) performing event detection and argument extraction jointly; 2) detecting and extracting multiple events from a piece of text; 3) capturing the complicated interaction between event arguments and triggers. Experimental results on ACE2005 show that our model is competitive to state-of-the-art systems and has substantially improved the results on argument extraction. Additionally, we create two new datasets from ACE2005 where we keep the entire text spans for event arguments, instead of just the head word(s). Our code and models will be released as open-source",
    "checked": true,
    "id": "7d2b1cd45f96a20ab8f4818ee2d0a2c86ca684c6",
    "semantic_title": "eventgraph: event extraction as semantic graph parsing",
    "citation_count": 4,
    "authors": [
      "Huiling You",
      "David Samuel",
      "Samia Touileb",
      "Lilja Øvrelid"
    ]
  },
  "https://aclanthology.org/2022.case-1.3": {
    "title": "NLP4ITF @ Causal News Corpus 2022: Leveraging Linguistic Information for Event Causality Classification",
    "volume": "workshop",
    "abstract": "We present our submission to Subtask 1 of theCASE-2022 Shared Task 3: Event CausalityIdentification with Causal News Corpus as partof the 5th Workshop on Challenges and Applicationsof Automated Extraction of SociopoliticalEvents from Text (CASE 2022) (Tanet al., 2022a). The task focuses on causal eventclassification on the sentence level and involvesdifferentiating between sentences that include acause-effect relation and sentences that do not. We approached this as a binary text classificationtask and experimented with multiple trainingsets augmented with additional linguisticinformation. Our best model was generated bytraining roberta-base on a combination ofdata from both Subtasks 1 and 2 with the additionof named entity annotations. During thedevelopment phase we achieved a macro F1 of0.8641 with this model on the development setprovided by the task organizers. When testingthe model on the final test data, we achieved amacro F1 of 0.8516",
    "checked": true,
    "id": "254320b73b10b4cd524dd742273e56568a491190",
    "semantic_title": "nlp4itf @ causal news corpus 2022: leveraging linguistic information for event causality classification",
    "citation_count": 1,
    "authors": [
      "Theresa Krumbiegel",
      "Sophie Decher"
    ]
  },
  "https://aclanthology.org/2022.case-1.4": {
    "title": "A Hybrid Knowledge and Transformer-Based Model for Event Detection with Automatic Self-Attention Threshold, Layer and Head Selection",
    "volume": "workshop",
    "abstract": "Event and argument role detection are frequently conceived as separate tasks. In this work we conceive both processes as one taskin a hybrid event detection approach. Its main component is based on automatic keyword extraction (AKE) using the self-attention mechanism of a BERT transformer model. As a bottleneck for AKE is defining the threshold of the attention values, we propose a novel method for automatic self-attention thresholdselection. It is fueled by core event information, or simply the verb and its arguments as the backbone of an event. These are outputted by a knowledge-based syntactic parser. In a secondstep the event core is enriched with other semantically salient words provided by the transformer model. Furthermore, we propose an automatic self-attention layer and head selectionmechanism, by analyzing which self-attention cells in the BERT transformer contribute most to the hybrid event detection and which linguistic tasks they represent. This approach was integrated in a pipeline event extraction approachand outperforms three state of the art multi-task event extraction methods",
    "checked": true,
    "id": "0e4e447ead89cbe2d8b627a546166d1843031d08",
    "semantic_title": "a hybrid knowledge and transformer-based model for event detection with automatic self-attention threshold, layer and head selection",
    "citation_count": 1,
    "authors": [
      "Thierry Desot",
      "Orphee De Clercq",
      "Veronique Hoste"
    ]
  },
  "https://aclanthology.org/2022.case-1.5": {
    "title": "Improving Zero-Shot Event Extraction via Sentence Simplification",
    "volume": "workshop",
    "abstract": "The success of sites such as ACLED and Our World in Data have demonstrated the massive utility of extracting events in structured formats from large volumes of textual data in the formof news, social media, blogs and discussion forums. Event extraction can provide a window into ongoing geopolitical crises and yield actionable intelligence. In this work, we cast socio-political event extraction as a machine reading comprehension (MRC) task. % With the proliferation of large pretrained language models Machine Reading Comprehension (MRC) has emerged as a new paradigm for event extraction in recent times. In this approach, extraction of social-political actors and targets from a sentence is framed as an extractive question-answering problem conditioned on an event type. There are several advantages of using MRC for this task including the ability to leverage large pretrained multilingual language models and their ability to perform zero-shot extraction. Moreover, we find that the problem of long-range dependencies, i.e., large lexical distance between trigger and argument words and the difficulty of processing syntactically complex sentences plague MRC-based approaches. To address this, we present a general approach to improve the performance of MRC-based event extraction by performing unsupervised sentence simplification guided by the MRC model itself. We evaluate our approach on the ICEWS geopolitical event extraction dataset, with specific attention to ‘Actor' and ‘Target' argument roles. We show how such context simplification can improve the performance of MRC-based event extraction by more than 5% for actor extraction and more than 10% for target extraction",
    "checked": true,
    "id": "633c38bb5304b059dc2e790a9a7d493feeb2cbe1",
    "semantic_title": "improving zero-shot event extraction via sentence simplification",
    "citation_count": 5,
    "authors": [
      "Sneha Mehta",
      "Huzefa Rangwala",
      "Naren Ramakrishnan"
    ]
  },
  "https://aclanthology.org/2022.case-1.6": {
    "title": "SNU-Causality Lab @ Causal News Corpus 2022: Detecting Causality by Data Augmentation via Part-of-Speech tagging",
    "volume": "workshop",
    "abstract": "Finding causal relations in texts has been a challenge since it requires methods ranging from defining event ontologies to developing proper algorithmic approaches. In this paper, we developed a framework which classifies whether a given sentence contains a causal event. As our approach, we exploited an external corpus that has causal labels to overcome the small size of the original corpus (Causal News Corpus) provided by task organizers. Further, we employed a data augmentation technique utilizing Part-Of-Speech (POS) based on our observation that some parts of speech are more (or less) relevant to causality. Our approach especially improved the recall of detecting causal events in sentences",
    "checked": true,
    "id": "45144b23ad8614d91a5b970a12b1b4f4c360ca92",
    "semantic_title": "snu-causality lab @ causal news corpus 2022: detecting causality by data augmentation via part-of-speech tagging",
    "citation_count": 1,
    "authors": [
      "Juhyeon Kim",
      "Yesong Choe",
      "Sanghack Lee"
    ]
  },
  "https://aclanthology.org/2022.case-1.7": {
    "title": "LTRC @ Causal News Corpus 2022: Extracting and Identifying Causal Elements using Adapters",
    "volume": "workshop",
    "abstract": "Causality detection and identification is centered on identifying semantic and cognitive connections in a sentence. In this paper, we describe the effort of team LTRC for Causal News Corpus - Event Causality Shared Task 2022 at the 5th Workshop on Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2022). The shared task consisted of two subtasks: 1) identifying if a sentence contains a causality relation, and 2) identifying spans of text that correspond to cause, effect and signals. We fine-tuned transformer-based models with adapters for both subtasks. Our best-performing models obtained a binary F1 score of 0.853 on held-out data for subtask 1 and a macro F1 score of 0.032 on held-out data for subtask 2. Our approach is ranked third in subtask 1 and fourth in subtask 2. The paper describes our experiments, solutions, and analysis in detail",
    "checked": true,
    "id": "64a9896316bb9bfe901637b3dd018f4fe3e104ba",
    "semantic_title": "ltrc @ causal news corpus 2022: extracting and identifying causal elements using adapters",
    "citation_count": 1,
    "authors": [
      "Hiranmai Sri Adibhatla",
      "Manish Shrivastava"
    ]
  },
  "https://aclanthology.org/2022.case-1.8": {
    "title": "Cross-modal Transfer Between Vision and Language for Protest Detection",
    "volume": "workshop",
    "abstract": "Most of today's systems for socio-political event detection are text-based, while an increasing amount of information published on the web is multi-modal. We seek to bridge this gap by proposing a method that utilizes existing annotated unimodal data to perform event detection in another data modality, zero-shot. Specifically, we focus on protest detection in text and images, and show that a pretrained vision-and-language alignment model (CLIP) can be leveraged towards this end. In particular, our results suggest that annotated protest text data can act supplementarily for detecting protests in images, but significant transfer is demonstrated in the opposite direction as well",
    "checked": true,
    "id": "e878d54bc37f0eb6d4542bbbfae3186ea4e5de77",
    "semantic_title": "cross-modal transfer between vision and language for protest detection",
    "citation_count": 1,
    "authors": [
      "Ria Raj",
      "Kajsa Andreasson",
      "Tobias Norlund",
      "Richard Johansson",
      "Aron Lagerberg"
    ]
  },
  "https://aclanthology.org/2022.case-1.9": {
    "title": "IDIAPers @ Causal News Corpus 2022: Efficient Causal Relation Identification Through a Prompt-based Few-shot Approach",
    "volume": "workshop",
    "abstract": "In this paper, we describe our participation in the subtask 1 of CASE-2022, Event Causality Identification with Casual News Corpus. We address the Causal Relation Identification (CRI) task by exploiting a set of simple yet complementary techniques for fine-tuning language models (LMs) on a few annotated examples (i.e., a few-shot configuration).We follow a prompt-based prediction approach for fine-tuning LMs in which the CRI task is treated as a masked language modeling problem (MLM). This approach allows LMs natively pre-trained on MLM tasks to directly generate textual responses to CRI-specific prompts. We compare the performance of this method against ensemble techniques trained on the entire dataset. Our best-performing submission was fine-tuned with only 256 instances per class, 15.7% of the all available data, and yet obtained the second-best precision (0.82), third-best accuracy (0.82), and an F1-score (0.85) very close to what was reported by the winner team (0.86)",
    "checked": true,
    "id": "8c6db6748aa64526b52a207fee455de2d55cef72",
    "semantic_title": "idiapers @ causal news corpus 2022: efficient causal relation identification through a prompt-based few-shot approach",
    "citation_count": 1,
    "authors": [
      "Sergio Burdisso",
      "Juan Pablo Zuluaga-gomez",
      "Esau Villatoro-tello",
      "Martin Fajcik",
      "Muskaan Singh",
      "Pavel Smrz",
      "Petr Motlicek"
    ]
  },
  "https://aclanthology.org/2022.case-1.10": {
    "title": "IDIAPers @ Causal News Corpus 2022: Extracting Cause-Effect-Signal Triplets via Pre-trained Autoregressive Language Model",
    "volume": "workshop",
    "abstract": "In this paper, we describe our shared task submissions for Subtask 2 in CASE-2022, Event Causality Identification with Casual News Corpus. The challenge focused on the automatic detection of all cause-effect-signal spans present in the sentence from news-media. We detect cause-effect-signal spans in a sentence using T5 — a pre-trained autoregressive language model. We iteratively identify all cause-effect-signal span triplets, always conditioning the prediction of the next triplet on the previously predicted ones. To predict the triplet itself, we consider different causal relationships such as cause→effect→signal. Each triplet component is generated via a language model conditioned on the sentence, the previous parts of the current triplet, and previously predicted triplets. Despite training on an extremely small dataset of 160 samples, our approach achieved competitive performance, being placed second in the competition. Furthermore, we show that assuming either cause→effect or effect→cause order achieves similar results",
    "checked": true,
    "id": "b2dd1c1efe8eb2dee39c21d987f2bbb5f04db224",
    "semantic_title": "idiapers @ causal news corpus 2022: extracting cause-effect-signal triplets via pre-trained autoregressive language model",
    "citation_count": 2,
    "authors": [
      "Martin Fajcik",
      "Muskaan Singh",
      "Juan Pablo Zuluaga-gomez",
      "Esau Villatoro-tello",
      "Sergio Burdisso",
      "Petr Motlicek",
      "Pavel Smrz"
    ]
  },
  "https://aclanthology.org/2022.case-1.11": {
    "title": "NoisyAnnot@ Causal News Corpus 2022: Causality Detection using Multiple Annotation Decisions",
    "volume": "workshop",
    "abstract": "The paper describes the work that has been submitted to the 5th workshop on Challenges and Applications of Automated Extraction of socio-political events from text (CASE 2022). The work is associated with Subtask 1 of Shared Task 3 that aims to detect causality in protest news corpus. The authors used different large language models with customized cross-entropy loss functions that exploit annotation information. The experiments showed that bert-based-uncased with refined cross-entropy outperformed the others, achieving a F1 score of 0.8501 on the Causal News Corpus dataset",
    "checked": true,
    "id": "57e03418a8a2bf1cb99f292937a6a003b177ebed",
    "semantic_title": "noisyannot@ causal news corpus 2022: causality detection using multiple annotation decisions",
    "citation_count": 1,
    "authors": [
      "Quynh Anh Nguyen",
      "Arka Mitra"
    ]
  },
  "https://aclanthology.org/2022.case-1.12": {
    "title": "GGNN@Causal News Corpus 2022:Gated Graph Neural Networks for Causal Event Classification from Social-Political News Articles",
    "volume": "workshop",
    "abstract": "The discovery of causality mentions from text is a core cognitive concept and appears in many natural language processing (NLP) applications. In this paper, we study the task of Event Causality Identification (ECI) from social-political news. The aim of the task is to detect causal relationships between event mention pairs in text. Although deep learning models have recently achieved a state-of-the-art performance on many tasks and applications in NLP, most of them still fail to capture rich semantic and syntactic structures within sentences which is key for causality classification. We present a solution for causal event detection from social-political news that captures semantic and syntactic information based on gated graph neural networks (GGNN) and contextualized language embeddings. Experimental results show that our proposed method outperforms the baseline model (BERT (Bidirectional Embeddings from Transformers) in terms of f1-score and accuracy",
    "checked": true,
    "id": "cddc8c9e09fdc82a1a162ef697c6359f0f3a8f83",
    "semantic_title": "ggnn@causal news corpus 2022:gated graph neural networks for causal event classification from social-political news articles",
    "citation_count": 2,
    "authors": [
      "Paul Trust",
      "Rosane Minghim",
      "Evangelos Milos",
      "Kadusabe Provia"
    ]
  },
  "https://aclanthology.org/2022.case-1.13": {
    "title": "1Cademy @ Causal News Corpus 2022: Leveraging Self-Training in Causality Classification of Socio-Political Event Data",
    "volume": "workshop",
    "abstract": "This paper details our participation in the Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE) workshop @ EMNLP 2022, where we take part in Subtask 1 of Shared Task 3 (CITATION). We approach the given task of event causality detection by proposing a self-training pipeline that follows a teacher-student classifier method. More specifically, we initially train a teacher model on the true, original task data, and use that teacher model to self-label data to be used in the training of a separate student model for the final task prediction. We test how restricting the number of positive or negative self-labeled examples in the self-training process affects classification performance. Our final results show that using self-training produces a comprehensive performance improvement across all models and self-labeled training sets tested within the task of event causality sequence classification. On top of that, we find that self-training performance did not diminish even when restricting either positive/negative examples used in training. Our code is be publicly available at https://github.com/Gzhang-umich/1CademyTeamOfCASE",
    "checked": true,
    "id": "2c1db2d4dc878625b3c1056bcd8517cb04e7a8bc",
    "semantic_title": "1cademy @ causal news corpus 2022: leveraging self-training in causality classification of socio-political event data",
    "citation_count": 2,
    "authors": [
      "Adam Nik",
      "Ge Zhang",
      "Xingran Chen",
      "Mingyu Li",
      "Jie Fu"
    ]
  },
  "https://aclanthology.org/2022.case-1.14": {
    "title": "1Cademy @ Causal News Corpus 2022: Enhance Causal Span Detection via Beam-Search-based Position Selector",
    "volume": "workshop",
    "abstract": "In this paper, we present our approach and empirical observations for Cause-Effect Signal Span Detection—Subtask 2 of Shared task 3 at CASE 2022. The shared task aims to extract the cause, effect, and signal spans from a given causal sentence. We model the task as a reading comprehension (RC) problem and apply a token-level RC-based span prediction paradigm to the task as the baseline. We explore different training objectives to fine-tune the model, as well as data augmentation (DA) tricks based on the language model (LM) for performance improvement. Additionally, we propose an efficient beam-search post-processing strategy to due with the drawbacks of span detection to obtain a further performance gain. Our approach achieves an average F1 score of 54.15 and ranks 1ˆst in the CASE competition. Our code is available at https://github.com/Gzhang-umich/1CademyTeamOfCASE",
    "checked": true,
    "id": "4b99a55d77af90cd8f731ad25f0b9958a39c48ec",
    "semantic_title": "1cademy @ causal news corpus 2022: enhance causal span detection via beam-search-based position selector",
    "citation_count": 5,
    "authors": [
      "Xingran Chen",
      "Ge Zhang",
      "Adam Nik",
      "Mingyu Li",
      "Jie Fu"
    ]
  },
  "https://aclanthology.org/2022.case-1.15": {
    "title": "Hybrid Knowledge Engineering Leveraging a Robust ML Framework to Produce an Assassination Dataset",
    "volume": "workshop",
    "abstract": "Social and political researchers require robust event datasets to conduct data-driven analysis, an example being the need for trigger event datasets to analyze under what conditions and in what patterns certain trigger-type events increase the probability of mass killings. Fortunately, NLP and ML can be leveraged to create these robust datasets. In this paper we (i) outline a robust ML framework that prioritizes understandability through visualizations and generalizability through the ability to implement different ML algorithms, (ii) perform a comparative analysis of these ML tools within the framework for the coup trigger, (iii) leverage our ML framework along with a unique combination of NLP tools, such as NER and knowledge graphs, to produce a dataset for the the assassination trigger, and (iv) make this comprehensive, consolidated, and cohesive assassination dataset publicly available to provide temporal data for understanding political violence as well as training data for further socio-political research",
    "checked": true,
    "id": "ba93841878fe9d7bbfc25e279a8be702d631ef25",
    "semantic_title": "hybrid knowledge engineering leveraging a robust ml framework to produce an assassination dataset",
    "citation_count": 1,
    "authors": [
      "Abigail Sticha",
      "Paul Brenner"
    ]
  },
  "https://aclanthology.org/2022.case-1.16": {
    "title": "Political Event Coding as Text-to-Text Sequence Generation",
    "volume": "workshop",
    "abstract": "We report on the current status of an effort to produce political event data from unstructured text via a Transformer language model. Compelled by the current lack of publicly available and up-to-date event coding software, we seek to train a model that can produce structured political event records at the sentence level. Our approach differs from previous efforts in that we conceptualize this task as one of text-to-text sequence generation. We motivate this choice by outlining desirable properties of text generation models for the needs of event coding. To overcome the lack of sufficient training data, we also describe a method for generating synthetic text and event record pairs that we use to fit our model",
    "checked": true,
    "id": "f4666ec25c7af298ed359c0eca05295b908bab59",
    "semantic_title": "political event coding as text-to-text sequence generation",
    "citation_count": 1,
    "authors": [
      "Yaoyao Dai",
      "Benjamin Radford",
      "Andrew Halterman"
    ]
  },
  "https://aclanthology.org/2022.case-1.17": {
    "title": "Zero-Shot Ranking Socio-Political Texts with Transformer Language Models to Reduce Close Reading Time",
    "volume": "workshop",
    "abstract": "We approach the classification problem as an entailment problem and apply zero-shot ranking to socio-political texts. Documents that are ranked at the top can be considered positively classified documents and this reduces the close reading time for the information extraction process. We use Transformer Language Models to get the entailment probabilities and investigate different types of queries. We find that DeBERTa achieves higher mean average precision scores than RoBERTa and when declarative form of the class label is used as a query, it outperforms dictionary definition of the class label. We show that one can reduce the close reading time by taking some percentage of the ranked documents that the percentage depends on how much recall they want to achieve. However, our findings also show that percentage of the documents that should be read increases as the topic gets broader",
    "checked": true,
    "id": "0a8204a43cb70bea2696d37635ae2fc6a4d82070",
    "semantic_title": "zero-shot ranking socio-political texts with transformer language models to reduce close reading time",
    "citation_count": 1,
    "authors": [
      "Kiymet Akdemir",
      "Ali Hürriyetoğlu"
    ]
  },
  "https://aclanthology.org/2022.case-1.18": {
    "title": "SPOCK @ Causal News Corpus 2022: Cause-Effect-Signal Span Detection Using Span-Based and Sequence Tagging Models",
    "volume": "workshop",
    "abstract": "Understanding causal relationship is an importance part of natural language processing. We address the causal information extraction problem with different neural models built on top of pre-trained transformer-based language models for identifying Cause, Effect and Signal spans, from news data sets. We use the Causal News Corpus subtask 2 training data set to train span-based and sequence tagging models. Our span-based model based on pre-trained BERT base weights achieves an F1 score of 47.48 on the test set with an accuracy score of 36.87 and obtained 3rd place in the Causal News Corpus 2022 shared task",
    "checked": true,
    "id": "42f64196dfe89c62a9af05f1b3dde625a2b0531b",
    "semantic_title": "spock @ causal news corpus 2022: cause-effect-signal span detection using span-based and sequence tagging models",
    "citation_count": 1,
    "authors": [
      "Anik Saha",
      "Alex Gittens",
      "Jian Ni",
      "Oktie Hassanzadeh",
      "Bulent Yener",
      "Kavitha Srinivas"
    ]
  },
  "https://aclanthology.org/2022.case-1.19": {
    "title": "CSECU-DSG @ Causal News Corpus 2022: Fusion of RoBERTa Transformers Variants for Causal Event Classification",
    "volume": "workshop",
    "abstract": "Identifying cause-effect relationships in sentences is one of the formidable tasks to tackle the challenges of inference and understanding of natural language. However, the diversity of word semantics and sentence structure makes it challenging to determine the causal relationship effectively. To address these challenges, CASE-2022 shared task 3 introduced a task focusing on event causality identification with causal news corpus. This paper presents our participation in this task, especially in subtask 1 which is the causal event classification task. To tackle the task challenge, we propose a unified neural model through exploiting two fine-tuned transformer models including RoBERTa and Twitter-RoBERTa. For the score fusion, we combine the prediction scores of each component model using weighted arithmetic mean to generate the probability score for class label identification. The experimental results showed that our proposed method achieved the top performance (ranked 1st) among the participants",
    "checked": true,
    "id": "9f322abbff1154178e132ab86f1df007b6bdc549",
    "semantic_title": "csecu-dsg @ causal news corpus 2022: fusion of roberta transformers variants for causal event classification",
    "citation_count": 2,
    "authors": [
      "Abdul Aziz",
      "Md. Akram Hossain",
      "Abu Nowshed Chy"
    ]
  },
  "https://aclanthology.org/2022.case-1.20": {
    "title": "ARGUABLY @ Causal News Corpus 2022: Contextually Augmented Language Models for Event Causality Identification",
    "volume": "workshop",
    "abstract": "Causal (a cause-effect relationship between two arguments) has become integral to various NLP domains such as question answering, summarization, and event prediction. To understand causality in detail, Event Causality Identification with Causal News Corpus (CASE-2022) has organized shared tasks. This paper defines our participation in Subtask 1, which focuses on classifying event causality. We used sentence-level augmentation based on contextualized word embeddings of distillBERT to construct new data. This data was then trained using two approaches. The first technique used the DeBERTa language model, and the second used the RoBERTa language model in combination with cross-attention. We obtained the second-best F1 score (0.8610) in the competition with the Contextually Augmented DeBERTa model",
    "checked": true,
    "id": "cf10b56dcb512902ca596b113c5605d2cd6bfa50",
    "semantic_title": "arguably @ causal news corpus 2022: contextually augmented language models for event causality identification",
    "citation_count": 1,
    "authors": [
      "Guneet Kohli",
      "Prabsimran Kaur",
      "Jatin Bedi"
    ]
  },
  "https://aclanthology.org/2022.case-1.21": {
    "title": "ClassBases at the CASE-2022 Multilingual Protest Event Detection Task: Multilingual Protest News Detection and Automatically Replicating Manually Created Event Datasets",
    "volume": "workshop",
    "abstract": "In this report, we describe our ClassBases submissions to a shared task on multilingual protest event detection. For the multilingual protest news detection, we participated in subtask-1, subtask-2 and subtask-4 which are document classification, sentence classification and token classification. In subtask-1, we compare XLM-RoBERTa-base, mLUKE-base and XLM-RoBERTa-large on finetuning in a sequential classification setting. We always use a combination of the training data from every language provided to train our multilingual models. We found that larger models seem to work better and entity knowledge helps but at a non-negligible cost. For subtask-2, we only submitted an mLUKE-base system for sentence classification. For subtask-4, we only submitted an XLM-RoBERTa-base for token classification system for sequence labeling. For automatically replicating manually created event datasets, we participated in COVID-related protest events from the New York Times news corpus. We created a system to process the crawled data into a dataset of protest events",
    "checked": true,
    "id": "c6c872176d6808a62f3d6549a2c2a45532b08ccd",
    "semantic_title": "classbases at the case-2022 multilingual protest event detection task: multilingual protest news detection and automatically replicating manually created event datasets",
    "citation_count": 2,
    "authors": [
      "Peratham Wiriyathammabhum"
    ]
  },
  "https://aclanthology.org/2022.case-1.22": {
    "title": "EventGraph at CASE 2021 Task 1: A General Graph-based Approach to Protest Event Extraction",
    "volume": "workshop",
    "abstract": "This paper presents our submission to the 2022 edition of the CASE 2021 shared task 1, subtask 4. The EventGraph system adapts an end-to-end, graph-based semantic parser to the task of Protest Event Extraction and more specifically subtask 4 on event trigger and argument extraction. We experiment with various graphs, encoding the events as either \"labeled-edge\" or \"node-centric\" graphs. We show that the \"node-centric\" approach yields best results overall, performing well across the three languages of the task, namely English, Spanish, and Portuguese. EventGraph is ranked 3rd for English and Portuguese, and 4th for Spanish",
    "checked": true,
    "id": "a1db37d5c7e4fd43edb1e75631f1dcee6509985f",
    "semantic_title": "eventgraph at case 2021 task 1: a general graph-based approach to protest event extraction",
    "citation_count": 1,
    "authors": [
      "Huiling You",
      "David Samuel",
      "Samia Touileb",
      "Lilja Øvrelid"
    ]
  },
  "https://aclanthology.org/2022.case-1.23": {
    "title": "NSUT-NLP at CASE 2022 Task 1: Multilingual Protest Event Detection using Transformer-based Models",
    "volume": "workshop",
    "abstract": "Event detection, specifically in the socio-political domain, has posed a long-standing challenge to researchers in the NLP domain. Therefore, the creation of automated techniques that perform classification of the large amounts of accessible data on the Internet becomes imperative. This paper is a summary of the efforts we made in participating in Task 1 of CASE 2022. We use state-of-art multilingual BERT (mBERT) with further fine-tuning to perform document classification in English, Portuguese, Spanish, Urdu, Hindi, Turkish and Mandarin. In the document classification subtask, we were able to achieve F1 scores of 0.8062, 0.6445, 0.7302, 0.5671, 0.6555, 0.7545 and 0.6702 in English, Spanish, Portuguese, Hindi, Urdu, Mandarin and Turkish respectively achieving a rank of 5 in English and 7 on the remaining language tasks",
    "checked": true,
    "id": "afaabfc0e7a55c4e95e3b88d84c3496fdd49a875",
    "semantic_title": "nsut-nlp at case 2022 task 1: multilingual protest event detection using transformer-based models",
    "citation_count": 1,
    "authors": [
      "Manan Suri",
      "Krish Chopra",
      "Adwita Arora"
    ]
  },
  "https://aclanthology.org/2022.case-1.24": {
    "title": "CamPros at CASE 2022 Task 1: Transformer-based Multilingual Protest News Detection",
    "volume": "workshop",
    "abstract": "Socio-political protests often lead to grave consequences when they occur. The early detection of such protests is very important for taking early precautionary measures. However, the main shortcoming of protest event detection is the scarcity of sufficient training data for specific language categories, which makes it difficult to train data-hungry deep learning models effectively. Therefore, cross-lingual and zero-shot learning models are needed to detect events in various low-resource languages. This paper proposes a multi-lingual cross-document level event detection approach using pre-trained transformer models developed for Shared Task 1 at CASE 2022. The shared task constituted four subtasks for event detection at different granularity levels, i.e., document level to token level, spread over multiple languages (English, Spanish, Portuguese, Turkish, Urdu, and Mandarin). Our system achieves an average F1 score of 0.73 for document-level event detection tasks. Our approach secured 2nd position for the Hindi language in subtask 1 with an F1 score of 0.80. While for Spanish, we secure 4th position with an F1 score of 0.69. Our code is available at https://github.com/nehapspathak/campros/",
    "checked": true,
    "id": "411cd75264b86a0c087e67fe02493dc55a941c62",
    "semantic_title": "campros at case 2022 task 1: transformer-based multilingual protest news detection",
    "citation_count": 1,
    "authors": [
      "Neha Kumari",
      "Mrinal Anand",
      "Tushar Mohan",
      "Ponnurangam Kumaraguru",
      "Arun Balaji Buduru"
    ]
  },
  "https://aclanthology.org/2022.case-1.25": {
    "title": "ARC-NLP at CASE 2022 Task 1: Ensemble Learning for Multilingual Protest Event Detection",
    "volume": "workshop",
    "abstract": "Automated socio-political protest event detection is a challenging task when multiple languages are considered. In CASE 2022 Task 1, we propose ensemble learning methods for multilingual protest event detection in four subtasks with different granularity levels from document-level to entity-level. We develop an ensemble of fine-tuned Transformer-based language models, along with a post-processing step to regularize the predictions of our ensembles. Our approach places the first place in 6 out of 16 leaderboards organized in seven languages including English, Mandarin, and Turkish",
    "checked": true,
    "id": "f024008bcd71133bb22b3d385345ee6965719eb0",
    "semantic_title": "arc-nlp at case 2022 task 1: ensemble learning for multilingual protest event detection",
    "citation_count": 4,
    "authors": [
      "Umitcan Sahin",
      "Oguzhan Ozcelik",
      "Izzet Emre Kucukkaya",
      "Cagri Toraman"
    ]
  },
  "https://aclanthology.org/2022.case-1.26": {
    "title": "CEIA-NLP at CASE 2022 Task 1: Protest News Detection for Portuguese",
    "volume": "workshop",
    "abstract": "This paper summarizes our work on the document classification subtask of Multilingual protest news detection of the CASE @ ACL-IJCNLP 2022 workshok. In this context, we investigate the performance of monolingual and multilingual transformer-based models in low data resources, taking Portuguese as an example and evaluating language models on document classification. Our approach became the winning solution in Portuguese document classification achieving 0.8007 F1 Score on Test set. The experimental results demonstrate that multilingual models achieve best results in scenarios with few dataset samples of specific language, because we can train models using datasets from other languages of the same task and domain",
    "checked": true,
    "id": "424594a4010a28d985a33f3897c8c41886b12a1e",
    "semantic_title": "ceia-nlp at case 2022 task 1: protest news detection for portuguese",
    "citation_count": 1,
    "authors": [
      "Diogo Fernandes",
      "Adalberto Junior",
      "Gabriel Marques",
      "Anderson Soares",
      "Arlindo Galvao Filho"
    ]
  },
  "https://aclanthology.org/2022.case-1.27": {
    "title": "SPARTA at CASE 2021 Task 1: Evaluating Different Techniques to Improve Event Extraction",
    "volume": "workshop",
    "abstract": "We participated in the Shared Task 1 at CASE 2021, Subtask 4 on protest event extraction from news articles and examined different techniques aimed at improving the performance of the winning system from the last competition round. We evaluated in-domain pre-training, task-specific pre-fine-tuning, alternative loss function, translation of the English training dataset into other target languages (i.e., Portuguese, Spanish, and Hindi) for the token classification task, and a simple data augmentation technique by random sentence reordering. This paper summarizes the results, showing that random sentence reordering leads to a consistent improvement of the model performance",
    "checked": true,
    "id": "34c5fc9a09f9ef6074f3e9a3130392d7bba1c669",
    "semantic_title": "sparta at case 2021 task 1: evaluating different techniques to improve event extraction",
    "citation_count": 1,
    "authors": [
      "Arthur Müller",
      "Andreas Dafnos"
    ]
  },
  "https://aclanthology.org/2022.case-1.28": {
    "title": "Event Causality Identification with Causal News Corpus - Shared Task 3, CASE 2022",
    "volume": "workshop",
    "abstract": "The Event Causality Identification Shared Task of CASE 2022 involved two subtasks working on the Causal News Corpus. Subtask 1 required participants to predict if a sentence contains a causal relation or not. This is a supervised binary classification task. Subtask 2 required participants to identify the Cause, Effect and Signal spans per causal sentence. This could be seen as a supervised sequence labeling task. For both subtasks, participants uploaded their predictions for a held-out test set, and ranking was done based on binary F1 and macro F1 scores for Subtask 1 and 2, respectively. This paper summarizes the work of the 17 teams that submitted their results to our competition and 12 system description papers that were received. The best F1 scores achieved for Subtask 1 and 2 were 86.19% and 54.15%, respectively. All the top-performing approaches involved pre-trained language models fine-tuned to the targeted task. We further discuss these approaches and analyze errors across participants' systems in this paper",
    "checked": true,
    "id": "220b915c3f86925c7dc05a59e613f53e485ad87d",
    "semantic_title": "event causality identification with causal news corpus - shared task 3, case 2022",
    "citation_count": 23,
    "authors": [
      "Fiona Anting Tan",
      "Hansi Hettiarachchi",
      "Ali Hürriyetoğlu",
      "Tommaso Caselli",
      "Onur Uca",
      "Farhana Ferdousi Liza",
      "Nelleke Oostdijk"
    ]
  },
  "https://aclanthology.org/2022.case-1.29": {
    "title": "Tracking COVID-19 protest events in the United States. Shared Task 2: Event Database Replication, CASE 2022",
    "volume": "workshop",
    "abstract": "The goal of Shared Task 2 is evaluating state-of-the-art event detection systems by comparing the spatio-temporal distribution of the events they detect with existing event databases. The task focuses on some usability requirements of event detection systems in real worldscenarios. Namely, it aims to measure the ability of such a system to: (i) detect socio-political event mentions in news and social media, (ii) properly find their geographical locations, (iii) de-duplicate reports extracted from multiple sources referring to the same actual event. Building an annotated corpus for training and evaluating jointly these sub-tasks is highly time consuming. One possible way to indirectly evaluate a system's output without an annotated corpus available is to measure its correlation with human-curated event data sets. In the last three years, the COVID-19 pandemic became motivation for restrictions and anti-pandemic measures on a world scale. This has triggered a wave of reactions and citizen actions in many countries. Shared Task 2 challenges participants to identify COVID-19 related protest actions from large unstructureddata sources both from mainstream and social media. We assess each system's ability to model the evolution of protest events both temporally and spatially by using a number of correlation metrics with respect to a comprehensive and validated data set of COVID-related protest events (Raleigh et al., 2010)",
    "checked": true,
    "id": "e521fab50f3fcc68809d55421c247b52247012ae",
    "semantic_title": "tracking covid-19 protest events in the united states. shared task 2: event database replication, case 2022",
    "citation_count": 6,
    "authors": [
      "Vanni Zavarella",
      "Hristo Tanev",
      "Ali Hürriyetoğlu",
      "Peratham Wiriyathammabhum",
      "Bertrand De Longueville"
    ]
  },
  "https://aclanthology.org/2022.case-1.30": {
    "title": "Challenges and Applications of Automated Extraction of Socio-political Events from Text (CASE 2022): Workshop and Shared Task Report",
    "volume": "workshop",
    "abstract": "We provide a summary of the fifth edition of the CASE workshop that is held in the scope of EMNLP 2022. The workshop consists of regular papers, two keynotes, working papers of shared task participants, and task overview papers. This workshop has been bringing together all aspects of event information collection across technical and social science fields. In addition to the progress in depth, the submission and acceptance of multimodal approaches show the widening of this interdisciplinary research topic",
    "checked": true,
    "id": "d4068bbccbb8e326d14a617340585dad7cecf2f4",
    "semantic_title": "challenges and applications of automated extraction of socio-political events from text (case 2022): workshop and shared task report",
    "citation_count": 20,
    "authors": [
      "Ali Hürriyetoğlu",
      "Hristo Tanev",
      "Vanni Zavarella",
      "Reyyan Yeniterzi",
      "Osman Mutlu",
      "Erdem Yörük"
    ]
  },
  "https://aclanthology.org/2022.case-1.31": {
    "title": "Extended Multilingual Protest News Detection - Shared Task 1, CASE 2021 and 2022",
    "volume": "workshop",
    "abstract": "We report results of the CASE 2022 Shared Task 1 on Multilingual Protest Event Detection. This task is a continuation of CASE 2021 that consists of four subtasks that are i) document classification, ii) sentence classification, iii) event sentence coreference identification, and iv) event extraction. The CASE 2022 extension consists of expanding the test data with more data in previously available languages, namely, English, Hindi, Portuguese, and Spanish, and adding new test data in Mandarin, Turkish, and Urdu for Sub-task 1, document classification. The training data from CASE 2021 in English, Portuguese and Spanish were utilized. Therefore, predicting document labels in Hindi, Mandarin, Turkish, and Urdu occurs in a zero-shot setting. The CASE 2022 workshop accepts reports on systems developed for predicting test data of CASE 2021 as well. We observe that the best systems submitted by CASE 2022 participants achieve between 79.71 and 84.06 F1-macro for new languages in a zero-shot setting. The winning approaches are mainly ensembling models and merging data in multiple languages. The best two submissions on CASE 2021 data outperform submissions from last year for Subtask 1 and Subtask 2 in all languages. Only the following scenarios were not outperformed by new submissions on CASE 2021: Subtask 3 Portuguese & Subtask 4 English",
    "checked": true,
    "id": "3ffdce5056944cf18f54bfde0f9de5bcfb696540",
    "semantic_title": "extended multilingual protest news detection - shared task 1, case 2021 and 2022",
    "citation_count": 13,
    "authors": [
      "Ali Hürriyetoğlu",
      "Osman Mutlu",
      "Fırat Duruşan",
      "Onur Uca",
      "Alaeddin Gürel",
      "Benjamin J. Radford",
      "Yaoyao Dai",
      "Hansi Hettiarachchi",
      "Niklas Stoehr",
      "Tadashi Nomoto",
      "Milena Slavcheva",
      "Francielle Vargas",
      "Aaqib Javid",
      "Fatih Beyhan",
      "Erdem Yörük"
    ]
  },
  "https://aclanthology.org/2022.conll-1.1": {
    "title": "A Multilingual Bag-of-Entities Model for Zero-Shot Cross-Lingual Text Classification",
    "volume": "workshop",
    "abstract": "We present a multilingual bag-of-entities model that effectively boosts the performance of zero-shot cross-lingual text classification by extending a multilingual pre-trained language model (e.g., M-BERT). It leverages the multilingual nature of Wikidata: entities in multiple languages representing the same concept are defined with a unique identifier. This enables entities described in multiple languages to be represented using shared embeddings. A model trained on entity features in a resource-rich language can thus be directly applied to other languages. Our experimental results on cross-lingual topic classification (using the MLDoc and TED-CLDC datasets) and entity typing (using the SHINRA2020-ML dataset) show that the proposed model consistently outperforms state-of-the-art models",
    "checked": true,
    "id": "c595a4b65c94d1ca48dae301ff22c81ce951db21",
    "semantic_title": "a multilingual bag-of-entities model for zero-shot cross-lingual text classification",
    "citation_count": 2,
    "authors": [
      "Sosuke Nishikawa",
      "Ikuya Yamada",
      "Yoshimasa Tsuruoka",
      "Isao Echizen"
    ]
  },
  "https://aclanthology.org/2022.conll-1.2": {
    "title": "Collateral facilitation in humans and language models",
    "volume": "workshop",
    "abstract": "Are the predictions of humans and language models affected by similar things? Research suggests that while comprehending language, humans make predictions about upcoming words, with more predictable words being processed more easily. However, evidence also shows that humans display a similar processing advantage for highly anomalous words when these words are semantically related to the preceding context or to the most probable continuation. Using stimuli from 3 psycholinguistic experiments, we find that this is also almost always also the case for 8 contemporary transformer language models (BERT, ALBERT, RoBERTa, XLM-R, GPT-2, GPT-Neo, GPT-J, and XGLM). We then discuss the implications of this phenomenon for our understanding of both human language comprehension and the predictions made by language models",
    "checked": true,
    "id": "4061a9941fa0ff106e884272d9ed753650417ec4",
    "semantic_title": "collateral facilitation in humans and language models",
    "citation_count": 6,
    "authors": [
      "James Michaelov",
      "Benjamin Bergen"
    ]
  },
  "https://aclanthology.org/2022.conll-1.3": {
    "title": "How Hate Speech Varies by Target Identity: A Computational Analysis",
    "volume": "workshop",
    "abstract": "This paper investigates how hate speech varies in systematic ways according to the identities it targets. Across multiple hate speech datasets annotated for targeted identities, we find that classifiers trained on hate speech targeting specific identity groups struggle to generalize to other targeted identities. This provides empirical evidence for differences in hate speech by target identity; we then investigate which patterns structure this variation. We find that the targeted demographic category (e.g. gender/sexuality or race/ethnicity) appears to have a greater effect on the language of hate speech than does the relative social power of the targeted identity group. We also find that words associated with hate speech targeting specific identities often relate to stereotypes, histories of oppression, current social movements, and other social contexts specific to identities. These experiments suggest the importance of considering targeted identity, as well as the social contexts associated with these identities, in automated hate speech classification",
    "checked": true,
    "id": "5d80dee677cc700fefc25ffef5ebd5efc9f2481b",
    "semantic_title": "how hate speech varies by target identity: a computational analysis",
    "citation_count": 7,
    "authors": [
      "Michael Yoder",
      "Lynnette Ng",
      "David West Brown",
      "Kathleen Carley"
    ]
  },
  "https://aclanthology.org/2022.conll-1.4": {
    "title": "Continual Learning for Natural Language Generations with Transformer Calibration",
    "volume": "workshop",
    "abstract": "Conventional natural language process (NLP) generation models are trained offline with a given dataset for a particular task, which is referred to as isolated learning. Research on sequence-to-sequence language generation aims to study continual learning model to constantly learning from sequentially encountered tasks. However, continual learning studies often suffer from catastrophic forgetting, a persistent challenge for lifelong learning. In this paper, we present a novel NLP transformer model that attempts to mitigate catastrophic forgetting in online continual learning from a new perspective, i.e., attention calibration. We model the attention in the transformer as a calibrated unit in a general formulation, where the attention calibration could give benefits to balance the stability and plasticity of continual learning algorithms through influencing both their forward inference path and backward optimization path. Our empirical experiments, paraphrase generation and dialog response generation, demonstrate that this work outperforms state-of-the-art models by a considerable margin and effectively mitigate the forgetting",
    "checked": true,
    "id": "d2d3cee3342f7c0885a670c6bf53a509fdcd63b2",
    "semantic_title": "continual learning for natural language generations with transformer calibration",
    "citation_count": 4,
    "authors": [
      "Peng Yang",
      "Dingcheng Li",
      "Ping Li"
    ]
  },
  "https://aclanthology.org/2022.conll-1.5": {
    "title": "That's so cute!: The CARE Dataset for Affective Response Detection",
    "volume": "workshop",
    "abstract": "Social media plays an increasing role in our communication with friends and family, and in our consumption of entertainment and information. Hence, to design effective ranking functions for posts on social media, it would be useful to predict the affective responses of a post (e.g., whether it is likely to elicit feelings of entertainment, inspiration, or anger). Similar to work on emotion detection (which focuses on the affect of the publisher of the post), the traditional approach to recognizing affective response would involve an expensive investment in human annotation of training data. We create and publicly release CARE DB, a dataset of 230k social media post annotations according to seven affective responses using the Common Affective Response Expression (CARE) method. The CARE method is a means of leveraging the signal that is present in comments that are posted in response to a post, providing high-precision evidence about the affective response to the post without human annotation. Unlike human annotation, the annotation process we describe here can be iterated upon to expand the coverage of the method, particularly for new affective responses. We present experiments that demonstrate that the CARE annotations compare favorably with crowdsourced annotations. Finally, we use CARE DB to train competitive BERT-based models for predicting affective response as well as emotion detection, demonstrating the utility of the dataset for related tasks",
    "checked": true,
    "id": "68be3cdda97d1ec1ad49a07c15a5356353dd4aa8",
    "semantic_title": "that's so cute!: the care dataset for affective response detection",
    "citation_count": 2,
    "authors": [
      "Jane Yu",
      "Alon Halevy"
    ]
  },
  "https://aclanthology.org/2022.conll-1.6": {
    "title": "A Fine-grained Interpretability Evaluation Benchmark for Neural NLP",
    "volume": "workshop",
    "abstract": "While there is increasing concern about the interpretability of neural models, the evaluation of interpretability remains an open problem, due to the lack of proper evaluation datasets and metrics. In this paper, we present a novel benchmark to evaluate the interpretability of both neural models and saliency methods. This benchmark covers three representative NLP tasks: sentiment analysis, textual similarity and reading comprehension, each provided with both English and Chinese annotated data. In order to precisely evaluate the interpretability, we provide token-level rationales that are carefully annotated to be sufficient, compact and comprehensive. We also design a new metric, i.e., the consistency between the rationales before and after perturbations, to uniformly evaluate the interpretability on different types of tasks. Based on this benchmark, we conduct experiments on three typical models with three saliency methods, and unveil their strengths and weakness in terms of interpretability. We will release this benchmark (https://www.luge.ai/#/luge/task/taskDetail?taskId=15) and hope it can facilitate the research in building trustworthy systems",
    "checked": true,
    "id": "4a3568b47c042f3059d2a11f5e12ca5ce3492d75",
    "semantic_title": "a fine-grained interpretability evaluation benchmark for neural nlp",
    "citation_count": 12,
    "authors": [
      "Lijie Wang",
      "Yaozong Shen",
      "Shuyuan Peng",
      "Shuai Zhang",
      "Xinyan Xiao",
      "Hao Liu",
      "Hongxuan Tang",
      "Ying Chen",
      "Hua Wu",
      "Haifeng Wang"
    ]
  },
  "https://aclanthology.org/2022.conll-1.7": {
    "title": "Towards More Natural Artificial Languages",
    "volume": "workshop",
    "abstract": "A number of papers have recently argued in favor of using artificially generated languages to investigate the inductive biases of linguistic models, or to develop models for low-resource languages with underrepresented typologies. But the promise of artificial languages comes with a caveat: if these artificial languages are not sufficiently reflective of natural language, then using them as a proxy may lead to inaccurate conclusions. In this paper, we take a step towards increasing the realism of artificial language by introducing a variant of indexed grammars that draw their weights from hierarchical Pitman-Yor processes. We show that this framework generates languages that emulate the statistics of natural language corpora better than the current approach of directly formulating weighted context-free grammars",
    "checked": true,
    "id": "a86dd7d1b52943b7072afea3b7deafa5935eaffb",
    "semantic_title": "towards more natural artificial languages",
    "citation_count": 0,
    "authors": [
      "Mark Hopkins"
    ]
  },
  "https://aclanthology.org/2022.conll-1.8": {
    "title": "Causal Analysis of Syntactic Agreement Neurons in Multilingual Language Models",
    "volume": "workshop",
    "abstract": "Structural probing work has found evidence for latent syntactic information in pre-trained language models. However, much of this analysis has focused on monolingual models, and analyses of multilingual models have employed correlational methods that are confounded by the choice of probing tasks. In this study, we causally probe multilingual language models (XGLM and multilingual BERT) as well as monolingual BERT-based models across various languages; we do this by performing counterfactual perturbations on neuron activations and observing the effect on models' subject-verb agreement probabilities. We observe where in the model and to what extent syntactic agreement is encoded in each language. We find significant neuron overlap across languages in autoregressive multilingual language models, but not masked language models. We also find two distinct layer-wise effect patterns and two distinct sets of neurons used for syntactic agreement, depending on whether the subject and verb are separated by other tokens. Finally, we find that behavioral analyses of language models are likely underestimating how sensitive masked language models are to syntactic information",
    "checked": true,
    "id": "e886fe33b9cda6e0b0f523d5fbbb7287c23aba2b",
    "semantic_title": "causal analysis of syntactic agreement neurons in multilingual language models",
    "citation_count": 4,
    "authors": [
      "Aaron Mueller",
      "Yu Xia",
      "Tal Linzen"
    ]
  },
  "https://aclanthology.org/2022.conll-1.9": {
    "title": "Combining Noisy Semantic Signals with Orthographic Cues: Cognate Induction for the Indic Dialect Continuum",
    "volume": "workshop",
    "abstract": "We present a novel method for unsupervised cognate/borrowing identification from monolingual corpora designed for low and extremely low resource scenarios, based on combining noisy semantic signals from joint bilingual spaces with orthographic cues modelling sound change. We apply our method to the North Indian dialect continuum, containing several dozens of dialects and languages spoken by more than 100 million people. Many of these languages are zero-resource and therefore natural language processing for them is non-existent. We first collect monolingual data for 26 Indic languages, 16 of which were previously zero-resource, and perform exploratory character, lexical and subword cross-lingual alignment experiments for the first time at this scale on this dialect continuum. We create bilingual evaluation lexicons against Hindi for 20 of the languages. We then apply our cognate identification method on the data, and show that our method outperforms both traditional orthography baselines as well as EM-style learnt edit distance matrices. To the best of our knowledge, this is the first work to combine traditional orthographic cues with noisy bilingual embeddings to tackle unsupervised cognate detection in a (truly) low-resource setup, showing that even noisy bilingual embeddings can act as good guides for this task. We release our multilingual dialect corpus, called HinDialect, as well as our scripts for evaluation data collection and cognate induction",
    "checked": true,
    "id": "4c634317136f6ce4fd18e5aa176ddf91ea5be0f1",
    "semantic_title": "combining noisy semantic signals with orthographic cues: cognate induction for the indic dialect continuum",
    "citation_count": 2,
    "authors": [
      "Niyati Bafna",
      "Josef van Genabith",
      "Cristina España-Bonet",
      "Zdeněk Žabokrtský"
    ]
  },
  "https://aclanthology.org/2022.conll-1.10": {
    "title": "Detecting Unintended Social Bias in Toxic Language Datasets",
    "volume": "workshop",
    "abstract": "With the rise of online hate speech, automatic detection of Hate Speech, Offensive texts as a natural language processing task is getting popular. However, very little research has been done to detect unintended social bias from these toxic language datasets. This paper introduces a new dataset ToxicBias curated from the existing dataset of Kaggle competition named \"Jigsaw Unintended Bias in Toxicity Classification\". We aim to detect social biases, their categories, and targeted groups. The dataset contains instances annotated for five different bias categories, viz., gender, race/ethnicity, religion, political, and LGBTQ. We train transformer-based models using our curated datasets and report baseline performance for bias identification, target generation, and bias implications. Model biases and their mitigation are also discussed in detail. Our study motivates a systematic extraction of social bias data from toxic language datasets",
    "checked": true,
    "id": "10ae93c9d40548f85d86a43ab9c3bf715815e7d9",
    "semantic_title": "detecting unintended social bias in toxic language datasets",
    "citation_count": 8,
    "authors": [
      "Nihar Sahoo",
      "Himanshu Gupta",
      "Pushpak Bhattacharyya"
    ]
  },
  "https://aclanthology.org/2022.conll-1.11": {
    "title": "Incremental Processing of Principle B: Mismatches Between Neural Models and Humans",
    "volume": "workshop",
    "abstract": "Despite neural language models qualitatively capturing many human linguistic behaviors, recent work has demonstrated that they underestimate the true processing costs of ungrammatical structures. We extend these more fine-grained comparisons between humans and models by investigating the interaction between Principle B and coreference processing. While humans use Principle B to block certain structural positions from affecting their incremental processing, we find that GPT-based language models are influenced by ungrammatical positions. We conclude by relating the mismatch between neural models and humans to properties of training data and suggest that certain aspects of human processing behavior do not directly follow from linguistic data",
    "checked": true,
    "id": "4b43bc712cab78ef05d40730ff2db203fdd6c153",
    "semantic_title": "incremental processing of principle b: mismatches between neural models and humans",
    "citation_count": 0,
    "authors": [
      "Forrest Davis"
    ]
  },
  "https://aclanthology.org/2022.conll-1.12": {
    "title": "Parsing as Deduction Revisited: Using an Automatic Theorem Prover to Solve an SMT Model of a Minimalist Parser",
    "volume": "workshop",
    "abstract": "We introduce a constraint-based parser for Minimalist Grammars (MG), implemented as a working computer program, that falls within the long established \"Parsing as Deduction\" framework. The parser takes as input an MG lexicon and a (partially specified) pairing of sound with meaning - i.e. a word sequence paired with a semantic representation - and, using an axiomatized logic, declaratively deduces syntactic derivations (i.e. parse trees) that comport with the specified interface conditions. The parser is built on the first axiomatization of MGs to use Satisfiability Modulo Theories (SMT), encoding in a constraint-based way the principles of minimalist syntax. The parser operates via a novel solution method: it assembles an SMT model of an MG derivation, translates the inputs into SMT formulae that constrain the model, and then solves the model using the Z3 SMT-solver, a high-performance automatic theorem prover; as the SMT-model has finite size (being bounded by the inputs), it is decidable and thus solvable in finite time. The output derivation is then recovered from the model solution. To demonstrate this, we run the parser on several representative inputs and examine how the output derivations differ when the inputs are partially vs. fully specified. We conclude by discussing the parser's extensibility and how a linguist can use it to automatically identify: (i) dependencies between input interface conditions and principles of syntax, and (ii) contradictions or redundancies between the model axioms encoding principles of syntax",
    "checked": true,
    "id": "3a722ad92327720b5163689a56eea3508ee48116",
    "semantic_title": "parsing as deduction revisited: using an automatic theorem prover to solve an smt model of a minimalist parser",
    "citation_count": 1,
    "authors": [
      "Sagar Indurkhya"
    ]
  },
  "https://aclanthology.org/2022.conll-1.13": {
    "title": "Entailment Semantics Can Be Extracted from an Ideal Language Model",
    "volume": "workshop",
    "abstract": "Language models are often trained on text alone, without additional grounding. There is debate as to how much of natural language semantics can be inferred from such a procedure. We prove that entailment judgments between sentences can be extracted from an ideal language model that has perfectly learned its target distribution, assuming the training sentences are generated by Gricean agents, i.e., agents who follow fundamental principles of communication from the linguistic theory of pragmatics. We also show entailment judgments can be decoded from the predictions of a language model trained on such Gricean data. Our results reveal a pathway for understanding the semantic information encoded in unlabeled linguistic data and a potential framework for extracting semantics from language models",
    "checked": true,
    "id": "7b0f2ee7c2a5f725308596b90b55a795280fcf69",
    "semantic_title": "entailment semantics can be extracted from an ideal language model",
    "citation_count": 9,
    "authors": [
      "William Merrill",
      "Alex Warstadt",
      "Tal Linzen"
    ]
  },
  "https://aclanthology.org/2022.conll-1.14": {
    "title": "On Neurons Invariant to Sentence Structural Changes in Neural Machine Translation",
    "volume": "workshop",
    "abstract": "We present a methodology that explores how sentence structure is reflected in neural representations of machine translation systems. We demonstrate our model-agnostic approach with the Transformer English-German translation model. We analyze neuron-level correlation of activations between paraphrases while discussing the methodology challenges and the need for confound analysis to isolate the effects of shallow cues. We find that similarity between activation patterns can be mostly accounted for by similarity in word choice and sentence length. Following that, we manipulate neuron activations to control the syntactic form of the output. We show this intervention to be somewhat successful, indicating that deep models capture sentence-structure distinctions, despite finding no such indication at the neuron level. To conduct our experiments, we develop a semi-automatic method to generate meaning-preserving minimal pair paraphrases (active-passive voice and adverbial clause-noun phrase) and compile a corpus of such pairs",
    "checked": true,
    "id": "4362580e8dba234d12a5b6ff0833f0a26ea014eb",
    "semantic_title": "on neurons invariant to sentence structural changes in neural machine translation",
    "citation_count": 2,
    "authors": [
      "Gal Patel",
      "Leshem Choshen",
      "Omri Abend"
    ]
  },
  "https://aclanthology.org/2022.conll-1.15": {
    "title": "Shared knowledge in natural conversations: can entropy metrics shed light on information transfers?",
    "volume": "workshop",
    "abstract": "The mechanisms underlying human communication have been under investigation for decades, but the answer to how understanding between locutors emerges remains incomplete. Interaction theories suggest the development of a structural alignment between the speakers, allowing for the construction of a shared knowledge base (common ground). In this paper, we propose to apply metrics derived from information theory to quantify the amount of information exchanged between participants, the dynamics of information exchanges, to provide an objective way to measure the common ground instantiation. We focus on a corpus of free conversations augmented with prosodic segmentation and an expert annotation of thematic episodes. We show that during free conversations, the amount of information remains globally constant at the scale of the conversation, but varies depending on the thematic structuring, underlining the role of the speaker introducing the theme. We propose an original methodology applied to uncontrolled material",
    "checked": true,
    "id": "fd5d3e8aad2cafe08a9d0099ead681e4a724d3a7",
    "semantic_title": "shared knowledge in natural conversations: can entropy metrics shed light on information transfers?",
    "citation_count": 0,
    "authors": [
      "Eliot Maës",
      "Philippe Blache",
      "Leonor Becerra"
    ]
  },
  "https://aclanthology.org/2022.conll-1.16": {
    "title": "Leveraging a New Spanish Corpus for Multilingual and Cross-lingual Metaphor Detection",
    "volume": "workshop",
    "abstract": "The lack of wide coverage datasets annotated with everyday metaphorical expressions for languages other than English is striking. This means that most research on supervised metaphor detection has been published only for that language. In order to address this issue, this work presents the first corpus annotated with naturally occurring metaphors in Spanish large enough to develop systems to perform metaphor detection. The presented dataset, CoMeta, includes texts from various domains, namely, news, political discourse, Wikipedia and reviews. In order to label CoMeta, we apply the MIPVU method, the guidelines most commonly used to systematically annotate metaphor on real data. We use our newly created dataset to provide competitive baselines by fine-tuning several multilingual and monolingual state-of-the-art large language models. Furthermore, by leveraging the existing VUAM English data in addition to CoMeta, we present the, to the best of our knowledge, first cross-lingual experiments on supervised metaphor detection. Finally, we perform a detailed error analysis that explores the seemingly high transfer of everyday metaphor across these two languages and datasets",
    "checked": true,
    "id": "1b056844e9bd3d05b9752172f35f877b4da7343f",
    "semantic_title": "leveraging a new spanish corpus for multilingual and cross-lingual metaphor detection",
    "citation_count": 5,
    "authors": [
      "Elisa Sanchez-Bayona",
      "Rodrigo Agerri"
    ]
  },
  "https://aclanthology.org/2022.conll-1.17": {
    "title": "Cognitive Simplification Operations Improve Text Simplification",
    "volume": "workshop",
    "abstract": "Text Simplification (TS) is the task of converting a text into a form that is easier to read while maintaining the meaning of the original text. A sub-task of TS is Cognitive Simplification (CS), converting text to a form that is readily understood by people with cognitive disabilities without rendering it childish or simplistic. This sub-task has yet to be explored with neural methods in NLP, and resources for it are scarcely available. In this paper, we present a method for incorporating knowledge from the cognitive accessibility domain into a TS model, by introducing an inductive bias regarding what simplification operations to use. We show that by adding this inductive bias to a TS-trained model, it is able to adapt better to CS without ever seeing CS data, and outperform a baseline model on a traditional TS benchmark. In addition, we provide a novel test dataset for CS, and analyze the differences between CS corpora and existing TS corpora, in terms of how simplification operations are applied",
    "checked": true,
    "id": "9f66471463ea53f5c2da8d3057c43aae20cc7d57",
    "semantic_title": "cognitive simplification operations improve text simplification",
    "citation_count": 2,
    "authors": [
      "Eytan Chamovitz",
      "Omri Abend"
    ]
  },
  "https://aclanthology.org/2022.conll-1.18": {
    "title": "On Language Spaces, Scales and Cross-Lingual Transfer of UD Parsers",
    "volume": "workshop",
    "abstract": "Cross-lingual transfer of parsing models has been shown to work well for several closely-related languages, but predicting the success in other cases remains hard. Our study is a comprehensive analysis of the impact of linguistic distance on the transfer of UD parsers. As an alternative to syntactic typological distances extracted from URIEL, we propose three text-based feature spaces and show that they can be more precise predictors, especially on a more local scale, when only shorter distances are taken into account. Our analyses also reveal that the good coverage in typological databases is not among the factors that explain good transfer",
    "checked": true,
    "id": "8929066ce924696f960512c92a720c70bba65586",
    "semantic_title": "on language spaces, scales and cross-lingual transfer of ud parsers",
    "citation_count": 2,
    "authors": [
      "Tanja Samardžić",
      "Ximena Gutierrez-Vasques",
      "Rob van der Goot",
      "Max Müller-Eberstein",
      "Olga Pelloni",
      "Barbara Plank"
    ]
  },
  "https://aclanthology.org/2022.conll-1.19": {
    "title": "Visual Semantic Parsing: From Images to Abstract Meaning Representation",
    "volume": "workshop",
    "abstract": "The success of scene graphs for visual scene understanding has brought attention to the benefits of abstracting a visual input (e.g., image) into a structured representation, where entities (people and objects) are nodes connected by edges specifying their relations. Building these representations, however, requires expensive manual annotation in the form of images paired with their scene graphs or frames. These formalisms remain limited in the nature of entities and relations they can capture. In this paper, we propose to leverage a widely-used meaning representation in the field of natural language processing, the Abstract Meaning Representation (AMR), to address these shortcomings. Compared to scene graphs, which largely emphasize spatial relationships, our visual AMR graphs are more linguistically informed, with a focus on higher-level semantic concepts extrapolated from visual input. Moreover, they allow us to generate meta-AMR graphs to unify information contained in multiple image descriptions under one representation. Through extensive experimentation and analysis, we demonstrate that we can re-purpose an existing text-to-AMR parser to parse images into AMRs. Our findings point to important future research directions for improved scene understanding",
    "checked": true,
    "id": "9b65fdde3f47a6cb5da72f474b7eb4e5eb61635f",
    "semantic_title": "visual semantic parsing: from images to abstract meaning representation",
    "citation_count": 0,
    "authors": [
      "Mohamed Ashraf Abdelsalam",
      "Zhan Shi",
      "Federico Fancellu",
      "Kalliopi Basioti",
      "Dhaivat Bhatt",
      "Vladimir Pavlovic",
      "Afsaneh Fazly"
    ]
  },
  "https://aclanthology.org/2022.conll-1.20": {
    "title": "Syntactic Surprisal From Neural Models Predicts, But Underestimates, Human Processing Difficulty From Syntactic Ambiguities",
    "volume": "workshop",
    "abstract": "Humans exhibit garden path effects: When reading sentences that are temporarily structurally ambiguous, they slow down when the structure is disambiguated in favor of the less preferred alternative. Surprisal theory (Hale, 2001; Levy, 2008), a prominent explanation of this finding, proposes that these slowdowns are due to the unpredictability of each of the words that occur in these sentences. Challenging this hypothesis, van Schijndel and Linzen (2021) find that estimates of the cost of word predictability derived from language models severely underestimate the magnitude of human garden path effects. In this work, we consider whether this underestimation is due to the fact that humans weight syntactic factors in their predictions more highly than language models do. We propose a method for estimating syntactic predictability from a language model, allowing us to weigh the cost of lexical and syntactic predictability independently. We find that treating syntactic predictability independently from lexical predictability indeed results in larger estimates of garden path. At the same time, even when syntactic predictability is independently weighted, surprisal still greatly underestimate the magnitude of human garden path effects. Our results support the hypothesis that predictability is not the only factor responsible for the processing cost associated with garden path sentences",
    "checked": true,
    "id": "ca9d0f0fcd88b80c6f04c3d64ae69b6b1b7d8611",
    "semantic_title": "syntactic surprisal from neural models predicts, but underestimates, human processing difficulty from syntactic ambiguities",
    "citation_count": 22,
    "authors": [
      "Suhas Arehalli",
      "Brian Dillon",
      "Tal Linzen"
    ]
  },
  "https://aclanthology.org/2022.conll-1.21": {
    "title": "OpenStance: Real-world Zero-shot Stance Detection",
    "volume": "workshop",
    "abstract": "Prior studies of zero-shot stance detection identify the attitude of texts towards unseen topics occurring in the same document corpus. Such task formulation has three limitations: (i) Single domain/dataset. A system is optimized on a particular dataset from a single domain; therefore, the resulting system cannot work well on other datasets; (ii) the model is evaluated on a limited number of unseen topics; (iii) it is assumed that part of the topics has rich annotations, which might be impossible in real-world applications. These drawbacks will lead to an impractical stance detection system that fails to generalize to open domains and open-form topics. This work defines OpenStance: open-domain zero-shot stance detection, aiming to handle stance detection in an open world with neither domain constraints nor topic-specific annotations. The key challenge of OpenStance lies in open-domain generalization: learning a system with fully unspecific supervision but capable of generalizing to any dataset. To solve OpenStance, we propose to combine indirect supervision, from textual entailment datasets, and weak supervision, from data generated automatically by pre-trained Language Models. Our single system, without any topic-specific supervision, outperforms the supervised method on three popular datasets. To our knowledge, this is the first work that studies stance detection under the open-domain zero-shot setting. All data and code will be publicly released",
    "checked": true,
    "id": "a498b3603a20e6dbcaa1dcc44639dedfcdda7c9b",
    "semantic_title": "openstance: real-world zero-shot stance detection",
    "citation_count": 6,
    "authors": [
      "Hanzi Xu",
      "Slobodan Vucetic",
      "Wenpeng Yin"
    ]
  },
  "https://aclanthology.org/2022.conll-1.22": {
    "title": "Optimizing text representations to capture (dis)similarity between political parties",
    "volume": "workshop",
    "abstract": "Even though fine-tuned neural language models have been pivotal in enabling \"deep\" automatic text analysis, optimizing text representations for specific applications remains a crucial bottleneck. In this study, we look at this problem in the context of a task from computational social science, namely modeling pairwise similarities between political parties. Our research question is what level of structural information is necessary to create robust text representation, contrasting a strongly informed approach (which uses both claim span and claim category annotations) with approaches that forgo one or both types of annotation with document structure-based heuristics. Evaluating our models on the manifestos of German parties for the 2021 federal election. We find that heuristics that maximize within-party over between-party similarity along with a normalization step lead to reliable party similarity prediction, without the need for manual annotation",
    "checked": true,
    "id": "2a25ef1e1aeac46f9cc15d326214fd53460e7bb2",
    "semantic_title": "optimizing text representations to capture (dis)similarity between political parties",
    "citation_count": 3,
    "authors": [
      "Tanise Ceron",
      "Nico Blokker",
      "Sebastian Padó"
    ]
  },
  "https://aclanthology.org/2022.conll-1.23": {
    "title": "Computational cognitive modeling of predictive sentence processing in a second language",
    "volume": "workshop",
    "abstract": "We propose an ACT-R cue-based retrieval model of the real-time gender predictions displayed by second language (L2) learners. The model extends a previous model of native (L1) speakers according to two central accounts in L2 sentence processing: (i) the Interference Hypothesis, which proposes that retrieval interference is higher in L2 than L1 speakers; (ii) the Lexical Bottleneck Hypothesis, which proposes that problems with gender agreement are due to weak gender representations. We tested the predictions of these accounts using data from two visual world experiments, which found that the gender predictions elicited by German possessive pronouns were delayed and smaller in size in L2 than L1 speakers. The experiments also found a \"match effect\", such that when the antecedent and possessee of the pronoun had the same gender, predictions were earlier than when the two genders differed. This match effect was smaller in L2 than L1 speakers. The model implementing the Lexical Bottleneck Hypothesis captured the effects of smaller predictions, smaller match effect and delayed predictions in one of the two conditions. By contrast, the model implementing the Interference Hypothesis captured the smaller prediction effect but it showed an earlier prediction effect and an increased match effect in L2 than L1 speakers. These results provide evidence for the Lexical Bottleneck Hypothesis, and they demonstrate a method for extending computational models of L1 to L2 processing",
    "checked": true,
    "id": "ec5fd6fa32dc834e74db7175dcf29ecf899c9c03",
    "semantic_title": "computational cognitive modeling of predictive sentence processing in a second language",
    "citation_count": 0,
    "authors": [
      "Umesh Patil",
      "Sol Lago"
    ]
  },
  "https://aclanthology.org/2022.conll-1.24": {
    "title": "PIE-QG: Paraphrased Information Extraction for Unsupervised Question Generation from Small Corpora",
    "volume": "workshop",
    "abstract": "Supervised Question Answering systems (QA systems) rely on domain-specific human-labeled data for training. Unsupervised QA systems generate their own question-answer training pairs, typically using secondary knowledge sources to achieve this outcome. Our approach (called PIE-QG) uses Open Information Extraction (OpenIE) to generate synthetic training questions from paraphrased passages and uses the question-answer pairs as training data for a language model for a state-of-the-art QA system based on BERT. Triples in the form of <subject, predicate, object> are extracted from each passage, and questions are formed with subjects (or objects) and predicates while objects (or subjects) are considered as answers. Experimenting on five extractive QA datasets demonstrates that our technique achieves on-par performance with existing state-of-the-art QA systems with the benefit of being trained on an order of magnitude fewer documents and without any recourse to external reference data sources",
    "checked": true,
    "id": "512919550f259878fc156d15cd1b7621bfe6eca7",
    "semantic_title": "pie-qg: paraphrased information extraction for unsupervised question generation from small corpora",
    "citation_count": 3,
    "authors": [
      "Dinesh Nagumothu",
      "Bahadorreza Ofoghi",
      "Guangyan Huang",
      "Peter Eklund"
    ]
  },
  "https://aclanthology.org/2022.conll-1.25": {
    "title": "Probing for targeted syntactic knowledge through grammatical error detection",
    "volume": "workshop",
    "abstract": "Targeted studies testing knowledge of subject-verb agreement (SVA) indicate that pre-trained language models encode syntactic information. We assert that if models robustly encode subject-verb agreement, they should be able to identify when agreement is correct and when it is incorrect. To that end, we propose grammatical error detection as a diagnostic probe to evaluate token-level contextual representations for their knowledge of SVA. We evaluate contextual representations at each layer from five pre-trained English language models: BERT, XLNet, GPT-2, RoBERTa and ELECTRA. We leverage public annotated training data from both English second language learners and Wikipedia edits, and report results on manually crafted stimuli for subject-verb agreement. We find that masked language models linearly encode information relevant to the detection of SVA errors, while the autoregressive models perform on par with our baseline. However, we also observe a divergence in performance when probes are trained on different training sets, and when they are evaluated on different syntactic constructions, suggesting the information pertaining to SVA error detection is not robustly encoded",
    "checked": true,
    "id": "b327db5fa9960dff3eba8de33530e93c6599a976",
    "semantic_title": "probing for targeted syntactic knowledge through grammatical error detection",
    "citation_count": 2,
    "authors": [
      "Christopher Davis",
      "Christopher Bryant",
      "Andrew Caines",
      "Marek Rei",
      "Paula Buttery"
    ]
  },
  "https://aclanthology.org/2022.conll-1.26": {
    "title": "An Alignment-based Approach to Text Segmentation Similarity Scoring",
    "volume": "workshop",
    "abstract": "Text segmentation is a natural language processing task with popular applications, such as topic segmentation, element discourse extraction, and sentence tokenization. Much work has been done to develop accurate segmentation similarity metrics, but even the most advanced metrics used today, B, and WindowDiff, exhibit incorrect behavior due to their evaluation of boundaries in isolation. In this paper, we present a new segment-alignment based approach to segmentation similarity scoring and a new similarity metric A. We show that A does not exhibit the erratic behavior of $ and WindowDiff, quantify the likelihood of B and WindowDiff misbehaving through simulation, and discuss the versatility of alignment-based approaches for segmentation similarity scoring. We make our implementation of A publicly available and encourage the community to explore more sophisticated approaches to text segmentation similarity scoring",
    "checked": true,
    "id": "fb2aea16f51f1978e84cda634de0a268156fbdd2",
    "semantic_title": "an alignment-based approach to text segmentation similarity scoring",
    "citation_count": 1,
    "authors": [
      "Gerardo Ocampo Diaz",
      "Jessica Ouyang"
    ]
  },
  "https://aclanthology.org/2022.conll-1.27": {
    "title": "Enhancing the Transformer Decoder with Transition-based Syntax",
    "volume": "workshop",
    "abstract": "Notwithstanding recent advances, syntactic generalization remains a challenge for text decoders. While some studies showed gains from incorporating source-side symbolic syntactic and semantic structure into text generation Transformers, very little work addressed the decoding of such structure. We propose a general approach for tree decoding using a transition-based approach. Examining the challenging test case of incorporating Universal Dependencies syntax into machine translation, we present substantial improvements on test sets that focus on syntactic generalization, while presenting improved or comparable performance on standard MT benchmarks. Further qualitative analysis addresses cases where syntactic generalization in the vanilla Transformer decoder is inadequate and demonstrates the advantages afforded by integrating syntactic information",
    "checked": true,
    "id": "bdf10808cc436c44e6d5ae2c3e8b8ffcfbe58d17",
    "semantic_title": "enhancing the transformer decoder with transition-based syntax",
    "citation_count": 1,
    "authors": [
      "Leshem Choshen",
      "Omri Abend"
    ]
  },
  "https://aclanthology.org/2022.conll-1.28": {
    "title": "Characterizing Verbatim Short-Term Memory in Neural Language Models",
    "volume": "workshop",
    "abstract": "When a language model is trained to predict natural language sequences, its prediction at each moment depends on a representation of prior context. What kind of information about the prior context can language models retrieve? We tested whether language models could retrieve the exact words that occurred previously in a text. In our paradigm, language models (transformers and an LSTM) processed English text in which a list of nouns occurred twice. We operationalized retrieval as the reduction in surprisal from the first to the second list. We found that the transformers retrieved both the identity and ordering of nouns from the first list. Further, the transformers' retrieval was markedly enhanced when they were trained on a larger corpus and with greater model depth. Lastly, their ability to index prior tokens was dependent on learned attention patterns. In contrast, the LSTM exhibited less precise retrieval, which was limited to list-initial tokens and to short intervening texts. The LSTM's retrieval was not sensitive to the order of nouns and it improved when the list was semantically coherent. We conclude that transformers implemented something akin to a working memory system that could flexibly retrieve individual token representations across arbitrary delays; conversely, the LSTM maintained a coarser and more rapidly-decaying semantic gist of prior tokens, weighted toward the earliest items",
    "checked": true,
    "id": "4583738cfaf1fd90f33de6cfb0f4bb2693f54fa6",
    "semantic_title": "characterizing verbatim short-term memory in neural language models",
    "citation_count": 3,
    "authors": [
      "Kristijan Armeni",
      "Christopher Honey",
      "Tal Linzen"
    ]
  },
  "https://aclanthology.org/2022.evonlp-1.1": {
    "title": "MLLabs-LIG at TempoWiC 2022: A Generative Approach for Examining Temporal Meaning Shift",
    "volume": "workshop",
    "abstract": "In this paper, we present our system for the EvoNLP 2022 shared task Temporal Meaning Shift (TempoWiC). Different from the typically used discriminative model, we propose a generative approach based on pre-trained generation models. The basic architecture of our system is a seq2seq model where the input sequence consists of two documents followed by a question asking whether the meaning of target word changed or not, the target output sequence is a declarative sentence describing the meaning of target word changed or not. The experimental results on TempoWiC test set show that our best system (with time information) obtained an accuracy and Marco F-1 score of 68.09% and 62.59% respectively, which ranked 12th among all submitted systems. The results have shown the plausibility of using generation model for WiC tasks, meanwhile also indicate there's still room for further improvement",
    "checked": true,
    "id": "3da169761815248e56f6956fe297477ef24d5086",
    "semantic_title": "mllabs-lig at tempowic 2022: a generative approach for examining temporal meaning shift",
    "citation_count": 4,
    "authors": [
      "Chenyang Lyu",
      "Yongxin Zhou",
      "Tianbo Ji"
    ]
  },
  "https://aclanthology.org/2022.evonlp-1.2": {
    "title": "Using Deep Mixture-of-Experts to Detect Word Meaning Shift for TempoWiC",
    "volume": "workshop",
    "abstract": "This paper mainly describes the dma submission to the TempoWiC task, which achieves a macro-F1 score of 77.05% and attains the first place in this task. We first explore the impact of different pre-trained language models. Then we adopt data cleaning, data augmentation, and adversarial training strategies to enhance the model generalization and robustness. For further improvement, we integrate POS information and word semantic representation using a Mixture-of-Experts (MoE) approach. The experimental results show that MoE can overcome the feature overuse issue and combine the context, POS, and word semantic features well. Additionally, we use a model ensemble method for the final prediction, which has been proven effective by many research works",
    "checked": true,
    "id": "bbd1c0d3b11947447a6e1f1e869e98344de86409",
    "semantic_title": "using deep mixture-of-experts to detect word meaning shift for tempowic",
    "citation_count": 2,
    "authors": [
      "Ze Chen",
      "Kangxu Wang",
      "Zijian Cai",
      "Jiewen Zheng",
      "Jiarong He",
      "Max Gao",
      "Jason Zhang"
    ]
  },
  "https://aclanthology.org/2022.evonlp-1.3": {
    "title": "Using Two Losses and Two Datasets Simultaneously to Improve TempoWiC Accuracy",
    "volume": "workshop",
    "abstract": "WSD (Word Sense Disambiguation) is the task of identifying which sense of a word is meant in a sentence or other segment of text. Researchers have worked on this task (e.g. Pustejovsky, 2002) for years but it's still a challenging one even for SOTA (state-of-the-art) LMs (language models). The new dataset, TempoWiC introduced by Loureiro et al. (2022b) focuses on the fact that words change over time. Their best baseline achieves 70.33% macro-F1. In this work, we use two different losses simultaneously. We also improve our model by using another similar dataset to generalize better. Our best configuration beats their best baseline by 4.23%",
    "checked": true,
    "id": "07dd5d7b208ffeb697cd3506ef3ef5799469c198",
    "semantic_title": "using two losses and two datasets simultaneously to improve tempowic accuracy",
    "citation_count": 0,
    "authors": [
      "Mohammad Javad Pirhadi",
      "Motahhare Mirzaei",
      "Sauleh Eetemadi"
    ]
  },
  "https://aclanthology.org/2022.evonlp-1.4": {
    "title": "Class Incremental Learning for Intent Classification with Limited or No Old Data",
    "volume": "workshop",
    "abstract": "In this paper, we explore class-incremental learning for intent classification (IC) in a setting with limited old data available. IC is the task of mapping user utterances to their corresponding intents. Even though class-incremental learning without storing the old data yields high potential of reducing human and computational resources in industry NLP model releases, to the best of our knowledge, it hasn't been studied for NLP classification tasks in the literature before. In this work, we compare several contemporary class-incremental learning methods, i.e., BERT warm start, L2, Elastic Weight Consolidation, RecAdam and Knowledge Distillation within two realistic class-incremental learning scenarios: one where only the previous model is assumed to be available, but no data corresponding to old classes, and one in which limited unlabeled data for old classes is assumed to be available. Our results indicate that among the investigated continual learning methods, Knowledge Distillation worked best for our class-incremental learning tasks, and adding limited unlabeled data helps the model in both adaptability and stability",
    "checked": true,
    "id": "d9e7f6cf2864f1e0558480839d30896873525b4b",
    "semantic_title": "class incremental learning for intent classification with limited or no old data",
    "citation_count": 1,
    "authors": [
      "Debjit Paul",
      "Daniil Sorokin",
      "Judith Gaspers"
    ]
  },
  "https://aclanthology.org/2022.evonlp-1.5": {
    "title": "CC-Top: Constrained Clustering for Dynamic Topic Discovery",
    "volume": "workshop",
    "abstract": "Research on multi-class text classification of short texts mainly focuses on supervised (transfer) learning approaches, requiring a finite set of pre-defined classes which is constant over time. This work explores deep constrained clustering (CC) as an alternative to supervised learning approaches in a setting with a dynamically changing number of classes, a task we introduce as dynamic topic discovery (DTD).We do so by using pairwise similarity constraints instead of instance-level class labels which allow for a flexible number of classes while exhibiting a competitive performance compared to supervised approaches. First, we substantiate this through a series of experiments and show that CC algorithms exhibit a predictive performance similar to state-of-the-art supervised learning algorithms while requiring less annotation effort. Second, we demonstrate the overclustering capabilities of deep CC for detecting topics in short text data sets in the absence of the ground truth class cardinality during model training. Third, we showcase that these capabilities can be leveraged for the DTD setting as a step towards dynamic learning over time and finally, we release our codebase to nurture further research in this area",
    "checked": true,
    "id": "289f569c80757ddfa650710d637cfd8a5cfde107",
    "semantic_title": "cc-top: constrained clustering for dynamic topic discovery",
    "citation_count": 1,
    "authors": [
      "Jann Goschenhofer",
      "Pranav Ragupathy",
      "Christian Heumann",
      "Bernd Bischl",
      "Matthias Aßenmacher"
    ]
  },
  "https://aclanthology.org/2022.evonlp-1.6": {
    "title": "HSE at TempoWiC: Detecting Meaning Shift in Social Media with Diachronic Language Models",
    "volume": "workshop",
    "abstract": "This paper describes our methods for temporal meaning shift detection, implemented during the TempoWiC shared task. We present two systems: with and without time span data usage. Our approaches are based on the language models fine-tuned for Twitter domain. Both systems outperformed all the competition's baselines except TimeLMs-SIM. Our best submission achieved the macro-F1 score of 70.09% and took the 7th place. This result was achieved by using diachronic language models from the TimeLMs project",
    "checked": true,
    "id": "186d28349b232f279d822e3564e88ad226f95daa",
    "semantic_title": "hse at tempowic: detecting meaning shift in social media with diachronic language models",
    "citation_count": 0,
    "authors": [
      "Elizaveta Tukhtina",
      "Kseniia Kashleva",
      "Svetlana Vydrina"
    ]
  },
  "https://aclanthology.org/2022.evonlp-1.7": {
    "title": "Leveraging time-dependent lexical features for offensive language detection",
    "volume": "workshop",
    "abstract": "We present a study on the integration of time-sensitive information in lexicon-based offensive language detection systems. Our focus is on Offenseval sub-task A, aimed at detecting offensive tweets. We apply a semantic change detection algorithm over a short time span of two years to detect words whose semantics has changed and we focus particularly on those words that acquired or lost an offensive meaning between 2019 and 2020. Using the output of this semantic change detection approach, we train an SVM classifier on the Offenseval 2019 training set. We build on the already competitive SINAI system submitted to Offenseval 2019 by adding new lexical features, including those that capture the change in usage of words and their association with emerging offensive usages. We discuss the challenges, opportunities and limitations of integrating semantic change detection in offensive language detection models. Our work draws attention to an often neglected aspect of offensive language, namely that the meanings of words are constantly evolving and that NLP systems that account for this change can achieve good performance even when not trained on the most recent training data",
    "checked": true,
    "id": "bc7688e229b15e4ce585cf5f71cc00bc38618284",
    "semantic_title": "leveraging time-dependent lexical features for offensive language detection",
    "citation_count": 5,
    "authors": [
      "Barbara McGillivray",
      "Malithi Alahapperuma",
      "Jonathan Cook",
      "Chiara Di Bonaventura",
      "Albert Meroño-Peñuela",
      "Gareth Tyson",
      "Steven Wilson"
    ]
  },
  "https://aclanthology.org/2022.evonlp-1.8": {
    "title": "Temporal Word Meaning Disambiguation using TimeLMs",
    "volume": "workshop",
    "abstract": "Meaning of words constantly change given the events in modern civilization. Large Language Models use word embeddings, which are often static and thus cannot cope with this semantic change. Thus, it is important to resolve ambiguity in word meanings. This paper is an effort in this direction, where we explore methods for word sense disambiguation for the EvoNLP shared task. We conduct rigorous ablations for two solutions to this problem. We see that an approach using time-aware language models helps this task. Furthermore, we explore possible future directions to this problem",
    "checked": true,
    "id": "0fd97ed923a570367fc88668f820b1bf1941432d",
    "semantic_title": "temporal word meaning disambiguation using timelms",
    "citation_count": 1,
    "authors": [
      "Mihir Godbole",
      "Parth Dandavate",
      "Aditya Kane"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.1": {
    "title": "Contextualizing Emerging Trends in Financial News Articles",
    "volume": "workshop",
    "abstract": "Identifying and exploring emerging trends in news is becoming more essential than ever with many changes occurring around the world due to the global health crises. However, most of the recent research has focused mainly on detecting trends in social media, thus, benefiting from social features (e.g. likes and retweets on Twitter) which helped the task as they can be used to measure the engagement and diffusion rate of content. Yet, formal text data, unlike short social media posts, comes with a longer, less restricted writing format, and thus, more challenging. In this paper, we focus our study on emerging trends detection in financial news articles about Microsoft, collected before and during the start of the COVID-19 pandemic (July 2019 to July 2020). We make the dataset freely available and we also propose a strong baseline (Contextual Leap2Trend) for exploring the dynamics of similarities between pairs of keywords based on topic modeling and term frequency. Finally, we evaluate against a gold standard (Google Trends) and present noteworthy real-world scenarios regarding the influence of the pandemic on Microsoft",
    "checked": true,
    "id": "eb8b81484a1851e28463e7bf1fc3ed4f54d6c701",
    "semantic_title": "contextualizing emerging trends in financial news articles",
    "citation_count": 0,
    "authors": [
      "Nhu Khoa Nguyen",
      "Thierry Delahaut",
      "Emanuela Boros",
      "Antoine Doucet",
      "Gaël Lejeune"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.2": {
    "title": "AstBERT: Enabling Language Model for Financial Code Understanding with Abstract Syntax Trees",
    "volume": "workshop",
    "abstract": "Using the pre-trained language models to understand source codes has attracted increasing attention from financial institutions owing to the great potential to uncover financial risks. However, there are several challenges in applying these language models to solve programming language related problems directly. For instance, the shift of domain knowledge between natural language (NL) and programming language (PL) requires understanding the semantic and syntactic information from the data from different perspectives. To this end, we propose the AstBERT model, a pre-trained PL model aiming to better understand the financial codes using the abstract syntax tree (AST). Specifically, we collect a sheer number of source codes (both Java and Python) from the Alipay code repository and incorporate both syntactic and semantic code knowledge into our model through the help of code parsers, in which AST information of the source codes can be interpreted and integrated. We evaluate the performance of the proposed model on three tasks, including code question answering, code clone detection and code refinement. Experiment results show that our AstBERT achieves promising performance on three different downstream tasks",
    "checked": true,
    "id": "2e375d8f4c4dbbf2fdf209f54eda70c9546e4096",
    "semantic_title": "astbert: enabling language model for financial code understanding with abstract syntax trees",
    "citation_count": 1,
    "authors": [
      "Rong Liang",
      "Tiehua Zhang",
      "Yujie Lu",
      "Yuze Liu",
      "Zhen Huang",
      "Xin Chen"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.3": {
    "title": "Disentangled Variational Topic Inference for Topic-Accurate Financial Report Generation",
    "volume": "workshop",
    "abstract": "Automatic generating financial report from a set of news is important but challenging. The financial reports is composed of key points of the news and corresponding inferring and reasoning from specialists in financial domain with professional knowledge. The challenges lie in the effective learning of the extra knowledge that is not well presented in the news, and the misalignment between topic of input news and output knowledge in target reports. In this work, we introduce a disentangled variational topic inference approach to learn two latent variables for news and report, respectively. We use a publicly available dataset to evaluate the proposed approach. The results demonstrate its effectiveness of enhancing the language informativeness and the topic accuracy of the generated financial reports",
    "checked": true,
    "id": "8867cf07cf854a15c8bb6a978463f207995d97ce",
    "semantic_title": "disentangled variational topic inference for topic-accurate financial report generation",
    "citation_count": 0,
    "authors": [
      "Sixing Yan"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.4": {
    "title": "Toward Privacy-preserving Text Embedding Similarity with Homomorphic Encryption",
    "volume": "workshop",
    "abstract": "Text embedding is an essential component to build efficient natural language applications based on text similarities such as search engines and chatbots. Certain industries like finance and healthcare demand strict privacy-preserving conditions that user's data should not be exposed to any potential malicious users even including service providers. From a privacy standpoint, text embeddings seem impossible to be interpreted but there is still a privacy risk that they can be recovered to original texts through inversion attacks. To satisfy such privacy requirements, in this paper, we study a Homomorphic Encryption (HE) based text similarity inference. To validate our method, we perform extensive experiments on two vital text similarity tasks. Through text embedding inversion tests, we prove that the benchmark datasets are vulnerable to inversion attacks and another privacy preserving approach, dχ-privacy, a relaxed version of Local Differential Privacy method fails to prevent them. We show that our approach preserves the performance of models compared to that the baseline has degradation up to 10% of scores for the minimum security",
    "checked": true,
    "id": "ea1829559fecc5452bc4c6cdd69eaf33104ca806",
    "semantic_title": "toward privacy-preserving text embedding similarity with homomorphic encryption",
    "citation_count": 4,
    "authors": [
      "Donggyu Kim",
      "Garam Lee",
      "Sungwoo Oh"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.5": {
    "title": "TweetFinSent: A Dataset of Stock Sentiments on Twitter",
    "volume": "workshop",
    "abstract": "Stock sentiment has strong correlations with the stock market but traditional sentiment analysis task classifies sentiment according to having feelings and emotions of good or bad. This definition of sentiment is not an accurate indicator of public opinion about specific stocks. To bridge this gap, we introduce a new task of stock sentiment analysis and present a new dataset for this task named TweetFinSent. In TweetFinSent, tweets are annotated based on if one gained or expected to gain positive or negative return from a stock. Experiments on TweetFinSent with several sentiment analysis models from lexicon-based to transformer-based have been conducted. Experimental results show that TweetFinSent dataset constitutes a challenging problem and there is ample room for improvement on the stock sentiment analysis task. TweetFinSent is available at https://github.com/jpmcair/tweetfinsent",
    "checked": true,
    "id": "f3189aa8eccb36efc00efcdcb647120d3d197f68",
    "semantic_title": "tweetfinsent: a dataset of stock sentiments on twitter",
    "citation_count": 3,
    "authors": [
      "Yulong Pei",
      "Amarachi Mbakwe",
      "Akshat Gupta",
      "Salwa Alamir",
      "Hanxuan Lin",
      "Xiaomo Liu",
      "Sameena Shah"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.6": {
    "title": "Stock Price Volatility Prediction: A Case Study with AutoML",
    "volume": "workshop",
    "abstract": "Accurate prediction of the stock price volatility, the rate at which the price of a stock increases or decreases over a particular period, is an important problem in finance. Inaccurate prediction of stock price volatility might lead to investment risk and financial loss, while accurate prediction might generate significant returns for investors. Several studies investigated stock price volatility prediction in a regression task by using the transcripts of earning calls (quarterly conference calls held by public companies) with Natural Language Processing (NLP) techniques. Existing studies use the entire transcript and this degrades the performance due to noise caused by irrelevant information that might not have a significant impact on stock price volatility. In order to overcome these limitations, by considering stock price volatility prediction as a classification task, we explore several denoising approaches, ranging from general-purpose approaches to techniques specific to finance to remove the noise, and leverage AutoML systems that enable auto-exploration of a wide variety of models. Our preliminary findings indicate that domain-specific denoising approaches provide better results than general-purpose approaches, moreover AutoML systems provide promising results",
    "checked": true,
    "id": "5879273fa8d1dd0bd61d43e0267d28961b660e8e",
    "semantic_title": "stock price volatility prediction: a case study with automl",
    "citation_count": 3,
    "authors": [
      "Hilal Pataci",
      "Yunyao Li",
      "Yannis Katsis",
      "Yada Zhu",
      "Lucian Popa"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.7": {
    "title": "DigiCall: A Benchmark for Measuring the Maturity of Digital Strategy through Company Earning Calls",
    "volume": "workshop",
    "abstract": "Digital transformation reinvents companies, their vision and strategy, organizational structure, processes, capabilities, and culture, and enables the development of new or enhanced products and services delivered to customers more efficiently. Organizations, by formalizing their digital strategy attempt to plan for their digital transformations and accelerate their company growth. Understanding how successful a company is in its digital transformation starts with accurate measurement of its digital maturity levels. However, existing approaches to measuring organizations' digital strategy have low accuracy levels and this leads to inconsistent results, and also does not provide resources (data) for future research to improve. In order to measure the digital strategy maturity of companies, we leverage the state-of-the-art NLP models on unstructured data (earning call transcripts), and reach the state-of-the-art levels (94%) for this task. We release 3.691 earning call transcripts and also annotated data set, labeled particularly for the digital strategy maturity by linguists. Our work provides an empirical baseline for research in industry and management science",
    "checked": true,
    "id": "3a2e98ca83edf157e6e4b4672d15a979081440f8",
    "semantic_title": "digicall: a benchmark for measuring the maturity of digital strategy through company earning calls",
    "citation_count": 0,
    "authors": [
      "Hilal Pataci",
      "Kexuan Sun",
      "T. Ravichandran"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.8": {
    "title": "Learning Better Intent Representations for Financial Open Intent Classification",
    "volume": "workshop",
    "abstract": "With the recent surge of NLP technologies in the financial domain, banks and other financial entities have adopted virtual agents (VA) to assist customers. A challenging problem for VAs in this domain is determining a user's reason or intent for contacting the VA, especially when the intent was unseen or open during the VA's training. One method for handling open intents is adaptive decision boundary (ADB) post-processing, which learns tight decision boundaries from intent representations to separate known and open intents. We propose incorporating two methods for supervised pre-training of intent representations: prefix tuning and fine-tuning just the last layer of a large language model (LLM). With this proposal, our accuracy is 1.63% - 2.07% higher than the prior state-of-the-art ADB method for open intent classification on the banking77 benchmark amongst others. Notably, we only supplement the original ADB model with 0.1% additional trainable parameters. Ablation studies also determine that our method yields better results than full fine-tuning the entire model. We hypothesize that our findings could stimulate a new optimal method of downstream tuning that combines parameter efficient tuning modules with fine-tuning a subset of the base model's layers",
    "checked": true,
    "id": "12c20b14f0652c2953dee2e4fc7da59e46744ff4",
    "semantic_title": "learning better intent representations for financial open intent classification",
    "citation_count": 4,
    "authors": [
      "Xianzhi Li",
      "Will Aitken",
      "Xiaodan Zhu",
      "Stephen W. Thomas"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.9": {
    "title": "Exploring Robustness of Prefix Tuning in Noisy Data: A Case Study in Financial Sentiment Analysis",
    "volume": "workshop",
    "abstract": "The invention of transformer-based models such as BERT, GPT, and RoBERTa has enabled researchers and financial companies to finetune these powerful models and use them in different downstream tasks to achieve state-of-the-art performance. Recently, a lightweight alternative (approximately 0.1% - 3% of the original model parameters) to fine-tuning, known as prefix tuning has been introduced. This method freezes the model parameters and only updates the prefix to achieve performance comparable to full fine-tuning. Prefix tuning enables researchers and financial practitioners to achieve similar results with much fewer parameters. In this paper, we explore the robustness of prefix tuning when facing noisy data. Our experiments demonstrate that fine-tuning is more robust to noise than prefix tuning—the latter method faces a significant decrease in performance on most corrupted data sets with increasing noise levels. Furthermore, prefix tuning has high variances on the F1 scores compared to fine-tuning in many corruption methods. We strongly advocate that caution should be carefully taken when applying the state-of-the-art prefix tuning method to noisy data",
    "checked": true,
    "id": "59c9e9221a9d09cc125b47d17cf792bb28287488",
    "semantic_title": "exploring robustness of prefix tuning in noisy data: a case study in financial sentiment analysis",
    "citation_count": 0,
    "authors": [
      "Sudhandar Balakrishnan",
      "Yihao Fang",
      "Xiaodan Zhu"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.10": {
    "title": "A Taxonomical NLP Blueprint to Support Financial Decision Making through Information-Centred Interactions",
    "volume": "workshop",
    "abstract": "Investment management professionals (IMPs) often make decisions after manual analysis of text transcripts of central banks' conferences or companies' earning calls. Their current software tools, while interactive, largely leave users unassisted in using these transcripts. A key component to designing speech and NLP techniques for this community is to qualitatively characterize their perceptions of AI as well as their legitimate needs so as to (1) better apply existing NLP methods, (2) direct future research and (3) correct IMPs' perceptions of what AI is capable of. This paper presents such a study, through a contextual inquiry with eleven IMPs, uncovering their information practices when using such transcripts. We then propose a taxonomy of user requirements and usability criteria to support IMP decision making, and validate the taxonomy through participatory design workshops with four IMPs. Our investigation suggests that: (1) IMPs view visualization methods and natural language processing algorithms primarily as time-saving tools that are incapable of enhancing either discovery or interpretation and (2) their existing software falls well short of the state of the art in both visualization and NLP",
    "checked": true,
    "id": "3cebcc3b8ce4111c18bf0d1c98cbc8abf0e6aa25",
    "semantic_title": "a taxonomical nlp blueprint to support financial decision making through information-centred interactions",
    "citation_count": 0,
    "authors": [
      "Siavash Kazemian",
      "Cosmin Munteanu",
      "Gerald Penn"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.11": {
    "title": "Overview of the FinNLP-2022 ERAI Task: Evaluating the Rationales of Amateur Investors",
    "volume": "workshop",
    "abstract": "This paper provides an overview of the shared task, Evaluating the Rationales of Amateur Investors (ERAI), in FinNLP-2022 at EMNLP-2022. This shared task aims to sort out investment opinions that would lead to higher profit from social platforms. We obtained 19 registered teams; 9 teams submitted their results for final evaluation, and 8 teams submitted papers to share their methods. The discussed directions are various: prompting, fine-tuning, translation system comparison, and tailor-made neural network architectures. We provide details of the task settings, data statistics, participants' results, and fine-grained analysis",
    "checked": true,
    "id": "3663bf8461995a593e0bb3c76c77883087c1f6e2",
    "semantic_title": "overview of the finnlp-2022 erai task: evaluating the rationales of amateur investors",
    "citation_count": 6,
    "authors": [
      "Chung-Chi Chen",
      "Hen-Hsen Huang",
      "Hiroya Takamura",
      "Hsin-Hsi Chen"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.12": {
    "title": "PromptShots at the FinNLP-2022 ERAI Task: Pairwise Comparison and Unsupervised Ranking",
    "volume": "workshop",
    "abstract": "This report describes our PromptShots submissions to a shared task on Evaluating the Rationales of Amateur Investors (ERAI). We participated in both pairwise comparison and unsupervised ranking tasks. For pairwise comparison, we employed instruction-based models based on T5-small and OpenAI InstructGPT language models. Surprisingly, we observed OpenAI InstructGPT language model few-shot trained on Chinese data works best in our submissions, ranking 3rd on the maximal loss (ML) pairwise accuracy. This model works better than training on the Google translated English data by a large margin, where the English few-shot trained InstructGPT model even performs worse than an instruction-based T5-small model finetuned on the English data. However, all instruction-based submissions do not perform well on the maximal potential profit (MPP) pairwise accuracy where there are more data and learning signals. The Chinese few-shot trained InstructGPT model still performs best in our setting. For unsupervised ranking, we utilized many language models, including many financial-specific ones, and Bayesian lexicons unsupervised-learned on both Chinese and English words using a method-of-moments estimator. All our submissions rank best in the MPP ranking, from 1st to 3rd. However, they all do not perform well for ML scoring. Therefore, both MPP and ML scores need different treatments since we treated MPP and ML using the same formula. Our only difference is the treatment of market sentiment lexicons",
    "checked": true,
    "id": "3985999efd7ff8505e412b6e73ad8a7dd2db1132",
    "semantic_title": "promptshots at the finnlp-2022 erai task: pairwise comparison and unsupervised ranking",
    "citation_count": 2,
    "authors": [
      "Peratham Wiriyathammabhum"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.13": {
    "title": "LIPI at the FinNLP-2022 ERAI Task: Ensembling Sentence Transformers for Assessing Maximum Possible Profit and Loss from Online Financial Posts",
    "volume": "workshop",
    "abstract": "Using insights from social media for making investment decisions has become mainstream. However, in the current era of information ex- plosion, it is essential to mine high-quality so- cial media posts. The FinNLP-2022 ERAI task deals with assessing Maximum Possible Profit (MPP) and Maximum Loss (ML) from social me- dia posts relating to finance. In this paper, we present our team LIPI's approach. We ensem- bled a range of Sentence Transformers to quan- tify these posts. Unlike other teams with vary- ing performances across different metrics, our system performs consistently well. Our code is available here https://github.com/sohomghosh/LIPI_ERAI_ FinNLP_EMNLP- 2022/",
    "checked": true,
    "id": "4bd8847cb2a6ff044d0f9591a0b1a38bc746415f",
    "semantic_title": "lipi at the finnlp-2022 erai task: ensembling sentence transformers for assessing maximum possible profit and loss from online financial posts",
    "citation_count": 1,
    "authors": [
      "Sohom Ghosh",
      "Sudip Kumar Naskar"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.14": {
    "title": "DCU-ML at the FinNLP-2022 ERAI Task: Investigating the Transferability of Sentiment Analysis Data for Evaluating Rationales of Investors",
    "volume": "workshop",
    "abstract": "In this paper, we describe our system for the FinNLP-2022 shared task: Evaluating the Rationales of Amateur Investors (ERAI). The ERAI shared tasks focuses on mining profitable information from financial texts by predicting the possible Maximal Potential Profit (MPP) and Maximal Loss (ML) based on the posts from amateur investors. There are two sub-tasks in ERAI: Pairwise Comparison and Unsupervised Rank, both target on the prediction of MPP and ML. To tackle the two tasks, we frame this task as a text-pair classification task where the input consists of two documents and the output is the label of whether the first document will lead to higher MPP or lower ML. Specifically, we propose to take advantage of the transferability of Sentiment Analysis data with an assumption that a more positive text will lead to higher MPP or higher ML to facilitate the prediction of MPP and ML. In experiment on the ERAI blind test set, our systems trained on Sentiment Analysis data and ERAI training data ranked 1st and 8th in ML and MPP pairwise comparison respectively. Code available in this link",
    "checked": true,
    "id": "c7a34d84a33974787952ee6764279ee7050d5930",
    "semantic_title": "dcu-ml at the finnlp-2022 erai task: investigating the transferability of sentiment analysis data for evaluating rationales of investors",
    "citation_count": 1,
    "authors": [
      "Chenyang Lyu",
      "Tianbo Ji",
      "Liting Zhou"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.15": {
    "title": "UOA at the FinNLP-2022 ERAI Task: Leveraging the Class Label Description for Financial Opinion Mining",
    "volume": "workshop",
    "abstract": "Evaluating the Rationales of Amateur Investors (ERAI) is a task about mining expert-like viewpoints from social media. This paper summarizes our solutions to the ERAI shared task, which is co-located with the FinNLP workshop at EMNLP 2022. There are 2 sub-tasks in ERAI. Sub-task 1 is a pair-wised comparison task, where we propose a BERT-based pre-trained model projecting opinion pairs in a common space for classification. Sub-task 2 is an unsupervised learning task ranking the opinions' maximal potential profit (MPP) and maximal loss (ML), where our model leverages the regression method and multi-layer perceptron to rank the MPP and ML values. The proposed approaches achieve competitive accuracy of 54.02% on ML Accuracy and 51.72% on MPP Accuracy for pairwise tasks, also 12.35% and -9.39% regression unsupervised ranking task for MPP and ML",
    "checked": true,
    "id": "253238d9b2baeb9fcc4757fe0ff18fe4a7670166",
    "semantic_title": "uoa at the finnlp-2022 erai task: leveraging the class label description for financial opinion mining",
    "citation_count": 0,
    "authors": [
      "Jinan Zou",
      "Haiyao Cao",
      "Yanxi Liu",
      "Lingqiao Liu",
      "Ehsan Abbasnejad",
      "Javen Qinfeng Shi"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.16": {
    "title": "aiML at the FinNLP-2022 ERAI Task: Combining Classification and Regression Tasks for Financial Opinion Mining",
    "volume": "workshop",
    "abstract": "Identifying posts of high financial quality from opinions is of extraordinary significance for investors. Hence, this paper focuses on evaluating the rationales of amateur investors (ERAI) in a shared task, and we present our solutions. The pairwise comparison task aims at extracting the post that will trigger higher MPP and ML values from pairs of posts. The goal of the unsupervised ranking task is to find the top 10% of posts with higher MPP and ML values. We initially model the shared task as text classification and regression problems. We then propose a multi-learning approach applied by financial domain pre-trained models and multiple linear classifiers for factor combinations to integrate better relationships and information between training data. The official results have proved that our method achieves 48.28% and 52.87% for MPP and ML accuracy on pairwise tasks, 14.02% and -4.17% regarding unsupervised ranking tasks for MPP and ML. Our source code is available",
    "checked": true,
    "id": "62826f9cfd041bd95b54256d9c165e7edf49b0a6",
    "semantic_title": "aiml at the finnlp-2022 erai task: combining classification and regression tasks for financial opinion mining",
    "citation_count": 1,
    "authors": [
      "Zhaoxuan Qin",
      "Jinan Zou",
      "Qiaoyang Luo",
      "Haiyao Cao",
      "Yang Jiao"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.17": {
    "title": "Yet at the FinNLP-2022 ERAI Task: Modified models for evaluating the Rationales of Amateur Investors",
    "volume": "workshop",
    "abstract": "The financial reports usually reveal the recent development of the company and often cause the volatility in the company's share price. The opinions causing higher maximal potential profit and lower maximal loss can help the amateur investors choose rational strategies. FinNLP-2022 ERAI task aims to quantify the opinions' potentials of leading higher maximal potential profit and lower maximal loss. In this paper, different strategies were applied to solve the ERAI tasks. Valinna ‘RoBERTa-wwm' showed excellent performance and helped us rank second in ‘MPP' label prediction task. After integrating some tricks, the modified ‘RoBERTa-wwm' outperformed all other models in ‘ML' ranking task",
    "checked": true,
    "id": "50bd71214770a9d43e32df26be88fe7c3b806b04",
    "semantic_title": "yet at the finnlp-2022 erai task: modified models for evaluating the rationales of amateur investors",
    "citation_count": 1,
    "authors": [
      "Yan Zhuang",
      "Fuji Ren"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.18": {
    "title": "LDPP at the FinNLP-2022 ERAI Task: Determinantal Point Processes and Variational Auto-encoders for Identifying High-Quality Opinions from a pool of Social Media Posts",
    "volume": "workshop",
    "abstract": "Social media and online forums have made it easier for people to share their views and opinions on various topics in society. In this paper, we focus on posts discussing investment related topics. When it comes to investment , people can now easily share their opinions about online traded items and also provide rationales to support their arguments on social media. However, there are millions of posts to read with potential of having some posts from amateur investors or completely unrelated posts. Identifying the most important posts that could lead to higher maximal potential profit (MPP) and lower maximal loss for investment is not a trivial task. In this paper, propose to use determinantal point processes and variational autoencoders to identify high quality posts from the given rationales. Experimental results suggest that our method mines quality posts compared to random selection and also latent variable modeling improves improves the quality of selected posts",
    "checked": true,
    "id": "d0e2d366e1d3ba6c11ada9eefc847017fc5901ec",
    "semantic_title": "ldpp at the finnlp-2022 erai task: determinantal point processes and variational auto-encoders for identifying high-quality opinions from a pool of social media posts",
    "citation_count": 0,
    "authors": [
      "Paul Trust",
      "Rosane Minghim"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.19": {
    "title": "Jetsons at the FinNLP-2022 ERAI Task: BERT-Chinese for mining high MPP posts",
    "volume": "workshop",
    "abstract": "In this paper, we discuss the various approaches by the Jetsons team for the \"Pairwise Comparison\" sub-task of the ERAI shared task to compare financial opinions for profitability and loss. Our BERT-Chinese model considers a pair of opinions and predicts the one with a higher maximum potential profit (MPP) with 62.07% accuracy. We analyze the performance of our approaches on both the MPP and maximal loss (ML) problems and deeply dive into why BERT-Chinese outperforms other models",
    "checked": true,
    "id": "ed6fe2f53a43debf53ce8509e1ebdbcea019d575",
    "semantic_title": "jetsons at the finnlp-2022 erai task: bert-chinese for mining high mpp posts",
    "citation_count": 1,
    "authors": [
      "Alolika Gon",
      "Sihan Zha",
      "Sai Krishna Rallabandi",
      "Parag Pravin Dakle",
      "Preethi Raghavan"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.20": {
    "title": "No Stock is an Island: Learning Internal and Relational Attributes of Stocks with Contrastive Learning",
    "volume": "workshop",
    "abstract": "Previous work has demonstrated the viability of applying deep learning techniques in the financial area. Recently, the task of stock embedding learning has been drawing attention from the research community, which aims to represent the characteristics of stocks with distributed vectors that can be used in various financial analysis scenarios. Existing approaches for learning stock embeddings either require expert knowledge, or mainly focus on the textual part of information corresponding to individual temporal movements. In this paper, we propose to model stock properties as the combination of internal attributes and relational attributes, which takes into consideration both the time-invariant properties of individual stocks and their movement patterns in relation to the market. To learn the two types of attributes from financial news and transaction data, we design several training objectives based on contrastive learning to extract and separate the long-term and temporary information in the data that are able to counter the inherent randomness of the stock market. Experiments and further analyses on portfolio optimization reveal the effectiveness of our method in extracting comprehensive stock information from various data sources",
    "checked": true,
    "id": "a89aab0fcbf06867c32e8444529dc6545b636964",
    "semantic_title": "no stock is an island: learning internal and relational attributes of stocks with contrastive learning",
    "citation_count": 1,
    "authors": [
      "Shicheng Li",
      "Wei Li",
      "Zhiyuan Zhang",
      "Ruihan Bao",
      "Keiko Harimoto",
      "Xu Sun"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.21": {
    "title": "Prospectus Language and IPO Performance",
    "volume": "workshop",
    "abstract": "Pricing a firm's Initial Public Offering (IPO) has historically been very difficult, with high average returns on the first-day of trading. Furthermore, IPO withdrawal, the event in which companies who file to go public ultimately rescind the application before the offering, is an equally challenging prediction problem. This research utilizes word embedding techniques to evaluate existing theories concerning firm sentiment on first-day trading performance and the probability of withdrawal, which has not yet been explored empirically. The results suggest that firms attempting to go public experience a decreased probability of withdrawal with the increased presence of positive, litigious, and uncertain language in their initial prospectus, while the increased presence of strong modular language leads to an increased probability of withdrawal. The results also suggest that frequent or large adjustments in the strong modular language of subsequent filings leads to smaller first-day returns",
    "checked": true,
    "id": "6c43842d52992cc94686e2ffcf2d4a3d5694e63e",
    "semantic_title": "prospectus language and ipo performance",
    "citation_count": 2,
    "authors": [
      "Jared Sharpe",
      "Keith Decker"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.22": {
    "title": "It's Time to Reason: Annotating Argumentation Structures in Financial Earnings Calls: The FinArg Dataset",
    "volume": "workshop",
    "abstract": "With the goal of reasoning on the financial textual data, we present in this paper, a novel approach for annotating arguments, their components and relations in the transcripts of earnings conference calls (ECCs). The proposed scheme is driven from the argumentation theory at the micro-structure level of discourse. We further conduct a manual annotation study with four annotators on 136 documents. We obtained inter-annotator agreement of lphaU = 0.70 for argument components and lpha = 0.81 for argument relations. The final created corpus, with the size of 804 documents, as well as the annotation guidelines are publicly available for researchers in the domains of computational argumentation, finance and FinNLP",
    "checked": true,
    "id": "ac46f8390ae999e6cb048cbf889e0a29f4f69bcf",
    "semantic_title": "it's time to reason: annotating argumentation structures in financial earnings calls: the finarg dataset",
    "citation_count": 8,
    "authors": [
      "Alaa Alhamzeh",
      "Romain Fonck",
      "Erwan Versmée",
      "Elöd Egyed-Zsigmond",
      "Harald Kosch",
      "Lionel Brunie"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.23": {
    "title": "How Can a Teacher Make Learning From Sparse Data Softer? Application to Business Relation Extraction",
    "volume": "workshop",
    "abstract": "Business Relation Extraction between market entities is a challenging information extraction task that suffers from data imbalance due to the over-representation of negative relations (also known as No-relation or Others) compared to positive relations that corresponds to the taxonomy of relations of interest. This paper proposes a novel solution to tackle this problem, relying on binary soft labels supervision generated by an approach based on knowledge distillation. When evaluated on a business relation extraction dataset, the results suggest that the proposed approach improves the overall performance, beating state-of-the art solutions for data imbalance. In particular, it improves the extraction of under-represented relations as well as the detection of false negatives",
    "checked": true,
    "id": "91b3ed21cabc3bbd0fae4003e77dcd72dbcb91dc",
    "semantic_title": "how can a teacher make learning from sparse data softer? application to business relation extraction",
    "citation_count": 0,
    "authors": [
      "Hadjer Khaldi",
      "Farah Benamara",
      "Camille Pradel",
      "Nathalie Aussenac-Gilles"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.24": {
    "title": "Astock: A New Dataset and Automated Stock Trading based on Stock-specific News Analyzing Model",
    "volume": "workshop",
    "abstract": "Natural Language Processing (NLP) demonstrates a great potential to support financial decision-making by analyzing the text from social media or news outlets. In this work, we build a platform to study the NLP-aided stock auto-trading algorithms systematically. In contrast to the previous work, our platform is characterized by three features: (1) We provide financial news for each specific stock. (2) We provide various stock factors for each stock. (3) We evaluate performance from more financial-relevant metrics. Such a design allows us to develop and evaluate NLP-aided stock auto-trading algorithms in a more realistic setting. In addition to designing an evaluation platform and dataset collection, we also made a technical contribution by proposing a system to automatically learn a good feature representation from various input information. The key to our algorithm is a method called semantic role labeling Pooling (SRLP), which leverages Semantic Role Labeling (SRL) to create a compact representation of each news paragraph. Based on SRLP, we further incorporate other stock factors to make the final prediction. In addition, we propose a self-supervised learning strategy based on SRLP to enhance the out-of-distribution generalization performance of our system. Through our experimental study, we show that the proposed method achieves better performance and outperforms all the baselines' annualized rate of return as well as the maximum drawdown of the CSI300 index and XIN9 index on real trading. Our Astock dataset and code are available at https://github.com/JinanZou/Astock",
    "checked": true,
    "id": "8b4ea38f844a2e5b18d296cce6779354fe651a28",
    "semantic_title": "astock: a new dataset and automated stock trading based on stock-specific news analyzing model",
    "citation_count": 8,
    "authors": [
      "Jinan Zou",
      "Haiyao Cao",
      "Lingqiao Liu",
      "Yuhao Lin",
      "Ehsan Abbasnejad",
      "Javen Qinfeng Shi"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.25": {
    "title": "Next-Year Bankruptcy Prediction from Textual Data: Benchmark and Baselines",
    "volume": "workshop",
    "abstract": "Models for bankruptcy prediction are useful in several real-world scenarios, and multiple research contributions have been devoted to the task, based on structured (numerical) as well as unstructured (textual) data. However, the lack of a common benchmark dataset and evaluation strategy impedes the objective comparison between models. This paper introduces such a benchmark for the unstructured data scenario, based on novel and established datasets, in order to stimulate further research into the task. We describe and evaluate several classical and neural baseline models, and discuss benefits and flaws of different strategies. In particular, we find that a lightweight bag-of-words model based on static in-domain word representations obtains surprisingly good results, especially when taking textual data from several years into account. These results are critically assessed, and discussed in light of particular aspects of the data and the task. All code to replicate the data and experimental results will be released",
    "checked": true,
    "id": "a458ae019fb7f500d47bb22863c81e525d823b24",
    "semantic_title": "next-year bankruptcy prediction from textual data: benchmark and baselines",
    "citation_count": 4,
    "authors": [
      "Henri Arno",
      "Klaas Mulier",
      "Joke Baeck",
      "Thomas Demeester"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.26": {
    "title": "AdaK-NER: An Adaptive Top-K Approach for Named Entity Recognition with Incomplete Annotations",
    "volume": "workshop",
    "abstract": "State-of-the-art Named Entity Recognition (NER) models rely heavily on large amounts of fully annotated training data. However, accessible data are often incompletely annotated since the annotators usually lack comprehensive knowledge in the target domain. Normally the unannotated tokens are regarded as non-entities by default, while we underline that these tokens could either be non-entities or part of any entity. Here, we study NER modeling with incomplete annotated data where only a fraction of the named entities are labeled, and the unlabeled tokens are equivalently multi-labeled by every possible label. Taking multi-labeled tokens into account, the numerous possible paths can distract the training model from the gold path (ground truth label sequence), and thus hinders the learning ability. In this paper, we propose AdaK-NER, named the adaptive top-K approach, to help the model focus on a smaller feasible region where the gold path is more likely to be located. We demonstrate the superiority of our approach through extensive experiments on both English and Chinese datasets, averagely improving 2% in F-score on the CoNLL-2003 and over 10% on two Chinese datasets compared with the prior state-of-the-art works",
    "checked": true,
    "id": "687b458a8c8eefcde6dc44a136852ecc93f9f03e",
    "semantic_title": "adak-ner: an adaptive top-k approach for named entity recognition with incomplete annotations",
    "citation_count": 0,
    "authors": [
      "Hongtao Ruan",
      "Liying Zheng",
      "Peixian Hu"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.27": {
    "title": "A Sentiment and Emotion Annotated Dataset for Bitcoin Price Forecasting Based on Reddit Posts",
    "volume": "workshop",
    "abstract": "Cryptocurrencies have gained enormous momentum in finance and are nowadays commonly adopted as a medium of exchange for online payments. After recent events during which GameStop's stocks were believed to be influenced by WallStreetBets subReddit, Reddit has become a very hot topic on the cryptocurrency market. The influence of public opinions on cryptocurrency price trends has inspired researchers on exploring solutions that integrate such information in crypto price change forecasting. A popular integration technique regards representing social media opinions via sentiment features. However, this research direction is still in its infancy, where a limited number of publicly available datasets with sentiment annotations exists. We propose a novel Bitcoin Reddit Sentiment Dataset, a ready-to-use dataset annotated with state-of-the-art sentiment and emotion recognition. The dataset contains pre-processed Reddit posts and comments about Bitcoin from several domain-related subReddits along with Bitcoin's financial data. We evaluate several widely adopted neural architectures for crypto price change forecasting. Our results show controversial benefits of sentiment and emotion features advocating for more sophisticated social media integration techniques. We make our dataset publicly available for research",
    "checked": true,
    "id": "2bef075eff476cdebfb6b5f4f32c644104053037",
    "semantic_title": "a sentiment and emotion annotated dataset for bitcoin price forecasting based on reddit posts",
    "citation_count": 4,
    "authors": [
      "Pavlo Seroyizhko",
      "Zhanel Zhexenova",
      "Muhammad Zohaib Shafiq",
      "Fabio Merizzi",
      "Andrea Galassi",
      "Federico Ruggeri"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.28": {
    "title": "FinSim4-ESG Shared Task: Learning Semantic Similarities for the Financial Domain. Extended edition to ESG insights",
    "volume": "workshop",
    "abstract": "This paper describes FinSim4-ESG 1 shared task organized in the 4th FinNLP workshopwhich is held in conjunction with the IJCAI-ECAI-2022 confer- enceThis year, the FinSim4 is extended to the Environment, Social and Government (ESG) insights and proposes two subtasks, one for ESG Taxonomy Enrichment and the other for Sustainable Sentence Prediction. Among the 28 teams registered to the shared task, a total of 8 teams submitted their systems results and 6 teams also submitted a paper to describe their method. The winner of each subtask shows good performance results of 0.85% and 0.95% in terms of accuracy, respectively",
    "checked": true,
    "id": "e3f91a96f6096fcdc7ca495ffaeb443eb3d034d5",
    "semantic_title": "finsim4-esg shared task: learning semantic similarities for the financial domain. extended edition to esg insights",
    "citation_count": 4,
    "authors": [
      "Juyeon Kang",
      "Ismail El Maarouf"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.29": {
    "title": "Using Contextual Sentence Analysis Models to Recognize ESG Concepts",
    "volume": "workshop",
    "abstract": "This paper summarizes the joint participation of the Trading Central Labs and the L3i laboratory of the University of La Rochelle on both sub-tasks of the Shared Task FinSim-4 evaluation campaign. The first sub-task aims to enrich the ‘Fortia ESG taxonomy' with new lexicon entries while the second one aims to classify sentences to either ‘sustainable' or ‘unsustainable' with respect to ESG (Environment, Social and Governance) related factors. For the first sub-task, we proposed a model based on pre-trained Sentence-BERT models to project sentences and concepts in a common space in order to better represent ESG concepts. The official task results show that our system yields a significant performance improvement compared to the baseline and outperforms all other submissions on the first sub-task. For the second sub-task, we combine the RoBERTa model with a feed-forward multi-layer perceptron in order to extract the context of sentences and classify them. Our model achieved high accuracy scores (over 92%) and was ranked among the top 5 systems",
    "checked": true,
    "id": "e5cd54993b13a1ffa19cd56bd9085c004294ae9c",
    "semantic_title": "using contextual sentence analysis models to recognize esg concepts",
    "citation_count": 5,
    "authors": [
      "Elvys Linhares Pontes",
      "Mohamed Ben Jannet",
      "Jose G. Moreno",
      "Antoine Doucet"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.30": {
    "title": "Automatic Term and Sentence Classification Via Augmented Term and Pre-trained language model in ESG Taxonomy texts",
    "volume": "workshop",
    "abstract": "In this paper, we present our solutions to the FinSim4 Shared Task which is co-located with the FinNLP workshop at IJCAI-2022. This new edition of FinSim4-ESG is extended to the \"Environment, Social and Governance (ESG)\" related issues in the financial domain. There are two sub-tasks in the FinSim4 shared task. The goal of sub-task1 is to develop a model to predict correctly a list of given terms from ESG taxonomy domain into the most relevant concepts. The aim of subtask2 is to design a system that can automatically classify the ESG Taxonomy text sentence into sustainable or unsustainable class. We have developed different classifiers to automatically classify the terms and sentences with augmented term and pre-trained language models: tf-idf vector, word2vec, Bert, Distill-Bert, Albert, Roberta. The result dashboard shows that our proposed methods yield a significant performance improvement compared to the baseline which ranked 1st in the subtask2 and 2rd of mean rank in the subtask1",
    "checked": true,
    "id": "8502b3c95f3686663fe16aaa0d973d19d958f3dc",
    "semantic_title": "automatic term and sentence classification via augmented term and pre-trained language model in esg taxonomy texts",
    "citation_count": 1,
    "authors": [
      "Ke Tian",
      "Zepeng Zhang",
      "Hua Chen"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.31": {
    "title": "Knowledge informed sustainability detection from short financial texts",
    "volume": "workshop",
    "abstract": "There is a global trend for responsible investing and the need for developing automated methods for analyzing and Environmental, Social and Governance (ESG) related elements in financial texts is raising. In this work we propose a solution to the FinSim4-ESG task, consisting of binary classification of sentences into sustainable or unsustainable. We propose a novel knowledge-based latent heterogeneous representation that is based on knowledge from taxonomies and knowledge graphs and multiple contemporary document representations. We hypothesize that an approach based on a combination of knowledge and document representations can introduce significant improvement over conventional document representation approaches. We consider ensembles on classifier as well on representation level late-fusion and early fusion. The proposed approaches achieve competitive accuracy of 89 and are 5.85 behind the best achieved score",
    "checked": true,
    "id": "fa437221a3d655fe105b0a8389a3f0855c32e0a1",
    "semantic_title": "knowledge informed sustainability detection from short financial texts",
    "citation_count": 1,
    "authors": [
      "Boshko Koloski",
      "Syrielle Montariol",
      "Matthew Purver",
      "Senja Pollak"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.32": {
    "title": "TCS WITM 2022@FinSim4-ESG: Augmenting BERT with Linguistic and Semantic features for ESG data classification",
    "volume": "workshop",
    "abstract": "Advanced neural network architectures have provided several opportunities to develop systems to automatically capture information from domain-specific unstructured text sources. The FinSim4-ESG shared task, collocated with the FinNLP workshop, proposed two sub-tasks. In sub-task1, the challenge was to design systems that could utilize contextual word embeddings along with sustainability resources to elaborate an ESG taxonomy. In the second sub-task, participants were asked to design a system that could classify sentences into sustainable or unsustainable sentences. In this paper, we utilize semantic similarity features along with BERT embeddings to segregate domain terms into a fixed number of class labels. The proposed model not only considers the contextual BERT embeddings but also incorporates Word2Vec, cosine, and Jaccard similarity which gives word-level importance to the model. For sentence classification, several linguistic elements along with BERT embeddings were used as classification features. We have shown a detailed ablation study for the proposed models",
    "checked": true,
    "id": "98f38031b84659fb8c93d0f225d42256f84cd90d",
    "semantic_title": "tcs witm 2022@finsim4-esg: augmenting bert with linguistic and semantic features for esg data classification",
    "citation_count": 2,
    "authors": [
      "Tushar Goel",
      "Vipul Chauhan",
      "Suyash Sangwan",
      "Ishan Verma",
      "Tirthankar Dasgupta",
      "Lipika Dey"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.33": {
    "title": "Ranking Environment, Social And Governance Related Concepts And Assessing Sustainability Aspect of Financial Texts",
    "volume": "workshop",
    "abstract": "Understanding Environmental, Social, and Governance (ESG) factors related to financial products has become extremely important for investors. However, manually screening through the corporate policies and reports to understand their sustainability aspect is extremely tedious. In this paper, we propose solutions to two such problems which were released as shared tasks of the FinNLP workshop of the IJCAI-2022 conference. Firstly, we train a Sentence Transformers based model which automatically ranks ESG related concepts for a given unknown term. Secondly, we fine-tune a RoBERTa model to classify financial texts as sustainable or not. Out of 26 registered teams, our team ranked 4th in sub-task 1 and 3rd in sub-task 2. The source code can be accessed from https://github.com/sohomghosh/Finsim4_ESG",
    "checked": true,
    "id": "4e7d904a33c35d9caecd30baa3e0943dc1e4acfc",
    "semantic_title": "ranking environment, social and governance related concepts and assessing sustainability aspect of financial texts",
    "citation_count": 3,
    "authors": [
      "Sohom Ghosh",
      "Sudip Kumar Naskar"
    ]
  },
  "https://aclanthology.org/2022.finnlp-1.34": {
    "title": "Using Transformer-based Models for Taxonomy Enrichment and Sentence Classification",
    "volume": "workshop",
    "abstract": "In this paper, we present a system that addresses the taxonomy enrichment problem for Environment, Social and Governance issues in the financial domain, as well as classifying sentences as sustainable or unsustainable, for FinSim4-ESG, a shared task for the FinNLP workshop at IJCAI-2022. We first created a derived dataset for taxonomy enrichment by using a sentence-BERT-based paraphrase detector (Reimers and Gurevych, 2019) (on the train set) to create positive and negative term-concept pairs. We then model the problem by fine-tuning the sentence-BERT-based paraphrase detector on this derived dataset, and use it as the encoder, and use a Logistic Regression classifier as the decoder, resulting in test Accuracy: 0.6 and Avg. Rank: 1.97. In case of the sentence classification task, the best-performing classifier (Accuracy: 0.92) consists of a pre-trained RoBERTa model (Liu et al., 2019a) as the encoder and a Feed Forward Neural Network classifier as the decoder",
    "checked": true,
    "id": "b450cf6c0302306e87471cf263be16a64a06fc9c",
    "semantic_title": "using transformer-based models for taxonomy enrichment and sentence classification",
    "citation_count": 1,
    "authors": [
      "Parag Pravin Dakle",
      "Shrikumar Patil",
      "Sai Krishna Rallabandi",
      "Chaitra Hegde",
      "Preethi Raghavan"
    ]
  },
  "https://aclanthology.org/2022.flp-1.1": {
    "title": "TEDB System Description to a Shared Task on Euphemism Detection 2022",
    "volume": "workshop",
    "abstract": "In this report, we describe our Transformers for euphemism detection baseline (TEDB) submissions to a shared task on euphemism detection 2022. We cast the task of predicting euphemism as text classification. We considered Transformer-based models which are the current state-of-the-art methods for text classification. We explored different training schemes, pretrained models, and model architectures. Our best result of 0.816 F1-score (0.818 precision and 0.814 recall) consists of a euphemism-detection-finetuned TweetEval/TimeLMs-pretrained RoBERTa model as a feature extractor frontend with a KimCNN classifier backend trained end-to-end using a cosine annealing scheduler. We observed pretrained models on sentiment analysis and offensiveness detection to correlate with more F1-score while pretraining on other tasks, such as sarcasm detection, produces less F1-scores. Also, putting more word vector channels does not improve the performance in our experiments",
    "checked": true,
    "id": "8a4619f3f967360558718e5577ddc2819e96e39c",
    "semantic_title": "tedb system description to a shared task on euphemism detection 2022",
    "citation_count": 2,
    "authors": [
      "Peratham Wiriyathammabhum"
    ]
  },
  "https://aclanthology.org/2022.flp-1.2": {
    "title": "A Prompt Based Approach for Euphemism Detection",
    "volume": "workshop",
    "abstract": "Euphemism is an indirect way to express sensitive topics. People can comfortably communicate with each other about sensitive topics or taboos by using euphemisms. The Euphemism Detection Shared Task in the Third Workshop on Figurative Language Processing co-located with EMNLP 2022 provided a euphemism detection dataset that was divided into the train set and the test set. We made euphemism detection experiments by prompt tuning pre-trained language models on the dataset. We used RoBERTa as the pre-trained language model and created suitable templates and verbalizers for the euphemism detection task. Our approach achieved the third-best score in the euphemism detection shared task. This paper describes our model participating in the task",
    "checked": true,
    "id": "094cc45fc3d90fb7320a240ad639c3d7a77a96b6",
    "semantic_title": "a prompt based approach for euphemism detection",
    "citation_count": 1,
    "authors": [
      "Abulimiti Maimaitituoheti",
      "Yang Yong",
      "Fan Xiaochao"
    ]
  },
  "https://aclanthology.org/2022.flp-1.3": {
    "title": "Transfer Learning Parallel Metaphor using Bilingual Embeddings",
    "volume": "workshop",
    "abstract": "Automated metaphor detection in languages other than English is highly restricted as training corpora are comparably rare. One way to overcome this problem is transfer learning. This paper gives an overview on transfer learning techniques applied to NLP. We first introduce types of transfer learning, then we present work focusing on: i) transfer learning with cross-lingual embeddings; ii) transfer learning in machine translation; and iii) transfer learning using pre-trained transformer models. The paper is complemented by first experiments that make use of bilingual embeddings generated from different sources of parallel data: We i) present the preparation of a parallel Gold corpus; ii) examine the embeddings spaces to search for metaphoric words cross-lingually; iii) run first experiments in transfer learning German metaphor from English labeled data only. Results show that finding data sources for bilingual embeddings training and the vocabulary covered by these embeddings is critical for learning metaphor cross-lingually",
    "checked": true,
    "id": "93eaaf33374d43175320b09aa3e0aafbffd971ee",
    "semantic_title": "transfer learning parallel metaphor using bilingual embeddings",
    "citation_count": 0,
    "authors": [
      "Maria Berger"
    ]
  },
  "https://aclanthology.org/2022.flp-1.4": {
    "title": "Ring That Bell: A Corpus and Method for Multimodal Metaphor Detection in Videos",
    "volume": "workshop",
    "abstract": "We present the first openly available multimodal metaphor annotated corpus. The corpus consists of videos including audio and subtitles that have been annotated by experts. Furthermore, we present a method for detecting metaphors in the new dataset based on the textual content of the videos. The method achieves a high F1-score (62%) for metaphorical labels. We also experiment with other modalities and multimodal methods; however, these methods did not out-perform the text-based model. In our error analysis, we do identify that there are cases where video could help in disambiguating metaphors, however, the visual cues are too subtle for our model to capture. The data is available on Zenodo",
    "checked": true,
    "id": "bc3e474a383efa9ec2c491171c35711b50337dfe",
    "semantic_title": "ring that bell: a corpus and method for multimodal metaphor detection in videos",
    "citation_count": 1,
    "authors": [
      "Khalid Alnajjar",
      "Mika Hämäläinen",
      "Shuo Zhang"
    ]
  },
  "https://aclanthology.org/2022.flp-1.5": {
    "title": "Picard understanding Darmok: A Dataset and Model for Metaphor-Rich Translation in a Constructed Language",
    "volume": "workshop",
    "abstract": "Tamarian, a fictional language introduced in the Star Trek episode Darmok, communicates meaning through utterances of metaphorical references, such as \"Darmok and Jalad at Tanagra\" instead of \"We should work together.\" This work assembles a Tamarian-English dictionary of utterances from the original episode and several follow-on novels, and uses this to construct a parallel corpus of 456 English-Tamarian utterances. A machine translation system based on a large language model (T5) is trained using this parallel corpus, and is shown to produce an accuracy of 76% when translating from English to Tamarian on known utterances",
    "checked": true,
    "id": "17b4be8eefa278af605b8a0bc740b7cf262af3fe",
    "semantic_title": "picard understanding darmok: a dataset and model for metaphor-rich translation in a constructed language",
    "citation_count": 0,
    "authors": [
      "Peter A. Jansen",
      "Jordan Boyd-Graber"
    ]
  },
  "https://aclanthology.org/2022.flp-1.6": {
    "title": "The Secret of Metaphor on Expressing Stronger Emotion",
    "volume": "workshop",
    "abstract": "Metaphors are proven to have stronger emotional impact than literal expressions. Although this conclusion is shown to be promising in benefiting various NLP applications, the reasons behind this phenomenon are not well studied. This paper conducts the first study in exploring how metaphors convey stronger emotion than their literal counterparts. We find that metaphors are generally more specific than literal expressions. The more specific property of metaphor can be one of the reasons for metaphors' superiority in emotion expression. When we compare metaphors with literal expressions with the same specificity level, the gap of emotion expressing ability between both reduces significantly. In addition, we observe specificity is crucial in literal language as well, as literal language can express stronger emotion by making it more specific",
    "checked": true,
    "id": "5670eed6a422b0399bbb2c7131716149abce29f8",
    "semantic_title": "the secret of metaphor on expressing stronger emotion",
    "citation_count": 6,
    "authors": [
      "Yucheng Li",
      "Frank Guerin",
      "Chenghua Lin"
    ]
  },
  "https://aclanthology.org/2022.flp-1.7": {
    "title": "Drum Up SUPPORT: Systematic Analysis of Image-Schematic Conceptual Metaphors",
    "volume": "workshop",
    "abstract": "Conceptual metaphors represent a cognitive mechanism to transfer knowledge structures from one onto another domain. Image-schematic conceptual metaphors (ISCMs) specialize on transferring sensorimotor experiences to abstract domains. Natural language is believed to provide evidence of such metaphors. However, approaches to verify this hypothesis largely rely on top-down methods, gathering examples by way of introspection, or on manual corpus analyses. In order to contribute towards a method that is systematic and can be replicated, we propose to bring together existing processing steps in a pipeline to detect ISCMs, exemplified for the image schema SUPPORT in the COVID-19 domain. This pipeline consist of neural metaphor detection, dependency parsing to uncover construction patterns, clustering, and BERT-based frame annotation of dependent constructions to analyse ISCMs",
    "checked": true,
    "id": "283a61671bae358d31b27df4274ff77cb97523eb",
    "semantic_title": "drum up support: systematic analysis of image-schematic conceptual metaphors",
    "citation_count": 2,
    "authors": [
      "Lennart Wachowiak",
      "Dagmar Gromann",
      "Chao Xu"
    ]
  },
  "https://aclanthology.org/2022.flp-1.8": {
    "title": "Effective Cross-Task Transfer Learning for Explainable Natural Language Inference with T5",
    "volume": "workshop",
    "abstract": "We compare sequential fine-tuning with a model for multi-task learning in the context where we are interested in boosting performance on two of the tasks, one of which depends on the other. We test these models on the FigLang2022 shared task which requires participants to predict language inference labels on figurative language along with corresponding textual explanations of the inference predictions. Our results show that while sequential multi-task learning can be tuned to be good at the first of two target tasks, it performs less well on the second and additionally struggles with overfitting. Our findings show that simple sequential fine-tuning of text-to-text models is an extraordinarily powerful method of achieving cross-task knowledge transfer while simultaneously predicting multiple interdependent targets. So much so, that our best model achieved the (tied) highest score on the task",
    "checked": true,
    "id": "2b166c7dea5473c149679b5b7f8d47702a302348",
    "semantic_title": "effective cross-task transfer learning for explainable natural language inference with t5",
    "citation_count": 2,
    "authors": [
      "Irina Bigoulaeva",
      "Rachneet Singh Sachdeva",
      "Harish Tayyar Madabushi",
      "Aline Villavicencio",
      "Iryna Gurevych"
    ]
  },
  "https://aclanthology.org/2022.flp-1.9": {
    "title": "Detecting Euphemisms with Literal Descriptions and Visual Imagery",
    "volume": "workshop",
    "abstract": "This paper describes our two-stage system for the Euphemism Detection shared task hosted by the 3rd Workshop on Figurative Language Processing in conjunction with EMNLP 2022. Euphemisms tone down expressions about sensitive or unpleasant issues like addiction and death. The ambiguous nature of euphemistic words or expressions makes it challenging to detect their actual meaning within a context. In the first stage, we seek to mitigate this ambiguity by incorporating literal descriptions into input text prompts to our baseline model. It turns out that this kind of direct supervision yields remarkable performance improvement. In the second stage, we integrate visual supervision into our system using visual imageries, two sets of images generated by a text-to-image model by taking terms and descriptions as input. Our experiments demonstrate that visual supervision also gives a statistically significant performance boost. Our system achieved the second place with an F1 score of 87.2%, only about 0.9% worse than the best submission",
    "checked": true,
    "id": "db7d7f9b5c5c7f13023ac84727ec5bc323c962f7",
    "semantic_title": "detecting euphemisms with literal descriptions and visual imagery",
    "citation_count": 2,
    "authors": [
      "Ilker Kesen",
      "Aykut Erdem",
      "Erkut Erdem",
      "Iacer Calixto"
    ]
  },
  "https://aclanthology.org/2022.flp-1.10": {
    "title": "Distribution-Based Measures of Surprise for Creative Language: Experiments with Humor and Metaphor",
    "volume": "workshop",
    "abstract": "Novelty or surprise is a fundamental attribute of creative output. As such, we postulate that a writer's creative use of language leads to word choices and, more importantly, corresponding semantic structures that are unexpected for the reader. In this paper we investigate measures of surprise that rely solely on word distributions computed by language models and show empirically that creative language such as humor and metaphor is strongly correlated with surprise. Surprisingly at first, information content is observed to be at least as good a predictor of creative language as any of the surprise measures investigated. However, the best prediction performance is obtained when information and surprise measures are combined, showing that surprise measures capture an aspect of creative language that goes beyond information content",
    "checked": true,
    "id": "d0e7e283f8ac89f809e679cd64747be3d24b0c6b",
    "semantic_title": "distribution-based measures of surprise for creative language: experiments with humor and metaphor",
    "citation_count": 4,
    "authors": [
      "Razvan C. Bunescu",
      "Oseremen O. Uduehi"
    ]
  },
  "https://aclanthology.org/2022.flp-1.11": {
    "title": "Euphemism Detection by Transformers and Relational Graph Attention Network",
    "volume": "workshop",
    "abstract": "Euphemism is a type of figurative language broadly adopted in social media and daily conversations. People use euphemism for politeness or to conceal what they are discussing. Euphemism detection is a challenging task because of its obscure and figurative nature. Even humans may not agree on if a word expresses euphemism. In this paper, we propose to employ bidirectional encoder representations transformers (BERT), and relational graph attention network in order to model the semantic and syntactic relations between the target words and the input sentence. The best performing method of ours reaches a Macro-F1 score of 84.0 on the euphemism detection dataset of the third workshop on figurative language processing shared task 2022",
    "checked": true,
    "id": "a2eb6fc280076091e5bcd5b11c085d5d7f9842ab",
    "semantic_title": "euphemism detection by transformers and relational graph attention network",
    "citation_count": 1,
    "authors": [
      "Yuting Wang",
      "Yiyi Liu",
      "Ruqing Zhang",
      "Yixing Fan",
      "Jiafeng Guo"
    ]
  },
  "https://aclanthology.org/2022.flp-1.12": {
    "title": "Just-DREAM-about-it: Figurative Language Understanding with DREAM-FLUTE",
    "volume": "workshop",
    "abstract": "Figurative language (e.g., \"he flew like the wind\") is challenging to understand, as it is hard to tell what implicit information is being conveyed from the surface form alone. We hypothesize that to perform this task well, the reader needs to mentally elaborate the scene being described to identify a sensible meaning of the language. We present DREAM-FLUTE, a figurative language understanding system that does this, first forming a \"mental model\" of situations described in a premise and hypothesis before making an entailment/contradiction decision and generating an explanation. DREAM-FLUTE uses an existing scene elaboration model, DREAM, for constructing its \"mental model.\" In the FigLang2022 Shared Task evaluation, DREAM-FLUTE achieved (joint) first place (Acc@60=63.3%), and can perform even better with ensemble techniques, demonstrating the effectiveness of this approach. More generally, this work suggests that adding a reflective component to pretrained language models can improve their performance beyond standard fine-tuning (3.3% improvement in Acc@60)",
    "checked": true,
    "id": "02e3cab451855891eb6e961a3a60e6c33795ba13",
    "semantic_title": "just-dream-about-it: figurative language understanding with dream-flute",
    "citation_count": 4,
    "authors": [
      "Yuling Gu",
      "Yao Fu",
      "Valentina Pyatkin",
      "Ian Magnusson",
      "Bhavana Dalvi Mishra",
      "Peter Clark"
    ]
  },
  "https://aclanthology.org/2022.flp-1.13": {
    "title": "Bayes at FigLang 2022 Euphemism Detection shared task: Cost-Sensitive Bayesian Fine-tuning and Venn-Abers Predictors for Robust Training under Class Skewed Distributions",
    "volume": "workshop",
    "abstract": "Transformers have achieved a state of the art performance across most natural language processing tasks. However the performance of these models degrade when being trained on skewed class distributions (class imbalance) because training tends to be biased towards head classes with most of the data points . Classical methods that have been proposed to handle this problem (re-sampling and re-weighting) often suffer from unstable performance, poor applicability and poor calibration. In this paper, we propose to use Bayesian methods and Venn-Abers predictors for well calibrated and robust training against class imbalance. Our proposed approach improves f1-score of the baseline RoBERTa (A Robustly Optimized Bidirectional Embedding from Transformers Pretraining Approach) model by about 6 points (79.0% against 72.6%) when training with class imbalanced data",
    "checked": true,
    "id": "f52a10cfe04f54b8f106b2cc46b6a2fd46a25b6e",
    "semantic_title": "bayes at figlang 2022 euphemism detection shared task: cost-sensitive bayesian fine-tuning and venn-abers predictors for robust training under class skewed distributions",
    "citation_count": 1,
    "authors": [
      "Paul Trust",
      "Kadusabe Provia",
      "Kizito Omala"
    ]
  },
  "https://aclanthology.org/2022.flp-1.14": {
    "title": "Food for Thought: How can we exploit contextual embeddings in the translation of idiomatic expressions?",
    "volume": "workshop",
    "abstract": "Idiomatic expressions (or idioms) are phrases where the meaning of the phrase cannot be determined from the meaning of the individual words in the expression. Translating idioms between languages is therefore a challenging task. Transformer models based on contextual embeddings have advanced the state-of-the-art across many domains in the field of natural language processing. While research using transformers has advanced both idiom detection as well as idiom disambiguation, idiom translation has not seen a similar advancement. In this work, we investigate two approaches to fine-tuning a pretrained Text-to-Text Transfer Transformer (T5) model to perform idiom translation from English to German. The first approach directly translates English idiom-containing sentences to German, while the second is underpinned by idiom paraphrasing, firstly paraphrasing English idiomatic expressions to their simplified English versions before translating them to German. Results of our evaluation show that each of the approaches is able to generate adequate translations",
    "checked": true,
    "id": "036ba418d7f7cade9e557c50e8080c786d6a8bcb",
    "semantic_title": "food for thought: how can we exploit contextual embeddings in the translation of idiomatic expressions?",
    "citation_count": 0,
    "authors": [
      "Lukas Santing",
      "Ryan Sijstermans",
      "Giacomo Anerdi",
      "Pedro Jeuris",
      "Marijn ten Thij",
      "Riza Batista-Navarro"
    ]
  },
  "https://aclanthology.org/2022.flp-1.15": {
    "title": "EUREKA: EUphemism Recognition Enhanced through Knn-based methods and Augmentation",
    "volume": "workshop",
    "abstract": "We introduce EUREKA, an ensemble-based approach for performing automatic euphemism detection. We (1) identify and correct potentially mislabelled rows in the dataset, (2) curate an expanded corpus called EuphAug, (3) leverage model representations of Potentially Euphemistic Terms (PETs), and (4) explore using representations of semantically close sentences to aid in classification. Using our augmented dataset and kNN-based methods, EUREKA was able to achieve state-of-the-art results on the public leaderboard of the Euphemism Detection Shared Task, ranking first with a macro F1 score of 0.881",
    "checked": true,
    "id": "fa3c6559c6807a197d53fd0cbd7f9d07ae0f249a",
    "semantic_title": "eureka: euphemism recognition enhanced through knn-based methods and augmentation",
    "citation_count": 3,
    "authors": [
      "Sedrick Scott Keh",
      "Rohit Bharadwaj",
      "Emmy Liu",
      "Simone Tedeschi",
      "Varun Gangal",
      "Roberto Navigli"
    ]
  },
  "https://aclanthology.org/2022.flp-1.16": {
    "title": "An insulin pump? Identifying figurative links in the construction of the drug lexicon",
    "volume": "workshop",
    "abstract": "One of the remarkable characteristics of the drug lexicon is its elusive nature. In order to communicate information related to drugs or drug trafficking, the community uses several terms that are mostly unknown to regular people, or even to the authorities. For instance, the terms jolly green, joystick, or jive are used to refer to marijuana. The selection of such terms is not necessarily a random or senseless process, but a communicative strategy in which figurative language plays a relevant role. In this study, we describe an ongoing research to identify drug-related terms by applying machine learning techniques. To this end, a data set regarding drug trafficking in Spanish was built. This data set was used to train a word embedding model to identify terms used by the community to creatively refer to drugs and related matters. The initial findings show an interesting repository of terms created to consciously veil drug-related contents by using figurative language devices, such as metaphor or metonymy. These findings can provide preliminary evidence to be applied by law agencies in order to address actions against crime, drug transactions on the internet, illicit activities, or human trafficking",
    "checked": true,
    "id": "2c7caae56406d87a09d89b991f488b2a283370cd",
    "semantic_title": "an insulin pump? identifying figurative links in the construction of the drug lexicon",
    "citation_count": 0,
    "authors": [
      "Antonio Reyes",
      "Rafael Saldivar"
    ]
  },
  "https://aclanthology.org/2022.flp-1.17": {
    "title": "Can Yes-No Question-Answering Models be Useful for Few-Shot Metaphor Detection?",
    "volume": "workshop",
    "abstract": "Metaphor detection has been a challenging task in the NLP domain both before and after the emergence of transformer-based language models. The difficulty lies in subtle semantic nuances that are required to detect metaphor and in the scarcity of labeled data. We explore few-shot setups for metaphor detection, and also introduce new question answering data that can enhance classifiers that are trained on a small amount of data. We formulate the classification task as a question-answering one, and train a question-answering model. We perform extensive experiments for few shot on several architectures and report the results of several strong baselines. Thus, the answer to the question posed in the title is a definite \"Yes!",
    "checked": true,
    "id": "699cfafab663c49bdf7ae35b80ead5356392627a",
    "semantic_title": "can yes-no question-answering models be useful for few-shot metaphor detection?",
    "citation_count": 1,
    "authors": [
      "Lena Dankin",
      "Kfir Bar",
      "Nachum Dershowitz"
    ]
  },
  "https://aclanthology.org/2022.flp-1.18": {
    "title": "An Exploration of Linguistically-Driven and Transfer Learning Methods for Euphemism Detection",
    "volume": "workshop",
    "abstract": "Euphemisms are often used to drive rhetoric, but their automated recognition and interpretation are under-explored. We investigate four methods for detecting euphemisms in sentences containing potentially euphemistic terms. The first three linguistically-motivated methods rest on an understanding of (1) euphemism's role to attenuate the harsh connotations of a taboo topic and (2) euphemism's metaphorical underpinnings. In contrast, the fourth method follows recent innovations in other tasks and employs transfer learning from a general-domain pre-trained language model. While the latter method ultimately (and perhaps surprisingly) performed best (F1 = 0.74), we comprehensively evaluate all four methods to derive additional useful insights from the negative results",
    "checked": true,
    "id": "d7b23ad2aacf24fb6fb70747b38d1bc44cea06c6",
    "semantic_title": "an exploration of linguistically-driven and transfer learning methods for euphemism detection",
    "citation_count": 1,
    "authors": [
      "Devika Tiwari",
      "Natalie Parde"
    ]
  },
  "https://aclanthology.org/2022.flp-1.19": {
    "title": "Back to the Roots: Predicting the Source Domain of Metaphors using Contrastive Learning",
    "volume": "workshop",
    "abstract": "Metaphors frame a given target domain using concepts from another, usually more concrete, source domain. Previous research in NLP has focused on the identification of metaphors and the interpretation of their meaning. In contrast, this paper studies to what extent the source domain can be predicted computationally from a metaphorical text. Given a dataset with metaphorical texts from a finite set of source domains, we propose a contrastive learning approach that ranks source domains by their likelihood of being referred to in a metaphorical text. In experiments, it achieves reasonable performance even for rare source domains, clearly outperforming a classification baseline",
    "checked": true,
    "id": "e2d4c0a1b400218772860beffcc347224a5fa582",
    "semantic_title": "back to the roots: predicting the source domain of metaphors using contrastive learning",
    "citation_count": 2,
    "authors": [
      "Meghdut Sengupta",
      "Milad Alshomary",
      "Henning Wachsmuth"
    ]
  },
  "https://aclanthology.org/2022.flp-1.20": {
    "title": "SBU Figures It Out: Models Explain Figurative Language",
    "volume": "workshop",
    "abstract": "Figurative language is ubiquitous in human communication. However, current NLP models are unable to demonstrate a significant understanding of instances of this phenomena. The EMNLP 2022 shared task on figurative language understanding posed the problem of predicting and explaining the relation between a premise and a hypothesis containing an instance of the use of figurative language. We experiment with different variations of using T5-large for this task and build a model that significantly outperforms the task baseline. Treating it as a new task for T5 and simply finetuning on the data achieves the best score on the defined evaluation. Furthermore, we find that hypothesis-only models are able to achieve most of the performance",
    "checked": true,
    "id": "8c108052266ef5d530c4adf19629e23a989c83ac",
    "semantic_title": "sbu figures it out: models explain figurative language",
    "citation_count": 1,
    "authors": [
      "Yash Kumar Lal",
      "Mohaddeseh Bastan"
    ]
  },
  "https://aclanthology.org/2022.flp-1.21": {
    "title": "NLP@UIT at FigLang-EMNLP 2022: A Divide-and-Conquer System For Shared Task On Understanding Figurative Language",
    "volume": "workshop",
    "abstract": "This paper describes our submissions to the EMNLP 2022 shared task on Understanding Figurative Language as part of the Figurative Language Workshop (FigLang 2022). Our systems based on pre-trained language model T5 are divide-and-conquer models which can address both two requirements of the task: 1) classification, and 2) generation. In this paper, we introduce different approaches in which each approach we employ a processing strategy on input model. We also emphasize the influence of the types of figurative language on our systems",
    "checked": true,
    "id": "018538f00c4b20d1c27564bc48c0457a02d211a0",
    "semantic_title": "nlp@uit at figlang-emnlp 2022: a divide-and-conquer system for shared task on understanding figurative language",
    "citation_count": 1,
    "authors": [
      "Khoa Thi-Kim Phan",
      "Duc-Vu Nguyen",
      "Ngan Luu-Thuy Nguyen"
    ]
  },
  "https://aclanthology.org/2022.flp-1.22": {
    "title": "Adversarial Perturbations Augmented Language Models for Euphemism Identification",
    "volume": "workshop",
    "abstract": "Euphemisms are mild words or expressions used instead of harsh or direct words while talking to someone to avoid discussing something unpleasant, embarrassing, or offensive. However, they are often ambiguous, thus making it a challenging task. The Third Workshop on Figurative Language Processing, colocated with EMNLP 2022 organized a shared task on Euphemism Detection to better understand euphemisms. We have used the adversarial augmentation technique to construct new data. This augmented data was then trained using two language models: BERT and longformer. To further enhance the overall performance, various combinations of the results obtained using longformer and BERT were passed through a voting ensembler. We achieved an F1 score of 71.5 using the combination of two adversarial longformers, two adversarial BERT, and one non-adversarial BERT",
    "checked": true,
    "id": "e301af8bf91b056a65b7659b6b72f271a8cb0630",
    "semantic_title": "adversarial perturbations augmented language models for euphemism identification",
    "citation_count": 1,
    "authors": [
      "Guneet Kohli",
      "Prabsimran Kaur",
      "Jatin Bedi"
    ]
  },
  "https://aclanthology.org/2022.flp-1.23": {
    "title": "FigurativeQA: A Test Benchmark for Figurativeness Comprehension for Question Answering",
    "volume": "workshop",
    "abstract": "Figurative language is widespread in human language (Lakoff and Johnson, 2008) posing potential challenges in NLP applications. In this paper, we investigate the effect of figurative language on the task of question answering (QA). We construct FigQA, a test set of 400 yes-no questions with figurative and non-figurative contexts, extracted from product reviews and restaurant reviews. We demonstrate that a state-of-the-art RoBERTa QA model has considerably lower performance in question answering when the contexts are figurative rather than literal, indicating a gap in current models. We propose a general method for improving the performance of QA models by converting the figurative contexts into non-figurative by prompting GPT-3, and demonstrate its effectiveness. Our results indicate a need for building QA models infused with figurative language understanding capabilities",
    "checked": true,
    "id": "c99a9fa1350ee9f5c2d7f8f860af538b2ed174f1",
    "semantic_title": "figurativeqa: a test benchmark for figurativeness comprehension for question answering",
    "citation_count": 0,
    "authors": [
      "Geetanjali Rakshit",
      "Jeffrey Flanigan"
    ]
  },
  "https://aclanthology.org/2022.flp-1.24": {
    "title": "Exploring Euphemism Detection in Few-Shot and Zero-Shot Settings",
    "volume": "workshop",
    "abstract": "This work builds upon the Euphemism Detection Shared Task proposed in the EMNLP 2022 FigLang Workshop, and extends it to few-shot and zero-shot settings. We demonstrate a few-shot and zero-shot formulation using the dataset from the shared task, and we conduct experiments in these settings using RoBERTa and GPT-3. Our results show that language models are able to classify euphemistic terms relatively well even on new terms unseen during training, indicating that it is able to capture higher-level concepts related to euphemisms",
    "checked": true,
    "id": "e757b93e7348c3a8d0bf276c9422729144d4e12c",
    "semantic_title": "exploring euphemism detection in few-shot and zero-shot settings",
    "citation_count": 3,
    "authors": [
      "Sedrick Scott Keh"
    ]
  },
  "https://aclanthology.org/2022.flp-1.25": {
    "title": "On the Cusp of Comprehensibility: Can Language Models Distinguish Between Metaphors and Nonsense?",
    "volume": "workshop",
    "abstract": "Utterly creative texts can sometimes be difficult to understand, balancing on the edge of comprehensibility. However, good language skills and common sense allow advanced language users both to interpret creative texts and to reject some linguistic input as nonsense. The goal of this paper is to evaluate whether the current language models are also able to make the distinction between a creative language use and nonsense. To test this, we have computed mean rank and pseudo-log-likelihood score (PLL) of metaphorical and nonsensical sentences, and fine-tuned several pretrained models (BERT, RoBERTa) for binary classification between the two categories. There was a significant difference in the mean ranks and PPL scores of the categories, and the classifier reached around 85.5% accuracy. The results raise further questions on what could have let to such satisfactory performance",
    "checked": true,
    "id": "eddda3013020949609ef93f45b855893e9cab093",
    "semantic_title": "on the cusp of comprehensibility: can language models distinguish between metaphors and nonsense?",
    "citation_count": 2,
    "authors": [
      "Bernadeta Griciūtė",
      "Marc Tanti",
      "Lucia Donatelli"
    ]
  },
  "https://aclanthology.org/2022.flp-1.26": {
    "title": "A Report on the FigLang 2022 Shared Task on Understanding Figurative Language",
    "volume": "workshop",
    "abstract": "We present the results of the Shared Task on Understanding Figurative Language that we conducted as a part of the 3rd Workshop on Figurative Language Processing (FigLang 2022) at EMNLP 2022. The shared task is based on the FLUTE dataset (Chakrabarty et al., 2022), which consists of NLI pairs containing figurative language along with free text explanations for each NLI instance. The task challenged participants to build models that are able to not only predict the right label for a figurative NLI instance, but also generate a convincing free-text explanation. The participants were able to significantly improve upon provided baselines in both automatic and human evaluation settings. We further summarize the submitted systems and discuss the evaluation results",
    "checked": true,
    "id": "1a8ed324961a01c83e505f47da7112b443c4fd8b",
    "semantic_title": "a report on the figlang 2022 shared task on understanding figurative language",
    "citation_count": 2,
    "authors": [
      "Arkadiy Saakyan",
      "Tuhin Chakrabarty",
      "Debanjan Ghosh",
      "Smaranda Muresan"
    ]
  },
  "https://aclanthology.org/2022.flp-1.27": {
    "title": "A Report on the Euphemisms Detection Shared Task",
    "volume": "workshop",
    "abstract": "This paper presents The Shared Task on Euphemism Detection for the Third Workshop on Figurative Language Processing (FigLang 2022) held in conjunction with EMNLP 2022. Participants were invited to investigate the euphemism detection task: given input text, identify whether it contains a euphemism. The input data is a corpus of sentences containing potentially euphemistic terms (PETs) collected from the GloWbE corpus, and are human-annotated as containing either a euphemistic or literal usage of a PET. In this paper, we present the results and analyze the common themes, methods and findings of the participating teams",
    "checked": true,
    "id": "6eb0f32f44b44ec5a5b9c140e01ea68483d8cfef",
    "semantic_title": "a report on the euphemisms detection shared task",
    "citation_count": 2,
    "authors": [
      "Patrick Lee",
      "Anna Feldman",
      "Jing Peng"
    ]
  },
  "https://aclanthology.org/2022.gem-1.1": {
    "title": "Improving abstractive summarization with energy-based re-ranking",
    "volume": "workshop",
    "abstract": "Current abstractive summarization systems present important weaknesses which prevent their deployment in real-world applications, such as the omission of relevant information and the generation of factual inconsistencies (also known as hallucinations). At the same time, automatic evaluation metrics such as CTC scores (Deng et al., 2021) have been recently proposed that exhibit a higher correlation with human judgments than traditional lexical-overlap metrics such as ROUGE. In this work, we intend to close the loop by leveraging the recent advances in summarization metrics to create quality-aware abstractive summarizers. Namely, we propose an energy-based model that learns to re-rank summaries according to one or a combination of these metrics. We experiment using several metrics to train our energy-based re-ranker and show that it consistently improves the scores achieved by the predicted summaries. Nonetheless, human evaluation results show that the re-ranking approach should be used with care for highly abstractive summaries, as the available metrics are not yet sufficiently reliable for this purpose",
    "checked": true,
    "id": "964340e00769d4c804239561af3e46c3e4581d03",
    "semantic_title": "improving abstractive summarization with energy-based re-ranking",
    "citation_count": 4,
    "authors": [
      "Diogo Pernes",
      "Afonso Mendes",
      "André F. T. Martins"
    ]
  },
  "https://aclanthology.org/2022.gem-1.2": {
    "title": "Task-driven augmented data evaluation",
    "volume": "workshop",
    "abstract": "In the area of data augmentation research, the main focus to date has been on the improvement of the generation models, while the examination and improvements to synthetic data evaluation methods remains less explored. In our work, we explore a number of sentence similarity measures in the context of data generation filtering, and evaluate their impact on the performance of the targeted Natural Language Understanding problem on the example of the intent classification and named entity recognition tasks. Our experiments on ATIS dataset show that the right choice of filtering technique can bring up to 33% in sentence accuracy improvement for targeted underrepresented intents",
    "checked": true,
    "id": "fd5ae3302a50df174b20a76823e7aba665be92ec",
    "semantic_title": "task-driven augmented data evaluation",
    "citation_count": 0,
    "authors": [
      "Olga Golovneva",
      "Pan Wei",
      "Khadige Abboud",
      "Charith Peris",
      "Lizhen Tan",
      "Haiyang Yu"
    ]
  },
  "https://aclanthology.org/2022.gem-1.3": {
    "title": "Generating Coherent Narratives with Subtopic Planning to Answer How-to Questions",
    "volume": "workshop",
    "abstract": "Answering how-to questions remains a major challenge in question answering research. A vast number of narrow, long-tail questions cannot be readily answered using a search engine. Moreover, there is little to no annotated data available to develop such systems. This paper makes a first attempt at generating coherent, long-form answers for how-to questions. We propose new architectures, consisting of passage retrieval, subtopic planning and narrative generation, to consolidate multiple relevant passages into a coherent, explanatory answer. Our subtopic planning module aims to produce a set of relevant, diverse subtopics that serve as the backbone for answer generation to improve topic coherence. We present extensive experiments on a WikiHow dataset repurposed for long-form question answering. Empirical results demonstrate that generating narratives to answer how-to questions is a challenging task. Nevertheless, our architecture incorporated with subtopic planning can produce high-quality, diverse narratives evaluated using automatic metrics and human assessment",
    "checked": true,
    "id": "fbf089606eac73d455a79fa45234466f52ffb52a",
    "semantic_title": "generating coherent narratives with subtopic planning to answer how-to questions",
    "citation_count": 3,
    "authors": [
      "Pengshan Cai",
      "Mo Yu",
      "Fei Liu",
      "Hong Yu"
    ]
  },
  "https://aclanthology.org/2022.gem-1.4": {
    "title": "Weakly Supervised Context-based Interview Question Generation",
    "volume": "workshop",
    "abstract": "We explore the task of automated generation of technical interview questions from a given textbook. Such questions are different from those for reading comprehension studied in question generation literature. We curate a context based interview questions data set for Machine Learning and Deep Learning from two popular textbooks. We first explore the possibility of using a large generative language model (GPT-3) for this task in a zero shot setting. We then evaluate the performance of smaller generative models such as BART fine-tuned on weakly supervised data obtained using GPT-3 and hand-crafted templates. We deploy an automatic question importance assignment technique to figure out suitability of a question in a technical interview. It improves the evaluation results in many dimensions. We dissect the performance of these models for this task and also scrutinize the suitability of questions generated by them for use in technical interviews",
    "checked": true,
    "id": "757feca0beaaf727a8ff985b90ad31bec33ab024",
    "semantic_title": "weakly supervised context-based interview question generation",
    "citation_count": 1,
    "authors": [
      "Samiran Pal",
      "Kaamraan Khan",
      "Avinash Kumar Singh",
      "Subhasish Ghosh",
      "Tapas Nayak",
      "Girish Palshikar",
      "Indrajit Bhattacharya"
    ]
  },
  "https://aclanthology.org/2022.gem-1.5": {
    "title": "Analyzing Multi-Task Learning for Abstractive Text Summarization",
    "volume": "workshop",
    "abstract": "Despite the recent success of multi-task learning and pre-finetuning for natural language understanding, few works have studied the effects of task families on abstractive text summarization. Task families are a form of task grouping during the pre-finetuning stage to learn common skills, such as reading comprehension. To close this gap, we analyze the influence of multi-task learning strategies using task families for the English abstractive text summarization task. We group tasks into one of three strategies, i.e., sequential, simultaneous, and continual multi-task learning, and evaluate trained models through two downstream tasks. We find that certain combinations of task families (e.g., advanced reading comprehension and natural language inference) positively impact downstream performance. Further, we find that choice and combinations of task families influence downstream performance more than the training scheme, supporting the use of task families for abstractive text",
    "checked": true,
    "id": "7633c8b7cd4209222d02c453184b480533a0e139",
    "semantic_title": "analyzing multi-task learning for abstractive text summarization",
    "citation_count": 4,
    "authors": [
      "Frederic Thomas Kirstein",
      "Jan Philip Wahle",
      "Terry Ruas",
      "Bela Gipp"
    ]
  },
  "https://aclanthology.org/2022.gem-1.6": {
    "title": "CLSE: Corpus of Linguistically Significant Entities",
    "volume": "workshop",
    "abstract": "One of the biggest challenges of natural language generation (NLG) is the proper handling of named entities. Named entities are a common source of grammar mistakes such as wrong prepositions, wrong article handling, or incorrect entity inflection. Without factoring linguistic representation, such errors are often underrepresented when evaluating on a small set of arbitrarily picked argument values, or when translating a dataset from a linguistically simpler language, like English, to a linguistically complex language, like Russian. However, for some applications, broadly precise grammatical correctness is critical – native speakers may find entity-related grammar errors silly, jarring, or even offensive. To enable the creation of more linguistically diverse NLG datasets, we release a Corpus of Linguistically Significant Entities (CLSE) annotated by linguist experts. The corpus includes 34 languages and covers 74 different semantic types to support various applications from airline ticketing to video games. To demonstrate one possible use of CLSE, we produce an augmented version of the Schema-Guided Dialog Dataset, SGD-CLSE. Using the CLSE's entities and a small number of human translations, we create a linguistically representative NLG evaluation benchmark in three languages: French (high-resource), Marathi (low-resource), and Russian (highly inflected language). We establish quality baselines for neural, template-based, and hybrid NLG systems and discuss the strengths and weaknesses of each approach",
    "checked": true,
    "id": "632d5072fd8f5a2ee190678ce4b5324460765b41",
    "semantic_title": "clse: corpus of linguistically significant entities",
    "citation_count": 1,
    "authors": [
      "Aleksandr Chuklin",
      "Justin Zhao",
      "Mihir Kale"
    ]
  },
  "https://aclanthology.org/2022.gem-1.7": {
    "title": "Revisiting text decomposition methods for NLI-based factuality scoring of summaries",
    "volume": "workshop",
    "abstract": "Scoring the factuality of a generated summary involves measuring the degree to which a target text contains factual information using the input document as support. Given the similarities in the problem formulation, previous work has shown that Natural Language Inference models can be effectively repurposed to perform this task. As these models are trained to score entailment at a sentence level, several recent studies have shown that decomposing either the input document or the summary into sentences helps with factuality scoring. But is fine-grained decomposition always a winning strategy? In this paper we systematically compare different granularities of decomposition - from document to sub-sentence level, and we show that the answer is no. Our results show that incorporating additional context can yield improvement, but that this does not necessarily apply to all datasets. We also show that small changes to previously proposed entailment-based scoring methods can result in better performance, highlighting the need for caution in model and methodology selection for downstream tasks",
    "checked": true,
    "id": "5e97969e3656e09dfbb879b1d448a24678289345",
    "semantic_title": "revisiting text decomposition methods for nli-based factuality scoring of summaries",
    "citation_count": 4,
    "authors": [
      "John Glover",
      "Federico Fancellu",
      "Vasudevan Jagannathan",
      "Matthew R. Gormley",
      "Thomas Schaaf"
    ]
  },
  "https://aclanthology.org/2022.gem-1.8": {
    "title": "Semantic Similarity as a Window into Vector- and Graph-Based Metrics",
    "volume": "workshop",
    "abstract": "In this work, we use sentence similarity as a lens through which to investigate the representation of meaning in graphs vs. vectors. On semantic textual similarity data, we examine how similarity metrics based on vectors alone (SENTENCE-BERT and BERTSCORE) fare compared to metrics based on AMR graphs (SMATCH and S2MATCH). Quantitative and qualitative analyses show that the AMR-based metrics can better capture meanings dependent on sentence structures, but can also be distracted by structural differences—whereas the BERT-based metrics represent finer-grained meanings of individual words, but often fail to capture the ordering effect of words within sentences and suffer from interpretability problems. These findings contribute to our understanding of each approach to semantic representation and motivate distinct use cases for graph and vector-based representations",
    "checked": true,
    "id": "ba8b3e12207ae6938d84d296dd766cfc03abac2a",
    "semantic_title": "semantic similarity as a window into vector- and graph-based metrics",
    "citation_count": 5,
    "authors": [
      "Wai Ching Leung",
      "Shira Wein",
      "Nathan Schneider"
    ]
  },
  "https://aclanthology.org/2022.gem-1.9": {
    "title": "Towards In-Context Non-Expert Evaluation of Reflection Generation for Counselling Conversations",
    "volume": "workshop",
    "abstract": "Reflection is an essential counselling strategy, where the therapist listens actively and responds with their own interpretation of the client's words. Recent work leveraged pre-trained language models (PLMs) to approach reflection generation as a promising tool to aid counsellor training. However, those studies used limited dialogue context for modelling and simplistic error analysis for human evaluation. In this work, we take the first step towards addressing those limitations. First, we fine-tune PLMs on longer dialogue contexts for reflection generation. Then, we collect free-text error descriptions from non-experts about generated reflections, identify common patterns among them, and accordingly establish discrete error categories using thematic analysis. Based on this scheme, we plan for future work a mass non-expert error annotation phase for generated reflections followed by an expert-based validation phase, namely \"whether a coherent and consistent response is a good reflection\"",
    "checked": true,
    "id": "fd22a98fbb5675e86d88a825448a611302dd41a9",
    "semantic_title": "towards in-context non-expert evaluation of reflection generation for counselling conversations",
    "citation_count": 2,
    "authors": [
      "Zixiu Wu",
      "Simone Balloccu",
      "Rim Helaoui",
      "Diego Reforgiato Recupero",
      "Daniele Riboni"
    ]
  },
  "https://aclanthology.org/2022.gem-1.10": {
    "title": "WikiOmnia: filtration and evaluation of the generated QA corpus on the whole Russian Wikipedia",
    "volume": "workshop",
    "abstract": "The General QA field has been developing the methodology referencing the Stanford Question answering dataset (SQuAD) as the significant benchmark. Compiling factual questions datasets requires manual annotations, limiting the training data's potential size. We present the WikiOmnia dataset, a new publicly available set of QA pairs and corresponding Russian Wikipedia article summary sections, composed with a fully automated generation and filtration pipeline. To ensure high quality of generated QA pairs, diverse manual and automated evaluation techniques were applied. The WikiOmnia pipeline is available open-source and is also tested for creating SQuAD-formatted QA on other domains, like news texts, fiction, and social media. The resulting dataset includes two parts: raw data on the whole Russian Wikipedia (7,930,873 QA pairs with paragraphs for ruGPT-3 XL and 7,991,040 QA pairs with paragraphs for ruT5-large) and cleaned data with strict automatic verification (over 160,000 QA pairs with paragraphs for ruGPT-3 XL and over 3,400,000 QA pairs with paragraphs for ruT5-large)",
    "checked": true,
    "id": "265d3e6c09816f744500924931aa977f0a8ba288",
    "semantic_title": "wikiomnia: filtration and evaluation of the generated qa corpus on the whole russian wikipedia",
    "citation_count": 0,
    "authors": [
      "Dina Pisarevskaya",
      "Tatiana Shavrina"
    ]
  },
  "https://aclanthology.org/2022.gem-1.12": {
    "title": "Evaluation of Response Generation Models: Shouldn't It Be Shareable and Replicable?",
    "volume": "workshop",
    "abstract": "Human Evaluation (HE) of automatically generated responses is necessary for the advancement of human-machine dialogue research. Current automatic evaluation measures are poor surrogates, at best. There are no agreed-upon HE protocols and it is difficult to develop them. As a result, researchers either perform non-replicable, non-transparent and inconsistent procedures or, worse, limit themselves to automated metrics. We propose to standardize the human evaluation of response generation models by publicly sharing a detailed protocol. The proposal includes the task design, annotators recruitment, task execution, and annotation reporting. Such protocol and process can be used as-is, as-a-whole, in-part, or modified and extended by the research community. We validate the protocol by evaluating two conversationally fine-tuned state-of-the-art models (GPT-2 and T5) for the complex task of personalized response generation. We invite the community to use this protocol - or its future community amended versions - as a transparent, replicable, and comparable approach to HE of generated responses",
    "checked": true,
    "id": "e1693c1430d3e0c60ec3af5c9b423770c5337fa7",
    "semantic_title": "evaluation of response generation models: shouldn't it be shareable and replicable?",
    "citation_count": 2,
    "authors": [
      "Seyed Mahed Mousavi",
      "Gabriel Roccabruna",
      "Michela Lorandi",
      "Simone Caldarella",
      "Giuseppe Riccardi"
    ]
  },
  "https://aclanthology.org/2022.gem-1.13": {
    "title": "Enhancing and Evaluating the Grammatical Framework Approach to Logic-to-Text Generation",
    "volume": "workshop",
    "abstract": "Logic-to-text generation is an important yet underrepresented area of natural language generation (NLG). In particular, most previous works on this topic lack sound evaluation. We address this limitation by building and evaluating a system that generates high-quality English text given a first-order logic (FOL) formula as input. We start by analyzing the performance of Ranta (2011)'s system. Based on this analysis, we develop an extended version of the system, which we name LoLa, that performs formula simplification based on logical equivalences and syntactic transformations. We carry out an extensive evaluation of LoLa using standard automatic metrics and human evaluation. We compare the results against a baseline and Ranta (2011)'s system. The results show that LoLa outperforms the other two systems in most aspects",
    "checked": true,
    "id": "16a3fba1528818e4b08f984aa984925429703023",
    "semantic_title": "enhancing and evaluating the grammatical framework approach to logic-to-text generation",
    "citation_count": 2,
    "authors": [
      "Eduardo Calò",
      "Elze van der Werf",
      "Albert Gatt",
      "Kees van Deemter"
    ]
  },
  "https://aclanthology.org/2022.gem-1.14": {
    "title": "Controllable Text Generation for All Ages: Evaluating a Plug-and-Play Approach to Age-Adapted Dialogue",
    "volume": "workshop",
    "abstract": "To be trusted and perceived as natural and coherent, conversational systems must adapt to the language of their users. While personalized dialogue is a promising direction, controlling generation for fine-grained language features remains a challenge in this approach. A recent line of research showed the effectiveness of leveraging pre-trained language models toward adapting to a text's topic or sentiment. In this study, we build on these approaches and focus on a higher-level dimension of language variation: speakers' age. We frame the task as a dialogue response generation, and test methods based on bag-of-words (BoW) and neural discriminators (Disc) to condition the output of GPT-2 and DialoGPT without altering the parameters of the language models. We show that Disc models achieve a higher degree of detectable control than BoW models based on automatic evaluation. In contrast, humans can partially detect age differences in BoW but not Disc responses. Since BoW responses are deemed better than Disc ones by humans, simple controllable methods thus appear to be a better tradeoff between adaptation and language quality. Our work confirms the challenges of adapting to higher-level dimensions of language variation. Moreover, it highlights the need to evaluate natural language generation thoroughly",
    "checked": true,
    "id": "2e356ea7afa13f39d80ed75a048f70b8c6512a9d",
    "semantic_title": "controllable text generation for all ages: evaluating a plug-and-play approach to age-adapted dialogue",
    "citation_count": 0,
    "authors": [
      "Lennert Jansen",
      "Štěpán Lars Laichter",
      "Arabella Sinclair",
      "Margot van der Goot",
      "Raquel Fernandez",
      "Sandro Pezzelle"
    ]
  },
  "https://aclanthology.org/2022.gem-1.15": {
    "title": "Template-based Contact Email Generation for Job Recommendation",
    "volume": "workshop",
    "abstract": "Text generation has long been a popular research topic in NLP. However, the task of generating contact emails from recruiters to candidates in the job recommendation scenario has received little attention by the research community. This work aims at defining the topic of automatic email generation for job recommendation, identifying the challenges, and providing a baseline template-based solution for Danish jobs. Evaluation by human experts shows that our method is effective. We wrap up by discussing the future research directions for better solving this task",
    "checked": true,
    "id": "89b10a64c26183e59ce04470df27f0cbf433bd55",
    "semantic_title": "template-based contact email generation for job recommendation",
    "citation_count": 0,
    "authors": [
      "Qiuchi Li",
      "Christina Lioma"
    ]
  },
  "https://aclanthology.org/2022.gem-1.17": {
    "title": "Are Abstractive Summarization Models truly ‘Abstractive'? An Empirical Study to Compare the two Forms of Summarization",
    "volume": "workshop",
    "abstract": "Automatic Text Summarization has seen a large paradigm shift from extractive methods to abstractive (or generation-based) methods in the last few years. This can be attributed to the availability of large autoregressive language models that have been shown to outperform extractive methods. In this work, we revisit extractive methods and study their performance against state of the art(SOTA) abstractive models. Through extensive studies, we notice that abstractive methods are not yet completely abstractive in their generated summaries. In addition to this finding, we propose an evaluation metric that could benefit the summarization research community to measure the degree of abstractiveness of a summary in comparison to their extractive counterparts. To confirm the generalizability of our findings, we conduct experiments on two summarization datasets using five powerful techniques in extractive and abstractive summarization and study their levels of abstraction",
    "checked": true,
    "id": "07eb238bd7e7ef3855030610bbe697206c9cae1f",
    "semantic_title": "are abstractive summarization models truly ‘abstractive'? an empirical study to compare the two forms of summarization",
    "citation_count": 0,
    "authors": [
      "Vinayshekhar Bannihatti Kumar",
      "Rashmi Gangadharaiah"
    ]
  },
  "https://aclanthology.org/2022.gem-1.18": {
    "title": "Transfer learning for multilingual vacancy text generation",
    "volume": "workshop",
    "abstract": "Writing job vacancies is a repetitive and expensive task for humans. This research focuses on automatically generating the benefit sections of vacancies at redacted from job attributes using mT5, the multilingual version of the state-of-the-art T5 transformer trained on general domains to generate texts in multiple languages. While transformers are accurate at generating coherent text, they are sometimes incorrect at including the structured data (the input) in the generated text. Including the input correctly is crucial for vacancy text generation; otherwise, the candidates may get misled. To evaluate how the model includes the input we developed our own domain-specific metrics (input generation accuracy). This was necessary, because Relation Generation, the pre-existing evaluation metric for data-to-text generation uses only string matching, which was not suitable for our dataset (due to the binary field). With the help of the new evaluation method we were able to measure how well the input is included in the generated text separately for different types of inputs (binary, categorical, numeric), offering another contribution to the field. Additionally, we also evaluated how accurate the mT5 model generates the text in the requested language. The results show that mT5 is very accurate at generating the text in the correct language, at including seen categorical inputs and binary values correctly in the generated text. However, mT5 performed worse when generating text from unseen city names or working with numeric inputs. Furthermore, we found that generating additional synthetic training data for the samples with numeric input can increase the input generation accuracy, however this only works when the numbers are integers and only cover a small range",
    "checked": true,
    "id": "bfb5ee16dd48d37e94e2169f07d4daa154a99a3b",
    "semantic_title": "transfer learning for multilingual vacancy text generation",
    "citation_count": 0,
    "authors": [
      "Anna Lorincz",
      "David Graus",
      "Dor Lavi",
      "Joao Lebre Magalhaes Pereira"
    ]
  },
  "https://aclanthology.org/2022.gem-1.19": {
    "title": "Plug-and-Play Recipe Generation with Content Planning",
    "volume": "workshop",
    "abstract": "Recent pre-trained language models have shown promising capability to generate fluent and realistic natural text. However, generating multi-sentence text with global content planning has been a long-existing research question. The current controlled text generation models cannot directly address this issue, as they usually condition on single known control attribute. We propose a low-cost yet effective framework that explicitly models content plans and optimizes the joint distribution of the natural sequence and the content plans in a plug-and-play post-processing manner. We evaluate our model with extensive automatic metrics and human evaluations and show that it achieves the state-of-the-art performance on the recipe generation task on Recipe1M+ dataset",
    "checked": true,
    "id": "0d22aec543f63c1617b83dbc859f2c4cce0f223a",
    "semantic_title": "plug-and-play recipe generation with content planning",
    "citation_count": 5,
    "authors": [
      "Yinhong Liu",
      "Yixuan Su",
      "Ehsan Shareghi",
      "Nigel Collier"
    ]
  },
  "https://aclanthology.org/2022.gem-1.20": {
    "title": "Towards Attribute-Entangled Controllable Text Generation: A Pilot Study of Blessing Generation",
    "volume": "workshop",
    "abstract": "Controllable Text Generation (CTG) has obtained great success due to its fine-grained generation ability obtained by focusing on multiple attributes. However, most existing CTG researches overlook how to utilize the attribute entanglement to enhance the diversity of the controlled generated texts. Facing this dilemma, we focus on a novel CTG scenario, i.e., blessing generation which is challenging because high-quality blessing texts require CTG models to comprehensively consider the entanglement between multiple attributes (e.g., objects and occasions). To promote the research on blessing generation, we present EBleT, a large-scale Entangled Blessing Text dataset containing 293K English sentences annotated with multiple attributes. Furthermore, we propose novel evaluation metrics to measure the quality of the blessing texts generated by the baseline models we designed. Our study opens a new research direction for controllable text generation and enables the development of attribute-entangled CTG models",
    "checked": true,
    "id": "9c12702ab3b4434e703d1a1086d3b636675c23d4",
    "semantic_title": "towards attribute-entangled controllable text generation: a pilot study of blessing generation",
    "citation_count": 4,
    "authors": [
      "Shulin Huang",
      "Shirong Ma",
      "Yinghui Li",
      "Li Yangning",
      "Shiyang Lin",
      "Haitao Zheng",
      "Ying Shen"
    ]
  },
  "https://aclanthology.org/2022.gem-1.21": {
    "title": "Unsupervised Token-level Hallucination Detection from Summary Generation By-products",
    "volume": "workshop",
    "abstract": "Hallucinations in abstractive summarization are model generations that are unfaithful to the source document. Current methods for detecting hallucinations operate mostly on noun phrases and named entities, and restrict themselves to the XSum dataset, which is known to have hallucinations in 3 out of 4 training examples (Maynez et al., 2020). We instead consider the CNN/DailyMail dataset where the summarization model has not seen abnormally many hallucinations during training. We automatically detect candidate hallucinations at the token level, irrespective of its part of speech. Our detection comes essentially for free, as we only use information the model already produces during generation of the summary. This enables practitioners to jointly generate a summary and identify possible hallucinations, with minimal overhead. We repurpose an existing factuality dataset and create our own token-level annotations. The evaluation on these two datasets shows that our model achieves better precision-recall tradeoffs than its competitors, which additionally require a model forward pass",
    "checked": true,
    "id": "34304715249d677d388c3bde02c278b7130d625d",
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andreas Marfurt",
      "James Henderson"
    ]
  },
  "https://aclanthology.org/2022.gem-1.22": {
    "title": "A Corpus and Evaluation for Predicting Semi-Structured Human Annotations",
    "volume": "workshop",
    "abstract": "A wide variety of tasks have been framed as text-to-text tasks to allow processing by sequence-to-sequence models. We propose a new task of generating a semi-structured interpretation of a source document. The interpretation is semi-structured in that it contains mandatory and optional fields with free-text information. This structure is surfaced by human annotations, which we standardize and convert to text format. We then propose an evaluation technique that is generally applicable to any such semi-structured annotation, called equivalence classes evaluation. The evaluation technique is efficient and scalable; it creates a large number of evaluation instances from a comparably cheap clustering of the free-text information by domain experts. For our task, we release a dataset about the monetary policy of the Federal Reserve. On this corpus, our evaluation shows larger differences between pretrained models than standard text generation metrics",
    "checked": true,
    "id": "a6145d4a2ec0a1a158d8e85eafb65e750f048fba",
    "semantic_title": "a corpus and evaluation for predicting semi-structured human annotations",
    "citation_count": 0,
    "authors": [
      "Andreas Marfurt",
      "Ashley Thornton",
      "David Sylvan",
      "Lonneke van der Plas",
      "James Henderson"
    ]
  },
  "https://aclanthology.org/2022.gem-1.23": {
    "title": "T5QL: Taming language models for SQL generation",
    "volume": "workshop",
    "abstract": "Automatic SQL generation has been an active research area, aiming at streamlining the access to databases by writing natural language with the given intent instead of writing SQL. Current SOTA methods for semantic parsing depend on LLMs to achieve high predictive accuracy on benchmark datasets. This reduces their applicability, since LLMs requires expensive GPUs. Furthermore, SOTA methods are ungrounded and thus not guaranteed to always generate valid SQL. Here we propose T5QL, a new SQL generation method that improves the performance in benchmark datasets when using smaller LMs, namely T5-Base, by 13pp when compared against SOTA methods. Additionally, T5QL is guaranteed to always output valid SQL using a context-free grammar to constrain SQL generation. Finally, we show that dividing semantic parsing in two tasks, candidate SQLs generation and candidate re-ranking, is a promising research avenue that can reduce the need for large LMs",
    "checked": true,
    "id": "885676b8a05437868f7b83c134a99f991190a1de",
    "semantic_title": "t5ql: taming language models for sql generation",
    "citation_count": 4,
    "authors": [
      "Samuel David Arcadinho",
      "David Aparicio",
      "Hugo Veiga",
      "Antonio Alegria"
    ]
  },
  "https://aclanthology.org/2022.gem-1.24": {
    "title": "Human perceiving behavior modeling in evaluation of code generation models",
    "volume": "workshop",
    "abstract": "Within this study, we evaluated a series of code generation models based on CodeGen and GPTNeo to compare the metric-based performance and human evaluation. For a deeper analysis of human perceiving within the evaluation procedure we've implemented a 5-level Likert scale assessment of the model output using a perceiving model based on the Theory of Planned Behavior (TPB). Through such analysis, we showed an extension of model assessment as well as a deeper understanding of the quality and applicability of generated code for practical question answering. The approach was evaluated with several model settings in order to assess diversity in quality and style of answer. With the TPB-based model, we showed a different level of perceiving the model result, namely personal understanding, agreement level, and readiness to use the particular code. With such analysis, we investigate a series of issues in code generation as natural language generation (NLG) problems observed in a practical context of programming question-answering with code",
    "checked": true,
    "id": "e772bf6ad9b87a333291f427d328e24cc57f23a1",
    "semantic_title": "human perceiving behavior modeling in evaluation of code generation models",
    "citation_count": 3,
    "authors": [
      "Sergey V. Kovalchuk",
      "Vadim Lomshakov",
      "Artem Aliev"
    ]
  },
  "https://aclanthology.org/2022.gem-1.25": {
    "title": "Nearest Neighbor Language Models for Stylistic Controllable Generation",
    "volume": "workshop",
    "abstract": "Recent language modeling performance has been greatly improved by the use of external memory. This memory encodes the context so that similar contexts can be recalled during decoding. This similarity depends on how the model learns to encode context, which can be altered to include other attributes, such as style. We construct and evaluate an architecture for this purpose, using corpora annotated for politeness, formality, and toxicity. Through extensive experiments and human evaluation we demonstrate the potential of our method to generate text while controlling style. We find that style-specific datastores improve generation performance, though results vary greatly across styles, and the effect of pretraining data and specific styles should be explored in future work",
    "checked": true,
    "id": "54abaf3108b7ca92e829f6797d5e73264c2350c1",
    "semantic_title": "nearest neighbor language models for stylistic controllable generation",
    "citation_count": 4,
    "authors": [
      "Severino Trotta",
      "Lucie Flek",
      "Charles Welch"
    ]
  },
  "https://aclanthology.org/2022.gem-1.26": {
    "title": "On reporting scores and agreement for error annotation tasks",
    "volume": "workshop",
    "abstract": "This work examines different ways of aggregating scores for error annotation in MT outputs: raw error counts, error counts normalised over total number of words (word percentage'), and error counts normalised over total number of errors (error percentage'). We use each of these three scores to calculate inter-annotator agreement in the form of Krippendorff's alpha and Pearson's r and compare the obtained numbers, overall and separately for different types of errors. While each score has its advantages depending on the goal of the evaluation, we argue that the best way of estimating inter-annotator agreement using such numbers are raw counts. If the annotation process ensures that the total number of words cannot differ among the annotators (for example, due to adding omission symbols), normalising over number of words will lead to the same conclusions. In contrast, total number of errors is very subjective because different annotators often perceive different amount of errors in the same text, therefore normalising over this number can indicate lower agreements",
    "checked": true,
    "id": "cc37b51cd9013fd335803e6e418f6c216366faf6",
    "semantic_title": "on reporting scores and agreement for error annotation tasks",
    "citation_count": 2,
    "authors": [
      "Maja Popović",
      "Anya Belz"
    ]
  },
  "https://aclanthology.org/2022.gem-1.27": {
    "title": "Answerability: A custom metric for evaluating chatbot performance",
    "volume": "workshop",
    "abstract": "Most commercial conversational AI products in domains spanning e-commerce, health care, finance, and education involve a hierarchy of NLP models that perform a variety of tasks such as classification, entity recognition, question-answering, sentiment detection, semantic text similarity, and so on. Despite our understanding of each of the constituent models, we do not have a clear view as to how these models affect the overall platform metrics. To bridge this gap, we define a metric known as answerability, which penalizes not only irrelevant or incorrect chatbot responses but also unhelpful responses that do not serve the chatbot's purpose despite being correct or relevant. Additionally, we describe a formula-based mathematical framework to relate individual model metrics to the answerability metric. We also describe a modeling approach for predicting a chatbot's answerability to a user question and its corresponding chatbot response",
    "checked": true,
    "id": "10a5a8932d5b811be017f255744444a9001b4ae4",
    "semantic_title": "answerability: a custom metric for evaluating chatbot performance",
    "citation_count": 0,
    "authors": [
      "Pranav Gupta",
      "Anand A. Rajasekar",
      "Amisha Patel",
      "Mandar Kulkarni",
      "Alexander Sunell",
      "Kyung Kim",
      "Krishnan Ganapathy",
      "Anusua Trivedi"
    ]
  },
  "https://aclanthology.org/2022.gem-1.28": {
    "title": "Improved Evaluation of Automatic Source Code Summarisation",
    "volume": "workshop",
    "abstract": "Source code summaries are a vital tool for the understanding and maintenance of source code as they can be used to explain code in simple terms. However, source code with missing, incorrect, or outdated summaries is a common occurrence in production code. Automatic source code summarisation seeks to solve these issues by generating up-to-date summaries of source code methods. Recent work in automatically generating source code summaries uses neural networks for generating summaries; commonly Sequence-to-Sequence or Transformer models, pretrained on method-summary pairs. The most common method of evaluating the quality of these summaries is comparing the machine-generated summaries against human-written summaries. Summaries can be evaluated using n-gram-based translation metrics such as BLEU, METEOR, or ROUGE-L. However, these metrics alone can be unreliable and new Natural Language Generation metrics based on large pretrained language models provide an alternative. In this paper, we propose a method of improving the evaluation of a model by improving the preprocessing of the data used to train it, as well as proposing evaluating the model with a metric based off a language model, pretrained on a Natural Language (English) alongside traditional metrics. Our evaluation suggests our model has been improved by cleaning and preprocessing the data used in model training. The addition of a pretrained language model metric alongside traditional metrics shows that both produce results which can be used to evaluate neural source code summarisation",
    "checked": true,
    "id": "5a3a1bd49d53ea39f0faba9d7688fefcb6df595d",
    "semantic_title": "improved evaluation of automatic source code summarisation",
    "citation_count": 2,
    "authors": [
      "Jesse Phillips",
      "David Bowes",
      "Mahmoud El-Haj",
      "Tracy Hall"
    ]
  },
  "https://aclanthology.org/2022.gem-1.29": {
    "title": "Most NLG is Low-Resource: here's what we can do about it",
    "volume": "workshop",
    "abstract": "Many domains and tasks in natural language generation (NLG) are inherently ‘low-resource', where training data, tools and linguistic analyses are scarce. This poses a particular challenge to researchers and system developers in the era of machine-learning-driven NLG. In this position paper, we initially present the challenges researchers & developers often encounter when dealing with low-resource settings in NLG. We then argue that it is unsustainable to collect large aligned datasets or build large language models from scratch for every possible domain due to cost, labour, and time constraints, so researching and developing methods and resources for low-resource settings is vital. We then discuss current approaches to low-resource NLG, followed by proposed solutions and promising avenues for future work in NLG for low-resource settings",
    "checked": true,
    "id": "b680f7a3a8e5a71f48b127432b2a04ac697b0592",
    "semantic_title": "most nlg is low-resource: here's what we can do about it",
    "citation_count": 2,
    "authors": [
      "David M. Howcroft",
      "Dimitra Gkatzia"
    ]
  },
  "https://aclanthology.org/2022.gem-1.30": {
    "title": "GiCCS: A German in-Context Conversational Similarity Benchmark",
    "volume": "workshop",
    "abstract": "The Semantic textual similarity (STS) task is commonly used to evaluate the semantic representations that language models (LMs) learn from texts, under the assumption that good-quality representations will yield accurate similarity estimates. When it comes to estimating the similarity of two utterances in a dialogue, however, the conversational context plays a particularly important role. We argue for the need of benchmarks specifically created using conversational data in order to evaluate conversational LMs in the STS task. We introduce GiCCS, a first conversational STS evaluation benchmark for German. We collected the similarity annotations for GiCCS using best-worst scaling and presenting the target items in context, in order to obtain highly-reliable context-dependent similarity scores. We present benchmarking experiments for evaluating LMs on capturing the similarity of utterances. Results suggest that pretraining LMs on conversational data and providing conversational context can be useful for capturing similarity of utterances in dialogues. GiCCS will be publicly available to encourage benchmarking of conversational LMs",
    "checked": true,
    "id": "f4bfb0a79421383ac689297a7b905bf736e8c723",
    "semantic_title": "giccs: a german in-context conversational similarity benchmark",
    "citation_count": 0,
    "authors": [
      "Shima Asaadi",
      "Zahra Kolagar",
      "Alina Liebel",
      "Alessandra Zarcone"
    ]
  },
  "https://aclanthology.org/2022.gem-1.31": {
    "title": "Control Prefixes for Parameter-Efficient Text Generation",
    "volume": "workshop",
    "abstract": "Prefix-tuning is a parameter-efficient and powerful technique for adapting a pre-trained language model to a downstream application. However, it uses the same dataset-level tuned set of parameters for all examples in the dataset. We extend the framework with a dynamic method, Control Prefixes, which allows for the effective inclusion of input-dependent information, thereby demonstrating how prefix-tuning can be used for controlled text generation tasks. The method incorporates attribute-level learnable representations into different layers of a pre-trained Transformer, enabling the generated text to be guided in a particular direction. We provide a systematic evaluation of the technique and apply it to five datasets from the GEM benchmark for natural language generation (NLG). Using only 0.1–2% additional trainable parameters, we show Control Prefixes can even outperform full fine-tuning methods, and present state-of-the-art results on several data-to-text datasets, including WebNLG. We also examine the common case where input-dependent information is unavailable at test time and show Control Prefixes can excel in this setting also",
    "checked": true,
    "id": "ab2a3676353acb9f403913a6ee2a7dddb49d6726",
    "semantic_title": "control prefixes for parameter-efficient text generation",
    "citation_count": 20,
    "authors": [
      "Jordan Clive",
      "Kris Cao",
      "Marek Rei"
    ]
  },
  "https://aclanthology.org/2022.gem-1.33": {
    "title": "A Survey of Recent Error Annotation Schemes for Automatically Generated Text",
    "volume": "workshop",
    "abstract": "While automatically computing numerical scores remains the dominant paradigm in NLP system evaluation, error analysis is receiving increasing attention, with numerous error annotation schemes being proposed for automatically generated text. However, there is little agreement about what error annotation schemes should look like, how many different types of errors should be distinguished and at what level of granularity. In this paper, our aim is to map out recent work on annotating errors in automatically generated text, with a particular focus on error taxonomies. We describe our systematic paper selection process, and survey the error annotation schemes reported in the papers, drawing out similarities and differences between them. Finally, we characterise the issues that would make it difficult to move from the current situation to a standardised error taxonomy for annotating errors in automatically generated text",
    "checked": true,
    "id": "57d36ce9957f94b0a61807161cdfcf19f11967ee",
    "semantic_title": "a survey of recent error annotation schemes for automatically generated text",
    "citation_count": 3,
    "authors": [
      "Rudali Huidrom",
      "Anya Belz"
    ]
  },
  "https://aclanthology.org/2022.gem-1.34": {
    "title": "What's in a (dataset's) name? The case of BigPatent",
    "volume": "workshop",
    "abstract": "Sharing datasets and benchmarks has been crucial for rapidly improving Natural Language Processing models and systems. Documenting datasets' characteristics (and any modification introduced over time) is equally important to avoid confusion and make comparisons reliable. Here, we describe the case of BigPatent, a dataset for patent summarization that exists in at least two rather different versions under the same name. While previous literature has not clearly distinguished among versions, their differences do not only lay on a surface level but also modify the dataset's core nature and, thus, the complexity of the summarization task. While this paper describes a specific case, we aim to shed light on new challenges that might emerge in resource sharing and advocate for comprehensive documentation of datasets and models",
    "checked": true,
    "id": "c8c3fcaca276c3ed5eecbcb0736ae5b9cc809f3b",
    "semantic_title": "what's in a (dataset's) name? the case of bigpatent",
    "citation_count": 1,
    "authors": [
      "Silvia Casola",
      "Alberto Lavelli",
      "Horacio Saggion"
    ]
  },
  "https://aclanthology.org/2022.gem-1.35": {
    "title": "Measuring the Measuring Tools: An Automatic Evaluation of Semantic Metrics for Text Corpora",
    "volume": "workshop",
    "abstract": "Similarity metrics for text corpora are becoming critical due to the tremendous growth in the number of generative models. These similarity metrics measure the semantic gap between human and machine-generated text on the corpus level. However, standard methods for evaluating the characteristics of these metrics have yet to be established. We propose a set of automatic measures for evaluating the characteristics of semantic similarity metrics for text corpora. Our measures allow us to sensibly compare and identify the strengths and weaknesses of these metrics. We demonstrate the effectiveness of our evaluation measures in capturing fundamental characteristics by comparing it to a collection of classical and state-of-the-art metrics. Our measures revealed that recent metrics are becoming better in identifying semantic distributional mismatch while classical metrics are more sensitive to perturbations in the surface text levels",
    "checked": true,
    "id": "1e179f9c36b5edfc9879fb34d232afee91b9da9f",
    "semantic_title": "measuring the measuring tools: an automatic evaluation of semantic metrics for text corpora",
    "citation_count": 5,
    "authors": [
      "George Kour",
      "Samuel Ackerman",
      "Eitan Daniel Farchi",
      "Orna Raz",
      "Boaz Carmeli",
      "Ateret Anaby Tavor"
    ]
  },
  "https://aclanthology.org/2022.gem-1.39": {
    "title": "Multilingual Social Media Text Generation and Evaluation with Few-Shot Prompting",
    "volume": "workshop",
    "abstract": "This work adapts large language models to generate multilingual social media text that meets several objectives simultaneously: topic relevance, author style consistency, and reply validity. Leveraging existing online information behavior simulators, which currently only forecast activities but not content, our approach comprised of generalizable prompt formation and efficient evaluation to produce a believable, personalized, and responsive synthetic social network. According to some preliminary experiments, our multi-objective prompt formation and automatic evaluation/selection methods are able to yield a significant number of high-quality synthetic texts according to both standardized and trained metrics",
    "checked": true,
    "id": "36731d3f9809535d5f57cc5cd610d92428a50716",
    "semantic_title": "multilingual social media text generation and evaluation with few-shot prompting",
    "citation_count": 0,
    "authors": [
      "Mack Blackburn"
    ]
  },
  "https://aclanthology.org/2022.gem-1.40": {
    "title": "Assessing Inter-metric Correlation for Multi-document Summarization Evaluation",
    "volume": "workshop",
    "abstract": "Recent advances in automatic text summarization have contemporaneously been accompanied by a great deal of new metrics of automatic evaluation. This in turn has inspired recent research to re-assess these evaluation metrics to see how well they correlate with each other as well as with human evaluation, mostly focusing on single-document summarization (SDS) tasks. Although many of these metrics are typically also used for evaluating multi-document summarization (MDS) tasks, so far, little attention has been paid to studying them under such a distinct scenario. To address this gap, we present a systematic analysis of the inter-metric correlations for MDS tasks, while comparing and contrasting the results with SDS models. Using datasets from a wide range of domains (news, peer reviews, tweets, dialogues), we thus study a unified set of metrics under both the task setups. Our empirical analysis suggests that while most reference-based metrics show fairly similar trends across both multi- and single-document summarization, there is a notable lack of correlation between reference-free metrics in multi-document summarization tasks",
    "checked": true,
    "id": "69c120355fdcdce1628446cd2da02686b4e678d4",
    "semantic_title": "assessing inter-metric correlation for multi-document summarization evaluation",
    "citation_count": 0,
    "authors": [
      "Michael Ridenour",
      "Ameeta Agrawal",
      "Olubusayo Olabisi"
    ]
  },
  "https://aclanthology.org/2022.gem-1.41": {
    "title": "Factual Error Correction for Abstractive Summaries Using Entity Retrieval",
    "volume": "workshop",
    "abstract": "Despite the recent advancements in abstractive summarization systems leveraged from large-scale datasets and pre-trained language models, the factual correctness of the summary is still insufficient. One line of trials to mitigate this problem is to include a post-editing process that can detect and correct factual errors in the summary. In building such a system, it is strongly required that 1) the process has a high success rate and interpretability and 2) it has a fast running time. Previous approaches focus on the regeneration of the summary, resulting in low interpretability and high computing resources. In this paper, we propose an efficient factual error correction system RFEC based on entity retrieval. RFEC first retrieves the evidence sentences from the original document by comparing the sentences with the target summary to reduce the length of the text to analyze. Next, RFEC detects entity-level errors in the summaries using the evidence sentences and substitutes the wrong entities with the accurate entities from the evidence sentences. Experimental results show that our proposed error correction system shows more competitive performance than baseline methods in correcting factual errors with a much faster speed",
    "checked": true,
    "id": "884349ca84ea87b82f4ce8ae37b2c9631a42fd90",
    "semantic_title": "factual error correction for abstractive summaries using entity retrieval",
    "citation_count": 10,
    "authors": [
      "Hwanhee Lee",
      "Cheoneum Park",
      "Seunghyun Yoon",
      "Trung Bui",
      "Franck Dernoncourt",
      "Juae Kim",
      "Kyomin Jung"
    ]
  },
  "https://aclanthology.org/2022.gem-1.42": {
    "title": "Coherent Long Text Generation by Contrastive Soft Prompt",
    "volume": "workshop",
    "abstract": "Improving the coherence of long text generation is an important but challenging task. Existing models still struggle to generate a logical and coherent sentence sequence. It is difficult for a model to plan long text generation and avoid generating incoherent texts from a high-level semantic perspective. We speculate that this is due to two factors: (1) current training methods mainly rely on maximum likelihood estimation computed from token-level probability prediction; (2) the role of incoherent texts has been largely under-explored, thus the noised generated texts with errors are out-of-distribution for the model. To address these issues, in this paper, we propose a Contrastive Soft Prompt (CSP) model for improving the coherence of long text generation. It learns text representations in the hidden space for better planning long text generation. To this end, it jointly learns to generate a text representation close to representations of coherent texts and away from incoherent ones, and then generate long text taking this representation as the soft prompt. We conduct experiments on two public story generation datasets, and experiment results show that our method can generate more coherent stories than the state-of-the-art model",
    "checked": true,
    "id": "4dc3683fa223d160045bca575a8b5ecf94f61604",
    "semantic_title": "coherent long text generation by contrastive soft prompt",
    "citation_count": 1,
    "authors": [
      "Guandan Chen",
      "Jiashu Pu",
      "Yadong Xi",
      "Rongsheng Zhang"
    ]
  },
  "https://aclanthology.org/2022.gem-1.43": {
    "title": "Error Analysis of ToTTo Table-to-Text Neural NLG Models",
    "volume": "workshop",
    "abstract": "We report error analysis of outputs from seven Table-to-Text generation models fine-tuned on ToTTo, an open-domain English language dataset. A manual error annotation of a subset of outputs (a total of 5,278 sentences) belonging to the topic of Politics generated by these seven models has been carried out. Our error annotation focused on eight categories of errors. The error analysis shows that more than 45% of sentences from each of the seven models have been error-free. It uncovered some of the specific classes of errors such as WORD errors that are the dominant errors in all the seven models, NAME and NUMBER errors are more committed by two of the GeM benchmark models, whereas DATE-DIMENSION and OTHER category of errors are more common in our Table-to-Text models",
    "checked": true,
    "id": "a0bd30c49e444d9fbf827e74ef5fcb04c5768dbe",
    "semantic_title": "error analysis of totto table-to-text neural nlg models",
    "citation_count": 0,
    "authors": [
      "Barkavi Sundararajan",
      "Somayajulu Sripada",
      "Ehud Reiter"
    ]
  },
  "https://aclanthology.org/2022.gem-1.44": {
    "title": "Improving Dialogue Act Recognition with Augmented Data",
    "volume": "workshop",
    "abstract": "We present our work on augmenting dialog act recognition capabilities utilizing synthetically generated data. Our work is motivated by the limitations of current dialog act datasets, and the need to adapt for new domains as well as ambiguity in utterances written by humans. We list our observations and findings towards how synthetically generated data can contribute meaningfully towards more robust dialogue act recognition models extending to new domains. Our major finding shows that synthetic data, which is linguistically varied, can be very useful towards this goal and increase the performance from (0.39, 0.16) to (0.85, 0.88) for AFFIRM and NEGATE dialog acts respectively",
    "checked": true,
    "id": "2a39e4af484a94a25437866f90799810ff1b7eaa",
    "semantic_title": "improving dialogue act recognition with augmented data",
    "citation_count": 0,
    "authors": [
      "Khyati Mahajan",
      "Soham Parikh",
      "Quaizar Vohra",
      "Mitul Tiwari",
      "Samira Shaikh"
    ]
  },
  "https://aclanthology.org/2022.gem-1.45": {
    "title": "Do Decoding Algorithms Capture Discourse Structure in Multi-Modal Tasks? A Case Study of Image Paragraph Generation",
    "volume": "workshop",
    "abstract": "This paper describes insights into how different inference algorithms structure discourse in image paragraphs. We train a multi-modal transformer and compare 11 variations of decoding algorithms. We propose to evaluate image paragraphs not only with standard automatic metrics, but also with a more extensive, \"under the hood\" analysis of the discourse formed by sentences. Our results show that while decoding algorithms can be unfaithful to the reference texts, they still generate grounded descriptions, but they also lack understanding of the discourse structure and differ from humans in terms of attentional structure over images",
    "checked": true,
    "id": "fc7dd995e9c43641d12ea5d93f88ec07a81cfd4f",
    "semantic_title": "do decoding algorithms capture discourse structure in multi-modal tasks? a case study of image paragraph generation",
    "citation_count": 1,
    "authors": [
      "Nikolai Ilinykh",
      "Simon Dobnik"
    ]
  },
  "https://aclanthology.org/2022.gem-1.46": {
    "title": "20Q: Overlap-Free World Knowledge Benchmark for Language Models",
    "volume": "workshop",
    "abstract": "What do language models know about our world? This question is hard to answer but important to get right. To this end, we introduce 20Q, a novel benchmark using the Twenty Questions game to evaluate world knowledge and common sense of language models. Thanks to our overlap-free benchmark, language models learn the game of Twenty Questions without learning relevant knowledge for the test set. We uncover two intuitive factors influencing the world knowledge of language models: the size of the model and the topic frequency in the pre-training data. Moreover, we show that in-context learning is inefficient for evaluating language models' world knowledge — fine-tuning is necessary to show their true capabilities. Lastly, our results show room for improvement to enhance the world knowledge and common sense of large language models. A potential solution would be to up-sample unfrequent topics in the pre-training of language models",
    "checked": true,
    "id": "9cd0cb3af7c2215eae9afdcf500a2bcd5330aae3",
    "semantic_title": "20q: overlap-free world knowledge benchmark for language models",
    "citation_count": 1,
    "authors": [
      "Maxime De Bruyn",
      "Ehsan Lotfi",
      "Jeska Buhmann",
      "Walter Daelemans"
    ]
  },
  "https://aclanthology.org/2022.gem-1.47": {
    "title": "What Was Your Name Again? Interrogating Generative Conversational Models For Factual Consistency Evaluation",
    "volume": "workshop",
    "abstract": "Generative conversational agents are known to suffer from problems like inconsistency and hallucination, and a big challenge in studying these issues remains evaluation: they are not properly reflected in common text generation metrics like perplexity or BLEU, and alternative implicit methods like semantic similarity or NLI labels can be misguided when few specific tokens are decisive. In this work we propose ConsisTest; a factual consistency benchmark including both WH and Y/N questions based on PersonaChat, along with a hybrid evaluation pipeline which aims to get the best of symbolic and sub-symbolic methods. Using these and focusing on pretrained generative models like BART, we provide detailed statistics and analysis on how the model's consistency is affected by variations in question and context",
    "checked": true,
    "id": "63583423eb12e37170fc9d87e36563fae076aabf",
    "semantic_title": "what was your name again? interrogating generative conversational models for factual consistency evaluation",
    "citation_count": 0,
    "authors": [
      "Ehsan Lotfi",
      "Maxime De Bruyn",
      "Jeska Buhmann",
      "Walter Daelemans"
    ]
  },
  "https://aclanthology.org/2022.gem-1.48": {
    "title": "Narrative Why-Question Answering: A Review of Challenges and Datasets",
    "volume": "workshop",
    "abstract": "Narrative Why-Question Answering is an important task to assess the causal reasoning ability of systems in narrative settings. Further progress in this domain needs clear identification of challenges related to understanding the causal structure of narration. In this paper, we give an overview of the challenges related to both narrative understanding and why-question answering, because Narrative Why-Question Answering combines the characteristics of these domains. We also identify narrative QA datasets containing why-questions and analyze their characteristics through the lens of these challenges",
    "checked": true,
    "id": "98f4b43487b8386728c14aba24f848b2eadad1e2",
    "semantic_title": "narrative why-question answering: a review of challenges and datasets",
    "citation_count": 3,
    "authors": [
      "Emil Kalbaliyev",
      "Kairit Sirts"
    ]
  },
  "https://aclanthology.org/2022.gem-1.49": {
    "title": "Exploring a POS-based Two-stage Approach for Improving Low-Resource AMR-to-Text Generation",
    "volume": "workshop",
    "abstract": "This work presents a two-stage approach for tackling low-resource AMR-to-text generation for Brazilian Portuguese. Our approach consists of (1) generating a masked surface realization in which some tokens are masked according to its Part-of-Speech class and (2) infilling the masked tokens according to the AMR graph and the previous masked surface realization. Results show a slight improvement over the baseline, mainly in BLEU (1.63) and METEOR (0.02) scores. Moreover, we evaluate the pipeline components separately, showing that the bottleneck of the pipeline is the masked surface realization. Finally, the human evaluation suggests that models still suffer from hallucinations, and some strategies to deal with the problems found are proposed",
    "checked": true,
    "id": "de9a408a9c252ae7c8f749393a42320b74c5377e",
    "semantic_title": "exploring a pos-based two-stage approach for improving low-resource amr-to-text generation",
    "citation_count": 1,
    "authors": [
      "Marco Antonio Sobrevilla Cabezudo",
      "Thiago Pardo"
    ]
  },
  "https://aclanthology.org/2022.gem-1.50": {
    "title": "What Makes Data-to-Text Generation Hard for Pretrained Language Models?",
    "volume": "workshop",
    "abstract": "Expressing natural language descriptions of structured facts or relations – data-to-text generation (D2T) – increases the accessibility of structured knowledge repositories. Previous work shows that pre-trained language models (PLMs) perform remarkably well on this task after fine-tuning on a significant amount of task-specific training data. On the other hand, while auto-regressive PLMs can generalize from a few task examples, their efficacy at D2T is largely unexplored. Furthermore, we have an incomplete understanding of the limits of PLMs on D2T. In this work, we conduct an empirical study of both fine-tuned and auto-regressive PLMs on the DART multi-domain D2T dataset. We consider their performance as a function of the amount of task-specific data and how the data is incorporated into the models: zero and few-shot learning, and fine-tuning of model weights. In addition, we probe the limits of PLMs by measuring performance on subsets of the evaluation data: novel predicates and abstractive test examples. To improve the performance on these subsets, we investigate two techniques: providing predicate descriptions in the context and re-ranking generated candidates by information reflected in the source. Finally, we conduct a human evaluation of model errors and show that D2T generation tasks would benefit from datasets with more careful manual curation",
    "checked": true,
    "id": "1b2bf55e8432c2d42bc94c2abb868ff3bb23f175",
    "semantic_title": "what makes data-to-text generation hard for pretrained language models?",
    "citation_count": 7,
    "authors": [
      "Moniba Keymanesh",
      "Adrian Benton",
      "Mark Dredze"
    ]
  },
  "https://aclanthology.org/2022.gem-1.51": {
    "title": "Don't Say What You Don't Know: Improving the Consistency of Abstractive Summarization by Constraining Beam Search",
    "volume": "workshop",
    "abstract": "Abstractive summarization systems today produce fluent and relevant output, but often \"hallucinate\" statements not supported by the source text. We analyze the connection between hallucinations and training data, and find evidence that models hallucinate because they train on target summaries that are unsupported by the source. Based on our findings, we present PINOCCHIO, a new decoding method that improves the consistency of a transformer-based abstractive summarizer by constraining beam search to avoid hallucinations. Given the model states and outputs at a given step, PINOCCHIO detects likely model hallucinations based on various measures of attribution to the source text. PINOCCHIO backtracks to find more consistent output, and can opt to produce no summary at all when no consistent generation can be found. In experiments, we find that PINOCCHIO improves the consistency of generation by an average of 67% on two abstractive summarization datasets, without hurting recall",
    "checked": true,
    "id": "879080effb3846368de4ae22570f85329e77e96f",
    "semantic_title": "don't say what you don't know: improving the consistency of abstractive summarization by constraining beam search",
    "citation_count": 22,
    "authors": [
      "Daniel King",
      "Zejiang Shen",
      "Nishant Subramani",
      "Daniel S. Weld",
      "Iz Beltagy",
      "Doug Downey"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.1": {
    "title": "Exploring the Influence of Dialog Input Format for Unsupervised Clinical Questionnaire Filling",
    "volume": "workshop",
    "abstract": "In the medical field, we have seen the emergence of health-bots that interact with patients to gather data and track their state. One of the downstream application is automatic questionnaire filling, where the content of the dialog is used to automatically fill a pre-defined medical questionnaire. Previous work has shown that answering questions from the dialog context can successfully be cast as a Natural Language Inference (NLI) task and therefore benefit from current pre-trained NLI models. However, NLI models have mostly been trained on text rather than dialogs, which may have an influence on their performance. In this paper, we study the influence of content transformation and content selection on the questionnaire filling task. Our results demonstrate that dialog pre-processing can significantly improve the performance of zero-shot questionnaire filling models which take health-bots dialogs as input",
    "checked": true,
    "id": "39b050e29109e7648383f66ad24481f69dd706f3",
    "semantic_title": "exploring the influence of dialog input format for unsupervised clinical questionnaire filling",
    "citation_count": 0,
    "authors": [
      "Farnaz Ghassemi Toudeshki",
      "Anna Liednikova",
      "Philippe Jolivet",
      "Claire Gardent"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.2": {
    "title": "Assessing the Limits of Straightforward Models for Nested Named Entity Recognition in Spanish Clinical Narratives",
    "volume": "workshop",
    "abstract": "Nested Named Entity Recognition (NER) is an information extraction task that aims to identify entities that may be nested within other entity mentions. Despite the availability of several corpora with nested entities in the Spanish clinical domain, most previous work has overlooked them due to the lack of models and a clear annotation scheme for dealing with the task. To fill this gap, this paper provides an empirical study of straightforward methods for tackling the nested NER task on two Spanish clinical datasets, Clinical Trials, and the Chilean Waiting List. We assess the advantages and limitations of two sequence labeling approaches; one based on Multiple LSTM-CRF architectures and another on Joint labeling models. To better understand the differences between these models, we compute task-specific metrics that adequately measure the ability of models to detect nested entities and perform a fine-grained comparison across models. Our experimental results show that employing domain-specific language models trained from scratch significantly improves the performance obtained with strong domain-specific and general-domain baselines, achieving state-of-the-art results in both datasets. Specifically, we obtained F1 scores of 89.21 and 83.16 in Clinical Trials and the Chilean Waiting List, respectively. Interestingly enough, we observe that the task-specific metrics and analysis properly reflect the limitations of the models when recognizing nested entities. Finally, we perform a case study on an aggregated NER dataset created from several clinical corpora in Spanish. We highlight how entity length and the simultaneous recognition of inner and outer entities are the most critical variables for the nested NER task",
    "checked": true,
    "id": "daaf82b3469bee2d884359eaa0d824c9bd8a5f1c",
    "semantic_title": "assessing the limits of straightforward models for nested named entity recognition in spanish clinical narratives",
    "citation_count": 1,
    "authors": [
      "Matias Rojas",
      "Casimiro Pio Carrino",
      "Aitor Gonzalez-Agirre",
      "Jocelyn Dunstan",
      "Marta Villegas"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.3": {
    "title": "Can Current Explainability Help Provide References in Clinical Notes to Support Humans Annotate Medical Codes?",
    "volume": "workshop",
    "abstract": "The medical codes prediction problem from clinical notes has received substantial interest in the NLP community, and several recent studies have shown the state-of-the-art (SOTA) code prediction results of full-fledged deep learning-based methods. However, most previous SOTA works based on deep learning are still in early stages in terms of providing textual references and explanations of the predicted codes, despite the fact that this level of explainability of the prediction outcomes is critical to gaining trust from professional medical coders. This raises the important question of how well current explainability methods apply to advanced neural network models such as transformers to predict correct codes and present references in clinical notes that support code prediction. First, we present an explainable Read, Attend, and Code (xRAC) framework and assess two approaches, attention score-based xRAC-ATTN and model-agnostic knowledge-distillation-based xRAC-KD, through simplified but thorough human-grounded evaluations with SOTA transformer-based model, RAC. We find that the supporting evidence text highlighted by xRAC-ATTN is of higher quality than xRAC-KD whereas xRAC-KD has potential advantages in production deployment scenarios. More importantly, we show for the first time that, given the current state of explainability methodologies, using the SOTA medical codes prediction system still requires the expertise and competencies of professional coders, even though its prediction accuracy is superior to that of human coders. This, we believe, is a very meaningful step toward developing explainable and accurate machine learning systems for fully autonomous medical code prediction from clinical notes",
    "checked": true,
    "id": "7fd508693a19aebd2ad053b3a79648ef09096702",
    "semantic_title": "can current explainability help provide references in clinical notes to support humans annotate medical codes?",
    "citation_count": 4,
    "authors": [
      "Byung-Hak Kim",
      "Zhongfen Deng",
      "Philip Yu",
      "Varun Ganapathi"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.4": {
    "title": "Distinguishing between focus and background entities in biomedical corpora using discourse structure and transformers",
    "volume": "workshop",
    "abstract": "Scientific documents typically contain numerous entity mentions, while only a subset are directly relevant to the key contributions of the paper. Distinguishing these focus entities from background ones effectively could improve the recovery of relevant documents and the extraction of information from documents. To study the identification of focus entities, we developed two large datasets of disease-causing biological pathogens using MEDLINE, the largest collection of biomedical citations, and PubMed Central, a collection of full text articles. The focus entities were identified using human-curated indexing on these collections. Experiments with machine learning methods to identify focus entities show that transformer methods achieve high precision and recall and that document discourse information is relevant. The work lays the foundation for more targeted retrieval/summarisation of entity-relevant documents",
    "checked": true,
    "id": "b88b56dfe6e9e6407926b07334f56e04bd0858d0",
    "semantic_title": "distinguishing between focus and background entities in biomedical corpora using discourse structure and transformers",
    "citation_count": 1,
    "authors": [
      "Antonio Jimeno Yepes",
      "Karin Verspoor"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.5": {
    "title": "FrenchMedMCQA: A French Multiple-Choice Question Answering Dataset for Medical domain",
    "volume": "workshop",
    "abstract": "This paper introduces FrenchMedMCQA, the first publicly available Multiple-Choice Question Answering (MCQA) dataset in French for medical domain. It is composed of 3,105 questions taken from real exams of the French medical specialization diploma in pharmacy, mixing single and multiple answers. Each instance of the dataset contains an identifier, a question, five possible answers and their manual correction(s). We also propose first baseline models to automatically process this MCQA task in order to report on the current performances and to highlight the difficulty of the task. A detailed analysis of the results showed that it is necessary to have representations adapted to the medical domain or to the MCQA task: in our case, English specialized models yielded better results than generic French ones, even though FrenchMedMCQA is in French. Corpus, models and tools are available online",
    "checked": true,
    "id": "4ce68478791bd4cfcdf883d75fa31fc1ebc6c7cc",
    "semantic_title": "frenchmedmcqa: a french multiple-choice question answering dataset for medical domain",
    "citation_count": 14,
    "authors": [
      "Yanis Labrak",
      "Adrien Bazoge",
      "Richard Dufour",
      "Beatrice Daille",
      "Pierre-Antoine Gourraud",
      "Emmanuel Morin",
      "Mickael Rouvier"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.6": {
    "title": "A Large-Scale Dataset for Biomedical Keyphrase Generation",
    "volume": "workshop",
    "abstract": "Keyphrase generation is the task consisting in generating a set of words or phrases that highlight the main topics of a document. There are few datasets for keyphrase generation in the biomedical domain and they do not meet the expectations in terms of size for training generative models. In this paper, we introduce kp-biomed, the first large-scale biomedical keyphrase generation dataset collected from PubMed abstracts. We train and release several generative models and conduct a series of experiments showing that using large scale datasets improves significantly the performances for present and absent keyphrase generation. The dataset and models are available online",
    "checked": true,
    "id": "7426b421af6b89ddb7065a2254514b368d8a8d6e",
    "semantic_title": "a large-scale dataset for biomedical keyphrase generation",
    "citation_count": 1,
    "authors": [
      "Maël Houbre",
      "Florian Boudin",
      "Beatrice Daille"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.7": {
    "title": "Section Classification in Clinical Notes with Multi-task Transformers",
    "volume": "workshop",
    "abstract": "Clinical notes are the backbone of electronic health records, often containing vital information not observed in other structured data. Unfortunately, the unstructured nature of clinical notes can lead to critical patient-related information being lost. Algorithms that organize clinical notes into distinct sections are often proposed in order to allow medical professionals to better access information in a given note. These algorithms, however, often assume a given partition over the note, and classify section types given this information. In this paper, we propose a multi-task solution for note sectioning, where a single model identifies context changes and labels each section with its medically-relevant title. Results on in-distribution (MIMIC-III) and out-of-distribution (private held-out) datasets reveal that our approach successfully identifies note sections across different hospital systems",
    "checked": true,
    "id": "891c1667436c82eaad61044664920292be4ccf7f",
    "semantic_title": "section classification in clinical notes with multi-task transformers",
    "citation_count": 4,
    "authors": [
      "Fan Zhang",
      "Itay Laish",
      "Ayelet Benjamini",
      "Amir Feder"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.8": {
    "title": "Building a Clinically-Focused Problem List From Medical Notes",
    "volume": "workshop",
    "abstract": "Clinical notes often contain useful information not documented in structured data, but their unstructured nature can lead to critical patient-related information being missed. To increase the likelihood that this valuable information is utilized for patient care, algorithms that summarize notes into a problem list have been proposed. Focused on identifying medically-relevant entities in the free-form text, these solutions are often detached from a canonical ontology and do not allow downstream use of the detected text-spans. Mitigating these issues, we present here a system for generating a canonical problem list from medical notes, consisting of two major stages. At the first stage, annotation, we use a transformer model to detect all clinical conditions which are mentioned in a single note. These clinical conditions are then grounded to a predefined ontology, and are linked to spans in the text. At the second stage, summarization, we develop a novel algorithm that aggregates over the set of clinical conditions detected on all of the patient's notes, and produce a concise patient summary that organizes their most important conditions",
    "checked": true,
    "id": "8aecf983fd2dbf64455502b02fb71a0fb5193e89",
    "semantic_title": "building a clinically-focused problem list from medical notes",
    "citation_count": 3,
    "authors": [
      "Amir Feder",
      "Itay Laish",
      "Shashank Agarwal",
      "Uri Lerner",
      "Avel Atias",
      "Cathy Cheung",
      "Peter Clardy",
      "Alon Peled-Cohen",
      "Rachana Fellinger",
      "Hengrui Liu",
      "Lan Huong Nguyen",
      "Birju Patel",
      "Natan Potikha",
      "Amir Taubenfeld",
      "Liwen Xu",
      "Seung Doo Yang",
      "Ayelet Benjamini",
      "Avinatan Hassidim"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.9": {
    "title": "Specializing Static and Contextual Embeddings in the Medical Domain Using Knowledge Graphs: Let's Keep It Simple",
    "volume": "workshop",
    "abstract": "Domain adaptation of word embeddings has mainly been explored in the context of retraining general models on large specialized corpora. While this usually yields good results, we argue that knowledge graphs, which are used less frequently, could also be utilized to enhance existing representations with specialized knowledge. In this work, we aim to shed some light on whether such knowledge injection could be achieved using a basic set of tools: graph-level embeddings and concatenation. To that end, we adopt an incremental approach where we first demonstrate that static embeddings can indeed be improved through concatenation with in-domain node2vec representations. Then, we validate this approach on contextual models and generalize it further by proposing a variant of BERT that incorporates knowledge embeddings within its hidden states through the same process of concatenation. We show that this variant outperforms plain retraining on several specialized tasks, then discuss how this simple approach could be improved further. Both our code and pre-trained models are open-sourced for future research. In this work, we conduct experiments that target the medical domain and the English language",
    "checked": true,
    "id": "adcde6469455b854d50282fe0115128616d11ed1",
    "semantic_title": "specializing static and contextual embeddings in the medical domain using knowledge graphs: let's keep it simple",
    "citation_count": 2,
    "authors": [
      "Hicham El Boukkouri",
      "Olivier Ferret",
      "Thomas Lavergne",
      "Pierre Zweigenbaum"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.10": {
    "title": "BioSimCSE: BioMedical Sentence Embeddings using Contrastive learning",
    "volume": "workshop",
    "abstract": "Sentence embeddings in the form of fixed-size vectors that capture the information in the sentence as well as the context are critical components of Natural Language Processing systems. With transformer model based sentence encoders outperforming the other sentence embedding methods in the general domain, we explore the transformer based architectures to generate dense sentence embeddings in the biomedical domain. In this work, we present BioSimCSE, where we train sentence embeddings with domain specific transformer based models with biomedical texts. We assess our model's performance with zero-shot and fine-tuned settings on Semantic Textual Similarity (STS) and Recognizing Question Entailment (RQE) tasks. Our BioSimCSE model using BioLinkBERT achieves state of the art (SOTA) performance on both tasks",
    "checked": true,
    "id": "19d2ab1d475ed281530b1d99f59473bd480b08d5",
    "semantic_title": "biosimcse: biomedical sentence embeddings using contrastive learning",
    "citation_count": 4,
    "authors": [
      "Kamal raj Kanakarajan",
      "Bhuvana Kundumani",
      "Abhijith Abraham",
      "Malaikannan Sankarasubbu"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.11": {
    "title": "Proxy-based Zero-Shot Entity Linking by Effective Candidate Retrieval",
    "volume": "workshop",
    "abstract": "A recent advancement in the domain of biomedical Entity Linking is the development of powerful two-stage algorithms – an initial candidate retrieval stage that generates a shortlist of entities for each mention, followed by a candidate ranking stage. However, the effectiveness of both stages are inextricably dependent on computationally expensive components. Specifically, in candidate retrieval via dense representation retrieval it is important to have hard negative samples, which require repeated forward passes and nearest neighbour searches across the entire entity label set throughout training. In this work, we show that pairing a proxy-based metric learning loss with an adversarial regularizer provides an efficient alternative to hard negative sampling in the candidate retrieval stage. In particular, we show competitive performance on the recall@1 metric, thereby providing the option to leave out the expensive candidate ranking step. Finally, we demonstrate how the model can be used in a zero-shot setting to discover out of knowledge base biomedical entities",
    "checked": true,
    "id": "a0b8294241038f95777dc8ecf43e927cb36e68dd",
    "semantic_title": "proxy-based zero-shot entity linking by effective candidate retrieval",
    "citation_count": 1,
    "authors": [
      "Maciej Wiatrak",
      "Eirini Arvaniti",
      "Angus Brayne",
      "Jonas Vetterle",
      "Aaron Sim"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.12": {
    "title": "BERT for Long Documents: A Case Study of Automated ICD Coding",
    "volume": "workshop",
    "abstract": "Transformer models have achieved great success across many NLP problems. However, previous studies in automated ICD coding concluded that these models fail to outperform some of the earlier solutions such as CNN-based models. In this paper we challenge this conclusion. We present a simple and scalable method to process long text with the existing transformer models such as BERT. We show that this method significantly improves the previous results reported for transformer models in ICD coding, and is able to outperform one of the prominent CNN-based methods",
    "checked": true,
    "id": "28980fd125402febec34913ed9540a70e55888c2",
    "semantic_title": "bert for long documents: a case study of automated icd coding",
    "citation_count": 5,
    "authors": [
      "Arash Afkanpour",
      "Shabir Adeel",
      "Hansenclever Bassani",
      "Arkady Epshteyn",
      "Hongbo Fan",
      "Isaac Jones",
      "Mahan Malihi",
      "Adrian Nauth",
      "Raj Sinha",
      "Sanjana Woonna",
      "Shiva Zamani",
      "Elli Kanal",
      "Mikhail Fomitchev",
      "Donny Cheung"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.13": {
    "title": "Parameter Efficient Transfer Learning for Suicide Attempt and Ideation Detection",
    "volume": "workshop",
    "abstract": "Pre-trained language models (LMs) have been deployed as the state-of-the-art natural language processing (NLP) approaches for multiple clinical applications. Model generalisability is important in clinical domain due to the low available resources. In this study, we evaluated transfer learning techniques for an important clinical application: detecting suicide attempt (SA) and suicide ideation (SI) in electronic health records (EHRs). Using the annotation guideline provided by the authors of ScAN, we annotated two EHR datasets from different hospitals. We then fine-tuned ScANER, a publicly available SA and SI detection model, to evaluate five different parameter efficient transfer learning techniques, such as adapter-based learning and soft-prompt tuning, on the two datasets. Without any fine-tuning, ScANER achieve macro F1-scores of 0.85 and 0.87 for SA and SI evidence detection across the two datasets. We observed that by fine-tuning less than ~2% of ScANER's parameters, we were able to further improve the macro F1-score for SA-SI evidence detection by 3% and 5% for the two EHR datasets. Our results show that parameter-efficient transfer learning methods can help improve the performance of publicly available clinical models on new hospital datasets with few annotations",
    "checked": true,
    "id": "298038faf569e9feb71c1441d43a8168b0113b35",
    "semantic_title": "parameter efficient transfer learning for suicide attempt and ideation detection",
    "citation_count": 0,
    "authors": [
      "Bhanu Pratap Singh Rawat",
      "Hong Yu"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.14": {
    "title": "Automatic Patient Note Assessment without Strong Supervision",
    "volume": "workshop",
    "abstract": "Training of physicians requires significant practice writing patient notes that document the patient's medical and health information and physician diagnostic reasoning. Assessment and feedback of the patient note requires experienced faculty, consumes significant amounts of time and delays feedback to learners. Grading patient notes is thus a tedious and expensive process for humans that could be improved with the addition of natural language processing. However, the large manual effort required to create labeled datasets increases the challenge, particularly when test cases change. Therefore, traditional supervised NLP methods relying on labelled datasets are impractical in such a low-resource scenario. In our work, we proposed an unsupervised framework as a simple baseline and a weakly supervised method utilizing transfer learning for automatic assessment of patient notes under a low-resource scenario. Experiments on our self-collected datasets show that our weakly-supervised methods could provide reliable assessment for patient notes with accuracy of 0.92",
    "checked": true,
    "id": "a93e2844cf119e56ee010dd27323beb941c7d291",
    "semantic_title": "automatic patient note assessment without strong supervision",
    "citation_count": 3,
    "authors": [
      "Jianing Zhou",
      "Vyom Nayan Thakkar",
      "Rachel Yudkowsky",
      "Suma Bhat",
      "William F. Bond"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.15": {
    "title": "DDI-MuG: Multi-aspect Graphs for Drug-Drug Interaction Extraction",
    "volume": "workshop",
    "abstract": "Drug-drug interaction (DDI) may leads to adverse reactions in patients, thus it is important to extract such knowledge from biomedical texts. However, previously proposed approaches typically focus on capturing sentence-aspect information while ignoring valuable knowledge concerning the whole corpus. In this paper, we propose a Multi-aspect Graph-based DDI extraction model, named DDI-MuG. We first employ a bio-specific pre-trained language model to obtain the token contextualized representations. Then we use two graphs to get syntactic information from input instance and word co-occurrence information within the entire corpus, respectively. Finally, we combine the representations of drug entities and verb tokens for the final classification. It is encouraging to see that the proposed model outperforms all baseline models on two benchmark datasets. To the best of our knowledge, this is the first model that explores multi-aspect graphs to the DDI extraction task, and we hope it can establish a foundation for more robust multi-aspect works in the future",
    "checked": true,
    "id": "89cbb16aea55469e56a7b5051196e14055511a00",
    "semantic_title": "ddi-mug: multi-aspect graphs for drug-drug interaction extraction",
    "citation_count": 2,
    "authors": [
      "Jie Yang",
      "Yihao Ding",
      "Siqu Long",
      "Josiah Poon",
      "Soyeon Caren Han"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.16": {
    "title": "Divide and Conquer: An Extreme Multi-Label Classification Approach for Coding Diseases and Procedures in Spanish",
    "volume": "workshop",
    "abstract": "Clinical coding is the task of transforming medical documents into structured codes following a standard ontology. Since these terminologies are composed of hundreds of codes, this problem can be considered an Extreme Multi-label Classification task. This paper proposes a novel neural network-based architecture for clinical coding. First, we take full advantage of the hierarchical nature of ontologies to create clusters based on semantic relations. Then, we use a Matcher module to assign the probability of documents belonging to each cluster. Finally, the Ranker calculates the probability of each code considering only the documents in the cluster. This division allows a fine-grained differentiation within the cluster, which cannot be addressed using a single classifier. In addition, since most of the previous work has focused on solving this task in English, we conducted our experiments on three clinical coding corpora in Spanish. The experimental results demonstrate the effectiveness of our model, achieving state-of-the-art results on two of the three datasets. Specifically, we outperformed previous models on two subtasks of the CodiEsp shared task: CodiEsp-D (diseases) and CodiEsp-P (procedures). Automatic coding can profoundly impact healthcare by structuring critical information written in free text in electronic health records",
    "checked": true,
    "id": "3460d4e0967d848e4398ba06800db6db420fbb69",
    "semantic_title": "divide and conquer: an extreme multi-label classification approach for coding diseases and procedures in spanish",
    "citation_count": 4,
    "authors": [
      "Jose Barros",
      "Matias Rojas",
      "Jocelyn Dunstan",
      "Andres Abeliuk"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.17": {
    "title": "Curriculum-guided Abstractive Summarization for Mental Health Online Posts",
    "volume": "workshop",
    "abstract": "Automatically generating short summaries from users' online mental health posts could save counselors' reading time and reduce their fatigue so that they can provide timely responses to those seeking help for improving their mental state. Recent Transformers-based summarization models have presented a promising approach to abstractive summarization. They go beyond sentence selection and extractive strategies to deal with more complicated tasks such as novel word generation and sentence paraphrasing. Nonetheless, these models have a prominent shortcoming; their training strategy is not quite efficient, which restricts the model's performance. In this paper, we include a curriculum learning approach to reweigh the training samples, bringing about an efficient learning procedure. We apply our model on extreme summarization dataset of MentSum posts —-a dataset of mental health related posts from Reddit social media. Compared to the state-of-the-art model, our proposed method makes substantial gains in terms of Rouge and Bertscore evaluation metrics, yielding 3.5% Rouge-1, 10.4% Rouge-2, and 4.7% Rouge-L, 1.5% Bertscore relative improvements",
    "checked": true,
    "id": "f1648eaec9f329a5dbbff49f14d0b3f31f163155",
    "semantic_title": "curriculum-guided abstractive summarization for mental health online posts",
    "citation_count": 1,
    "authors": [
      "Sajad Sotudeh",
      "Nazli Goharian",
      "Hanieh Deilamsalehy",
      "Franck Dernoncourt"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.18": {
    "title": "Improving information fusion on multimodal clinical data in classification settings",
    "volume": "workshop",
    "abstract": "Clinical data often exists in different forms across the lifetime of a patient's interaction with the healthcare system - structured, unstructured or semi-structured data in the form of laboratory readings, clinical notes, diagnostic codes, imaging and audio data of various kinds, and other observational data. Formulating a representation model that aggregates information from these heterogeneous sources may allow us to jointly model on data with more predictive signal than noise and help inform our model with useful constraints learned from better data. Multimodal fusion approaches help produce representations combined from heterogeneous modalities, which can be used for clinical prediction tasks. Representations produced through different fusion techniques require different training strategies. We investigate the advantage of adding narrative clinical text to structured modalities to classification tasks in the clinical domain. We show that while there is a competitive advantage in combined representations of clinical data, the approach can be helped by training guidance customized to each modality. We show empirical results across binary/multiclass settings, single/multitask settings and unified/multimodal learning rate settings for early and late information fusion of clinical data",
    "checked": true,
    "id": "3b956eda4a225e938b6c5038a7b21de1bcd19a29",
    "semantic_title": "improving information fusion on multimodal clinical data in classification settings",
    "citation_count": 0,
    "authors": [
      "Sneha Jha",
      "Erik Mayer",
      "Mauricio Barahona"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.19": {
    "title": "How Long Is Enough? Exploring the Optimal Intervals of Long-Range Clinical Note Language Modeling",
    "volume": "workshop",
    "abstract": "Large pre-trained language models (LMs) have been widely adopted in biomedical and clinical domains, introducing many powerful LMs such as bio-lm and BioELECTRA. However, the applicability of these methods to real clinical use cases is hindered, due to the limitation of pre-trained LMs in processing long textual data with thousands of words, which is a common length for a clinical note. In this work, we explore long-range adaptation from such LMs with Longformer, allowing the LMs to capture longer clinical notes context. We conduct experiments on three n2c2 challenges datasets and a longitudinal clinical dataset from Hong Kong Hospital Authority electronic health record (EHR) system to show the effectiveness and generalizability of this concept, achieving ~10% F1-score improvement. Based on our experiments, we conclude that capturing a longer clinical note interval is beneficial to the model performance, but there are different cut-off intervals to achieve the optimal performance for different target variables",
    "checked": true,
    "id": "5cc2001af252e89b106b2ecb781270cc36f2b408",
    "semantic_title": "how long is enough? exploring the optimal intervals of long-range clinical note language modeling",
    "citation_count": 2,
    "authors": [
      "Samuel Cahyawijaya",
      "Bryan Wilie",
      "Holy Lovenia",
      "Huan Zhong",
      "MingQian Zhong",
      "Yuk-Yu Nancy Ip",
      "Pascale Fung"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.20": {
    "title": "A Quantitative and Qualitative Analysis of Schizophrenia Language",
    "volume": "workshop",
    "abstract": "Schizophrenia is one of the most disabling mental health conditions to live with. Approximately one percent of the population has schizophrenia which makes it fairly common, and it affects many people and their families. Patients with schizophrenia suffer different symptoms: formal thought disorder (FTD), delusions, and emotional flatness. In this paper, we quantitatively and qualitatively analyze the language of patients with schizophrenia measuring various linguistic features in two modalities: speech and written text. We examine the following features: coherence and cohesion of thoughts, emotions, specificity, level of commit- ted belief (LCB), and personality traits. Our results show that patients with schizophrenia score high in fear and neuroticism compared to healthy controls. In addition, they are more committed to their beliefs, and their writing lacks details. They score lower in most of the linguistic features of cohesion with significant p-values",
    "checked": true,
    "id": "1ec9b27ae7b94b8d46a75b056a40448b44e35ea7",
    "semantic_title": "a quantitative and qualitative analysis of schizophrenia language",
    "citation_count": 3,
    "authors": [
      "Amal Alqahtani",
      "Efsun Sarioglu Kayi",
      "Sardar Hamidian",
      "Michael Compton",
      "Mona Diab"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.21": {
    "title": "Exploring Hybrid and Ensemble Models for Multiclass Prediction of Mental Health Status on Social Media",
    "volume": "workshop",
    "abstract": "In recent years, there has been a surge of interest in research on automatic mental health detection (MHD) from social media data leveraging advances in natural language processing and machine learning techniques. While significant progress has been achieved in this interdisciplinary research area, the vast majority of work has treated MHD as a binary classification task. The multiclass classification setup is, however, essential if we are to uncover the subtle differences among the statistical patterns of language use associated with particular mental health conditions. Here, we report on experiments aimed at predicting six conditions (anxiety, attention deficit hyperactivity disorder, bipolar disorder, post-traumatic stress disorder, depression, and psychological stress) from Reddit social media posts. We explore and compare the performance of hybrid and ensemble models leveraging transformer-based architectures (BERT and RoBERTa) and BiLSTM neural networks trained on within-text distributions of a diverse set of linguistic features. This set encompasses measures of syntactic complexity, lexical sophistication and diversity, readability, and register-specific ngram frequencies, as well as sentiment and emotion lexicons. In addition, we conduct feature ablation experiments to investigate which types of features are most indicative of particular mental health conditions",
    "checked": true,
    "id": "99abc027b166eb989d0ff3b36e8183bce0f59d2b",
    "semantic_title": "exploring hybrid and ensemble models for multiclass prediction of mental health status on social media",
    "citation_count": 2,
    "authors": [
      "Sourabh Zanwar",
      "Daniel Wiechmann",
      "Yu Qiao",
      "Elma Kerz"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.22": {
    "title": "A Knowledge-Graph-Based Intrinsic Test for Benchmarking Medical Concept Embeddings and Pretrained Language Models",
    "volume": "workshop",
    "abstract": "Using language models created from large data sources has improved the performance of several deep learning-based architectures, obtaining state-of-the-art results in several NLP extrinsic tasks. However, little research is related to creating intrinsic tests that allow us to compare the quality of different language models when obtaining contextualized embeddings. This gap increases even more when working on specific domains in languages other than English. This paper proposes a novel graph-based intrinsic test that allows us to measure the quality of different language models in clinical and biomedical domains in Spanish. Our results show that our intrinsic test performs better for clinical and biomedical language models than a general one. Also, it correlates with better outcomes for a NER task using a probing model over contextualized embeddings. We hope our work will help the clinical NLP research community to evaluate and compare new language models in other languages and find the most suitable models for solving downstream tasks",
    "checked": true,
    "id": "ca81c16d1f82702ded74e3b6b0a469339fe9b16f",
    "semantic_title": "a knowledge-graph-based intrinsic test for benchmarking medical concept embeddings and pretrained language models",
    "citation_count": 4,
    "authors": [
      "Claudio Aracena",
      "Fabián Villena",
      "Matias Rojas",
      "Jocelyn Dunstan"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.23": {
    "title": "Enriching Deep Learning with Frame Semantics for Empathy Classification in Medical Narrative Essays",
    "volume": "workshop",
    "abstract": "Empathy is a vital component of health care and plays a key role in the training of future doctors. Paying attention to medical students' self-reflective stories of their interactions with patients can encourage empathy and the formation of professional identities that embody desirable values such as integrity and respect. We present a computational approach and linguistic analysis of empathic language in a large corpus of 440 essays written by pre-med students as narrated simulated patient – doctor interactions. We analyze the discourse of three kinds of empathy: cognitive, affective, and prosocial as highlighted by expert annotators. We also present various experiments with state-of-the-art recurrent neural networks and transformer models for classifying these forms of empathy. To further improve over these results, we develop a novel system architecture that makes use of frame semantics to enrich our state-of-the-art models. We show that this novel framework leads to significant improvement on the empathy classification task for this dataset",
    "checked": true,
    "id": "698e2b87c3b9746c99d0d228de57fdb9f12e30e4",
    "semantic_title": "enriching deep learning with frame semantics for empathy classification in medical narrative essays",
    "citation_count": 4,
    "authors": [
      "Priyanka Dey",
      "Roxana Girju"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.24": {
    "title": "Condition-Treatment Relation Extraction on Disease-related Social Media Data",
    "volume": "workshop",
    "abstract": "Social media has become a popular platform where people share information about personal healthcare conditions, diagnostic histories, and medical plans. Analyzing posts on social media depicting such realistic information can help improve quality and clinical decision-making; however, the lack of structured resources in this genre limits us to build robust NLP models for meaningful analysis. This paper presents a new corpus annotating relations among many types of conditions, treatments, and their attributes illustrated in social media posts by patients and caregivers. For experiments, a transformer encoder is pretrained on 1M raw posts and used to train several document-level relation extraction models using our corpus. Our best-performing model achieves the F1 scores of 70.9 and 51.7 for Entity Recognition and Relation Extraction, respectively. These results are encouraging as it is the first neural model extracting complex relations of this kind on social media data",
    "checked": true,
    "id": "0cea216f7b82a7394942dae04d061d4c5843c866",
    "semantic_title": "condition-treatment relation extraction on disease-related social media data",
    "citation_count": 1,
    "authors": [
      "Sichang Tu",
      "Stephen Doogan",
      "Jinho D. Choi"
    ]
  },
  "https://aclanthology.org/2022.louhi-1.25": {
    "title": "Integration of Heterogeneous Knowledge Sources for Biomedical Text Processing",
    "volume": "workshop",
    "abstract": "Recently, research into bringing outside knowledge sources into current neural NLP models has been increasing. Most approaches that leverage external knowledge sources require laborious and non-trivial designs, as well as tailoring the system through intensive ablation of different knowledge sources, an effort that discourages users to use quality ontological resources. In this paper, we show that multiple large heterogeneous KSs can be easily integrated using a decoupled approach, allowing for an automatic ablation of irrelevant KSs, while keeping the overall parameter space tractable. We experiment with BERT and pre-trained graph embeddings, and show that they interoperate well without performance degradation, even when some do not contribute to the task",
    "checked": true,
    "id": "440a74077e396bf988d6679ac12afec4437f89c5",
    "semantic_title": "integration of heterogeneous knowledge sources for biomedical text processing",
    "citation_count": 0,
    "authors": [
      "Parsa Bagherzadeh",
      "Sabine Bergler"
    ]
  },
  "https://aclanthology.org/2022.mathnlp-1.1": {
    "title": "Tracing and Manipulating intermediate values in Neural Math Problem Solvers",
    "volume": "workshop",
    "abstract": "How language models process complex input that requires multiple steps of inference is not well understood. Previous research has shown that information about intermediate values of these inputs can be extracted from the activations of the models, but it is unclear where that information is encoded and whether that information is indeed used during inference. We introduce a method for analyzing how a Transformer model processes these inputs by focusing on simple arithmetic problems and their intermediate values. To trace where information about intermediate values is encoded, we measure the correlation between intermediate values and the activations of the model using principal component analysis (PCA). Then, we perform a causal intervention by manipulating model weights. This intervention shows that the weights identified via tracing are not merely correlated with intermediate values, but causally related to model predictions. Our findings show that the model has a locality to certain intermediate values, and this is useful for enhancing the interpretability of the models",
    "checked": true,
    "id": "2c1e2f2110d0ba6d53eb9a086a0d8bd9d7320647",
    "semantic_title": "tracing and manipulating intermediate values in neural math problem solvers",
    "citation_count": 1,
    "authors": [
      "Yuta Matsumoto",
      "Benjamin Heinzerling",
      "Masashi Yoshikawa",
      "Kentaro Inui"
    ]
  },
  "https://aclanthology.org/2022.mathnlp-1.2": {
    "title": "Investigating Math Word Problems using Pretrained Multilingual Language Models",
    "volume": "workshop",
    "abstract": "In this paper, we revisit math word problems (MWPs) from the cross-lingual and multilingual perspective. We construct our MWP solvers over pretrained multilingual language models using the sequence-to-sequence model with copy mechanism. We compare how the MWP solvers perform in cross-lingual and multilingual scenarios. To facilitate the comparison of cross-lingual performance, we first adapt the large-scale English dataset MathQA as a counterpart of the Chinese dataset Math23K. Then we extend several English datasets to bilingual datasets through machine translation plus human annotation. Our experiments show that the MWP solvers may not be transferred to a different language even if the target expressions share the same numerical constants and operator set. However, it can be better generalized if problem types exist on both source language and target language",
    "checked": true,
    "id": "7382e3383130298910b2d7c2fe2109e0cd13832e",
    "semantic_title": "investigating math word problems using pretrained multilingual language models",
    "citation_count": 24,
    "authors": [
      "Minghuan Tan",
      "Lei Wang",
      "Lingxiao Jiang",
      "Jing Jiang"
    ]
  },
  "https://aclanthology.org/2022.mathnlp-1.3": {
    "title": "Induced Natural Language Rationales and Interleaved Markup Tokens Enable Extrapolation in Large Language Models",
    "volume": "workshop",
    "abstract": "The ability to extrapolate, i.e., to make predictions on sequences that are longer than those presented as training examples, is a challenging problem for current deep learning models. Recent work shows that this limitation persists in state-of-the-art Transformer-based models. Most solutions to this problem use specific architectures or training methods that do not generalize to other tasks. We demonstrate that large language models can succeed in extrapolation without modifying their architecture or training procedure. Our experimental results show that generating step-by-step rationales and introducing marker tokens are both required for effective extrapolation. First, we induce a language model to produce step-by-step rationales before outputting the answer to effectively communicate the task to the model. However, as sequences become longer, we find that current models struggle to keep track of token positions. To address this issue, we interleave output tokens with markup tokens that act as explicit positional and counting symbols. Our findings show how these two complementary approaches enable remarkable sequence extrapolation and highlight a limitation of current architectures to effectively generalize without explicit surface form guidance. Code available at https://anonymous.4open.science/r/induced-rationales-markup-tokens-0650/README.md",
    "checked": true,
    "id": "108c25905be36b2a7a0fc7256ac314985ecd9699",
    "semantic_title": "induced natural language rationales and interleaved markup tokens enable extrapolation in large language models",
    "citation_count": 10,
    "authors": [
      "Mirelle Candida Bueno",
      "Carlos Gemmell",
      "Jeff Dalton",
      "Roberto Lotufo",
      "Rodrigo Nogueira"
    ]
  },
  "https://aclanthology.org/2022.mathnlp-1.4": {
    "title": "Towards Autoformalization of Mathematics and Code Correctness: Experiments with Elementary Proofs",
    "volume": "workshop",
    "abstract": "The ever-growing complexity of mathematical proofs makes their manual verification by mathematicians very cognitively demanding. Autoformalization seeks to address this by translating proofs written in natural language into a formal representation that is computer-verifiable via interactive theorem provers. In this paper, we introduce a semantic parsing approach, based on the Universal Transformer architecture, that translates elementary mathematical proofs into an equivalent formalization in the language of the Coq interactive theorem prover. The same architecture is also trained to translate simple imperative code decorated with Hoare triples into formally verifiable proofs of correctness in Coq. Experiments on a limited domain of artificial and human-written proofs show that the models generalize well to intermediate lengths not seen during training and variations in natural language",
    "checked": true,
    "id": "10422b7bcf17eae9b04d4a020a591b3a61b45593",
    "semantic_title": "towards autoformalization of mathematics and code correctness: experiments with elementary proofs",
    "citation_count": 8,
    "authors": [
      "Garett Cunningham",
      "Razvan Bunescu",
      "David Juedes"
    ]
  },
  "https://aclanthology.org/2022.mathnlp-1.5": {
    "title": "Numerical Correlation in Text",
    "volume": "workshop",
    "abstract": "Evaluation of quantitative reasoning of large language models is an important step towards understanding their current capabilities and limitations. We propose a new task, Numerical Correlation in Text, which requires models to identify the correlation between two numbers in a sentence. To this end, we introduce a new dataset, which contains over 2,000 Wikipedia sentences with two numbers and their correlation labels. Using this dataset we are able to show that recent numerically aware pretraining methods for language models do not help generalization on this task posing a challenge for future work in this area",
    "checked": true,
    "id": "ffd5d435c9534cf7e4e6995cd9d6a888d317e2f9",
    "semantic_title": "numerical correlation in text",
    "citation_count": 0,
    "authors": [
      "Daniel Spokoyny",
      "Chien-Sheng Wu",
      "Caiming Xiong"
    ]
  },
  "https://aclanthology.org/2022.mathnlp-1.6": {
    "title": "Extracting Operator Trees from Model Embeddings",
    "volume": "workshop",
    "abstract": "Transformer-based language models are able to capture several linguistic properties such as hierarchical structures like dependency or constituency trees. Whether similar structures for mathematics are extractable from language models has not yet been explored. This work aims to probe current state-of-the-art models for the extractability of Operator Trees from their contextualized embeddings using the structure probe designed by Hewitt and Manning. We release the code and our data set for future analysis",
    "checked": true,
    "id": "5eadc68b7a6a049eacd5449a8047405a3f6d3893",
    "semantic_title": "extracting operator trees from model embeddings",
    "citation_count": 1,
    "authors": [
      "Anja Reusch",
      "Wolfgang Lehner"
    ]
  },
  "https://aclanthology.org/2022.mathnlp-1.7": {
    "title": "End-to-End Evaluation of a Spoken Dialogue System for Learning Basic Mathematics",
    "volume": "workshop",
    "abstract": "The advances in language-based Artificial Intelligence (AI) technologies applied to build educational applications can present AI for social-good opportunities with a broader positive impact. Across many disciplines, enhancing the quality of mathematics education is crucial in building critical thinking and problem-solving skills at younger ages. Conversational AI systems have started maturing to a point where they could play a significant role in helping students learn fundamental math concepts. This work presents a task-oriented Spoken Dialogue System (SDS) built to support play-based learning of basic math concepts for early childhood education. The system has been evaluated via real-world deployments at school while the students are practicing early math concepts with multimodal interactions. We discuss our efforts to improve the SDS pipeline built for math learning, for which we explore utilizing MathBERT representations for potential enhancement to the Natural Language Understanding (NLU) module. We perform an end-to-end evaluation using real-world deployment outputs from the Automatic Speech Recognition (ASR), Intent Recognition, and Dialogue Manager (DM) components to understand how error propagation affects the overall performance in real-world scenarios",
    "checked": true,
    "id": "96a2f16ce9c87db6f647c78666e242cd963d699f",
    "semantic_title": "end-to-end evaluation of a spoken dialogue system for learning basic mathematics",
    "citation_count": 3,
    "authors": [
      "Eda Okur",
      "Saurav Sahay",
      "Roddy Fuentes Alba",
      "Lama Nachman"
    ]
  },
  "https://aclanthology.org/2022.mmnlu-1.1": {
    "title": "Robust Domain Adaptation for Pre-trained Multilingual Neural Machine Translation Models",
    "volume": "workshop",
    "abstract": "Recent literature has demonstrated the potential of multilingual Neural Machine Translation (mNMT) models. However, the most efficient models are not well suited to specialized industries. In these cases, internal data is scarce and expensive to find in all language pairs. Therefore, fine-tuning a mNMT model on a specialized domain is hard. In this context, we decided to focus on a new task: Domain Adaptation of a pre-trained mNMT model on a single pair of language while trying to maintain model quality on generic domain data for all language pairs. The risk of loss on generic domain and on other pairs is high. This task is key for mNMT model adoption in the industry and is at the border of many others. We propose a fine-tuning procedure for the generic mNMT that combines embeddings freezing and adversarial loss. Our experiments demonstrated that the procedure improves performances on specialized data with a minimal loss in initial performances on generic domain for all languages pairs, compared to a naive standard approach (+10.0 BLEU score on specialized data, -0.01 to -0.5 BLEU on WMT and Tatoeba datasets on the other pairs with M2M100)",
    "checked": true,
    "id": "51d82076fb0026fe73e33b08cbf95aa9b05ee930",
    "semantic_title": "robust domain adaptation for pre-trained multilingual neural machine translation models",
    "citation_count": 2,
    "authors": [
      "Mathieu Grosso",
      "Alexis Mathey",
      "Pirashanth Ratnamogan",
      "William Vanhuffel",
      "Michael Fotso"
    ]
  },
  "https://aclanthology.org/2022.mmnlu-1.2": {
    "title": "Fine-grained Multi-lingual Disentangled Autoencoder for Language-agnostic Representation Learning",
    "volume": "workshop",
    "abstract": "Encoding both language-specific and language-agnostic information into a single high-dimensional space is a common practice of pre-trained Multi-lingual Language Models (pMLM). Such encoding has been shown to perform effectively on natural language tasks requiring semantics of the whole sentence (e.g., translation). However, its effectiveness appears to be limited on tasks requiring partial information of the utterance (e.g., multi-lingual entity retrieval, template retrieval, and semantic alignment). In this work, a novel Fine-grained Multilingual Disentangled Autoencoder (FMDA) is proposed to disentangle fine-grained semantic information from language-specific information in a multi-lingual setting. FMDA is capable of successfully extracting the disentangled template semantic and residual semantic representations. Experiments conducted on the MASSIVE dataset demonstrate that the disentangled encoding can boost each other during the training, thus consistently outperforming the original pMLM and the strong language disentanglement baseline on monolingual template retrieval and cross-lingual semantic retrieval tasks across multiple languages",
    "checked": true,
    "id": "42299f98f4288b3d434571060077ed7eac838e0e",
    "semantic_title": "fine-grained multi-lingual disentangled autoencoder for language-agnostic representation learning",
    "citation_count": 0,
    "authors": [
      "Zetian Wu",
      "Zhongkai Sun",
      "Zhengyang Zhao",
      "Sixing Lu",
      "Chengyuan Ma",
      "Chenlei Guo"
    ]
  },
  "https://aclanthology.org/2022.mmnlu-1.3": {
    "title": "Byte-Level Massively Multilingual Semantic Parsing",
    "volume": "workshop",
    "abstract": "Token free approaches have been successfully applied to a series of word and span level tasks. In this work, we evaluate a byte-level sequence to sequence model (ByT5) on the 51 languages in the MASSIVE multilingual semantic parsing dataset. We examine multiple experimental settings: (i) zero-shot, (ii) full gold data and (iii) zero-shot with synthetic data. By leveraging a state-of-the-art label projection method for machine translated examples, we are able to reduce the gap in exact match to only 5 points with respect to a model trained on gold data from all the languages. We additionally provide insights on the cross-lingual transfer of ByT5 and show how the model compares with respect to mT5 across all parameter sizes",
    "checked": true,
    "id": "48088e1b8ae6e38c294717c697d85edcecd7990a",
    "semantic_title": "byte-level massively multilingual semantic parsing",
    "citation_count": 1,
    "authors": [
      "Massimo Nicosia",
      "Francesco Piccinno"
    ]
  },
  "https://aclanthology.org/2022.mmnlu-1.4": {
    "title": "HIT-SCIR at MMNLU-22: Consistency Regularization for Multilingual Spoken Language Understanding",
    "volume": "workshop",
    "abstract": "Multilingual spoken language understanding (SLU) consists of two sub-tasks, namely intent detection and slot filling. To improve the performance of these two sub-tasks, we propose to use consistency regularization based on a hybrid data augmentation strategy. The consistency regularization enforces the predicted distributions for an example and its semantically equivalent augmentation to be consistent. We conduct experiments on the MASSIVE dataset under both full-dataset and zero-shot settings. Experimental results demonstrate that our proposed method improves the performance on both intent detection and slot filling tasks. Our system ranked 1st in the MMNLU-22 competition under the full-dataset setting",
    "checked": true,
    "id": "ea3c05db8ea9f784e8835b2d9065d5b4baae2a42",
    "semantic_title": "hit-scir at mmnlu-22: consistency regularization for multilingual spoken language understanding",
    "citation_count": 2,
    "authors": [
      "Bo Zheng",
      "Zhouyang Li",
      "Fuxuan Wei",
      "Qiguang Chen",
      "Libo Qin",
      "Wanxiang Che"
    ]
  },
  "https://aclanthology.org/2022.mmnlu-1.5": {
    "title": "Play música alegre: A Large-Scale Empirical Analysis of Cross-Lingual Phenomena in Voice Assistant Interactions",
    "volume": "workshop",
    "abstract": "Cross-lingual phenomena are quite common in informal contexts like social media, where users are likely to mix their native language with English or other languages. However, few studies have focused so far on analyzing cross-lingual interactions in voice-assistant data, which present peculiar features in terms of sentence length, named entities, and use of spoken language. Also, little attention has been posed to European countries, where English is frequently used as a second language. In this paper, we present a large-scale empirical analysis of cross-lingual phenomena (code-mixing, linguistic borrowing, foreign named entities) in the interactions with a large-scale voice assistant in European countries. To do this, we first introduce a general, highly-scalable technique to generate synthetic mixed training data annotated with token-level language labels and we train two neural network models to predict them. We evaluate the models both on the synthetic dataset and on a real dataset of code-switched utterances, showing that the best performance is obtained by a character convolution based model. The results of the analysis highlight different behaviors between countries, having Italy with the highest ratio of cross-lingual utterances and Spain with a marked preference in keeping Spanish words. Our research, paired to the increase of the cross-lingual phenomena in time, motivates further research in developing multilingual Natural Language Understanding (NLU) models, which can naturally deal with cross-lingual interactions",
    "checked": true,
    "id": "b3bbe6f841821061c40ff752297f52335795928f",
    "semantic_title": "play música alegre: a large-scale empirical analysis of cross-lingual phenomena in voice assistant interactions",
    "citation_count": 0,
    "authors": [
      "Donato Crisostomi",
      "Alessandro Manzotti",
      "Enrico Palumbo",
      "Davide Bernardi",
      "Sarah Campbell",
      "Shubham Garg"
    ]
  },
  "https://aclanthology.org/2022.mmnlu-1.6": {
    "title": "Zero-Shot Cross-Lingual Sequence Tagging as Seq2Seq Generation for Joint Intent Classification and Slot Filling",
    "volume": "workshop",
    "abstract": "The joint intent classification and slot filling task seeks to detect the intent of an utterance and extract its semantic concepts. In the zero-shot cross-lingual setting, a model is trained on a source language and then transferred to other target languages through multi-lingual representations without additional training data. While prior studies show that pre-trained multilingual sequence-to-sequence (Seq2Seq) models can facilitate zero-shot transfer, there is little understanding on how to design the output template for the joint prediction tasks. In this paper, we examine three aspects of the output template – (1) label mapping, (2) task dependency, and (3) word order. Experiments on the MASSIVE dataset consisting of 51 languages show that our output template significantly improves the performance of pre-trained cross-lingual language models",
    "checked": true,
    "id": "614a71d9fef4875294a3239d71945e657450946c",
    "semantic_title": "zero-shot cross-lingual sequence tagging as seq2seq generation for joint intent classification and slot filling",
    "citation_count": 0,
    "authors": [
      "Fei Wang",
      "Kuan-hao Huang",
      "Anoop Kumar",
      "Aram Galstyan",
      "Greg Ver steeg",
      "Kai-wei Chang"
    ]
  },
  "https://aclanthology.org/2022.mmnlu-1.7": {
    "title": "C5L7: A Zero-Shot Algorithm for Intent and Slot Detection in Multilingual Task Oriented Languages",
    "volume": "workshop",
    "abstract": "Voice assistants are becoming central to our lives. The convenience of using voice assistants to do simple tasks has created an industry for voice-enabled devices like TVs, thermostats, air conditioners, etc. It has also improved the quality of life of elders by making the world more accessible. Voice assistants engage in task-oriented dialogues using machine-learned language understanding models. However, training deep-learned models take a lot of training data, which is time-consuming and expensive. Furthermore, it is even more problematic if we want the voice assistant to understand hundreds of languages. In this paper, we present a zero-shot deep learning algorithm that uses only the English part of the Massive dataset and achieves a high level of accuracy across 51 languages. The algorithm uses a delexicalized translation model to generate multilingual data for data augmentation. The training data is further weighted to improve the accuracy of the worst-performing languages. We report on our experiments with code-switching, word order, multilingual ensemble methods, and other techniques and their impact on overall accuracy",
    "checked": true,
    "id": "f1d0a6162694be420b3b6f6582c05c86529e849d",
    "semantic_title": "c5l7: a zero-shot algorithm for intent and slot detection in multilingual task oriented languages",
    "citation_count": 0,
    "authors": [
      "Jiun-hao Jhan",
      "Qingxiaoyang Zhu",
      "Nehal Bengre",
      "Tapas Kanungo"
    ]
  },
  "https://aclanthology.org/2022.mmnlu-1.8": {
    "title": "Machine Translation for Multilingual Intent Detection and Slots Filling",
    "volume": "workshop",
    "abstract": "We expect to interact with home assistants irrespective of our language. However, scaling the Natural Language Understanding pipeline to multiple languages while keeping the same level of accuracy remains a challenge. In this work, we leverage the inherent multilingual aspect of translation models for the task of multilingual intent classification and slot filling. Our experiments reveal that they work equally well with general-purpose multilingual text-to-text models. Furthermore, their accuracy can be further improved by artificially increasing the size of the training set. Unfortunately, increasing the training set also increases the overlap with the test set, leading to overestimating their true capabilities. As a result, we propose two new evaluation methods capable of accounting for an overlap between the training and test set",
    "checked": true,
    "id": "710ceab1ff91b96e8596b8400ebf2912ee6e2836",
    "semantic_title": "machine translation for multilingual intent detection and slots filling",
    "citation_count": 3,
    "authors": [
      "Maxime De bruyn",
      "Ehsan Lotfi",
      "Jeska Buhmann",
      "Walter Daelemans"
    ]
  },
  "https://aclanthology.org/2022.mmnlu-1.9": {
    "title": "Massively Multilingual Natural Language Understanding 2022 (MMNLU-22) Workshop and Competition",
    "volume": "workshop",
    "abstract": "To be writen (workshop summary paper)",
    "checked": true,
    "id": "be2df0fafa89b6355d1ff1336c10e0d4c8d27276",
    "semantic_title": "massively multilingual natural language understanding 2022 (mmnlu-22) workshop and competition",
    "citation_count": 1,
    "authors": [
      "Jack FitzGerald",
      "Christopher Hench",
      "Charith Peris",
      "Kay Rottmann"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.1": {
    "title": "Entity Retrieval from Multilingual Knowledge Graphs",
    "volume": "workshop",
    "abstract": "Knowledge Graphs (KGs) are structured databases that capture real-world entities and their relationships. The task of entity retrieval from a KG aims at retrieving a ranked list of entities relevant to a given user query. While English-only entity retrieval has attracted considerable attention, user queries, as well as the information contained in the KG, may be represented in multiple—and possibly distinct—languages. Furthermore, KG content may vary between languages due to different information sources and points of view. Recent advances in language representation have enabled natural ways of bridging gaps between languages. In this paper, we therefore propose to utilise language models (LMs) and diverse entity representations to enable truly multilingual entity retrieval. We propose two approaches: (i) an array of monolingual retrievers and (ii) a single multilingual retriever, trained using queries and documents in multiple languages. We show that while our approach is on par with the significantly more complex state-of-the-art method for the English task, it can be successfully applied to virtually any language with a LM. Furthermore, it allows languages to benefit from one another, yielding significantly better performance, both for low- and high-resource languages",
    "checked": true,
    "id": "8f52464d89cf2efe1fbeaff6753b53700e6d454f",
    "semantic_title": "entity retrieval from multilingual knowledge graphs",
    "citation_count": 0,
    "authors": [
      "Saher Esmeir",
      "Arthur Câmara",
      "Edgar Meij"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.2": {
    "title": "Few-Shot Cross-Lingual Learning for Event Detection",
    "volume": "workshop",
    "abstract": "Cross-Lingual Event Detection (CLED) models are capable of performing the Event Detection (ED) task in multiple languages. Such models are trained using data from a source language and then evaluated on data from a distinct target language. Training is usually performed in the standard supervised setting with labeled data available in the source language. The Few-Shot Learning (FSL) paradigm is yet to be explored for CLED despite its inherent advantage of allowing models to better generalize to unseen event types. As such, in this work, we study the CLED task under an FSL setting. Our contribution is threefold: first, we introduce a novel FSL classification method based on Optimal Transport (OT); second, we present a novel regularization term to incorporate the global distance between the support and query sets; and third, we adapt our approach to the cross-lingual setting by exploiting the alignment between source and target data. Our experiments on three, syntactically-different, target languages show the applicability of our approach and its effectiveness at improving the cross-lingual performance of few-shot models for event detection",
    "checked": true,
    "id": "d620f1567f6c45473ed0f2f4727b274c30d61f02",
    "semantic_title": "few-shot cross-lingual learning for event detection",
    "citation_count": 0,
    "authors": [
      "Luis Guzman Nateras",
      "Viet Lai",
      "Franck Dernoncourt",
      "Thien Nguyen"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.3": {
    "title": "Zero-shot Cross-Lingual Counterfactual Detection via Automatic Extraction and Prediction of Clue Phrases",
    "volume": "workshop",
    "abstract": "Counterfactual statements describe events that did not or cannot take place unless some conditions are satisfied. Existing counterfactual detection (CFD) methods assume the availability of manually labelled statements for each language they consider, limiting the broad applicability of CFD. In this paper, we consider the problem of zero-shot cross-lingual transfer learning for CFD. Specifically, we propose a novel loss function based on the clue phrase prediction for generalising a CFD model trained on a source language to multiple target languages, without requiring any human-labelled data. We obtain clue phrases that express various language-specific lexical indicators of counterfactuality in the target language in an unsupervised manner using a neural alignment model. We evaluate our method on the Amazon Multilingual Counterfactual Dataset (AMCD) for English, German, and Japanese languages in the zero-shot cross-lingual transfer setup where no manual annotations are used for the target language during training. The best CFD model fine-tuned on XLM-R improves the macro F1 score by 25% for German and 20% for Japanese target languages compared to a model that is trained only using English source language data",
    "checked": true,
    "id": "962d99389b2729a7e0a9a44f82fc507e0ee5e196",
    "semantic_title": "zero-shot cross-lingual counterfactual detection via automatic extraction and prediction of clue phrases",
    "citation_count": 0,
    "authors": [
      "Asahi Ushio",
      "Danushka Bollegala"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.4": {
    "title": "Zero-shot Cross-Language Transfer of Monolingual Entity Linking Models",
    "volume": "workshop",
    "abstract": "Most entity linking systems, whether mono or multilingual, link mentions to a single English knowledge base. Few have considered linking non-English text to a non-English KB, and therefore, transferring an English entity linking model to both a new document and KB language. We consider the task of zero-shot cross-language transfer of entity linking systems to a new language and KB. We find that a system trained with multilingual representations does reasonably well, and propose improvements to system training that lead to improved recall in most datasets, often matching the in-language performance. We further conduct a detailed evaluation to elucidate the challenges of this setting",
    "checked": true,
    "id": "b1f1f6890c679ce7d2680ef38c01016fa56a323f",
    "semantic_title": "zero-shot cross-language transfer of monolingual entity linking models",
    "citation_count": 0,
    "authors": [
      "Elliot Schumacher",
      "James Mayfield",
      "Mark Dredze"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.5": {
    "title": "Rule-Based Clause-Level Morphology for Multiple Languages",
    "volume": "workshop",
    "abstract": "This paper describes an approach for the morphosyntactic analysis of clauses, including the analysis of composite verb forms and both overt and covert pronouns. The approach uses grammatical rules for verb inflection and clause-internal word agreement to compute a clause's morphosyntactic features from the morphological features of the individual words. The approach is tested for eight languages in the 1st Shared Task on Multilingual Clause-Level Morphology, where it achieves F1 scores between 79% and 99% (94% in average)",
    "checked": true,
    "id": "d193c214b6fbdbcb1266c8daf8d5859c24cb0d11",
    "semantic_title": "rule-based clause-level morphology for multiple languages",
    "citation_count": 1,
    "authors": [
      "Tillmann Dönicke"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.6": {
    "title": "Comparative Analysis of Cross-lingual Contextualized Word Embeddings",
    "volume": "workshop",
    "abstract": "Contextualized word embeddings have emerged as the most important tool for performing NLP tasks in a large variety of languages. In order to improve the cross- lingual representation and transfer learning quality, contextualized embedding alignment techniques, such as mapping and model fine-tuning, are employed. Existing techniques however are time-, data- and computational resource-intensive. In this paper we analyze these techniques by utilizing three tasks: bilingual lexicon induction (BLI), word retrieval and cross-lingual natural language inference (XNLI) for a high resource (German-English) and a low resource (Bengali-English) language pair. In contrast to previous works which focus only on a few popular models, we compare five multilingual and seven monolingual language models and investigate the effect of various aspects on their performance, such as vocabulary size, number of languages used for training and number of parameters. Additionally, we propose a parameter-, data- and runtime-efficient technique which can be trained with 10% of the data, less than 10% of the time and have less than 5% of the trainable parameters compared to model fine-tuning. We show that our proposed method is competitive with resource heavy models, even outperforming them in some cases, even though it relies on less resource",
    "checked": true,
    "id": "21e76cee90b6977aaccaa3ab939eb8ce05bdf642",
    "semantic_title": "comparative analysis of cross-lingual contextualized word embeddings",
    "citation_count": 0,
    "authors": [
      "Hossain Shaikh Saadi",
      "Viktor Hangya",
      "Tobias Eder",
      "Alexander Fraser"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.7": {
    "title": "How Language-Dependent is Emotion Detection? Evidence from Multilingual BERT",
    "volume": "workshop",
    "abstract": "As emotion analysis in text has gained a lot of attention in the field of natural language processing, differences in emotion expression across languages could have consequences for how emotion detection models work. We evaluate the language-dependence of an mBERT-based emotion detection model by comparing language identification performance before and after fine-tuning on emotion detection, and performing (adjusted) zero-shot experiments to assess whether emotion detection models rely on language-specific information. When dealing with typologically dissimilar languages, we found evidence for the language-dependence of emotion detection",
    "checked": true,
    "id": "03146e06bc24aee0f4d44016084a97bd31b4612a",
    "semantic_title": "how language-dependent is emotion detection? evidence from multilingual bert",
    "citation_count": 0,
    "authors": [
      "Luna De Bruyne",
      "Pranaydeep Singh",
      "Orphee De Clercq",
      "Els Lefever",
      "Veronique Hoste"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.9": {
    "title": "MicroBERT: Effective Training of Low-resource Monolingual BERTs through Parameter Reduction and Multitask Learning",
    "volume": "workshop",
    "abstract": "BERT-style contextualized word embedding models are critical for good performance in most NLP tasks, but they are data-hungry and therefore difficult to train for low-resource languages. In this work, we investigate whether a combination of greatly reduced model size and two linguistically rich auxiliary pretraining tasks (part-of-speech tagging and dependency parsing) can help produce better BERTs in a low-resource setting. Results from 7 diverse languages indicate that our model, MicroBERT, is able to produce marked improvements in downstream task evaluations, including gains up to 18% for parser LAS and 11% for NER F1 compared to an mBERT baseline, and we achieve these results with less than 1% of the parameter count of a multilingual BERT base–sized model. We conclude that training very small BERTs and leveraging any available labeled data for multitask learning during pretraining can produce models which outperform both their multilingual counterparts and traditional fixed embeddings for low-resource languages",
    "checked": true,
    "id": "b16a7adc26d791d83971708aad17e8855b95db4d",
    "semantic_title": "microbert: effective training of low-resource monolingual berts through parameter reduction and multitask learning",
    "citation_count": 7,
    "authors": [
      "Luke Gessler",
      "Amir Zeldes"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.10": {
    "title": "Transformers on Multilingual Clause-Level Morphology",
    "volume": "workshop",
    "abstract": "This paper describes the KUIS-AI NLP team's submission for the 1st Shared Task on Multilingual Clause-level Morphology (MRL2022). We present our work on all three parts of the shared task: inflection, reinflection, and analysis. We mainly explore two approaches: Trans- former models in combination with data augmentation, and exploiting the state-of-the-art language modeling techniques for morphological analysis. Data augmentation leads to a remarkable performance improvement for most of the languages in the inflection task. Prefix-tuning on pretrained mGPT model helps us to adapt reinflection and analysis tasks in a low-data setting. Additionally, we used pipeline architectures using publicly available open-source lemmatization tools and monolingual BERT- based morphological feature classifiers for rein- flection and analysis tasks, respectively. While Transformer architectures with data augmentation and pipeline architectures achieved the best results for inflection and reinflection tasks, pipelines and prefix-tuning on mGPT received the highest results for the analysis task. Our methods achieved first place in each of the three tasks and outperforms mT5-baseline with 89% for inflection, 80% for reflection, and 12% for analysis. Our code 1 is publicly available",
    "checked": true,
    "id": "d181b2c36d74d7603f93f1a323cc417686aab330",
    "semantic_title": "transformers on multilingual clause-level morphology",
    "citation_count": 3,
    "authors": [
      "Emre Can Acikgoz",
      "Tilek Chubakov",
      "Muge Kural",
      "Gözde Şahin",
      "Deniz Yuret"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.11": {
    "title": "Impact of Sequence Length and Copying on Clause-Level Inflection",
    "volume": "workshop",
    "abstract": "We present the University of British Columbia's submission to the MRL shared task on multilingual clause-level morphology. Our submission extends word-level inflectional models to the clause-level in two ways: first, by evaluating the role that BPE has on the learning of inflectional morphology, and second, by evaluating the importance of a copy bias obtained through data hallucination. Experiments demonstrate a strong preference for language-tuned BPE and a copy bias over a vanilla transformer. The methods are complementary for inflection and analysis tasks – combined models see error reductions of 38% for inflection and 15.6% for analysis; However, this synergy does not hold for reinflection, which performs best under a BPE-only setting. A deeper analysis of the errors generated by our models illustrates that the copy bias may be too strong - the combined model produces predictions more similar to the copy-influenced system, despite the success of the BPE-model",
    "checked": true,
    "id": "729508bbd090d97e2e0ba57b3a6ea2b5832bf091",
    "semantic_title": "impact of sequence length and copying on clause-level inflection",
    "citation_count": 2,
    "authors": [
      "Badr Jaidi",
      "Utkarsh Saboo",
      "Xihan Wu",
      "Garrett Nicolai",
      "Miikka Silfverberg"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.12": {
    "title": "Towards Improved Distantly Supervised Multilingual Named-Entity Recognition for Tweets",
    "volume": "workshop",
    "abstract": "Recent low-resource named-entity recognition (NER) work has shown impressive gains by leveraging a single multilingual model trained using distantly supervised data derived from cross-lingual knowledge bases. In this work, we investigate such approaches by leveraging Wikidata to build large-scale NER datasets of Tweets and propose two orthogonal improvements for low-resource NER in the Twitter social media domain: (1) leveraging domain-specific pre-training on Tweets; and (2) building a model for each language family rather than an all-in-one single multilingual model. For (1), we show that mBERT with Tweet pre-training outperforms the state-of-the-art multilingual transformer-based language model, LaBSE, by a relative increase of 34.6% in F1 when evaluated on Twitter data in a language-agnostic multilingual setting. For (2), we show that learning NER models for language families outperforms a single multilingual model by relative increases of 14.1%, 15.8% and 45.3% in F1 when utilizing mBERT, mBERT with Tweet pre-training and LaBSE, respectively. We conduct analyses and present examples for these observed improvements",
    "checked": true,
    "id": "c76865bd12981f8d46d97e4a516611c178a23e97",
    "semantic_title": "towards improved distantly supervised multilingual named-entity recognition for tweets",
    "citation_count": 1,
    "authors": [
      "Ramy Eskander",
      "Shubhanshu Mishra",
      "Sneha Mehta",
      "Sofia Samaniego",
      "Aria Haghighi"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.13": {
    "title": "Average Is Not Enough: Caveats of Multilingual Evaluation",
    "volume": "workshop",
    "abstract": "This position paper discusses the problem of multilingual evaluation. Using simple statistics, such as average language performance, might inject linguistic biases in favor of dominant language families into evaluation methodology. We argue that a qualitative analysis informed by comparative linguistics is needed for multilingual results to detect this kind of bias. We show in our case study that results in published works can indeed be linguistically biased and we demonstrate that visualization based on URIEL typological database can detect it",
    "checked": true,
    "id": "a428df8e851d448bed2db2e13a6e9f1c065deb5a",
    "semantic_title": "average is not enough: caveats of multilingual evaluation",
    "citation_count": 1,
    "authors": [
      "Matúš Pikuliak",
      "Marian Simko"
    ]
  },
  "https://aclanthology.org/2022.mrl-1.14": {
    "title": "The MRL 2022 Shared Task on Multilingual Clause-level Morphology",
    "volume": "workshop",
    "abstract": "The 2022 Multilingual Representation Learning (MRL) Shared Task was dedicated to clause-level morphology. As the first ever benchmark that defines and evaluates morphology outside its traditional lexical boundaries, the shared task on multilingual clause-level morphology sets the scene for competition across different approaches to morphological modeling, with 3 clause-level sub-tasks: morphological inflection, reinflection and analysis, where systems are required to generate, manipulate or analyze simple sentences centered around a single content lexeme and a set of morphological features characterizing its syntactic clause. This year's tasks covered eight typologically distinct languages: English, French, German, Hebrew, Russian, Spanish, Swahili and Turkish. The tasks has received submissions of four systems from three teams which were compared to two baselines implementing prominent multilingual learning methods. The results show that modern NLP models are effective in solving morphological tasks even at the clause level. However, there is still room for improvement, especially in the task of morphological analysis",
    "checked": true,
    "id": "cf865f0a25a4efccf0e514e56861f766f95c1605",
    "semantic_title": "the mrl 2022 shared task on multilingual clause-level morphology",
    "citation_count": 3,
    "authors": [
      "Omer Goldman",
      "Francesco Tinner",
      "Hila Gonen",
      "Benjamin Muller",
      "Victoria Basmov",
      "Shadrack Kirimi",
      "Lydia Nishimwe",
      "Benoît Sagot",
      "Djamé Seddah",
      "Reut Tsarfaty",
      "Duygu Ataman"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.1": {
    "title": "On Breadth Alone: Improving the Precision of Terminology Extraction Systems on Patent Corpora",
    "volume": "workshop",
    "abstract": "Automatic Terminology Extraction (ATE) methods are a class of linguistic, statistical, machine learning or hybrid techniques for identifying terminology in a set of documents. Most modern ATE methods use a statistical measure of how important or characteristic a potential term is to a foreground corpus by using a second background corpus as a baseline. While many variables with ATE methods have been carefully evaluated and tuned in the literature, the effects of choosing a particular background corpus over another are not obvious. In this paper, we propose a methodology that allows us to adjust the relative breadth of the foreground and background corpora in patent documents by taking advantage of the Cooperative Patent Classification (CPC) scheme. Our results show that for every foreground corpus, the broadest background corpus gave the worst performance, in the worst case that difference is 17%. Similarly, the least broad background corpus gave suboptimal performance in all three experiments. We also demonstrate qualitative differences between background corpora – narrower background corpora tend towards more technical output. We expect our results to generalize to terminology extraction for other legal and technical documents and, generally, to the foreground/background approach to ATE",
    "checked": true,
    "id": "0a095a60b75e2284453c2696d71021272e57e46e",
    "semantic_title": "on breadth alone: improving the precision of terminology extraction systems on patent corpora",
    "citation_count": 0,
    "authors": [
      "Sean Nordquist",
      "Adam Meyers"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.2": {
    "title": "On What it Means to Pay Your Fair Share: Towards Automatically Mapping Different Conceptions of Tax Justice in Legal Research Literature",
    "volume": "workshop",
    "abstract": "In this article, we explore the potential and challenges of applying transformer-based pre-trained language models (PLMs) and statistical methods to a particularly challenging, yet highly important and largely uncharted domain: normative discussions in tax law research. On our conviction, the role of NLP in this essentially contested territory is to make explicit implicit normative assumptions, and to foster debates across ideological divides. To this goal, we propose the first steps towards a method that automatically labels normative statements in tax law research, and that suggests the normative background of these statements. Our results are encouraging, but it is clear that there is still room for improvement",
    "checked": true,
    "id": "6848f1f32e9ebf6ae793c87fcc3e1bb852640121",
    "semantic_title": "on what it means to pay your fair share: towards automatically mapping different conceptions of tax justice in legal research literature",
    "citation_count": 1,
    "authors": [
      "Reto Gubelmann",
      "Peter Hongler",
      "Elina Margadant",
      "Siegfried Handschuh"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.3": {
    "title": "ClassActionPrediction: A Challenging Benchmark for Legal Judgment Prediction of Class Action Cases in the US",
    "volume": "workshop",
    "abstract": "The research field of Legal Natural Language Processing (NLP) has been very active recently, with Legal Judgment Prediction (LJP) becoming one of the most extensively studied tasks. To date, most publicly released LJP datasets originate from countries with civil law. In this work, we release, for the first time, a challenging LJP dataset focused on class action cases in the US. It is the first dataset in the common law system that focuses on the harder and more realistic task involving the complaints as input instead of the often used facts summary written by the court. Additionally, we study the difficulty of the task by collecting expert human predictions, showing that even human experts can only reach 53% accuracy on this dataset. Our Longformer model clearly outperforms the human baseline (63%), despite only considering the first 2,048 tokens. Furthermore, we perform a detailed error analysis and find that the Longformer model is significantly better calibrated than the human experts. Finally, we publicly release the dataset and the code used for the experiments",
    "checked": true,
    "id": "bcf272c12c55362a92741b1a0b2ac76f066466f9",
    "semantic_title": "classactionprediction: a challenging benchmark for legal judgment prediction of class action cases in the us",
    "citation_count": 11,
    "authors": [
      "Gil Semo",
      "Dor Bernsohn",
      "Ben Hagag",
      "Gila Hayat",
      "Joel Niklaus"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.4": {
    "title": "Combining WordNet and Word Embeddings in Data Augmentation for Legal Texts",
    "volume": "workshop",
    "abstract": "Creating balanced labeled textual corpora for complex tasks, like legal analysis, is a challenging and expensive process that often requires the collaboration of domain experts. To address this problem, we propose a data augmentation method based on the combination of GloVe word embeddings and the WordNet ontology. We present an example of application in the legal domain, specifically on decisions of the Court of Justice of the European Union.Our evaluation with human experts confirms that our method is more robust than the alternatives",
    "checked": true,
    "id": "7fc191d0ec2960e65b96bb01855c1473d2114a97",
    "semantic_title": "combining wordnet and word embeddings in data augmentation for legal texts",
    "citation_count": 3,
    "authors": [
      "Sezen Perçin",
      "Andrea Galassi",
      "Francesca Lagioia",
      "Federico Ruggeri",
      "Piera Santin",
      "Giovanni Sartor",
      "Paolo Torroni"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.5": {
    "title": "A Legal Approach to Hate Speech – Operationalizing the EU's Legal Framework against the Expression of Hatred as an NLP Task",
    "volume": "workshop",
    "abstract": "We propose a ‘legal approach' to hate speech detection by operationalization of the decision as to whether a post is subject to criminal law into an NLP task. Comparing existing regulatory regimes for hate speech, we base our investigation on the European Union's framework as it provides a widely applicable legal minimum standard. Accurately deciding whether a post is punishable or not usually requires legal education. We show that, by breaking the legal assessment down into a series of simpler sub-decisions, even laypersons can annotate consistently. Based on a newly annotated dataset, our experiments show that directly learning an automated model of punishable content is challenging. However, learning the two sub-tasks of ‘target group' and ‘targeting conduct' instead of a holistic, end-to-end approach to the legal assessment yields better results. Overall, our method also provides decisions that are more transparent than those of end-to-end models, which is a crucial point in legal decision-making",
    "checked": true,
    "id": "acb663af55e3652a3a233a7c50babaf8edb6579f",
    "semantic_title": "a legal approach to hate speech – operationalizing the eu's legal framework against the expression of hatred as an nlp task",
    "citation_count": 6,
    "authors": [
      "Frederike Zufall",
      "Marius Hamacher",
      "Katharina Kloppenborg",
      "Torsten Zesch"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.6": {
    "title": "Privacy Pitfalls of Online Service Terms and Conditions: a Hybrid Approach for Classification and Summarization",
    "volume": "workshop",
    "abstract": "Verbose and complicated legal terminology in online service terms and conditions (T&C) means that users typically don't read these documents before accepting the terms of such unilateral service contracts. With such services becoming part of mainstream digital life, highlighting Terms of Service (ToS) clauses that impact on the collection and use of user data and privacy are important concerns. Advances in text summarization can help to create informative and concise summaries of the terms, but existing approaches geared towards news and microblogging corpora are not directly applicable to the ToS domain, which is hindered by a lack of T&C-relevant resources for training and evaluation. This paper presents a ToS model, developing a hybrid extractive-classifier-abstractive pipeline that highlights the privacy and data collection/use-related sections in a ToS document and paraphrases these into concise and informative sentences. Relying on significantly less training data (4313 training pairs) than previous representative works (287,226 pairs), our model outperforms extractive baselines by at least 50% in ROUGE-1 score and 54% in METEOR score. The paper also contributes to existing community efforts by curating a dataset of online service T&C, through a developed web scraping tool",
    "checked": true,
    "id": "b8457d63b15fc823673b924180f3aeb301a731bc",
    "semantic_title": "privacy pitfalls of online service terms and conditions: a hybrid approach for classification and summarization",
    "citation_count": 0,
    "authors": [
      "Emilia Lukose",
      "Suparna De",
      "Jon Johnson"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.7": {
    "title": "Abstractive Summarization of Dutch Court Verdicts Using Sequence-to-sequence Models",
    "volume": "workshop",
    "abstract": "With the legal sector embracing digitization, the increasing availability of information has led to a need for systems that can automatically summarize legal documents. Most existing research on legal text summarization has so far focused on extractive models, which can result in awkward summaries, as sentences in legal documents can be very long and detailed. In this study, we apply two abstractive summarization models on a Dutch legal domain dataset. The results show that existing models transfer quite well across domains and languages: the ROUGE scores of our experiments are comparable to state-of-the-art studies on English news article texts. Examining one of the models showed the capability of rewriting long legal sentences to much shorter ones, using mostly vocabulary from the source document. Human evaluation shows that for both models hand-made summaries are still perceived as more relevant and readable, and automatic summaries do not always capture elements such as background, considerations and judgement. Still, generated summaries are valuable if only a keyword summary or no summary at all is present",
    "checked": true,
    "id": "3423273c8603f1f22e5c5e41fbc0283122705507",
    "semantic_title": "abstractive summarization of dutch court verdicts using sequence-to-sequence models",
    "citation_count": 3,
    "authors": [
      "Marijn Schraagen",
      "Floris Bex",
      "Nick Van De Luijtgaarden",
      "Daniël Prijs"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.8": {
    "title": "Legal-Tech Open Diaries: Lesson learned on how to develop and deploy light-weight models in the era of humongous Language Models",
    "volume": "workshop",
    "abstract": "In the era of billion-parameter-sized Language Models (LMs), start-ups have to follow trends and adapt their technology accordingly. Nonetheless, there are open challenges since the development and deployment of large models comes with a need for high computational resources and has economical consequences. In this work, we follow the steps of the R&D group of a modern legal-tech start-up and present important insights on model development and deployment. We start from ground zero by pre-training multiple domain-specific multi-lingual LMs which are a better fit to contractual and regulatory text compared to the available alternatives (XLM-R). We present benchmark results of such models in a half-public half-private legal benchmark comprising 5 downstream tasks showing the impact of larger model size. Lastly, we examine the impact of a full-scale pipeline for model compression which includes: a) Parameter Pruning, b) Knowledge Distillation, and c) Quantization: The resulting models are much more efficient without sacrificing performance at large",
    "checked": true,
    "id": "810e7ff45d5cdb2318f88a2787a37b2fadd9bf82",
    "semantic_title": "legal-tech open diaries: lesson learned on how to develop and deploy light-weight models in the era of humongous language models",
    "citation_count": 1,
    "authors": [
      "Stelios Maroudas",
      "Sotiris Legkas",
      "Prodromos Malakasiotis",
      "Ilias Chalkidis"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.9": {
    "title": "Towards Cross-Domain Transferability of Text Generation Models for Legal Text",
    "volume": "workshop",
    "abstract": "Legalese can often be filled with verbose domain-specific jargon which can make it challenging to understand and use for non-experts. Creating succinct summaries of legal documents often makes it easier for user comprehension. However, obtaining labeled data for every domain of legal text is challenging, which makes cross-domain transferability of text generation models for legal text, an important area of research. In this paper, we explore the ability of existing state-of-the-art T5 & BART-based summarization models to transfer across legal domains. We leverage publicly available datasets across four domains for this task, one of which is a new resource for summarizing privacy policies, that we curate and release for academic research. Our experiments demonstrate the low cross-domain transferability of these models, while also highlighting the benefits of combining different domains. Further, we compare the effectiveness of standard metrics for this task and illustrate the vast differences in their performance",
    "checked": true,
    "id": "5df17721fc7ac2a5e33c0204977bf6ae0d5596bc",
    "semantic_title": "towards cross-domain transferability of text generation models for legal text",
    "citation_count": 2,
    "authors": [
      "Vinayshekhar Bannihatti Kumar",
      "Kasturi Bhattacharjee",
      "Rashmi Gangadharaiah"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.10": {
    "title": "Parameter-Efficient Legal Domain Adaptation",
    "volume": "workshop",
    "abstract": "Seeking legal advice is often expensive. Recent advancements in machine learning for solving complex problems can be leveraged to help make legal services more accessible to the public. However, real-life applications encounter significant challenges. State-of-the-art language models are growing increasingly large, making parameter-efficient learning increasingly important. Unfortunately, parameter-efficient methods perform poorly with small amounts of data, which are common in the legal domain (where data labelling costs are high). To address these challenges, we propose parameter-efficient legal domain adaptation, which uses vast unsupervised legal data from public legal forums to perform legal pre-training. This method exceeds or matches the fewshot performance of existing models such as LEGAL-BERT on various legal tasks while tuning only approximately 0.1% of model parameters. Additionally, we show that our method can achieve calibration comparable to existing methods across several tasks. To the best of our knowledge, this work is among the first to explore parameter-efficient methods of tuning language models in the legal domain",
    "checked": true,
    "id": "73b222c2808a95878c8a3aa762b9ba1d4dd9ecd4",
    "semantic_title": "parameter-efficient legal domain adaptation",
    "citation_count": 3,
    "authors": [
      "Jonathan Li",
      "Rohan Bhambhoria",
      "Xiaodan Zhu"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.11": {
    "title": "Processing Long Legal Documents with Pre-trained Transformers: Modding LegalBERT and Longformer",
    "volume": "workshop",
    "abstract": "Pre-trained Transformers currently dominate most NLP tasks. They impose, however, limits on the maximum input length (512 sub-words in BERT), which are too restrictive in the legal domain. Even sparse-attention models, such as Longformer and BigBird, which increase the maximum input length to 4,096 sub-words, severely truncate texts in three of the six datasets of LexGLUE. Simpler linear classifiers with TF-IDF features can handle texts of any length, require far less resources to train and deploy, but are usually outperformed by pre-trained Transformers. We explore two directions to cope with long legal texts: (i) modifying a Longformer warm-started from LegalBERT to handle even longer texts (up to 8,192 sub-words), and (ii) modifying LegalBERT to use TF-IDF representations. The first approach is the best in terms of performance, surpassing a hierarchical version of LegalBERT, which was the previous state of the art in LexGLUE. The second approach leads to computationally more efficient models at the expense of lower performance, but the resulting models still outperform overall a linear SVM with TF-IDF features in long legal document classification",
    "checked": true,
    "id": "156a66da569b68ea776c5db38e033aadb4755971",
    "semantic_title": "processing long legal documents with pre-trained transformers: modding legalbert and longformer",
    "citation_count": 14,
    "authors": [
      "Dimitris Mamakas",
      "Petros Tsotsi",
      "Ion Androutsopoulos",
      "Ilias Chalkidis"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.12": {
    "title": "Data-efficient end-to-end Information Extraction for Statistical Legal Analysis",
    "volume": "workshop",
    "abstract": "Legal practitioners often face a vast amount of documents. Lawyers, for instance, search for appropriate precedents favorable to their clients, while the number of legal precedents is ever-growing. Although legal search engines can assist finding individual target documents and narrowing down the number of candidates, retrieved information is often presented as unstructured text and users have to examine each document thoroughly which could lead to information overloading. This also makes their statistical analysis challenging. Here, we present an end-to-end information extraction (IE) system for legal documents. By formulating IE as a generation task, our system can be easily applied to various tasks without domain-specific engineering effort. The experimental results of four IE tasks on Korean precedents shows that our IE system can achieve competent scores (-2.3 on average) compared to the rule-based baseline with as few as 50 training examples per task and higher score (+5.4 on average) with 200 examples. Finally, our statistical analysis on two case categories — drunk driving and fraud — with 35k precedents reveals the resulting structured information from our IE system faithfully reflects the macroscopic features of Korean legal system",
    "checked": true,
    "id": "2f0857f00624adfa3c1050fa5390273835fa239a",
    "semantic_title": "data-efficient end-to-end information extraction for statistical legal analysis",
    "citation_count": 2,
    "authors": [
      "Wonseok Hwang",
      "Saehee Eom",
      "Hanuhl Lee",
      "Hai Jin Park",
      "Minjoon Seo"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.13": {
    "title": "Semantic Segmentation of Legal Documents via Rhetorical Roles",
    "volume": "workshop",
    "abstract": "Legal documents are unstructured, use legal jargon, and have considerable length, making them difficult to process automatically via conventional text processing techniques. A legal document processing system would benefit substantially if the documents could be segmented into coherent information units. This paper proposes a new corpus of legal documents annotated (with the help of legal experts) with a set of 13 semantically coherent units labels (referred to as Rhetorical Roles), e.g., facts, arguments, statute, issue, precedent, ruling, and ratio. We perform a thorough analysis of the corpus and the annotations. For automatically segmenting the legal documents, we experiment with the task of rhetorical role prediction: given a document, predict the text segments corresponding to various roles. Using the created corpus, we experiment extensively with various deep learning-based baseline models for the task. Further, we develop a multitask learning (MTL) based deep model with document rhetorical role label shift as an auxiliary task for segmenting a legal document. The proposed model shows superior performance over the existing models. We also experiment with model performance in the case of domain transfer and model distillation techniques to see the model performance in limited data conditions",
    "checked": true,
    "id": "378773dffdb7f6b845807a4c612422bcf76cc543",
    "semantic_title": "semantic segmentation of legal documents via rhetorical roles",
    "citation_count": 30,
    "authors": [
      "Vijit Malik",
      "Rishabh Sanjay",
      "Shouvik Kumar Guha",
      "Angshuman Hazarika",
      "Shubham Kumar Nigam",
      "Arnab Bhattacharya",
      "Ashutosh Modi"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.14": {
    "title": "Privacy-Preserving Models for Legal Natural Language Processing",
    "volume": "workshop",
    "abstract": "Pre-training large transformer models with in-domain data improves domain adaptation and helps gain performance on the domain-specific downstream tasks. However, sharing models pre-trained on potentially sensitive data is prone to adversarial privacy attacks. In this paper, we asked to which extent we can guarantee privacy of pre-training data and, at the same time, achieve better downstream performance on legal tasks without the need of additional labeled data. We extensively experiment with scalable self-supervised learning of transformer models under the formal paradigm of differential privacy and show that under specific training configurations we can improve downstream performance without sacrifying privacy protection for the in-domain data. Our main contribution is utilizing differential privacy for large-scale pre-training of transformer language models in the legal NLP domain, which, to the best of our knowledge, has not been addressed before",
    "checked": true,
    "id": "cb8374f90c7b61f07b257377b4ce5e6d917c0df3",
    "semantic_title": "privacy-preserving models for legal natural language processing",
    "citation_count": 6,
    "authors": [
      "Ying Yin",
      "Ivan Habernal"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.15": {
    "title": "Named Entity Recognition in Indian court judgments",
    "volume": "workshop",
    "abstract": "Identification of named entities from legal texts is an essential building block for developing other legal Artificial Intelligence applications. Named Entities in legal texts are slightly different and more fine-grained than commonly used named entities like Person, Organization, Location etc. In this paper, we introduce a new corpus of 46545 annotated legal named entities mapped to 14 legal entity types. The Baseline model for extracting legal named entities from judgment text is also developed",
    "checked": true,
    "id": "327c84ba20f01bd118f019b3e4aa71d03d1824bc",
    "semantic_title": "named entity recognition in indian court judgments",
    "citation_count": 28,
    "authors": [
      "Prathamesh Kalamkar",
      "Astha Agarwal",
      "Aman Tiwari",
      "Smita Gupta",
      "Saurabh Karn",
      "Vivek Raghavan"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.17": {
    "title": "The Legal Argument Reasoning Task in Civil Procedure",
    "volume": "workshop",
    "abstract": "We present a new NLP task and dataset from the domain of the U.S. civil procedure. Each instance of the dataset consists of a general introduction to the case, a particular question, and a possible solution argument, accompanied by a detailed analysis of why the argument applies in that case. Since the dataset is based on a book aimed at law students, we believe that it represents a truly complex task for benchmarking modern legal language models. Our baseline evaluation shows that fine-tuning a legal transformer provides some advantage over random baseline models, but our analysis reveals that the actual ability to infer legal arguments remains a challenging open research question",
    "checked": true,
    "id": "bce21f12b35d187aa6582be5641d3373cbde6468",
    "semantic_title": "the legal argument reasoning task in civil procedure",
    "citation_count": 4,
    "authors": [
      "Leonard Bongard",
      "Lena Held",
      "Ivan Habernal"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.18": {
    "title": "Efficient Deep Learning-based Sentence Boundary Detection in Legal Text",
    "volume": "workshop",
    "abstract": "A key component of the Natural Language Processing (NLP) pipeline is Sentence Boundary Detection (SBD). Erroneous SBD could affect other processing steps and reduce performance. A few criteria based on punctuation and capitalization are necessary to identify sentence borders in well-defined corpora. However, due to several grammatical ambiguities, the complex structure of legal data poses difficulties for SBD. In this paper, we have trained a neural network framework for identifying the end of the sentence in legal text. We used several state-of-the-art deep learning models, analyzed their performance, and identified that Convolutional Neural Network(CNN) outperformed other deep learning frameworks. We compared the results with rule-based, statistical, and transformer-based frameworks. The best neural network model outscored the popular rule-based framework with an improvement of 8% in the F1 score. Although domain-specific statistical models have slightly improved performance, the trained CNN is 80 times faster in run-time and doesn't require much feature engineering. Furthermore, after extensive pretraining, the transformer models fall short in overall performance compared to the best deep learning model",
    "checked": true,
    "id": "5b6763c6c3a22d03b0b7017bf883e555f8da7723",
    "semantic_title": "efficient deep learning-based sentence boundary detection in legal text",
    "citation_count": 1,
    "authors": [
      "Reshma Sheik",
      "Gokul T",
      "S Nirmala"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.19": {
    "title": "Tracking Semantic Shifts in German Court Decisions with Diachronic Word Embeddings",
    "volume": "workshop",
    "abstract": "Language and its usage change over time. While legal language is arguably more stable than everyday language, it is still subject to change. Sometimes it changes gradually and slowly, sometimes almost instantaneously, for example through legislative changes. This paper presents an application of diachronic word embeddings to track changes in the usage of language by German courts triggered by changing legislation, based on a corpus of more than 200,000 documents. The results show the swift and lasting effect that changes in legislation can have on the usage of language by courts and suggest that using time-restricted word embedding models could be beneficial for downstream NLP tasks",
    "checked": true,
    "id": "53a98e817fa390740d2f3243cba53e8976cecf9d",
    "semantic_title": "tracking semantic shifts in german court decisions with diachronic word embeddings",
    "citation_count": 0,
    "authors": [
      "Daniel Braun"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.20": {
    "title": "Should I disclose my dataset? Caveats between reproducibility and individual data rights",
    "volume": "workshop",
    "abstract": "Natural language processing techniques have helped domain experts solve legal problems. Digital availability of court documents increases possibilities for researchers, who can access them as a source for building datasets — whose disclosure is aligned with good reproducibility practices in computational research. Large and digitized court systems, such as the Brazilian one, are prone to be explored in that sense. However, personal data protection laws impose restrictions on data exposure and state principles about which researchers should be mindful. Special caution must be taken in cases with human rights violations, such as gender discrimination, over which we elaborate as an example of interest. We present legal and ethical considerations on the issue, as well as guidelines for researchers dealing with this kind of data and deciding whether to disclose it",
    "checked": true,
    "id": "5da195cd5bc6b07da02159adfbc40b1335093046",
    "semantic_title": "should i disclose my dataset? caveats between reproducibility and individual data rights",
    "citation_count": 0,
    "authors": [
      "Raysa M. Benatti",
      "Camila M. L. Villarroel",
      "Sandra Avila",
      "Esther L. Colombini",
      "Fabiana Severi"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.21": {
    "title": "Attack on Unfair ToS Clause Detection: A Case Study using Universal Adversarial Triggers",
    "volume": "workshop",
    "abstract": "Recent work has demonstrated that natural language processing techniques can support consumer protection by automatically detecting unfair clauses in the Terms of Service (ToS) Agreement. This work demonstrates that transformer-based ToS analysis systems are vulnerable to adversarial attacks. We conduct experiments attacking an unfair-clause detector with universal adversarial triggers. Experiments show that a minor perturbation of the text can considerably reduce the detection performance. Moreover, to measure the detectability of the triggers, we conduct a detailed human evaluation study by collecting both answer accuracy and response time from the participants. The results show that the naturalness of the triggers remains key to tricking readers",
    "checked": true,
    "id": "9d2328298a0448bbcfad894accc5b141a5eadb0f",
    "semantic_title": "attack on unfair tos clause detection: a case study using universal adversarial triggers",
    "citation_count": 0,
    "authors": [
      "Shanshan Xu",
      "Irina Broda",
      "Rashid Haddad",
      "Marco Negrini",
      "Matthias Grabmair"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.22": {
    "title": "E-NER — An Annotated Named Entity Recognition Corpus of Legal Text",
    "volume": "workshop",
    "abstract": "Identifying named entities such as a person, location or organization, in documents can highlight key information to readers. Training Named Entity Recognition (NER) models requires an annotated data set, which can be a time-consuming labour-intensive task. Nevertheless, there are publicly available NER data sets for general English. Recently there has been interest in developing NER for legal text. However, prior work and experimental results reported here indicate that there is a significant degradation in performance when NER methods trained on a general English data set are applied to legal text. We describe a publicly available legal NER data set, called E-NER, based on legal company filings available from the US Securities and Exchange Commission's EDGAR data set. Training a number of different NER algorithms on the general English CoNLL-2003 corpus but testing on our test collection confirmed significant degradations in accuracy, as measured by the F1-score, of between 29.4% and 60.4%, compared to training and testing on the E-NER collection",
    "checked": true,
    "id": "2423905453ea1bbae03727fd81890007cccedd43",
    "semantic_title": "e-ner — an annotated named entity recognition corpus of legal text",
    "citation_count": 11,
    "authors": [
      "Ting Wai Terence Au",
      "Vasileios Lampos",
      "Ingemar Cox"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.24": {
    "title": "Detecting Relevant Differences Between Similar Legal Texts",
    "volume": "workshop",
    "abstract": "Given two similar legal texts, is it useful to be able to focus only on the parts that contain relevant differences. However, because of variation in linguistic structure and terminology, it is not easy to identify true semantic differences. An accurate difference detection model between similar legal texts is therefore in demand, in order to increase the efficiency of legal research and document analysis. In this paper, we automatically label a training dataset of sentence pairs using an existing legal resource of international investment treaties that were already manually annotated with metadata. Then we propose models based on state-of-the-art deep learning techniques for the novel task of detecting relevant differences. In addition to providing solutions for this task, we include models for automatically producing metadata for the treaties that do not have it",
    "checked": true,
    "id": "50825767c31d4a069cb8bc550e262d5efad9dd6a",
    "semantic_title": "detecting relevant differences between similar legal texts",
    "citation_count": 1,
    "authors": [
      "Xiang Li",
      "Jiaxun Gao",
      "Diana Inkpen",
      "Wolfgang Alschner"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.25": {
    "title": "Legal and Political Stance Detection of SCOTUS Language",
    "volume": "workshop",
    "abstract": "We analyze publicly available US Supreme Court documents using automated stance detection. In the first phase of our work, we investigate the extent to which the Court's public-facing language is political. We propose and calculate two distinct ideology metrics of SCOTUS justices using oral argument transcripts. We then compare these language-based metrics to existing social scientific measures of the ideology of the Supreme Court and the public. Through this cross-disciplinary analysis, we find that justices who are more responsive to public opinion tend to express their ideology during oral arguments. This observation provides a new kind of evidence in favor of the attitudinal change hypothesis of Supreme Court justice behavior. As a natural extension of this political stance detection, we propose the more specialized task of legal stance detection with our new dataset SC-stance, which matches written opinions to legal questions. We find competitive performance on this dataset using language adapters trained on legal documents",
    "checked": true,
    "id": "e329a7326ac8a96e9f224d8c41adb247e4a9a2b8",
    "semantic_title": "legal and political stance detection of scotus language",
    "citation_count": 4,
    "authors": [
      "Noah Bergam",
      "Emily Allaway",
      "Kathleen Mckeown"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.26": {
    "title": "Graph-based Keyword Planning for Legal Clause Generation from Topics",
    "volume": "workshop",
    "abstract": "Generating domain-specific content such as legal clauses based on minimal user-provided information can be of significant benefit in automating legal contract generation. In this paper, we propose a controllable graph-based mechanism that can generate legal clauses using only the topic or type of the legal clauses. Our pipeline consists of two stages involving a graph-based planner followed by a clause generator. The planner outlines the content of a legal clause as a sequence of keywords in the order of generic to more specific clause information based on the input topic using a controllable graph-based mechanism. The generation stage takes in a given plan and generates a clause. The pipeline consists of a graph-based planner followed by text generation. We illustrate the effectiveness of our proposed two-stage approach on a broad set of clause topics in contracts",
    "checked": true,
    "id": "808245dbe81f988fbcf5143d0762462500e705c0",
    "semantic_title": "graph-based keyword planning for legal clause generation from topics",
    "citation_count": 0,
    "authors": [
      "Sagar Joshi",
      "Sumanth Balaji",
      "Aparna Garimella",
      "Vasudeva Varma"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.27": {
    "title": "Automatic Classification of Legal Violations in Cookie Banner Texts",
    "volume": "workshop",
    "abstract": "Cookie banners are designed to request consent from website visitors for their personal data. Recent research suggest that a high percentage of cookie banners violate legal regulations as defined by the General Data Protection Regulation (GDPR) and the ePrivacy Directive. In this paper, we focus on language used in these cookie banners, and whether these violations can be automatically detected, or not. We make use of a small cookie banner dataset that is annotated by five experts for legal violations and test it with state of the art classification models, namely BERT, LEGAL-BERT, BART in a zero-shot setting and BERT with LIWC embeddings. Our results show that none of the models outperform the others in all classes, but in general, BERT and LEGAL-BERT provide the highest accuracy results (70%-97%). However, they are influenced by the small size and the unbalanced distributions in the dataset",
    "checked": true,
    "id": "fde9464a2bcfd5c79590602c1d82b65828dde9d8",
    "semantic_title": "automatic classification of legal violations in cookie banner texts",
    "citation_count": 3,
    "authors": [
      "Marieke Van Hofslot",
      "Almila Akdag Salah",
      "Albert Gatt",
      "Cristiana Santos"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.28": {
    "title": "Text Simplification for Legal Domain: {I}nsights and Challenges",
    "volume": "workshop",
    "abstract": "Legal documents such as contracts contain complex and domain-specific jargons, long and nested sentences, and often present with several details that may be difficult to understand for laypeople without domain expertise. In this paper, we explore the problem of text simplification (TS) in legal domain. The main challenge to this is the lack of availability of complex-simple parallel datasets for the legal domain. We investigate some of the existing datasets, methods, and metrics in the TS literature for simplifying legal texts, and perform human evaluation to analyze the gaps. We present some of the challenges involved, and outline a few open questions that need to be addressed for future research in this direction",
    "checked": true,
    "id": "6dbe7b892c51d93d1a553de1a8bd254efe29d477",
    "semantic_title": "text simplification for legal domain: {i}nsights and challenges",
    "citation_count": 7,
    "authors": [
      "Aparna Garimella",
      "Abhilasha Sancheti",
      "Vinay Aggarwal",
      "Ananya Ganesh",
      "Niyati Chhaya",
      "Nandakishore Kambhatla"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.29": {
    "title": "Legal Named Entity Recognition with Multi-Task Domain Adaptation",
    "volume": "workshop",
    "abstract": "Named Entity Recognition (NER) is a well-explored area from Information Retrieval and Natural Language Processing with an extensive research community. Despite that, few languages, such as English and German, are well-resourced, whereas many other languages, such as Romanian, have scarce resources, especially in domain-specific applications. In this work, we address the NER problem in the legal domain from both Romanian and German languages and evaluate the performance of our proposed method based on domain adaptation. We employ multi-task learning to jointly train a neural network on two legal and general domains and perform adaptation among them. The results show that domain adaptation increase performances by a small amount, under 1%, while considerable improvements are in the recall metric",
    "checked": true,
    "id": "10789b2688396fa5e753b7a1ccc827eb8399ff96",
    "semantic_title": "legal named entity recognition with multi-task domain adaptation",
    "citation_count": 2,
    "authors": [
      "Răzvan-Alexandru Smădu",
      "Ion-Robert Dinică",
      "Andrei-Marius Avram",
      "Dumitru-Clementin Cercel",
      "Florin Pop",
      "Mihaela-Claudia Cercel"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.30": {
    "title": "Computing and Exploiting Document Structure to Improve Unsupervised Extractive Summarization of Legal Case Decisions",
    "volume": "workshop",
    "abstract": "Though many algorithms can be used to automatically summarize legal case decisions, most fail to incorporate domain knowledge about how important sentences in a legal decision relate to a representation of its document structure. For example, analysis of a legal case sum- marization dataset demonstrates that sentences serving different types of argumentative roles in the decision appear in different sections of the document. In this work, we propose an unsupervised graph-based ranking model that uses a reweighting algorithm to exploit properties of the document structure of legal case decisions. We also explore the impact of using different methods to compute the document structure. Results on the Canadian Legal Case Law dataset show that our proposed method outperforms several strong baselines",
    "checked": true,
    "id": "22738832547df9f924ebf9267b5f2e262919c8f7",
    "semantic_title": "computing and exploiting document structure to improve unsupervised extractive summarization of legal case decisions",
    "citation_count": 4,
    "authors": [
      "Yang Zhong",
      "Diane Litman"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.31": {
    "title": "AraLegal-BERT: A pretrained language model for Arabic Legal text",
    "volume": "workshop",
    "abstract": "The effectiveness of the bidirectional encoder representations from transformers (BERT) model for multiple linguistic tasks is well documented. However, its potential for a narrow and specific domain, such as legal, has not been fully explored. In this study, we examine the use of BERT in the Arabic legal domain and customize this language model for several downstream tasks using different domain-relevant training and test datasets to train BERT from scratch. We introduce AraLegal-BERT, a bidirectional encoder transformer-based model that has been thoroughly tested and carefully optimized with the goal of amplifying the impact of natural language processing-driven solutions on jurisprudence, legal documents, and legal practice. We fine-tuned AraLegal-BERT and evaluated it against three BERT variants for the Arabic language in three natural language understanding tasks. The results showed that the base version of AraLegal-BERT achieved better accuracy than the typical and original BERT model concerning legal texts",
    "checked": true,
    "id": "f9d01f8ab34bb707afdee382350f7ce23534c2d9",
    "semantic_title": "aralegal-bert: a pretrained language model for arabic legal text",
    "citation_count": 7,
    "authors": [
      "Muhammad Al-qurishi",
      "Sarah Alqaseemi",
      "Riad Souissi"
    ]
  },
  "https://aclanthology.org/2022.nllp-1.32": {
    "title": "An Efficient Active Learning Pipeline for Legal Text Classification",
    "volume": "workshop",
    "abstract": "Active Learning (AL) is a powerful tool for learning with less labeled data, in particular, for specialized domains, like legal documents, where unlabeled data is abundant, but the annotation requires domain expertise and is thus expensive. Recent works have shown the effectiveness of AL strategies for pre-trained language models. However, most AL strategies require a set of labeled samples to start with, which is expensive to acquire. In addition, pre-trained language models have been shown unstable during fine-tuning with small datasets, and their embeddings are not semantically meaningful. In this work, we propose a pipeline for effectively using active learning with pre-trained language models in the legal domain. To this end, we leverage the available unlabeled data in three phases. First, we continue pre-training the model to adapt it to the downstream task. Second, we use knowledge distillation to guide the model's embeddings to a semantically meaningful space. Finally, we propose a simple, yet effective, strategy to find the initial set of labeled samples with fewer actions compared to existing methods. Our experiments on Contract-NLI, adapted to the classification task, and LEDGAR benchmarks show that our approach outperforms standard AL strategies, and is more efficient. Furthermore, our pipeline reaches comparable results to the fully-supervised approach with a small performance gap, and dramatically reduced annotation cost. Code and the adapted data will be made available",
    "checked": true,
    "id": "428900d3e1059ed93a00d641421ff6edce903794",
    "semantic_title": "an efficient active learning pipeline for legal text classification",
    "citation_count": 0,
    "authors": [
      "Sepideh Mamooler",
      "Rémi Lebret",
      "Stephane Massonnet",
      "Karl Aberer"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.1": {
    "title": "A unified framework for cross-domain and cross-task learning of mental health conditions",
    "volume": "workshop",
    "abstract": "The detection of mental health conditions based on an individual's use of language has received considerable attention in the NLP community. However, most work has focused on single-task and single-domain models, limiting the semantic space that they are able to cover and risking significant cross-domain loss. In this paper, we present two approaches towards a unified framework for cross-domain and cross-task learning for the detection of depression, post-traumatic stress disorder and suicide risk across different platforms that further utilizes inductive biases across tasks. Firstly, we develop a lightweight model using a general set of features that sets a new state of the art on several tasks while matching the performance of more complex task- and domain-specific systems on others. We also propose a multi-task approach and further extend our framework to explicitly capture the affective characteristics of someone's language, further consolidating transfer of inductive biases and of shared linguistic characteristics. Finally, we present a novel dynamically adaptive loss weighting approach that allows for more stable learning across imbalanced datasets and better neural generalization performance. Our results demonstrate the effectiveness of our unified framework for mental ill-health detection across a number of diverse English datasets",
    "checked": true,
    "id": "33477d1ccd5025c1197cad80c88a73f2e8609b59",
    "semantic_title": "a unified framework for cross-domain and cross-task learning of mental health conditions",
    "citation_count": 2,
    "authors": [
      "Huikai Chua",
      "Andrew Caines",
      "Helen Yannakoudakis"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.2": {
    "title": "Critical Perspectives: A Benchmark Revealing Pitfalls in PerspectiveAPI",
    "volume": "workshop",
    "abstract": "Detecting \"toxic\" language in internet content is a pressing social and technical challenge. In this work, we focus on Perspective API from Jigsaw, a state-of-the-art tool that promises to score the \"toxicity\" of text, with a recent model update that claims impressive results (Lees et al., 2022). We seek to challenge certain normative claims about toxic language by proposing a new benchmark, Selected Adversarial SemanticS, or SASS. We evaluate Perspective on SASS, and compare to low-effort alternatives, like zero-shot and few-shot GPT-3 prompt models, in binary classification settings. We find that Perspective exhibits troubling shortcomings across a number of our toxicity categories. SASS provides a new tool for evaluating performance on previously undetected toxic language that avoids common normative pitfalls. Our work leads us to emphasize the importance of questioning assumptions made by tools already in deployment for toxicity detection in order to anticipate and prevent disparate harms",
    "checked": true,
    "id": "b4d9cba448229a11fb07a9e7d1451015a4ec6612",
    "semantic_title": "critical perspectives: a benchmark revealing pitfalls in perspectiveapi",
    "citation_count": 1,
    "authors": [
      "Lucas Rosenblatt",
      "Lorena Piedras",
      "Julia Wilkins"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.3": {
    "title": "Securely Capturing People's Interactions with Voice Assistants at Home: A Bespoke Tool for Ethical Data Collection",
    "volume": "workshop",
    "abstract": "Speech production is nuanced and unique to every individual, but today's Spoken Dialogue Systems (SDSs) are trained to use general speech patterns to successfully improve performance on various evaluation metrics. However, these patterns do not apply to certain user groups - often the very people that can benefit the most from SDSs. For example, people with dementia produce more disfluent speech than the general population. In order to evaluate systems with specific user groups in mind, and to guide the design of such systems to deliver maximum benefit to these users, data must be collected securely. In this short paper we present CVR-SI, a bespoke tool for ethical data collection. Designed for the healthcare domain, we argue that it should also be used in more general settings. We detail how off-the-shelf solutions fail to ensure that sensitive data remains secure and private. We then describe the ethical design and security features of our device, with a full guide on how to build both the hardware and software components of CVR-SI. Our design ensures inclusivity to all researchers in this field, particularly those who are not hardware experts. This guarantees everyone can collect appropriate data for human evaluation ethically, securely, and in a timely manner",
    "checked": true,
    "id": "e6194f0d52f9eab39dcd87213808e04279ae8f25",
    "semantic_title": "securely capturing people's interactions with voice assistants at home: a bespoke tool for ethical data collection",
    "citation_count": 3,
    "authors": [
      "Angus Addlesee"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.4": {
    "title": "Leveraging World Knowledge in Implicit Hate Speech Detection",
    "volume": "workshop",
    "abstract": "While much attention has been paid to identifying explicit hate speech, implicit hateful expressions that are disguised in coded or indirect language are pervasive and remain a major challenge for existing hate speech detection systems. This paper presents the first attempt to apply Entity Linking (EL) techniques to both explicit and implicit hate speech detection, where we show that such real world knowledge about entity mentions in a text does help models better detect hate speech, and the benefit of adding it into the model is more pronounced when explicit entity triggers (e.g., rally, KKK) are present. We also discuss cases where real world knowledge does not add value to hate speech detection, which provides more insights into understanding and modeling the subtleties of hate speech",
    "checked": true,
    "id": "e2e5d7042ceb86559390e35c0f497d2f0e2f2dc2",
    "semantic_title": "leveraging world knowledge in implicit hate speech detection",
    "citation_count": 3,
    "authors": [
      "Jessica Lin"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.5": {
    "title": "A Dataset of Sustainable Diet Arguments on Twitter",
    "volume": "workshop",
    "abstract": "Sustainable development requires a significant change in our dietary habits. Argument mining can help achieve this goal by both affecting and helping understand people's behavior. We design an annotation scheme for argument mining from online discourse around sustainable diets, including novel evidence types specific to this domain. Using Twitter as a source, we crowdsource a dataset of 597 tweets annotated in relation to 5 topics. We benchmark a variety of NLP models on this dataset, demonstrating strong performance in some sub-tasks, while highlighting remaining challenges",
    "checked": true,
    "id": "7d9623ff66158e194b61f52395a259c1bb385262",
    "semantic_title": "a dataset of sustainable diet arguments on twitter",
    "citation_count": 4,
    "authors": [
      "Marcus Hansen",
      "Daniel Hershcovich"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.6": {
    "title": "Impacts of Low Socio-economic Status on Educational Outcomes: A Narrative Based Analysis",
    "volume": "workshop",
    "abstract": "Socioeconomic status (SES) is a metric used to compare a person's social standing based on their income, level of education, and occupation. Students from low SES backgrounds are those whose parents have low income and have limited access to the resources and opportunities they need to aid their success. Researchers have studied many issues and solutions for students with low SES, and there is a lot of research going on in many fields, especially in the social sciences. Computer science, however, has not yet as a field turned its considerable potential to addressing these inequalities. Utilizing Natural Language Processing (NLP) methods and technology, our work aims to address these disparities and ways to bridge the gap. We built a simple string matching algorithm including Latent Dirichlet Allocation (LDA) topic model and Open Information Extraction (open IE) to generate relational triples that are connected to the context of the students' challenges, and the strategies they follow to overcome them. We manually collected 16 narratives about the experiences of low SES students in higher education from a publicly accessible internet forum (Reddit) and tested our model on them. We demonstrate that our strategy is effective (from 37.50% to 80%) in gathering contextual data about low SES students, in particular, about their difficulties while in a higher educational institution and how they improve their situation. A detailed error analysis suggests that increase of data, improvement of the LDA model, and quality of triples can help get better results from our model. For the advantage of other researchers, we make our code available",
    "checked": true,
    "id": "5171fefa46bb5fb44a2346e69a2d5bf76ed90da5",
    "semantic_title": "impacts of low socio-economic status on educational outcomes: a narrative based analysis",
    "citation_count": 0,
    "authors": [
      "Motti Kelbessa",
      "Ilyas Jamil",
      "Labiba Jahan"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.9": {
    "title": "Enhancing Crisis-Related Tweet Classification with Entity-Masked Language Modeling and Multi-Task Learning",
    "volume": "workshop",
    "abstract": "Social media has become an important information source for crisis management and provides quick access to ongoing developments and critical information. However, classification models suffer from event-related biases and highly imbalanced label distributions which still poses a challenging task. To address these challenges, we propose a combination of entity-masked language modeling and hierarchical multi-label classification as a multi-task learning problem. We evaluate our method on tweets from the TREC-IS dataset and show an absolute performance gain w.r.t. F1-score of up to 10% for actionable information types. Moreover, we found that entity-masking reduces the effect of overfitting to in-domain events and enables improvements in cross-event generalization",
    "checked": true,
    "id": "41ee0d709226ab99ce5ee44254c0e64df4fa99f2",
    "semantic_title": "enhancing crisis-related tweet classification with entity-masked language modeling and multi-task learning",
    "citation_count": 3,
    "authors": [
      "Philipp Seeberger",
      "Korbinian Riedhammer"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.10": {
    "title": "Misinformation Detection in the Wild: News Source Classification as a Proxy for Non-article Texts",
    "volume": "workshop",
    "abstract": "Creating classifiers of disinformation is time-consuming, expensive, and requires vast effort from experts spanning different fields. Even when these efforts succeed, their roll-out to publicly available applications stagnates. While these models struggle to find their consumer-accessible use, disinformation behavior online evolves at a pressing speed. The hoaxes get shared in various abbreviations on social networks, often in user-restricted areas, making external monitoring and intervention virtually impossible. To re-purpose existing NLP methods for the new paradigm of sharing misinformation, we propose leveraging information about given texts' originating news sources to proxy the respective text's trustworthiness. We first present a methodology for determining the sources' overall credibility. We demonstrate our pipeline construction in a specific language and introduce CNSC: a novel dataset for Czech articles' news source and source credibility classification. We constitute initial benchmarks on multiple architectures. Lastly, we create in-the-wild wrapper applications of the trained models: a chatbot, a browser extension, and a standalone web application",
    "checked": true,
    "id": "3ec460ec18867721d4bc9e4178299726a9b3f235",
    "semantic_title": "misinformation detection in the wild: news source classification as a proxy for non-article texts",
    "citation_count": 0,
    "authors": [
      "Matyas Bohacek"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.11": {
    "title": "Modelling Persuasion through Misuse of Rhetorical Appeals",
    "volume": "workshop",
    "abstract": "It is important to understand how people use words to persuade each other. This helps understand debate, and detect persuasive narratives in regard to e.g. misinformation. While computational modelling of some aspects of persuasion has received some attention, a way to unify and describe the overall phenomenon of when persuasion becomes undesired and problematic, is missing. In this paper, we attempt to address this by proposing a taxonomy of computational persuasion. Drawing upon existing research and resources, this paper shows how to re-frame and re-organise current work into a coherent framework targeting the misuse of rhetorical appeals. As a study to validate these re-framings, we then train and evaluate models of persuasion adapted to our taxonomy. Our results show an application of our taxonomy, and we are able to detecting misuse of rhetorical appeals, finding that these are more often used in misinformative contexts than in true ones",
    "checked": true,
    "id": "57094ba5104464f11b512210aa2b4e66c8147552",
    "semantic_title": "modelling persuasion through misuse of rhetorical appeals",
    "citation_count": 4,
    "authors": [
      "Amalie Pauli",
      "Leon Derczynski",
      "Ira Assent"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.12": {
    "title": "Breaking through Inequality of Information Acquisition among Social Classes: A Modest Effort on Measuring \"Fun",
    "volume": "workshop",
    "abstract": "With the identification of the inequality encoded in information acquisition among social classes, we propose to leverage a powerful concept that has never been studied as a linguistic construct, \"fun\", to deconstruct the inequality. Inspired by theories in sociology, we draw connection between social class and information cocoon, through the lens of fun, and hypothesize the measurement of \"how fun one's dominating social cocoon is\" to be an indicator of the social class of an individual. Following this, we propose an NLP framework to combat the issue by measuring how fun one's information cocoon is, and empower individuals to emancipate from their trapped cocoons. We position our work to be a domain-agnostic framework that can be deployed in a lot of downstream cases, and is one that aims to deconstruct, as opposed to reinforcing, the traditional social structure of beneficiaries",
    "checked": true,
    "id": "a4dd1f44445edd463f5f335a43412cb5b7305941",
    "semantic_title": "breaking through inequality of information acquisition among social classes: a modest effort on measuring \"fun",
    "citation_count": 0,
    "authors": [
      "Chenghao Xiao",
      "Baicheng Sun",
      "Jindi Wang",
      "Mingyue Liu",
      "Jiayi Feng"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.13": {
    "title": "Using NLP to Support English Teaching in Rural Schools",
    "volume": "workshop",
    "abstract": "We present a web application for creating games and exercises for teaching English as a foreign language with the help of NLP tools. The application contains different kinds of games such as crosswords, word searches, a memory game, and a multiplayer game based on the classic battleship pen and paper game. This application was built with the aim of supporting teachers in rural schools that are teaching English lessons, so they can easily create interactive and engaging activities for their students. We present the context and history of the project, the current state of the web application, and some ideas on how we will expand it in the future",
    "checked": true,
    "id": "2f6922e5b4b6085afacfdbfbdd6d313fc01a4fbe",
    "semantic_title": "using nlp to support english teaching in rural schools",
    "citation_count": 1,
    "authors": [
      "Luis Chiruzzo",
      "Laura Musto",
      "Santiago Gongora",
      "Brian Carpenter",
      "Juan Filevich",
      "Aiala Rosa"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.14": {
    "title": "Am I Answering My Job Interview Questions Right?\": A NLP Approach to Predict Degree of Explanation in Job Interview Responses",
    "volume": "workshop",
    "abstract": "Providing the right amount of explanation in an employment interview can help the interviewee effectively communicate their skills and experience to the interviewer and convince the she/he is the right candidate for the job. This paper examines natural language processing (NLP) approaches, including word-based tokenization, lexicon-based representations, and pre-trained embeddings with deep learning models, for detecting the degree of explanation in a job interview response. These are exemplified in a study of 24 military veterans who are the focal group of this study, since they can experience unique challenges in job interviews due to the unique verbal communication style that is prevalent in the military. Military veterans conducted mock interviews with industry recruiters and data from these interviews were transcribed and analyzed. Results indicate that the feasibility of automated NLP methods for detecting the degree of explanation in an interview response. Features based on tokenizer analysis are the most effective in detecting under-explained responses (i.e., 0.29 F1-score), while lexicon-based methods depict the higher performance in detecting over-explanation (i.e., 0.51 F1-score). Findings from this work lay the foundation for the design of intelligent assistive technologies that can provide personalized learning pathways to job candidates, especially those belonging to sensitive or under-represented populations, and helping them succeed in employment job interviews, ultimately contributing to an inclusive workforce",
    "checked": true,
    "id": "c679ce89b07232701c16c6407f0e1d0cc013bc10",
    "semantic_title": "am i answering my job interview questions right?\": a nlp approach to predict degree of explanation in job interview responses",
    "citation_count": 0,
    "authors": [
      "Raghu Verrap",
      "Ehsanul Nirjhar",
      "Ani Nenkova",
      "Theodora Chaspari"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.15": {
    "title": "Identifying Condescending Language: A Tale of Two Distinct Phenomena?",
    "volume": "workshop",
    "abstract": "Patronizing and condescending language is characterized, among others, by its subtle nature. It thus seems reasonable to assume that detecting condescending language in text would be harder than detecting more explicitly harmful language, such as hate speech. However, the results of a SemEval-2022 Task devoted to this topic paint a different picture, with the top-performing systems achieving remarkably strong results. In this paper, we analyse the surprising effectiveness of standard text classification methods in more detail. In particular, we highlight the presence of two rather different types of condescending language in the dataset from the SemEval task. Some inputs are condescending because of the way they talk about a particular subject, i.e. condescending language in this case is a linguistic phenomenon, which can, in principle, be learned from training examples. However, other inputs are condescending because of the nature of what is said, rather than the way in which it is expressed, e.g. by emphasizing stereotypes about a given community. In such cases, our ability to detect condescending language, with current methods, largely depends on the presence of similar examples in the training data",
    "checked": true,
    "id": "93c29385302c20f6bbf6d710b851439725a0cfb1",
    "semantic_title": "identifying condescending language: a tale of two distinct phenomena?",
    "citation_count": 0,
    "authors": [
      "Carla Perez Almendros",
      "Steven Schockaert"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.17": {
    "title": "BELA: Bot for English Language Acquisition",
    "volume": "workshop",
    "abstract": "In this paper, we introduce a conversational agent (chatbot) for Hindi-speaking youth called BELA—Bot for English Language Acquisition. Developed for young underprivileged students at an Indian non-profit, the agent supports both Hindi and Hinglish (code-switched Hindi and English, written primarily with English orthography) utterances. BELA has two interaction modes: a question-answering mode for classic English language learning tasks like word meanings, translations, reading passage comprehensions, etc., and an open-domain dialogue system mode to allow users to practice their language skills. We present a high-level overview of the design of BELA, including the implementation details and the preliminary results of our early prototype. We also report the challenges in creating an English-language learning chatbot for a largely Hindi-speaking population",
    "checked": true,
    "id": "a0d7c36a49e747dfe73cc0a729d628d08f4e4436",
    "semantic_title": "bela: bot for english language acquisition",
    "citation_count": 0,
    "authors": [
      "Muskan Mahajan"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.18": {
    "title": "Applicability of Pretrained Language Models: Automatic Screening for Children's Language Development Level",
    "volume": "workshop",
    "abstract": "The various potential of children can be limited by language delay or language impairments. However, there are many instances where parents are unaware of the child's condition and do not obtain appropriate treatment as a result. Additionally, experts collecting children's utterance to establish norms of language tests and evaluating children's language development level takes a significant amount of time and work. To address these issues, dependable automated screening tools are required. In this paper, we used pretrained LM to assist experts in quickly and objectively screening the language development level of children. Here, evaluating the language development level is to ensure that the child has the appropriate language abilities for his or her age, which is the same as the child's age. To do this, we analyzed the utterances of children according to age. Based on these findings, we use the standard deviations of the pretrained LM's probability as a score for children to screen their language development level. The experiment results showed very strong correlations between our proposed method and the Korean language test REVT (REVT-R, REVT-E), with Pearson correlation coefficient of 0.9888 and 0.9892, respectively",
    "checked": true,
    "id": "0d15d4995edb1c982dea403ec95d2df1de0d33b4",
    "semantic_title": "applicability of pretrained language models: automatic screening for children's language development level",
    "citation_count": 0,
    "authors": [
      "Byoung-doo Oh",
      "Yoon-koung Lee",
      "Yu-seop Kim"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.19": {
    "title": "Transformers-Based Approach for a Sustainability Term-Based Sentiment Analysis (STBSA)",
    "volume": "workshop",
    "abstract": "Traditional sentiment analysis is a sentence level or document-level task. However, a sentence or paragraph may contain multiple target terms with different sentiments, making sentiment prediction more challenging. Although pre-trained language models like BERT have been successful, incorporating dynamic semantic changes into aspect-based sentiment models remains difficult, especially for domain-specific sentiment analysis. To this end, in this paper, we propose a Term-Based Sentiment Analysis (TBSA), a novel method designed to learn Environmental, Social, and Governance (ESG) contexts based on a sustainability taxonomy for ESG aspect-oriented sentiment analysis. Notably, we introduce a technique enhancing the ESG term's attention, inspired by the success of attention-based neural networks in machine translation (Bahdanau et al., 2015) and Computer Vision (Bello et al., 2019). It enables the proposed model to focus on a small region of the sentences at each step and to reweigh the crucial terms for a better understanding of the ESG aspect-aware sentiment. Beyond the novelty in the model design, we propose a new dataset of 125,000+ ESG analyst annotated data points for sustainability term based sentiment classification, which derives from historical sustainability corpus data and expertise acquired by development finance institutions. Our extensive experiments combining the new method and the new dataset demonstrate the effectiveness of the Sustainability TBSA model with an accuracy of 91.30% (90% F1-score). Both internal and external business applications of our model show an evident potential for a significant positive impact toward furthering sustainable development goals (SDGs)",
    "checked": true,
    "id": "86ceb8066b71ceaf45ff365620dc49282ae998c0",
    "semantic_title": "transformers-based approach for a sustainability term-based sentiment analysis (stbsa)",
    "citation_count": 1,
    "authors": [
      "Blaise Sandwidi",
      "Suneer Pallitharammal Mukkolakal"
    ]
  },
  "https://aclanthology.org/2022.nlp4pi-1.20": {
    "title": "Hate-CLIPper: Multimodal Hateful Meme Classification based on Cross-modal Interaction of CLIP Features",
    "volume": "workshop",
    "abstract": "Hateful memes are a growing menace on social media. While the image and its corresponding text in a meme are related, they do not necessarily convey the same meaning when viewed individually. Hence, detecting hateful memes requires careful consideration of both visual and textual information. Multimodal pre-training can be beneficial for this task because it effectively captures the relationship between the image and the text by representing them in a similar feature space. Furthermore, it is essential to model the interactions between the image and text features through intermediate fusion. Most existing methods either employ multimodal pre-training or intermediate fusion, but not both. In this work, we propose the Hate-CLIPper architecture, which explicitly models the cross-modal interactions between the image and text representations obtained using Contrastive Language-Image Pre-training (CLIP) encoders via a feature interaction matrix (FIM). A simple classifier based on the FIM representation is able to achieve state-of-the-art performance on the Hateful Memes Challenge (HMC) dataset with an AUROC of 85.8, which even surpasses the human performance of 82.65. Experiments on other meme datasets such as Propaganda Memes and TamilMemes also demonstrate the generalizability of the proposed approach. Finally, we analyze the interpretability of the FIM representation and show that cross-modal interactions can indeed facilitate the learning of meaningful concepts. The code for this work is available at https://github.com/gokulkarthik/hateclipper",
    "checked": true,
    "id": "0c086bc5a9e63c36f4590f800b5ded52e7d94517",
    "semantic_title": "hate-clipper: multimodal hateful meme classification based on cross-modal interaction of clip features",
    "citation_count": 20,
    "authors": [
      "Gokul Karthik Kumar",
      "Karthik Nandakumar"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.1": {
    "title": "Improving the Generalizability of Text-Based Emotion Detection by Leveraging Transformers with Psycholinguistic Features",
    "volume": "workshop",
    "abstract": "recent years, there has been increased interest in building predictive models that harness natural language processing and machine learning techniques to detect emotions from various text sources, including social media posts, micro-blogs or news articles. Yet, deployment of such models in real-world sentiment and emotion applications faces challenges, in particular poor out-of-domain generalizability. This is likely due to domain-specific differences (e.g., topics, communicative goals, and annotation schemes) that make transfer between different models of emotion recognition difficult. In this work we propose approaches for text-based emotion detection that leverage transformer models (BERT and RoBERTa) in combination with Bidirectional Long Short-Term Memory (BiLSTM) networks trained on a comprehensive set of psycholinguistic features. First, we evaluate the performance of our models within-domain on two benchmark datasets GoEmotion (Demszky et al., 2020) and ISEAR (Scherer and Wallbott, 1994). Second, we conduct transfer learning experiments on six datasets from the Unified Emotion Dataset (Bostan and Klinger, 2018) to evaluate their out-of-domain robustness. We find that the proposed hybrid models improve the ability to generalize to out-of-distribution data compared to a standard transformer-based approach. Moreover, we observe that these models perform competitively on in-domain data",
    "checked": true,
    "id": "62da5df0c07e61f16dd9a605197ad63dc6ddde08",
    "semantic_title": "improving the generalizability of text-based emotion detection by leveraging transformers with psycholinguistic features",
    "citation_count": 0,
    "authors": [
      "Sourabh Zanwar",
      "Daniel Wiechmann",
      "Yu Qiao",
      "Elma Kerz"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.2": {
    "title": "Fine-Grained Extraction and Classification of Skill Requirements in German-Speaking Job Ads",
    "volume": "workshop",
    "abstract": "Monitoring the development of labor market skill requirements is an information need that is more and more approached by applying text mining methods to job advertisement data. We present an approach for fine-grained extraction and classification of skill requirements from German-speaking job advertisements. We adapt pre-trained transformer-based language models to the domain and task of computing meaningful representations of sentences or spans. By using context from job advertisements and the large ESCO domain ontology we improve our similarity-based unsupervised multi-label classification results. Our best model achieves a mean average precision of 0.969 on the skill class level",
    "checked": true,
    "id": "c4c949b11e6d4385c87b76104ad9d5cdac6f532e",
    "semantic_title": "fine-grained extraction and classification of skill requirements in german-speaking job ads",
    "citation_count": 6,
    "authors": [
      "Ann-sophie Gnehm",
      "Eva Bühlmann",
      "Helen Buchs",
      "Simon Clematide"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.3": {
    "title": "Experiencer-Specific Emotion and Appraisal Prediction",
    "volume": "workshop",
    "abstract": "Emotion classification in NLP assigns emotions to texts, such as sentences or paragraphs. With texts like \"I felt guilty when he cried\", focusing on the sentence level disregards the standpoint of each participant in the situation: the writer (\"I\") and the other entity (\"he\") could in fact have different affective states. The emotions of different entities have been considered only partially in emotion semantic role labeling, a task that relates semantic roles to emotion cue words. Proposing a related task, we narrow the focus on the experiencers of events, and assign an emotion (if any holds) to each of them. To this end, we represent each emotion both categorically and with appraisal variables, as a psychological access to explaining why a person develops a particular emotion. On an event description corpus, our experiencer-aware models of emotions and appraisals outperform the experiencer-agnostic baselines, showing that disregarding event participants is an oversimplification for the emotion detection task",
    "checked": true,
    "id": "f7b02dbc38be4329c52175446befa1a0e4a58989",
    "semantic_title": "experiencer-specific emotion and appraisal prediction",
    "citation_count": 4,
    "authors": [
      "Maximilian Wegge",
      "Enrica Troiano",
      "Laura Ana Maria Oberlaender",
      "Roman Klinger"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.4": {
    "title": "Understanding Narratives from Demographic Survey Data: a Comparative Study with Multiple Neural Topic Models",
    "volume": "workshop",
    "abstract": "Fertility intentions as verbalized in surveys are a poor predictor of actual fertility outcomes, the number of children people have. This can partly be explained by the uncertainty people have in their intentions. Such uncertainties are hard to capture through traditional survey questions, although open-ended questions can be used to get insight into people's subjective narratives of the future that determine their intentions. Analyzing such answers to open-ended questions can be done through Natural Language Processing techniques. Traditional topic models (e.g., LSA and LDA), however, often fail to do since they rely on co-occurrences, which are often rare in short survey responses. The aim of this study was to apply and evaluate topic models on demographic survey data. In this study, we applied neural topic models (e.g. BERTopic, CombinedTM) based on language models to responses from Dutch women on their fertility plans, and compared the topics and their coherence scores from each model to expert judgments. Our results show that neural models produce topics more in line with human interpretation compared to LDA. However, the coherence score could only partly reflect on this, depending on the corpus used for calculation. This research is important because, first, it helps us develop more informed strategies on model selection and evaluation for topic modeling on survey data; and second, it shows that the field of demography has much to gain from adopting NLP methods",
    "checked": true,
    "id": "33e3c173a90176a4d3c127d0d32b2b6601c364bc",
    "semantic_title": "understanding narratives from demographic survey data: a comparative study with multiple neural topic models",
    "citation_count": 1,
    "authors": [
      "Xiao Xu",
      "Gert Stulp",
      "Antal Van Den Bosch",
      "Anne Gauthier"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.6": {
    "title": "To Prefer or to Choose? Generating Agency and Power Counterfactuals Jointly for Gender Bias Mitigation",
    "volume": "workshop",
    "abstract": "Gender bias may emerge from an unequal representation of agency and power, for example, by portraying women frequently as passive and powerless (\"She accepted her future\") and men as proactive and powerful (\"He chose his future\"). When language models learn from respective texts, they may reproduce or even amplify the bias. An effective way to mitigate bias is to generate counterfactual sentences with opposite agency and power to the training. Recent work targeted agency-specific verbs from a lexicon to this end. We argue that this is insufficient, due to the interaction of agency and power and their dependence on context. In this paper, we thus develop a new rewriting model that identifies verbs with the desired agency and power in the context of the given sentence. The verbs' probability is then boosted to encourage the model to rewrite both connotations jointly. According to automatic metrics, our model effectively controls for power while being competitive in agency to the state of the art. In our main evaluation, human annotators favored its counterfactuals in terms of both connotations, also deeming its meaning preservation better",
    "checked": true,
    "id": "7f1cce61d8099be424a6f3b8036180562e5cef14",
    "semantic_title": "to prefer or to choose? generating agency and power counterfactuals jointly for gender bias mitigation",
    "citation_count": 4,
    "authors": [
      "Maja Stahl",
      "Maximilian Spliethöver",
      "Henning Wachsmuth"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.8": {
    "title": "Conspiracy Narratives in the Protest Movement Against COVID-19 Restrictions in Germany. A Long-term Content Analysis of Telegram Chat Groups",
    "volume": "workshop",
    "abstract": "From the start of the COVID-19 pandemic in Germany, different groups have been protesting measures implemented by different government bodies in Germany to control the pandemic. It was widely claimed that many of the offline and online protests were driven by conspiracy narratives disseminated through groups and channels on the messenger app Telegram. We investigate this claim by measuring the frequency of conspiracy narratives in messages from open Telegram chat groups of the Querdenken movement, set up to organize protests against COVID-19 restrictions in Germany. We furthermore explore the content of these messages using topic modelling. To this end, we collected 822k text messages sent between April 2020 and May 2022 in 34 chat groups. By fine-tuning a Distilbert model, using self-annotated data, we find that 8.24% of the sent messages contain signs of conspiracy narratives. This number is not static, however, as the share of conspiracy messages grew while the overall number of messages shows a downward trend since its peak at the end of 2020. We further find a mix of known conspiracy narratives make up the topics in our topic model. Our findings suggest that the Querdenken movement is getting smaller over time, but its remaining members focus even more on conspiracy narratives",
    "checked": true,
    "id": "2cf6e3c86f14850826d88e55eb3bd2d3d87836b7",
    "semantic_title": "conspiracy narratives in the protest movement against covid-19 restrictions in germany. a long-term content analysis of telegram chat groups",
    "citation_count": 1,
    "authors": [
      "Manuel Weigand",
      "Maximilian Weber",
      "Johannes Gruber"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.9": {
    "title": "Conditional Language Models for Community-Level Linguistic Variation",
    "volume": "workshop",
    "abstract": "Community-level linguistic variation is a core concept in sociolinguistics. In this paper, we use conditioned neural language models to learn vector representations for 510 online communities. We use these representations to measure linguistic variation between commu-nities and investigate the degree to which linguistic variation corresponds with social connections between communities. We find that our sociolinguistic embeddings are highly correlated with a social network-based representation that does not use any linguistic input",
    "checked": true,
    "id": "3295b719a5c3bd8cd6dae0b48a3cd58f4537cbdd",
    "semantic_title": "conditional language models for community-level linguistic variation",
    "citation_count": 2,
    "authors": [
      "Bill Noble",
      "Jean-philippe Bernardy"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.10": {
    "title": "Understanding Interpersonal Conflict Types and their Impact on Perception Classification",
    "volume": "workshop",
    "abstract": "Studies on interpersonal conflict have a long history and contain many suggestions for conflict typology. We use this as the basis of a novel annotation scheme and release a new dataset of situations and conflict aspect annotations. We then build a classifier to predict whether someone will perceive the actions of one individual as right or wrong in a given situation. Our analyses include conflict aspects, but also generated clusters, which are human validated, and show differences in conflict content based on the relationship of participants to the author. Our findings have important implications for understanding conflict and social norms",
    "checked": true,
    "id": "84acb81a44641455dfcaedbde619be3498cb6675",
    "semantic_title": "understanding interpersonal conflict types and their impact on perception classification",
    "citation_count": 4,
    "authors": [
      "Charles Welch",
      "Joan Plepi",
      "Béla Neuendorf",
      "Lucie Flek"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.11": {
    "title": "Examining Political Rhetoric with Epistemic Stance Detection",
    "volume": "workshop",
    "abstract": "Participants in political discourse employ rhetorical strategies—such as hedging, attributions, or denials—to display varying degrees of belief commitments to claims proposed by themselves or others. Traditionally, political scientists have studied these epistemic phenomena through labor-intensive manual content analysis. We propose to help automate such work through epistemic stance prediction, drawn from research in computational semantics, to distinguish at the clausal level what is asserted, denied, or only ambivalently suggested by the author or other mentioned entities (belief holders). We first develop a simple RoBERTa-based model for multi-source stance predictions that outperforms more complex state-of-the-art modeling. Then we demonstrate its novel application to political science by conducting a large-scale analysis of the Mass Market Manifestos corpus of U.S. political opinion books, where we characterize trends in cited belief holders—respected allies and opposed bogeymen—across U.S. political ideologies",
    "checked": true,
    "id": "488a670f2e9414dc2084f955c301f665d2bb48ba",
    "semantic_title": "examining political rhetoric with epistemic stance detection",
    "citation_count": 0,
    "authors": [
      "Ankita Gupta",
      "Su Lin Blodgett",
      "Justin Gross",
      "Brendan O’connor"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.12": {
    "title": "Linguistic Elements of Engaging Customer Service Discourse on Social Media",
    "volume": "workshop",
    "abstract": "Customers are rapidly turning to social media for customer support. While brand agents on these platforms are motivated and well-intentioned to help and engage with customers, their efforts are often ignored if their initial response to the customer does not match a specific tone, style, or topic the customer is aiming to receive. The length of a conversation can reflect the effort and quality of the initial response made by a brand toward collaborating and helping consumers, even when the overall sentiment of the conversation might not be very positive. Thus, through this study, we aim to bridge this critical gap in the existing literature by analyzing language's content and stylistic aspects such as expressed empathy, psycho-linguistic features, dialogue tags, and metrics for quantifying personalization of the utterances that can influence the engagement of an interaction. This paper demonstrates that we can predict engagement using initial customer and brand posts",
    "checked": true,
    "id": "5fa20d7c72a8a789f2bd62d2d3dc65b2edc322a7",
    "semantic_title": "linguistic elements of engaging customer service discourse on social media",
    "citation_count": 1,
    "authors": [
      "Sonam Singh",
      "Anthony Rios"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.13": {
    "title": "Measuring Harmful Representations in Scandinavian Language Models",
    "volume": "workshop",
    "abstract": "Scandinavian countries are perceived as role-models when it comes to gender equality. With the advent of pre-trained language models and their widespread usage, we investigate to what extent gender-based harmful and toxic content exists in selected Scandinavian language models. We examine nine models, covering Danish, Swedish, and Norwegian, by manually creating template-based sentences and probing the models for completion. We evaluate the completions using two methods for measuring harmful and toxic completions and provide a thorough analysis of the results. We show that Scandinavian pre-trained language models contain harmful and gender-based stereotypes with similar values across all languages. This finding goes against the general expectations related to gender equality in Scandinavian countries and shows the possible problematic outcomes of using such models in real-world settings. Warning: Some of the examples provided in this paper can be upsetting and offensive",
    "checked": true,
    "id": "2969970823b3831fbbea7cdd6a83dbd05efa651f",
    "semantic_title": "measuring harmful representations in scandinavian language models",
    "citation_count": 6,
    "authors": [
      "Samia Touileb",
      "Debora Nozza"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.14": {
    "title": "Can Contextualizing User Embeddings Improve Sarcasm and Hate Speech Detection?",
    "volume": "workshop",
    "abstract": "While implicit embeddings so far have been mostly concerned with creating an overall representation of the user, we evaluate a different approach. By only considering content directed at a specific topic, we create sub-user embeddings, and measure their usefulness on the tasks of sarcasm and hate speech detection. In doing so, we show that task-related topics can have a noticeable effect on model performance, especially when dealing with intended expressions like sarcasm, but less so for hate speech, which is usually labelled as such on the receiving end",
    "checked": true,
    "id": "205a405e5d2823c9bfdf77a3452b2ac8481a1525",
    "semantic_title": "can contextualizing user embeddings improve sarcasm and hate speech detection?",
    "citation_count": 1,
    "authors": [
      "Kim Breitwieser"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.15": {
    "title": "Professional Presentation and Projected Power: A Case Study of Implicit Gender Information in English CVs",
    "volume": "workshop",
    "abstract": "Gender discrimination in hiring is a pertinent and persistent bias in society, and a common motivating example for exploring bias in NLP. However, the manifestation of gendered language in application materials has received limited attention. This paper investigates the framing of skills and background in CVs of self-identified men and women. We introduce a data set of 1.8K authentic, English-language, CVs from the US, covering 16 occupations, allowing us to partially control for the confound occupation-specific gender base rates. We find that (1) women use more verbs evoking impressions of low power; and (2) classifiers capture gender signal even after data balancing and removal of pronouns and named entities, and this holds for both transformer-based and linear classifiers",
    "checked": true,
    "id": "16c79fed6481f223dcb6d7e967cf00bd63aa1435",
    "semantic_title": "professional presentation and projected power: a case study of implicit gender information in english cvs",
    "citation_count": 1,
    "authors": [
      "Jinrui Yang",
      "Sheilla Njoto",
      "Marc Cheong",
      "Leah Ruppanner",
      "Lea Frermann"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.16": {
    "title": "Detecting Dissonant Stance in Social Media: The Role of Topic Exposure",
    "volume": "workshop",
    "abstract": "We address dissonant stance detection, classifying conflicting stance between two input statements. Computational models for traditional stance detection have typically been trained to indicate pro/con for a given target topic (e.g. gun control) and thus do not generalize well to new topics. In this paper, we systematically evaluate the generalizability of dissonant stance detection to situations where examples of the topic have not been seen at all or have only been seen a few times. We show that dissonant stance detection models trained on only 8 topics, none of which are the target topic, can perform as well as those trained only on a target topic. Further, adding non-target topics boosts performance further up to approximately 32 topics where accuracies start to plateau. Taken together, our experiments suggest dissonant stance detection models can generalize to new unanticipated topics, an important attribute for the social scientific study of social media where new topics emerge daily",
    "checked": true,
    "id": "148138a424d59f305222145f0d8cf857ff646682",
    "semantic_title": "detecting dissonant stance in social media: the role of topic exposure",
    "citation_count": 3,
    "authors": [
      "Vasudha Varadarajan",
      "Nikita Soni",
      "Weixi Wang",
      "Christian Luhmann",
      "H. Andrew Schwartz",
      "Naoya Inoue"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.17": {
    "title": "An Analysis of Acknowledgments in NLP Conference Proceedings",
    "volume": "workshop",
    "abstract": "While acknowledgments are often overlooked and sometimes entirely missing from publications, this short section of a paper can provide insights on the state of a field. We characterize and perform a textual analysis of acknowledgments in NLP conference proceedings across the last 17 years, revealing broader trends in funding and research directions in NLP as well as interesting phenomena including career incentives and the influence of defaults",
    "checked": true,
    "id": "79731877ad7bf051b4ad8db0591a5b5ab61258ee",
    "semantic_title": "an analysis of acknowledgments in nlp conference proceedings",
    "citation_count": 0,
    "authors": [
      "Winston Wu"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.18": {
    "title": "Extracting Associations of Intersectional Identities with Discourse about Institution from Nigeria",
    "volume": "workshop",
    "abstract": "Word embedding models have been used in prior work to extract associations of intersectional identities within discourse concerning institutions of power, but restricted its focus on narratives of the nineteenth-century U.S. south. This paper leverages this prior work and introduces an initial study on the association of intersected identities with discourse concerning social institutions within social media from Nigeria. Specifically, we use word embedding models trained on tweets from Nigeria and extract associations of intersected social identities with institutions (e.g., domestic, culture, etc.) to provide insight into the alignment of identities with institutions. Our initial experiments indicate that identities at the intersection of gender and economic status groups have significant associations with discourse about the economic, political, and domestic institutions",
    "checked": true,
    "id": "52b0d8c7409031b17fac103a20a4d69bbd6a7d01",
    "semantic_title": "extracting associations of intersectional identities with discourse about institution from nigeria",
    "citation_count": 0,
    "authors": [
      "Pavan Kantharaju",
      "Sonja Schmer-galunder"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.19": {
    "title": "OLALA: Object-Level Active Learning for Efficient Document Layout Annotation",
    "volume": "workshop",
    "abstract": "Layout detection is an essential step for accurately extracting structured contents from historical documents. The intricate and varied layouts present in these document images make it expensive to label the numerous layout regions that can be densely arranged on each page. Current active learning methods typically rank and label samples at the image level, where the annotation budget is not optimally spent due to the overexposure of common objects per image. Inspired by recent progress in semi-supervised learning and self-training, we propose OLALA, an Object-Level Active Learning framework for efficient document layout Annotation. OLALA aims to optimize the annotation process by selectively annotating only the most ambiguous regions within an image, while using automatically generated labels for the rest. Central to OLALA is a perturbation-based scoring function that determines which objects require manual annotation. Extensive experiments show that OLALA can significantly boost model performance and improve annotation efficiency, facilitating the extraction of masses of structured text for downstream NLP applications",
    "checked": true,
    "id": "bd2a7c4432bd22d06cf4df2d450d6dea8df21ab4",
    "semantic_title": "olala: object-level active learning for efficient document layout annotation",
    "citation_count": 4,
    "authors": [
      "Zejiang Shen",
      "Weining Li",
      "Jian Zhao",
      "Yaoliang Yu",
      "Melissa Dell"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.20": {
    "title": "Towards Few-Shot Identification of Morality Frames using In-Context Learning",
    "volume": "workshop",
    "abstract": "Data scarcity is a common problem in NLP, especially when the annotation pertains to nuanced socio-linguistic concepts that require specialized knowledge. As a result, few-shot identification of these concepts is desirable. Few-shot in-context learning using pre-trained Large Language Models (LLMs) has been recently applied successfully in many NLP tasks. In this paper, we study few-shot identification of a psycho-linguistic concept, Morality Frames (Roy et al., 2021), using LLMs. Morality frames are a representation framework that provides a holistic view of the moral sentiment expressed in text, identifying the relevant moral foundation (Haidt and Graham, 2007) and at a finer level of granularity, the moral sentiment expressed towards the entities mentioned in the text. Previous studies relied on human annotation to identify morality frames in text which is expensive. In this paper, we propose prompting based approaches using pretrained Large Language Models for identification of morality frames, relying only on few-shot exemplars. We compare our models' performance with few-shot RoBERTa and found promising results",
    "checked": true,
    "id": "b13668fe9c944b8ad441edb473c218d4cf303de8",
    "semantic_title": "towards few-shot identification of morality frames using in-context learning",
    "citation_count": 3,
    "authors": [
      "Shamik Roy",
      "Nishanth Sridhar Nakshatri",
      "Dan Goldwasser"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.22": {
    "title": "Utilizing Weak Supervision to Create S3D: A Sarcasm Annotated Dataset",
    "volume": "workshop",
    "abstract": "Sarcasm is prevalent in all corners of social media, posing many challenges within Natural Language Processing (NLP), particularly for sentiment analysis. Sarcasm detection remains a largely unsolved problem in many NLP tasks due to its contradictory and typically derogatory nature as a figurative language construct. With recent strides in NLP, many pre-trained language models exist that have been trained on data from specific social media platforms, i.e., Twitter. In this paper, we evaluate the efficacy of multiple sarcasm detection datasets using machine and deep learning models. We create two new datasets - a manually annotated gold standard Sarcasm Annotated Dataset (SAD) and a Silver-Standard Sarcasm-annotated Dataset (S3D). Using a combination of existing sarcasm datasets with SAD, we train a sarcasm detection model over a social-media domain pre-trained language model, BERTweet, which yields an F1-score of 78.29%. Using an Ensemble model with an underlying majority technique, we further label S3D to produce a weakly supervised dataset containing over 100,000 tweets. We publicly release all the code, our manually annotated and weakly supervised datasets, and fine-tuned models for further research",
    "checked": true,
    "id": "359eb64e95d24abd083651ceb59edd44a8436364",
    "semantic_title": "utilizing weak supervision to create s3d: a sarcasm annotated dataset",
    "citation_count": 1,
    "authors": [
      "Jordan Painter",
      "Helen Treharne",
      "Diptesh Kanojia"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.23": {
    "title": "A Robust Bias Mitigation Procedure Based on the Stereotype Content Model",
    "volume": "workshop",
    "abstract": "The Stereotype Content model (SCM) states that we tend to perceive minority groups as cold, incompetent or both. In this paper we adapt existing work to demonstrate that the Stereotype Content model holds for contextualised word embeddings, then use these results to evaluate a fine-tuning process designed to drive a language model away from stereotyped portrayals of minority groups. We find the SCM terms are better able to capture bias than demographic agnostic terms related to pleasantness. Further, we were able to reduce the presence of stereotypes in the model through a simple fine-tuning procedure that required minimal human and computer resources, without harming downstream performance. We present this work as a prototype of a debiasing procedure that aims to remove the need for a priori knowledge of the specifics of bias in the model",
    "checked": true,
    "id": "2274a5dd64920eacc817a0facbd90c40c57c0bbc",
    "semantic_title": "a robust bias mitigation procedure based on the stereotype content model",
    "citation_count": 10,
    "authors": [
      "Eddie Ungless",
      "Amy Rafferty",
      "Hrichika Nag",
      "Björn Ross"
    ]
  },
  "https://aclanthology.org/2022.nlpcss-1.24": {
    "title": "Who is GPT-3? An exploration of personality, values and demographics",
    "volume": "workshop",
    "abstract": "Language models such as GPT-3 have caused a furore in the research community. Some studies found that GPT-3 has some creative abilities and makes mistakes that are on par with human behaviour. This paper answers a related question: Who is GPT-3? We administered two validated measurement tools to GPT-3 to assess its personality, the values it holds and its self-reported demographics. Our results show that GPT-3 scores similarly to human samples in terms of personality and - when provided with a model response memory - in terms of the values it holds. We provide the first evidence of psychological assessment of the GPT-3 model and thereby add to our understanding of this language model. We close with suggestions for future research that moves social science closer to language models and vice versa",
    "checked": true,
    "id": "73b54046259f84a0c4e9409714d6a71c41981b57",
    "semantic_title": "who is gpt-3? an exploration of personality, values and demographics",
    "citation_count": 44,
    "authors": [
      "Marilù Miotto",
      "Nicola Rossberg",
      "Bennett Kleinberg"
    ]
  },
  "https://aclanthology.org/2022.seretod-1.1": {
    "title": "Oh My Mistake!: Toward Realistic Dialogue State Tracking including Turnback Utterances",
    "volume": "workshop",
    "abstract": "The primary purpose of dialogue state tracking(DST), a critical component of an end-toend conversational system, is to build a model that responds well to real-world situations. Although we often change our minds from time to time during ordinary conversations, current benchmark datasets do not adequately reflect such occurrences and instead consist of over-simplified conversations, in which no one changes their mind during a conversation. As the main question inspiring the present study, \"Are current benchmark datasets sufficiently diverse to handle casual conversations in which one changes their mind after a certain topic is over?\" We found that the answer is \"No\" because DST models cannot refer to previous user preferences when template-based turnback utterances are injected into the dataset. Even in the the simplest mind-changing (turnback) scenario, the performance of DST models significantly degenerated. However, we found that this performance degeneration can be recovered when the turnback scenarios are explicitly designed in the training set, implying that the problem is not with the DST models but rather with the construction of the benchmark dataset",
    "checked": true,
    "id": "c4abd28645f1c4dc027d3323717ae985c81dfebf",
    "semantic_title": "oh my mistake!: toward realistic dialogue state tracking including turnback utterances",
    "citation_count": 3,
    "authors": [
      "Takyoung Kim",
      "Yukyung Lee",
      "Hoonsang Yoon",
      "Pilsung Kang",
      "Junseong Bang",
      "Misuk Kim"
    ]
  },
  "https://aclanthology.org/2022.seretod-1.2": {
    "title": "A GlobalPointer based Robust Approach for Information Extraction from Dialog Transcripts",
    "volume": "workshop",
    "abstract": "With the widespread popularisation of intelligent technology, task-based dialogue systems (TOD) are increasingly being applied to a wide variety of practical scenarios. As the key tasks in dialogue systems, named entity recognition and slot filling play a crucial role in the completeness and accuracy of information extraction. This paper is an evaluation paper for Sere-TOD 2022 Workshop challenge (Track 1 Information extraction from dialog transcripts). We proposed a multi-model fusion approach based on GlobalPointer, combined with some optimisation tricks, finally achieved an entity F1 of 60.73, an entity-slot-value triple F1 of 56, and an average F1 of 58.37, and got the highest score in SereTOD 2022 Workshop challenge",
    "checked": true,
    "id": "3c380f5181a38443566b12836f5108e76cfba3e0",
    "semantic_title": "a globalpointer based robust approach for information extraction from dialog transcripts",
    "citation_count": 0,
    "authors": [
      "Yanbo J. Wang",
      "Sheng Chen",
      "Hengxing Cai",
      "Wei Wei",
      "Kuo Yan",
      "Zhe Sun",
      "Hui Qin",
      "Yuming Li",
      "Xiaochen Cai"
    ]
  },
  "https://aclanthology.org/2022.seretod-1.3": {
    "title": "A Token-pair Framework for Information Extraction from Dialog Transcripts in SereTOD Challenge",
    "volume": "workshop",
    "abstract": "This paper describes our solution for Sere- TOD Challenge Track 1: Information extraction from dialog transcripts. We propose a token-pair framework to simultaneously identify entity and value mentions and link them into corresponding triples. As entity mentions are usually coreferent, we adopt a baseline model for coreference resolution. We exploit both annotated transcripts and unsupervised dialogs for training. With model ensemble and post-processing strategies, our system significantly outperforms the baseline solution and ranks first in triple f1 and third in entity f1",
    "checked": true,
    "id": "e9c45612eb476e1c6ee00078b54619267dff22fc",
    "semantic_title": "a token-pair framework for information extraction from dialog transcripts in seretod challenge",
    "citation_count": 0,
    "authors": [
      "Chenyue Wang",
      "Xiangxing Kong",
      "Mengzuo Huang",
      "Feng Li",
      "Jian Xing",
      "Weidong Zhang",
      "Wuhe Zou"
    ]
  },
  "https://aclanthology.org/2022.seretod-1.4": {
    "title": "Prompt Learning for Domain Adaptation in Task-Oriented Dialogue",
    "volume": "workshop",
    "abstract": "Conversation designers continue to face significant obstacles when creating productionquality task-oriented dialogue systems. The complexity and cost involved in schema development and data collection is often a major barrier for such designers, limiting their ability to create natural, user-friendly experiences. We frame the classification of user intent as the generation of a canonical form, a lightweight semantic representation using natural language. We show that canonical forms offer a promising alternative to traditional methods for intent classification. By tuning soft prompts for a frozen large language model, we show that canonical forms generalize very well to new, unseen domains in a zero- or few-shot setting. The method is also sample-efficient, reducing the complexity and effort of developing new task-oriented dialogue domains",
    "checked": true,
    "id": "c18331248f8ee4995a467b0298880ae7a2c158ba",
    "semantic_title": "prompt learning for domain adaptation in task-oriented dialogue",
    "citation_count": 1,
    "authors": [
      "Makesh Narsimhan Sreedhar",
      "Christopher Parisien"
    ]
  },
  "https://aclanthology.org/2022.seretod-1.5": {
    "title": "Disentangling Confidence Score Distribution for Out-of-Domain Intent Detection with Energy-Based Learning",
    "volume": "workshop",
    "abstract": "Detecting Out-of-Domain (OOD) or unknown intents from user queries is essential in a taskoriented dialog system. Traditional softmaxbased confidence scores are susceptible to the overconfidence issue. In this paper, we propose a simple but strong energy-based score function to detect OOD where the energy scores of OOD samples are higher than IND samples. Further, given a small set of labeled OOD samples, we introduce an energy-based margin objective for supervised OOD detection to explicitly distinguish OOD samples from INDs. Comprehensive experiments and analysis prove our method helps disentangle confidence score distributions of IND and OOD data",
    "checked": true,
    "id": "82d9561d3392ec595635467114669ed0ec907797",
    "semantic_title": "disentangling confidence score distribution for out-of-domain intent detection with energy-based learning",
    "citation_count": 2,
    "authors": [
      "Yanan Wu",
      "Zhiyuan Zeng",
      "Keqing He",
      "Yutao Mou",
      "Pei Wang",
      "Yuanmeng Yan",
      "Weiran Xu"
    ]
  },
  "https://aclanthology.org/2022.seretod-1.6": {
    "title": "Semi-Supervised Knowledge-Grounded Pre-training for Task-Oriented Dialog Systems",
    "volume": "workshop",
    "abstract": "Recent advances in neural approaches greatly improve task-oriented dialogue (TOD) systems which assist users to accomplish their goals. However, such systems rely on costly manually labeled dialogs which are not available in practical scenarios. In this paper, we present our models for Track 2 of the SereTOD 2022 challenge, which is the first challenge of building semisupervised and reinforced TOD systems on a large-scale real-world Chinese TOD dataset MobileCS. We build a knowledge-grounded dialog model to formulate dialog history and local KB as input and predict the system response. And we perform semi-supervised pretraining both on the labeled and unlabeled data. Our system achieves the first place both in the automatic evaluation and human interaction, especially with higher BLEU (+7.64) and Success (+13.6%) than the second place",
    "checked": true,
    "id": "08fc1f48af6b34abba5e68604cbd2e880fd3960f",
    "semantic_title": "semi-supervised knowledge-grounded pre-training for task-oriented dialog systems",
    "citation_count": 14,
    "authors": [
      "Weihao Zeng",
      "Keqing He",
      "Zechen Wang",
      "Dayuan Fu",
      "Guanting Dong",
      "Ruotong Geng",
      "Pei Wang",
      "Jingang Wang",
      "Chaobo Sun",
      "Wei Wu",
      "Weiran Xu"
    ]
  },
  "https://aclanthology.org/2022.seretod-1.7": {
    "title": "CMCC: A Comprehensive and Large-Scale Human-Human Dataset for Dialogue Systems",
    "volume": "workshop",
    "abstract": "Dialogue modeling problems severely limit the real-world deployment of neural conversational models and building a human-like dialogue agent is an extremely challenging task. Recently, data-driven models become more and more prevalent which need a huge amount of conversation data. In this paper, we release around 100,000 dialogue, which come from real-world dialogue transcripts between real users and customer-service staffs. We call this dataset as CMCC (China Mobile Customer Care) dataset, which differs from existing dialogue datasets in both size and nature significantly. The dataset reflects several characteristics of human-human conversations, e.g., task-driven, care-oriented, and long-term dependency among the context. It also covers various dialogue types including task-oriented, chitchat and conversational recommendation in real-world scenarios. To our knowledge, CMCC is the largest real human-human spoken dialogue dataset and has dozens of times the data scale of others, which shall significantly promote the training and evaluation of dialogue modeling methods. The results of extensive experiments indicate that CMCC is challenging and needs further effort. We hope that this resource will allow for more effective models across various dialogue sub-problems to be built in the future",
    "checked": true,
    "id": "4f2d5249b93e0c436f28bee2df0387ec54a33afe",
    "semantic_title": "cmcc: a comprehensive and large-scale human-human dataset for dialogue systems",
    "citation_count": 0,
    "authors": [
      "Yi Huang",
      "Xiaoting Wu",
      "Si Chen",
      "Wei Hu",
      "Qing Zhu",
      "Junlan Feng",
      "Chao Deng",
      "Zhijian Ou",
      "Jiangjiang Zhao"
    ]
  },
  "https://aclanthology.org/2022.seretod-1.8": {
    "title": "State-Aware Adversarial Training for Utterance-Level Dialogue Generation",
    "volume": "workshop",
    "abstract": "Dialogue generation is a challenging problem because it not only requires us to model the context in a conversation but also to exploit it to generate a coherent and fluent utterance. This paper, aiming for a specific topic of this field, proposes an adversarial training based framework for utterance-level dialogue generation. Technically, we train an encoder-decoder generator simultaneously with a discriminative classifier that make the utterance approximate to the state-aware inputs. Experiments on MultiWoZ 2.0 and MultiWoZ 2.1 datasets show that our method achieves advanced improvements on both automatic and human evaluations, and on the effectiveness of our framework facing low-resource. We further explore the effect of fine-grained augmentations for downstream dialogue state tracking (DST) tasks. Experimental results demonstrate the high-quality data generated by our proposed framework improves the performance over state-of-the-art models",
    "checked": true,
    "id": "00c4de0e15f56cd5563f8e04e7302e61517cfb1a",
    "semantic_title": "state-aware adversarial training for utterance-level dialogue generation",
    "citation_count": 0,
    "authors": [
      "Yi Huang",
      "Xiaoting Wu",
      "Wei Hu",
      "Junlan Feng",
      "Chao Deng"
    ]
  },
  "https://aclanthology.org/2022.seretod-1.9": {
    "title": "Information Extraction and Human-Robot Dialogue towards Real-life Tasks A Baseline Study with the MobileCS Dataset",
    "volume": "workshop",
    "abstract": "Recently, there have merged a class of taskoriented dialogue (TOD) datasets collected through Wizard-of-Oz simulated games. However, the Wizard-of-Oz data are in fact simulated data and thus are fundamentally different from real-life conversations, which are more noisy and casual. Recently, the SereTOD challenge is organized and releases the MobileCS dataset, which consists of real-world dialog transcripts between real users and customerservice staffs from China Mobile. Based on the MobileCS dataset, the SereTOD challenge has two tasks, not only evaluating the construction of the dialogue system itself, but also examining information extraction from dialog transcripts, which is crucial for building the knowledge base for TOD. This paper mainly presents a baseline study of the two tasks with the MobileCS dataset. We introduce how the two baselines are constructed, the problems encountered, and the results. We anticipate that the baselines can facilitate exciting future research to build human-robot dialogue systems for real-life tasks",
    "checked": true,
    "id": "ba034601c3af8408107629fb5af644781821a8c9",
    "semantic_title": "information extraction and human-robot dialogue towards real-life tasks a baseline study with the mobilecs dataset",
    "citation_count": 5,
    "authors": [
      "Hong Liu",
      "Hao Peng",
      "Zhijian Ou",
      "Juanzi Li",
      "Yi Huang",
      "Junlan Feng"
    ]
  },
  "https://aclanthology.org/2022.seretod-1.10": {
    "title": "A Generative User Simulator with GPT-based Architecture and Goal State Tracking for Reinforced Multi-Domain Dialog Systems",
    "volume": "workshop",
    "abstract": "Building user simulators (USs) for reinforcement learning (RL) of task-oriented dialog systems (DSs) has gained more and more attention, which, however, still faces several fundamental challenges. First, it is unclear whether we can leverage pretrained language models to design, for example, GPT-2 based USs, to catch up and interact with the recently advanced GPT- 2 based DSs. Second, an important ingredient in a US is that the user goal can be effectively incorporated and tracked; but how to flexibly integrate goal state tracking and develop an end-to-end trainable US for multi-domains has remained to be a challenge. In this work, we propose a generative user simulator (GUS) with GPT-2 based architecture and goal state tracking towards addressing the above two challenges. Extensive experiments are conducted on MultiWOZ2.1. Different DSs are trained via RL with GUS, the classic agenda-based user simulator (ABUS) and other ablation simulators respectively, and are compared for crossmodel evaluation, corpus-based evaluation and human evaluation. The GUS achieves superior results in all three evaluation tasks",
    "checked": true,
    "id": "bba250f9ac68dfeb9dd90b09bb3ed0da31543ea5",
    "semantic_title": "a generative user simulator with gpt-based architecture and goal state tracking for reinforced multi-domain dialog systems",
    "citation_count": 3,
    "authors": [
      "Hong Liu",
      "Yucheng Cai",
      "Zhijian Ou",
      "Yi Huang",
      "Junlan Feng"
    ]
  },
  "https://aclanthology.org/2022.seretod-1.11": {
    "title": "Offline-to-Online Co-Evolutional User Simulator and Dialogue System",
    "volume": "workshop",
    "abstract": "Reinforcement learning (RL) has emerged as a promising approach to fine-tune offline pretrained GPT-2 model in task-oriented dialogue (TOD) systems. In order to obtain human-like online interactions while extending the usage of RL, building pretrained user simulators (US) along with dialogue systems (DS) and facilitating jointly fine-tuning via RL becomes prevalent. However, joint training brings distributional shift problem caused by compounding exposure bias. Existing methods usually iterative update US and DS to ameliorate the ensued non-stationarity problem, which could lead to sub-optimal policy and less sample efficiency. To take a step further for tackling the problem, we introduce an Offline-to-oNline Co-Evolutional (ONCE) framework, which enables bias-aware concurrent joint update for RL-based fine-tuning whilst takes advantages from GPT-2 based end-to-end modeling on US and DS. Extensive experiments demonstrate that ONCE builds high-quality loops of policy learning and dialogues data collection, and achieves state-of-the-art online and offline evaluation results on MultiWOZ2.1 dataset. Opensourced code will be implemented with Mindspore (MS, 2022) and released on our homepage",
    "checked": true,
    "id": "eaf7ecdef0415bf3b9c65a2fd20fd169d912a359",
    "semantic_title": "offline-to-online co-evolutional user simulator and dialogue system",
    "citation_count": 0,
    "authors": [
      "Dafeng Chi",
      "Yuzheng Zhuang",
      "Yao Mu",
      "Bin Wang",
      "Jianzhu Bao",
      "Yasheng Wang",
      "Yuhan Dong",
      "Xin Jiang",
      "Qun Liu",
      "Jianye Hao"
    ]
  },
  "https://aclanthology.org/2022.sustainlp-1.2": {
    "title": "Efficient Two-Stage Progressive Quantization of BERT",
    "volume": "workshop",
    "abstract": "The success of large BERT models has raised the demand for model compression methods to reduce model size and computational cost. Quantization can reduce the model size and inference latency, making inference more efficient, without changing its stucture, but it comes at the cost of performance degradation. Due to the complex loss landscape of ternarized/binarized BERT, we present an efficient two-stage progressive quantization method in which we fine tune the model with quantized weights and progressively lower its bits, and then we fine tune the model with quantized weights and activations. At the same time, we strategically choose which bitwidth to fine-tune on and to initialize from, and which bitwidth to fine-tune under augmented data to outperform the existing BERT binarization methods without adding an extra module, compressing the binary model 18% more than previous binarization methods or compressing BERT by 31x w.r.t. to the full-precision model. Our method without data augmentation can outperform existing BERT ternarization methods",
    "checked": true,
    "id": "fe5feb255909c898abda8dca8b69a046b6afe7ad",
    "semantic_title": "efficient two-stage progressive quantization of bert",
    "citation_count": 0,
    "authors": [
      "Charles Le",
      "Arash Ardakani",
      "Amir Ardakani",
      "Hang Zhang",
      "Yuyan Chen",
      "James Clark",
      "Brett Meyer",
      "Warren Gross"
    ]
  },
  "https://aclanthology.org/2022.sustainlp-1.3": {
    "title": "KGRefiner: Knowledge Graph Refinement for Improving Accuracy of Translational Link Prediction Methods",
    "volume": "workshop",
    "abstract": "Link Prediction is the task of predicting missing relations between knowledge graph entities (KG). Recent work in link prediction mainly attempted to adapt a model to increase link prediction accuracy by using more layers in neural network architecture, which heavily rely on computational resources. This paper proposes the refinement of knowledge graphs to perform link prediction operations more accurately using relatively fast translational models. Translational link prediction models have significantly less complexity than deep learning approaches; this motivated us to improve their accuracy. Our method uses the ontologies of knowledge graphs to add information as auxiliary nodes to the graph. Then, these auxiliary nodes are connected to ordinary nodes of the KG that contain auxiliary information in their hierarchy. Our experiments show that our method can significantly increase the performance of translational link prediction methods in Hit@10, Mean Rank, and Mean Reciprocal Rank",
    "checked": true,
    "id": "e589d5e2a5aad912184d69dacf1cd9101cef9ce2",
    "semantic_title": "kgrefiner: knowledge graph refinement for improving accuracy of translational link prediction methods",
    "citation_count": 3,
    "authors": [
      "Mohammad Javad Saeedizade",
      "Najmeh Torabian",
      "Behrouz Minaei-Bidgoli"
    ]
  },
  "https://aclanthology.org/2022.sustainlp-1.4": {
    "title": "Algorithmic Diversity and Tiny Models: Comparing Binary Networks and the Fruit Fly Algorithm on Document Representation Tasks",
    "volume": "workshop",
    "abstract": "Neural language models have seen a dramatic increase in size in the last years. While many still advocate that ‘bigger is better', work in model distillation has shown that the number of parameters used by very large networks is actually more than what is required for state-of-the-art performance. This prompts an obvious question: can we build smaller models from scratch, rather than going through the inefficient process of training at scale and subsequently reducing model size. In this paper, we investigate the behaviour of a biologically inspired algorithm, based on the fruit fly's olfactory system. This algorithm has shown good performance in the past on the task of learning word embeddings. We now put it to the test on the task of semantic hashing. Specifically, we compare the fruit fly to a standard binary network on the task of generating locality-sensitive hashes for text documents, measuring both task performance and energy consumption. Our results indicate that the two algorithms have complementary strengths while showing similar electricity usage",
    "checked": true,
    "id": "9917e0ad8f927a13a86c7073f9b0fe8a7ffeb9b2",
    "semantic_title": "algorithmic diversity and tiny models: comparing binary networks and the fruit fly algorithm on document representation tasks",
    "citation_count": 0,
    "authors": [
      "Tanise Ceron",
      "Nhut Truong",
      "Aurelie Herbelot"
    ]
  },
  "https://aclanthology.org/2022.sustainlp-1.5": {
    "title": "Look Ma, Only 400 Samples! Revisiting the Effectiveness of Automatic N-Gram Rule Generation for Spelling Normalization in Filipino",
    "volume": "workshop",
    "abstract": "With 84.75 million Filipinos online, the ability for models to process online text is crucial for developing Filipino NLP applications. To this end, spelling correction is a crucial preprocessing step for downstream processing. However, the lack of data prevents the use of language models for this task. In this paper, we propose an N-Gram + Damerau-Levenshtein distance model with automatic rule extraction. We train the model on 300 samples, and show that despite limited training data, it achieves good performance and outperforms other deep learning approaches in terms of accuracy and edit distance. Moreover, the model (1) requires little compute power, (2) trains in little time, thus allowing for retraining, and (3) is easily interpretable, allowing for direct troubleshooting, highlighting the success of traditional approaches over more complex deep learning models in settings where data is unavailable",
    "checked": true,
    "id": "aa94724d1dbc9cad0ad3377903174e776175837a",
    "semantic_title": "look ma, only 400 samples! revisiting the effectiveness of automatic n-gram rule generation for spelling normalization in filipino",
    "citation_count": 0,
    "authors": [
      "Lorenzo Jaime Flores",
      "Dragomir Radev"
    ]
  },
  "https://aclanthology.org/2022.sustainlp-1.6": {
    "title": "Who Says Elephants Can't Run: Bringing Large Scale MoE Models into Cloud Scale Production",
    "volume": "workshop",
    "abstract": "Mixture of Experts (MoE) models with conditional execution of sparsely activated layers has enabled training models with a much larger number of parameters. As a result, these models have achieved significantly better quality on various natural language processing tasks including machine translation. However, it remains challenging to deploy such models in real-life scenarios due to the large memory requirements and inefficient inference. In this work, we introduce a highly efficient inference framework with several optimization approaches to accelerate the computation of sparse models and cut down the memory consumption significantly. While we achieve up to 26x speed-up in terms of throughput, we also reduce the model size almost to one eighth of the original 32-bit float model by quantizing expert weights into 4-bit integers. As a result, we are able to deploy 136x larger models with 27% less cost and significantly better quality with large scale MoE model deployment compared to the existing solutions. This enables a paradigm shift in deploying large scale multilingual MoE transformers models instead of distilling into dozens of smaller models per language or task",
    "checked": true,
    "id": "8e2930ac8ae9a758b367513cccb7d562f354afea",
    "semantic_title": "who says elephants can't run: bringing large scale moe models into cloud scale production",
    "citation_count": 6,
    "authors": [
      "Young Jin Kim",
      "Rawn Henry",
      "Raffy Fahim",
      "Hany Hassan"
    ]
  },
  "https://aclanthology.org/2022.sustainlp-1.7": {
    "title": "Data-Efficient Auto-Regressive Document Retrieval for Fact Verification",
    "volume": "workshop",
    "abstract": "Document retrieval is a core component of many knowledge-intensive natural language processing task formulations such as fact verification. Sources of textual knowledge such as Wikipedia articles condition the generation of answers from the models. Recent advances in retrieval use sequence-to-sequence models to incrementally predict the title of the appropriate Wikipedia page given an input instance. However, this method requires supervision in the form of human annotation to label which Wikipedia pages contain appropriate context. This paper introduces a distant-supervision method that does not require any annotation train auto-regressive retrievers that attain competitive R-Precision and Recall in a zero-shot setting. Furthermore we show that with task-specific supervised fine-tuning, auto-regressive retrieval performance for two Wikipedia-based fact verification tasks can approach or even exceed full supervision using less than 1/4 of the annotated data. We release all code and models",
    "checked": true,
    "id": "2a9082223fd64018786a92c5c626b4923ab8bd72",
    "semantic_title": "data-efficient auto-regressive document retrieval for fact verification",
    "citation_count": 4,
    "authors": [
      "James Thorne"
    ]
  },
  "https://aclanthology.org/2022.sustainlp-1.11": {
    "title": "AfroLM: A Self-Active Learning-based Multilingual Pretrained Language Model for 23 African Languages",
    "volume": "workshop",
    "abstract": "In recent years, multilingual pre-trained language models have gained prominence due to their remarkable performance on numerous downstream Natural Language Processing tasks (NLP). However, pre-training these large multilingual language models requires a lot of training data, which is not available for African Languages. Active learning is a semi-supervised learning algorithm, in which a model consistently and dynamically learns to identify the most beneficial samples to train itself on, in order to achieve better optimization and performance on downstream tasks. Furthermore, active learning effectively and practically addresses real-world data scarcity. Despite all its benefits, active learning, in the context of NLP and especially multilingual language models pretraining, has received little consideration. In this paper, we present AfroLM, a multilingual language model pretrained from scratch on 23 African languages (the largest effort to date) using our novel self-active learning framework. Pretrained on a dataset significantly (14x) smaller than existing baselines, AfroLM outperforms many multilingual pretrained language models (AfriBERTa, XLMR-base, mBERT) on various NLP downstream tasks (NER, text classification, and sentiment analysis). Additional out-of-domain sentiment analysis experiments show that AfroLM is able to generalize well across various domains. We release the code source, and our datasets used in our framework at https://github.com/bonaventuredossou/MLM_AL",
    "checked": true,
    "id": "c6b30fc2469c4e72a311d91f831cb09ad9345a5d",
    "semantic_title": "afrolm: a self-active learning-based multilingual pretrained language model for 23 african languages",
    "citation_count": 26,
    "authors": [
      "Bonaventure F. P. Dossou",
      "Atnafu Lambebo Tonja",
      "Oreen Yousuf",
      "Salomey Osei",
      "Abigail Oppong",
      "Iyanuoluwa Shode",
      "Oluwabusayo Olufunke Awoyomi",
      "Chris Emezue"
    ]
  },
  "https://aclanthology.org/2022.sustainlp-1.13": {
    "title": "Towards Fair Dataset Distillation for Text Classification",
    "volume": "workshop",
    "abstract": "With the growing prevalence of large-scale language models, their energy footprint and potential to learn and amplify historical biases are two pressing challenges. Dataset distillation (DD) — a method for reducing the dataset size by learning a small number of synthetic samples which encode the information in the original dataset — is a method for reducing the cost of model training, however its impact on fairness has not been studied. We investigate how DD impacts on group bias, with experiments over two language classification tasks, concluding that vanilla DD preserves the bias of the dataset. We then show how existing debiasing methods can be combined with DD to produce models that are fair and accurate, at reduced training cost",
    "checked": true,
    "id": "1a1dec9f649aed22272d6c3e30a5cc1fae427310",
    "semantic_title": "towards fair dataset distillation for text classification",
    "citation_count": 2,
    "authors": [
      "Xudong Han",
      "Aili Shen",
      "Yitong Li",
      "Lea Frermann",
      "Timothy Baldwin",
      "Trevor Cohn"
    ]
  },
  "https://aclanthology.org/2022.umios-1.1": {
    "title": "Named Entity Recognition as Structured Span Prediction",
    "volume": "workshop",
    "abstract": "Named Entity Recognition (NER) is an important task in Natural Language Processing with applications in many domains. While the dominant paradigm of NER is sequence labelling, span-based approaches have become very popular in recent times but are less well understood. In this work, we study different aspects of span-based NER, namely the span representation, learning strategy, and decoding algorithms to avoid span overlap. We also propose an exact algorithm that efficiently finds the set of non-overlapping spans that maximizes a global score, given a list of candidate spans. We performed our study on three benchmark NER datasets from different domains. We make our code publicly available at https://github.com/urchade/span-structured-prediction",
    "checked": true,
    "id": "98ba5adbfbac2185ac9b771d41ea337566812c5e",
    "semantic_title": "named entity recognition as structured span prediction",
    "citation_count": 9,
    "authors": [
      "Urchade Zaratiana",
      "Nadi Tomeh",
      "Pierre Holat",
      "Thierry Charnois"
    ]
  },
  "https://aclanthology.org/2022.umios-1.2": {
    "title": "Global Span Selection for Named Entity Recognition",
    "volume": "workshop",
    "abstract": "Named Entity Recognition (NER) is an important task in Natural Language Processing with applications in many domains. In this paper, we describe a novel approach to named entity recognition, in which we output a set of spans (i.e., segmentations) by maximizing a global score. During training, we optimize our model by maximizing the probability of the gold segmentation. During inference, we use dynamic programming to select the best segmentation under a linear time complexity. We prove that our approach outperforms CRF and semi-CRF models for Named Entity Recognition. We will make our code publicly available",
    "checked": true,
    "id": "f0611c2438f0784ad706c82d7c4281efe37cfb64",
    "semantic_title": "global span selection for named entity recognition",
    "citation_count": 1,
    "authors": [
      "Urchade Zaratiana",
      "Niama El Elkhbir",
      "Pierre Holat",
      "Nadi Tomeh",
      "Thierry Charnois"
    ]
  },
  "https://aclanthology.org/2022.umios-1.3": {
    "title": "Visual Grounding of Inter-lingual Word-Embeddings",
    "volume": "workshop",
    "abstract": "Visual grounding of Language aims at enriching textual representations of language with multiple sources of visual knowledge such as images and videos. Although visual grounding is an area of intense research, inter-lingual aspects of visual grounding have not received much attention. The present study investigates the inter-lingual visual grounding of word embeddings. We propose an implicit alignment technique between the two spaces of vision and language in which inter-lingual textual information interacts in order to enrich pre-trained textual word embeddings. We focus on three languages in our experiments, namely, English, Arabic, and German. We obtained visually grounded vector representations for these languages and studied whether visual grounding on one or multiple languages improved the performance of embeddings on word similarity and categorization benchmarks. Our experiments suggest that inter-lingual knowledge improves the performance of grounded embeddings in similar languages such as German and English. However, inter-lingual grounding of German or English with Arabic led to a slight degradation in performance on word similarity benchmarks. On the other hand, we observed an opposite trend on categorization benchmarks where Arabic had the most improvement on English. In the discussion section, several reasons for those findings are laid out. We hope that our experiments provide a baseline for further research on inter lingual visual grounding",
    "checked": true,
    "id": "eb10a62973b6a10b253494a71423f02d954a926e",
    "semantic_title": "visual grounding of inter-lingual word-embeddings",
    "citation_count": 0,
    "authors": [
      "Wafaa Mohammed",
      "Hassan Shahmohammadi",
      "Hendrik P. A. Lensch",
      "R. Harald Baayen"
    ]
  },
  "https://aclanthology.org/2022.umios-1.4": {
    "title": "A Subspace-Based Analysis of Structured and Unstructured Representations in Image-Text Retrieval",
    "volume": "workshop",
    "abstract": "In this paper, we specifically look at the image-text retrieval problem. Recent multimodal frameworks have shown that structured inputs and fine-tuning lead to consistent performance improvement. However, this paradigm has been challenged recently with newer Transformer-based models that can reach zero-shot state-of-the-art results despite not explicitly using structured data during pre-training. Since such strategies lead to increased computational resources, we seek to better understand their role in image-text retrieval by analyzing visual and text representations extracted with three multimodal frameworks – SGM, UNITER, and CLIP. To perform such analysis, we represent a single image or text as low-dimensional linear subspaces and perform retrieval based on subspace similarity. We chose this representation as subspaces give us the flexibility to model an entity based on feature sets, allowing us to observe how integrating or reducing information changes the representation of each entity. We analyze the performance of the selected models' features on two standard benchmark datasets. Our results indicate that heavily pre-training models can already lead to features with critical information representing each entity, with zero-shot UNITER features performing consistently better than fine-tuned features. Furthermore, while models can benefit from structured inputs, learning representations for objects and relationships separately, such as in SGM, likely causes a loss of crucial contextual information needed to obtain a compact cluster that can effectively represent a single entity",
    "checked": true,
    "id": "12ff5ac46bb3bfaf6913f0db30d9ecee96e16ac0",
    "semantic_title": "a subspace-based analysis of structured and unstructured representations in image-text retrieval",
    "citation_count": 0,
    "authors": [
      "Erica K. Shimomoto",
      "Edison Marrese-Taylor",
      "Hiroya Takamura",
      "Ichiro Kobayashi",
      "Yusuke Miyao"
    ]
  },
  "https://aclanthology.org/2022.umios-1.5": {
    "title": "Discourse Relation Embeddings: Representing the Relations between Discourse Segments in Social Media",
    "volume": "workshop",
    "abstract": "Discourse relations are typically modeled as a discrete class that characterizes the relation between segments of text (e.g. causal explanations, expansions). However, such predefined discrete classes limit the universe of potential relationships and their nuanced differences. Adding higher-level semantic structure to contextual word embeddings, we propose representing discourse relations as points in high dimensional continuous space. However, unlike words, discourse relations often have no surface form (relations are in between two segments, often with no word or phrase in that gap) which presents a challenge for existing embedding techniques. We present a novel method for automatically creating discourse relation embeddings (DiscRE), addressing the embedding challenge through a weakly supervised, multitask approach to learn diverse and nuanced relations in social media. Results show DiscRE representations obtain the best performance on Twitter discourse relation classification (macro F1=0.76), social media causality prediction (from F1=0.79 to 0.81), and perform beyond modern sentence and word transformers at traditional discourse relation classification, capturing novel nuanced relations (e.g. relations at the intersection of causal explanations and counterfactuals)",
    "checked": true,
    "id": "6708f03f18215f32fbae800a8b748d4a792a1923",
    "semantic_title": "discourse relation embeddings: representing the relations between discourse segments in social media",
    "citation_count": 10,
    "authors": [
      "Youngseo Son",
      "Vasudha Varadarajan",
      "H. Andrew Schwartz"
    ]
  },
  "https://aclanthology.org/2022.umios-1.6": {
    "title": "Understanding Cross-modal Interactions in V&L Models that Generate Scene Descriptions",
    "volume": "workshop",
    "abstract": "Image captioning models tend to describe images in an object-centric way, emphasising visible objects. But image descriptions can also abstract away from objects and describe the type of scene depicted. In this paper, we explore the potential of a state of the art Vision and Language model, VinVL, to caption images at the scene level using (1) a novel dataset which pairs images with both object-centric and scene descriptions. Through (2) an in-depth analysis of the effect of the fine-tuning, we show (3) that a small amount of curated data suffices to generate scene descriptions without losing the capability to identify object-level concepts in the scene; the model acquires a more holistic view of the image compared to when object-centric descriptions are generated. We discuss the parallels between these results and insights from computational and cognitive science research on scene perception",
    "checked": true,
    "id": "c9731012ce41943eba34a88cf250e9ae07cf345e",
    "semantic_title": "understanding cross-modal interactions in v&l models that generate scene descriptions",
    "citation_count": 2,
    "authors": [
      "Michele Cafagna",
      "Kees van Deemter",
      "Albert Gatt"
    ]
  },
  "https://aclanthology.org/2022.umios-1.8": {
    "title": "DeepParliament: A Legal domain Benchmark & Dataset for Parliament Bills Prediction",
    "volume": "workshop",
    "abstract": "This paper introduces DeepParliament, a legal domain Benchmark Dataset that gathers bill documents and metadata and performs various bill status classification tasks. The proposed dataset text covers a broad range of bills from 1986 to the present and contains richer information on parliament bill content. Data collection, detailed statistics and analyses are provided in the paper. Moreover, we experimented with different types of models ranging from RNN to pretrained and reported the results. We are proposing two new benchmarks: Binary and Multi-Class Bill Status classification. Models developed for bill documents and relevant supportive tasks may assist Members of Parliament (MPs), presidents, and other legal practitioners. It will help review or prioritise bills, thus speeding up the billing process, improving the quality of decisions and reducing the time consumption in both houses. Considering that the foundation of the country\"s democracy is Parliament and state legislatures, we anticipate that our research will be an essential addition to the Legal NLP community. This work will be the first to present a Parliament bill prediction task. In order to improve the accessibility of legal AI resources and promote reproducibility, we have made our code and dataset publicly accessible at github.com/monk1337/DeepParliament",
    "checked": true,
    "id": "41a7ad784a344d64c766bd3b2317810155187d68",
    "semantic_title": "deepparliament: a legal domain benchmark & dataset for parliament bills prediction",
    "citation_count": 0,
    "authors": [
      "Ankit Pal"
    ]
  },
  "https://aclanthology.org/2022.umios-1.9": {
    "title": "Punctuation and case restoration in code mixed Indian languages",
    "volume": "workshop",
    "abstract": "Automatic Speech Recognition (ASR) systems are taking over in different industries starting from producing video subtitles to interactive digital assistants. ASR output can be used in automatic indexing, categorizing, searching along with normal human readability. Raw transcripts from ASR systems are difficult to interpret since it usually produces text without punctuation and case information (all lower, all upper, camel case etc.), thus limiting the performance of downstream NLP tasks. We proposed an approach to restore the punctuation and case for both English and Hinglish (i.e Hindi vocabulary in Latin script) languages. We have performed a classification task using encoder-based transformers which is a mini BERT consisting of 4 encoder layers for punctuation and case restoration instead of the traditional Seq2Seq model considering the latency constraint in real world use cases. It consists of a total number of 15 distinct classes for the model which includes 5 punctuations i.e Period(.), Comma(,), Single Quote(‘), Double Quote(\") & Question Mark(?) with different combinations of casing. The model is benchmarked on an internal dataset which was based on user conversation with the voice assistant and it achieves a F1(macro) score of 91.52% on the test set",
    "checked": true,
    "id": "0ea3921965a6048940d3d4e2639cfc4b04424e69",
    "semantic_title": "punctuation and case restoration in code mixed indian languages",
    "citation_count": 0,
    "authors": [
      "Subhashree Tripathy",
      "Ashis Samal"
    ]
  },
  "https://aclanthology.org/2022.umios-1.10": {
    "title": "Probing Script Knowledge from Pre-Trained Models",
    "volume": "workshop",
    "abstract": "Adversarial attack of structured prediction models faces various challenges such as the difficulty of perturbing discrete words, the sentence quality issue, and the sensitivity of outputs to small perturbations. In this work, we introduce SHARP, a new attack method that formulates the black-box adversarial attack as a search-based optimization problem with a specially designed objective function considering sentence fluency, meaning preservation and attacking effectiveness. Additionally, three different searching strategies are analyzed and compared, , Beam Search, Metropolis-Hastings Sampling, and Hybrid Search. We demonstrate the effectiveness of our attacking strategies on two challenging structured prediction tasks: part-of-speech (POS) tagging and dependency parsing. Through automatic and human evaluations, we show that our method performs a more potent attack compared with pioneer arts. Moreover, the generated adversarial examples can be used to successfully boost the robustness and performance of the victim model via adversarial training",
    "checked": true,
    "id": "cf2453589ee98561c599694fce3220aa79e5c56b",
    "semantic_title": "probing script knowledge from pre-trained models",
    "citation_count": 4,
    "authors": [
      "Zijia Jin",
      "Xingyu Zhang",
      "Mo Yu",
      "Lifu Huang"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.1": {
    "title": "CAraNER: The COVID-19 Arabic Named Entity Corpus",
    "volume": "workshop",
    "abstract": "Named Entity Recognition (NER) is a well-known problem for the natural language processing (NLP) community. It is a key component of different NLP applications, including information extraction, question answering, and information retrieval. In the literature, there are several Arabic NER datasets with different named entity tags; however, due to data and concept drift, we are always in need of new data for NER and other NLP applications. In this paper, first, we introduce Wassem, a web-based annotation platform for Arabic NLP applications. Wassem can be used to manually annotate textual data for a variety of NLP tasks: text classification, sequence classification, and word segmentation. Second, we introduce the COVID-19 Arabic Named Entities Recognition (CAraNER) dataset. CAraNER has 55,389 tokens distributed over 1,278 sentences randomly extracted from Saudi Arabian newspaper articles published during 2019, 2020, and 2021. The dataset is labeled by five annotators with five named-entity tags, namely: Person, Title, Location, Organization, and Miscellaneous. The CAraNER corpus is available for download for free. We evaluate the corpus by finetuning four BERT-based Arabic language models on the CAraNER corpus. The best model was AraBERTv0.2-large with 0.86 for the F1 macro measure",
    "checked": true,
    "id": "f44c5405cf8ad8cced3f74e3db9e8f0275ac0606",
    "semantic_title": "caraner: the covid-19 arabic named entity corpus",
    "citation_count": 2,
    "authors": [
      "Abdulmohsen Al-Thubaity",
      "Sakhar Alkhereyf",
      "Wejdan Alzahrani",
      "Alia Bahanshal"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.2": {
    "title": "Joint Coreference Resolution for Zeros and non-Zeros in Arabic",
    "volume": "workshop",
    "abstract": "Most existing proposals about anaphoric zero pronoun (AZP) resolution regard full mention coreference and AZP resolution as two independent tasks, even though the two tasks are clearly related. The main issues that need tackling to develop a joint model for zero and non-zero mentions are the difference between the two types of arguments (zero pronouns, being null, provide no nominal information) and the lack of annotated datasets of a suitable size in which both types of arguments are annotated for languages other than Chinese and Japanese. In this paper, we introduce two architectures for jointly resolving AZPs and non-AZPs, and evaluate them on Arabic, a language for which, as far as we know, there has been no prior work on joint resolution. Doing this also required creating a new version of the Arabic subset of the standard coreference resolution dataset used for the CoNLL-2012 shared task (Pradhan et al.,2012) in which both zeros and non-zeros are included in a single dataset",
    "checked": true,
    "id": "5933df595e23614cd886931a4c8121f7ff91d2b0",
    "semantic_title": "joint coreference resolution for zeros and non-zeros in arabic",
    "citation_count": 1,
    "authors": [
      "Abdulrahman Aloraini",
      "Sameer Pradhan",
      "Massimo Poesio"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.3": {
    "title": "SAIDS: A Novel Approach for Sentiment Analysis Informed of Dialect and Sarcasm",
    "volume": "workshop",
    "abstract": "Sentiment analysis becomes an essential part of every social network, as it enables decision-makers to know more about users' opinions in almost all life aspects. Despite its importance, there are multiple issues it encounters like the sentiment of the sarcastic text which is one of the main challenges of sentiment analysis. This paper tackles this challenge by introducing a novel system (SAIDS) that predicts the sentiment, sarcasm and dialect of Arabic tweets. SAIDS uses its prediction of sarcasm and dialect as known information to predict the sentiment. It uses MARBERT as a language model to generate sentence embedding, then passes it to the sarcasm and dialect models, and then the outputs of the three models are concatenated and passed to the sentiment analysis model. Multiple system design setups were experimented with and reported. SAIDS was applied to the ArSarcasm-v2 dataset where it outperforms the state-of-the-art model for the sentiment analysis task. By training all tasks together, SAIDS achieves results of 75.98 FPN, 59.09 F1-score and 71.13 F1-score for sentiment analysis, sarcasm detection, and dialect identification respectively. The system design can be used to enhance the performance of any task which is dependent on other tasks",
    "checked": true,
    "id": "c80228c8fbc3018b0db8bb4205bccdd490c8e9ad",
    "semantic_title": "saids: a novel approach for sentiment analysis informed of dialect and sarcasm",
    "citation_count": 3,
    "authors": [
      "Abdelrahman Kaseb",
      "Mona Farouk"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.4": {
    "title": "AraBART: a Pretrained Arabic Sequence-to-Sequence Model for Abstractive Summarization",
    "volume": "workshop",
    "abstract": "Like most natural language understanding and generation tasks, state-of-the-art models for summarization are transformer-based sequence-to-sequence architectures that are pretrained on large corpora. While most existing models focus on English, Arabic remains understudied. In this paper we propose AraBART, the first Arabic model in which the encoder and the decoder are pretrained end-to-end, based on BART. We show that AraBART achieves the best performance on multiple abstractive summarization datasets, outperforming strong baselines including a pretrained Arabic BERT-based model, multilingual BART, Arabic T5, and a multilingual T5 model. AraBART is publicly available",
    "checked": true,
    "id": "f72413a441737e1f944a4346221db0ab9baec32d",
    "semantic_title": "arabart: a pretrained arabic sequence-to-sequence model for abstractive summarization",
    "citation_count": 24,
    "authors": [
      "Moussa Kamal Eddine",
      "Nadi Tomeh",
      "Nizar Habash",
      "Joseph Le Roux",
      "Michalis Vazirgiannis"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.5": {
    "title": "Towards Arabic Sentence Simplification via Classification and Generative Approaches",
    "volume": "workshop",
    "abstract": "This paper presents an attempt to build a Modern Standard Arabic (MSA) sentence-level simplification system. We experimented with sentence simplification using two approaches: (i) a classification approach leading to lexical simplification pipelines which use Arabic-BERT, a pre-trained contextualised model, as well as a model of fastText word embeddings; and (ii) a generative approach, a Seq2Seq technique by applying a multilingual Text-to-Text Transfer Transformer mT5. We developed our training corpus by aligning the original and simplified sentences from the internationally acclaimed Arabic novel Saaq al-Bambuu. We evaluate effectiveness of these methods by comparing the generated simple sentences to the target simple sentences using the BERTScore evaluation metric. The simple sentences produced by the mT5 model achieve P 0.72, R 0.68 and F-1 0.70 via BERTScore, while, combining Arabic-BERT and fastText achieves P 0.97, R 0.97 and F-1 0.97. In addition, we report a manual error analysis for these experiments",
    "checked": true,
    "id": "3efedba458a2bbdbc50bbfbc374cee0a4293a98d",
    "semantic_title": "towards arabic sentence simplification via classification and generative approaches",
    "citation_count": 2,
    "authors": [
      "Nouran Khallaf",
      "Serge Sharoff",
      "Rasha Soliman"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.6": {
    "title": "Generating Classical Arabic Poetry using Pre-trained Models",
    "volume": "workshop",
    "abstract": "Poetry generation tends to be a complicated task given meter and rhyme constraints. Previous work resorted to exhaustive methods in-order to employ poetic elements. In this paper we leave pre-trained models, GPT-J and BERTShared to recognize patterns of meters and rhyme to generate classical Arabic poetry and present our findings and results on how well both models could pick up on these classical Arabic poetic elements",
    "checked": true,
    "id": "6bff90e44c26f59f6201ecf132516ff9a62442cc",
    "semantic_title": "generating classical arabic poetry using pre-trained models",
    "citation_count": 1,
    "authors": [
      "Nehal Elkaref",
      "Mervat Abu-Elkheir",
      "Maryam ElOraby",
      "Mohamed Abdelgaber"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.7": {
    "title": "A Benchmark Study of Contrastive Learning for Arabic Social Meaning",
    "volume": "workshop",
    "abstract": "Contrastive learning (CL) has brought significant progress to various NLP tasks. Despite such a progress, CL has not been applied to Arabic NLP. Nor is it clear how much benefits it could bring to particular classes of tasks such as social meaning (e.g., sentiment analysis, dialect identification, hate speech detection). In this work, we present a comprehensive benchmark study of state-of-the-art supervised CL methods on a wide array of Arabic social meaning tasks. Through an extensive empirical analysis, we show that CL methods outperform vanilla finetuning on most of the tasks. We also show that CL can be data efficient and quantify this efficiency, demonstrating the promise of these methods in low-resource settings vis-a-vis the particular downstream tasks (especially label granularity)",
    "checked": true,
    "id": "e0a5634fd334b4a07e8782a0aae15dca31a17be7",
    "semantic_title": "a benchmark study of contrastive learning for arabic social meaning",
    "citation_count": 2,
    "authors": [
      "Md Tawkat Islam Khondaker",
      "El Moatez Billah Nagoudi",
      "AbdelRahim Elmadany",
      "Muhammad Abdul-Mageed",
      "Laks Lakshmanan, V.S."
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.8": {
    "title": "Adversarial Text-to-Speech for low-resource languages",
    "volume": "workshop",
    "abstract": "In this paper we propose a new method for training adversarial text-to-speech (TTS) models for low-resource languages using auxiliary data. Specifically, we modify the MelGAN (Kumar et al., 2019) architecture to achieve better performance in Arabic speech generation, exploring multiple additional datasets and architectural choices, which involved extra discriminators designed to exploit high-frequency similarities between languages. In our evaluation, we used subjective human evaluation, MOS-Mean Opinion Score, and a novel quantitative metric, the Fréchet Wav2Vec Distance, which we found to be well correlated with MOS. Both subjectively and quantitatively, our method outperformed the standard MelGAN model",
    "checked": true,
    "id": "86ab75aa77c4562689b7718ae8f00d7a8686ae7e",
    "semantic_title": "adversarial text-to-speech for low-resource languages",
    "citation_count": 1,
    "authors": [
      "Ashraf Elneima",
      "Mikołaj Bińkowski"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.9": {
    "title": "NADI 2022: The Third Nuanced Arabic Dialect Identification Shared Task",
    "volume": "workshop",
    "abstract": "We describe the findings of the third Nuanced Arabic Dialect Identification Shared Task (NADI 2022). NADI aims at advancing state-of-the-art Arabic NLP, including Arabic dialects. It does so by affording diverse datasets and modeling opportunities in a standardized context where meaningful comparisons between models and approaches are possible. NADI 2022 targeted both dialect identification (Subtask 1) and dialectal sentiment analysis (Subtask 2) at the country level. A total of 41 unique teams registered for the shared task, of whom 21 teams have participated (with 105 valid submissions). Among these, 19 teams participated in Subtask 1, and 10 participated in Subtask 2. The winning team achieved F1=27.06 on Subtask 1 and F1=75.16 on Subtask 2, reflecting that both subtasks remain challenging and motivating future work in this area. We describe the methods employed by the participating teams and offer an outlook for NADI",
    "checked": true,
    "id": "c1bec16532c631f7de1e571c5404e3b25c3ef22f",
    "semantic_title": "nadi 2022: the third nuanced arabic dialect identification shared task",
    "citation_count": 33,
    "authors": [
      "Muhammad Abdul-Mageed",
      "Chiyu Zhang",
      "AbdelRahim Elmadany",
      "Houda Bouamor",
      "Nizar Habash"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.10": {
    "title": "The Shared Task on Gender Rewriting",
    "volume": "workshop",
    "abstract": "In this paper, we present the results and findings of the Shared Task on Gender Rewriting, which was organized as part of the Seventh Arabic Natural Language Processing Workshop. The task of gender rewriting refers to generating alternatives of a given sentence to match different target user gender contexts (e.g., a female speaker with a male listener, a male speaker with a male listener, etc.). This requires changing the grammatical gender (masculine or feminine) of certain words referring to the users. In this task, we focus on Arabic, a gender-marking morphologically rich language. A total of five teams from four countries participated in the shared task",
    "checked": true,
    "id": "9413f46e9461c272570e9a3ecdd665a759aa78a1",
    "semantic_title": "the shared task on gender rewriting",
    "citation_count": 1,
    "authors": [
      "Bashar Alhafni",
      "Nizar Habash",
      "Houda Bouamor",
      "Ossama Obeid",
      "Sultan Alrowili",
      "Daliyah AlZeer",
      "Kawla Mohmad Shnqiti",
      "Ahmed Elbakry",
      "Muhammad ElNokrashy",
      "Mohamed Gabr",
      "Abderrahmane Issam",
      "Abdelrahim Qaddoumi",
      "Vijay Shanker",
      "Mahmoud Zyate"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.11": {
    "title": "Overview of the WANLP 2022 Shared Task on Propaganda Detection in Arabic",
    "volume": "workshop",
    "abstract": "Propaganda is defined as an expression of opinion or action by individuals or groups deliberately designed to influence opinions or actions of other individuals or groups with reference to predetermined ends and this is achieved by means of well-defined rhetorical and psychological devices. Currently, propaganda (or persuasion) techniques have been commonly used on social media to manipulate or mislead social media users. Automatic detection of propaganda techniques from textual, visual, or multimodal content has been studied recently, however, major of such efforts are focused on English language content. In this paper, we propose a shared task on detecting propaganda techniques for Arabic textual content. We have done a pilot annotation of 200 Arabic tweets, which we plan to extend to 2,000 tweets, covering diverse topics. We hope that the shared task will help in building a community for Arabic propaganda detection. The dataset will be made publicly available, which can help in future studies",
    "checked": true,
    "id": "7135f82cf14f0ffefcffdb45667d3c559314679d",
    "semantic_title": "overview of the wanlp 2022 shared task on propaganda detection in arabic",
    "citation_count": 37,
    "authors": [
      "Firoj Alam",
      "Hamdy Mubarak",
      "Wajdi Zaghouani",
      "Giovanni Da San Martino",
      "Preslav Nakov"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.12": {
    "title": "ArzEn-ST: A Three-way Speech Translation Corpus for Code-Switched Egyptian Arabic-English",
    "volume": "workshop",
    "abstract": "We present our work on collecting ArzEn-ST, a code-switched Egyptian Arabic-English Speech Translation Corpus. This corpus is an extension of the ArzEn speech corpus, which was collected through informal interviews with bilingual speakers. In this work, we collect translations in both directions, monolingual Egyptian Arabic and monolingual English, forming a three-way speech translation corpus. We make the translation guidelines and corpus publicly available. We also report results for baseline systems for machine translation and speech translation tasks. We believe this is a valuable resource that can motivate and facilitate further research studying the code-switching phenomenon from a linguistic perspective and can be used to train and evaluate NLP systems",
    "checked": true,
    "id": "db2c4168c864dc99477866b4221a1ded8640bcef",
    "semantic_title": "arzen-st: a three-way speech translation corpus for code-switched egyptian arabic-english",
    "citation_count": 8,
    "authors": [
      "Injy Hamed",
      "Nizar Habash",
      "Slim Abdennadher",
      "Ngoc Thang Vu"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.13": {
    "title": "Maknuune: A Large Open Palestinian Arabic Lexicon",
    "volume": "workshop",
    "abstract": "We present Maknuune, a large open lexicon for the Palestinian Arabic dialect. Maknuune has over 36K entries from 17K lemmas, and 3.7K roots. All entries include diacritized Arabic orthography, phonological transcription and English glosses. Some entries are enriched with additional information such as broken plurals and templatic feminine forms, associated phrases and collocations, Standard Arabic glosses, and examples or notes on grammar, usage, or location of collected entry",
    "checked": true,
    "id": "ffb44addd534988fc707e417d31e303d19dda168",
    "semantic_title": "maknuune: a large open palestinian arabic lexicon",
    "citation_count": 1,
    "authors": [
      "Shahd Salah Uddin Dibas",
      "Christian Khairallah",
      "Nizar Habash",
      "Omar Fayez Sadi",
      "Tariq Sairafy",
      "Karmel Sarabta",
      "Abrar Ardah"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.14": {
    "title": "Developing a Tag-Set and Extracting the Morphological Lexicons to Build a Morphological Analyzer for Egyptian Arabic",
    "volume": "workshop",
    "abstract": "This paper sheds light on an in-progress work for building a morphological analyzer for Egyptian Arabic (EGY). To build such a tool, a tag-set schema is developed depending on a corpus of 527,000 EGY words covering different sources and genres. This tag-set schema is used in annotating about 318,940 words, morphologically, according to their contexts. Each annotated word is associated with its suitable prefix(s), original stem, tag, suffix(s), glossary, number, gender, definiteness, and conventional lemma and stem. These morphologically annotated words, in turns, are used in developing the proposed morphological analyzer where the morphological lexicons and the compatibility tables are extracted and tested. The system is compared with one of best EGY morphological analyzers; CALIMA",
    "checked": true,
    "id": "de5dac89784130b4b61ccd536ad7c58f7187dcf6",
    "semantic_title": "developing a tag-set and extracting the morphological lexicons to build a morphological analyzer for egyptian arabic",
    "citation_count": 3,
    "authors": [
      "Amany Fashwan",
      "Sameh Alansary"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.15": {
    "title": "A Weak Supervised Transfer Learning Approach for Sentiment Analysis to the Kuwaiti Dialect",
    "volume": "workshop",
    "abstract": "Developing a system for sentiment analysis is very challenging for the Arabic language due to the limitations in the available Arabic datasets. Many Arabic dialects are still not studied by researchers in Arabic sentiment analysis due to the complexity of annotators' recruitment process during dataset creation. This paper covers the research gap in sentiment analysis for the Kuwaiti dialect by proposing a weak supervised approach to develop a large labeled dataset. Our dataset consists of over 16.6k tweets with 7,905 negatives, 7,902 positives, and 860 neutrals that spans several themes and time frames to remove any bias that might affect its content. The annotation agreement between our proposed system's labels and human-annotated labels reports 93% for the pairwise percent agreement and 0.87 for Cohen's kappa coefficient. Furthermore, we evaluate our dataset using multiple traditional machine learning classifiers and advanced deep learning language models to test its performance. The results report 89% accuracy when applied to the testing dataset using the ARBERT model",
    "checked": true,
    "id": "82194b3642f8cf2218e7fe0e04313be197d00423",
    "semantic_title": "a weak supervised transfer learning approach for sentiment analysis to the kuwaiti dialect",
    "citation_count": 4,
    "authors": [
      "Fatemah Husain",
      "Hana Al-Ostad",
      "Halima Omar"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.16": {
    "title": "Mawqif: A Multi-label Arabic Dataset for Target-specific Stance Detection",
    "volume": "workshop",
    "abstract": "Social media platforms are becoming inherent parts of people's daily life to express opinions and stances toward topics of varying polarities. Stance detection determines the viewpoint expressed in a text toward a target. While communication on social media (e.g., Twitter) takes place in more than 40 languages, the majority of stance detection research has been focused on English. Although some efforts have recently been made to develop stance detection datasets in other languages, no similar efforts seem to have considered the Arabic language. In this paper, we present Mawqif, the first Arabic dataset for target-specific stance detection, composed of 4,121 tweets annotated with stance, sentiment, and sarcasm polarities. Mawqif, as a multi-label dataset, can provide more opportunities for studying the interaction between different opinion dimensions and evaluating a multi-task model. We provide a detailed description of the dataset, present an analysis of the produced annotation, and evaluate four BERT-based models on it. Our best model achieves a macro-F1 of 78.89%, which shows that there is ample room for improvement on this challenging task. We publicly release our dataset, the annotation guidelines, and the code of the experiments",
    "checked": true,
    "id": "11451dc28b5bc7cdc4caf0bb5f223ee30af3bc0d",
    "semantic_title": "mawqif: a multi-label arabic dataset for target-specific stance detection",
    "citation_count": 6,
    "authors": [
      "Nora Saleh Alturayeif",
      "Hamzah Abdullah Luqman",
      "Moataz Aly Kamaleldin Ahmed"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.17": {
    "title": "Assessing the Linguistic Knowledge in Arabic Pre-trained Language Models Using Minimal Pairs",
    "volume": "workshop",
    "abstract": "Despite the noticeable progress that we recently witnessed in Arabic pre-trained language models (PLMs), the linguistic knowledge captured by these models remains unclear. In this paper, we conducted a study to evaluate available Arabic PLMs in terms of their linguistic knowledge. BERT-based language models (LMs) are evaluated using Minimum Pairs (MP), where each pair represents a grammatical sentence and its contradictory counterpart. MPs isolate specific linguistic knowledge to test the model's sensitivity in understanding a specific linguistic phenomenon. We cover nine major Arabic phenomena: Verbal sentences, Nominal sentences, Adjective Modification, and Idafa construction. The experiments compared the results of fifteen Arabic BERT-based PLMs. Overall, among all tested models, CAMeL-CA outperformed the other PLMs by achieving the highest overall accuracy",
    "checked": true,
    "id": "a3bd35735922310e516d502ef95cacf45e27a548",
    "semantic_title": "assessing the linguistic knowledge in arabic pre-trained language models using minimal pairs",
    "citation_count": 0,
    "authors": [
      "Wafa Abdullah Alrajhi",
      "Hend Al-Khalifa",
      "Abdulmalik AlSalman"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.18": {
    "title": "Identifying Code-switching in Arabizi",
    "volume": "workshop",
    "abstract": "We describe a corpus of social media posts that include utterances in Arabizi, a Roman-script rendering of Arabic, mixed with other languages, notably English, French, and Arabic written in the Arabic script. We manually annotated a subset of the texts with word-level language IDs; this is a non-trivial task due to the nature of mixed-language writing, especially on social media. We developed classifiers that can accurately predict the language ID tags. Then, we extended the word-level predictions to identify sentences that include Arabizi (and code-switching), and applied the classifiers to the raw corpus, thereby harvesting a large number of additional instances. The result is a large-scale dataset of Arabizi, with precise indications of code-switching between Arabizi and English, French, and Arabic",
    "checked": true,
    "id": "88e77c1d72f44bbe233e4396c38c9d47e0e6a091",
    "semantic_title": "identifying code-switching in arabizi",
    "citation_count": 2,
    "authors": [
      "Safaa Shehadi",
      "Shuly Wintner"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.19": {
    "title": "Authorship Verification for Arabic Short Texts Using Arabic Knowledge-Base Model (AraKB)",
    "volume": "workshop",
    "abstract": "Arabic is a Semitic language, considered to be one of the most complex languages in the world due to its unique composition and complex linguistic features. It consequently causes challenges for verifying the authorship of Arabic texts, requiring extensive research and development. This paper presents a new knowledge-based model to enhance Natural Language Understanding and thereby improve authorship verification performance. The proposed model provided promising results that would benefit the Arabic research for different Natural Language Processing tasks",
    "checked": true,
    "id": "86cf70e8884862dfe09e9683b1dbc96950ea906e",
    "semantic_title": "authorship verification for arabic short texts using arabic knowledge-base model (arakb)",
    "citation_count": 0,
    "authors": [
      "Fatimah Alqahtani",
      "Helen Yannakoudakis"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.20": {
    "title": "A Semi-supervised Approach for a Better Translation of Sentiment in Dialectical Arabic UGT",
    "volume": "workshop",
    "abstract": "In the online world, Machine Translation (MT) systems are extensively used to translate User-Generated Text (UGT) such as reviews, tweets, and social media posts, where the main message is often the author's positive or negative attitude towards the topic of the text. However, MT systems still lack accuracy in some low-resource languages and sometimes make critical translation errors that completely flip the sentiment polarity of the target word or phrase and hence delivers a wrong affect message. This is particularly noticeable in texts that do not follow common lexico-grammatical standards such as the dialectical Arabic (DA) used on online platforms. In this research, we aim to improve the translation of sentiment in UGT written in the dialectical versions of the Arabic language to English. Given the scarcity of gold-standard parallel data for DA-EN in the UGT domain, we introduce a semi-supervised approach that exploits both monolingual and parallel data for training an NMT system initialised by a cross-lingual language model trained with supervised and unsupervised modeling objectives. We assess the accuracy of sentiment translation by our proposed system through a numerical ‘sentiment-closeness' measure as well as human evaluation. We will show that our semi-supervised MT system can significantly help with correcting sentiment errors detected in the online translation of dialectical Arabic UGT",
    "checked": true,
    "id": "faadbb6c492722eb07bcd02fe584c3d9816671f7",
    "semantic_title": "a semi-supervised approach for a better translation of sentiment in dialectical arabic ugt",
    "citation_count": 2,
    "authors": [
      "Hadeel Saadany",
      "Constantin Orăsan",
      "Emad Mohamed",
      "Ashraf Tantawy"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.21": {
    "title": "Cross-lingual transfer for low-resource Arabic language understanding",
    "volume": "workshop",
    "abstract": "This paper explores cross-lingual transfer learning in natural language understanding (NLU), with the focus on bootstrapping Arabic from high-resource English and French languages for domain classification, intent classification, and named entity recognition tasks. We adopt a BERT-based architecture and pretrain three models using open-source Wikipedia data and large-scale commercial datasets: monolingual:Arabic, bilingual:Arabic-English, and trilingual:Arabic-English-French models. Additionally, we use off-the-shelf machine translator to translate internal data from source English language to the target Arabic language, in an effort to enhance transfer learning through translation. We conduct experiments that finetune the three models for NLU tasks and evaluate them on a large internal dataset. Despite the morphological, orthographical, and grammatical differences between Arabic and the source languages, transfer learning performance gains from source languages and through machine translation are achieved on a real-world Arabic test dataset in both a zero-shot setting and in a setting when the models are further finetuned on labeled data from the target language",
    "checked": true,
    "id": "60133690c344850b278f05a0060ff37de6c68600",
    "semantic_title": "cross-lingual transfer for low-resource arabic language understanding",
    "citation_count": 2,
    "authors": [
      "Khadige Abboud",
      "Olga Golovneva",
      "Christopher DiPersio"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.22": {
    "title": "Improving POS Tagging for Arabic Dialects on Out-of-Domain Texts",
    "volume": "workshop",
    "abstract": "We investigate part of speech tagging for four Arabic dialects (Gulf, Levantine, Egyptian, and Maghrebi), in an out-of-domain setting. More specifically, we look at the effectiveness of 1) upsampling the target dialect in the training data of a joint model, 2) increasing the consistency of the annotations, and 3) using word embeddings pre-trained on a large corpus of dialectal Arabic. We increase the accuracy on average by about 20 percentage points",
    "checked": true,
    "id": "2c3ce2d95089742152de4d06c00712144dc30da4",
    "semantic_title": "improving pos tagging for arabic dialects on out-of-domain texts",
    "citation_count": 0,
    "authors": [
      "Noor Abo Mokh",
      "Daniel Dakota",
      "Sandra Kübler"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.23": {
    "title": "Domain Adaptation for Arabic Crisis Response",
    "volume": "workshop",
    "abstract": "Deep learning algorithms can identify related tweets to reduce the information overload that prevents humanitarian organisations from using valuable Twitter posts. However, they rely heavily on human-labelled data, which are unavailable for emerging crises. Because each crisis has its own features, such as location, time and social media response, current models are known to suffer from generalising to unseen disaster events when pre-trained on past ones. Tweet classifiers for low-resource languages like Arabic has the additional issue of limited labelled data duplicates caused by the absence of good language resources. Thus, we propose a novel domain adaptation approach that employs distant supervision to automatically label tweets from emerging Arabic crisis events to be used to train a model along with available human-labelled data. We evaluate our work on data from seven 2018–2020 Arabic events from different crisis types (flood, explosion, virus and storm). Results show that our method outperforms self-training in identifying crisis-related tweets in real-time scenarios and can be seen as a robust Arabic tweet classifier",
    "checked": true,
    "id": "711c85db73ea4697890d1a342170e08b0e4e8fe4",
    "semantic_title": "domain adaptation for arabic crisis response",
    "citation_count": 0,
    "authors": [
      "Reem Alrashdi",
      "Simon O’Keefe"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.24": {
    "title": "Weakly and Semi-Supervised Learning for Arabic Text Classification using Monodialectal Language Models",
    "volume": "workshop",
    "abstract": "The lack of resources such as annotated datasets and tools for low-resource languages is a significant obstacle to the advancement of Natural Language Processing (NLP) applications targeting users who speak these languages. Although learning techniques such as semi-supervised and weakly supervised learning are effective in text classification cases where annotated data is limited, they are still not widely investigated in many languages due to the sparsity of data altogether, both labeled and unlabeled. In this study, we deploy both weakly, and semi-supervised learning approaches for text classification in low-resource languages and address the underlying limitations that can hinder the effectiveness of these techniques. To that end, we propose a suite of language-agnostic techniques for large-scale data collection, automatic data annotation, and language model training in scenarios where resources are scarce. Specifically, we propose a novel data collection pipeline for under-represented languages, or dialects, that is language and task agnostic and of sufficient size for training a language model capable of achieving competitive results on common NLP tasks, as our experiments show. The models will be shared with the research community",
    "checked": true,
    "id": "bfef324f5e38a43992fb90e7cd50323e6126c157",
    "semantic_title": "weakly and semi-supervised learning for arabic text classification using monodialectal language models",
    "citation_count": 1,
    "authors": [
      "Reem AlYami",
      "Rabah Al-Zaidy"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.25": {
    "title": "Event-Based Knowledge MLM for Arabic Event Detection",
    "volume": "workshop",
    "abstract": "With the fast pace of reporting around the globe from various sources, event extraction has increasingly become an important task in NLP. The use of pre-trained language models (PTMs) has become popular to provide contextual representation for downstream tasks. This work aims to pre-train language models that enhance event extraction accuracy. To this end, we propose an Event-Based Knowledge (EBK) masking approach to mask the most significant terms in the event detection task. These significant terms are based on an external knowledge source that is curated for the purpose of event detection for the Arabic language. The proposed approach improves the classification accuracy of all the 9 event types. The experimental results demonstrate the effectiveness of the proposed masking approach and encourage further exploration",
    "checked": true,
    "id": "ca811a58fa3da09be62d906b69b639661a8d6e83",
    "semantic_title": "event-based knowledge mlm for arabic event detection",
    "citation_count": 0,
    "authors": [
      "Asma Z Yamani",
      "Amjad K Alsulami",
      "Rabeah A Al-Zaidy"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.26": {
    "title": "Establishing a Baseline for Arabic Patents Classification: A Comparison of Twelve Approaches",
    "volume": "workshop",
    "abstract": "Nowadays, the number of patent applications is constantly growing and there is an economical interest on developing accurate and fast models to automate their classification task. In this paper, we introduce the first public Arabic patent dataset called ArPatent and experiment with twelve classification approaches to develop a baseline for Arabic patents classification. To achieve the goal of finding the best baseline for classifying Arabic patents, different machine learning, pre-trained language models as well as ensemble approaches were conducted. From the obtained results, we can observe that the best performing model for classifying Arabic patents was ARBERT with F1 of 66.53%, while the ensemble approach of the best three performing language models, namely: ARBERT, CAMeL-MSA, and QARiB, achieved the second best F1 score, i.e., 64.52%",
    "checked": true,
    "id": "453ac5287cc28ccf8a0306d13c48a6a256d9fac9",
    "semantic_title": "establishing a baseline for arabic patents classification: a comparison of twelve approaches",
    "citation_count": 0,
    "authors": [
      "Taif Omar Al-Omar",
      "Hend Al-Khalifa",
      "Rawan Al-Matham"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.27": {
    "title": "Towards Learning Arabic Morphophonology",
    "volume": "workshop",
    "abstract": "One core challenge facing morphological inflection systems is capturing language-specific morphophonological changes. This is particularly true of languages like Arabic which are morphologically complex. In this paper, we learn explicit morphophonological rules from morphologically annotated Egyptian Arabic and corresponding surface forms. These rules are human-interpretable, capture known morphophonological phenomena in the language, and are generalizable to unseen forms",
    "checked": true,
    "id": "ba504d3b4ab70d5b9ebbc48cdb0a65b0a5d37c69",
    "semantic_title": "towards learning arabic morphophonology",
    "citation_count": 2,
    "authors": [
      "Salam Khalifa",
      "Jordan Kodner",
      "Owen Rambow"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.28": {
    "title": "AraDepSu: Detecting Depression and Suicidal Ideation in Arabic Tweets Using Transformers",
    "volume": "workshop",
    "abstract": "Among mental health diseases, depression is one of the most severe, as it often leads to suicide which is the fourth leading cause of death in the Middle East. In the Middle East, Egypt has the highest percentage of suicidal deaths; due to this, it is important to identify depression and suicidal ideation. In Arabic culture, there is a lack of awareness regarding the importance of diagnosing and living with mental health diseases. However, as noted for the last couple years people all over the world, including Arab citizens, tend to express their feelings openly on social media. Twitter is the most popular platform designed to enable the expression of emotions through short texts, pictures, or videos. This paper aims to predict depression and depression with suicidal ideation. Due to the tendency of people to treat social media as their personal diaries and share their deepest thoughts on social media platforms. Social data contain valuable information that can be used to identify user's psychological states. We create AraDepSu dataset by scrapping tweets from twitter and manually labelling them. We expand the diversity of user tweets, by adding a neutral label (\"neutral\") so the dataset include three classes (\"depressed\", \"suicidal\", \"neutral\"). Then we train our AraDepSu dataset on 30+ different transformer models. We find that the best-performing model is MARBERT with accuracy, precision, recall and F1-Score values of 91.20%, 88.74%, 88.50% and 88.75%",
    "checked": true,
    "id": "2fc2a2a471e9eac11b64d0b61bc87008f8260de6",
    "semantic_title": "aradepsu: detecting depression and suicidal ideation in arabic tweets using transformers",
    "citation_count": 3,
    "authors": [
      "Mariam Hassib",
      "Nancy Hossam",
      "Jolie Sameh",
      "Marwan Torki"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.29": {
    "title": "End-to-End Speech Translation of Arabic to English Broadcast News",
    "volume": "workshop",
    "abstract": "Speech translation (ST) is the task of directly translating acoustic speech signals in a source language into text in a foreign language. ST task has been addressed, for a long time, using a pipeline approach with two modules : first an Automatic Speech Recognition (ASR) in the source language followed by a text-to-text Machine translation (MT). In the past few years, we have seen a paradigm shift towards the end-to-end approaches using sequence-to-sequence deep neural network models. This paper presents our efforts towards the development of the first Broadcast News end-to-end Arabic to English speech translation system. Starting from independent ASR and MT LDC releases, we were able to identify about 92 hours of Arabic audio recordings for which the manual transcription was also translated into English at the segment level. These data was used to train and compare pipeline and end-to-end speech translation systems under multiple scenarios including transfer learning and data augmentation techniques",
    "checked": true,
    "id": "d0937728739aacd251b4295046de2a3e95f02d03",
    "semantic_title": "end-to-end speech translation of arabic to english broadcast news",
    "citation_count": 0,
    "authors": [
      "Fethi Bougares",
      "Salim Jouili"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.30": {
    "title": "Arabic Keyphrase Extraction: Enhancing Deep Learning Models with Pre-trained Contextual Embedding and External Features",
    "volume": "workshop",
    "abstract": "Keyphrase extraction is essential to many Information retrieval (IR) and Natural language Processing (NLP) tasks such as summarization and indexing. This study investigates deep learning approaches to Arabic keyphrase extraction. We address the problem as sequence classification and create a Bi-LSTM model to classify each sequence token as either part of the keyphrase or outside of it. We have extracted word embeddings from two pre-trained models, Word2Vec and BERT. Moreover, we have investigated the effect of incorporating linguistic, positional, and statistical features with word embeddings on performance. Our best-performing model has achieved 0.45 F1-score on ArabicKPE dataset when combining linguistic and positional features with BERT embedding",
    "checked": true,
    "id": "ba64a37bbdb3ec3b35f18644e05f8e3908cdc011",
    "semantic_title": "arabic keyphrase extraction: enhancing deep learning models with pre-trained contextual embedding and external features",
    "citation_count": 0,
    "authors": [
      "Randah Alharbi",
      "Husni Al-Muhtasab"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.31": {
    "title": "ArabIE: Joint Entity, Relation and Event Extraction for Arabic",
    "volume": "workshop",
    "abstract": "Previous work on Arabic information extraction has mainly focused on named entity recognition and very little work has been done on Arabic relation extraction and event recognition. Moreover, modeling Arabic data for such tasks is not straightforward because of the morphological richness and idiosyncrasies of the Arabic language. We propose in this article the first neural joint information extraction system for the Arabic language",
    "checked": true,
    "id": "a390013f42d93a38ab2b17ab2a5851be710584c0",
    "semantic_title": "arabie: joint entity, relation and event extraction for arabic",
    "citation_count": 4,
    "authors": [
      "Niama El Khbir",
      "Nadi Tomeh",
      "Thierry Charnois"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.32": {
    "title": "Emoji Sentiment Roles for Sentiment Analysis: A Case Study in Arabic Texts",
    "volume": "workshop",
    "abstract": "Emoji (digital pictograms) are crucial features for textual sentiment analysis. However, analysing the sentiment roles of emoji is very complex. This is due to its dependency on different factors, such as textual context, cultural perspective, interlocutor's personal traits, interlocutors' relationships or a platforms' functional features. This work introduces an approach to analysing the sentiment effects of emoji as textual features. Using an Arabic dataset as a benchmark, our results confirm the borrowed argument that each emoji has three different norms of sentiment role (negative, neutral or positive). Therefore, an emoji can play different sentiment roles depending upon the context. It can behave as an emphasizer, an indicator, a mitigator, a reverser or a trigger of either negative or positive sentiment within a text. In addition, an emoji may have a neutral effect (i.e., no effect) on the sentiment of the text",
    "checked": true,
    "id": "9db7c73afcbeb249729b080a605d6045714b421d",
    "semantic_title": "emoji sentiment roles for sentiment analysis: a case study in arabic texts",
    "citation_count": 4,
    "authors": [
      "Shatha Ali A. Hakami",
      "Robert Hendley",
      "Phillip Smith"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.33": {
    "title": "Gulf Arabic Diacritization: Guidelines, Initial Dataset, and Results",
    "volume": "workshop",
    "abstract": "Arabic diacritic recovery is important for a variety of downstream tasks such as text-to-speech. In this paper, we introduce a new Gulf Arabic diacritization dataset composed of 19,850 words based on a subset of the Gumar corpus. We provide comprehensive set of guidelines for diacritization to enable the diacritization of more data. We also report on diacritization results based on the new corpus using a Hidden Markov Model and character-based sequence to sequence models",
    "checked": true,
    "id": "d7590c134eb2fc4fc7555d2a46331924c8d94cd0",
    "semantic_title": "gulf arabic diacritization: guidelines, initial dataset, and results",
    "citation_count": 1,
    "authors": [
      "Nouf Alabbasi",
      "Mohamed Al-Badrashiny",
      "Maryam Aldahmani",
      "Ahmed AlDhanhani",
      "Abdullah Saleh Alhashmi",
      "Fawaghy Ahmed Alhashmi",
      "Khalid Al Hashemi",
      "Rama Emad Alkhobbi",
      "Shamma T Al Maazmi",
      "Mohammed Ali Alyafeai",
      "Mariam M Alzaabi",
      "Mohamed Saqer Alzaabi",
      "Fatma Khalid Badri",
      "Kareem Darwish",
      "Ehab Mansour Diab",
      "Muhammad Morsy Elmallah",
      "Amira Ayman Elnashar",
      "Ashraf Hatim Elneima",
      "MHD Tameem Kabbani",
      "Nour Rabih",
      "Ahmad Saad",
      "Ammar Mamoun Sousou"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.34": {
    "title": "Learning From Arabic Corpora But Not Always From Arabic Speakers: A Case Study of the Arabic Wikipedia Editions",
    "volume": "workshop",
    "abstract": "Wikipedia is a common source of training data for Natural Language Processing (NLP) research, especially as a source for corpora in languages other than English. However, for many downstream NLP tasks, it is important to understand the degree to which these corpora reflect representative contributions of native speakers. In particular, many entries in a given language may be translated from other languages or produced through other automated mechanisms. Language models built using corpora like Wikipedia can embed history, culture, bias, stereotypes, politics, and more, but it is important to understand whose views are actually being represented. In this paper, we present a case study focusing specifically on differences among the Arabic Wikipedia editions (Modern Standard Arabic, Egyptian, and Moroccan). In particular, we document issues in the Egyptian Arabic Wikipedia with automatic creation/generation and translation of content pages from English without human supervision. These issues could substantially affect the performance and accuracy of Large Language Models (LLMs) trained from these corpora, producing models that lack the cultural richness and meaningful representation of native speakers. Fortunately, the metadata maintained by Wikipedia provides visibility into these issues, but unfortunately, this is not the case for all corpora used to train LLMs",
    "checked": true,
    "id": "f25ebbecbdad6dd285f89a0b9a8149e39a944365",
    "semantic_title": "learning from arabic corpora but not always from arabic speakers: a case study of the arabic wikipedia editions",
    "citation_count": 4,
    "authors": [
      "Saied Alshahrani",
      "Esma Wali",
      "Jeanna Matthews"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.35": {
    "title": "A Pilot Study on the Collection and Computational Analysis of Linguistic Differences Amongst Men and Women in a Kuwaiti Arabic WhatsApp Dataset",
    "volume": "workshop",
    "abstract": "This study focuses on the collection and computational analysis of Kuwaiti Arabic (KA), which is considered a low resource dialect, to test different sociolinguistic hypotheses related to gendered language use. In this paper, we describe the collection and analysis of a corpus of WhatsApp Group chats with mixed gender Kuwaiti participants. This corpus, which we are making publicly available, is the first corpus of KA conversational data. We analyse different interactional and linguistic features to get insights about features that may be indicative of gender to inform the development of a gender classification system for KA in an upcoming study. Statistical analysis of our data shows that there is insufficient evidence to claim that there are significant differences amongst men and women with respect to number of turns, length of turns and number of emojis. However, qualitative analysis shows that men and women differ substantially in the types of emojis they use and in their use of lengthened words",
    "checked": true,
    "id": "740496c080a8a85f8c00d01949ea02c438fb604d",
    "semantic_title": "a pilot study on the collection and computational analysis of linguistic differences amongst men and women in a kuwaiti arabic whatsapp dataset",
    "citation_count": 2,
    "authors": [
      "Hesah Aldihan",
      "Robert Gaizauskas",
      "Susan Fitzmaurice"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.36": {
    "title": "Beyond Arabic: Software for Perso-Arabic Script Manipulation",
    "volume": "workshop",
    "abstract": "This paper presents an open-source software library that provides a set of finite-state transducer (FST) components and corresponding utilities for manipulating the writing systems of languages that use the Perso-Arabic script. The operations include various levels of script normalization, including visual invariance-preserving operations that subsume and go beyond the standard Unicode normalization forms, as well as transformations that modify the visual appearance of characters in accordance with the regional orthographies for eleven contemporary languages from diverse language families. The library also provides simple FST-based romanization and transliteration. We additionally attempt to formalize the typology of Perso-Arabic characters by providing one-to-many mappings from Unicode code points to the languages that use them. While our work focuses on the Arabic script diaspora rather than Arabic itself, this approach could be adopted for any language that uses the Arabic script, thus providing a unified framework for treating a script family used by close to a billion people",
    "checked": true,
    "id": "ad7ed2a58549eb074d97cb414ac56ed5fa32a57f",
    "semantic_title": "beyond arabic: software for perso-arabic script manipulation",
    "citation_count": 3,
    "authors": [
      "Alexander Gutkin",
      "Cibu Johny",
      "Raiomond Doctor",
      "Brian Roark",
      "Richard Sproat"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.37": {
    "title": "Coreference Annotation of an Arabic Corpus using a Virtual World Game",
    "volume": "workshop",
    "abstract": "Coreference resolution is a key aspect of text comprehension, but the size of the available coreference corpora for Arabic is limited in comparison to the size of the corpora for other languages. In this paper we present a Game-With-A-Purpose called Stroll with a Scroll created to collect from players coreference annotations for Arabic. The key contribution of this work is the embedding of the annotation task in a virtual world setting, as opposed to the puzzle-type games used in previously proposed Games-With-A-Purpose for coreference",
    "checked": true,
    "id": "19ae67cf81a856f0a766a7b4be81030da8e73971",
    "semantic_title": "coreference annotation of an arabic corpus using a virtual world game",
    "citation_count": 0,
    "authors": [
      "Wateen Abdullah Aliady",
      "Abdulrahman Aloraini",
      "Christopher Madge",
      "Juntao Yu",
      "Richard Bartle",
      "Massimo Poesio"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.38": {
    "title": "NatiQ: An End-to-end Text-to-Speech System for Arabic",
    "volume": "workshop",
    "abstract": "NatiQ is end-to-end text-to-speech system for Arabic. Our speech synthesizer uses an encoder-decoder architecture with attention. We used both tacotron-based models (tacotron- 1 and tacotron-2) and the faster transformer model for generating mel-spectrograms from characters. We concatenated Tacotron1 with the WaveRNN vocoder, Tacotron2 with the WaveGlow vocoder and ESPnet transformer with the parallel wavegan vocoder to synthesize waveforms from the spectrograms. We used in-house speech data for two voices: 1) neu- tral male \"Hamza\"- narrating general content and news, and 2) expressive female \"Amina\"- narrating children story books to train our models. Our best systems achieve an aver- age Mean Opinion Score (MOS) of 4.21 and 4.40 for Amina and Hamza respectively. The objective evaluation of the systems using word and character error rate (WER and CER) as well as the response time measured by real- time factor favored the end-to-end architecture ESPnet. NatiQ demo is available online at https://tts.qcri.org",
    "checked": true,
    "id": "ef15bdd870e9a9107c1fa2c542272da50829de83",
    "semantic_title": "natiq: an end-to-end text-to-speech system for arabic",
    "citation_count": 8,
    "authors": [
      "Ahmed Abdelali",
      "Nadir Durrani",
      "Cenk Demiroglu",
      "Fahim Dalvi",
      "Hamdy Mubarak",
      "Kareem Darwish"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.39": {
    "title": "The Effect of Arabic Dialect Familiarity on Data Annotation",
    "volume": "workshop",
    "abstract": "Data annotation is the foundation of most natural language processing (NLP) tasks. However, data annotation is complex and there is often no specific correct label, especially in subjective tasks. Data annotation is affected by the annotators' ability to understand the provided data. In the case of Arabic, this is important due to the large dialectal variety. In this paper, we analyse how Arabic speakers understand other dialects in written text. Also, we analyse the effect of dialect familiarity on the quality of data annotation, focusing on Arabic sarcasm detection. This is done by collecting third-party labels and comparing them to high-quality first-party labels. Our analysis shows that annotators tend to better identify their own dialect and they are prone to confuse dialects they are unfamiliar with. For task labels, annotators tend to perform better on their dialect or dialects they are familiar with. Finally, females tend to perform better than males on the sarcasm detection task. We suggest that to guarantee high-quality labels, researchers should recruit native dialect speakers for annotation",
    "checked": true,
    "id": "7b028acc98ee95a3f1406592197d5f01f9b05c5f",
    "semantic_title": "the effect of arabic dialect familiarity on data annotation",
    "citation_count": 8,
    "authors": [
      "Ibrahim Abu Farha",
      "Walid Magdy"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.40": {
    "title": "Optimizing Naive Bayes for Arabic Dialect Identification",
    "volume": "workshop",
    "abstract": "This article describes the language identification system used by the SUKI team in the 2022 Nuanced Arabic Dialect Identification (NADI) shared task. In addition to the system description, we give some details of the dialect identification experiments we conducted while preparing our submissions. In the end, we submitted only one official run. We used a Naive Bayes-based language identifier with character n-grams from one to four, of which we implemented a new version, which automatically optimizes its parameters. We also experimented with clustering the training data according to different topics. With the macro F1 score of 0.1963 on test set A and 0.1058 on test set B, we achieved the 18th position out of the 19 competing teams",
    "checked": true,
    "id": "e3a68a69b09bcfde4692d67b53b86b289ecada38",
    "semantic_title": "optimizing naive bayes for arabic dialect identification",
    "citation_count": 4,
    "authors": [
      "Tommi Jauhiainen",
      "Heidi Jauhiainen",
      "Krister Lindén"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.41": {
    "title": "iCompass Working Notes for the Nuanced Arabic Dialect Identification Shared task",
    "volume": "workshop",
    "abstract": "We describe our submitted system to the Nuanced Arabic Dialect Identification (NADI) shared task. We tackled only the first subtask (Subtask 1). We used state-of-the-art Deep Learning models and pre-trained contextualized text representation models that we finetuned according to the downstream task in hand. As a first approach, we used BERT Arabic variants: MARBERT with its two versions MARBERT v1 and MARBERT v2, we combined MARBERT embeddings with a CNN classifier, and finally, we tested the Quasi-Recurrent Neural Networks (QRNN) model. The results found show that version 2 of MARBERT outperforms all of the previously mentioned models on Subtask 1",
    "checked": true,
    "id": "2b95434dd736ec2cd94764c10321e56a2b8548b1",
    "semantic_title": "icompass working notes for the nuanced arabic dialect identification shared task",
    "citation_count": 4,
    "authors": [
      "Abir Messaoudi",
      "Chayma Fourati",
      "Hatem Haddad",
      "Moez BenHajhmida"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.42": {
    "title": "TF-IDF or Transformers for Arabic Dialect Identification? ITFLOWS participation in the NADI 2022 Shared Task",
    "volume": "workshop",
    "abstract": "This study targets the shared task of Nuanced Arabic Dialect Identification (NADI) organized with the Workshop on Arabic Natural Language Processing (WANLP). It further focuses on Subtask 1 on the identification of the Arabic dialects at the country level. More specifically, it studies the impact of a traditional approach such as TF-IDF and then moves on to study the impact of advanced deep learning based methods. These methods include fully fine-tuning MARBERT as well as adapter based fine-tuning of MARBERT with and without performing data augmentation. The evaluation shows that the traditional approach based on TF-IDF scores the best in terms of accuracy on TEST-A dataset, while, the fine-tuned MARBERT with adapter on augmented data scores the second on Macro F1-score on the TEST-B dataset. This led to the proposed system being ranked second on the shared task on average",
    "checked": true,
    "id": "460d205d8719f85ccd8c09d7c30c16abaa8d1621",
    "semantic_title": "tf-idf or transformers for arabic dialect identification? itflows participation in the nadi 2022 shared task",
    "citation_count": 3,
    "authors": [
      "Fouad Shammary",
      "Yiyi Chen",
      "Zsolt T Kardkovacs",
      "Mehwish Alam",
      "Haithem Afli"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.43": {
    "title": "Domain-Adapted BERT-based Models for Nuanced Arabic Dialect Identification and Tweet Sentiment Analysis",
    "volume": "workshop",
    "abstract": "This paper summarizes the solution of the Nuanced Arabic Dialect Identification (NADI) 2022 shared task. It consists of two subtasks: a country-level Arabic Dialect Identification (ADID) and an Arabic Sentiment Analysis (ASA). Our work shows the importance of using domain-adapted models and language-specific pre-processing in NLP task solutions. We implement a simple but strong baseline technique to increase the stability of fine-tuning settings to obtain a good generalization of models. Our best model for the Dialect Identification subtask achieves a Macro F-1 score of 25.54% as an average of both Test-A (33.89%) and Test-B (19.19%) F-1 scores. We also obtained a Macro F-1 score of 74.29% of positive and negative sentiments only, in the Sentiment Analysis task",
    "checked": true,
    "id": "80e1ecf54dbdb88b8ee81491db0b4f95a114ba95",
    "semantic_title": "domain-adapted bert-based models for nuanced arabic dialect identification and tweet sentiment analysis",
    "citation_count": 5,
    "authors": [
      "Giyaseddin Bayrak",
      "Abdul Majeed Issifu"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.44": {
    "title": "Benchmarking transfer learning approaches for sentiment analysis of Arabic dialect",
    "volume": "workshop",
    "abstract": "Arabic has a widely varying collection of dialects. With the explosion of the use of social networks, the volume of written texts has remarkably increased. Most users express themselves using their own dialect. Unfortunately, many of these dialects remain under-studied due to the scarcity of resources. Researchers and industry practitioners are increasingly interested in analyzing users' sentiments. In this context, several approaches have been proposed, namely: traditional machine learning, deep learning transfer learning and more recently few-shot learning approaches. In this work, we compare their efficiency as part of the NADI competition to develop a country-level sentiment analysis model. Three models were beneficial for this sub-task: The first based on Sentence Transformer (ST) and achieve 43.23% on DEV set and 42.33% on TEST set, the second based on CAMeLBERT and achieve 47.85% on DEV set and 41.72% on TEST set and the third based on multi-dialect BERT model and achieve 66.72% on DEV set and 39.69% on TEST set",
    "checked": true,
    "id": "206f0768175ff3031aabf2db07d441144468cd07",
    "semantic_title": "benchmarking transfer learning approaches for sentiment analysis of arabic dialect",
    "citation_count": 4,
    "authors": [
      "Emna Fsih",
      "Sameh Kchaou",
      "Rahma Boujelbane",
      "Lamia Hadrich-Belguith"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.45": {
    "title": "SQU-CS @ NADI 2022: Dialectal Arabic Identification using One-vs-One Classification with TF-IDF Weights Computed on Character n-grams",
    "volume": "workshop",
    "abstract": "In this paper, I present an approach using one-vs-one classification scheme with TF-IDF term weighting on character n-grams for identifying Arabic dialects used in social media. The scheme was evaluated in the context of the third Nuanced Arabic Dialect Identification (NADI 2022) shared task for identifying Arabic dialects used in Twitter messages. The approach was implemented with logistic regression loss and trained using stochastic gradient decent (SGD) algorithm. This simple method achieved a macro F1 score of 22.89% and 10.83% on TEST A and TEST B, respectively, in comparison to an approach based on AraBERT pretrained transformer model which achieved a macro F1 score of 30.01% and 14.84%, respectively. My submission based on AraBERT scored a macro F1 average of 22.42% and was ranked 10 out of the 19 teams who participated in the task",
    "checked": true,
    "id": "5bd578b737d5ee9d10c4ad8500881d98606a6462",
    "semantic_title": "squ-cs @ nadi 2022: dialectal arabic identification using one-vs-one classification with tf-idf weights computed on character n-grams",
    "citation_count": 1,
    "authors": [
      "Abdulrahman Khalifa AAlAbdulsalam"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.46": {
    "title": "Ahmed and Khalil at NADI 2022: Transfer Learning and Addressing Class Imbalance for Arabic Dialect Identification and Sentiment Analysis",
    "volume": "workshop",
    "abstract": "In this paper, we present our findings in the two subtasks of the 2022 NADI shared task. First, in the Arabic dialect identification subtask, we find that there is heavy class imbalance, and propose to address this issue using focal loss. Our experiments with the focusing hyperparameter confirm that focal loss improves performance. Second, in the Arabic tweet sentiment analysis subtask, we deal with a smaller dataset, where text includes both Arabic dialects and Modern Standard Arabic. We propose to use transfer learning from both pre-trained MSA language models and our own model from the first subtask. Our system ranks in the 5th and 7th best spots of the leaderboards of first and second subtasks respectively",
    "checked": true,
    "id": "16156f70b544c1427f56e34042af2916674e200e",
    "semantic_title": "ahmed and khalil at nadi 2022: transfer learning and addressing class imbalance for arabic dialect identification and sentiment analysis",
    "citation_count": 1,
    "authors": [
      "Ahmed Oumar",
      "Khalil Mrini"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.47": {
    "title": "Arabic Sentiment Analysis by Pretrained Ensemble",
    "volume": "workshop",
    "abstract": "This paper presents the 259 team's BERT ensemble designed for the NADI 2022 Subtask 2 (sentiment analysis) (Abdul-Mageed et al., 2022). Twitter Sentiment analysis is one of the language processing (NLP) tasks that provides a method to understand the perception and emotions of the public around specific topics. The most common research approach focuses on obtaining the tweet's sentiment by analyzing its lexical and syntactic features. We used multiple pretrained Arabic-Bert models with a simple average ensembling and then chose the best-performing ensemble on the training dataset and ran it on the development dataset. This system ranked 3rd in Subtask 2 with a Macro-PN-F1-score of 72.49%",
    "checked": true,
    "id": "66372ef79072f87fd118456232d6003f5049982b",
    "semantic_title": "arabic sentiment analysis by pretrained ensemble",
    "citation_count": 0,
    "authors": [
      "Abdelrahim Qaddoumi"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.48": {
    "title": "Dialect & Sentiment Identification in Nuanced Arabic Tweets Using an Ensemble of Prompt-based, Fine-tuned, and Multitask BERT-Based Models",
    "volume": "workshop",
    "abstract": "Dialect Identification is important to improve the performance of various application as translation, speech recognition, etc. In this paper, we present our findings and results in the Nuanced Arabic Dialect Identification Shared Task (NADI 2022) for country-level dialect identification and sentiment identification for dialectical Arabic. The proposed model is an ensemble between fine-tuned BERT-based models and various approaches of prompt-tuning. Our model secured first place on the leaderboard for subtask 1 with an 27.06 F1-macro score, and subtask 2 secured first place with 75.15 F1-PN score. Our findings show that prompt-tuning-based models achieved better performance when compared to fine-tuning and Multi-task based methods. Moreover, using an ensemble of different loss functions might improve model performance",
    "checked": true,
    "id": "1c4a3505d9b189fc07fa16661a0cd8942f1e6c8d",
    "semantic_title": "dialect & sentiment identification in nuanced arabic tweets using an ensemble of prompt-based, fine-tuned, and multitask bert-based models",
    "citation_count": 7,
    "authors": [
      "Reem Abdel-Salam"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.49": {
    "title": "On The Arabic Dialects' Identification: Overcoming Challenges of Geographical Similarities Between Arabic dialects and Imbalanced Datasets",
    "volume": "workshop",
    "abstract": "Arabic is one of the world's richest languages, with a diverse range of dialects based on geographical origin. In this paper, we present a solution to tackle subtask 1 (Country-level dialect identification) of the Nuanced Arabic Dialect Identification (NADI) shared task 2022 achieving third place with an average macro F1 score between the two test sets of 26.44%. In the preprocessing stage, we removed the most common frequent terms from all sentences across all dialects, and in the modeling step, we employed a hybrid loss function approach that includes Weighted cross entropy loss and Vector Scaling(VS) Loss. On test sets A and B, our model achieved 35.68% and 17.192% Macro F1 scores, respectively",
    "checked": true,
    "id": "645661792af4b64b68191773f3834f27f94a4fb9",
    "semantic_title": "on the arabic dialects' identification: overcoming challenges of geographical similarities between arabic dialects and imbalanced datasets",
    "citation_count": 0,
    "authors": [
      "Salma Jamal",
      "Aly M .Kassem",
      "Omar Mohamed",
      "Ali Ashraf"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.50": {
    "title": "Arabic dialect identification using machine learning and transformer-based models: Submission to the NADI 2022 Shared Task",
    "volume": "workshop",
    "abstract": "Arabic has a wide range of dialects. Dialect is the language variation of a specific community. In this paper, we show the models we created to participate in the third Nuanced Arabic Dialect Identification (NADI) shared task (Subtask 1) that involves developing a system to classify a tweet into a country-level dialect. We utilized a number of machine learning techniques as well as deep learning transformer-based models. For the machine learning approach, we build an ensemble classifier of various machine learning models. In our deep learning approach, we consider bidirectional LSTM model and AraBERT pretrained model. The results demonstrate that the deep learning approach performs noticeably better than the other machine learning approaches with 68.7% accuracy on the development set",
    "checked": true,
    "id": "d458d540435adf8c7ce31825e5ededb5ec1a2783",
    "semantic_title": "arabic dialect identification using machine learning and transformer-based models: submission to the nadi 2022 shared task",
    "citation_count": 4,
    "authors": [
      "Nouf AlShenaifi",
      "Aqil Azmi"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.51": {
    "title": "NLP DI at NADI Shared Task Subtask-1: Sub-word Level Convolutional Neural Models and Pre-trained Binary Classifiers for Dialect Identification",
    "volume": "workshop",
    "abstract": "In this paper, we describe our systems submitted to the NADI Subtask 1: country-wise dialect classifications. We designed two types of solutions. The first type is convolutional neural network CNN) classifiers trained on subword segments of optimized lengths. The second type is fine-tuned classifiers with BERT-based language specific pre-trained models. To deal with the missing dialects in one of the test sets, we experimented with binary classifiers, analyzing the predicted probability distribution patterns and comparing them with the development set patterns. The better performing approach on the development set was fine-tuning language specific pre-trained model (best F-score 26.59%). On the test set, on the other hand, we obtained the best performance with the CNN model trained on subword tokens obtained with a Unigram model (the best F-score 26.12%). Re-training models on samples of training data simulating missing dialects gave the maximum performance on the test set version with a number of dialects lesser than the training set (F-score 16.44%)",
    "checked": true,
    "id": "7c502fa0250bc5f899e850350cd712934b5f2e0d",
    "semantic_title": "nlp di at nadi shared task subtask-1: sub-word level convolutional neural models and pre-trained binary classifiers for dialect identification",
    "citation_count": 1,
    "authors": [
      "Vani Kanjirangat",
      "Tanja Samardzic",
      "Ljiljana Dolamic",
      "Fabio Rinaldi"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.52": {
    "title": "Word Representation Models for Arabic Dialect Identification",
    "volume": "workshop",
    "abstract": "This paper describes the systems submitted by BFCAI team to Nuanced Arabic Dialect Identification (NADI) shared task 2022. Dialect identification task aims at detecting the source variant of a given text or speech segment automatically. There are two subtasks in NADI 2022, the first subtask for country-level identification and the second subtask for sentiment analysis. Our team participated in the first subtask. The proposed systems use Term Frequency Inverse/Document Frequency and word embeddings as vectorization models. Different machine learning algorithms have been used as classifiers. The proposed systems have been tested on two test sets: Test-A and Test-B. The proposed models achieved Macro-f1 score of 21.25% and 9.71% for Test-A and Test-B set respectively. On other hand, the best-performed submitted system achieved Macro-f1 score of 36.48% and 18.95% for Test-A and Test-B set respectively",
    "checked": true,
    "id": "0a4526368df575b88e908b00cf4f483cff382a75",
    "semantic_title": "word representation models for arabic dialect identification",
    "citation_count": 2,
    "authors": [
      "Mahmoud Sobhy",
      "Ahmed H. Abu El-Atta",
      "Ahmed A. El-Sawy",
      "Hamada Nayel"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.53": {
    "title": "Building an Ensemble of Transformer Models for Arabic Dialect Classification and Sentiment Analysis",
    "volume": "workshop",
    "abstract": "In this paper, we describe the approaches we developed for the Nuanced Arabic Dialect Identification (NADI) 2022 shared task, which consists of two subtasks: the identification of country-level Arabic dialects and sentiment analysis. Our team, UniManc, developed approaches to the two subtasks which are underpinned by the same model: a pre-trained MARBERT language model. For Subtask 1, we applied undersampling to create versions of the training data with a balanced distribution across classes. For Subtask 2, we further trained the original MARBERT model for the masked language modelling objective using a NADI-provided dataset of unlabelled Arabic tweets. For each of the subtasks, a MARBERT model was fine-tuned for sequence classification, using different values for hyperparameters such as seed and learning rate. This resulted in multiple model variants, which formed the basis of an ensemble model for each subtask. Based on the official NADI evaluation, our ensemble model obtained a macro-F1-score of 26.863, ranking second overall in the first subtask. In the second subtask, our ensemble model also ranked second, obtaining a macro-F1-PN score (macro-averaged F1-score over the Positive and Negative classes) of 73.544",
    "checked": true,
    "id": "b5e46a2374e26b4f1b89c9590410fe1899514c3b",
    "semantic_title": "building an ensemble of transformer models for arabic dialect classification and sentiment analysis",
    "citation_count": 5,
    "authors": [
      "Abdullah Salem Khered",
      "Ingy Yasser Hassan Abdou Abdelhalim",
      "Riza Batista-Navarro"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.54": {
    "title": "Arabic Dialect Identification and Sentiment Classification using Transformer-based Models",
    "volume": "workshop",
    "abstract": "In this paper, we present two deep learning approaches that are based on AraBERT, submitted to the Nuanced Arabic Dialect Identification (NADI) shared task of the Seventh Workshop for Arabic Natural Language Processing (WANLP 2022). NADI consists of two main sub-tasks, mainly country-level dialect and sentiment identification for dialectical Arabic. We present one system per sub-task. The first system is a multi-task learning model that consists of a shared AraBERT encoder with three task-specific classification layers. This model is trained to jointly learn the country-level dialect of the tweet as well as the region-level and area-level dialects. The second system is a distilled model of an ensemble of models trained using K-fold cross-validation. Each model in the ensemble consists of an AraBERT model and a classifier, fine-tuned on (K-1) folds of the training set. Our team Pythoneers achieved rank 6 on the first test set of the first sub-task, rank 9 on the second test set of the first sub-task, and rank 4 on the test set of the second sub-task",
    "checked": true,
    "id": "653185f6f8a707df079822369462372cf98a9a0c",
    "semantic_title": "arabic dialect identification and sentiment classification using transformer-based models",
    "citation_count": 3,
    "authors": [
      "Joseph Attieh",
      "Fadi Hassan"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.55": {
    "title": "Generative Approach for Gender-Rewriting Task with ArabicT5",
    "volume": "workshop",
    "abstract": "Addressing the correct gender in generative tasks (e.g., Machine Translation) has been an overlooked issue in the Arabic NLP. However, the recent introduction of the Arabic Parallel Gender Corpus (APGC) dataset has established new baselines for the Arabic Gender Rewriting task. To address the Gender Rewriting task, we first pre-train our new Seq2Seq ArabicT5 model on a 17GB of Arabic Corpora. Then, we continue pre-training our ArabicT5 model on the APGC dataset using a newly proposed method. Our evaluation shows that our ArabicT5 model, when trained on the APGC dataset, achieved competitive results against existing state-of-the-art methods. In addition, our ArabicT5 model shows better results on the APGC dataset compared to other Arabic and multilingual T5 models",
    "checked": true,
    "id": "694097e75f746b7405894837b5d17b9d19019596",
    "semantic_title": "generative approach for gender-rewriting task with arabict5",
    "citation_count": 2,
    "authors": [
      "Sultan Alrowili",
      "Vijay Shanker"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.56": {
    "title": "AraProp at WANLP 2022 Shared Task: Leveraging Pre-Trained Language Models for Arabic Propaganda Detection",
    "volume": "workshop",
    "abstract": "This paper presents the approach taken for the shared task on Propaganda Detection in Arabic at the Seventh Arabic Natural Language Processing Workshop (WANLP 2022). We participated in Sub-task 1 where the text of a tweet is provided, and the goal is to identify the different propaganda techniques used in it. This problem belongs to multi-label classification. For our solution, we approached leveraging different transformer based pre-trained language models with fine-tuning to solve this problem. We found that MARBERTv2 outperforms in terms of performance where F1-macro is 0.08175 and F1-micro is 0.61116 compared to other language models that we considered. Our method achieved rank 4 in the testing phase of the challenge",
    "checked": true,
    "id": "1ddd5102bd2e8074a0ccf12ea46180cce7cbd6ec",
    "semantic_title": "araprop at wanlp 2022 shared task: leveraging pre-trained language models for arabic propaganda detection",
    "citation_count": 2,
    "authors": [
      "Gaurav Singh"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.57": {
    "title": "TUB at WANLP22 Shared Task: Using Semantic Similarity for Propaganda Detection in Arabic",
    "volume": "workshop",
    "abstract": "Propaganda and the spreading of fake news through social media have become a serious problem in recent years. In this paper we present our approach for the shared task on propaganda detection in Arabic in which the goal is to identify propaganda techniques in the Arabic social media text. We propose a semantic similarity detection model to compare text in the test set with the sentences in the train set to find the most similar instances. The label of the target text is obtained from the most similar texts in the train set. The proposed model obtained the micro F1 score of 0.494 on the text data set",
    "checked": true,
    "id": "e51e699ef9cb0a78f03a0e8c8a27c5dee344f19b",
    "semantic_title": "tub at wanlp22 shared task: using semantic similarity for propaganda detection in arabic",
    "citation_count": 3,
    "authors": [
      "Salar Mohtaj",
      "Sebastian Möller"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.58": {
    "title": "SI2M & AIOX Labs at WANLP 2022 Shared Task: Propaganda Detection in Arabic, A Data Augmentation and Name Entity Recognition Approach",
    "volume": "workshop",
    "abstract": "This paper presents SI2M & AIOX Labs work among the propaganda detection in Arabic text shared task. The objective of this challenge is to identify the propaganda techniques used in specific propaganda fragments. We use a combination of data augmentation, Name Entity Recognition, rule-based repetition detection, and ARBERT prediction to develop our system. The model we provide scored 0.585 micro F1-Score and ranked 6th out of 12 teams",
    "checked": true,
    "id": "bd2422a1c3010c178dc80bf7edbfdfa9f60dea75",
    "semantic_title": "si2m & aiox labs at wanlp 2022 shared task: propaganda detection in arabic, a data augmentation and name entity recognition approach",
    "citation_count": 1,
    "authors": [
      "Kamel Gaanoun",
      "Imade Benelallam"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.59": {
    "title": "iCompass at WANLP 2022 Shared Task: ARBERT and MARBERT for Multilabel Propaganda Classification of Arabic Tweets",
    "volume": "workshop",
    "abstract": "Arabic propaganda detection in Arabic was carried out using transformers pre-trained models ARBERT, MARBERT. They were fine-tuned for the down-stream task in hand ‘subtask 1', multilabel classification of Arabic tweets. Submitted model was MARBERT the got 0.597 micro F1 score and got the fifth rank",
    "checked": true,
    "id": "7e868ed8e3c8e2e7a7f57aef3044be8a79369aba",
    "semantic_title": "icompass at wanlp 2022 shared task: arbert and marbert for multilabel propaganda classification of arabic tweets",
    "citation_count": 4,
    "authors": [
      "Bilel - Taboubi",
      "Bechir Brahem",
      "Hatem Haddad"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.60": {
    "title": "ChavanKane at WANLP 2022 Shared Task: Large Language Models for Multi-label Propaganda Detection",
    "volume": "workshop",
    "abstract": "The spread of propaganda through the internet has increased drastically over the past years. Lately, propaganda detection has started gaining importance because of the negative impact it has on society. In this work, we describe our approach for the WANLP 2022 shared task which handles the task of propaganda detection in a multi-label setting. The task demands the model to label the given text as having one or more types of propaganda techniques. There are a total of 21 propaganda techniques to be detected. We show that an ensemble of five models performs the best on the task, scoring a micro-F1 score of 59.73%. We also conduct comprehensive ablations and propose various future directions for this work",
    "checked": true,
    "id": "5fc3c7bd875f540ad88925957571f01a85520970",
    "semantic_title": "chavankane at wanlp 2022 shared task: large language models for multi-label propaganda detection",
    "citation_count": 2,
    "authors": [
      "Tanmay Chavan",
      "Aditya Manish Kane"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.61": {
    "title": "AraBERT Model for Propaganda Detection",
    "volume": "workshop",
    "abstract": "Nowadays, the rapid dissemination of data on digital platforms has resulted in the emergence of information pollution and data contamination, specifically mis-information, mal-information, dis-information, fake news, and various types of propaganda. These topics are now posing a serious threat to the online digital realm, posing numerous challenges to social media platforms and governments around the world. In this article, we propose a propaganda detection model based on the transformer-based model AraBERT, with the objective of using this framework to detect propagandistic content in the Arabic social media text scene, well with purpose of making online Arabic news and media consumption healthier and safer. Given the dataset, our results are relatively encouraging, indicating a huge potential for this line of approaches in Arabic online news text NLP",
    "checked": true,
    "id": "bbd56817ab170d82b801723b54f818e2ab01f154",
    "semantic_title": "arabert model for propaganda detection",
    "citation_count": 0,
    "authors": [
      "Mohamad Sharara",
      "Wissam Mohamad",
      "Ralph Tawil",
      "Ralph Chobok",
      "Wolf Assi",
      "Antonio Tannoury"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.62": {
    "title": "AraBEM at WANLP 2022 Shared Task: Propaganda Detection in Arabic Tweets",
    "volume": "workshop",
    "abstract": "Propaganda is information or ideas that an organized group or government spreads to influence peopleś opinions, especially by not giving all the facts or secretly emphasizing only one way of looking at the points. The ability to automatically detect propaganda-related linguistic signs is a challenging task that researchers in the NLP community have recently started to address. This paper presents the participation of our team AraBEM in the propaganda detection shared task on Arabic tweets. Our system utilized a pre-trained BERT model to perform multi-class binary classification. It attained the best score at 0.602 micro-f1, ranking third on subtask-1, which identifies the propaganda techniques as a multilabel classification problem with a baseline of 0.079",
    "checked": true,
    "id": "4ccd3171b6ed6ba8f4fe707f8b0a4b9cfa4f5818",
    "semantic_title": "arabem at wanlp 2022 shared task: propaganda detection in arabic tweets",
    "citation_count": 2,
    "authors": [
      "Eshrag Ali Refaee",
      "Basem Ahmed",
      "Motaz Saad"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.63": {
    "title": "IITD at WANLP 2022 Shared Task: Multilingual Multi-Granularity Network for Propaganda Detection",
    "volume": "workshop",
    "abstract": "We present our system for the two subtasks of the shared task on propaganda detection in Arabic, part of WANLP'2022. Subtask 1 is a multi-label classification problem to find the propaganda techniques used in a given tweet. Our system for this task uses XLM-R to predict probabilities for the target tweet to use each of the techniques. In addition to finding the techniques, subtask 2 further asks to identify the textual span for each instance of each technique that is present in the tweet; the task can be modelled as a sequence tagging problem. We use a multi-granularity network with mBERT encoder for subtask 2. Overall, our system ranks second for both subtasks (out of 14 and 3 participants, respectively). Our experimental results and analysis show that it does not help to use a much larger English corpus annotated with propaganda techniques, regardless of whether used in English or after translation to Arabic",
    "checked": true,
    "id": "ec04d59ea63c2262b40ef81affc2d07bbc334b31",
    "semantic_title": "iitd at wanlp 2022 shared task: multilingual multi-granularity network for propaganda detection",
    "citation_count": 3,
    "authors": [
      "Shubham Mittal",
      "Preslav Nakov"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.64": {
    "title": "Pythoneers at WANLP 2022 Shared Task: Monolingual AraBERT for Arabic Propaganda Detection and Span Extraction",
    "volume": "workshop",
    "abstract": "In this paper, we present two deep learning approaches that are based on AraBERT, submitted to the Propaganda Detection shared task of the Seventh Workshop for Arabic Natural Language Processing (WANLP 2022). Propaganda detection consists of two main sub-tasks, mainly propaganda identification and span extraction. We present one system per sub-task. The first system is a Multi-Task Learning model that consists of a shared AraBERT encoder with task-specific binary classification layers. This model is trained to jointly learn one binary classification task per propaganda method. The second system is an AraBERT model with a Conditional Random Field (CRF) layer. We achieved rank 3 on the first sub-task and rank 1 on the second sub-task",
    "checked": true,
    "id": "bcba209c9d067d17fe678bba5cf8ea4eeb7f3a9e",
    "semantic_title": "pythoneers at wanlp 2022 shared task: monolingual arabert for arabic propaganda detection and span extraction",
    "citation_count": 3,
    "authors": [
      "Joseph Attieh",
      "Fadi Hassan"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.65": {
    "title": "CNLP-NITS-PP at WANLP 2022 Shared Task: Propaganda Detection in Arabic using Data Augmentation and AraBERT Pre-trained Model",
    "volume": "workshop",
    "abstract": "In today's time, online users are regularly exposed to media posts that are propagandistic. Several strategies have been developed to promote safer media consumption in Arabic to combat this. However, there is a limited available multilabel annotated social media dataset. In this work, we have used a pre-trained AraBERT twitter-base model on an expanded train data via data augmentation. Our team CNLP-NITS-PP, has achieved the third rank in subtask 1 at WANLP-2022, for propaganda detection in Arabic (shared task) in terms of micro-F1 score of 0.602",
    "checked": true,
    "id": "9598fd6f50ff65722a0c57b7268404c879a1c36c",
    "semantic_title": "cnlp-nits-pp at wanlp 2022 shared task: propaganda detection in arabic using data augmentation and arabert pre-trained model",
    "citation_count": 3,
    "authors": [
      "Sahinur Rahman Laskar",
      "Rahul Singh",
      "Abdullah Faiz Ur Rahman Khilji",
      "Riyanka Manna",
      "Partha Pakray",
      "Sivaji Bandyopadhyay"
    ]
  },
  "https://aclanthology.org/2022.wanlp-1.66": {
    "title": "NGU CNLP atWANLP 2022 Shared Task: Propaganda Detection in Arabic",
    "volume": "workshop",
    "abstract": "This paper presents the system developed by the NGU_CNLP team for addressing the shared task on Propaganda Detection in Arabic at WANLP 2022. The team participated in the shared tasks' two sub-tasks which are: 1) Propaganda technique identification in text and 2) Propaganda technique span identification. In the first sub-task, the goal is to detect all employed propaganda techniques in some given piece of text out of a possible 17 different techniques or to detect that no propaganda technique is being used in that piece of text. As such, this first sub-task is a multi-label classification problem with a pool of 18 possible labels. Subtask 2 extends sub-task 1, by requiring the identification of the exact text span in which a propaganda technique was employed, making it a sequence labeling problem. For task 1, a combination of a data augmentation strategy coupled with an enabled transformer-based model comprised our classification model. This classification model ranked first amongst the 14 systems participating in this subtask. For sub-task two, a transfer learning model was adopted. The system ranked third among the 3 different models that participated in this subtask",
    "checked": true,
    "id": "6f6e9ba4fd034d38d8de7283682801fe2a0ac73c",
    "semantic_title": "ngu cnlp atwanlp 2022 shared task: propaganda detection in arabic",
    "citation_count": 2,
    "authors": [
      "Ahmed Samir Hussein",
      "Abu Bakr Soliman Mohammad",
      "Mohamed Ibrahim",
      "Laila Hesham Afify",
      "Samhaa R. El-Beltagy"
    ]
  }
}