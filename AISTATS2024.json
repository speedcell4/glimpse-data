{
  "https://proceedings.mlr.press/v238/ruegamer24a.html": {
    "title": "Scalable Higher-Order Tensor Product Spline Models",
    "volume": "main",
    "abstract": "In the current era of vast data and transparent machine learning, it is essential for techniques to operate at a large scale while providing a clear mathematical comprehension of the internal workings of the method. Although there already exist interpretable semi-parametric regression methods for large-scale applications that take into account non-linearity in the data, the complexity of the models is still often limited. One of the main challenges is the absence of interactions in these models, which are left out for the sake of better interpretability but also due to impractical computational costs. To overcome this limitation, we propose a new approach using a factorization method to derive a highly scalable higher-order tensor product spline model. Our method allows for the incorporation of all (higher-order) interactions of non-linear feature effects while having computational costs proportional to a model without interactions. We further develop a meaningful penalization scheme and examine the induced optimization problem. We conclude by evaluating the predictive and estimation performance of our method",
    "checked": true,
    "id": "dfacaf4f4de33745be4a1937e9b6d6708a496cf0",
    "semantic_title": "scalable higher-order tensor product spline models",
    "citation_count": 0,
    "authors": [
      "David Ruegamer"
    ]
  },
  "https://proceedings.mlr.press/v238/amagata24a.html": {
    "title": "Fair k-center Clustering with Outliers",
    "volume": "main",
    "abstract": "The importance of dealing with big data is further increasing, as machine learning (ML) systems obtain useful knowledge from big datasets. However, using all data is practically prohibitive because of the massive sizes of the datasets, so summarizing them by centers obtained from k-center clustering is a promising approach. We have two concerns here. One is fairness, because if the summary does not have some specific groups, subsequent applications may provide unfair results for the groups. The other is the presence of outliers, and if outliers dominate the summary, it cannot be useful. To overcome these concerns, we address the problem of fair k-center clustering with outliers. Although prior works studied the fair k-center clustering problem, they do not consider outliers. This paper yields a linear time algorithm that satisfies the fairness constraint of our problem and probabilistically guarantees the almost 3-approximation bound. Its empirical efficiency and effectiveness are also reported",
    "checked": true,
    "id": "3cf3d1e04481b34bb910e3e74afc0b9bc4cdc8d2",
    "semantic_title": "fair k-center clustering with outliers",
    "citation_count": 0,
    "authors": [
      "Daichi Amagata"
    ]
  },
  "https://proceedings.mlr.press/v238/shankar24a.html": {
    "title": "A/B testing under Interference with Partial Network Information",
    "volume": "main",
    "abstract": "A/B tests are often required to be conducted on subjects that might have social connections. For e.g., experiments on social media, or medical and social interventions to control the spread of an epidemic. In such settings, the SUTVA assumption for randomized-controlled trials is violated due to network interference, or spill-over effects, as treatments to group A can potentially also affect the control group B. When the underlying social network is known exactly, prior works have demonstrated how to conduct A/B tests adequately to estimate the global average treatment effect (GATE). However, in practice, it is often impossible to obtain knowledge about the exact underlying network. In this paper, we present UNITE: a novel estimator that relax this assumption and can identify GATE while only relying on knowledge of the superset of neighbors for any subject in the graph. Through theoretical analysis and extensive experiments, we show that the proposed approach performs better in comparison to standard estimators",
    "checked": true,
    "id": "23e9ddc6a752b966e10c8e60b59b491fb92fedad",
    "semantic_title": "a/b testing under interference with partial network information",
    "citation_count": 1,
    "authors": [
      "Shiv Shankar",
      "Ritwik Sinha",
      "Yash Chandak",
      "Saayan Mitra",
      "Madalina Fiterau"
    ]
  },
  "https://proceedings.mlr.press/v238/jang24a.html": {
    "title": "Achieving Fairness through Separability: A Unified Framework for Fair Representation Learning",
    "volume": "main",
    "abstract": "Fairness is a growing concern in machine learning as state-of-the-art models may amplify social prejudice by making biased predictions against specific demographics such as race and gender. Such discrimination raises issues in various fields such as employment, criminal justice, and trust score evaluation. To address the concerns, we propose learning fair representation through a straightforward yet effective approach to project intrinsic information while filtering sensitive information for downstream tasks. Our model consists of two goals: one is to ensure that the latent data from different demographic groups is non-separable (i.e., make the latent data distribution independent of the sensitive feature to improve fairness); the other is to maximize the separability of latent data from different classes (i.e., maintain the discriminative power of data for the sake of the downstream tasks like classification). Our method adopts a non-zero-sum adversarial game to minimize the distance between data from different demographic groups while maximizing the margin between data from different classes. Moreover, the proposed objective function can be easily generalized to multiple sensitive attributes and multi-class scenarios as it upper bounds popular fairness metrics in these cases. We provide theoretical analysis of the fairness of our model and validate w.r.t. both fairness and predictive performance on benchmark datasets",
    "checked": true,
    "id": "7696d4cc5f1ae70528e5fbd70bf14c3ea90b0891",
    "semantic_title": "achieving fairness through separability: a unified framework for fair representation learning",
    "citation_count": 0,
    "authors": [
      "Taeuk Jang",
      "Hongchang Gao",
      "Pengyi Shi",
      "Xiaoqian Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/li24a.html": {
    "title": "Personalized Federated X-armed Bandit",
    "volume": "main",
    "abstract": "In this work, we study the personalized federated $\\mathcal{X}$-armed bandit problem, where the heterogeneous local objectives of the clients are optimized simultaneously in the federated learning paradigm. We propose the \\texttt{PF-PNE} algorithm with a unique double elimination strategy, which safely eliminates the non-optimal regions while encouraging federated collaboration through biased but effective evaluations of the local objectives. The proposed \\texttt{PF-PNE} algorithm is able to optimize local objectives with arbitrary levels of heterogeneity, and its limited communications protects the confidentiality of the client-wise reward data. Our theoretical analysis shows the benefit of the proposed algorithm over single-client algorithms. Experimentally, \\texttt{PF-PNE} outperforms multiple baselines on both synthetic and real life datasets",
    "checked": false,
    "id": "186f745dc4518e1df276a57b5f57eda775c93034",
    "semantic_title": "personalized federated x -armed bandit",
    "citation_count": 0,
    "authors": [
      "Wenjie Li",
      "Qifan Song",
      "Jean Honorio"
    ]
  },
  "https://proceedings.mlr.press/v238/li24b.html": {
    "title": "Non-Neighbors Also Matter to Kriging: A New Contrastive-Prototypical Learning",
    "volume": "main",
    "abstract": "Kriging aims to estimate the attributes of unseen geo-locations from observations in the spatial vicinity or physical connections. Existing works assume that neighbors' information offers the basis for estimating the unobserved target while ignoring non-neighbors. However, neighbors could also be quite different or even misleading, and the non-neighbors could still offer constructive information. To this end, we propose \"Contrastive-Prototypical\" self-supervised learning for Kriging (KCP): (1) The neighboring contrastive module coarsely pushes neighbors together and non-neighbors apart. (2) In parallel, the prototypical module identifies similar representations via exchanged prediction, such that it refines the misleading neighbors and recycles the useful non-neighbors from the neighboring contrast component. As a result, not all the neighbors and some of the non-neighbors will be used to infer the target. (3) To learn general and robust representations, we design an adaptive augmentation module that encourages data diversity. Theoretical bound is derived for the proposed augmentation. Extensive experiments on real-world datasets demonstrate the superior performance of KCP compared to its peers with 6% improvements and exceptional transferability and robustness",
    "checked": true,
    "id": "074664024ec6005741748e4e3af7f1e3bfe22b77",
    "semantic_title": "non-neighbors also matter to kriging: a new contrastive-prototypical learning",
    "citation_count": 2,
    "authors": [
      "Zhishuai Li",
      "Yunhao Nie",
      "Ziyue Li",
      "Lei Bai",
      "Yisheng Lv",
      "Rui Zhao"
    ]
  },
  "https://proceedings.mlr.press/v238/hill24a.html": {
    "title": "Boundary-Aware Uncertainty for Feature Attribution Explainers",
    "volume": "main",
    "abstract": "Post-hoc explanation methods have become a critical tool for understanding black-box classifiers in high-stakes applications. However, high-performing classifiers are often highly nonlinear and can exhibit complex behavior around the decision boundary, leading to brittle or misleading local explanations. Therefore there is an impending need to quantify the uncertainty of such explanation methods in order to understand when explanations are trustworthy. In this work we propose the Gaussian Process Explanation unCertainty (GPEC) framework, which generates a unified uncertainty estimate combining decision boundary-aware uncertainty with explanation function approximation uncertainty. We introduce a novel geodesic-based kernel, which captures the complexity of the target black-box decision boundary. We show theoretically that the proposed kernel similarity increases with decision boundary complexity. The proposed framework is highly flexible; it can be used with any black-box classifier and feature attribution method. Empirical results on multiple tabular and image datasets show that the GPEC uncertainty estimate improves understanding of explanations as compared to existing methods",
    "checked": true,
    "id": "51cdedfb9850844e9f24235d5c79f624a93280a9",
    "semantic_title": "boundary-aware uncertainty for feature attribution explainers",
    "citation_count": 1,
    "authors": [
      "Davin Hill",
      "Aria Masoomi",
      "Max Torop",
      "Sandesh Ghimire",
      "Jennifer Dy"
    ]
  },
  "https://proceedings.mlr.press/v238/even24a.html": {
    "title": "Asynchronous SGD on Graphs: a Unified Framework for Asynchronous Decentralized and Federated Optimization",
    "volume": "main",
    "abstract": "Decentralized and asynchronous communications are two popular techniques to speedup communication complexity of distributed machine learning, by respectively removing the dependency over a central orchestrator and the need for synchronization. Yet, combining these two techniques together still remains a challenge. In this paper, we take a step in this direction and introduce Asynchronous SGD on Graphs (AGRAF SGD) — a general algorithmic framework that covers asynchronous versions of many popular algorithms including SGD, Decentralized SGD, Local SGD, FedBuff, thanks to its relaxed communication and computation assumptions. We provide rates of convergence under much milder assumptions than previous decentralized asynchronous works, while still recovering or even improving over the best know results for all the algorithms covered",
    "checked": true,
    "id": "0f9ded926e889e35695e2028a059c96476fc8daa",
    "semantic_title": "asynchronous sgd on graphs: a unified framework for asynchronous decentralized and federated optimization",
    "citation_count": 7,
    "authors": [
      "Mathieu Even",
      "Anastasia Koloskova",
      "Laurent Massoulie"
    ]
  },
  "https://proceedings.mlr.press/v238/hellstrom24a.html": {
    "title": "Comparing Comparators in Generalization Bounds",
    "volume": "main",
    "abstract": "We derive generic information-theoretic and PAC-Bayesian generalization bounds involving an arbitrary convex comparator function, which measures the discrepancy between the training loss and the population loss. The bounds hold under the assumption that the cumulant-generating function (CGF) of the comparator is upper-bounded by the corresponding CGF within a family of bounding distributions. We show that the tightest possible bound is obtained with the comparator being the convex conjugate of the CGF of the bounding distribution, also known as the Cramér function. This conclusion applies more broadly to generalization bounds with a similar structure. This confirms the near-optimality of known bounds for bounded and sub-Gaussian losses and leads to novel bounds under other bounding distributions",
    "checked": true,
    "id": "8ec2d05bdeb8820d656ffdc898aafb3bc8f92dab",
    "semantic_title": "comparing comparators in generalization bounds",
    "citation_count": 1,
    "authors": [
      "Fredrik Hellström",
      "Benjamin Guedj"
    ]
  },
  "https://proceedings.mlr.press/v238/dagreou24a.html": {
    "title": "A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization",
    "volume": "main",
    "abstract": "Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $O((n+m)^{1/2}\\epsilon^{-1})$ oracle calls to achieve $\\epsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, making it optimal in terms of sample complexity",
    "checked": true,
    "id": "d86c87c44071f149508b5b0f718c607e908966fd",
    "semantic_title": "a lower bound and a near-optimal algorithm for bilevel empirical risk minimization",
    "citation_count": 6,
    "authors": [
      "Mathieu Dagréou",
      "Thomas Moreau",
      "Samuel Vaiter",
      "Pierre Ablin"
    ]
  },
  "https://proceedings.mlr.press/v238/zheng24a.html": {
    "title": "Better Batch for Deep Probabilistic Time Series Forecasting",
    "volume": "main",
    "abstract": "Deep probabilistic time series forecasting has gained attention for its ability to provide nonlinear approximation and valuable uncertainty quantification for decision-making. However, existing models often oversimplify the problem by assuming a time-independent error process and overlooking serial correlation. To overcome this limitation, we propose an innovative training method that incorporates error autocorrelation to enhance probabilistic forecasting accuracy. Our method constructs a mini-batch as a collection of D consecutive time series segments for model training. It explicitly learns a time-varying covariance matrix over each mini-batch, encoding error correlation among adjacent time steps. The learned covariance matrix can be used to improve prediction accuracy and enhance uncertainty quantification. We evaluate our method on two different neural forecasting models and multiple public datasets. Experimental results confirm the effectiveness of the proposed approach in improving the performance of both models across a range of datasets, resulting in notable improvements in predictive accuracy",
    "checked": true,
    "id": "5a37896de7f956b6cff13e914db09f858d004b21",
    "semantic_title": "better batch for deep probabilistic time series forecasting",
    "citation_count": 1,
    "authors": [
      "Zhihao Zheng",
      "Seongjin Choi",
      "Lijun Sun"
    ]
  },
  "https://proceedings.mlr.press/v238/sundhar-ramesh24a.html": {
    "title": "Distributionally Robust Model-based Reinforcement Learning with Large State Spaces",
    "volume": "main",
    "abstract": "Three major challenges in reinforcement learning are the complex dynamical systems with large state spaces, the costly data acquisition processes, and the deviation of real-world dynamics from the training environment deployment. To overcome these issues, we study distributionally robust Markov decision processes with continuous state spaces under the widely used Kullback-Leibler, chi-square, and total variation uncertainty sets. We propose a model-based approach that utilizes Gaussian Processes and the maximum variance reduction algorithm to efficiently learn multi-output nominal transition dynamics, leveraging access to a generative model (i.e., simulator). We further demonstrate the statistical sample complexity of the proposed method for different uncertainty sets. These complexity bounds are independent of the number of states and extend beyond linear dynamics, ensuring the effectiveness of our approach in identifying near-optimal distributionally-robust policies. The proposed method can be further combined with other model-free distributionally robust reinforcement learning methods to obtain a near-optimal robust policy. Experimental results demonstrate the robustness of our algorithm to distributional shifts and its superior performance in terms of the number of samples needed",
    "checked": true,
    "id": "e3556000f28908e124c5facb6cb0a2dc55d0c373",
    "semantic_title": "distributionally robust model-based reinforcement learning with large state spaces",
    "citation_count": 6,
    "authors": [
      "Shyam Sundhar Ramesh",
      "Pier Giuseppe Sessa",
      "Yifan Hu",
      "Andreas Krause",
      "Ilija Bogunovic"
    ]
  },
  "https://proceedings.mlr.press/v238/el-ahmad24a.html": {
    "title": "Sketch In, Sketch Out: Accelerating both Learning and Inference for Structured Prediction with Kernels",
    "volume": "main",
    "abstract": "Leveraging the kernel trick in both the input and output spaces, surrogate kernel methods are a flexible and theoretically grounded solution to structured output prediction. If they provide state-of-the-art performance on complex data sets of moderate size (e.g., in chemoinformatics), these approaches however fail to scale. We propose to equip surrogate kernel methods with sketching-based approximations, applied to both the input and output feature maps. We prove excess risk bounds on the original structured prediction problem, showing how to attain close-to-optimal rates with a reduced sketch size that depends on the eigendecay of the input/output covariance operators. From a computational perspective, we show that the two approximations have distinct but complementary impacts: sketching the input kernel mostly reduces training time, while sketching the output kernel decreases the inference time. Empirically, our approach is shown to scale, achieving state-of-the-art performance on benchmark data sets where non-sketched methods are intractable",
    "checked": true,
    "id": "0e42aa9569404ed314ed9d6cb1142b62cd355b6e",
    "semantic_title": "sketch in, sketch out: accelerating both learning and inference for structured prediction with kernels",
    "citation_count": 4,
    "authors": [
      "Tamim El Ahmad",
      "Luc Brogat-Motte",
      "Pierre Laforgue",
      "Florence d’Alché-Buc"
    ]
  },
  "https://proceedings.mlr.press/v238/vadori24a.html": {
    "title": "Ordinal Potential-based Player Rating",
    "volume": "main",
    "abstract": "It was recently observed that Elo ratings fail at preserving transitive relations among strategies and therefore cannot correctly extract the transitive component of a game. We provide a characterization of transitive games as a weak variant of ordinal potential games and show that Elo ratings actually do preserve transitivity when computed in the right space, using suitable invertible mappings. Leveraging this insight, we introduce a new game decomposition of an arbitrary game into transitive and cyclic components that is learnt using a neural network-based architecture and that prioritises capturing the sign pattern of the game, namely transitive and cyclic relations among strategies. We link our approach to the known concept of sign-rank, and evaluate our methodology using both toy examples and empirical data from real-world games",
    "checked": true,
    "id": "c9a24d35bf506e2aac1aed5d5d6eedf209204b44",
    "semantic_title": "ordinal potential-based player rating",
    "citation_count": 1,
    "authors": [
      "Nelson Vadori",
      "Rahul Savani"
    ]
  },
  "https://proceedings.mlr.press/v238/rudner24a.html": {
    "title": "Mind the GAP: Improving Robustness to Subpopulation Shifts with Group-Aware Priors",
    "volume": "main",
    "abstract": "Machine learning models often perform poorly under subpopulation shifts in the data distribution. Developing methods that allow machine learning models to better generalize to such shifts is crucial for safe deployment in real-world settings. In this paper, we develop a family of group-aware prior (GAP) distributions over neural network parameters that explicitly favor models that generalize well under subpopulation shifts. We design a simple group-aware prior that only requires access to a small set of data with group information and demonstrate that training with this prior yields state-of-the-art performance—even when only retraining the final layer of a previously trained non-robust model. Group aware-priors are conceptually simple, complementary to existing approaches, such as attribute pseudo labeling and data reweighting, and open up promising new avenues for harnessing Bayesian inference to enable robustness to subpopulation shifts",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tim G. J. Rudner",
      "Ya Shi Zhang",
      "Andrew Gordon Wilson",
      "Julia Kempe"
    ]
  },
  "https://proceedings.mlr.press/v238/buch24a.html": {
    "title": "Simple and scalable algorithms for cluster-aware precision medicine",
    "volume": "main",
    "abstract": "AI-enabled precision medicine promises a transformational improvement in healthcare outcomes. However, training on biomedical data presents significant challenges as they are often high dimensional, clustered, and of limited sample size. To overcome these challenges, we propose a simple and scalable approach for cluster-aware embedding that combines latent factor methods with a convex clustering penalty in a modular way. Our novel approach overcomes the complexity and limitations of current joint embedding and clustering methods and enables hierarchically clustered principal component analysis (PCA), locally linear embedding (LLE), and canonical correlation analysis (CCA). Through numerical experiments and real-world examples, we demonstrate that our approach outperforms fourteen clustering methods on highly underdetermined problems (e.g., with limited sample size) as well as on large sample datasets. Importantly, our approach does not require the user to choose the desired number of clusters, yields improved model selection if they do, and yields interpretable hierarchically clustered embedding dendrograms. Thus, our approach improves significantly on existing methods for identifying patient subgroups in multiomics and neuroimaging data and enables scalable and interpretable biomarkers for precision medicine",
    "checked": true,
    "id": "18401e3c8b867c6fb822605cb41bd6e2e5ce7edc",
    "semantic_title": "simple and scalable algorithms for cluster-aware precision medicine",
    "citation_count": 0,
    "authors": [
      "Amanda M. Buch",
      "Conor Liston",
      "Logan Grosenick"
    ]
  },
  "https://proceedings.mlr.press/v238/lin24a.html": {
    "title": "A Specialized Semismooth Newton Method for Kernel-Based Optimal Transport",
    "volume": "main",
    "abstract": "Kernel-based optimal transport (OT) estimators offer an alternative, functional estimation procedure to address OT problems from samples. Recent works suggest that these estimators are more statistically efficient than plug-in (linear programming-based) OT estimators when comparing probability measures in high-dimensions (Vacher et al., 2021). Unfortunately,that statistical benefit comes at a very steep computational price: because their computation relies on the short-step interior-point method (SSIPM), which comes with a large iteration count in practice, these estimators quickly become intractable w.r.t. sample size $n$. To scale these estimators to larger $n$, we propose a nonsmooth fixedpoint model for the kernel-based OT problem, and show that it can be efficiently solved via a specialized semismooth Newton (SSN) method: We show, exploring the problem's structure, that the per-iteration cost of performing one SSN step can be significantly reduced in practice. We prove that our SSN method achieves a global convergence rate of $O(1/\\sqrt{k})$, and a local quadratic convergence rate under standard regularity conditions. We show substantial speedups over SSIPM on both synthetic and real datasets",
    "checked": true,
    "id": "157c69ef084364273ef763cb7058fca84828f9ee",
    "semantic_title": "a specialized semismooth newton method for kernel-based optimal transport",
    "citation_count": 0,
    "authors": [
      "Tianyi Lin",
      "Marco Cuturi",
      "Michael Jordan"
    ]
  },
  "https://proceedings.mlr.press/v238/dai24a.html": {
    "title": "Local Causal Discovery with Linear non-Gaussian Cyclic Models",
    "volume": "main",
    "abstract": "Local causal discovery is of great practical significance, as there are often situations where the discovery of the global causal structure is unnecessary, and the interest lies solely on a single target variable. Most existing local methods utilize conditional independence relations, providing only a partially directed graph, and assume acyclicity for the ground-truth structure, even though real-world scenarios often involve cycles like feedback mechanisms. In this work, we present a general, unified local causal discovery method with linear non-Gaussian models, whether they are cyclic or acyclic. We extend the application of independent component analysis from the global context to independent subspace analysis, enabling the exact identification of the equivalent local directed structures and causal strengths from the Markov blanket of the target variable. We also propose an alternative regression-based method in the particular acyclic scenarios. Our identifiability results are empirically validated using both synthetic and real-world datasets",
    "checked": true,
    "id": "1304f88cf92fecccbcf2c26aaac3d4f0a7964e05",
    "semantic_title": "local causal discovery with linear non-gaussian cyclic models",
    "citation_count": 2,
    "authors": [
      "Haoyue Dai",
      "Ignavier Ng",
      "Yujia Zheng",
      "Zhengqing Gao",
      "Kun Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/park24a.html": {
    "title": "Density Uncertainty Layers for Reliable Uncertainty Estimation",
    "volume": "main",
    "abstract": "Assessing the predictive uncertainty of deep neural networks is crucial for safety-related applications of deep learning. Although Bayesian deep learning offers a principled framework for estimating model uncertainty, the common approaches that approximate the parameter posterior often fail to deliver reliable estimates of predictive uncertainty. In this paper, we propose a novel criterion for reliable predictive uncertainty: a model's predictive variance should be grounded in the empirical density of the input. That is, the model should produce higher uncertainty for inputs that are improbable in the training data and lower uncertainty for inputs that are more probable. To operationalize this criterion, we develop the density uncertainty layer, a stochastic neural network architecture that satisfies the density uncertain criterion by design. We study density uncertainty layers on the UCI and CIFAR-10/100 uncertainty benchmarks. Compared to existing approaches, density uncertainty layers provide more reliable uncertainty estimates and robust out-of-distribution detection performance",
    "checked": true,
    "id": "3cb746ee9ab49920ead4bd832d94ca0bc1ee5d3b",
    "semantic_title": "density uncertainty layers for reliable uncertainty estimation",
    "citation_count": 1,
    "authors": [
      "Yookoon Park",
      "David Blei"
    ]
  },
  "https://proceedings.mlr.press/v238/carton24a.html": {
    "title": "Double InfoGAN for Contrastive Analysis",
    "volume": "main",
    "abstract": "Contrastive Analysis (CA) deals with the discovery of what is common and what is distinctive of a target domain compared to a background one. This is of great interest in many applications, such as medical imaging. Current state-of-the-art (SOTA) methods are latent variable models based on VAE (CA-VAEs). However, they all either ignore important constraints or they don't enforce fundamental assumptions. This may lead to sub-optimal solutions where distinctive factors are mistaken for common ones (or viceversa). Furthermore, the generated images have a rather poor quality, typical of VAEs, decreasing their interpretability and usefulness. Here, we propose Double InfoGAN, the first GAN based method for CA that leverages the high-quality synthesis of GAN and the separation power of InfoGAN. Experimental results on four visual datasets, from simple synthetic examples to complex medical images, show that the proposed method outperforms SOTA CA-VAEs in terms of latent separation and image quality. Datasets and code are available online",
    "checked": true,
    "id": "bcc1580fbd66a0c9f1a008537a02f190b1d07f57",
    "semantic_title": "double infogan for contrastive analysis",
    "citation_count": 2,
    "authors": [
      "Florence Carton",
      "Robin Louiset",
      "Pietro Gori"
    ]
  },
  "https://proceedings.mlr.press/v238/feng24a.html": {
    "title": "Is this model reliable for everyone? Testing for strong calibration",
    "volume": "main",
    "abstract": "In a well-calibrated risk prediction model, the average predicted probability is close to the true event rate for any given subgroup. Such models are reliable across heterogeneous populations and satisfy strong notions of algorithmic fairness. However, the task of auditing a model for strong calibration is well-known to be difficult—particularly for machine learning (ML) algorithms—due to the sheer number of potential subgroups. As such, common practice is to only assess calibration with respect to a few predefined subgroups. Recent developments in goodness-of-fit testing offer potential solutions but are not designed for settings with weak signal or where the poorly calibrated subgroup is small, as they either overly subdivide the data or fail to divide the data at all. We introduce a new testing procedure based on the following insight: if we can reorder observations by their expected residuals, there should be a change in the association between the predicted and observed residuals along this sequence if a poorly calibrated subgroup exists. This lets us reframe the problem of calibration testing into one of changepoint detection, for which powerful methods already exist. We begin with introducing a sample-splitting procedure where a portion of the data is used to train a suite of candidate models for predicting the residual, and the remaining data are used to perform a score-based cumulative sum (CUSUM) test. To further improve power, we then extend this adaptive CUSUM test to incorporate cross-validation, while maintaining Type I error control under minimal assumptions. Compared to existing methods, the proposed procedure consistently achieved higher power in empirical analyses",
    "checked": true,
    "id": "1c965a39aae320fb048ef7d8aa2cf55c8dfb49c1",
    "semantic_title": "is this model reliable for everyone? testing for strong calibration",
    "citation_count": 2,
    "authors": [
      "Jean Feng",
      "Alexej Gossmann",
      "Romain Pirracchio",
      "Nicholas Petrick",
      "Gene A Pennello",
      "Berkman Sahiner"
    ]
  },
  "https://proceedings.mlr.press/v238/palm24a.html": {
    "title": "An Online Bootstrap for Time Series",
    "volume": "main",
    "abstract": "Resampling methods such as the bootstrap have proven invaluable in the field of machine learning. However, the applicability of traditional bootstrap methods is limited when dealing with large streams of dependent data, such as time series or spatially correlated observations. In this paper, we propose a novel bootstrap method that is designed to account for data dependencies and can be executed online, making it particularly suitable for real-time applications. This method is based on an autoregressive sequence of increasingly dependent resampling weights. We prove the theoretical validity of the proposed bootstrap scheme under general conditions. We demonstrate the effectiveness of our approach through extensive simulations and show that it provides reliable uncertainty quantification even in the presence of complex data dependencies. Our work bridges the gap between classical resampling techniques and the demands of modern data analysis, providing a valuable tool for researchers and practitioners in dynamic, data-rich environments",
    "checked": true,
    "id": "80d7b73777ff734ab496f19a153872332d0eb55a",
    "semantic_title": "an online bootstrap for time series",
    "citation_count": 0,
    "authors": [
      "Nicolai Palm",
      "Thomas Nagler"
    ]
  },
  "https://proceedings.mlr.press/v238/xing24a.html": {
    "title": "Better Representations via Adversarial Training in Pre-Training: A Theoretical Perspective",
    "volume": "main",
    "abstract": "Pre-training is known to generate universal representations for downstream tasks in large-scale deep learning such as large language models. Existing literature, e.g., Kim et al. (2020), empirically observe that the downstream tasks can inherit the adversarial robustness of the pre-trained model. We provide theoretical justifications for this robustness inheritance phenomenon. Our theoretical results reveal that feature purification plays an important role in connecting the adversarial robustness of the pre-trained model and the downstream tasks in two-layer neural networks. Specifically, we show that (i) with adversarial training, each hidden node tends to pick only one (or a few) feature; (ii) without adversarial training, the hidden nodes can be vulnerable to attacks. This observation is valid for both supervised pre-training and contrastive learning. With purified nodes, it turns out that clean training is enough to achieve adversarial robustness in downstream tasks",
    "checked": true,
    "id": "56ce2e63d91c8ec1a999f552cbf9918c39006b12",
    "semantic_title": "better representations via adversarial training in pre-training: a theoretical perspective",
    "citation_count": 0,
    "authors": [
      "Yue Xing",
      "Xiaofeng Lin",
      "Qifan Song",
      "Yi Xu",
      "Belinda Zeng",
      "Guang Cheng"
    ]
  },
  "https://proceedings.mlr.press/v238/song24a.html": {
    "title": "Solving Attention Kernel Regression Problem via Pre-conditioner",
    "volume": "main",
    "abstract": "Attention mechanism is the key to large language models, and attention matrix serves as an algorithmic and computational bottleneck for such a scheme. In this paper, we define two problems, motivated by designing fast algorithms for \\emph{proxy} of attention matrix and solving regressions against them. Given an input matrix $A\\in \\mathbb{R}^{n\\times d}$ with $n\\gg d$ and a response vector $b$, we first consider the matrix exponential of the matrix $A^\\top A$ as a proxy, and we in turn design algorithms for two types of regression problems: $\\min_{x\\in \\mathbb{R}^d}\\|(A^\\top A)^jx-b\\|_2$ and $\\min_{x\\in \\mathbb{R}^d}\\|A(A^\\top A)^jx-b\\|_2$ for any positive integer $j$. Studying algorithms for these regressions is essential, as matrix exponential can be approximated term-by-term via these smaller problems. The second proxy is applying exponential entrywise to the Gram matrix, denoted by $\\exp(AA^\\top)$ and solving the regression $\\min_{x\\in \\mathbb{R}^n}\\|\\exp(AA^\\top)x-b \\|_2$. We call this problem the \\emph{attention kernel regression} problem, as the matrix $\\exp(AA^\\top)$ could be viewed as a kernel function with respect to $A$. We design fast algorithms for these regression problems, based on sketching and preconditioning. We hope these efforts will provide an alternative perspective of studying efficient approximation of attention matrices",
    "checked": true,
    "id": "420533d1fc0ef9e652a228a669a858ad7d7162ea",
    "semantic_title": "solving attention kernel regression problem via pre-conditioner",
    "citation_count": 5,
    "authors": [
      "Zhao Song",
      "Junze Yin",
      "Lichen Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/hu24a.html": {
    "title": "Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations",
    "volume": "main",
    "abstract": "Deep learning-based visual perception models lack robustness when faced with camera motion perturbations in practice. The current certification process for assessing robustness is costly and time-consuming due to the extensive number of image projections required for Monte Carlo sampling in the 3D camera motion space. To address these challenges, we present a novel, efficient, and practical framework for certifying the robustness of 3D-2D projective transformations against camera motion perturbations. Our approach leverages a smoothing distribution over the 2D-pixel space instead of in the 3D physical space, eliminating the need for costly camera motion sampling and significantly enhancing the efficiency of robustness certifications. With the pixel-wise smoothed classifier, we are able to fully upper bound the projection errors using a technique of uniform partitioning in camera motion space. Additionally, we extend our certification framework to a more general scenario where only a single-frame point cloud is required in the projection oracle. Through extensive experimentation, we validate the trade-off between effectiveness and efficiency enabled by our proposed method. Remarkably, our approach achieves approximately 80% certified accuracy while utilizing only 30% of the projected image frames",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanjiang Hu",
      "Zuxin Liu",
      "Linyi Li",
      "Jiacheng Zhu",
      "Ding Zhao"
    ]
  },
  "https://proceedings.mlr.press/v238/bengs24a.html": {
    "title": "Identifying Copeland Winners in Dueling Bandits with Indifferences",
    "volume": "main",
    "abstract": "We consider the task of identifying the Copeland winner(s) in a dueling bandits problem with ternary feedback. This is an underexplored but practically relevant variant of the conventional dueling bandits problem, in which, in addition to strict preference between two arms, one may observe feedback in the form of an indifference. We provide a lower bound on the sample complexity for any learning algorithm finding the Copeland winner(s) with a fixed error probability. Moreover, we propose POCOWISTA, an algorithm with a sample complexity that almost matches this lower bound, and which shows excellent empirical performance, even for the conventional dueling bandits problem. For the case where the preference probabilities satisfy a specific type of stochastic transitivity, we provide a refined version with an improved worst case sample complexity",
    "checked": true,
    "id": "52d4a52de42491c2bc2c2414e959f9fde5be105f",
    "semantic_title": "identifying copeland winners in dueling bandits with indifferences",
    "citation_count": 0,
    "authors": [
      "Viktor Bengs",
      "Björn Haddenhorst",
      "Eyke Hüllermeier"
    ]
  },
  "https://proceedings.mlr.press/v238/kim24a.html": {
    "title": "Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?",
    "volume": "main",
    "abstract": "We prove that black-box variational inference (BBVI) with control variates, particularly the sticking-the-landing (STL) estimator, converges at a geometric (traditionally called \"linear\") rate under perfect variational family specification. In particular, we prove a quadratic bound on the gradient variance of the STL estimator, one which encompasses misspecified variational families. Combined with previous works on the quadratic variance condition, this directly implies convergence of BBVI with the use of projected stochastic gradient descent. For the projection operator, we consider a domain with triangular scale matrices, which the projection onto is computable in $\\theta(d)$ time, where $d$ is the dimensionality of the target posterior. We also improve existing analysis on the regular closed-form entropy gradient estimators, which enables comparison against the STL estimator, providing explicit non-asymptotic complexity guarantees for both",
    "checked": true,
    "id": "0e1e358a47a640667311787e54b013e6af505cd6",
    "semantic_title": "linear convergence of black-box variational inference: should we stick the landing?",
    "citation_count": 4,
    "authors": [
      "Kyurae Kim",
      "Yian Ma",
      "Jacob Gardner"
    ]
  },
  "https://proceedings.mlr.press/v238/song24b.html": {
    "title": "Fast Dynamic Sampling for Determinantal Point Processes",
    "volume": "main",
    "abstract": "n this work, we provide fast dynamic algorithms for repeatedly sampling from distributions characterized by Determinantal Point Processes (DPPs) and Nonsymmetric Determinantal Point Processes (NDPPs). DPPs are a very well-studied class of distributions on subsets of items drawn from a ground set of cardinality $n$ characterized by a symmetric $n \\times n$ kernel matrix $L$ such that the probability of any subset is proportional to the determinant of its corresponding principal submatrix. Recent work has shown that the kernel symmetry constraint can be relaxed, leading to NDPPs, which can better model data in several machine learning applications. Given a low-rank kernel matrix ${\\cal L}=L+L^\\top\\in \\mathbb{R}^{n\\times n}$ and its corresponding eigendecomposition specified by $\\{\\lambda_i, u_i \\}_{i=1}^d$ where $d\\leq n$ is the rank, we design a data structure that uses $O(nd)$ space and preprocesses data in $O(nd^{\\omega-1})$ time where $\\omega\\approx 2.37$ is the exponent of matrix multiplication. The data structure can generate a sample according to DPP distribution in time $O(|E|^3\\log n+|E|^{\\omega-1}d^2)$ or according to NDPP distribution in time $O((|E|^3 \\log n+ |E|^{\\omega-1}d^2)(1+w)^d)$ for $E$ being the sampled indices and $w$ is a data-dependent parameter. This improves upon the space and preprocessing time over prior works, and achieves a state-of-the-art sampling time when the sampling set is relatively dense. At the heart of our data structure is an efficient sampling tree that can leverage batch initialization and fast inner product query simultaneously",
    "checked": true,
    "id": "987ec3bbf4132cfb9477c2960702cb44dcf8af2f",
    "semantic_title": "fast dynamic sampling for determinantal point processes",
    "citation_count": 0,
    "authors": [
      "Zhao Song",
      "Junze Yin",
      "Lichen Zhang",
      "Ruizhe Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/li24c.html": {
    "title": "Best Arm Identification with Resource Constraints",
    "volume": "main",
    "abstract": "Motivated by the cost heterogeneity in experimentation across different alternatives, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem. The agent aims to identify the best arm under resource constraints, where resources are consumed for each arm pull. We make two novel contributions. We design and analyze the Successive Halving with Resource Rationing algorithm (SH-RR). The SH-RR achieves a near-optimal non-asymptotic rate of convergence in terms of the probability of successively identifying an optimal arm. Interestingly, we identify a difference in convergence rates between the cases of deterministic and stochastic resource consumption",
    "checked": true,
    "id": "3cf60b3397bb216818fe3e907c5059be448b616b",
    "semantic_title": "best arm identification with resource constraints",
    "citation_count": 0,
    "authors": [
      "Zitian Li",
      "Wang Chi Cheung"
    ]
  },
  "https://proceedings.mlr.press/v238/yang24a.html": {
    "title": "Neural McKean-Vlasov Processes: Distributional Dependence in Diffusion Processes",
    "volume": "main",
    "abstract": "McKean-Vlasov stochastic differential equations (MV-SDEs) provide a mathematical description of the behavior of an infinite number of interacting particles by imposing a dependence on the particle density. We study the influence of explicitly including distributional information in the parameterization of the SDE. We propose a series of semi-parametric methods for representing MV-SDEs, and corresponding estimators for inferring parameters from data based on the properties of the MV-SDE. We analyze the characteristics of the different architectures and estimators, and consider their applicability in relevant machine learning problems. We empirically compare the performance of the different architectures and estimators on real and synthetic datasets for time series and probabilistic modeling. The results suggest that explicitly including distributional dependence in the parameterization of the SDE is effective in modeling temporal data with interaction under an exchangeability assumption while maintaining strong performance for standard Itô-SDEs due to the richer class of probability flows associated with MV-SDEs",
    "checked": true,
    "id": "e9c726973fc3ad0267c4646a40e6ca3910b2ed4f",
    "semantic_title": "neural mckean-vlasov processes: distributional dependence in diffusion processes",
    "citation_count": 1,
    "authors": [
      "Haoming Yang",
      "Ali Hasan",
      "Yuting Ng",
      "Vahid Tarokh"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24a.html": {
    "title": "HintMiner: Automatic Question Hints Mining From Q&A Web Posts with Language Model via Self-Supervised Learning",
    "volume": "main",
    "abstract": "Users often need ask questions and seek answers online. The Question - Answering (QA) forums such as Stack Overflow cannot always respond to the questions timely and properly. In this paper, we propose HintMiner, a novel automatic question hints mining tool for users to help them find answers. HintMiner leverages the machine comprehension and sequence generation techniques to automatically generate hints for users' questions. It firstly retrieve many web Q&A posts and then extract some hints from the posts using MiningNet that is built via a language model. Using the huge amount of online Q&A posts, we design a self-supervised objective to train the MiningNet that is a neural encoder-decoder model based on the transformer and copying mechanisms. We have evaluated HintMiner on 60,000 Stack Overflow questions. The experiment results show that the proposed approach is effective. For example, HintMiner achieves an average BLEU score of 36.17% and an average ROUGE-2 score of 36.29%. Our tool and experimental data are publicly available at \\url{https://github.com/zhangzhenyu13/HintMiner}",
    "checked": true,
    "id": "fd37e67e4c4ac05e0a314c240fb8dafb8b197579",
    "semantic_title": "hintminer: automatic question hints mining from q&a web posts with language model via self-supervised learning",
    "citation_count": 0,
    "authors": [
      "Zhenyu Zhang",
      "JiuDong Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/hong24a.html": {
    "title": "A Primal-Dual-Critic Algorithm for Offline Constrained Reinforcement Learning",
    "volume": "main",
    "abstract": "Offline constrained reinforcement learning (RL) aims to learn a policy that maximizes the expected cumulative reward subject to constraints on expected cumulative cost using an existing dataset. In this paper, we propose Primal-Dual-Critic Algorithm (PDCA), a novel algorithm for offline constrained RL with general function approximation. PDCA runs a primal-dual algorithm on the Lagrangian function estimated by critics. The primal player employs a no-regret policy optimization oracle to maximize the Lagrangian estimate and the dual player acts greedily to minimize the Lagrangian estimate. We show that PDCA finds a near saddle point of the Lagrangian, which is nearly optimal for the constrained RL problem. Unlike previous work that requires concentrability and a strong Bellman completeness assumption, PDCA only requires concentrability and realizability assumptions for sample-efficient learning",
    "checked": true,
    "id": "75605dfe587630c365d092db9f60094067c4110f",
    "semantic_title": "a primal-dual-critic algorithm for offline constrained reinforcement learning",
    "citation_count": 4,
    "authors": [
      "Kihyuk Hong",
      "Yuhang Li",
      "Ambuj Tewari"
    ]
  },
  "https://proceedings.mlr.press/v238/huang24a.html": {
    "title": "On the Statistical Efficiency of Mean-Field Reinforcement Learning with General Function Approximation",
    "volume": "main",
    "abstract": "In this paper, we study the fundamental statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general model-based function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MF-MBED), which characterizes the inherent complexity of mean-field model classes. We show that a rich family of Mean-Field RL problems exhibits low MF-MBED. Additionally, we propose algorithms based on maximal likelihood estimation, which can return an $\\epsilon$-optimal policy for MFC or an $\\epsilon$-Nash Equilibrium policy for MFG. The overall sample complexity depends only polynomially on MF-MBED, which is potentially much lower than the size of state-action space. Compared with previous works, our results only require the minimal assumptions including realizability and Lipschitz continuity",
    "checked": false,
    "id": "93c5963791eda842b1897a4660d737e76c852b25",
    "semantic_title": "on the statistical efficiency of mean field reinforcement learning with general function approximation",
    "citation_count": 6,
    "authors": [
      "Jiawei Huang",
      "Batuhan Yardim",
      "Niao He"
    ]
  },
  "https://proceedings.mlr.press/v238/demetci24a.html": {
    "title": "Breaking isometric ties and introducing priors in Gromov-Wasserstein distances",
    "volume": "main",
    "abstract": "Gromov-Wasserstein distance has many applications in machine learning due to its ability to compare measures across metric spaces and its invariance to isometric transformations. However, in certain applications, this invariant property can be too flexible, thus undesirable. Moreover, the Gromov-Wasserstein distance solely considers pairwise sample similarities in input datasets, disregarding the raw feature representations. We propose a new optimal transport formulation, called Augmented Gromov-Wasserstein (AGW), that allows for some control over the level of rigidity to transformations. It also incorporates feature alignments, enabling us to better leverage prior knowledge on the input data for improved performance. We first present theoretical insights into the proposed method. We then demonstrate its usefulness for single-cell multi-omic alignment tasks and heterogeneous domain adaptation in machine learning",
    "checked": true,
    "id": "385085f40b48070b4bcf557c7a2eb2c7b90192c2",
    "semantic_title": "breaking isometric ties and introducing priors in gromov-wasserstein distances",
    "citation_count": 0,
    "authors": [
      "Pinar Demetci",
      "Quang Huy Tran",
      "Ievgen Redko",
      "Ritambhara Singh"
    ]
  },
  "https://proceedings.mlr.press/v238/abbas24a.html": {
    "title": "Enhancing In-context Learning via Linear Probe Calibration",
    "volume": "main",
    "abstract": "In-context learning (ICL) is a new paradigm for natural language processing that utilizes Generative Pre-trained Transformer (GPT)-like models. This approach uses prompts that include in-context demonstrations to generate the corresponding output for a new query input. However, applying ICL in real cases does not scale with the number of samples, and lacks robustness to different prompt templates and demonstration permutations. In this paper, we first show that GPT-like models using ICL result in unreliable predictions based on a new metric based on Shannon entropy. Then, to solve this problem, we propose a new technique called the Linear Probe Calibration (LinC), a method that calibrates the model's output probabilities, resulting in reliable predictions and improved performance, while requiring only minimal additional samples (as few as five labeled data samples). LinC significantly enhances the ICL test performance of GPT models on various benchmark datasets, with an average improvement of up to 21%, and up to a 50% improvement in some cases, and significantly boosts the performance of PEFT methods, especially in the low resource regime. Moreover, LinC achieves lower expected calibration error, and is highly robust to varying label proportions, prompt templates, and demonstration permutations",
    "checked": true,
    "id": "2fd6d186eb5648c71eefbcd9baf83471aeefc92b",
    "semantic_title": "enhancing in-context learning via linear probe calibration",
    "citation_count": 3,
    "authors": [
      "Momin Abbas",
      "Yi Zhou",
      "Parikshit Ram",
      "Nathalie Baracaldo",
      "Horst Samulowitz",
      "Theodoros Salonidis",
      "Tianyi Chen"
    ]
  },
  "https://proceedings.mlr.press/v238/lin24b.html": {
    "title": "DNNLasso: Scalable Graph Learning for Matrix-Variate Data",
    "volume": "main",
    "abstract": "We consider the problem of jointly learning row-wise and column-wise dependencies of matrix-variate observations, which are modelled separately by two precision matrices. Due to the complicated structure of Kronecker-product precision matrices in the commonly used matrix-variate Gaussian graphical models, a sparser Kronecker-sum structure was proposed recently based on the Cartesian product of graphs. However, existing methods for estimating Kronecker-sum structured precision matrices do not scale well to large scale datasets. In this paper, we introduce DNNLasso, a diagonally non-negative graphical lasso model for estimating the Kronecker-sum structured precision matrix, which outperforms the state-of-the-art methods by a large margin in both accuracy and computational time",
    "checked": true,
    "id": "e799d36fe2750c994fedd80782bf8c6b5cc9064d",
    "semantic_title": "dnnlasso: scalable graph learning for matrix-variate data",
    "citation_count": 0,
    "authors": [
      "Meixia Lin",
      "Yangjing Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/houry24a.html": {
    "title": "Fast 1-Wasserstein distance approximations using greedy strategies",
    "volume": "main",
    "abstract": "Among numerous linear approximation methods proposed for optimal transport (OT), tree-based methods appear to be fairly reliable, notably for language processing applications. Inspired by these tree methods, we introduce several greedy heuristics aiming to compute even faster approximations of OT. We first explicitly establish the equivalence between greedy matching and optimal transport for tree metrics, and then we show that tree greedy matching can be reduced to greedy matching on a one-dimensional line. Next, we propose two new greedy-based algorithms in one dimension: the $k$-Greedy and 1D-ICT algorithms. This novel approach provides Wasserstein approximations with accuracy similar to the original tree methods on text datasets while being faster in practice. Finally, these algorithms are applicable beyond tree approximations: using sliced projections of the original data still provides fairly good accuracy while eliminating the need for embedding the data in a fixed and rigid tree structure. This property makes these approaches even more versatile than the original tree OT methods",
    "checked": true,
    "id": "cac1ea8c0376c199feaff683d24ed482ba770dcf",
    "semantic_title": "fast 1-wasserstein distance approximations using greedy strategies",
    "citation_count": 0,
    "authors": [
      "Guillaume Houry",
      "Han Bao",
      "Han Zhao",
      "Makoto Yamada"
    ]
  },
  "https://proceedings.mlr.press/v238/carlsson24a.html": {
    "title": "Pure Exploration in Bandits with Linear Constraints",
    "volume": "main",
    "abstract": "We address the problem of identifying the optimal policy with a fixed confidence level in a multi-armed bandit setup, when \\emph{the arms are subject to linear constraints}. Unlike the standard best-arm identification problem which is well studied, the optimal policy in this case may not be deterministic and could mix between several arms. This changes the geometry of the problem which we characterize via an information-theoretic lower bound. We introduce two asymptotically optimal algorithms for this setting, one based on the Track-and-Stop method and the other based on a game-theoretic approach. Both these algorithms try to track an optimal allocation based on the lower bound and computed by a weighted projection onto the boundary of a normal cone. Finally, we provide empirical results that validate our bounds and visualize how constraints change the hardness of the problem",
    "checked": true,
    "id": "2b0fc501d8a776263df434df499322c45933359f",
    "semantic_title": "pure exploration in bandits with linear constraints",
    "citation_count": 2,
    "authors": [
      "Emil Carlsson",
      "Debabrota Basu",
      "Fredrik Johansson",
      "Devdatt Dubhashi"
    ]
  },
  "https://proceedings.mlr.press/v238/dean24a.html": {
    "title": "Emergent specialization from participation dynamics and multi-learner retraining",
    "volume": "main",
    "abstract": "Numerous online services are data-driven: the behavior of users affects the system's parameters, and the system's parameters affect the users' experience of the service, which in turn affects the way users may interact with the system. For example, people may choose to use a service only for tasks that already works well, or they may choose to switch to a different service. These adaptations influence the ability of a system to learn about a population of users and tasks in order to improve its performance broadly. In this work, we analyze a class of such dynamics—where users allocate their participation amongst services to reduce the individual risk they experience, and services update their model parameters to reduce the service's risk on their current user population. We refer to these dynamics as \\emph{risk-reducing}, which cover a broad class of common model updates including gradient descent and multiplicative weights. For this general class of dynamics, we show that asymptotically stable equilibria are always segmented, with sub-populations allocated to a single learner. Under mild assumptions, the utilitarian social optimum is a stable equilibrium. In contrast to previous work, which shows that repeated risk minimization can result in representation disparity and high overall loss with a single learner (Hashimoto et al., 2018; Miller et al., 2021), we find that repeated myopic updates with multiple learners lead to better outcomes. We illustrate the phenomena via a simulated example initialized from real data",
    "checked": true,
    "id": "e42a3e626322f3fb46f31d40dacfc5142cdca044",
    "semantic_title": "emergent specialization from participation dynamics and multi-learner retraining",
    "citation_count": 2,
    "authors": [
      "Sarah Dean",
      "Mihaela Curmei",
      "Lillian Ratliff",
      "Jamie Morgenstern",
      "Maryam Fazel"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24b.html": {
    "title": "Optimal Sparse Survival Trees",
    "volume": "main",
    "abstract": "Interpretability is crucial for doctors, hospitals, pharmaceutical companies and biotechnology corporations to analyze and make decisions for high stakes problems that involve human health. Tree-based methods have been widely adopted for survival analysis due to their appealing interpretablility and their ability to capture complex relationships. However, most existing methods to produce survival trees rely on heuristic (or greedy) algorithms, which risk producing sub-optimal models. We present a dynamic-programming-with-bounds approach that finds provably-optimal sparse survival tree models, frequently in only a few seconds",
    "checked": true,
    "id": "360409a49002e741d350c0051eddec6bc1fa896f",
    "semantic_title": "optimal sparse survival trees",
    "citation_count": 0,
    "authors": [
      "Rui Zhang",
      "Rui Xin",
      "Margo Seltzer",
      "Cynthia Rudin"
    ]
  },
  "https://proceedings.mlr.press/v238/li24d.html": {
    "title": "TenGAN: Pure Transformer Encoders Make an Efficient Discrete GAN for De Novo Molecular Generation",
    "volume": "main",
    "abstract": "Deep generative models for de novo molecular generation using discrete data, such as the simplified molecular-input line-entry system (SMILES) strings, have attracted widespread attention in drug design. However, training instability often plagues generative adversarial networks (GANs), leading to problems such as mode collapse and low diversity. This study proposes a pure transformer encoder-based GAN (TenGAN) to solve these issues. The generator and discriminator of TenGAN are variants of the transformer encoders and are combined with reinforcement learning (RL) to generate molecules with the desired chemical properties. Besides, data augmentation of the variant SMILES is leveraged for the TenGAN training to learn the semantics and syntax of SMILES strings. Additionally, we introduce an enhanced variant of TenGAN, named Ten(W)GAN, which incorporates mini-batch discrimination and Wasserstein GAN to improve the ability to generate molecules. The experimental results and ablation studies on the QM9 and ZINC datasets showed that the proposed models generated highly valid and novel molecules with the desired chemical properties in a computationally efficient manner",
    "checked": true,
    "id": "4a7e8e7dfab88a4613eff758d74e023c12a73ef1",
    "semantic_title": "tengan: pure transformer encoders make an efficient discrete gan for de novo molecular generation",
    "citation_count": 1,
    "authors": [
      "Chen Li",
      "Yoshihiro Yamanishi"
    ]
  },
  "https://proceedings.mlr.press/v238/yoshikawa24a.html": {
    "title": "Explanation-based Training with Differentiable Insertion/Deletion Metric-aware Regularizers",
    "volume": "main",
    "abstract": "The quality of explanations for the predictions made by complex machine learning predictors is often measured using insertion and deletion metrics, which assess the faithfulness of the explanations, i.e., how accurately the explanations reflect the predictor's behavior. To improve the faithfulness, we propose insertion/deletion metric-aware explanation-based optimization (ID-ExpO), which optimizes differentiable predictors to improve both the insertion and deletion scores of the explanations while maintaining their predictive accuracy. Because the original insertion and deletion metrics are non-differentiable with respect to the explanations and directly unavailable for gradient-based optimization, we extend the metrics so that they are differentiable and use them to formalize insertion and deletion metric-based regularizers. Our experimental results on image and tabular datasets show that the deep neural network-based predictors that are fine-tuned using ID-ExpO enable popular post-hoc explainers to produce more faithful and easier-to-interpret explanations while maintaining high predictive accuracy. The code is available at https://github.com/yuyay/idexpo",
    "checked": true,
    "id": "4b0b320baf8f7d1b2d4c9b252d227116be935970",
    "semantic_title": "explanation-based training with differentiable insertion/deletion metric-aware regularizers",
    "citation_count": 0,
    "authors": [
      "Yuya Yoshikawa",
      "Tomoharu Iwata"
    ]
  },
  "https://proceedings.mlr.press/v238/baudry24a.html": {
    "title": "Multi-armed bandits with guaranteed revenue per arm",
    "volume": "main",
    "abstract": "We consider a Multi-Armed Bandit problem with covering constraints, where the primary goal is to ensure that each arm receives a minimum expected reward while maximizing the total cumulative reward. In this scenario, the optimal policy then belongs to some unknown feasible set. Unlike much of the existing literature, we do not assume the presence of a safe policy or a feasibility margin, which hinders the exclusive use of conservative approaches. Consequently, we propose and analyze an algorithm that switches between pessimism and optimism in the face of uncertainty. We prove both precise problem-dependent and problem-independent bounds, demonstrating that our algorithm achieves the best of the two approaches—depending on the presence or absence of a feasibility margin—in terms of constraint violation guarantees. Furthermore, our results indicate that playing greedily on the constraints actually outperforms pessimism when considering long-term violations rather than violations on a per-round basis",
    "checked": true,
    "id": "62eafea540141083378a1f83d3d8d42f0289539a",
    "semantic_title": "multi-armed bandits with guaranteed revenue per arm",
    "citation_count": 0,
    "authors": [
      "Dorian Baudry",
      "Nadav Merlis",
      "Mathieu Benjamin Molina",
      "Hugo Richard",
      "Vianney Perchet"
    ]
  },
  "https://proceedings.mlr.press/v238/richard24a.html": {
    "title": "Constant or Logarithmic Regret in Asynchronous Multiplayer Bandits with Limited Communication",
    "volume": "main",
    "abstract": "Multiplayer bandits have recently garnered significant attention due to their relevance in cognitive radio networks. While the existing body of literature predominantly focuses on synchronous players, real-world radio networks, such as those in IoT applications, often feature asynchronous (i.e., randomly activated) devices. This highlights the need for addressing the more challenging asynchronous multiplayer bandits problem. Our first result shows that a natural extension of UCB achieves a minimax regret of $\\mathcal{O}(\\sqrt{T\\log(T)})$ in the centralized setting. More significantly, we introduce Cautious Greedy, which uses $\\mathcal{O}(\\log(T))$ communications and whose instance-dependent regret is constant if the optimal policy assigns at least one player to each arm (a situation proven to occur when arm means are sufficiently close). Otherwise, the regret is, as usual, $\\log(T)$ times the sum of some inverse sub-optimality gaps. We substantiate the optimality of Cautious Greedy through lower-bound analysis based on data-dependent terms. Therefore, we establish a strong baseline for asynchronous multiplayer bandits, at least with $\\mathcal{O}(\\log(T))$ communications",
    "checked": true,
    "id": "b1ef4b93d38ddc77995383e9f99b9504144f5620",
    "semantic_title": "constant or logarithmic regret in asynchronous multiplayer bandits with limited communication",
    "citation_count": 0,
    "authors": [
      "Hugo Richard",
      "Etienne Boursier",
      "Vianney Perchet"
    ]
  },
  "https://proceedings.mlr.press/v238/savvides24a.html": {
    "title": "Error bounds for any regression model using Gaussian processes with gradient information",
    "volume": "main",
    "abstract": "We provide an upper bound for the expected quadratic loss on new data for any regression model. We derive the bound by modelling the underlying function by a Gaussian process (GP). Instead of a single kernel or family of kernels of the same form, we consider all GPs with translation-invariant and continuously twice differentiable kernels having a bounded signal variance and prior covariance of the gradient. To obtain a bound for the expected posterior loss, we present bounds for the posterior variance and squared bias. The squared bias bound depends on the regression model used, which can be arbitrary and not based on GPs. The bounds scale well with data size, in contrast to computing the GP posterior by a Cholesky factorisation of a large matrix. More importantly, our bounds do not require strong prior knowledge as we do not specify the exact kernel form. We validate our theoretical findings by numerical experiments and show that the bounds have applications in uncertainty estimation and concept drift detection",
    "checked": true,
    "id": "c975d41eb6b7e16d0e3c3740981ac44dc6679a2e",
    "semantic_title": "error bounds for any regression model using gaussian processes with gradient information",
    "citation_count": 0,
    "authors": [
      "Rafael Savvides",
      "Hoang Phuc Hau Luu",
      "Kai Puolamäki"
    ]
  },
  "https://proceedings.mlr.press/v238/guimera-cuevas24a.html": {
    "title": "Robust Non-linear Normalization of Heterogeneous Feature Distributions with Adaptive Tanh-Estimators",
    "volume": "main",
    "abstract": "Feature normalization is a crucial step in machine learning that scales numerical values to improve model effectiveness. Noisy or impure datasets can pose a challenge for traditional normalization methods as they may contain outliers that violate statistical assumptions, leading to reduced model performance and increased unpredictability. Non-linear Tanh-Estimators (TE) have been found to provide robust feature normalization, but their fixed scaling factor may not be appropriate for all distributions of feature values. This work presents a refinement to the TE that employs the Wasserstein distance to adaptively estimate the optimal scaling factor for each feature individually against a specified target distribution. The results demonstrate that this adaptive approach can outperform the current TE method in the literature in terms of convergence speed by enabling better initial training starts, thus reducing or eliminating the need to re-adjust model weights during early training phases due to inadequately scaled features. Empirical evaluation was done on synthetic data, standard toy computer vision datasets, and a real-world numeric tabular dataset",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felip Guimerà Cuevas",
      "Helmut Schmid"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24a.html": {
    "title": "Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes",
    "volume": "main",
    "abstract": "We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate that ISAHP is capable of discovering complex instance-level causal structures that cannot be handled by classical models. We also show that ISAHP achieves state-of-the-art performance in proxy tasks involving type-level causal discovery and instance-level event type prediction",
    "checked": true,
    "id": "5fcd8a50ae8ad279ebfe2566956815155b32a891",
    "semantic_title": "learning granger causality from instance-wise self-attentive hawkes processes",
    "citation_count": 0,
    "authors": [
      "Dongxia Wu",
      "Tsuyoshi Ide",
      "Georgios Kollias",
      "Jiri Navratil",
      "Aurelie Lozano",
      "Naoki Abe",
      "Yian Ma",
      "Rose Yu"
    ]
  },
  "https://proceedings.mlr.press/v238/hands24a.html": {
    "title": "P-tensors: a General Framework for Higher Order Message Passing in Subgraph Neural Networks",
    "volume": "main",
    "abstract": "Several recent papers have proposed increasing the expressiveness of graph neural networks by exploiting subgraphs or other topological structures. In parallel, researchers have investigated higher order permutation equivariant networks. In this paper we tie these two threads together by providing a general framework for higher order permutation equivariant message passing in subgraph neural networks. Our exposition hinges on so-called $P$-tensors, which provide a simple way to define the most general form of permutation equivariant message passing in this category of networks. We show that this paradigm can achieve state-of-the-art performance on benchmark molecular datasets",
    "checked": true,
    "id": "d795f9eac83f783151c7a610620c271433d2953d",
    "semantic_title": "p-tensors: a general framework for higher order message passing in subgraph neural networks",
    "citation_count": 0,
    "authors": [
      "Andrew R. Hands",
      "Tianyi Sun",
      "Risi Kondor"
    ]
  },
  "https://proceedings.mlr.press/v238/saha24a.html": {
    "title": "Faster Convergence with MultiWay Preferences",
    "volume": "main",
    "abstract": "We address the problem of convex optimization with preference feedback, where the goal is to minimize a convex function given a weaker form of comparison queries. Each query consists of two points and the dueling feedback returns a (noisy) single-bit binary comparison of the function values of the two queried points. Here we consider the sign-function-based comparison feedback model and analyze the convergence rates with batched and multiway (argmin of a set queried points) comparisons. Our main goal is to understand the improved convergence rates owing to parallelization in sign-feedback-based optimization problems. Our work is the first to study the problem of convex optimization with multiway preferences and analyze the optimal convergence rates. Our first contribution lies in designing efficient algorithms with a convergence rate of $\\smash{\\widetilde O}(\\frac{d}{\\min\\{m,d\\} \\epsilon})$ for $m$-batched preference feedback where the learner can query $m$-pairs in parallel. We next study a $m$-multiway comparison (‘battling') feedback, where the learner can get to see the argmin feedback of $m$-subset of queried points and show a convergence rate of $\\smash{\\widetilde O}(\\frac{d}{ \\min\\{\\log m,d\\}\\epsilon })$. We show further improved convergence rates with an additional assumption of strong convexity. Finally, we also study the convergence lower bounds for batched preferences and multiway feedback optimization showing the optimality of our convergence rates w.r.t. $m$",
    "checked": true,
    "id": "ebd5cee7c0b327360f8ffc2d1f002c88c20a02f0",
    "semantic_title": "faster convergence with multiway preferences",
    "citation_count": 0,
    "authors": [
      "Aadirupa Saha",
      "Vitaly Feldman",
      "Yishay Mansour",
      "Tomer Koren"
    ]
  },
  "https://proceedings.mlr.press/v238/gong24a.html": {
    "title": "Testing Generated Distributions in GANs to Penalize Mode Collapse",
    "volume": "main",
    "abstract": "Mode collapse remains the primary unresolved challenge within generative adversarial networks (GANs). In this work, we introduce an innovative approach that supplements the discriminator by additionally enforcing the similarity between the generated and real distributions. We implement a one-sample test on the generated samples and employ the resulting test statistic to penalize deviations from the real distribution. Our method encompasses a practical strategy to estimate distributions, compute the test statistic via a differentiable function, and seamlessly incorporate test outcomes into the training objective. Crucially, our approach preserves the convergence and theoretical integrity of GANs, as the introduced constraint represents a requisite condition for optimizing the generator training objective. Notably, our method circumvents reliance on regularization or network modules, enhancing compatibility and facilitating its practical application. Empirical evaluations on diverse public datasets validate the efficacy of our proposed approach",
    "checked": true,
    "id": "b601bbbd465c99af0217d52058f824e543d32523",
    "semantic_title": "testing generated distributions in gans to penalize mode collapse",
    "citation_count": 0,
    "authors": [
      "Yanxiang Gong",
      "Zhiwei Xie",
      "Mei Xie",
      "Xin Ma"
    ]
  },
  "https://proceedings.mlr.press/v238/cabannes24a.html": {
    "title": "The Galerkin method beats Graph-Based Approaches for Spectral Algorithms",
    "volume": "main",
    "abstract": "Historically, the machine learning community has derived spectral decompositions from graph-based approaches. We break with this approach and prove the statistical and computational superiority of the Galerkin method, which consists in restricting the study to a small set of test functions. In particular, we introduce implementation tricks to deal with differential operators in large dimensions with structured kernels. Finally, we extend on the core principles beyond our approach to apply them to non-linear spaces of functions, such as the ones parameterized by deep neural networks, through loss-based optimization procedures",
    "checked": true,
    "id": "c6fa9d1ec3ac195c5020c552c135b926b7713ba4",
    "semantic_title": "the galerkin method beats graph-based approaches for spectral algorithms",
    "citation_count": 2,
    "authors": [
      "Vivien A. Cabannes",
      "Francis Bach"
    ]
  },
  "https://proceedings.mlr.press/v238/sima24a.html": {
    "title": "Online Distribution Learning with Local Privacy Constraints",
    "volume": "main",
    "abstract": "We study the problem of online conditional distribution estimation with \\emph{unbounded} label sets under local differential privacy. The problem may be succinctly stated as follows. Let $\\mathcal{F}$ be a distribution-valued function class with an unbounded label set. Our aim is to estimate an \\emph{unknown} function $f\\in \\mathcal{F}$ in an online fashion. More precisely, at time $t$, given a sample ${\\mathbf{x}}_t$, we generate an estimate of $f({\\mathbf{x}}_t)$ using only a \\emph{privatized} version of the true \\emph{labels} sampled from $f({\\mathbf{x}}_t)$. The objective is to minimize the cumulative KL-risk of a finite horizon $T$. We show that under $(\\epsilon,0)$-local differential privacy for the labels, the KL-risk equals $\\tilde{\\Theta}(\\frac{1}{\\epsilon}\\sqrt{KT}),$ up to poly-logarithmic factors, where $K=|\\mathcal{F}|$. This result significantly differs from the $\\tilde{\\Theta}(\\sqrt{T\\log K})$ bound derived in Wu et al., (2023a) for \\emph{bounded} label sets. As a side-result, our approach recovers a nearly tight upper bound for the hypothesis selection problem of Gopi et al., (2020), which has only been established for the \\emph{batch} setting",
    "checked": true,
    "id": "076be151b0912594c601504da397759a9d60eedd",
    "semantic_title": "online distribution learning with local privacy constraints",
    "citation_count": 0,
    "authors": [
      "Jin Sima",
      "Changlong Wu",
      "Olgica Milenkovic",
      "Wojciech Szpankowski"
    ]
  },
  "https://proceedings.mlr.press/v238/kyu-kwon24a.html": {
    "title": "Minimax optimal density estimation using a shallow generative model with a one-dimensional latent variable",
    "volume": "main",
    "abstract": "A deep generative model yields an implicit estimator for the unknown distribution or density function of the observation. This paper investigates some statistical properties of the implicit density estimator pursued by VAE-type methods from a nonparametric density estimation framework. More specifically, we obtain convergence rates of the VAE-type density estimator under the assumption that the underlying true density function belongs to a locally Holder class. Remarkably, a near minimax optimal rate with respect to the Hellinger metric can be achieved by the simplest network architecture, a shallow generative model with a one-dimensional latent variable",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyeok Kyu Kwon",
      "Minwoo Chae"
    ]
  },
  "https://proceedings.mlr.press/v238/ananthakrishnan24a.html": {
    "title": "Delegating Data Collection in Decentralized Machine Learning",
    "volume": "main",
    "abstract": "Motivated by the emergence of decentralized machine learning (ML) ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental information asymmetries that arise in decentralized ML: uncertainty in the assessment of model quality and uncertainty regarding the optimal performance of any model. We show that a principal can cope with such asymmetry via simple linear contracts that achieve $1-1/\\epsilon$ fraction of the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract. We also analyze the optimal utility and linear contracts for the more complex setting of multiple interactions",
    "checked": true,
    "id": "a34bad7b02ba6572c020b4a0347872153392ec17",
    "semantic_title": "delegating data collection in decentralized machine learning",
    "citation_count": 3,
    "authors": [
      "Nivasini Ananthakrishnan",
      "Stephen Bates",
      "Michael Jordan",
      "Nika Haghtalab"
    ]
  },
  "https://proceedings.mlr.press/v238/isik24a.html": {
    "title": "Adaptive Compression in Federated Learning via Side Information",
    "volume": "main",
    "abstract": "The high communication cost of sending model updates from the clients to the server is a significant bottleneck for scalable federated learning (FL). Among existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been achieved using stochastic compression methods – in which the client n sends a sample from a client-only probability distribution $q_{\\phi^{(n)}}$, and the server estimates the mean of the clients' distributions using these samples. However, such methods do not take full advantage of the FL setup where the server, throughout the training process, has side information in the form of a global distribution $p_{\\theta}$ that is close to the client-only distribution $q_{\\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit this \\emph{closeness} between the clients' distributions $q_{\\phi^{(n)}}$'s and the side information $p_{\\theta}$ at the server, and propose a framework that requires approximately $D_{KL}(q_{\\phi^{(n)}}|| p_{\\theta})$ bits of communication. We show that our method can be integrated into many existing stochastic compression frameworks to attain the same (and often higher) test accuracy with up to 82 times smaller bitrate than the prior work – corresponding to 2,650 times overall compression",
    "checked": true,
    "id": "82b0100ee958fa6d831391cb4aa7b1bc8042a13b",
    "semantic_title": "adaptive compression in federated learning via side information",
    "citation_count": 4,
    "authors": [
      "Berivan Isik",
      "Francesco Pase",
      "Deniz Gunduz",
      "Sanmi Koyejo",
      "Tsachy Weissman",
      "Michele Zorzi"
    ]
  },
  "https://proceedings.mlr.press/v238/adachi24b.html": {
    "title": "Adaptive Batch Sizes for Active Learning: A Probabilistic Numerics Approach",
    "volume": "main",
    "abstract": "Active learning parallelization is widely used, but typically relies on fixing the batch size throughout experimentation. This fixed approach is inefficient because of a dynamic trade-off between cost and speed—larger batches are more costly, smaller batches lead to slower wall-clock run-times—and the trade-off may change over the run (larger batches are often preferable earlier). To address this trade-off, we propose a novel Probabilistic Numerics framework that adaptively changes batch sizes. By framing batch selection as a quadrature task, our integration-error-aware algorithm facilitates the automatic tuning of batch sizes to meet predefined quadrature precision objectives, akin to how typical optimizers terminate based on convergence thresholds. This approach obviates the necessity for exhaustive searches across all potential batch sizes. We also extend this to scenarios with constrained active learning and constrained optimization, interpreting constraint violations as reductions in the precision requirement, to subsequently adapt batch construction. Through extensive experiments, we demonstrate that our approach significantly enhances learning efficiency and flexibility in diverse Bayesian batch active learning and Bayesian optimization applications",
    "checked": true,
    "id": "a420222563da4ed3412ce3f453ec0b99bb3ca4db",
    "semantic_title": "adaptive batch sizes for active learning: a probabilistic numerics approach",
    "citation_count": 4,
    "authors": [
      "Masaki Adachi",
      "Satoshi Hayakawa",
      "Martin Jørgensen",
      "Xingchen Wan",
      "Vu Nguyen",
      "Harald Oberhauser",
      "Michael A. Osborne"
    ]
  },
  "https://proceedings.mlr.press/v238/adachi24a.html": {
    "title": "Looping in the Human: Collaborative and Explainable Bayesian Optimization",
    "volume": "main",
    "abstract": "Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to a vanilla Bayesian optimization. We validate CoExBO's efficacy through human-AI teaming experiments in lithium-ion battery design, highlighting substantial improvements over conventional methods. Code is available https://github.com/ma921/CoExBO",
    "checked": true,
    "id": "e74aae28c1295639d0c4f89b6778d978f0cff9d3",
    "semantic_title": "looping in the human: collaborative and explainable bayesian optimization",
    "citation_count": 6,
    "authors": [
      "Masaki Adachi",
      "Brady Planden",
      "David Howey",
      "Michael A. Osborne",
      "Sebastian Orbell",
      "Natalia Ares",
      "Krikamol Muandet",
      "Siu Lun Chau"
    ]
  },
  "https://proceedings.mlr.press/v238/chatterjee24a.html": {
    "title": "Efficient Quantum Agnostic Improper Learning of Decision Trees",
    "volume": "main",
    "abstract": "The agnostic setting is the hardest generalization of the PAC model since it is akin to learning with adversarial noise. In this paper, we give a poly $(n, t, 1/\\epsilon)$ quantum algorithm for learning size $t$ decision trees over $n$-bit inputs with uniform marginal over instances, in the agnostic setting, without membership queries (MQ). This is the first algorithm (classical or quantum) for efficiently learning decision trees without MQ. First, we construct a quantum agnostic weak learner by designing a quantum variant of the classical Goldreich-Levin algorithm that works with strongly biased function oracles. Next, we show how to quantize the agnostic boosting algorithm by Kalai and Kanade (2009) to obtain the first efficient quantum agnostic boosting algorithm (that has a polynomial speedup over existing adaptive quantum boosting algorithms). We then use the quantum agnostic boosting algorithm to boost the weak quantum agnostic learner constructed previously to obtain a quantum agnostic learner for decision trees. Using the above framework, we also give quantum decision tree learning algorithms without MQ in weaker noise models",
    "checked": true,
    "id": "d787681327d1f1d44ab608e4505592d386e14535",
    "semantic_title": "efficient quantum agnostic improper learning of decision trees",
    "citation_count": 1,
    "authors": [
      "Sagnik Chatterjee",
      "Tharrmashastha SAPV",
      "Debajyoti Bera"
    ]
  },
  "https://proceedings.mlr.press/v238/bilaj24a.html": {
    "title": "Meta Learning in Bandits within shared affine Subspaces",
    "volume": "main",
    "abstract": "We study the problem of meta-learning several contextual stochastic bandits tasks by leveraging their concentration around a low dimensional affine subspace, which we learn via online principal component analysis to reduce the expected regret over the encountered bandits. We propose and theoretically analyze two strategies that solve the problem: One based on the principle of optimism in the face of uncertainty and the other via Thompson sampling. Our framework is generic and includes previously proposed approaches as special cases. Besides, the empirical results show that our methods significantly reduce the regret on several bandit tasks",
    "checked": true,
    "id": "43b4c6e0e60d5b6ba7dc481755e114e4eb40ddbc",
    "semantic_title": "meta learning in bandits within shared affine subspaces",
    "citation_count": 1,
    "authors": [
      "Steven Bilaj",
      "Sofien Dhouib",
      "Setareh Maghsudi"
    ]
  },
  "https://proceedings.mlr.press/v238/braun24a.html": {
    "title": "VEC-SBM: Optimal Community Detection with Vectorial Edges Covariates",
    "volume": "main",
    "abstract": "Social networks are often associated with rich side information, such as texts and images. While numerous methods have been developed to identify communities from pairwise interactions, they usually ignore such side information. In this work, we study an extension of the Stochastic Block Model (SBM), a widely used statistical framework for community detection, that integrates vectorial edges covariates: the Vectorial Edges Covariates Stochastic Block Model (VEC-SBM). We propose a novel algorithm based on iterative refinement techniques and show that it optimally recovers the latent communities under the VEC-SBM. Furthermore, we rigorously assess the added value of leveraging edge's side information in the community detection process. We complement our theoretical results with numerical experiments on synthetic and semi-synthetic data",
    "checked": true,
    "id": "27c134900d10436cbd0025ea224b95c5d3594b36",
    "semantic_title": "vec-sbm: optimal community detection with vectorial edges covariates",
    "citation_count": 0,
    "authors": [
      "Guillaume Braun",
      "Masashi Sugiyama"
    ]
  },
  "https://proceedings.mlr.press/v238/zhu24a.html": {
    "title": "Robust Offline Reinforcement Learning with Heavy-Tailed Rewards",
    "volume": "main",
    "abstract": "This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions. The implementation of the proposal is available at \\url{https://github.com/Mamba413/ROOM}",
    "checked": true,
    "id": "179addc882c4c977215a0125651119e8cefa4ccc",
    "semantic_title": "robust offline reinforcement learning with heavy-tailed rewards",
    "citation_count": 0,
    "authors": [
      "Jin Zhu",
      "Runzhe Wan",
      "Zhengling Qi",
      "Shikai Luo",
      "Chengchun Shi"
    ]
  },
  "https://proceedings.mlr.press/v238/fokkema24a.html": {
    "title": "The Risks of Recourse in Binary Classification",
    "volume": "main",
    "abstract": "Algorithmic recourse provides explanations that help users overturn an unfavorable decision by a machine learning system. But so far very little attention has been paid to whether providing recourse is beneficial or not. We introduce an abstract learning-theoretic framework that compares the risks (i.e., expected losses) for classification with and without algorithmic recourse. This allows us to answer the question of when providing recourse is beneficial or harmful at the population level. Surprisingly, we find that there are many plausible scenarios in which providing recourse turns out to be harmful, because it pushes users to regions of higher class uncertainty and therefore leads to more mistakes. We further study whether the party deploying the classifier has an incentive to strategize in anticipation of having to provide recourse, and we find that sometimes they do, to the detriment of their users. Providing algorithmic recourse may therefore also be harmful at the systemic level. We confirm our theoretical findings in experiments on simulated and real-world data. All in all, we conclude that the current concept of algorithmic recourse is not reliably beneficial, and therefore requires rethinking",
    "checked": true,
    "id": "a69f15c4659b8c69b9b3446c3cc45e27d3e10251",
    "semantic_title": "the risks of recourse in binary classification",
    "citation_count": 1,
    "authors": [
      "Hidde Fokkema",
      "Damien Garreau",
      "Tim van Erven"
    ]
  },
  "https://proceedings.mlr.press/v238/li24e.html": {
    "title": "Prior-dependent analysis of posterior sampling reinforcement learning with function approximation",
    "volume": "main",
    "abstract": "This work advances randomized exploration in reinforcement learning (RL) with function approximation modeled by linear mixture MDPs. We establish the first prior-dependent Bayesian regret bound for RL with function approximation; and refine the Bayesian regret analysis for posterior sampling reinforcement learning (PSRL), presenting an upper bound of $\\tilde{\\mathcal{O}}(d\\sqrt{H^3 T \\log T})$, where $d$ represents the dimensionality of the transition kernel, $H$ the planning horizon, and $T$ the total number of interactions. This signifies a methodological enhancement by optimizing the $\\mathcal{O}(\\sqrt{\\log T})$ factor over the previous benchmark (Osband and Van Roy, 2014) specified to linear mixture MDPs. Our approach, leveraging a value-targeted model learning perspective, introduces a decoupling argument and a variance reduction technique, moving beyond traditional analyses reliant on confidence sets and concentration inequalities to formalize Bayesian regret bounds more effectively",
    "checked": true,
    "id": "dd089f7e75f8e7fc12b0e8051b328fa6779d9632",
    "semantic_title": "prior-dependent analysis of posterior sampling reinforcement learning with function approximation",
    "citation_count": 0,
    "authors": [
      "Yingru Li",
      "Zhiquan Luo"
    ]
  },
  "https://proceedings.mlr.press/v238/dalirrooyfard24a.html": {
    "title": "Graph Partitioning with a Move Budget",
    "volume": "main",
    "abstract": "In many real world networks, there already exists a (not necessarily optimal) $k$-partitioning of the network. Oftentimes, for such networks, one aims to find a $k$-partitioning with a smaller cut value by moving only a few nodes across partitions. The number of nodes that can be moved across partitions is often a constraint forced by budgetary limitations. Motivated by such real-world applications, we introduce and study the $r$-move $k$-partitioning problem, a natural variant of the Multiway cut problem. Given a graph, a set of $k$ terminals and an initial partitioning of the graph, the $r$-move $k$-partitioning problem aims to find a $k$-partitioning with the minimum-weighted cut among all the $k$-partitionings that can be obtained by moving at most $r$ non-terminal nodes to partitions different from their initial ones. Our main result is a polynomial time $3(r+1)$ approximation algorithm for this problem. We further show that this problem is $W[1]$-hard, and give an FPTAS for when $r$ is a small constant",
    "checked": true,
    "id": "413f566badb404c45109ab07c1b49c645fbfa12b",
    "semantic_title": "graph partitioning with a move budget",
    "citation_count": 0,
    "authors": [
      "Mina Dalirrooyfard",
      "Elaheh Fata",
      "Majid Behbahani",
      "Yuriy Nevmyvaka"
    ]
  },
  "https://proceedings.mlr.press/v238/limnios24a.html": {
    "title": "On Ranking-based Tests of Independence",
    "volume": "main",
    "abstract": "In this paper we develop a novel nonparametric framework to test the independence of two random variables $X$ and $Y$ with unknown respective marginals $H(dx)$ and $G(dy)$ and joint distribution $F(dxdy)$, based on Receiver Operating Characteristic (ROC) analysis and bipartite ranking. The rationale behind our approach relies on the fact that, the independence hypothesis $\\mathcal{H}_0$ is necessarily false as soon as the optimal scoring function related to the pair of distributions $(H\\otimes G,;{F})$, obtained from a bipartite ranking algorithm, has a ROC curve that deviates from the main diagonal of the unit square. We consider a wide class of rank statistics encompassing many ways of deviating from the diagonal in the ROC space to build tests of independence. Beyond its great flexibility, this new method has theoretical properties that far surpass those of its competitors. Nonasymptotic bounds for the two types of testing errors are established. From an empirical perspective, the novel procedure we promote in this paper exhibits a remarkable ability to detect small departures, of various types, from the null assumption $\\mathcal{H}_0$, even in high dimension, as supported by the numerical experiments presented here",
    "checked": true,
    "id": "c40b4625730bfcc6ee9e30dd6aa136152256f8f6",
    "semantic_title": "on ranking-based tests of independence",
    "citation_count": 0,
    "authors": [
      "Myrto Limnios",
      "Stéphan Clémençon"
    ]
  },
  "https://proceedings.mlr.press/v238/sebbouh24a.html": {
    "title": "Structured Transforms Across Spaces with Cost-Regularized Optimal Transport",
    "volume": "main",
    "abstract": "Matching a source to a target probability measure is often solved by instantiating a linear optimal transport (OT) problem, parameterized by a ground cost function that quantifies discrepancy between points. When these measures live in the same metric space, the ground cost often defaults to its distance. When instantiated across two different spaces, however, choosing that cost in the absence of aligned data is a conundrum. As a result, practitioners often resort to solving instead a quadratic Gromow-Wasserstein (GW) problem. We exploit in this work a parallel between GW and cost-regularized OT, the regularized minimization of a linear OT objective parameterized by a ground cost. We use this cost-regularized formulation to match measures across two different Euclidean spaces, where the cost is evaluated between transformed source points and target points. We show that several quadratic OT problems fall in this category, and consider enforcing structure in linear transform (e.g., sparsity), by introducing structure-inducing regularizers. We provide a proximal algorithm to extract such transforms from unaligned data, and demonstrate its applicability to single-cell spatial transcriptomics/multiomics matching tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Othmane Sebbouh",
      "Marco Cuturi",
      "Gabriel Peyré"
    ]
  },
  "https://proceedings.mlr.press/v238/odonnat24a.html": {
    "title": "Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias",
    "volume": "main",
    "abstract": "Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, \\texttt{softmax} prediction probabilities are often used as a confidence measure, although they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraints. To address this issue, we propose a novel confidence measure, called $\\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on classification datasets of various data modalities. The code is available at https://github.com/ambroiseodt/tsim",
    "checked": true,
    "id": "df51bc92af21e51b7a13b340722a9a0fff39a342",
    "semantic_title": "leveraging ensemble diversity for robust self-training in the presence of sample selection bias",
    "citation_count": 5,
    "authors": [
      "Ambroise Odonnat",
      "Vasilii Feofanov",
      "Ievgen Redko"
    ]
  },
  "https://proceedings.mlr.press/v238/gupta24a.html": {
    "title": "Clustering Items From Adaptively Collected Inconsistent Feedback",
    "volume": "main",
    "abstract": "We study clustering in a query-based model where the learner can repeatedly query an oracle to determine if two items belong to the same cluster. However, these queries are costly and the oracle's responses are marred by inconsistency and noise. The learner's goal is to adaptively make a small number of queries and return the correct clusters for \\emph{all} $n$ items with high confidence. We develop efficient algorithms for this problem using the sequential hypothesis testing framework. We derive high probability upper bounds on their sample complexity (the number of queries they make) and complement this analysis with an information-theoretic lower bound. In particular, we show that our algorithm for two clusters is nearly optimal when the oracle's error probability is a constant. Our experiments verify these findings and highlight a few shortcomings of our algorithms. Namely, we show that their sample complexity deviates from the lower bound when the error probability of the oracle depends on $n$. We suggest an improvement based on a more efficient sequential hypothesis test and demonstrate it empirically",
    "checked": true,
    "id": "ab6a4591f3a4f17cc61ec3151781913d19016833",
    "semantic_title": "clustering items from adaptively collected inconsistent feedback",
    "citation_count": 1,
    "authors": [
      "Shubham Gupta",
      "Peter W J Staar",
      "Christian de Sainte Marie"
    ]
  },
  "https://proceedings.mlr.press/v238/hegazy24a.html": {
    "title": "Compression with Exact Error Distribution for Federated Learning",
    "volume": "main",
    "abstract": "Compression schemes have been extensively used in Federated Learning (FL) to reduce the communication cost of distributed learning. While most approaches rely on a bounded variance assumption of the noise produced by the compressor, this paper investigates the use of compression and aggregation schemes that produce a specific error distribution, e.g., Gaussian or Laplace, on the aggregated data. We present and analyze different aggregation schemes based on layered quantizers achieving exact error distribution. We provide different methods to leverage the proposed compression schemes to obtain compression-for-free in differential privacy applications. Our general compression methods can recover and improve standard FL schemes with Gaussian perturbations such as Langevin dynamics and randomized smoothing",
    "checked": true,
    "id": "ebd8202d9b2ab5a4ea458a1062fe7a703cc17ab6",
    "semantic_title": "compression with exact error distribution for federated learning",
    "citation_count": 4,
    "authors": [
      "Mahmoud Hegazy",
      "Rémi Leluc",
      "Cheuk Ting Li",
      "Aymeric Dieuleveut"
    ]
  },
  "https://proceedings.mlr.press/v238/pandeva24a.html": {
    "title": "Deep anytime-valid hypothesis testing",
    "volume": "main",
    "abstract": "We propose a general framework for constructing powerful, sequential hypothesis tests for a large class of nonparametric testing problems. The null hypothesis for these problems is defined in an abstract form using the action of two known operators on the data distribution. This abstraction allows for a unified treatment of several classical tasks, such as two-sample testing, independence testing, and conditional-independence testing, as well as modern problems, such as testing for adversarial robustness of machine learning (ML) models. Our proposed framework has the following advantages over classical batch tests: 1) it continuously monitors online data streams and efficiently aggregates evidence against the null, 2) it provides tight control over the type I error without the need for multiple testing correction, 3) it adapts the sample size requirement to the unknown hardness of the problem. We develop a principled approach of leveraging the representation capability of ML models within the testing-by-betting framework, a game-theoretic approach for designing sequential tests. Empirical results on synthetic and real-world datasets demonstrate that tests instantiated using our general framework are competitive against specialized baselines on several tasks",
    "checked": true,
    "id": "6a59a8008852236c06ebf1739809d45ec3261f48",
    "semantic_title": "deep anytime-valid hypothesis testing",
    "citation_count": 0,
    "authors": [
      "Teodora Pandeva",
      "Patrick Forré",
      "Aaditya Ramdas",
      "Shubhanshu Shekhar"
    ]
  },
  "https://proceedings.mlr.press/v238/blaser24a.html": {
    "title": "Federated Linear Contextual Bandits with Heterogeneous Clients",
    "volume": "main",
    "abstract": "The demand for collaborative and private bandit learning across multiple agents is surging due to the growing quantity of data generated from distributed systems. Federated bandit learning has emerged as a promising framework for private, efficient, and decentralized online learning. However, almost all previous works rely on strong assumptions of client homogeneity, i.e., all participating clients shall share the same bandit model; otherwise, they all would suffer linear regret. This greatly restricts the application of federated bandit learning in practice. In this work, we introduce a new approach for federated bandits for heterogeneous clients, which clusters clients for collaborative bandit learning under the federated learning setting. Our proposed algorithm achieves non-trivial sub-linear regret and communication cost for all clients, subject to the communication protocol under federated learning that at anytime only one model can be shared by the server",
    "checked": true,
    "id": "c0f7c58216f357c4215a481b39d63957fb9c4e4f",
    "semantic_title": "federated linear contextual bandits with heterogeneous clients",
    "citation_count": 0,
    "authors": [
      "Ethan Blaser",
      "Chuanhao Li",
      "Hongning Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/vu-tran24a.html": {
    "title": "LEDetection: A Simple Framework for Semi-Supervised Few-Shot Object Detection",
    "volume": "main",
    "abstract": "Few-shot object detection (FSOD) is a challenging problem aimed at detecting novel concepts from few exemplars. Existing approaches to FSOD all assume abundant base labels to adapt to novel objects. This paper studies the new task of semi-supervised FSOD by considering a realistic scenario in which both base and novel labels are simultaneously scarce. We explore the utility of unlabeled data within our proposed label-efficient detection framework and discover its remarkable ability to boost semi-supervised FSOD by way of region proposals. Motivated by this finding, we introduce SoftER Teacher, a robust detector combining pseudo-labeling with consistency learning on region proposals, to harness unlabeled data for improved FSOD without relying on abundant labels. Rigorous experiments show that SoftER Teacher surpasses the novel performance of a strong supervised detector using only 10% of required base labels, without catastrophic forgetting observed in prior approaches. Our work also sheds light on a potential relationship between semi-supervised and few-shot detection suggesting that a stronger semi-supervised detector leads to a more effective few-shot detector",
    "checked": true,
    "id": "e9dc60acbf043116888603c35913f70b2386ebbf",
    "semantic_title": "ledetection: a simple framework for semi-supervised few-shot object detection",
    "citation_count": 0,
    "authors": [
      "Phi Vu Tran"
    ]
  },
  "https://proceedings.mlr.press/v238/islamov24a.html": {
    "title": "AsGrad: A Sharp Unified Analysis of Asynchronous-SGD Algorithms",
    "volume": "main",
    "abstract": "We analyze asynchronous-type algorithms for distributed SGD in the heterogeneous setting, where each worker has its own computation and communication speeds, as well as data distribution. In these algorithms, workers compute possibly stale and stochastic gradients associated with their local data at some iteration back in history and then return those gradients to the server without synchronizing with other workers. We present a unified convergence theory for non-convex smooth functions in the heterogeneous regime. The proposed analysis provides convergence for pure asynchronous SGD and its various modifications. Moreover, our theory explains what affects the convergence rate and what can be done to improve the performance of asynchronous algorithms. In particular, we introduce a novel asynchronous method based on worker shuffling. As a by-product of our analysis, we also demonstrate convergence guarantees for gradient-type algorithms such as SGD with random reshuffling and shuffle-once mini-batch SGD. The derived rates match the best-known results for those algorithms, highlighting the tightness of our approach. Finally, our numerical evaluations support theoretical findings and show the good practical performance of our method",
    "checked": true,
    "id": "ed91e54f56a2c9519e164f23e4eb7e531dec1132",
    "semantic_title": "asgrad: a sharp unified analysis of asynchronous-sgd algorithms",
    "citation_count": 6,
    "authors": [
      "Rustem Islamov",
      "Mher Safaryan",
      "Dan Alistarh"
    ]
  },
  "https://proceedings.mlr.press/v238/hutchinson24a.html": {
    "title": "Directional Optimism for Safe Linear Bandits",
    "volume": "main",
    "abstract": "The safe linear bandit problem is a version of the classical stochastic linear bandit problem where the learner's actions must satisfy an uncertain constraint at all rounds. Due its applicability to many real-world settings, this problem has received considerable attention in recent years. By leveraging a novel approach that we call directional optimism, we find that it is possible to achieve improved regret guarantees for both well-separated problem instances and action sets that are finite star convex sets. Furthermore, we propose a novel algorithm for this setting that improves on existing algorithms in terms of empirical performance, while enjoying matching regret guarantees. Lastly, we introduce a generalization of the safe linear bandit setting where the constraints are convex and adapt our algorithms and analyses to this setting by leveraging a novel convex-analysis based approach",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Spencer Hutchinson",
      "Berkay Turan",
      "Mahnoosh Alizadeh"
    ]
  },
  "https://proceedings.mlr.press/v238/cui24a.html": {
    "title": "Theory-guided Message Passing Neural Network for Probabilistic Inference",
    "volume": "main",
    "abstract": "Probabilistic inference can be tackled by minimizing a variational free energy through message passing. To improve performance, neural networks are adopted for message computation. Neural message learning is heuristic and requires strong guidance to perform well. In this work, we propose a {\\em theory-guided message passing neural network} (TMPNN) for probabilistic inference. Inspired by existing work, we consider a generalized Bethe free energy which allows for a learnable variational assumption. Instead of using a black-box neural network for message computation, we utilize a general message equation and introduce a symbolic message function with semantically meaningful parameters. The analytically derived symbolic message function is seamlessly integrated into the MPNN framework, giving rise to the proposed TMPNN. TMPNN is trained using algorithmic supervision without requiring exact inference results. Leveraging the theory-guided symbolic function, TMPNN offers strengthened theoretical guarantees compared to conventional heuristic neural models. It presents a novel contribution by demonstrating its applicability to both MAP and marginal inference tasks, outperforming SOTAs in both cases. Furthermore, TMPNN provides improved generalizability across various graph structures and exhibits enhanced data efficiency",
    "checked": true,
    "id": "bec1205132b8bf0a3abe1dd300ad5171d18ed730",
    "semantic_title": "theory-guided message passing neural network for probabilistic inference",
    "citation_count": 0,
    "authors": [
      "Zijun Cui",
      "Hanjing Wang",
      "Tian Gao",
      "Kartik Talamadupula",
      "Qiang Ji"
    ]
  },
  "https://proceedings.mlr.press/v238/sun24a.html": {
    "title": "Understanding Generalization of Federated Learning via Stability: Heterogeneity Matters",
    "volume": "main",
    "abstract": "Generalization performance is a key metric in evaluating machine learning models when applied to real-world applications. Good generalization indicates the model can predict unseen data correctly when trained under a limited number of data. Federated learning (FL), which has emerged as a popular distributed learning framework, allows multiple devices or clients to train a shared model without violating privacy requirements. While the existing literature has studied extensively the generalization performances of centralized machine learning algorithms, similar analysis in the federated settings is either absent or with very restrictive assumptions on the loss functions. In this paper, we aim to analyze the generalization performances of federated learning by means of algorithmic stability, which measures the change of the output model of an algorithm when perturbing one data point. Three widely-used algorithms are studied, including FedAvg, SCAFFOLD, and FedProx, under convex and non-convex loss functions. Our analysis shows that the generalization performances of models trained by these three algorithms are closely related to the heterogeneity of clients' datasets as well as the convergence behaviors of the algorithms. Particularly, in the i.i.d. setting, our results recover the classical results of stochastic gradient descent (SGD)",
    "checked": true,
    "id": "d66227cfab0c27fa759b4000d37643ac55af8eab",
    "semantic_title": "understanding generalization of federated learning via stability: heterogeneity matters",
    "citation_count": 5,
    "authors": [
      "Zhenyu Sun",
      "Xiaochun Niu",
      "Ermin Wei"
    ]
  },
  "https://proceedings.mlr.press/v238/li24f.html": {
    "title": "Mechanics of Next Token Prediction with Self-Attention",
    "volume": "main",
    "abstract": "Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: What does a single self-attention layer learn from next-token prediction? We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: (1) Hard retrieval: Given input sequence, self-attention precisely selects the high-priority input tokens associated with the last input token. (2) Soft composition: It then creates a convex combination of the high-priority tokens from which the next token can be sampled. Under suitable conditions, we rigorously characterize these mechanics through a directed graph over tokens extracted from the training data. We prove that gradient descent implicitly discovers the strongly-connected components (SCC) of this graph and self-attention learns to retrieve the tokens that belong to the highest-priority SCC available in the context window. Our theory relies on decomposing the model weights into a directional component and a finite component that correspond to hard retrieval and soft composition steps respectively. This also formalizes a related implicit bias formula conjectured in [Tarzanagh et al. 2023]. We hope that these findings shed light on how self-attention processes sequential data and pave the path toward demystifying more complex architectures",
    "checked": true,
    "id": "24a2468a1a16d6c332efc44be90854e4f748eeca",
    "semantic_title": "mechanics of next token prediction with self-attention",
    "citation_count": 7,
    "authors": [
      "Yingcong Li",
      "Yixiao Huang",
      "Muhammed E. Ildiz",
      "Ankit Singh Rawat",
      "Samet Oymak"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24c.html": {
    "title": "Generalization Bounds of Nonconvex-(Strongly)-Concave Stochastic Minimax Optimization",
    "volume": "main",
    "abstract": "This paper studies the generalization performance of algorithms for solving nonconvex-(strongly)-concave (NC-SC/NC-C) stochastic minimax optimization measured by the stationarity of primal functions. We first establish algorithm-agnostic generalization bounds via uniform convergence between the empirical minimax problem and the population minimax problem. The sample complexities for achieving $\\epsilon$-generalization are $\\tilde{\\mathcal{O}}(d\\kappa^2\\epsilon^{-2})$ and $\\tilde{\\mathcal{O}}(d\\epsilon^{-4})$ for NC-SC and NC-C settings, respectively, where $d$ is the dimension of the primal variable and $\\kappa$ is the condition number. We further study the algorithm-dependent generalization bounds via stability arguments of algorithms. In particular, we introduce a novel stability notion for minimax problems and build a connection between stability and generalization. As a result, we establish algorithm-dependent generalization bounds for stochastic gradient descent ascent (SGDA) and the more general sampling-determined algorithms (SDA)",
    "checked": true,
    "id": "c525a1ec675224bab3574fdb0fe3616078e186a0",
    "semantic_title": "generalization bounds of nonconvex-(strongly)-concave stochastic minimax optimization",
    "citation_count": 0,
    "authors": [
      "Siqi Zhang",
      "Yifan Hu",
      "Liang Zhang",
      "Niao He"
    ]
  },
  "https://proceedings.mlr.press/v238/he24a.html": {
    "title": "TransFusion: Covariate-Shift Robust Transfer Learning for High-Dimensional Regression",
    "volume": "main",
    "abstract": "The main challenge that sets transfer learning apart from traditional supervised learning is the distribution shift, reflected as the shift between the source and target models and that between the marginal covariate distributions. In this work, we tackle model shifts in the presence of covariate shifts in the high-dimensional regression setting. Specifically, we propose a two-step method with a novel fused regularizer that effectively leverages samples from source tasks to improve the learning performance on a target task with limited samples. Nonasymptotic bound is provided for the estimation error of the target model, showing the robustness of the proposed method to covariate shifts. We further establish conditions under which the estimator is minimax-optimal. Additionally, we extend the method to a distributed setting, allowing for a pretraining-finetuning strategy, requiring just one round of communication while retaining the estimation rate of the centralized version. Numerical tests validate our theory, highlighting the method's robustness to covariate shifts",
    "checked": true,
    "id": "f112786edff69388e46f549d4ce7964ad7695861",
    "semantic_title": "transfusion: covariate-shift robust transfer learning for high-dimensional regression",
    "citation_count": 0,
    "authors": [
      "Zelin He",
      "Ying Sun",
      "Runze Li"
    ]
  },
  "https://proceedings.mlr.press/v238/gao24a.html": {
    "title": "Fusing Individualized Treatment Rules Using Secondary Outcomes",
    "volume": "main",
    "abstract": "An individualized treatment rule (ITR) is a decision rule that recommends treatments for patients based on their individual feature variables. In many practices, the ideal ITR for the primary outcome is also expected to cause minimal harm to other secondary outcomes. Therefore, our objective is to learn an ITR that not only maximizes the value function for the primary outcome, but also approximates the optimal rule for the secondary outcomes as closely as possible. To achieve this goal, we introduce a fusion penalty to encourage the ITRs based on different outcomes to yield similar recommendations. Two algorithms are proposed to estimate the ITR using surrogate loss functions. We prove that the agreement rate between the estimated ITR of the primary outcome and the optimal ITRs of the secondary outcomes converges to the true agreement rate faster than if the secondary outcomes are not taken into consideration. Furthermore, we derive the non-asymptotic properties of the value function and misclassification rate for the proposed method. Finally, simulation studies and a real data example are used to demonstrate the finite-sample performance of the proposed method",
    "checked": true,
    "id": "96b7cfbdc109166b702a56a08bbc2a7afdf4f45e",
    "semantic_title": "fusing individualized treatment rules using secondary outcomes",
    "citation_count": 0,
    "authors": [
      "Daiqi Gao",
      "Yuanjia Wang",
      "Donglin Zeng"
    ]
  },
  "https://proceedings.mlr.press/v238/janz24a.html": {
    "title": "Exploration via linearly perturbed loss minimisation",
    "volume": "main",
    "abstract": "We introduce \\emph{exploration via linear loss perturbations} (EVILL), a randomised exploration method for structured stochastic bandit problems that works by solving for the minimiser of a linearly perturbed regularised negative log-likelihood function. We show that, for the case of generalised linear bandits, EVILL reduces to perturbed history exploration (PHE), a method where exploration is done by training on randomly perturbed rewards. In doing so, we provide a simple and clean explanation of when and why random reward perturbations give rise to good bandit algorithms. We propose data-dependent perturbations not present in previous PHE-type methods that allow EVILL to match the performance of Thompson-sampling-style parameter-perturbation methods, both in theory and in practice. Moreover, we show an example outside generalised linear bandits where PHE leads to inconsistent estimates, and thus linear regret, while EVILL remains performant. Like PHE, EVILL can be implemented in just a few lines of code",
    "checked": true,
    "id": "09b1555fc11a15ed3bbf727e65df6410d788aec8",
    "semantic_title": "exploration via linearly perturbed loss minimisation",
    "citation_count": 4,
    "authors": [
      "David Janz",
      "Shuai Liu",
      "Alex Ayoub",
      "Csaba Szepesvári"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24a.html": {
    "title": "Proximal Causal Inference for Synthetic Control with Surrogates",
    "volume": "main",
    "abstract": "The synthetic control method (SCM) has become a popular tool for estimating causal effects in policy evaluation, where a single treated unit is observed. However, SCM faces challenges in accurately predicting post-intervention potential outcomes had, contrary to fact, the treatment been withheld, when the pre-intervention period is short or the post-intervention period is long. To address these issues, we propose a novel method that leverages post-intervention information, specifically time-varying correlates of the causal effect called \"surrogates\", within the synthetic control framework. We establish conditions for identifying model parameters using the proximal inference framework and apply the generalized method of moments (GMM) approach for estimation and inference about the average treatment effect on the treated (ATT). Interestingly, we uncover specific conditions under which exclusively using post-intervention data suffices for estimation within our framework. Through a synthetic experiment and a real-world application, we demonstrate that our method can outperform other synthetic control methods in estimating both short-term and long-term effects, yielding more accurate inferences",
    "checked": true,
    "id": "5403c745d76bef75dc634f9b7e9ca6d772245f0d",
    "semantic_title": "proximal causal inference for synthetic control with surrogates",
    "citation_count": 2,
    "authors": [
      "Jizhou Liu",
      "Eric Tchetgen Tchetgen",
      "Carlos Varjão"
    ]
  },
  "https://proceedings.mlr.press/v238/jankowiak24a.html": {
    "title": "Reparameterized Variational Rejection Sampling",
    "volume": "main",
    "abstract": "Traditional approaches to variational inference rely on parametric families of variational distributions, with the choice of family playing a critical role in determining the accuracy of the resulting posterior approximation. Simple mean-field families often lead to poor approximations, while rich families of distributions like normalizing flows can be difficult to optimize and usually do not incorporate the known structure of the target distribution due to their black-box nature. To expand the space of flexible variational families, we revisit Variational Rejection Sampling (VRS) [Grover et al., 2018], which combines a parametric proposal distribution with rejection sampling to define a rich non-parametric family of distributions that explicitly utilizes the known target distribution. By introducing a low-variance reparameterized gradient estimator for the parameters of the proposal distribution, we make VRS an attractive inference strategy for models with continuous latent variables. We argue theoretically and demonstrate empirically that the resulting method–Reparameterized Variational Rejection Sampling (RVRS)–offers an attractive trade-off between computational cost and inference fidelity. In experiments we show that our method performs well in practice and that it is well suited for black-box inference, especially for models with local latent variables",
    "checked": true,
    "id": "6952eac32f0a921ecfe089cc3721ec2181b189f8",
    "semantic_title": "reparameterized variational rejection sampling",
    "citation_count": 0,
    "authors": [
      "Martin Jankowiak",
      "Du Phan"
    ]
  },
  "https://proceedings.mlr.press/v238/anh-trang24a.html": {
    "title": "E(3)-Equivariant Mesh Neural Networks",
    "volume": "main",
    "abstract": "Triangular meshes are widely used to represent three-dimensional objects. As a result, many recent works have addressed the need for geometric deep learning on 3D meshes. However, we observe that the complexities in many of these architectures do not translate to practical performance, and simple deep models for geometric graphs are competitive in practice. Motivated by this observation, we minimally extend the update equations of E(n)-Equivariant Graph Neural Networks (EGNNs) (Satorras et al., 2021) to incorporate mesh face information and further improve it to account for long-range interactions through a hierarchy. The resulting architecture, Equivariant Mesh Neural Network (EMNN), outperforms other, more complicated equivariant methods on mesh tasks, with a fast run-time and no expensive preprocessing. Our implementation is available at \\url{https://github.com/HySonLab/EquiMesh}",
    "checked": true,
    "id": "c5b655805d8a48d1974db7aa09dde43ff59916fa",
    "semantic_title": "e(3)-equivariant mesh neural networks",
    "citation_count": 1,
    "authors": [
      "Thuan Anh Trang",
      "Nhat Khang Ngo",
      "Daniel T. Levy",
      "Thieu Ngoc Vo",
      "Siamak Ravanbakhsh",
      "Truong Son Hy"
    ]
  },
  "https://proceedings.mlr.press/v238/qin24a.html": {
    "title": "A General Algorithm for Solving Rank-one Matrix Sensing",
    "volume": "main",
    "abstract": "Matrix sensing has many real-world applications in science and engineering, such as system control, distance embedding, and computer vision. The goal of matrix sensing is to recover a matrix $A_\\star \\in \\mathbb{R}^{n \\times n}$, based on a sequence of measurements $(u_i,b_i) \\in \\mathbb{R}^{n} \\times \\mathbb{R}$ such that $u_i^\\top A_\\star u_i = b_i$. Previous work (Zhong et al., 2015) focused on the scenario where matrix $A_{\\star}$ has a small rank, e.g. rank-$k$. Their analysis heavily relies on the RIP assumption, making it unclear how to generalize to high-rank matrices. In this paper, we relax that rank-$k$ assumption and solve a much more general matrix sensing problem. Given an accuracy parameter $\\delta \\in (0,1)$, we can compute $A \\in \\mathbb{R}^{n \\times n}$ in $\\widetilde{O}(m^{3/2} n^2 \\delta^{-1} )$, such that $ |u_i^\\top A u_i - b_i| \\leq \\delta$ for all $i \\in [m]$. We design an efficient algorithm with provable convergence guarantees using stochastic gradient descent for this problem",
    "checked": true,
    "id": "ea683506bf202e612ea0c644affd052a09d90e36",
    "semantic_title": "a general algorithm for solving rank-one matrix sensing",
    "citation_count": 15,
    "authors": [
      "Lianke Qin",
      "Zhao Song",
      "Ruizhe Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24a.html": {
    "title": "Oracle-Efficient Pessimism: Offline Policy Optimization In Contextual Bandits",
    "volume": "main",
    "abstract": "We consider offline policy optimization (OPO) in contextual bandits, where one is given a fixed dataset of logged interactions. While pessimistic regularizers are typically used to mitigate distribution shift, prior implementations thereof are either specialized or computationally inefficient. We present the first \\emph{general} oracle-efficient algorithm for pessimistic OPO: it reduces to supervised learning, leading to broad applicability. We obtain statistical guarantees analogous to those for prior pessimistic approaches. We instantiate our approach for both discrete and continuous actions and perform experiments in both settings, showing advantage over unregularized OPO across a wide range of configurations",
    "checked": true,
    "id": "282ca5950e831b08dd22f90662090e77febc3ff0",
    "semantic_title": "oracle-efficient pessimism: offline policy optimization in contextual bandits",
    "citation_count": 6,
    "authors": [
      "Lequn Wang",
      "Akshay Krishnamurthy",
      "Alex Slivkins"
    ]
  },
  "https://proceedings.mlr.press/v238/dupuis24a.html": {
    "title": "The Solution Path of SLOPE",
    "volume": "main",
    "abstract": "The SLOPE estimator has the particularity of having null components (sparsity) and components that are equal in absolute value (clustering). The number of clusters depends on the regularization parameter of the estimator. This parameter can be chosen as a trade-off between interpretability (with a small number of clusters) and accuracy (with a small mean squared error or a small prediction error). Finding such a compromise requires to compute the solution path, that is the function mapping the regularization parameter to the estimator. We provide in this article an algorithm to compute the solution path of SLOPE and show how it can be used to adjust the regularization parameter",
    "checked": true,
    "id": "7e4def491e0f9d154efc9be24352cd3716fb2a06",
    "semantic_title": "the solution path of slope",
    "citation_count": 1,
    "authors": [
      "Xavier Dupuis",
      "Patrick Tardivel"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24a.html": {
    "title": "Lower-level Duality Based Reformulation and Majorization Minimization Algorithm for Hyperparameter Optimization",
    "volume": "main",
    "abstract": "Hyperparameter tuning is an important task of machine learning, which can be formulated as a bilevel program (BLP). However, most existing algorithms are not applicable for BLP with non-smooth lower-level problems. To address this, we propose a single-level reformulation of the BLP based on lower-level duality without involving any implicit value function. To solve the reformulation, we propose a majorization minimization algorithm that marjorizes the constraint in each iteration. Furthermore, we show that the subproblems of the proposed algorithm for several widely-used hyperparameter turning models can be reformulated into conic programs that can be efficiently solved by the off-the-shelf solvers. We theoretically prove the convergence of the proposed algorithm and demonstrate its superiority through numerical experiments",
    "checked": true,
    "id": "45f36475475f10892c88db41f62ce138abca682a",
    "semantic_title": "lower-level duality based reformulation and majorization minimization algorithm for hyperparameter optimization",
    "citation_count": 0,
    "authors": [
      "He Chen",
      "Haochen Xu",
      "Rujun Jiang",
      "Anthony Man-Cho So"
    ]
  },
  "https://proceedings.mlr.press/v238/karjol24a.html": {
    "title": "A Unified Framework for Discovering Discrete Symmetries",
    "volume": "main",
    "abstract": "We consider the problem of learning a function respecting a symmetry from among a class of symmetries. We develop a unified framework that enables symmetry discovery across a broad range of subgroups including locally symmetric, dihedral and cyclic subgroups. At the core of the framework is a novel architecture composed of linear, matrix-valued and non-linear functions that expresses functions invariant to these subgroups in a principled manner. The structure of the architecture enables us to leverage multi-armed bandit algorithms and gradient descent to efficiently optimize over the linear and the non-linear functions, respectively, and to infer the symmetry that is ultimately learnt. We also discuss the necessity of the matrix-valued functions in the architecture. Experiments on image-digit sum and polynomial regression tasks demonstrate the effectiveness of our approach",
    "checked": true,
    "id": "310fd7597ea3d6702dbc0041e575ad643dfbe0b6",
    "semantic_title": "a unified framework for discovering discrete symmetries",
    "citation_count": 1,
    "authors": [
      "Pavan Karjol",
      "Rohan Kashyap",
      "Aditya Gopalan",
      "A. P. Prathosh"
    ]
  },
  "https://proceedings.mlr.press/v238/amiraz24a.html": {
    "title": "Recovery Guarantees for Distributed-OMP",
    "volume": "main",
    "abstract": "We study distributed schemes for high-dimensional sparse linear regression, based on orthogonal matching pursuit (OMP). Such schemes are particularly suited for settings where a central fusion center is connected to end machines, that have both computation and communication limitations. We prove that under suitable assumptions, distributed-OMP schemes recover the support of the regression vector with communication per machine linear in its sparsity and logarithmic in the dimension. Remarkably, this holds even at low signal-to-noise-ratios, where individual machines are unable to detect the support. Our simulations show that distributed-OMP schemes are competitive with more computationally intensive methods, and in some cases even outperform them",
    "checked": true,
    "id": "1486b624ff064a41b5ba824a86a4073e0e2343a9",
    "semantic_title": "recovery guarantees for distributed-omp",
    "citation_count": 0,
    "authors": [
      "Chen Amiraz",
      "Robert Krauthgamer",
      "Boaz Nadler"
    ]
  },
  "https://proceedings.mlr.press/v238/vilucchio24a.html": {
    "title": "Asymptotic Characterisation of the Performance of Robust Linear Regression in the Presence of Outliers",
    "volume": "main",
    "abstract": "We study robust linear regression in high-dimension, when both the dimension $d$ and the number of data points $n$ diverge with a fixed ratio $\\alpha=n/d$, and study a data model that includes outliers. We provide exact asymptotics for the performances of the empirical risk minimisation (ERM) using $\\ell_2$-regularised $\\ell_2$, $\\ell_1$, and Huber losses, which are the standard approach to such problems. We focus on two metrics for the performance: the generalisation error to similar datasets with outliers, and the estimation error of the original, unpolluted function. Our results are compared with the information theoretic Bayes-optimal estimation bound. For the generalization error, we find that optimally-regularised ERM is asymptotically consistent in the large sample complexity limit if one perform a simple calibration, and compute the rates of convergence. For the estimation error however, we show that due to a norm calibration mismatch, the consistency of the estimator requires an oracle estimate of the optimal norm, or the presence of a cross-validation set not corrupted by the outliers. We examine in detail how performance depends on the loss function and on the degree of outlier corruption in the training set and identify a region of parameters where the optimal performance of the Huber loss is identical to that of the $\\ell_2$ loss, offering insights into the use cases of different loss functions",
    "checked": true,
    "id": "2ddef0ffaa8e09df9e3169692b96b62c4fc5a17e",
    "semantic_title": "asymptotic characterisation of the performance of robust linear regression in the presence of outliers",
    "citation_count": 2,
    "authors": [
      "Matteo Vilucchio",
      "Emanuele Troiani",
      "Vittorio Erba",
      "Florent Krzakala"
    ]
  },
  "https://proceedings.mlr.press/v238/yu24a.html": {
    "title": "Riemannian Laplace Approximation with the Fisher Metric",
    "volume": "main",
    "abstract": "Laplace's method approximates a target density with a Gaussian distribution at its mode. It is computationally efficient and asymptotically exact for Bayesian inference due to the Bernstein-von Mises theorem, but for complex targets and finite-data posteriors it is often too crude an approximation. A recent generalization of the Laplace Approximation transforms the Gaussian approximation according to a chosen Riemannian geometry providing a richer approximation family, while still retaining computational efficiency. However, as shown here, its properties depend heavily on the chosen metric, indeed the metric adopted in previous work results in approximations that are overly narrow as well as being biased even at the limit of infinite data. We correct this shortcoming by developing the approximation family further, deriving two alternative variants that are exact at the limit of infinite data, extending the theoretical analysis of the method, and demonstrating practical improvements in a range of experiments",
    "checked": true,
    "id": "89a222ae4b4ff78a11671d698854f5eede34ee53",
    "semantic_title": "riemannian laplace approximation with the fisher metric",
    "citation_count": 1,
    "authors": [
      "Hanlin Yu",
      "Marcelo Hartmann",
      "Bernardo Williams Moreno Sanchez",
      "Mark Girolami",
      "Arto Klami"
    ]
  },
  "https://proceedings.mlr.press/v238/reichelt24a.html": {
    "title": "Beyond Bayesian Model Averaging over Paths in Probabilistic Programs with Stochastic Support",
    "volume": "main",
    "abstract": "The posterior in probabilistic programs with stochastic support decomposes as a weighted sum of the local posterior distributions associated with each possible program path. We show that making predictions with this full posterior implicitly performs a Bayesian model averaging (BMA) over paths. This is potentially problematic, as BMA weights can be unstable due to model misspecification or inference approximations, leading to sub-optimal predictions in turn. To remedy this issue, we propose alternative mechanisms for path weighting: one based on stacking and one based on ideas from PAC-Bayes. We show how both can be implemented as a cheap post-processing step on top of existing inference engines. In our experiments, we find them to be more robust and lead to better predictions compared to the default BMA weights",
    "checked": true,
    "id": "ba49a846177829dde8c148854ef67d138e6a85b6",
    "semantic_title": "beyond bayesian model averaging over paths in probabilistic programs with stochastic support",
    "citation_count": 0,
    "authors": [
      "Tim Reichelt",
      "Luke Ong",
      "Tom Rainforth"
    ]
  },
  "https://proceedings.mlr.press/v238/aghbalou24a.html": {
    "title": "Sharp error bounds for imbalanced classification: how many examples in the minority class?",
    "volume": "main",
    "abstract": "When dealing with imbalanced classification data, reweighting the loss function is a standard procedure allowing to equilibrate between the true positive and true negative rates within the risk measure. Despite significant theoretical work in this area, existing results do not adequately address a main challenge within the imbalanced classification framework, which is the negligible size of one class in relation to the full sample size and the need to rescale the risk function by a probability tending to zero. To address this gap, we present two novel contributions in the setting where the rare class probability approaches zero: (1) a non asymptotic fast rate probability bound for constrained balanced empirical risk minimization, and (2) a consistent upper bound for balanced nearest neighbors estimates. Our findings provide a clearer understanding of the benefits of class-weighting in realistic settings, opening new avenues for further research in this field",
    "checked": true,
    "id": "da0936a195a63852ab2376f91ca947ef61a30337",
    "semantic_title": "sharp error bounds for imbalanced classification: how many examples in the minority class?",
    "citation_count": 1,
    "authors": [
      "Anass Aghbalou",
      "Anne Sabourin",
      "François Portier"
    ]
  },
  "https://proceedings.mlr.press/v238/bickford-smith24a.html": {
    "title": "Making Better Use of Unlabelled Data in Bayesian Active Learning",
    "volume": "main",
    "abstract": "Fully supervised models are predominant in Bayesian active learning. We argue that their neglect of the information present in unlabelled data harms not just predictive performance but also decisions about what data to acquire. Our proposed solution is a simple framework for semi-supervised Bayesian active learning. We find it produces better-performing models than either conventional Bayesian active learning or semi-supervised learning with randomly acquired data. It is also easier to scale up than the conventional approach. As well as supporting a shift towards semi-supervised models, our findings highlight the importance of studying models and acquisition methods in conjunction",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Freddie Bickford Smith",
      "Adam Foster",
      "Tom Rainforth"
    ]
  },
  "https://proceedings.mlr.press/v238/puchkin24a.html": {
    "title": "Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems",
    "volume": "main",
    "abstract": "We consider stochastic optimization problems with heavy-tailed noise with structured density. For such problems, we show that it is possible to get faster rates of convergence than $O(K^{-2(\\alpha - 1) / \\alpha})$, when the stochastic gradients have finite $\\alpha$-th moment, $\\alpha \\in (1, 2]$. In particular, our analysis allows the noise norm to have an unbounded expectation. To achieve these results, we stabilize stochastic gradients, using smoothed medians of means. We prove that the resulting estimates have negligible bias and controllable variance. This allows us to carefully incorporate them into clipped-SGD and clipped-SSTM and derive new high-probability complexity bounds in the considered setup",
    "checked": true,
    "id": "77d8d32251aec2aad6b4f317e12b0028ea0c4926",
    "semantic_title": "breaking the heavy-tailed noise barrier in stochastic optimization problems",
    "citation_count": 0,
    "authors": [
      "Nikita Puchkin",
      "Eduard Gorbunov",
      "Nickolay Kutuzov",
      "Alexander Gasnikov"
    ]
  },
  "https://proceedings.mlr.press/v238/ahuja24a.html": {
    "title": "Multi-Domain Causal Representation Learning via Weak Distributional Invariances",
    "volume": "main",
    "abstract": "Causal representation learning has emerged as the center of action in causal machine learning research. In particular, multi-domain datasets present a natural opportunity for showcasing the advantages of causal representation learning over standard unsupervised representation learning. While recent works have taken crucial steps towards learning causal representations, they often lack applicability to multi-domain datasets due to over-simplifying assumptions about the data; e.g. each domain comes from a different single-node perfect intervention. In this work, we relax these assumptions and capitalize on the following observation: there often exists a subset of latents whose certain distributional properties (e.g., support, variance) remain stable across domains; this property holds when, for example, each domain comes from a multi-node imperfect intervention. Leveraging this observation, we show that autoencoders that incorporate such invariances can provably identify the stable set of latents from the rest across different settings",
    "checked": true,
    "id": "c5cef109bbf67e4d837bb2f841ae80e5dd655a05",
    "semantic_title": "multi-domain causal representation learning via weak distributional invariances",
    "citation_count": 5,
    "authors": [
      "Kartik Ahuja",
      "Amin Mansouri",
      "Yixin Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/ahmadian24a.html": {
    "title": "Unsupervised Novelty Detection in Pretrained Representation Space with Locally Adapted Likelihood Ratio",
    "volume": "main",
    "abstract": "Detecting novelties given unlabeled examples of normal data is a challenging task in machine learning, particularly when the novel and normal categories are semantically close. Large deep models pretrained on massive datasets can provide a rich representation space in which the simple k-nearest neighbor distance works as a novelty measure. However, as we show in this paper, the basic k-NN method might be insufficient in this context due to ignoring the 'local geometry' of the distribution over representations as well as the impact of irrelevant 'background features'. To address this, we propose a fully unsupervised novelty detection approach that integrates the flexibility of k-NN with a locally adapted scaling of dimensions based on the 'neighbors of nearest neighbor' and computing a 'likelihood ratio' in pretrained (self-supervised) representation spaces. Our experiments with image data show the advantage of this method when off-the-shelf vision transformers (e.g., pretrained by DINO) are used as the feature extractor without any fine-tuning",
    "checked": true,
    "id": "23643ac9a94c066330094a0884a5372fc744b205",
    "semantic_title": "unsupervised novelty detection in pretrained representation space with locally adapted likelihood ratio",
    "citation_count": 0,
    "authors": [
      "Amirhossein Ahmadian",
      "Yifan Ding",
      "Gabriel Eilertsen",
      "Fredrik Lindsten"
    ]
  },
  "https://proceedings.mlr.press/v238/scieur24a.html": {
    "title": "Adaptive Quasi-Newton and Anderson Acceleration Framework with Explicit Global (Accelerated) Convergence Rates",
    "volume": "main",
    "abstract": "Despite the impressive numerical performance of the quasi-Newton and Anderson/nonlinear acceleration methods, their global convergence rates have remained elusive for over 50 years. This study addresses this long-standing issue by introducing a framework that derives novel, adaptive quasi-Newton and nonlinear/Anderson acceleration schemes. Under mild assumptions, the proposed iterative methods exhibit explicit, non-asymptotic convergence rates that blend those of the gradient descent and Cubic Regularized Newton's methods. The proposed approach also includes an accelerated version for convex functions. Notably, these rates are achieved adaptively without prior knowledge of the function's parameters. The framework presented in this study is generic, and its special cases include algorithms such as Newton's method with random subspaces, finite differences, or lazy Hessian. Numerical experiments demonstrated the efficiency of the proposed framework, even compared to the l-BFGS algorithm with Wolfe line-search. The code used in the experiments is available on \\url{https://github.com/windows7lover/QN_With_Guarantees}",
    "checked": true,
    "id": "eb0c5c9298faac81d59214068d7d49c4fd28457a",
    "semantic_title": "adaptive quasi-newton and anderson acceleration framework with explicit global (accelerated) convergence rates",
    "citation_count": 0,
    "authors": [
      "Damien Scieur"
    ]
  },
  "https://proceedings.mlr.press/v238/bao24a.html": {
    "title": "BOBA: Byzantine-Robust Federated Learning with Label Skewness",
    "volume": "main",
    "abstract": "In federated learning, most existing robust aggregation rules (AGRs) combat Byzantine attacks in the IID setting, where client data is assumed to be independent and identically distributed. In this paper, we address label skewness, a more realistic and challenging non-IID setting, where each client only has access to a few classes of data. In this setting, state-of-the-art AGRs suffer from selection bias, leading to significant performance drop for particular classes; they are also more vulnerable to Byzantine attacks due to the increased variation among gradients of honest clients. To address these limitations, we propose an efficient two-stage method named BOBA. Theoretically, we prove the convergence of BOBA with an error of the optimal order. Our empirical evaluations demonstrate BOBA's superior unbiasedness and robustness across diverse models and datasets when compared to various baselines",
    "checked": true,
    "id": "7aeeea5d31314e0c531e6112f0c5202ceab04127",
    "semantic_title": "boba: byzantine-robust federated learning with label skewness",
    "citation_count": 0,
    "authors": [
      "Wenxuan Bao",
      "Jun Wu",
      "Jingrui He"
    ]
  },
  "https://proceedings.mlr.press/v238/guo24a.html": {
    "title": "A White-Box False Positive Adversarial Attack Method on Contrastive Loss Based Offline Handwritten Signature Verification Models",
    "volume": "main",
    "abstract": "In this paper, we tackle the challenge of white-box false positive adversarial attacks on contrastive loss based offline handwritten signature verification models. We propose a novel attack method that treats the attack as a style transfer between closely related but distinct writing styles. To guide the generation of deceptive images, we introduce two new loss functions that enhance the attack success rate by perturbing the Euclidean distance between the embedding vectors of the original and synthesized samples, while ensuring minimal perturbations by reducing the difference between the generated image and the original image. Our method demonstrates state-of-the-art performance in white-box attacks on contrastive loss based offline handwritten signature verification models, as evidenced by our experiments. The key contributions of this paper include a novel false positive attack method, two new loss functions, effective style transfer in handwriting styles, and superior performance in white-box false positive attacks compared to other white-box attack methods",
    "checked": false,
    "id": "72f5c20c887e1def6fa3f70281b7e8acd33a2af5",
    "semantic_title": "a white-box false positive adversarial attack method on contrastive loss-based offline handwritten signature verification models",
    "citation_count": 6,
    "authors": [
      "Zhongliang Guo",
      "Weiye Li",
      "Yifei Qian",
      "Ognjen Arandjelovic",
      "Lei Fang"
    ]
  },
  "https://proceedings.mlr.press/v238/regol24a.html": {
    "title": "Categorical Generative Model Evaluation via Synthetic Distribution Coarsening",
    "volume": "main",
    "abstract": "As we expect to see a rapid integration of generative models in our day to day lives, the development of rigorous methods of evaluation and analysis for generative models has never been more pressing. Multiple works have highlighted the shortcomings of widely used metrics and exposed how they fail to behave as expected in some settings. So far, the response has been to use a variety of metrics that target different desirable and interpretable properties such as fidelity, diversity, and authenticity, to obtain a clearer picture of a generative model's capabilities. These methods mainly focus on ordinal data and they all suffer from the same unavoidable issues stemming from estimating quantities of high-dimensional data from a limited number of samples. We propose to take an alternative approach and to return to the synthetic data setting where the ground truth is explicit and known. We focus on nominal categorical data and introduce an evaluation method that can scale to the high-dimensional settings often encountered in practice. Our method involves successively binning the large space to obtain smaller probability spaces and coarser distributions where meaningful statistical estimates can be obtained. This allows us to provide probabilistic guarantees and sample complexities and we illustrate how our method can be applied to distinguish between the capabilities of several state-of-the-art categorical models",
    "checked": true,
    "id": "1dea33faa4b268e527546825af2eea988ffcd1d2",
    "semantic_title": "categorical generative model evaluation via synthetic distribution coarsening",
    "citation_count": 0,
    "authors": [
      "Florence Regol",
      "Mark Coates"
    ]
  },
  "https://proceedings.mlr.press/v238/feng24b.html": {
    "title": "Monitoring machine learning-based risk prediction algorithms in the presence of performativity",
    "volume": "main",
    "abstract": "Performance monitoring of machine learning (ML)-based risk prediction models in healthcare is complicated by the issue of performativity: when an algorithm predicts a patient to be at high risk for an adverse event, clinicians are more likely to administer prophylactic treatment and alter the very target that the algorithm aims to predict. A simple approach is to ignore performativity and monitor only the untreated patients, whose outcomes remain unaltered. In general, ignoring performativity may inflate Type I error because (i) untreated patients disproportionally represent those with low predicted risk, and (ii) changes in the clinician's trust in the ML algorithm and the algorithm itself can induce complex dependencies that violate standard assumptions. Nevertheless, we show that valid inference is still possible when monitoring \\textit{conditional} rather than marginal performance measures under either the assumption of conditional exchangeability or time-constant selection bias. Finally, performativity can vary over time and induce nonstationarity in the data, which presents challenges for monitoring. To this end, we introduce a new score-based cumulative sum (CUSUM) monitoring procedure with dynamic control limits. Through extensive simulation studies, we study applications of the score-based CUSUM and how it is affected by various factors, including the efficiency of model updating procedures and the level of clinician trust. Finally, we apply the procedure to detect calibration decay of a risk model during the COVID-19 pandemic",
    "checked": true,
    "id": "15367f7a34062a94796073cd98f4c86e56c18a65",
    "semantic_title": "monitoring machine learning-based risk prediction algorithms in the presence of performativity",
    "citation_count": 1,
    "authors": [
      "Jean Feng",
      "Alexej Gossmann",
      "Gene A Pennello",
      "Nicholas Petrick",
      "Berkman Sahiner",
      "Romain Pirracchio"
    ]
  },
  "https://proceedings.mlr.press/v238/depavia24a.html": {
    "title": "Learning-Based Algorithms for Graph Searching Problems",
    "volume": "main",
    "abstract": "We consider the problem of graph searching with prediction recently introduced by Banerjee et al. (2023). In this problem, an agent starting at some vertex r has to traverse a (potentially unknown) graph G to find a hidden goal node g while minimizing the total distance traveled. We study a setting in which at any node v, the agent receives a noisy estimate of the distance from v to g. We design algorithms for this search task on unknown graphs. We establish the first formal guarantees on unknown weighted graphs and provide lower bounds showing that the algorithms we propose have optimal or nearly-optimal dependence on the prediction error. Further, we perform numerical experiments demonstrating that in addition to being robust to adversarial error, our algorithms perform well in typical instances in which the error is stochastic. Finally, we provide simpler performance bounds on the algorithms of Banerjee et al. (2023) for the case of searching on a known graph and establish new lower bounds for this setting",
    "checked": true,
    "id": "b8b2d2efa6e9d979757f5f2336395c1da2d92a34",
    "semantic_title": "learning-based algorithms for graph searching problems",
    "citation_count": 0,
    "authors": [
      "Adela F. DePavia",
      "Erasmo Tani",
      "Ali Vakilian"
    ]
  },
  "https://proceedings.mlr.press/v238/bacchiocchi24a.html": {
    "title": "Autoregressive Bandits",
    "volume": "main",
    "abstract": "Autoregressive processes naturally arise in a large variety of real-world scenarios, including stock markets, sales forecasting, weather prediction, advertising, and pricing. When facing a sequential decision-making problem in such a context, the temporal dependence between consecutive observations should be properly accounted for guaranteeing convergence to the optimal policy. In this work, we propose a novel online learning setting, namely, Autoregressive Bandits (ARBs), in which the observed reward is governed by an autoregressive process of order $k$, whose parameters depend on the chosen action. We show that, under mild assumptions on the reward process, the optimal policy can be conveniently computed. Then, we devise a new optimistic regret minimization algorithm, namely, AutoRegressive Upper Confidence Bound (AR-UCB), that suffers sublinear regret of order $\\tilde{O} ( \\frac{(k+1)^{3/2}\\sqrt{nT}}{(1-\\Gamma)^2} )$, where $T$ is the optimization horizon, $n$ is the number of actions, and $\\Gamma < 1$ is a stability index of the process. Finally, we empirically validate our algorithm, illustrating its advantages w.r.t. bandit baselines and its robustness to misspecification of key parameters",
    "checked": true,
    "id": "043e4c58f6cbdb881a6b402a28239da2fe45184c",
    "semantic_title": "autoregressive bandits",
    "citation_count": 2,
    "authors": [
      "Francesco Bacchiocchi",
      "Gianmarco Genalti",
      "Davide Maran",
      "Marco Mussi",
      "Marcello Restelli",
      "Nicola Gatti",
      "Alberto Maria Metelli"
    ]
  },
  "https://proceedings.mlr.press/v238/kim24b.html": {
    "title": "DeepFDR: A Deep Learning-based False Discovery Rate Control Method for Neuroimaging Data",
    "volume": "main",
    "abstract": "Voxel-based multiple testing is widely used in neuroimaging data analysis. Traditional false discovery rate (FDR) control methods often ignore the spatial dependence among the voxel-based tests and thus suffer from substantial loss of testing power. While recent spatial FDR control methods have emerged, their validity and optimality remain questionable when handling the complex spatial dependencies of the brain. Concurrently, deep learning methods have revolutionized image segmentation, a task closely related to voxel-based multiple testing. In this paper, we propose DeepFDR, a novel spatial FDR control method that leverages unsupervised deep learning-based image segmentation to address the voxel-based multiple testing problem. Numerical studies, including comprehensive simulations and Alzheimer's disease FDG-PET image analysis, demonstrate DeepFDR's superiority over existing methods. DeepFDR not only excels in FDR control and effectively diminishes the false nondiscovery rate, but also boasts exceptional computational efficiency highly suited for tackling large-scale neuroimaging data",
    "checked": true,
    "id": "993bdb90f6bed53f7607a56fbd83defd46de3478",
    "semantic_title": "deepfdr: a deep learning-based false discovery rate control method for neuroimaging data",
    "citation_count": 0,
    "authors": [
      "Taehyo Kim",
      "Hai Shu",
      "Qiran Jia",
      "Mony de Leon"
    ]
  },
  "https://proceedings.mlr.press/v238/ye24a.html": {
    "title": "Enhancing Hypergradients Estimation: A Study of Preconditioning and Reparameterization",
    "volume": "main",
    "abstract": "Bilevel optimization aims to optimize an outer objective function that depends on the solution to an inner optimization problem. It is routinely used in Machine Learning, notably for hyperparameter tuning. The conventional method to compute the so-called hypergradient of the outer problem is to use the Implicit Function Theorem (IFT). As a function of the error of the inner problem resolution, we study the error of the IFT method. We analyze two strategies to reduce this error: preconditioning the IFT formula and reparameterizing the inner problem. We give a detailed account of the impact of these two modifications on the error, highlighting the role played by higher-order derivatives of the functionals at stake. Our theoretical findings explain when super efficiency, namely reaching an error on the hypergradient that depends quadratically on the error on the inner problem, is achievable and compare the two approaches when this is impossible. Numerical evaluations on hyperparameter tuning for regression problems substantiate our theoretical findings",
    "checked": true,
    "id": "21abf1c043ef91ac7f75b182eac2a1d9963f7104",
    "semantic_title": "enhancing hypergradients estimation: a study of preconditioning and reparameterization",
    "citation_count": 0,
    "authors": [
      "Zhenzhang Ye",
      "Gabriel Peyré",
      "Daniel Cremers",
      "Pierre Ablin"
    ]
  },
  "https://proceedings.mlr.press/v238/stempfle24a.html": {
    "title": "MINTY: Rule-based models that minimize the need for imputing features with missing values",
    "volume": "main",
    "abstract": "Rule models are often preferred in prediction tasks with tabular inputs as they can be easily interpreted using natural language and provide predictive performance on par with more complex models. However, most rule models' predictions are undefined or ambiguous when some inputs are missing, forcing users to rely on statistical imputation models or heuristics like zero imputation, undermining the interpretability of the models. In this work, we propose fitting concise yet precise rule models that learn to avoid relying on features with missing values and, therefore, limit their reliance on imputation at test time. We develop MINTY, a method that learns rules in the form of disjunctions between variables that act as replacements for each other when one or more is missing. This results in a sparse linear rule model, regularized to have small dependence on features with missing values, that allows a trade-off between goodness of fit, interpretability, and robustness to missing values at test time. We demonstrate the value of MINTY in experiments using synthetic and real-world data sets and find its predictive performance comparable or favorable to baselines, with smaller reliance on features with missing values",
    "checked": true,
    "id": "aa6f8f0988b81e578470ae9cef6c4e93e12864fe",
    "semantic_title": "minty: rule-based models that minimize the need for imputing features with missing values",
    "citation_count": 0,
    "authors": [
      "Lena Stempfle",
      "Fredrik Johansson"
    ]
  },
  "https://proceedings.mlr.press/v238/zimerman24a.html": {
    "title": "Multi-Dimensional Hyena for Spatial Inductive Bias",
    "volume": "main",
    "abstract": "The advantage of Vision Transformers over CNNs is only fully manifested when trained over a large dataset, mainly due to the reduced inductive bias towards spatial locality within the transformer's self-attention mechanism. In this work, we present a data-efficient vision transformer that does not rely on self-attention. Instead, it employs a novel generalization to multiple axes of the very recent Hyena layer. We propose several alternative approaches for obtaining this generalization and delve into their unique distinctions and considerations from both empirical and theoretical perspectives. The proposed Hyena N-D layer boosts the performance of various Vision Transformer architectures, such as ViT, Swin, and DeiT across multiple datasets. Furthermore, in the small dataset regime, our Hyena-based ViT is favorable to ViT variants from the recent literature that are specifically designed for solving the same challenge. Finally, we show that a hybrid approach that is based on Hyena N-D for the first layers in ViT, followed by layers that incorporate conventional attention, consistently boosts the performance of various vision transformer architectures. Our code is attached as supplementary",
    "checked": true,
    "id": "e6917b14918f90e8fb89ad4debebd3937e57a123",
    "semantic_title": "multi-dimensional hyena for spatial inductive bias",
    "citation_count": 3,
    "authors": [
      "Itamar Zimerman",
      "Lior Wolf"
    ]
  },
  "https://proceedings.mlr.press/v238/yijia-zheng24a.html": {
    "title": "Graph Machine Learning through the Lens of Bilevel Optimization",
    "volume": "main",
    "abstract": "Bilevel optimization refers to scenarios whereby the optimal solution of a lower-level energy function serves as input features to an upper-level objective of interest. These optimal features typically depend on tunable parameters of the lower-level energy in such a way that the entire bilevel pipeline can be trained end-to-end. Although not generally presented as such, this paper demonstrates how a variety of graph learning techniques can be recast as special cases of bilevel optimization or simplifications thereof. In brief, building on prior work we first derive a more flexible class of energy functions that, when paired with various descent steps (e.g., gradient descent, proximal methods, momentum, etc.), form graph neural network (GNN) message-passing layers; critically, we also carefully unpack where any residual approximation error lies with respect to the underlying constituent message-passing functions. We then probe several simplifications of this framework to derive close connections with non-GNN-based graph learning approaches, including knowledge graph embeddings, various forms of label propagation, and efficient graph-regularized MLP models. And finally, we present supporting empirical results that demonstrate the versatility of the proposed bilevel lens, which we refer to as BloomGML, referencing that BiLevel Optimization Offers More Graph Machine Learning. Our code is available at \\url{https://github.com/amberyzheng/BloomGML}. Let graph ML bloom",
    "checked": false,
    "id": "741157c69f38613c10d910c3a500c7d040d76993",
    "semantic_title": "bloomgml: graph machine learning through the lens of bilevel optimization",
    "citation_count": 0,
    "authors": [
      "Amber Yijia Zheng",
      "Tong He",
      "Yixuan Qiu",
      "Minjie Wang",
      "David Wipf"
    ]
  },
  "https://proceedings.mlr.press/v238/allouah24a.html": {
    "title": "Robust Sparse Voting",
    "volume": "main",
    "abstract": "Many applications, such as content moderation and recommendation, require reviewing and scoring a large number of alternatives. Doing so robustly is however very challenging. Indeed, voters' inputs are inevitably sparse: most alternatives are only scored by a small fraction of voters. This sparsity amplifies the effects of biased voters introducing unfairness, and of malicious voters seeking to hack the voting process by reporting dishonest scores. We give a precise definition of the problem of robust sparse voting, highlight its underlying technical challenges, and present a novel voting mechanism addressing the problem. We prove that, using this mechanism, no voter can have more than a small parameterizable effect on each alternative's score; a property we call Lipschitz resilience. We also identify conditions of voters comparability under which any unanimous preferences can be recovered, even when each voter provides sparse scores, on a scale that is potentially very different from any other voter's score scale. Proving these properties required us to introduce, analyze and carefully compose novel aggregation primitives which could be of independent interest",
    "checked": true,
    "id": "5ab8d1451845185f31d90798a54ffb5fb18e39e1",
    "semantic_title": "robust sparse voting",
    "citation_count": 4,
    "authors": [
      "Youssef Allouah",
      "Rachid Guerraoui",
      "Lê-Nguyên Hoang",
      "Oscar Villemaud"
    ]
  },
  "https://proceedings.mlr.press/v238/joshi24a.html": {
    "title": "Data-Efficient Contrastive Language-Image Pretraining: Prioritizing Data Quality over Quantity",
    "volume": "main",
    "abstract": "Contrastive Language-Image Pre-training (CLIP) on large-scale image-caption datasets learns representations that can achieve remarkable zero-shot generalization. However, such models require a massive amount of pre-training data. Improving the quality of the pre-training data has been shown to be much more effective in improving CLIP's performance than increasing its volume. Nevertheless, finding small subsets of training data that provably generalize best has remained an open question. In this work, we propose the first theoretically rigorous data selection method for CLIP. We show that subsets that closely preserve the cross-covariance of the images and captions of the full data provably achieve a superior generalization performance.Our extensive experiments on ConceptualCaptions3M and ConceptualCaptions12M demonstrate that subsets found by \\textsc{ClipCov} achieve over 2.7x and 1.4x the accuracy of the next best baseline on ImageNet and its shifted versions. Moreover, we show that our subsets obtain 1.5x the average accuracy across 11 downstream datasets, of the next best baseline. The code is available at: \\url{https://github.com/BigML-CS-UCLA/clipcov-data-efficient-clip}",
    "checked": true,
    "id": "7cb06b1a932f96e418e767770305084b0c26e97d",
    "semantic_title": "data-efficient contrastive language-image pretraining: prioritizing data quality over quantity",
    "citation_count": 4,
    "authors": [
      "Siddharth Joshi",
      "Arnav Jain",
      "Ali Payani",
      "Baharan Mirzasoleiman"
    ]
  },
  "https://proceedings.mlr.press/v238/min-kwon24a.html": {
    "title": "Efficient Low-Dimensional Compression of Overparameterized Models",
    "volume": "main",
    "abstract": "In this work, we present a novel approach for compressing overparameterized models, developed through studying their learning dynamics. We observe that for many deep models, updates to the weight matrices occur within a low-dimensional invariant subspace. For deep linear models, we demonstrate that their principal components are fitted incrementally within a small subspace, and use these insights to propose a compression algorithm for deep linear networks that involve decreasing the width of their intermediate layers. We empirically evaluate the effectiveness of our compression technique on matrix recovery problems. Remarkably, by using an initialization that exploits the structure of the problem, we observe that our compressed network converges faster than the original network, consistently yielding smaller recovery errors. We substantiate this observation by developing a theory focused on deep matrix factorization. Finally, we empirically demonstrate how our compressed model has the potential to improve the utility of deep nonlinear models. Overall, our algorithm improves the training efficiency by more than 2x, without compromising generalization",
    "checked": true,
    "id": "2f7ffe3f031864d621e41e2b51e8de7daa0e0393",
    "semantic_title": "efficient low-dimensional compression of overparameterized models",
    "citation_count": 1,
    "authors": [
      "Soo Min Kwon",
      "Zekai Zhang",
      "Dogyoon Song",
      "Laura Balzano",
      "Qing Qu"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24b.html": {
    "title": "Data-Adaptive Probabilistic Likelihood Approximation for Ordinary Differential Equations",
    "volume": "main",
    "abstract": "Estimating the parameters of ordinary differential equations (ODEs) is of fundamental importance in many scientific applications. While ODEs are typically approximated with deterministic algorithms, new research on probabilistic solvers indicates that they produce more reliable parameter estimates by better accounting for numerical errors. However, many ODE systems are highly sensitive to their parameter values. This produces deep local maxima in the likelihood function – a problem which existing probabilistic solvers have yet to resolve. Here we present a novel probabilistic ODE likelihood approximation, DALTON, which can dramatically reduce parameter sensitivity by learning from noisy ODE measurements in a data-adaptive manner. Our approximation scales linearly in both ODE variables and time discretization points, and is applicable to ODEs with both partially-unobserved components and non-Gaussian measurement models. Several examples demonstrate that DALTON produces more accurate parameter estimates via numerical optimization than existing probabilistic ODE solvers, and even in some cases than the exact ODE likelihood itself",
    "checked": true,
    "id": "c5e0ac4479fe346421f272933651887dae0a82df",
    "semantic_title": "data-adaptive probabilistic likelihood approximation for ordinary differential equations",
    "citation_count": 2,
    "authors": [
      "Mohan Wu",
      "Martin Lysy"
    ]
  },
  "https://proceedings.mlr.press/v238/el-halabi24a.html": {
    "title": "Fairness in Submodular Maximization over a Matroid Constraint",
    "volume": "main",
    "abstract": "Submodular maximization over a matroid constraint is a fundamental problem with various applications in machine learning. Some of these applications involve decision-making over datapoints with sensitive attributes such as gender or race. In such settings, it is crucial to guarantee that the selected solution is fairly distributed with respect to this attribute. Recently, fairness has been investigated in submodular maximization under a cardinality constraint in both the streaming and offline settings, however the more general problem with matroid constraint has only been considered in the streaming setting and only for monotone objectives. This work fills this gap. We propose various algorithms and impossibility results offering different trade-offs between quality, fairness, and generality",
    "checked": true,
    "id": "043d2624593266f7c6026e240fc6141938b3a1b9",
    "semantic_title": "fairness in submodular maximization over a matroid constraint",
    "citation_count": 1,
    "authors": [
      "Marwa El Halabi",
      "Jakub Tarnawski",
      "Ashkan Norouzi-Fard",
      "Thuy-Duong Vuong"
    ]
  },
  "https://proceedings.mlr.press/v238/shuo-liu24a.html": {
    "title": "Unified Transfer Learning in High-Dimensional Linear Regression",
    "volume": "main",
    "abstract": "Transfer learning plays a key role in modern data analysis when: (1) the target data are scarce but the source data are sufficient; (2) the distributions of the source and target data are heterogeneous. This paper develops an interpretable unified transfer learning model, termed as UTrans, which can detect both transferable variables and source data. More specifically, we establish the estimation error bounds and prove that our bounds are lower than those with target data only. Besides, we propose a source detection algorithm based on hypothesis testing to exclude the nontransferable data. We evaluate and compare UTrans to the existing algorithms in multiple experiments. It is shown that UTrans attains much lower estimation and prediction errors than the existing methods, while preserving interpretability. We finally apply it to the US intergenerational mobility data and compare our proposed algorithms to the classical machine learning algorithms",
    "checked": true,
    "id": "77adff15b396409836db53107f07efb167e4c43b",
    "semantic_title": "unified transfer learning in high-dimensional linear regression",
    "citation_count": 0,
    "authors": [
      "Shuo Shuo Liu"
    ]
  },
  "https://proceedings.mlr.press/v238/de-bartolomeis24a.html": {
    "title": "Hidden yet quantifiable: A lower bound for confounding strength using randomized trials",
    "volume": "main",
    "abstract": "In the era of fast-paced precision medicine, observational studies play a major role in properly evaluating new treatments in clinical practice. Yet, unobserved confounding can significantly compromise causal conclusions drawn from non-randomized data. We propose a novel strategy that leverages randomized trials to quantify unobserved confounding. First, we design a statistical test to detect unobserved confounding above a certain strength. Then, we use the test to estimate an asymptotically valid lower bound on the unobserved confounding strength. We evaluate the power and validity of our statistical test on several synthetic and semi-synthetic datasets. Further, we show how our lower bound can correctly identify the absence and presence of unobserved confounding in a real-world example",
    "checked": true,
    "id": "913822f40013f33d783f1122c9decd4e60c63beb",
    "semantic_title": "hidden yet quantifiable: a lower bound for confounding strength using randomized trials",
    "citation_count": 2,
    "authors": [
      "Piersilvio De Bartolomeis",
      "Javier Abad Martinez",
      "Konstantin Donhauser",
      "Fanny Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/ghosh24a.html": {
    "title": "Towards Achieving Sub-linear Regret and Hard Constraint Violation in Model-free RL",
    "volume": "main",
    "abstract": "We study the constrained Markov decision processes (CMDPs), in which an agent aims to maximize the expected cumulative reward subject to a constraint on the expected total value of a utility function. Existing approaches have primarily focused on \\emph{soft} constraint violation, which allows compensation across episodes, making it easier to satisfy the constraints. In contrast, we consider a stronger \\emph{hard} constraint violation metric, where only positive constraint violations are accumulated. Our main result is the development of the \\emph{first model-free}, \\emph{simulator-free} algorithm that achieves a sub-linear regret and a sub-linear hard constraint violation simultaneously, even in \\emph{large-scale} systems. In particular, we show that $\\tilde{\\mathcal{O}}(\\sqrt{d^3H^4K})$ regret and $\\tilde{\\mathcal{O}}(\\sqrt{d^3H^4K})$ hard constraint violation bounds can be achieved, where $K$ is the number of episodes, $d$ is the dimension of the feature mapping, $H$ is the length of the episode. Our results are achieved via novel adaptations of the primal-dual LSVI-UCB algorithm, i.e., it searches for the dual variable that balances between regret and constraint violation within every episode, rather than updating it at the end of each episode. This turns out to be crucial for our theoretical guarantees when dealing with hard constraint violations",
    "checked": true,
    "id": "270d870719c717ae82f0e97e8ee29887c93e2983",
    "semantic_title": "towards achieving sub-linear regret and hard constraint violation in model-free rl",
    "citation_count": 3,
    "authors": [
      "Arnob Ghosh",
      "Xingyu Zhou",
      "Ness Shroff"
    ]
  },
  "https://proceedings.mlr.press/v238/xie24a.html": {
    "title": "Distributionally Robust Quickest Change Detection using Wasserstein Uncertainty Sets",
    "volume": "main",
    "abstract": "The problem of quickest detection of a change in the distribution of streaming data is considered. It is assumed that the pre-change distribution is known, while the only information about the post-change is through a (small) set of labeled data. This post-change data is used in a data-driven minimax robust framework, where an uncertainty set for the post-change distribution is constructed. The robust change detection problem is studied in an asymptotic setting where the mean time to false alarm goes to infinity. It is shown that the least favorable distribution (LFD) is an exponentially tilted version of the pre-change density and can be obtained efficiently. A Cumulative Sum (CuSum) test based on the LFD, which is referred to as the distributionally robust (DR) CuSum test, is then shown to be asymptotically robust. The results are extended to the case with multiple post-change uncertainty sets and validated using synthetic and real data examples",
    "checked": true,
    "id": "881b0d069e6764e3919471bb9d8706b77b80107d",
    "semantic_title": "distributionally robust quickest change detection using wasserstein uncertainty sets",
    "citation_count": 1,
    "authors": [
      "Liyan Xie",
      "Yuchen Liang",
      "Venugopal V. Veeravalli"
    ]
  },
  "https://proceedings.mlr.press/v238/harsha-tanneru24a.html": {
    "title": "Quantifying Uncertainty in Natural Language Explanations of Large Language Models",
    "volume": "main",
    "abstract": "Large Language Models (LLMs) are increasingly used as powerful tools for several high-stakes natural language processing (NLP) applications. Recent prompting works claim to elicit intermediate reasoning steps and key tokens that serve as proxy explanations for LLM predictions. However, there is no certainty whether these explanations are reliable and reflect the LLM's behavior. In this work, we make one of the first attempts at quantifying the uncertainty in explanations of LLMs. To this end, we propose two novel metrics — Verbalized Uncertainty and Probing Uncertainty — to quantify the uncertainty of generated explanations. While verbalized uncertainty involves prompting the LLM to express its confidence in its explanations, probing uncertainty leverages sample and model perturbations as a means to quantify the uncertainty. Our empirical analysis of benchmark datasets reveals that verbalized uncertainty is not a reliable estimate of explanation confidence. Further, we show that the probing uncertainty estimates are correlated with the faithfulness of an explanation, with lower uncertainty corresponding to explanations with higher faithfulness. Our study provides insights into the challenges and opportunities of quantifying uncertainty in LLM explanations, contributing to the broader discussion of the trustworthiness of foundation models",
    "checked": true,
    "id": "ad402080a4aa66ef3c57a46ce4685a47a3cc0a61",
    "semantic_title": "quantifying uncertainty in natural language explanations of large language models",
    "citation_count": 5,
    "authors": [
      "Sree Harsha Tanneru",
      "Chirag Agarwal",
      "Himabindu Lakkaraju"
    ]
  },
  "https://proceedings.mlr.press/v238/raed-mualem24a.html": {
    "title": "Submodular Minimax Optimization: Finding Effective Sets",
    "volume": "main",
    "abstract": "Despite the rich existing literature about minimax optimization in continuous settings, only very partial results of this kind have been obtained for combinatorial settings. In this paper, we fill this gap by providing a characterization of submodular minimax optimization, the problem of finding a set (for either the min or the max player) that is effective against every possible response. We show when and under what conditions we can find such sets. We also demonstrate how minimax submodular optimization provides robust solutions for downstream machine learning applications such as (i) prompt engineering in large language models, (ii) identifying robust waiting locations for ride-sharing, (iii) kernelization of the difficulty of instances of the last setting, and (iv) finding adversarial images. Our experiments show that our proposed algorithms consistently outperform other baselines",
    "checked": true,
    "id": "ea982b0cdd588340c1b6e2abc2dae51bf5463b21",
    "semantic_title": "submodular minimax optimization: finding effective sets",
    "citation_count": 4,
    "authors": [
      "Loay Raed Mualem",
      "Ethan R Elenberg",
      "Moran Feldman",
      "Amin Karbasi"
    ]
  },
  "https://proceedings.mlr.press/v238/haldar24a.html": {
    "title": "Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability",
    "volume": "main",
    "abstract": "The existence of adversarial attacks on machine learning models imperceptible to a human is still quite a mystery from a theoretical perspective. In this work, we introduce two notions of adversarial attacks: natural or on-manifold attacks, which are perceptible by a human/oracle, and unnatural or off-manifold attacks, which are not. We argue that the existence of the off-manifold attacks is a natural consequence of the dimension gap between the intrinsic and ambient dimensions of the data. For 2-layer ReLU networks, we prove that even though the dimension gap does not affect generalization performance on samples drawn from the observed data space, it makes the clean-trained model more vulnerable to adversarial perturbations in the off-manifold direction of the data space. Our main results provide an explicit relationship between the $\\ell_2,\\ell_{\\infty}$ attack strength of the on/off-manifold attack and the dimension gap",
    "checked": true,
    "id": "d29ed434340b91c4addb84cc6d03de5dc73ca638",
    "semantic_title": "effect of ambient-intrinsic dimension gap on adversarial vulnerability",
    "citation_count": 1,
    "authors": [
      "Rajdeep Haldar",
      "Yue Xing",
      "Qifan Song"
    ]
  },
  "https://proceedings.mlr.press/v238/futami24a.html": {
    "title": "Information-theoretic Analysis of Bayesian Test Data Sensitivity",
    "volume": "main",
    "abstract": "Bayesian inference is often used to quantify uncertainty. Several recent analyses have rigorously decomposed uncertainty in prediction by Bayesian inference into two types: the inherent randomness in the data generation process and the variability due to lack of data respectively. Existing studies have analyzed these uncertainties from an information-theoretic perspective, assuming the model is well-specified and treating the model parameters as latent variables. However, such information-theoretic uncertainty analysis fails to account for a widely believed property of uncertainty known as sensitivity between test and training data. This means that if the test data is similar to the training data in some sense, the uncertainty will be smaller. In this study, we study such sensitivity using a new decomposition of uncertainty. Our analysis successfully defines such sensitivity using information-theoretic quantities. Furthermore, we extend the existing analysis of Bayesian meta-learning and show the novel sensitivities among tasks for the first time",
    "checked": true,
    "id": "e746c2ff2a5e18d0787905e4dbd0d6ec9b208511",
    "semantic_title": "information-theoretic analysis of bayesian test data sensitivity",
    "citation_count": 0,
    "authors": [
      "Futoshi Futami",
      "Tomoharu Iwata"
    ]
  },
  "https://proceedings.mlr.press/v238/mosenzon24a.html": {
    "title": "Scalable Algorithms for Individual Preference Stable Clustering",
    "volume": "main",
    "abstract": "In this paper, we study the individual preference (IP) stability, which is an notion capturing individual fairness and stability in clustering. Within this setting, a clustering is $\\alpha$-IP stable when each data point's average distance to its cluster is no more than $\\alpha$ times its average distance to any other cluster. In this paper, we study the natural local search algorithm for IP stable clustering. Our analysis confirms a $O(\\log n)$-IP stability guarantee for this algorithm, where $n$ denotes the number of points in the input. Furthermore, by refining the local search approach, we show it runs in an almost linear time, $\\tilde{O}(nk)$",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ron Mosenzon",
      "Ali Vakilian"
    ]
  },
  "https://proceedings.mlr.press/v238/yang24b.html": {
    "title": "Orthogonal Gradient Boosting for Simpler Additive Rule Ensembles",
    "volume": "main",
    "abstract": "Gradient boosting of prediction rules is an efficient approach to learn potentially interpretable yet accurate probabilistic models. However, actual interpretability requires to limit the number and size of the generated rules, and existing boosting variants are not designed for this purpose. Though corrective boosting refits all rule weights in each iteration to minimise prediction risk, the included rule conditions tend to be sub-optimal, because commonly used objective functions fail to anticipate this refitting. Here, we address this issue by a new objective function that measures the angle between the risk gradient vector and the projection of the condition output vector onto the orthogonal complement of the already selected conditions. This approach correctly approximates the ideal update of adding the risk gradient itself to the model and favours the inclusion of more general and thus shorter rules. As we demonstrate using a wide range of prediction tasks, this significantly improves the comprehensibility/accuracy trade-off of the fitted ensemble. Additionally, we show how objective values for related rule conditions can be computed incrementally to avoid any substantial computational overhead of the new method",
    "checked": true,
    "id": "de8ad7e6d58c831c9889077dfd9bf1052ed3fdbf",
    "semantic_title": "orthogonal gradient boosting for simpler additive rule ensembles",
    "citation_count": 0,
    "authors": [
      "Fan Yang",
      "Pierre Le Bodic",
      "Michael Kamp",
      "Mario Boley"
    ]
  },
  "https://proceedings.mlr.press/v238/li24g.html": {
    "title": "When No-Rejection Learning is Consistent for Regression with Rejection",
    "volume": "main",
    "abstract": "Learning with rejection has been a prototypical model for studying the human-AI interaction on prediction tasks. Upon the arrival of a sample instance, the model first uses a rejector to decide whether to accept and use the AI predictor to make a prediction or reject and defer the sample to humans. Learning such a model changes the structure of the original loss function and often results in undesirable non-convexity and inconsistency issues. For the classification with rejection problem, several works develop consistent surrogate losses for the joint learning of the predictor and the rejector, while there have been fewer works for the regression counterpart. This paper studies the regression with rejection (RwR) problem and investigates a no-rejection learning strategy that uses all the data to learn the predictor. We first establish the consistency for such a strategy under the weak realizability condition. Then for the case without the weak realizability, we show that the excessive risk can also be upper bounded with the sum of two parts: prediction error and calibration error. Lastly, we demonstrate the advantage of such a proposed learning strategy with empirical evidence",
    "checked": true,
    "id": "282068bc365f5ad531c4efc3784c0786f55ae498",
    "semantic_title": "when no-rejection learning is consistent for regression with rejection",
    "citation_count": 0,
    "authors": [
      "Xiaocheng Li",
      "Shang Liu",
      "Chunlin Sun",
      "Hanzhao Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/yi24a.html": {
    "title": "Filter, Rank, and Prune: Learning Linear Cyclic Gaussian Graphical Models",
    "volume": "main",
    "abstract": "Causal structures in the real world often exhibit cycles naturally due to equilibrium, homeostasis, or feedback. However, causal discovery from observational studies regarding cyclic models has not been investigated extensively because the underlying structure of a linear cyclic structural equation model (SEM) cannot be determined solely from observational data. Inspired by the Bayesian information Criterion (BIC), we construct a score function that assesses both accuracy and sparsity of the structure to determine which linear Gaussian SEM is the best when only observational data is given. Then, we formulate a causal discovery problem as an optimization problem of the measure and propose the Filter, Rank, and Prune (FRP) method for solving it. We empirically demonstrate that our method outperforms competitive cyclic causal discovery baselines",
    "checked": true,
    "id": "e32b65410fa003b9880b80a666906db0452cfef3",
    "semantic_title": "filter, rank, and prune: learning linear cyclic gaussian graphical models",
    "citation_count": 0,
    "authors": [
      "Soheun Yi",
      "Sanghack Lee"
    ]
  },
  "https://proceedings.mlr.press/v238/holland24a.html": {
    "title": "Robust variance-regularized risk minimization with concomitant scaling",
    "volume": "main",
    "abstract": "Under losses which are potentially heavy-tailed, we consider the task of minimizing sums of the loss mean and standard deviation, without trying to accurately estimate the variance. By modifying a technique for variance-free robust mean estimation to fit our problem setting, we derive a simple learning procedure which can be easily combined with standard gradient-based solvers to be used in traditional machine learning workflows. Empirically, we verify that our proposed approach, despite its simplicity, performs as well or better than even the best-performing candidates derived from alternative criteria such as CVaR or DRO risks on a variety of datasets",
    "checked": true,
    "id": "cf422c3ab66720a94b199e049b6986e2ecad1411",
    "semantic_title": "robust variance-regularized risk minimization with concomitant scaling",
    "citation_count": 0,
    "authors": [
      "Matthew J. Holland"
    ]
  },
  "https://proceedings.mlr.press/v238/fan24a.html": {
    "title": "Fast and Adversarial Robust Kernelized SDU Learning",
    "volume": "main",
    "abstract": "SDU learning, a weakly supervised learning problem with only pairwise similarities, dissimilarities data points and unlabeled data available, has many practical applications. However, it is still lacking in defense against adversarial samples, and its learning process can be expensive. To address this gap, we propose a novel adversarial training framework for SDU learning. Our approach reformulates the conventional minimax problem as an equivalent minimization problem based on the kernel perspective, departing from traditional confrontational training methods. Additionally, we employ the random gradient method and random features to accelerate the training process. Theoretical analysis shows that our method can converge to a stationary point at a rate of $\\mathcal{O}(1/T^{1/4})$. Our experimental results show that our algorithm is superior to other adversarial training methods in terms of generalization, efficiency and scalability against various adversarial attacks",
    "checked": true,
    "id": "cdf499af47df6e734071a5f4c327fe58735da0cd",
    "semantic_title": "fast and adversarial robust kernelized sdu learning",
    "citation_count": 0,
    "authors": [
      "Yajing Fan",
      "wanli shi",
      "Yi Chang",
      "Bin Gu"
    ]
  },
  "https://proceedings.mlr.press/v238/zhai24a.html": {
    "title": "Learning Sampling Policy to Achieve Fewer Queries for Zeroth-Order Optimization",
    "volume": "main",
    "abstract": "Zeroth-order (ZO) methods, which use the finite difference of two function evaluations (also called ZO gradient) to approximate first-order gradient, have attracted much attention recently in machine learning because of their broad applications. The accuracy of the ZO gradient highly depends on how many finite differences are averaged, which are intrinsically determined by the number of perturbations randomly drawn from a distribution. Existing ZO methods try to learn a data-driven distribution for sampling the perturbations to improve the efficiency of ZO optimization (ZOO) algorithms. In this paper, we explore a new and parallel direction, \\textit{i.e.}, learn an optimal sampling policy instead of using a totally random strategy to generate perturbations based on the techniques of reinforcement learning (RL), which makes it possible to approximate the gradient with only two function evaluations. Specifically, we first formulate the problem of learning a sampling policy as a Markov decision process. Then, we propose our ZO-RL algorithm, \\textit{i.e.}, using deep deterministic policy gradient, an actor-critic RL algorithm to learn a sampling policy that can guide the generation of perturbed vectors in getting ZO gradients as accurately as possible. Importantly, the existing ZOO algorithms for learning a distribution can be plugged in to improve the exploration of ZO-RL. Experimental results with different ZO estimators show that our ZO-RL algorithm can effectively reduce the query complexity of ZOO algorithms and converge faster than existing ZOO algorithms, especially in the later stage of the optimization process",
    "checked": true,
    "id": "8c2bad0494c378b4ea7fc1446967289d020a6bda",
    "semantic_title": "learning sampling policy to achieve fewer queries for zeroth-order optimization",
    "citation_count": 0,
    "authors": [
      "Zhou Zhai",
      "Wanli Shi",
      "Heng Huang",
      "Yi Chang",
      "Bin Gu"
    ]
  },
  "https://proceedings.mlr.press/v238/medvedovsky24a.html": {
    "title": "Efficient Graph Laplacian Estimation by Proximal Newton",
    "volume": "main",
    "abstract": "The Laplacian-constrained Gaussian Markov Random Field (LGMRF) is a common multivariate statistical model for learning a weighted sparse dependency graph from given data. This graph learning problem can be formulated as a maximum likelihood estimation (MLE) of the precision matrix, subject to Laplacian structural constraints, with a sparsity-inducing penalty term. This paper aims to solve this learning problem accurately and efficiently. First, since the commonly used $\\ell_1$-norm penalty is inappropriate in this setting and may lead to a complete graph, we employ the nonconvex minimax concave penalty (MCP), which promotes sparse solutions with lower estimation bias. Second, as opposed to existing first-order methods for this problem, we develop a second-order proximal Newton approach to obtain an efficient solver, utilizing several algorithmic features, such as using conjugate gradients, preconditioning, and splitting to active/free sets. Numerical experiments demonstrate the advantages of the proposed method in terms of both computational complexity and graph learning accuracy compared to existing methods",
    "checked": true,
    "id": "38baee574980808dc04adcaaf3631c99dc260c18",
    "semantic_title": "efficient graph laplacian estimation by proximal newton",
    "citation_count": 1,
    "authors": [
      "Yakov Medvedovsky",
      "Eran Treister",
      "Tirza S Routtenberg"
    ]
  },
  "https://proceedings.mlr.press/v238/huyuk24a.html": {
    "title": "Adaptive Experiment Design with Synthetic Controls",
    "volume": "main",
    "abstract": "Clinical trials are typically run in order to understand the effects of a new treatment on a given population of patients. However, patients in large populations rarely respond the same way to the same treatment. This heterogeneity in patient responses necessitates trials that investigate effects on multiple subpopulations—especially when a treatment has marginal or no benefit for the overall population but might have significant benefit for a particular subpopulation. Motivated by this need, we propose Syntax, an exploratory trial design that identifies subpopulations with positive treatment effect among many subpopulations. Syntax is sample efficient as it (i) recruits and allocates patients adaptively and (ii) estimates treatment effects by forming synthetic controls for each subpopulation that combines control samples from other subpopulations. We validate the performance of Syntax and provide insights into when it might have an advantage over conventional trial designs through experiments",
    "checked": true,
    "id": "d50e832266ca4476bbf26a8e6808c9b8950cca01",
    "semantic_title": "adaptive experiment design with synthetic controls",
    "citation_count": 1,
    "authors": [
      "Alihan Hüyük",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ]
  },
  "https://proceedings.mlr.press/v238/concha-duarte24a.html": {
    "title": "Online non-parametric likelihood-ratio estimation by Pearson-divergence functional minimization",
    "volume": "main",
    "abstract": "Quantifying the difference between two probability density functions, $p$ and $q$, using available data, is a fundamental problem in Statistics and Machine Learning. A usual approach for addressing this problem is the likelihood-ratio estimation (LRE) between $p$ and $q$, which -to our best knowledge- has been investigated mainly for the offline case. This paper contributes by introducing a new framework for online non-parametric LRE (OLRE) for the setting where pairs of iid observations $(x_t \\sim p, x'_t \\sim q)$ are observed over time. The non-parametric nature of our approach has the advantage of being agnostic to the forms of $p$ and $q$. Moreover, we capitalize on the recent advances in Kernel Methods and functional minimization to develop an estimator that can be efficiently updated at every iteration. We provide theoretical guarantees for the performance of the OLRE method along with empirical validation in synthetic experiments",
    "checked": true,
    "id": "ee6565cf693f417712e3028da7f0a3a576bebc15",
    "semantic_title": "online non-parametric likelihood-ratio estimation by pearson-divergence functional minimization",
    "citation_count": 0,
    "authors": [
      "Alejandro D. de la Concha Duarte",
      "Nicolas Vayatis",
      "Argyris Kalogeratos"
    ]
  },
  "https://proceedings.mlr.press/v238/barrainkua24a.html": {
    "title": "Uncertainty Matters: Stable Conclusions under Unstable Assessment of Fairness Results",
    "volume": "main",
    "abstract": "Recent studies highlight the effectiveness of Bayesian methods in assessing algorithm performance, particularly in fairness and bias evaluation. We present Uncertainty Matters, a multi-objective uncertainty-aware algorithmic comparison framework. In fairness focused scenarios, it models sensitive group confusion matrices using Bayesian updates and facilitates joint comparison of performance (e.g., accuracy) and fairness metrics (e.g., true positive rate parity). Our approach works seamlessly with common evaluation methods like K-fold cross-validation, effectively addressing dependencies among the K posterior metric distributions. The integration of correlated information is carried out through a procedure tailored to the classifier's complexity. Experiments demonstrate that the insights derived from algorithmic comparisons employing the Uncertainty Matters approach are more informative, reliable, and less influenced by particular data partitions. Code for the paper is publicly available at \\url{https://github.com/abarrainkua/UncertaintyMatters}",
    "checked": true,
    "id": "f4d859cd13e72cf9047d973a2505869c2c230621",
    "semantic_title": "uncertainty matters: stable conclusions under unstable assessment of fairness results",
    "citation_count": 0,
    "authors": [
      "Ainhize Barrainkua",
      "Paula Gordaliza",
      "Jose A. Lozano",
      "Novi Quadrianto"
    ]
  },
  "https://proceedings.mlr.press/v238/rammal24a.html": {
    "title": "Communication Compression for Byzantine Robust Learning: New Efficient Algorithms and Improved Rates",
    "volume": "main",
    "abstract": "Byzantine robustness is an essential feature of algorithms for certain distributed optimization problems, typically encountered in collaborative/federated learning. These problems are usually huge-scale, implying that communication compression is also imperative for their resolution. These factors have spurred recent algorithmic and theoretical developments in the literature of Byzantine-robust learning with compression. In this paper, we contribute to this research area in two main directions. First, we propose a new Byzantine-robust method with compression – Byz-DASHA-PAGE – and prove that the new method has better convergence rate (for non-convex and Polyak-Lojasiewicz smooth optimization problems), smaller neighborhood size in the heterogeneous case, and tolerates more Byzantine workers under over-parametrization than the previous method with SOTA theoretical convergence guarantees (Byz-VR-MARINA). Secondly, we develop the first Byzantine-robust method with communication compression and error feedback – Byz-EF21 – along with its bi-directional compression version – Byz-EF21-BC – and derive the convergence rates for these methods for non-convex and Polyak-Lojasiewicz smooth case. We test the proposed methods and illustrate our theoretical findings in the numerical experiments",
    "checked": true,
    "id": "42b380c5c36092400e6ad6259709c90bf37855c1",
    "semantic_title": "communication compression for byzantine robust learning: new efficient algorithms and improved rates",
    "citation_count": 1,
    "authors": [
      "Ahmad Rammal",
      "Kaja Gruntkowska",
      "Nikita Fedin",
      "Eduard Gorbunov",
      "Peter Richtarik"
    ]
  },
  "https://proceedings.mlr.press/v238/kuroki24a.html": {
    "title": "Best-of-Both-Worlds Algorithms for Linear Contextual Bandits",
    "volume": "main",
    "abstract": "We study best-of-both-worlds algorithms for $K$-armed linear contextual bandits. Our algorithms deliver near-optimal regret bounds in both the adversarial and stochastic regimes, without prior knowledge about the environment. In the stochastic regime, we achieve the polylogarithmic rate $\\frac{(dK)^2\\mathrm{poly}\\!\\log(dKT)}{\\Delta_{\\min}}$, where $\\Delta_{\\min}$ is the minimum suboptimality gap over the $d$-dimensional context space. In the adversarial regime, we obtain either the first-order $\\widetilde{\\mathcal{O}}(dK\\sqrt{L^*})$ bound, or the second-order $\\widetilde{\\mathcal{O}}(dK\\sqrt{\\Lambda^*})$ bound, where $L^*$ is the cumulative loss of the best action and $\\Lambda^*$ is a notion of the cumulative second moment for the losses incurred by the algorithm. Moreover, we develop an algorithm based on FTRL with Shannon entropy regularizer that does not require the knowledge of the inverse of the covariance matrix, and achieves a polylogarithmic regret in the stochastic regime while obtaining $\\widetilde{\\mathcal{O}}\\big(dK\\sqrt{T}\\big)$ regret bounds in the adversarial regime",
    "checked": true,
    "id": "df7d75f4066de1a86cbb669d20948535d25cf235",
    "semantic_title": "best-of-both-worlds algorithms for linear contextual bandits",
    "citation_count": 1,
    "authors": [
      "Yuko Kuroki",
      "Alberto Rumi",
      "Taira Tsuchiya",
      "Fabio Vitale",
      "Nicolò Cesa-Bianchi"
    ]
  },
  "https://proceedings.mlr.press/v238/nakamura24a.html": {
    "title": "Fixed-Budget Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit",
    "volume": "main",
    "abstract": "We study the real-valued combinatorial pure exploration of the multi-armed bandit in the fixed-budget setting. We first introduce an algorithm named the Combinatorial Successive Asign (CSA) algorithm, which is the first algorithm that can identify the best action even when the size of the action class is exponentially large with respect to the number of arms. We show that the upper bound of the probability of error of the CSA algorithm matches a lower bound up to a logarithmic factor in the exponent. Then, we introduce another algorithm named the Minimax Combinatorial Successive Accepts and Rejects (Minimax-CombSAR) algorithm for the case where the size of the action class is polynomial, and show that it is optimal, which matches a lower bound. Finally, we experimentally compare the algorithms with previous methods and show that our algorithm performs better",
    "checked": true,
    "id": "b67d97145201272e9aeb498d46f99d78d30149d6",
    "semantic_title": "fixed-budget real-valued combinatorial pure exploration of multi-armed bandit",
    "citation_count": 1,
    "authors": [
      "Shintaro Nakamura",
      "Masashi Sugiyama"
    ]
  },
  "https://proceedings.mlr.press/v238/frick24a.html": {
    "title": "Scalable Learning of Item Response Theory Models",
    "volume": "main",
    "abstract": "Item Response Theory (IRT) models aim to assess latent abilities of $n$ examinees along with latent difficulty characteristics of $m$ test items from categorical data that indicates the quality of their corresponding answers. Classical psychometric assessments are based on a relatively small number of examinees and items, say a class of $200$ students solving an exam comprising $10$ problems. More recent global large scale assessments such as PISA, or internet studies, may lead to significantly increased numbers of participants. Additionally, in the context of Machine Learning where algorithms take the role of examinees and data analysis problems take the role of items, both $n$ and $m$ may become very large, challenging the efficiency and scalability of computations. To learn the latent variables in IRT models from large data, we leverage the similarity of these models to logistic regression, which can be approximated accurately using small weighted subsets called coresets. We develop coresets for their use in alternating IRT training algorithms, facilitating scalable learning from large data",
    "checked": true,
    "id": "f4c0ee84ea25c9e1e9623e5da7482711e8e5a834",
    "semantic_title": "scalable learning of item response theory models",
    "citation_count": 2,
    "authors": [
      "Susanne Frick",
      "Amer Krivosija",
      "Alexander Munteanu"
    ]
  },
  "https://proceedings.mlr.press/v238/nika24a.html": {
    "title": "Corruption-Robust Offline Two-Player Zero-Sum Markov Games",
    "volume": "main",
    "abstract": "We study data corruption robustness in offline two-player zero-sum Markov games. Given a dataset of realized trajectories of two players, an adversary is allowed to modify an $\\epsilon$-fraction of it. The learner's goal is to identify an approximate Nash Equilibrium policy pair from the corrupted data. We consider this problem in linear Markov games under different degrees of data coverage and corruption. We start by providing an information-theoretic lower bound on the suboptimality gap of any learner. Next, we propose robust versions of the Pessimistic Minimax Value Iteration algorithm (Zhong et al., 2022), both under coverage on the corrupted data and under coverage only on the clean data, and show that they achieve (near)-optimal suboptimality gap bounds with respect to $\\epsilon$. We note that we are the first to provide such a characterization of the problem of learning approximate Nash Equilibrium policies in offline two-player zero-sum Markov games under data corruption",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andi Nika",
      "Debmalya Mandal",
      "Adish Singla",
      "Goran Radanovic"
    ]
  },
  "https://proceedings.mlr.press/v238/iwazaki24a.html": {
    "title": "Risk Seeking Bayesian Optimization under Uncertainty for Obtaining Extremum",
    "volume": "main",
    "abstract": "Real-world black-box optimization tasks often focus on obtaining the best reward, which includes an intrinsic random quantity from uncontrollable environmental factors. For this problem, we formulate a novel risk-seeking optimization problem whose aim is to obtain the best possible reward within a fixed budget under uncontrollable factors. We consider two settings: (1) environmental model setting for the case that we can observe uncontrollable environmental variables that affect the observation as the input of a target function, and (2) heteroscedastic model setting for the case that any uncontrollable variables cannot be observed. We propose a novel Bayesian optimization method called kernel explore-then-commit (kernel-ETC) and provide the regret upper bound for both settings. We demonstrate the effectiveness of kernel-ETC through several numerical experiments, including the hyperparameter tuning task and the simulation function derived from polymer synthesis real data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shogo Iwazaki",
      "Tomohiko Tanabe",
      "Mitsuru Irie",
      "Shion Takeno",
      "Yu Inatsu"
    ]
  },
  "https://proceedings.mlr.press/v238/wesel24a.html": {
    "title": "Quantized Fourier and Polynomial Features for more Expressive Tensor Network Models",
    "volume": "main",
    "abstract": "In the context of kernel machines, polynomial and Fourier features are commonly used to provide a nonlinear extension to linear models by mapping the data to a higher-dimensional space. Unless one considers the dual formulation of the learning problem, which renders exact large-scale learning unfeasible, the exponential increase of model parameters in the dimensionality of the data caused by their tensor-product structure prohibits to tackle high-dimensional problems. One of the possible approaches to circumvent this exponential scaling is to exploit the tensor structure present in the features by constraining the model weights to be an underparametrized tensor network. In this paper we quantize, i.e. further tensorize, polynomial and Fourier features. Based on this feature quantization we propose to quantize the associated model weights, yielding quantized models. We show that, for the same number of model parameters, the resulting quantized models have a higher bound on the VC-dimension as opposed to their non-quantized counterparts, at no additional computational cost while learning from identical features. We verify experimentally how this additional tensorization regularizes the learning problem by prioritizing the most salient features in the data and how it provides models with increased generalization capabilities. We finally benchmark our approach on large regression task, achieving state-of-the-art results on a laptop computer",
    "checked": true,
    "id": "9965b5514fcb3d810edff44b9bf1449bef5f6135",
    "semantic_title": "quantized fourier and polynomial features for more expressive tensor network models",
    "citation_count": 0,
    "authors": [
      "Frederiek Wesel",
      "Kim Batselier"
    ]
  },
  "https://proceedings.mlr.press/v238/kjaersgaard24a.html": {
    "title": "Fair Soft Clustering",
    "volume": "main",
    "abstract": "Scholars in the machine learning community have recently focused on analyzing the fairness of learning models, including clustering algorithms. In this work we study fair clustering in a probabilistic (soft) setting, where observations may belong to several clusters determined by probabilities. We introduce new probabilistic fairness metrics, which generalize and extend existing non-probabilistic fairness frameworks and propose an algorithm for obtaining a fair probabilistic cluster solution from a data representation known as a fairlet decomposition. Finally, we demonstrate our proposed fairness metrics and algorithm by constructing a fair Gaussian mixture model on three real-world datasets. We achieve this by identifying balanced micro-clusters which minimize the distances induced by the model, and on which traditional clustering can be performed while ensuring the fairness of the solution",
    "checked": true,
    "id": "2b7f26a1b4b6ab59099d24f6a5d06391a988b8c0",
    "semantic_title": "fair soft clustering",
    "citation_count": 0,
    "authors": [
      "Rune D. Kjærsgaard",
      "Pekka Parviainen",
      "Saket Saurabh",
      "Madhumita Kundu",
      "Line Clemmensen"
    ]
  },
  "https://proceedings.mlr.press/v238/tong24a.html": {
    "title": "Simulation-Free Schrödinger Bridges via Score and Flow Matching",
    "volume": "main",
    "abstract": "We present simulation-free score and flow matching ([SF]$^2$M), a simulation-free objective for inferring stochastic dynamics given unpaired samples drawn from arbitrary source and target distributions. Our method generalizes both the score-matching loss used in the training of diffusion models and the recently proposed flow matching loss used in the training of continuous normalizing flows. [SF]$^2$M interprets continuous-time stochastic generative modeling as a Schrödinger bridge problem. It relies on static entropy-regularized optimal transport, or a minibatch approximation, to efficiently learn the SB without simulating the learned stochastic process. We find that [SF]$^2$M is more efficient and gives more accurate solutions to the SB problem than simulation-based methods from prior work. Finally, we apply [SF]$^2$M to the problem of learning cell dynamics from snapshot data. Notably, [SF]$^2$M is the first method to accurately model cell dynamics in high dimensions and can recover known gene regulatory networks from simulated data. Our code is available in the TorchCFM package at \\url{https://github.com/atong01/conditional-flow-matching}",
    "checked": true,
    "id": "38780dbcee61d67aeeb800d33eded440d7fcd32c",
    "semantic_title": "simulation-free schrödinger bridges via score and flow matching",
    "citation_count": 22,
    "authors": [
      "Alexander Y. Tong",
      "Nikolay Malkin",
      "Kilian Fatras",
      "Lazar Atanackovic",
      "Yanlei Zhang",
      "Guillaume Huguet",
      "Guy Wolf",
      "Yoshua Bengio"
    ]
  },
  "https://proceedings.mlr.press/v238/jolicoeur-martineau24a.html": {
    "title": "Generating and Imputing Tabular Data via Diffusion and Flow-based Gradient-Boosted Trees",
    "volume": "main",
    "abstract": "Tabular data is hard to acquire and is subject to missing values. This paper introduces a novel approach for generating and imputing mixed-type (continuous and categorical) tabular data utilizing score-based diffusion and conditional flow matching. In contrast to prior methods that rely on neural networks to learn the score function or the vector field, we adopt XGBoost, a widely used Gradient-Boosted Tree (GBT) technique. To test our method, we build one of the most extensive benchmarks for tabular data generation and imputation, containing 27 diverse datasets and 9 metrics. Through empirical evaluation across the benchmark, we demonstrate that our approach outperforms deep-learning generation methods in data generation tasks and remains competitive in data imputation. Notably, it can be trained in parallel using CPUs without requiring a GPU. Our Python and R code is available at \\url{https://github.com/SamsungSAILMontreal/ForestDiffusion}",
    "checked": true,
    "id": "2ba40e67539b2ea5c2ca8882ebf4497743e55e96",
    "semantic_title": "generating and imputing tabular data via diffusion and flow-based gradient-boosted trees",
    "citation_count": 11,
    "authors": [
      "Alexia Jolicoeur-Martineau",
      "Kilian Fatras",
      "Tal Kachman"
    ]
  },
  "https://proceedings.mlr.press/v238/carpintero-perez24a.html": {
    "title": "Gaussian process regression with Sliced Wasserstein Weisfeiler-Lehman graph kernels",
    "volume": "main",
    "abstract": "Supervised learning has recently garnered significant attention in the field of computational physics due to its ability to effectively extract complex patterns for tasks like solving partial differential equations, or predicting material properties. Traditionally, such datasets consist of inputs given as meshes with a large number of nodes representing the problem geometry (seen as graphs), and corresponding outputs obtained with a numerical solver. This means the supervised learning model must be able to handle large and sparse graphs with continuous node attributes. In this work, we focus on Gaussian process regression, for which we introduce the Sliced Wasserstein Weisfeiler-Lehman (SWWL) graph kernel. In contrast to existing graph kernels, the proposed SWWL kernel enjoys positive definiteness and a drastic complexity reduction, which makes it possible to process datasets that were previously impossible to handle. The new kernel is first validated on graph classification for molecular datasets, where the input graphs have a few tens of nodes. The efficiency of the SWWL kernel is then illustrated on graph regression in computational fluid dynamics and solid mechanics, where the input graphs are made up of tens of thousands of nodes",
    "checked": true,
    "id": "b989adba7eb8e8e0013df170b8a781ee5dd53a3b",
    "semantic_title": "gaussian process regression with sliced wasserstein weisfeiler-lehman graph kernels",
    "citation_count": 1,
    "authors": [
      "Raphaël Carpintero Perez",
      "Sébastien Da Veiga",
      "Josselin Garnier",
      "Brian Staber"
    ]
  },
  "https://proceedings.mlr.press/v238/robert-nicoud24a.html": {
    "title": "Intrinsic Gaussian Vector Fields on Manifolds",
    "volume": "main",
    "abstract": "Various applications ranging from robotics to climate science require modeling signals on non-Euclidean domains, such as the sphere. Gaussian process models on manifolds have recently been proposed for such tasks, in particular when uncertainty quantification is needed. In the manifold setting, vector-valued signals can behave very differently from scalar-valued ones, with much of the progress so far focused on modeling the latter. The former, however, are crucial for many applications, such as modeling wind speeds or force fields of unknown dynamical systems. In this paper, we propose novel Gaussian process models for vector-valued signals on manifolds that are intrinsically defined and account for the geometry of the space in consideration. We provide computational primitives needed to deploy the resulting Hodge-Matérn Gaussian vector fields on the two-dimensional sphere and the hypertori. Further, we highlight two generalization directions: discrete two-dimensional meshes and \"ideal\" manifolds like hyperspheres, Lie groups, and homogeneous spaces. Finally, we show that our Gaussian vector fields constitute considerably more refined inductive biases than the extrinsic fields proposed before",
    "checked": true,
    "id": "0c100d324968f0a3c2ed14027b5b6c21bc5827f2",
    "semantic_title": "intrinsic gaussian vector fields on manifolds",
    "citation_count": 2,
    "authors": [
      "Daniel Robert-Nicoud",
      "Andreas Krause",
      "Viacheslav Borovitskiy"
    ]
  },
  "https://proceedings.mlr.press/v238/cosier24a.html": {
    "title": "A Unifying Variational Framework for Gaussian Process Motion Planning",
    "volume": "main",
    "abstract": "To control how a robot moves, motion planning algorithms must compute paths in high-dimensional state spaces while accounting for physical constraints related to motors and joints, generating smooth and stable motions, avoiding obstacles, and preventing collisions. A motion planning algorithm must therefore balance competing demands, and should ideally incorporate uncertainty to handle noise, model errors, and facilitate deployment in complex environments. To address these issues, we introduce a framework for robot motion planning based on variational Gaussian processes, which unifies and generalizes various probabilistic-inference-based motion planning algorithms, and connects them with optimization-based planners. Our framework provides a principled and flexible way to incorporate equality-based, inequality-based, and soft motion-planning constraints during end-to-end training, is straightforward to implement, and provides both interval-based and Monte-Carlo-based uncertainty estimates. We conduct experiments using different environments and robots, comparing against baseline approaches based on the feasibility of the planned paths, and obstacle avoidance quality. Results show that our proposed approach yields a good balance between success rates and path quality",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lucas C. Cosier",
      "Rares Iordan",
      "Sicelukwanda N. T. Zwane",
      "Giovanni Franzese",
      "James T. Wilson",
      "Marc Deisenroth",
      "Alexander Terenin",
      "Yasemin Bekiroglu"
    ]
  },
  "https://proceedings.mlr.press/v238/benard24a.html": {
    "title": "MMD-based Variable Importance for Distributional Random Forest",
    "volume": "main",
    "abstract": "Distributional Random Forest (DRF) is a flexible forest-based method to estimate the full conditional distribution of a multivariate output of interest given input variables. In this article, we introduce a variable importance algorithm for DRFs, based on the well-established drop and relearn principle and MMD distance. While traditional importance measures only detect variables with an influence on the output mean, our algorithm detects variables impacting the output distribution more generally. We show that the introduced importance measure is consistent, exhibits high empirical performance on both real and simulated data, and outperforms competitors. In particular, our algorithm is highly efficient to select variables through recursive feature elimination, and can therefore provide small sets of variables to build accurate estimates of conditional output distributions",
    "checked": true,
    "id": "944442583f0bb86699b07101863c103516cc5297",
    "semantic_title": "mmd-based variable importance for distributional random forest",
    "citation_count": 0,
    "authors": [
      "Clément Bénard",
      "Jeffrey Näf",
      "Julie Josse"
    ]
  },
  "https://proceedings.mlr.press/v238/tebbe24a.html": {
    "title": "Efficiently Computable Safety Bounds for Gaussian Processes in Active Learning",
    "volume": "main",
    "abstract": "Active learning of physical systems must commonly respect practical safety constraints, which restricts the exploration of the design space. Gaussian Processes (GPs) and their calibrated uncertainty estimations are widely used for this purpose. In many technical applications the design space is explored via continuous trajectories, along which the safety needs to be assessed. This is particularly challenging for strict safety requirements in GP methods, as it employs computationally expensive Monte Carlo sampling of high quantiles. We address these challenges by providing provable safety bounds based on the adaptively sampled median of the supremum of the posterior GP. Our method significantly reduces the number of samples required for estimating high safety probabilities, resulting in faster evaluation without sacrificing accuracy and exploration speed. The effectiveness of our safe active learning approach is demonstrated through extensive simulations and validated using a real-world engine example",
    "checked": true,
    "id": "54fe70c363ca7fccc24ecc528959f4f3c0577e07",
    "semantic_title": "efficiently computable safety bounds for gaussian processes in active learning",
    "citation_count": 2,
    "authors": [
      "Jörn Tebbe",
      "Christoph Zimmer",
      "Ansgar Steland",
      "Markus Lange-Hegermann",
      "Fabian Mies"
    ]
  },
  "https://proceedings.mlr.press/v238/molaei24a.html": {
    "title": "Federated Learning For Heterogeneous Electronic Health Records Utilising Augmented Temporal Graph Attention Networks",
    "volume": "main",
    "abstract": "The proliferation of decentralised electronic healthcare records (EHRs) across medical institutions requires innovative federated learning strategies for collaborative data analysis and global model training, prioritising data privacy. A prevalent issue during decentralised model training is the data-view discrepancies across medical institutions that arises from differences or availability of healthcare services, such as blood test panels. The prevailing way to handle this issue is to select a common subset of features across institutions to make data-views consistent. This approach, however, constrains some institutions to shed some critical features that may play a significant role in improving the model performance. This paper introduces a federated learning framework that relies on augmented graph attention networks to address data-view heterogeneity. The proposed framework utilises an alignment augmentation layer over self-attention mechanisms to weigh the importance of neighbouring nodes when updating a node's embedding irrespective of the data-views. Furthermore, our framework adeptly addresses both the temporal nuances and structural intricacies of EHR datasets. This dual capability not only offers deeper insights but also effectively encapsulates EHR graphs' time-evolving nature. Using diverse real-world datasets, we show that the proposed framework significantly outperforms conventional FL methodology for dealing with heterogeneous data-views",
    "checked": true,
    "id": "0b89aa4353a23ba1a86a37be4623f7ad04330cea",
    "semantic_title": "federated learning for heterogeneous electronic health records utilising augmented temporal graph attention networks",
    "citation_count": 0,
    "authors": [
      "Soheila Molaei",
      "Anshul Thakur",
      "Ghazaleh Niknam",
      "Andrew Soltan",
      "Hadi Zare",
      "David A Clifton"
    ]
  },
  "https://proceedings.mlr.press/v238/hickey24a.html": {
    "title": "Adaptive Discretization for Event PredicTion (ADEPT)",
    "volume": "main",
    "abstract": "Recently developed survival analysis methods improve upon existing approaches by predicting the probability of event occurrence in each of a number pre-specified (discrete) time intervals. By avoiding placing strong parametric assumptions on the event density, this approach tends to improve prediction performance, particularly when data are plentiful. However, in clinical settings with limited available data, it is often preferable to judiciously partition the event time space into a limited number of intervals well suited to the prediction task at hand. In this work, we develop Adaptive Discretization for Event PredicTion (ADEPT) to learn from data a set of cut points defining such a partition. We show that in two simulated datasets, we are able to recover intervals that match the underlying generative model. We then demonstrate improved prediction performance on three real-world observational datasets, including a large, newly harmonized stroke risk prediction dataset. Finally, we argue that our approach facilitates clinical decision-making by suggesting time intervals that are most appropriate for each task, in the sense that they facilitate more accurate risk prediction",
    "checked": true,
    "id": "a1091dd548dc50cc5c92aa262267505151ebcf94",
    "semantic_title": "adaptive discretization for event prediction (adept)",
    "citation_count": 0,
    "authors": [
      "Jimmy Hickey",
      "Ricardo Henao",
      "Daniel Wojdyla",
      "Michael Pencina",
      "Matthew Engelhard"
    ]
  },
  "https://proceedings.mlr.press/v238/eun-huh24a.html": {
    "title": "Generalization Bounds for Label Noise Stochastic Gradient Descent",
    "volume": "main",
    "abstract": "We develop generalization error bounds for stochastic gradient descent (SGD) with label noise in non-convex settings under uniform dissipativity and smoothness conditions. Under a suitable choice of semimetric, we establish a contraction in Wasserstein distance of the label noise stochastic gradient flow that depends polynomially on the parameter dimension $d$. Using the framework of algorithmic stability, we derive time-independent generalisation error bounds for the discretized algorithm with a constant learning rate. The error bound we achieve scales polynomially with $d$ and with the rate of $n^{-2/3}$, where $n$ is the sample size. This rate is better than the best-known rate of $n^{-1/2}$ established for stochastic gradient Langevin dynamics (SGLD)—which employs parameter-independent Gaussian noise—under similar conditions. Our analysis offers quantitative insights into the effect of label noise",
    "checked": true,
    "id": "ff3549609627a6d26ad461aa01c449f0cbc6820a",
    "semantic_title": "generalization bounds for label noise stochastic gradient descent",
    "citation_count": 0,
    "authors": [
      "Jung Eun Huh",
      "Patrick Rebeschini"
    ]
  },
  "https://proceedings.mlr.press/v238/heidari24a.html": {
    "title": "Adaptive Parametric Prototype Learning for Cross-Domain Few-Shot Classification",
    "volume": "main",
    "abstract": "Cross-domain few-shot classification induces a much more challenging problem than its in-domain counterpart due to the existence of domain shifts between the training and test tasks. In this paper, we develop a novel Adaptive Parametric Prototype Learning (APPL) method under the meta-learning convention for cross-domain few-shot classification. Different from existing prototypical few-shot methods that use the averages of support instances to calculate the class prototypes, we propose to learn class prototypes from the concatenated features of the support set in a parametric fashion and meta-learn the model by enforcing prototype-based regularization on the query set. In addition, we fine-tune the model in the target domain in a transductive manner using a weighted-moving-average self-training approach on the query instances. We conduct experiments on multiple cross-domain few-shot benchmark datasets. The empirical results demonstrate that APPL yields superior performance to many state-of-the-art cross-domain few-shot learning methods",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marzi Heidari",
      "Abdullah Alchihabi",
      "Qing En",
      "Yuhong Guo"
    ]
  },
  "https://proceedings.mlr.press/v238/khan24a.html": {
    "title": "Analyzing Explainer Robustness via Probabilistic Lipschitzness of Prediction Functions",
    "volume": "main",
    "abstract": "Machine learning methods have significantly improved in their predictive capabilities, but at the same time they are becoming more complex and less transparent. As a result, explainers are often relied on to provide interpretability to these black-box prediction models. As crucial diagnostics tools, it is important that these explainers themselves are robust. In this paper we focus on one particular aspect of robustness, namely that an explainer should give similar explanations for similar data inputs. We formalize this notion by introducing and defining explainer astuteness, analogous to astuteness of prediction functions. Our formalism allows us to connect explainer robustness to the predictor's probabilistic Lipschitzness, which captures the probability of local smoothness of a function. We provide lower bound guarantees on the astuteness of a variety of explainers (e.g., SHAP, RISE, CXPlain) given the Lipschitzness of the prediction function. These theoretical results imply that locally smooth prediction functions lend themselves to locally robust explanations. We evaluate these results empirically on simulated as well as real datasets",
    "checked": true,
    "id": "3e39f21182f9fb3fc2423639a30a05998ce06b46",
    "semantic_title": "analyzing explainer robustness via probabilistic lipschitzness of prediction functions",
    "citation_count": 2,
    "authors": [
      "Zulqarnain Q. Khan",
      "Davin Hill",
      "Aria Masoomi",
      "Joshua T. Bone",
      "Jennifer Dy"
    ]
  },
  "https://proceedings.mlr.press/v238/phan24a.html": {
    "title": "Importance Matching Lemma for Lossy Compression with Side Information",
    "volume": "main",
    "abstract": "We propose two extensions to existing importance sampling based methods for lossy compression. First, we introduce an importance sampling based compression scheme that is a variant of ordered random coding (Theis and Ahmed, 2022) and is amenable to direct evaluation of the achievable compression rate for a finite number of samples. Our second and major contribution is the \\emph{importance matching lemma}, which is a finite proposal counterpart of the recently introduced {Poisson matching lemma} (Li and Anantharam, 2021). By integrating with deep learning, we provide a new coding scheme for distributed lossy compression with side information at the decoder. We demonstrate the effectiveness of the proposed scheme through experiments involving synthetic Gaussian sources, distributed image compression with MNIST and vertical federated learning with CIFAR-10",
    "checked": true,
    "id": "6ee037cee4fe00e78926f83a66cd7f75be1aeed5",
    "semantic_title": "importance matching lemma for lossy compression with side information",
    "citation_count": 4,
    "authors": [
      "Buu Phan",
      "Ashish Khisti",
      "Christos Louizos"
    ]
  },
  "https://proceedings.mlr.press/v238/donhauser24a.html": {
    "title": "Certified private data release for sparse Lipschitz functions",
    "volume": "main",
    "abstract": "As machine learning has become more relevant for everyday applications, a natural requirement is the protection of the privacy of the training data. When the relevant learning questions are unknown in advance, or hyper-parameter tuning plays a central role, one solution is to release a differentially private synthetic data set that leads to similar conclusions as the original training data. In this work, we introduce an algorithm that enjoys fast rates for the utility loss for sparse Lipschitz queries. Furthermore, we show how to obtain a certificate for the utility loss for a large class of algorithms",
    "checked": true,
    "id": "d945ceab4084449387e30d59d0f86fcadef47d90",
    "semantic_title": "certified private data release for sparse lipschitz functions",
    "citation_count": 2,
    "authors": [
      "Konstantin Donhauser",
      "Johan Lokna",
      "Amartya Sanyal",
      "March Boedihardjo",
      "Robert Hönig",
      "Fanny Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/trauger24a.html": {
    "title": "Sequence Length Independent Norm-Based Generalization Bounds for Transformers",
    "volume": "main",
    "abstract": "This paper provides norm-based generalization bounds for the Transformer architecture that do not depend on the input sequence length. We employ a covering number based approach to prove our bounds. We use three novel covering number bounds for the function class of bounded linear mappings to upper bound the Rademacher complexity of the Transformer. Furthermore, we show this generalization bound applies to the common Transformer training technique of masking and then predicting the masked word. We also run a simulated study on a sparse majority data set that empirically validates our theoretical findings",
    "checked": true,
    "id": "a51bd29d341ea8944f030a337beeb97f1ac230cb",
    "semantic_title": "sequence length independent norm-based generalization bounds for transformers",
    "citation_count": 4,
    "authors": [
      "Jacob Trauger",
      "Ambuj Tewari"
    ]
  },
  "https://proceedings.mlr.press/v238/jin24a.html": {
    "title": "Subsampling Error in Stochastic Gradient Langevin Diffusions",
    "volume": "main",
    "abstract": "The Stochastic Gradient Langevin Dynamics (SGLD) are popularly used to approximate Bayesian posterior distributions in statistical learning procedures with large-scale data. As opposed to many usual Markov chain Monte Carlo (MCMC) algorithms, SGLD is not stationary with respect to the posterior distribution; two sources of error appear: The first error is introduced by an Euler–Maruyama discretisation of a Langevin diffusion process, the second error comes from the data subsampling that enables its use in large-scale data settings. In this work, we consider an idealised version of SGLD to analyse the method's pure subsampling error that we then see as a best-case error for diffusion-based subsampling MCMC methods. Indeed, we introduce and study the Stochastic Gradient Langevin Diffusion (SGLDiff), a continuous-time Markov process that follows the Langevin diffusion corresponding to a data subset and switches this data subset after exponential waiting times. There, we show the exponential ergodicity of SLGDiff and that the Wasserstein distance between the posterior and the limiting distribution of SGLDiff is bounded above by a fractional power of the mean waiting time. We bring our results into context with other analyses of SGLD",
    "checked": true,
    "id": "554b0f1b0822cf13a572202a36862c506eba22ba",
    "semantic_title": "subsampling error in stochastic gradient langevin diffusions",
    "citation_count": 0,
    "authors": [
      "Kexin Jin",
      "Chenguang Liu",
      "Jonas Latz"
    ]
  },
  "https://proceedings.mlr.press/v238/vu24a.html": {
    "title": "Analysis of Privacy Leakage in Federated Large Language Models",
    "volume": "main",
    "abstract": "With the rapid adoption of Federated Learning (FL) as the training and tuning protocol for applications utilizing Large Language Models (LLMs), recent research highlights the need for significant modifications to FL to accommodate the large-scale of LLMs. While substantial adjustments to the protocol have been introduced as a response, comprehensive privacy analysis for the adapted FL protocol is currently lacking. To address this gap, our work delves into an extensive examination of the privacy analysis of FL when used for training LLMs, both from theoretical and practical perspectives. In particular, we design two active membership inference attacks with guaranteed theoretical success rates to assess the privacy leakages of various adapted FL configurations. Our theoretical findings are translated into practical attacks, revealing substantial privacy vulnerabilities in popular LLMs, including BERT, RoBERTa, DistilBERT, and OpenAI's GPTs, across multiple real-world language datasets. Additionally, we conduct thorough experiments to evaluate the privacy leakage of these models when data is protected by state-of-the-art differential privacy (DP) mechanisms",
    "checked": true,
    "id": "4f5e020ca9ad8339f1f2026e9a93f1a70da324e2",
    "semantic_title": "analysis of privacy leakage in federated large language models",
    "citation_count": 2,
    "authors": [
      "Minh Vu",
      "Truc Nguyen",
      "Tre’ Jeter",
      "My T. Thai"
    ]
  },
  "https://proceedings.mlr.press/v238/qian24a.html": {
    "title": "Exploring the Power of Graph Neural Networks in Solving Linear Optimization Problems",
    "volume": "main",
    "abstract": "Recently, machine learning, particularly message-passing graph neural networks (MPNNs), has gained traction in enhancing exact optimization algorithms. For example, MPNNs speed up solving mixed-integer optimization problems by imitating computational intensive heuristics like strong branching, which entails solving multiple linear optimization problems (LPs). Despite the empirical success, the reasons behind MPNNs' effectiveness in emulating linear optimization remain largely unclear. Here, we show that MPNNs can simulate standard interior-point methods for LPs, explaining their practical success. Furthermore, we highlight how MPNNs can serve as a lightweight proxy for solving LPs, adapting to a given problem instance distribution. Empirically, we show that MPNNs solve LP relaxations of standard combinatorial optimization problems close to optimality, often surpassing conventional solvers and competing approaches in solving time",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chendi Qian",
      "Didier Chételat",
      "Christopher Morris"
    ]
  },
  "https://proceedings.mlr.press/v238/en24a.html": {
    "title": "Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation",
    "volume": "main",
    "abstract": "Medical image segmentation typically demands extensive dense annotations for model training, which is both time-consuming and skill-intensive. To mitigate this burden, exemplar-based medical image segmentation methods have been introduced to achieve effective training with only one annotated image. In this paper, we introduce a novel Cross-model Mutual learning framework for Exemplar-based Medical image Segmentation (CMEMS), which leverages two models to mutually excavate implicit information from unlabeled data at multiple granularities. CMEMS can eliminate confirmation bias and enable collaborative training to learn complementary information by enforcing consistency at different granularities across models. Concretely, cross-model image perturbation based mutual learning is devised by using weakly perturbed images to generate high-confidence pseudo-labels, supervising predictions of strongly perturbed images across models. This approach enables joint pursuit of prediction consistency at the image granularity. Moreover, cross-model multi-level feature perturbation based mutual learning is designed by letting pseudo-labels supervise predictions from perturbed multi-level features with different resolutions, which can broaden the perturbation space and enhance the robustness of our framework. CMEMS is jointly trained using exemplar data, synthetic data, and unlabeled data in an end-to-end manner. Experimental results on two medical image datasets indicate that the proposed CMEMS outperforms the state-of-the-art segmentation methods with extremely limited supervision",
    "checked": true,
    "id": "5f4257d65c727ab3e5d5741a0756318585a10abf",
    "semantic_title": "cross-model mutual learning for exemplar-based medical image segmentation",
    "citation_count": 0,
    "authors": [
      "Qing En",
      "Yuhong Guo"
    ]
  },
  "https://proceedings.mlr.press/v238/deshpande24a.html": {
    "title": "Online Calibrated and Conformal Prediction Improves Bayesian Optimization",
    "volume": "main",
    "abstract": "Accurate uncertainty estimates are important in sequential model-based decision-making tasks such as Bayesian optimization. However, these estimates can be imperfect if the data violates assumptions made by the model (e.g., Gaussianity). This paper studies which uncertainties are needed in model-based decision-making and in Bayesian optimization, and argues that uncertainties can benefit from calibration—i.e., an 80% predictive interval should contain the true outcome 80% of the time. Maintaining calibration, however, can be challenging when the data is non-stationary and depends on our actions. We propose using simple algorithms based on online learning to provably maintain calibration on non-i.i.d. data, and we show how to integrate these algorithms in Bayesian optimization with minimal overhead. Empirically, we find that calibrated Bayesian optimization converges to better optima in fewer steps, and we demonstrate improved performance on standard benchmark functions and hyperparameter optimization tasks",
    "checked": false,
    "id": "9872cc5150ecccafb4406b549d1652552b50527a",
    "semantic_title": "calibrated regression against an adversary without regret",
    "citation_count": 0,
    "authors": [
      "Shachi Deshpande",
      "Charles Marx",
      "Volodymyr Kuleshov"
    ]
  },
  "https://proceedings.mlr.press/v238/kausik24a.html": {
    "title": "Offline Policy Evaluation and Optimization Under Confounding",
    "volume": "main",
    "abstract": "Evaluating and optimizing policies in the presence of unobserved confounders is a problem of growing interest in offline reinforcement learning. Using conventional methods for offline RL in the presence of confounding can not only lead to poor decisions and poor policies, but also have disastrous effects in critical applications such as healthcare and education. We map out the landscape of offline policy evaluation for confounded MDPs, distinguishing assumptions on confounding based on whether they are memoryless and on their effect on the data-collection policies. We characterize settings where consistent value estimates are provably not achievable, and provide algorithms with guarantees to instead estimate lower bounds on the value. When consistent estimates are achievable, we provide algorithms for value estimation with sample complexity guarantees. We also present new algorithms for offline policy improvement and prove local convergence guarantees. Finally, we experimentally evaluate our algorithms on both a gridworld environment and a simulated healthcare setting of managing sepsis patients. In gridworld, our model-based method provides tighter lower bounds than existing methods, while in the sepsis simulator, we demonstrate the effectiveness of our method and investigate the importance of a clustering sub-routine",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chinmaya Kausik",
      "Yangyi Lu",
      "Kevin Tan",
      "Maggie Makar",
      "Yixin Wang",
      "Ambuj Tewari"
    ]
  },
  "https://proceedings.mlr.press/v238/neuhof24a.html": {
    "title": "Confident Feature Ranking",
    "volume": "main",
    "abstract": "Machine learning models are widely applied in various fields. Stakeholders often use post-hoc feature importance methods to better understand the input features' contribution to the models' predictions. The interpretation of the importance values provided by these methods is frequently based on the relative order of the features (their ranking) rather than the importance values themselves. Since the order may be unstable, we present a framework for quantifying the uncertainty in global importance values. We propose a novel method for the post-hoc interpretation of feature importance values that is based on the framework and pairwise comparisons of the feature importance values. This method produces simultaneous confidence intervals for the features' ranks, which include the \"true\" (infinite sample) ranks with high probability, and enables the selection of the set of top-k important features",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bitya Neuhof",
      "Yuval Benjamini"
    ]
  },
  "https://proceedings.mlr.press/v238/hu24b.html": {
    "title": "Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications",
    "volume": "main",
    "abstract": "Two-timescale stochastic approximation (TTSA) is among the most general frameworks for iterative stochastic algorithms. This includes well-known stochastic optimization methods such as SGD variants and those designed for bilevel or minimax problems, as well as reinforcement learning like the family of gradient-based temporal difference (GTD) algorithms. In this paper, we conduct an in-depth asymptotic analysis of TTSA under controlled Markovian noise via central limit theorem (CLT), uncovering the coupled dynamics of TTSA influenced by the underlying Markov chain, which has not been addressed by previous CLT results of TTSA only with Martingale difference noise. Building upon our CLT, we expand its application horizon of efficient sampling strategies from vanilla SGD to a wider TTSA context in distributed learning, thus broadening the scope of Hu et al. 2020. In addition, we leverage our CLT result to deduce the statistical properties of GTD algorithms with nonlinear function approximation using Markovian samples and show their identical asymptotic performance, a perspective not evident from current finite-time bounds",
    "checked": true,
    "id": "6852bb068066549b37e477ea0b4fcccdbd8a21ed",
    "semantic_title": "central limit theorem for two-timescale stochastic approximation with markovian noise: theory and applications",
    "citation_count": 2,
    "authors": [
      "Jie Hu",
      "Vishwaraj Doshi",
      "Do Young Eun"
    ]
  },
  "https://proceedings.mlr.press/v238/vishwakarma24a.html": {
    "title": "Taming False Positives in Out-of-Distribution Detection with Human Feedback",
    "volume": "main",
    "abstract": "Robustness to out-of-distribution (OOD) samples is crucial for the safe deployment of machine learning models in the open world. Recent works have focused on designing scoring functions to quantify OOD uncertainty. Setting appropriate thresholds for these scoring functions for OOD detection is challenging as OOD samples are often unavailable up front. Typically, thresholds are set to achieve a desired true positive rate (TPR), e.g., $95%$ TPR. However, this can lead to very high false positive rates (FPR), ranging from 60 to 96%, as observed in the Open-OOD benchmark. In safety critical real-life applications, e.g., medical diagnosis, controlling the FPR is essential when dealing with various OOD samples dynamically. To address these challenges, we propose a mathematically grounded OOD detection framework that leverages expert feedback to \\emph{safely} update the threshold on the fly. We provide theoretical results showing that it is guaranteed to meet the FPR constraint at all times while minimizing the use of human feedback. Another key feature of our framework is that it can work with any scoring function for OOD uncertainty quantification. Empirical evaluation of our system on synthetic and benchmark OOD datasets shows that our method can maintain FPR at most $5%$ while maximizing TPR",
    "checked": true,
    "id": "b3f21af3032246b6fa87e05a6d9455433b25ce55",
    "semantic_title": "taming false positives in out-of-distribution detection with human feedback",
    "citation_count": 0,
    "authors": [
      "Harit Vishwakarma",
      "Heguang Lin",
      "Ramya Korlakai Vinayak"
    ]
  },
  "https://proceedings.mlr.press/v238/lebensold24a.html": {
    "title": "On the Privacy of Selection Mechanisms with Gaussian Noise",
    "volume": "main",
    "abstract": "Report Noisy Max and Above Threshold are two classical differentially private (DP) selection mechanisms. Their output is obtained by adding noise to a sequence of low-sensitivity queries and reporting the identity of the query whose (noisy) answer satisfies a certain condition. Pure DP guarantees for these mechanisms are easy to obtain when Laplace noise is added to the queries. On the other hand, when instantiated using Gaussian noise, standard analyses only yield approximate DP guarantees despite the fact that the outputs of these mechanisms lie in a discrete space. In this work, we revisit the analysis of Report Noisy Max and Above Threshold with Gaussian noise and show that, under the additional assumption that the underlying queries are bounded, it is possible to provide pure ex-ante DP bounds for Report Noisy Max and pure ex-post DP bounds for Above Threshold. The resulting bounds are tight and depend on closed-form expressions that can be numerically evaluated using standard methods. Empirically we find these lead to tighter privacy accounting in the high privacy, low data regime. Further, we propose a simple privacy filter for composing pure ex-post DP guarantees, and use it to derive a fully adaptive Gaussian Sparse Vector Technique mechanism. Finally, we provide experiments on mobility and energy consumption datasets demonstrating that our Sparse Vector Technique is practically competitive with previous approaches and requires less hyper-parameter tuning",
    "checked": true,
    "id": "843fbf43f0fdf1378d423542239f3f2ef0d471e0",
    "semantic_title": "on the privacy of selection mechanisms with gaussian noise",
    "citation_count": 0,
    "authors": [
      "Jonathan Lebensold",
      "Doina Precup",
      "Borja Balle"
    ]
  },
  "https://proceedings.mlr.press/v238/gazin24a.html": {
    "title": "Transductive conformal inference with adaptive scores",
    "volume": "main",
    "abstract": "Conformal inference is a fundamental and versatile tool that provides distribution-free guarantees for many machine learning tasks. We consider the transductive setting, where decisions are made on a test sample of $m$ new points, giving rise to $m$ conformal $p$-values. While classical results only concern their marginal distribution, we show that their joint distribution follows a Pólya urn model, and establish a concentration inequality for their empirical distribution function. The results hold for arbitrary exchangeable scores, including adaptive ones that can use the covariates of the test${+}$calibration samples at training stage for increased accuracy. We demonstrate the usefulness of these theoretical results through uniform, in-probability guarantees for two machine learning tasks of current interest: interval prediction for transductive transfer learning and novelty detection based on two-class classification",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ulysse Gazin",
      "Gilles Blanchard",
      "Etienne Roquain"
    ]
  },
  "https://proceedings.mlr.press/v238/cohen-indelman24a.html": {
    "title": "Learning Latent Partial Matchings with Gumbel-IPF Networks",
    "volume": "main",
    "abstract": "Learning to match discrete objects has been a central task in machine learning, often facilitated by a continuous relaxation of the matching structure. However, practical problems entail partial matchings due to missing correspondences, which pose difficulties to the one-to-one matching learning techniques that dominate the state-of-the-art. This paper introduces Gumbel-IPF networks for learning latent partial matchings. At the core of our method is the differentiable Iterative Proportional Fitting (IPF) procedure that biproportionally projects onto the transportation polytope of target marginals. Our theoretical framework also allows drawing samples from the temperature-dependent partial matching distribution. We investigate the properties of common-practice relaxations through the lens of biproportional fitting and introduce a new metric, the empirical prediction shift. Our method's advantages are demonstrated in experimental results on the semantic keypoints partial matching task on the Pascal VOC, IMC-PT-SparseGM, and CUB2001 datasets",
    "checked": true,
    "id": "832888baa5a95a3329b0166bccaf0ac81433a06c",
    "semantic_title": "learning latent partial matchings with gumbel-ipf networks",
    "citation_count": 0,
    "authors": [
      "Hedda Cohen Indelman",
      "Tamir Hazan"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24b.html": {
    "title": "On Counterfactual Metrics for Social Welfare: Incentives, Ranking, and Information Asymmetry",
    "volume": "main",
    "abstract": "From the social sciences to machine learning, it is well documented that metrics do not always align with social welfare. In healthcare, Dranove et al. (2003) showed that publishing surgery mortality metrics actually harmed sicker patients by increasing provider selection behavior. Using a principal-agent model, we analyze the incentive misalignments that arise from such average treated outcome metrics, and show that the incentives driving treatment decisions would align with maximizing total patient welfare if the metrics (i) accounted for counterfactual untreated outcomes and (ii) considered total welfare instead of averaging over treated patients. Operationalizing this, we show how counterfactual metrics can be modified to behave reasonably in patient-facing ranking systems. Extending to realistic settings when providers observe more about patients than the regulatory agencies do, we bound the decay in performance by the degree of information asymmetry between principal and agent. In doing so, our model connects principal-agent information asymmetry with unobserved heterogeneity in causal inference",
    "checked": true,
    "id": "a34b3742aab9a03aae4fdb8cff23247bbc4cff4e",
    "semantic_title": "on counterfactual metrics for social welfare: incentives, ranking, and information asymmetry",
    "citation_count": 1,
    "authors": [
      "Serena Wang",
      "Stephen Bates",
      "P Aronow",
      "Michael Jordan"
    ]
  },
  "https://proceedings.mlr.press/v238/dann24a.html": {
    "title": "Data-Driven Online Model Selection With Regret Guarantees",
    "volume": "main",
    "abstract": "We consider model selection for sequential decision making in stochastic environments with bandit feedback, where a meta-learner has at its disposal a pool of base learners, and decides on the fly which action to take based on the policies recommended by each base learner. Model selection is performed by regret balancing but, unlike the recent literature on this subject, we do not assume any prior knowledge about the base learners like candidate regret guarantees; instead, we uncover these quantities in a data-driven manner. The meta-learner is therefore able to leverage the *realized* regret incurred by each base learner for the learning environment at hand (as opposed to the *expected* regret), and single out the best such regret. We design two model selection algorithms operating with this more ambitious notion of regret and, besides proving model selection guarantees via regret balancing, we experimentally demonstrate the compelling practical benefits of dealing with actual regrets instead of candidate regret bounds",
    "checked": true,
    "id": "1c322b9c3a5ccc4964591a6f40cf593ad4e3a96c",
    "semantic_title": "data-driven online model selection with regret guarantees",
    "citation_count": 2,
    "authors": [
      "Chris Dann",
      "Claudio Gentile",
      "Aldo Pacchiano"
    ]
  },
  "https://proceedings.mlr.press/v238/rossellini24a.html": {
    "title": "Integrating Uncertainty Awareness into Conformalized Quantile Regression",
    "volume": "main",
    "abstract": "Conformalized Quantile Regression (CQR) is a recently proposed method for constructing prediction intervals for a response $Y$ given covariates $X$, without making distributional assumptions. However, existing constructions of CQR can be ineffective for problems where the quantile regressors perform better in certain parts of the feature space than others. The reason is that the prediction intervals of CQR do not distinguish between two forms of uncertainty: first, the variability of the conditional distribution of $Y$ given $X$ (i.e., aleatoric uncertainty), and second, our uncertainty in estimating this conditional distribution (i.e., epistemic uncertainty). This can lead to intervals that are overly narrow in regions where epistemic uncertainty is high. To address this, we propose a new variant of the CQR methodology, Uncertainty-Aware CQR (UACQR), that explicitly separates these two sources of uncertainty to adjust quantile regressors differentially across the feature space. Compared to CQR, our methods enjoy the same distribution-free theoretical coverage guarantees, while demonstrating in our experiments stronger conditional coverage properties in simulated settings and real-world data sets alike",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raphael Rossellini",
      "Rina Foygel Barber",
      "Rebecca Willett"
    ]
  },
  "https://proceedings.mlr.press/v238/dhillon24a.html": {
    "title": "On the Expected Size of Conformal Prediction Sets",
    "volume": "main",
    "abstract": "While conformal predictors reap the benefits of rigorous statistical guarantees on their error frequency, the size of their corresponding prediction sets is critical to their practical utility. Unfortunately, there is currently a lack of finite-sample analysis and guarantees for their prediction set sizes. To address this shortfall, we theoretically quantify the expected size of the prediction sets under the split conformal prediction framework. As this precise formulation cannot usually be calculated directly, we further derive point estimates and high-probability interval bounds that can be empirically computed, providing a practical method for characterizing the expected set size. We corroborate the efficacy of our results with experiments on real-world datasets for both regression and classification problems",
    "checked": true,
    "id": "b0886865ca3275b21a1aee37f9898f416a18a4bc",
    "semantic_title": "on the expected size of conformal prediction sets",
    "citation_count": 5,
    "authors": [
      "Guneet S. Dhillon",
      "George Deligiannidis",
      "Tom Rainforth"
    ]
  },
  "https://proceedings.mlr.press/v238/sevilla24a.html": {
    "title": "Estimation of partially known Gaussian graphical models with score-based structural priors",
    "volume": "main",
    "abstract": "We propose a novel algorithm for the support estimation of partially known Gaussian graphical models that incorporates prior information about the underlying graph. In contrast to classical approaches that provide a point estimate based on a maximum likelihood or maximum a posteriori approach using (simple) priors on the precision matrix, we consider a prior on the graph and rely on annealed Langevin diffusion to generate samples from the posterior distribution. Since the Langevin sampler requires access to the score function of the underlying graph prior, we use graph neural networks to effectively estimate the score from a graph dataset (either available beforehand or generated from a known distribution). Numerical experiments in different setups demonstrate the benefits of our approach",
    "checked": true,
    "id": "5b65ce36a5988b687c9a123c0d0b009d9f770b53",
    "semantic_title": "estimation of partially known gaussian graphical models with score-based structural priors",
    "citation_count": 2,
    "authors": [
      "Martín Sevilla",
      "Antonio G. Marques",
      "Santiago Segarra"
    ]
  },
  "https://proceedings.mlr.press/v238/takemori24a.html": {
    "title": "Model-Based Best Arm Identification for Decreasing Bandits",
    "volume": "main",
    "abstract": "We study the problem of reliably identifying the best (lowest loss) arm in a stochastic multi-armed bandit when the expected loss of each arm is monotone decreasing as a function of its pull count. This models, for instance, scenarios where each arm itself represents an optimization algorithm for finding the minimizer of a common function, and there is a limited time available to test the algorithms before committing to one of them. We assume that the decreasing expected loss of each arm depends on the number of its pulls as a (inverse) polynomial with unknown coefficients. We propose two fixed-budget best arm identification algorithms – one for the case of sparse polynomial decay models and the other for general polynomial models – along with bounds on the identification error probability. We also derive algorithm-independent lower bounds on the error probability. These bounds are seen to be factored into the product of the usual problem complexity and the model complexity that only depends on the parameters of the model. This indicates that our methods can identify the best arm even when the budget is smaller. We conduct empirical studies of our algorithms to complement our theoretical findings",
    "checked": true,
    "id": "f5e40367b3892693f991e0d6914367089f85e09f",
    "semantic_title": "model-based best arm identification for decreasing bandits",
    "citation_count": 0,
    "authors": [
      "Sho Takemori",
      "Yuhei Umeda",
      "Aditya Gopalan"
    ]
  },
  "https://proceedings.mlr.press/v238/ou24a.html": {
    "title": "Thompson Sampling Itself is Differentially Private",
    "volume": "main",
    "abstract": "In this work we first show that the classical Thompson sampling algorithm for multi-arm bandits is differentially private as-is, without any modification. We provide per-round privacy guarantees as a function of problem parameters and show composition over $T$ rounds; since the algorithm is unchanged, existing $O(\\sqrt{NT\\log N})$ regret bounds still hold and there is no loss in performance due to privacy. We then show that simple modifications – such as pre-pulling all arms a fixed number of times, increasing the sampling variance – can provide tighter privacy guarantees. We again provide privacy guarantees that now depend on the new parameters introduced in the modification, which allows the analyst to tune the privacy guarantee as desired. We also provide a novel regret analysis for this new algorithm, and show how the new parameters also impact expected regret. Finally, we empirically validate and illustrate our theoretical findings in two parameter regimes and demonstrate that tuning the new parameters substantially improve the privacy-regret tradeoff",
    "checked": true,
    "id": "2681883f50833e16b896716d17adced220f73a44",
    "semantic_title": "thompson sampling itself is differentially private",
    "citation_count": 0,
    "authors": [
      "Tingting Ou",
      "Rachel Cummings",
      "Marco Avella Medina"
    ]
  },
  "https://proceedings.mlr.press/v238/xiong24a.html": {
    "title": "A/B Testing and Best-arm Identification for Linear Bandits with Robustness to Non-stationarity",
    "volume": "main",
    "abstract": "We investigate the fixed-budget best-arm identification (BAI) problem for linear bandits in a potentially non-stationary environment. Given a finite arm set $\\mathcal{X}\\subset\\mathbb{R}^d$, a fixed budget $T$, and an unpredictable sequence of parameters $\\left\\lbrace\\theta_t\\right\\rbrace_{t=1}^{T}$, an algorithm will aim to correctly identify the best arm $x^* := \\arg\\max_{x\\in\\mathcal{X}}x^\\top\\sum_{t=1}^{T}\\theta_t$ with probability as high as possible. Prior work has addressed the stationary setting where $\\theta_t = \\theta_1$ for all $t$ and demonstrated that the error probability decreases as $\\exp(-T /\\rho^*)$ for a problem-dependent constant $\\rho^*$. But in many real-world $A/B/n$ multivariate testing scenarios that motivate our work, the environment is non-stationary and an algorithm expecting a stationary setting can easily fail. For robust identification, it is well-known that if arms are chosen randomly and non-adaptively from a G-optimal design over $\\mathcal{X}$ at each time then the error probability decreases as $\\exp(-T\\Delta^2_{(1)}/d)$, where $\\Delta_{(1)} = \\min_{x \\neq x^*} (x^* - x)^\\top \\frac{1}{T}\\sum_{t=1}^T \\theta_t$. As there exist environments where $\\Delta_{(1)}^2/ d \\ll 1/ \\rho^*$, we are motivated to propose a novel algorithm P1-RAGE that aims to obtain the best of both worlds: robustness to non-stationarity and fast rates of identification in benign settings. We characterize the error probability of P1-RAGE and demonstrate empirically that the algorithm indeed never performs worse than G-optimal design but compares favorably to the best algorithms in the stationary setting",
    "checked": true,
    "id": "6bf5c5a62a984e112b331dc1b538682656899c5d",
    "semantic_title": "a/b testing and best-arm identification for linear bandits with robustness to non-stationarity",
    "citation_count": 0,
    "authors": [
      "Zhihan Xiong",
      "Romain Camilleri",
      "Maryam Fazel",
      "Lalit Jain",
      "Kevin Jamieson"
    ]
  },
  "https://proceedings.mlr.press/v238/sohn24a.html": {
    "title": "Fair Supervised Learning with A Simple Random Sampler of Sensitive Attributes",
    "volume": "main",
    "abstract": "As the data-driven decision process becomes dominating for industrial applications, fairness-aware machine learning arouses great attention in various areas. This work proposes fairness penalties learned by neural networks with a simple random sampler of sensitive attributes for non-discriminatory supervised learning. In contrast to many existing works that critically rely on the discreteness of sensitive attributes and response variables, the proposed penalty is able to handle versatile formats of the sensitive attributes, so it is more extensively applicable in practice than many existing algorithms. This penalty enables us to build a computationally efficient group-level in-processing fairness-aware training framework. Empirical evidence shows that our framework enjoys better utility and fairness measures on popular benchmark data sets than competing methods. We also theoretically characterize estimation errors and loss of utility of the proposed neural-penalized risk minimization problem",
    "checked": true,
    "id": "34c8fdbe9ecff8382135ea6118bad8054623c972",
    "semantic_title": "fair supervised learning with a simple random sampler of sensitive attributes",
    "citation_count": 0,
    "authors": [
      "Jinwon Sohn",
      "Qifan Song",
      "Guang Lin"
    ]
  },
  "https://proceedings.mlr.press/v238/ma24a.html": {
    "title": "Absence of spurious solutions far from ground truth: A low-rank analysis with high-order losses",
    "volume": "main",
    "abstract": "Matrix sensing problems exhibit pervasive non-convexity, plaguing optimization with a proliferation of suboptimal spurious solutions. Avoiding convergence to these critical points poses a major challenge. This work provides new theoretical insights that help demystify the intricacies of the non-convex landscape. In this work, we prove that under certain conditions, critical points sufficiently distant from the ground truth matrix exhibit favorable geometry by being strict saddle points rather than troublesome local minima. Moreover, we introduce the notion of higher-order losses for the matrix sensing problem and show that the incorporation of such losses into the objective function amplifies the negative curvature around those distant critical points. This implies that increasing the complexity of the objective function via high-order losses accelerates the escape from such critical points and acts as a desirable alternative to increasing the complexity of the optimization problem via over-parametrization. By elucidating key characteristics of the non-convex optimization landscape, this work makes progress towards a comprehensive framework for tackling broader machine learning objectives plagued by non-convexity",
    "checked": true,
    "id": "73d3081dd07a388fb7e736cd5816edbdcd160a26",
    "semantic_title": "absence of spurious solutions far from ground truth: a low-rank analysis with high-order losses",
    "citation_count": 0,
    "authors": [
      "Ziye Ma",
      "Ying Chen",
      "Javad Lavaei",
      "Somayeh Sojoudi"
    ]
  },
  "https://proceedings.mlr.press/v238/jhunjhunwala24a.html": {
    "title": "FedFisher: Leveraging Fisher Information for One-Shot Federated Learning",
    "volume": "main",
    "abstract": "Standard federated learning (FL) algorithms typically require multiple rounds of communication between the server and the clients, which has several drawbacks, including requiring constant network connectivity, repeated investment of computational resources, and susceptibility to privacy attacks. One-Shot FL is a new paradigm that aims to address this challenge by enabling the server to train a global model in a single round of communication. In this work, we present FedFisher, a novel algorithm for one-shot FL that makes use of Fisher information matrices computed on local client models, motivated by a Bayesian perspective of FL. First, we theoretically analyze FedFisher for two-layer over-parameterized ReLU neural networks and show that the error of our one-shot FedFisher global model becomes vanishingly small as the width of the neural networks and amount of local training at clients increases. Next, we propose practical variants of FedFisher using the diagonal Fisher and K-FAC approximation for the full Fisher and highlight their communication and compute efficiency for FL. Finally, we conduct extensive experiments on various datasets, which show that these variants of FedFisher consistently improve over competing baselines",
    "checked": true,
    "id": "94665ddaa6ca8b7fe6f19c392a72604c7396f1e8",
    "semantic_title": "fedfisher: leveraging fisher information for one-shot federated learning",
    "citation_count": 1,
    "authors": [
      "Divyansh Jhunjhunwala",
      "Shiqiang Wang",
      "Gauri Joshi"
    ]
  },
  "https://proceedings.mlr.press/v238/choo24a.html": {
    "title": "Causal Discovery under Off-Target Interventions",
    "volume": "main",
    "abstract": "Causal graph discovery is a significant problem with applications across various disciplines. However, with observational data alone, the underlying causal graph can only be recovered up to its Markov equivalence class, and further assumptions or interventions are necessary to narrow down the true graph. This work addresses the causal discovery problem under the setting of stochastic interventions with the natural goal of minimizing the number of interventions performed. We propose the following stochastic intervention model which subsumes existing adaptive noiseless interventions in the literature while capturing scenarios such as fat-hand interventions and CRISPR gene knockouts: any intervention attempt results in an actual intervention on a random subset of vertices, drawn from a \\emph{distribution dependent on attempted action}. Under this model, we study the two fundamental problems in causal discovery of verification and search and provide approximation algorithms with polylogarithmic competitive ratios and provide some preliminary experimental results",
    "checked": true,
    "id": "213230dc1e3bbdd09326ada1d7beea3104e5fb52",
    "semantic_title": "causal discovery under off-target interventions",
    "citation_count": 0,
    "authors": [
      "Davin Choo",
      "Kirankumar Shiragur",
      "Caroline Uhler"
    ]
  },
  "https://proceedings.mlr.press/v238/jin24b.html": {
    "title": "Feasible $Q$-Learning for Average Reward Reinforcement Learning",
    "volume": "main",
    "abstract": "Average reward reinforcement learning (RL) provides a suitable framework for capturing the objective (i.e. long-run average reward) for continuing tasks, where there is often no natural way to identify a discount factor. However, existing average reward RL algorithms with sample complexity guarantees are not feasible, as they take as input the (unknown) mixing time of the Markov decision process (MDP). In this paper, we make initial progress towards addressing this open problem. We design a feasible average-reward $Q$-learning framework that requires no knowledge of any problem parameter as input. Our framework is based on discounted $Q$-learning, while we dynamically adapt the discount factor (and hence the effective horizon) to progressively approximate the average reward. In the synchronous setting, we solve three tasks: (i) learn a policy that is $\\epsilon$-close to optimal, (ii) estimate optimal average reward with $\\epsilon$-accuracy, and (iii) estimate the bias function (similar to $Q$-function in discounted case) with $\\epsilon$-accuracy. We show that with carefully designed adaptation schemes, (i) can be achieved with $\\tilde{O}(\\frac{SA t_{\\mathrm{mix}}^{8}}{\\epsilon^{8}})$ samples, (ii) with $\\tilde{O}(\\frac{SA t_{\\mathrm{mix}}^5}{\\epsilon^5})$ samples, and (iii) with $\\tilde{O}(\\frac{SA B}{\\epsilon^9})$ samples, where $t_\\mathrm{mix}$ is the mixing time, and $B > 0$ is an MDP-dependent constant. To our knowledge, we provide the first finite-sample guarantees that are polynomial in $S, A, t_{\\mathrm{mix}}, \\epsilon$ for a feasible variant of $Q$-learning. That said, the sample complexity bounds have tremendous room for improvement, which we leave for the community's best minds. Preliminary simulations verify that our framework is effective without prior knowledge of parameters as input",
    "checked": false,
    "id": "d529590de080b688c646591a501862684ae061c1",
    "semantic_title": "feasible q-learning for average reward reinforcement learning",
    "citation_count": 1,
    "authors": [
      "Ying Jin",
      "Ramki Gummadi",
      "Zhengyuan Zhou",
      "Jose Blanchet"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24c.html": {
    "title": "Joint control variate for faster black-box variational inference",
    "volume": "main",
    "abstract": "Black-box variational inference performance is sometimes hindered by the use of gradient estimators with high variance. This variance comes from two sources of randomness: Data subsampling and Monte Carlo sampling. While existing control variates only address Monte Carlo noise, and incremental gradient methods typically only address data subsampling, we propose a new \"joint\" control variate that jointly reduces variance from both sources of noise. This significantly reduces gradient variance, leading to faster optimization in several applications",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Wang",
      "Tomas Geffner",
      "Justin Domke"
    ]
  },
  "https://proceedings.mlr.press/v238/tang24a.html": {
    "title": "Adaptivity of Diffusion Models to Manifold Structures",
    "volume": "main",
    "abstract": "Empirical studies have demonstrated the effectiveness of (score-based) diffusion models in generating high-dimensional data, such as texts and images, which typically exhibit a low-dimensional manifold nature. These empirical successes raise the theoretical question of whether score-based diffusion models can optimally adapt to low-dimensional manifold structures. While recent work has validated the minimax optimality of diffusion models when the target distribution admits a smooth density with respect to the Lebesgue measure of the ambient data space, these findings do not fully account for the ability of diffusion models in avoiding the the curse of dimensionality when estimating high-dimensional distributions. This work considers two common classes of diffusion models: Langevin diffusion and forward-backward diffusion. We show that both models can adapt to the intrinsic manifold structure by showing that the convergence rate of the inducing distribution estimator depends only on the intrinsic dimension of the data. Moreover, our considered estimator does not require knowing or explicitly estimating the manifold. We also demonstrate that the forward-backward diffusion can achieve the minimax optimal rate under the Wasserstein metric when the target distribution possesses a smooth density with respect to the volume measure of the low-dimensional manifold",
    "checked": true,
    "id": "a634b8ca66e1d1998f0d7b791fef8369d8ae0fc8",
    "semantic_title": "adaptivity of diffusion models to manifold structures",
    "citation_count": 1,
    "authors": [
      "Rong Tang",
      "Yun Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/diamant24a.html": {
    "title": "Conformalized Deep Splines for Optimal and Efficient Prediction Sets",
    "volume": "main",
    "abstract": "Uncertainty estimation is critical in high-stakes machine learning applications. One effective way to estimate uncertainty is conformal prediction, which can provide predictive inference with statistical coverage guarantees. We present a new conformal regression method, Spline Prediction Intervals via Conformal Estimation (SPICE), that estimates the conditional density using neural- network-parameterized splines. We prove universal approximation and optimality results for SPICE, which are empirically reflected by our experiments. SPICE is compatible with two different efficient-to- compute conformal scores, one designed for size-efficient marginal coverage (SPICE-ND) and the other for size-efficient conditional coverage (SPICE-HPD). Results on benchmark datasets demonstrate SPICE-ND models achieve the smallest average prediction set sizes, including average size reductions of nearly 50% for some datasets compared to the next best baseline. SPICE-HPD models achieve the best conditional coverage compared to baselines. The SPICE implementation is made available",
    "checked": true,
    "id": "a2b04f844a805715a18b0ede5c7694a346a167c0",
    "semantic_title": "conformalized deep splines for optimal and efficient prediction sets",
    "citation_count": 1,
    "authors": [
      "Nathaniel Diamant",
      "Ehsan Hajiramezanali",
      "Tommaso Biancalani",
      "Gabriele Scalia"
    ]
  },
  "https://proceedings.mlr.press/v238/esaki24a.html": {
    "title": "Accuracy-Preserving Calibration via Statistical Modeling on Probability Simplex",
    "volume": "main",
    "abstract": "Classification models based on deep neural networks (DNNs) must be calibrated to measure the reliability of predictions. Some recent calibration methods have employed a probabilistic model on the probability simplex. However, these calibration methods cannot preserve the accuracy of pre-trained models, even those with a high classification accuracy. We propose an accuracy-preserving calibration method using the Concrete distribution as the probabilistic model on the probability simplex. We theoretically prove that a DNN model trained on cross-entropy loss has optimality as the parameter of the Concrete distribution. We also propose an efficient method that synthetically generates samples for training probabilistic models on the probability simplex. We demonstrate that the proposed method can outperform previous methods in accuracy-preserving calibration tasks using benchmarks",
    "checked": true,
    "id": "6d6e545ce1fd637fbce7549e668dbded40ac8581",
    "semantic_title": "accuracy-preserving calibration via statistical modeling on probability simplex",
    "citation_count": 0,
    "authors": [
      "Yasushi Esaki",
      "Akihiro Nakamura",
      "Keisuke Kawano",
      "Ryoko Tokuhisa",
      "Takuro Kutsuna"
    ]
  },
  "https://proceedings.mlr.press/v238/ye24b.html": {
    "title": "Smoothness-Adaptive Dynamic Pricing with Nonparametric Demand Learning",
    "volume": "main",
    "abstract": "We study the dynamic pricing problem where the demand function is nonparametric and Hölder smooth, and we focus on adaptivity to the unknown Hölder smoothness parameter $\\beta$ of the demand function. Traditionally the optimal dynamic pricing algorithm heavily relies on the knowledge of $\\beta$ to achieve a minimax optimal regret of $\\widetilde{O}(T^{\\frac{\\beta+1}{2\\beta+1}})$. However, we highlight the challenge of adaptivity in this dynamic pricing problem by proving that no pricing policy can adaptively achieve this minimax optimal regret without knowledge of $\\beta$. Motivated by the impossibility result, we propose a self-similarity condition to enable adaptivity. Importantly, we show that the self-similarity condition does not compromise the problem's inherent complexity since it preserves the regret lower bound $\\Omega(T^{\\frac{\\beta+1}{2\\beta+1}})$. Furthermore, we develop a smoothness-adaptive dynamic pricing algorithm and theoretically prove that the algorithm achieves this minimax optimal regret bound without the prior knowledge $\\beta$",
    "checked": true,
    "id": "a943983d43a282bd252340bb175bb1781b74256b",
    "semantic_title": "smoothness-adaptive dynamic pricing with nonparametric demand learning",
    "citation_count": 0,
    "authors": [
      "Zeqi Ye",
      "Hansheng Jiang"
    ]
  },
  "https://proceedings.mlr.press/v238/li24h.html": {
    "title": "Optimal Exploration is no harder than Thompson Sampling",
    "volume": "main",
    "abstract": "Given a set of arms $\\mathcal{Z}\\subset \\mathbb{R}^d$ and an unknown parameter vector $\\theta_\\ast\\in\\mathbb{R}^d$, the pure exploration linear bandits problem aims to return $\\arg\\max_{z\\in \\mathcal{Z}} z^{\\top}\\theta_{\\ast}$, with high probability through noisy measurements of $x^{\\top}\\theta_{\\ast}$ with $x\\in \\mathcal{X}\\subset \\mathbb{R}^d$. Existing (asymptotically) optimal methods require either a) potentially costly projections for each arm $z\\in \\mathcal{Z}$ or b) explicitly maintaining a subset of $\\mathcal{Z}$ under consideration at each time. This complexity is at odds with the popular and simple Thompson Sampling algorithm for regret minimization, which just requires access to a posterior sampling and argmax oracle, and does not need to enumerate $\\mathcal{Z}$ at any point. Unfortunately, Thompson sampling is known to be sub-optimal for pure exploration. In this work, we pose a natural question: is there an algorithm that can explore optimally and only needs the same computational primitives as Thompson Sampling? We answer the question in the affirmative. We provide an algorithm that leverages only sampling and argmax oracles and achieves an exponential convergence rate, with the exponent equal to the exponent of the optimal fixed allocation asymptotically. In addition, we show that our algorithm can be easily implemented and performs as well empirically as existing asymptotically optimal methods",
    "checked": true,
    "id": "ce251ccc31da6f1b8130b678de3c3936d3b0bfdf",
    "semantic_title": "optimal exploration is no harder than thompson sampling",
    "citation_count": 0,
    "authors": [
      "Zhaoqi Li",
      "Kevin Jamieson",
      "Lalit Jain"
    ]
  },
  "https://proceedings.mlr.press/v238/deng24a.html": {
    "title": "Sample Complexity Characterization for Linear Contextual MDPs",
    "volume": "main",
    "abstract": "Contextual Markov decision processes (CMDPs) describe a class of reinforcement learning problems in which the transition kernels and reward functions can change over time with different MDPs indexed by a context variable. While CMDPs serve as an important framework to model many real-world applications with time-varying environments, they are largely unexplored from theoretical perspective. In this paper, we study CMDPs under two linear function approximation models: Model I with context-varying representations and common linear weights for all contexts; and Model II with common representations for all contexts and context-varying linear weights. For both models, we propose novel model-based algorithms and show that they enjoy guaranteed $\\epsilon$-suboptimality gap with desired polynomial sample complexity. In particular, instantiating our result for the first model to the tabular CMDP improves the existing result by removing the reachability assumption. Our result for the second model is the first-known result for such a type of function approximation models. Comparison between our results for the two models further indicates that having context-varying features leads to much better sample efficiency than having common representations for all contexts under linear CMDPs",
    "checked": true,
    "id": "839b6c3bd3b1eac35fca726b31dbe9ab216b494b",
    "semantic_title": "sample complexity characterization for linear contextual mdps",
    "citation_count": 0,
    "authors": [
      "Junze Deng",
      "Yuan Cheng",
      "Shaofeng Zou",
      "Yingbin Liang"
    ]
  },
  "https://proceedings.mlr.press/v238/pal24a.html": {
    "title": "Sample-Efficient Personalization: Modeling User Parameters as Low Rank Plus Sparse Components",
    "volume": "main",
    "abstract": "Personalization of machine learning (ML) predictions for individual users/domains/enterprises is critical for practical recommendation systems. Standard personalization approaches involve learning a user/domain specific \\emph{embedding} that is fed into a fixed global model which can be limiting. On the other hand, personalizing/fine-tuning model itself for each user/domain — a.k.a meta-learning — has high storage/infrastructure cost. Moreover, rigorous theoretical studies of scalable personalization approaches have been very limited. To address the above issues, we propose a novel meta-learning style approach that models network weights as a sum of low-rank and sparse components. This captures common information from multiple individuals/users together in the low-rank part while sparse part captures user-specific idiosyncrasies. We then study the framework in the linear setting, where the problem reduces to that of estimating the sum of a rank-$r$ and a $k$-column sparse matrix using a small number of linear measurements. We propose a computationally efficient alternating minimization method with iterative hard thresholding — AMHT-LRS — to learn the low-rank and sparse part. Theoretically, for the realizable Gaussian data setting, we show that AMHT-LRS solves the problem efficiently with nearly optimal sample complexity. Finally, a significant challenge in personalization is ensuring privacy of each user's sensitive data. We alleviate this problem by proposing a differentially private variant of our method that also is equipped with strong generalization guarantees",
    "checked": true,
    "id": "847f2f224409e85783b19425d2785a8a868be224",
    "semantic_title": "sample-efficient personalization: modeling user parameters as low rank plus sparse components",
    "citation_count": 0,
    "authors": [
      "Soumyabrata Pal",
      "Prateek Varshney",
      "Gagan Madan",
      "Prateek Jain",
      "Abhradeep Thakurta",
      "Gaurav Aggarwal",
      "Pradeep Shenoy",
      "Gaurav Srivastava"
    ]
  },
  "https://proceedings.mlr.press/v238/leconte24a.html": {
    "title": "Queuing dynamics of asynchronous Federated Learning",
    "volume": "main",
    "abstract": "We study asynchronous federated learning mechanisms with nodes having potentially different computational speeds. In such an environment, each node is allowed to work on models with potential delays and contribute to updates to the central server at its own pace. Existing analyses of such algorithms typically depend on intractable quantities such as the maximum node delay and do not consider the underlying queuing dynamics of the system. In this paper, we propose a non-uniform sampling scheme for the central server that allows for lower delays with better complexity, taking into account the closed Jackson network structure of the associated computational graph. Our experiments clearly show a significant improvement of our method over current state-of-the-art asynchronous algorithms on image classification problems",
    "checked": true,
    "id": "1ec9c44667bf4c4461fd4962989f038cbe6d0f3b",
    "semantic_title": "queuing dynamics of asynchronous federated learning",
    "citation_count": 2,
    "authors": [
      "Louis Leconte",
      "Matthieu Jonckheere",
      "Sergey Samsonov",
      "Eric Moulines"
    ]
  },
  "https://proceedings.mlr.press/v238/tatli24a.html": {
    "title": "Learning Populations of Preferences via Pairwise Comparison Queries",
    "volume": "main",
    "abstract": "Ideal point based preference learning using pairwise comparisons of type \"Do you prefer a or b?\" has emerged as a powerful tool for understanding how we make preferences. Existing preference learning approaches assume homogeneity and focus on learning preference on average over the population or require a large number of queries per individual to localize individual preferences. However, in practical scenarios with heterogeneous preferences and limited availability of responses, these approaches are impractical. Therefore, we introduce the problem of learning the distribution of preferences over a population via pairwise comparisons using only one response per individual. Due to binary answers from comparison queries, we focus on learning the mass of the underlying distribution in the regions created by the intersection of bisecting hyperplanes between queried item pairs. We investigate this fundamental question in both 1-D and higher dimensional settings with noiseless response to comparison queries. We show that the problem is identifiable in 1-D setting and provide recovery guarantees. We show that the problem is not identifiable for higher dimensional settings in general and establish sufficient condition for identifiability. We propose using a regularized recovery, and provide guarantees on the total variation distance between the true mass and the learned distribution. We validate our findings through simulations and experiments on real datasets. We also introduce a new dataset for this task collected on a real crowdsourcing platform",
    "checked": true,
    "id": "849e41554381451f986e58d5f0ec519205911865",
    "semantic_title": "learning populations of preferences via pairwise comparison queries",
    "citation_count": 1,
    "authors": [
      "Gokcan Tatli",
      "Yi Chen",
      "Ramya Korlakai Vinayak"
    ]
  },
  "https://proceedings.mlr.press/v238/xiang24a.html": {
    "title": "A Neural Architecture Predictor based on GNN-Enhanced Transformer",
    "volume": "main",
    "abstract": "Neural architecture performance predictor is an efficient approach for architecture estimation in Neural Architecture Search (NAS). However, existing predictors based on Graph Neural Networks (GNNs) are deficient in modeling long-range interactions between operation nodes and prone to the problem of over-smoothing, which limits their ability to learn neural architecture representation. Furthermore, some Transformer-based predictors use simple position encodings to improve performance via self-attention mechanism, but they fail to fully exploit the subgraph structure information of the graph. To solve this problem, we propose a novel method to enhance the graph representation of neural architectures by combining GNNs and Transformer blocks. We evaluate the effectiveness of our predictor on NAS-Bench-101 and NAS-bench-201 benchmarks, the discovered architecture on DARTS search space achieves an accuracy of 97.61% on CIFAR-10 dataset, which outperforms traditional position encoding methods such as adjacency and Laplacian matrices. The code of our work is available at \\url{https://github.com/GNET}",
    "checked": true,
    "id": "b7c5b7077145c4f7641a111498d0d2be0555c930",
    "semantic_title": "a neural architecture predictor based on gnn-enhanced transformer",
    "citation_count": 0,
    "authors": [
      "Xunzhi Xiang",
      "Kun Jing",
      "Jungang Xu"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24b.html": {
    "title": "Efficient Neural Architecture Design via Capturing Architecture-Performance Joint Distribution",
    "volume": "main",
    "abstract": "The relationship between architecture and performance is critical for improving the efficiency of neural architecture design, yet few efforts have been devoted to understanding this relationship between architecture and performance, especially architecture-performance joint distribution. In this paper, we propose Semi-Supervised Generative Adversarial Networks Neural Architecture Design Method or SemiGAN-NAD to capture the architecture-performance joint distribution with few performance labels. It is composed of Bidirectional Transformer of Architecture and Performance (Bi-Arch2Perf) and Neural Architecture Conditional Generation (NACG). Bi-Arch2Perf is developed to learn the joint distribution of architecture and performance from bidirectional conditional distribution through the adversarial training of the discriminator, the architecture generator, and the performance predictor. Then, the incorporation of semi-supervised learning optimizes the construction of Bi-Arch2Perf by utilizing a large amount of architecture information without performance annotation in search space. Based on the learned bidirectional relationship, the performance of architecture is predicted by NACG in high-performance architecture space to efficiently discover well-promising neural architectures. The experimental results on NAS benchmarks demonstrate that SemiGAN-NAD achieves competitive performance with reduced evaluation time compared with the latest NAS methods. Moreover, the high-performance architecture signatures learned by Bi-Arch2Perf are also illustrated in our experiments",
    "checked": true,
    "id": "ee63836d45ba1edc179d47386bed291f104f6958",
    "semantic_title": "efficient neural architecture design via capturing architecture-performance joint distribution",
    "citation_count": 0,
    "authors": [
      "Yue Liu",
      "Ziyi Yu",
      "Zitu Liu",
      "Wenjie Tian"
    ]
  },
  "https://proceedings.mlr.press/v238/lee24a.html": {
    "title": "Analysis of Using Sigmoid Loss for Contrastive Learning",
    "volume": "main",
    "abstract": "Contrastive learning has emerged as a prominent branch of self-supervised learning for several years. Especially, CLIP, which applies contrastive learning to large sets of captioned images, has garnered significant attention. Recently, SigLIP, a variant of CLIP, has been proposed, which uses the sigmoid loss instead of the standard InfoNCE loss. SigLIP achieves the performance comparable to CLIP in a more efficient manner by eliminating the need for a global view. However, theoretical understanding of using the sigmoid loss in contrastive learning is underexplored. In this paper, we provide a theoretical analysis of using the sigmoid loss in contrastive learning, in the perspective of the geometric structure of learned embeddings. First, we propose the double-Constant Embedding Model (CCEM), a framework for parameterizing various well-known embedding structures by a single variable. Interestingly, the proposed CCEM is proven to contain the optimal embedding with respect to the sigmoid loss. Second, we mathematically analyze the optimal embedding minimizing the sigmoid loss for contrastive learning. The optimal embedding ranges from simplex equiangular-tight-frame to antipodal structure, depending on the temperature parameter used in the sigmoid loss. Third, our experimental results on synthetic datasets coincide with the theoretical results on the optimal embedding structures",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chungpa Lee",
      "Joonhwan Chang",
      "Jy-yong Sohn"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24c.html": {
    "title": "Robust Data Clustering with Outliers via Transformed Tensor Low-Rank Representation",
    "volume": "main",
    "abstract": "Recently, tensor low-rank representation (TLRR) has become a popular tool for tensor data recovery and clustering, due to its empirical success and theoretical guarantees. However, existing TLRR methods consider Gaussian or gross sparse noise, inevitably leading to performance degradation when the tensor data are contaminated by outliers or sample-specific corruptions. This paper develops an outlier-robust tensor low-rank representation (OR-TLRR) method that provides outlier detection and tensor data clustering simultaneously based on the t-SVD framework. For tensor observations with arbitrary outlier corruptions, OR-TLRR has provable performance guarantee for exactly recovering the row space of clean data and detecting outliers under mild conditions. Moreover, an extension of OR-TLRR is proposed to handle the case when parts of the data are missing. Finally, extensive experimental results on synthetic and real data demonstrate the effectiveness of the proposed algorithms. We release our code at \\url{https://github.com/twugithub/2024-AISTATS-ORTLRR}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tong Wu"
    ]
  },
  "https://proceedings.mlr.press/v238/han24a.html": {
    "title": "Robust SVD Made Easy: A fast and reliable algorithm for large-scale data analysis",
    "volume": "main",
    "abstract": "The singular value decomposition (SVD) is a crucial tool in machine learning and statistical data analysis. However, it is highly susceptible to outliers in the data matrix. Existing robust SVD algorithms often sacrifice speed for robustness or fail in the presence of only a few outliers. This study introduces an efficient algorithm, called Spherically Normalized SVD, for robust SVD approximation that is highly insensitive to outliers, computationally scalable, and provides accurate approximations of singular vectors. The proposed algorithm achieves remarkable speed by utilizing only two applications of a standard reduced-rank SVD algorithm to appropriately scaled data, significantly outperforming competing algorithms in computation times. To assess the robustness of the approximated singular vectors and their subspaces against data contamination, we introduce new notions of breakdown points for matrix-valued input, including row-wise, column-wise, and block-wise breakdown points. Theoretical and empirical analyses demonstrate that our algorithm exhibits higher breakdown points compared to standard SVD and its modifications. We empirically validate the effectiveness of our approach in applications such as robust low-rank approximation and robust principal component analysis of high-dimensional microarray datasets. Overall, our study presents a highly efficient and robust solution for SVD approximation that overcomes the limitations of existing algorithms in the presence of outliers",
    "checked": true,
    "id": "05ba0cdd689b9ebb26612321f90ddb4c4fcbbed7",
    "semantic_title": "robust svd made easy: a fast and reliable algorithm for large-scale data analysis",
    "citation_count": 0,
    "authors": [
      "Sangil Han",
      "Sungkyu Jung",
      "Kyoowon Kim"
    ]
  },
  "https://proceedings.mlr.press/v238/liang24a.html": {
    "title": "Regret Bounds for Risk-sensitive Reinforcement Learning with Lipschitz Dynamic Risk Measures",
    "volume": "main",
    "abstract": "We study finite episodic Markov decision processes incorporating dynamic risk measures to capture risk sensitivity. To this end, we present two model-based algorithms applied to \\emph{Lipschitz} dynamic risk measures, a wide range of risk measures that subsumes spectral risk measure, optimized certainty equivalent, and distortion risk measures, among others. We establish both regret upper bounds and lower bounds. Notably, our upper bounds demonstrate optimal dependencies on the number of actions and episodes while reflecting the inherent trade-off between risk sensitivity and sample complexity. Our approach offers a unified framework that not only encompasses multiple existing formulations in the literature but also broadens the application spectrum",
    "checked": true,
    "id": "a8af763f4bb0f52b32217633fd87c22eb54d4352",
    "semantic_title": "regret bounds for risk-sensitive reinforcement learning with lipschitz dynamic risk measures",
    "citation_count": 3,
    "authors": [
      "Hao Liang",
      "Zhiquan Luo"
    ]
  },
  "https://proceedings.mlr.press/v238/frederik-thielmann24a.html": {
    "title": "Neural Additive Models for Location Scale and Shape: A Framework for Interpretable Neural Regression Beyond the Mean",
    "volume": "main",
    "abstract": "Deep neural networks (DNNs) have proven to be highly effective in a variety of tasks, making them the go-to method for problems requiring high-level predictive power. Despite this success, the inner workings of DNNs are often not transparent, making them difficult to interpret or understand. This lack of interpretability has led to increased research on inherently interpretable neural networks in recent years. Models such as Neural Additive Models (NAMs) achieve visual interpretability through the combination of classical statistical methods with DNNs. However, these approaches only concentrate on mean response predictions, leaving out other properties of the response distribution of the underlying data. We propose Neural Additive Models for Location Scale and Shape (NAMLSS), a modelling framework that combines the predictive power of classical deep learning models with the inherent advantages of distributional regression while maintaining the interpretability of additive models. The code is available at the following link: \\url{https://github.com/AnFreTh/NAMpy}",
    "checked": true,
    "id": "c64d89501acd21c55bf18786e76b8df9e091bcdd",
    "semantic_title": "neural additive models for location scale and shape: a framework for interpretable neural regression beyond the mean",
    "citation_count": 4,
    "authors": [
      "Anton Frederik Thielmann",
      "René-Marcel Kruse",
      "Thomas Kneib",
      "Benjamin Säfken"
    ]
  },
  "https://proceedings.mlr.press/v238/eliasof24a.html": {
    "title": "On The Temporal Domain of Differential Equation Inspired Graph Neural Networks",
    "volume": "main",
    "abstract": "Graph Neural Networks (GNNs) have demonstrated remarkable success in modeling complex relationships in graph-structured data. A recent innovation in this field is the family of Differential Equation-Inspired Graph Neural Networks (DE-GNNs), which leverage principles from continuous dynamical systems to model information flow on graphs with built-in properties such as feature smoothing or preservation. However, existing DE-GNNs rely on first or second-order temporal dependencies. In this paper, we propose a neural extension to those pre-defined temporal dependencies. We show that our model, called TDE-GNN, can capture a wide range of temporal dynamics that go beyond typical first or second-order methods, and provide use cases where existing temporal models are challenged. We demonstrate the benefit of learning the temporal dependencies using our method rather than using pre-defined temporal dynamics on several graph benchmarks",
    "checked": true,
    "id": "9a227e7014c89095b713bdd0263b13ec6d6256f4",
    "semantic_title": "on the temporal domain of differential equation inspired graph neural networks",
    "citation_count": 3,
    "authors": [
      "Moshe Eliasof",
      "Eldad Haber",
      "Eran Treister",
      "Carola-Bibiane B Schönlieb"
    ]
  },
  "https://proceedings.mlr.press/v238/wagner24a.html": {
    "title": "Diagonalisation SGD: Fast & Convergent SGD for Non-Differentiable Models via Reparameterisation and Smoothing",
    "volume": "main",
    "abstract": "It is well-known that the reparameterisation gradient estimator, which exhibits low variance in practice, is biased for non-differentiable models. This may compromise correctness of gradient-based optimisation methods such as stochastic gradient descent (SGD). We introduce a simple syntactic framework to define non-differentiable functions piecewisely and present a systematic approach to obtain smoothings for which the reparameterisation gradient estimator is unbiased. Our main contribution is a novel variant of SGD, Diagonalisation Stochastic Gradient Descent, which progressively enhances the accuracy of the smoothed approximation during optimisation, and we prove convergence to stationary points of the unsmoothed (original) objective. Our empirical evaluation reveals benefits over the state of the art: our approach is simple, fast, stable and attains orders of magnitude reduction in work-normalised variance",
    "checked": true,
    "id": "d0e3a2dfab1c3f573c504288d7a4c2b125ee3000",
    "semantic_title": "diagonalisation sgd: fast & convergent sgd for non-differentiable models via reparameterisation and smoothing",
    "citation_count": 0,
    "authors": [
      "Dominik Wagner",
      "Basim Khajwal",
      "Luke Ong"
    ]
  },
  "https://proceedings.mlr.press/v238/sharrock24a.html": {
    "title": "Tuning-Free Maximum Likelihood Training of Latent Variable Models via Coin Betting",
    "volume": "main",
    "abstract": "We introduce two new particle-based algorithms for learning latent variable models via marginal maximum likelihood estimation, including one which is entirely tuning-free. Our methods are based on the perspective of marginal maximum likelihood estimation as an optimization problem: namely, as the minimization of a free energy functional. One way to solve this problem is via the discretization of a gradient flow associated with the free energy. We study one such approach, which resembles an extension of Stein variational gradient descent, establishing a descent lemma which guarantees that the free energy decreases at each iteration. This method, and any other obtained as the discretization of the gradient flow, necessarily depends on a learning rate which must be carefully tuned by the practitioner in order to ensure convergence at a suitable rate. With this in mind, we also propose another algorithm for optimizing the free energy which is entirely learning rate free, based on coin betting techniques from convex optimization. We validate the performance of our algorithms across several numerical experiments, including several high-dimensional settings. Our results are competitive with existing particle-based methods, without the need for any hyperparameter tuning",
    "checked": true,
    "id": "fc0fb830bbe7fab47d10ff102d999a1ead9c59f9",
    "semantic_title": "tuning-free maximum likelihood training of latent variable models via coin betting",
    "citation_count": 7,
    "authors": [
      "Louis Sharrock",
      "Daniel Dodd",
      "Christopher Nemeth"
    ]
  },
  "https://proceedings.mlr.press/v238/dold24a.html": {
    "title": "Bayesian Semi-structured Subspace Inference",
    "volume": "main",
    "abstract": "Semi-structured regression models enable the joint modeling of interpretable structured and complex unstructured feature effects. The structured model part is inspired by statistical models and can be used to infer the input-output relationship for features of particular importance. The complex unstructured part defines an arbitrary deep neural network and thereby provides enough flexibility to achieve competitive prediction performance. While these models can also account for aleatoric uncertainty, there is still a lack of work on accounting for epistemic uncertainty. In this paper, we address this problem by presenting a Bayesian approximation for semi-structured regression models using subspace inference. To this end, we extend subspace inference for joint posterior sampling from a full parameter space for structured effects and a subspace for unstructured effects. Apart from this hybrid sampling scheme, our method allows for tunable complexity of the subspace and can capture multiple minima in the loss landscape. Numerical experiments validate our approach's efficacy in recovering structured effect parameter posteriors in semi-structured models and approaching the full-space posterior distribution of MCMC for increasing subspace dimension. Further, our approach exhibits competitive predictive performance across simulated and real-world datasets",
    "checked": true,
    "id": "e87b7dfc84420d3a866af94810277c0e25e9f7d3",
    "semantic_title": "bayesian semi-structured subspace inference",
    "citation_count": 0,
    "authors": [
      "Daniel Dold",
      "David Ruegamer",
      "Beate Sick",
      "Oliver Dürr"
    ]
  },
  "https://proceedings.mlr.press/v238/nguyen-le-duy24a.html": {
    "title": "CAD-DA: Controllable Anomaly Detection after Domain Adaptation by Statistical Inference",
    "volume": "main",
    "abstract": "We propose a novel statistical method for testing the results of anomaly detection (AD) under domain adaptation (DA), which we call CAD-DA—controllable AD under DA. The distinct advantage of the CAD-DA lies in its ability to control the probability of misidentifying anomalies under a pre-specified level $\\alpha$ (e.g., 0.05). The challenge within this DA setting is the necessity to account for the influence of DA to ensure the validity of the inference results. We overcome the challenge by leveraging the concept of Selective Inference to handle the impact of DA. To our knowledge, this is the first work capable of conducting a valid statistical inference within the context of DA. We evaluate the performance of the CAD-DA method on both synthetic and real-world datasets",
    "checked": true,
    "id": "839b423f20d0bbf31e81fe8a3466c28915289861",
    "semantic_title": "cad-da: controllable anomaly detection after domain adaptation by statistical inference",
    "citation_count": 2,
    "authors": [
      "Vo Nguyen Le Duy",
      "Hsuan-Tien Lin",
      "Ichiro Takeuchi"
    ]
  },
  "https://proceedings.mlr.press/v238/jaffard24a.html": {
    "title": "Provable local learning rule by expert aggregation for a Hawkes network",
    "volume": "main",
    "abstract": "We propose a simple network of Hawkes processes as a cognitive model capable of learning to classify objects. Our learning algorithm, named HAN for Hawkes Aggregation of Neurons, is based on a local synaptic learning rule based on spiking probabilities at each output node. We were able to use local regret bounds to prove mathematically that the network is able to learn on average and even asymptotically under more restrictive assumptions",
    "checked": true,
    "id": "c8f186cb4fd33c85f7c0bc67706dcaeb42150098",
    "semantic_title": "provable local learning rule by expert aggregation for a hawkes network",
    "citation_count": 1,
    "authors": [
      "Sophie Jaffard",
      "Samuel Vaiter",
      "Alexandre Muzy",
      "Patricia Reynaud-Bouret"
    ]
  },
  "https://proceedings.mlr.press/v238/achddou24a.html": {
    "title": "Multitask Online Learning: Listen to the Neighborhood Buzz",
    "volume": "main",
    "abstract": "We study multitask online learning in a setting where agents can only exchange information with their neighbors on an arbitrary communication network. We introduce MT-CO\\textsubscript{2}OL, a decentralized algorithm for this setting whose regret depends on the interplay between the task similarities and the network structure. Our analysis shows that the regret of MT-CO\\textsubscript{2}OL is never worse (up to constants) than the bound obtained when agents do not share information. On the other hand, our bounds significantly improve when neighboring agents operate on similar tasks. In addition, we prove that our algorithm can be made differentially private with a negligible impact on the regret. Finally, we provide experimental support for our theory",
    "checked": true,
    "id": "1c50175a5a11cd084237e05d254332b0ac397656",
    "semantic_title": "multitask online learning: listen to the neighborhood buzz",
    "citation_count": 0,
    "authors": [
      "Juliette Achddou",
      "Nicolò Cesa-Bianchi",
      "Pierre Laforgue"
    ]
  },
  "https://proceedings.mlr.press/v238/korhonen24a.html": {
    "title": "Structural perspective on constraint-based learning of Markov networks",
    "volume": "main",
    "abstract": "Markov networks are probabilistic graphical models that employ undirected graphs to depict conditional independence relationships among variables. Our focus lies in constraint-based structure learning, which entails learning the undirected graph from data through the execution of conditional independence tests. We establish theoretical limits concerning two critical aspects of constraint-based learning of Markov networks: the number of tests and the sizes of the conditioning sets. These bounds uncover an exciting interplay between the structural properties of the graph and the amount of tests required to learn a Markov network. The starting point of our work is that the graph parameter maximum pairwise connectivity, $\\kappa$, that is, the maximum number of vertex-disjoint paths connecting a pair of vertices in the graph, is responsible for the sizes of independence tests required to learn the graph. On one hand, we show that at least one test with the size of the conditioning set at least $\\kappa$ is always necessary. On the other hand, we prove that any graph can be learned by performing tests of size at most $\\kappa$. This completely resolves the question of the minimum size of conditioning sets required to learn the graph. When it comes to the number of tests, our upper bound on the sizes of conditioning sets implies that every $n$-vertex graph can be learned by at most $n^{\\kappa}$ tests with conditioning sets of sizes at most $\\kappa$. We show that for any upper bound q on the sizes of the conditioning sets, there exist graphs with $O(nq)$ vertices that require at least $n^{\\Omega(\\kappa)}$ tests to learn. This lower bound holds even when the treewidth and the maximum degree of the graph are at most $\\kappa+2$. On the positive side, we prove that every graph of bounded treewidth can be learned by a polynomial number of tests with conditioning sets of sizes at most $2*\\kappa$",
    "checked": true,
    "id": "b130463eee68880a0e045ae76a5b45fc9c5350ee",
    "semantic_title": "structural perspective on constraint-based learning of markov networks",
    "citation_count": 0,
    "authors": [
      "Tuukka Korhonen",
      "Fedor Fomin",
      "Pekka Parviainen"
    ]
  },
  "https://proceedings.mlr.press/v238/huynh24a.html": {
    "title": "DAGnosis: Localized Identification of Data Inconsistencies using Structures",
    "volume": "main",
    "abstract": "Identification and appropriate handling of inconsistencies in data at deployment time is crucial to reliably use machine learning models. While recent data-centric methods are able to identify such inconsistencies with respect to the training set, they suffer from two key limitations: (1) suboptimality in settings where features exhibit statistical independencies, due to their usage of compressive representations and (2) lack of localization to pin-point why a sample might be flagged as inconsistent, which is important to guide future data collection. We solve these two fundamental limitations using directed acyclic graphs (DAGs) to encode the training set's features probability distribution and independencies as a structure. Our method, called DAGnosis, leverages these structural interactions to bring valuable and insightful data-centric conclusions. DAGnosis unlocks the localization of the causes of inconsistencies on a DAG, an aspect overlooked by previous approaches. Moreover, we show empirically that leveraging these interactions (1) leads to more accurate conclusions in detecting inconsistencies, as well as (2) provides more detailed insights into why some samples are flagged",
    "checked": true,
    "id": "e0b0b1a1f8fe7a46f4792c071f55cd91c35570e7",
    "semantic_title": "dagnosis: localized identification of data inconsistencies using structures",
    "citation_count": 0,
    "authors": [
      "Nicolas Huynh",
      "Jeroen Berrevoets",
      "Nabeel Seedat",
      "Jonathan Crabbé",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ]
  },
  "https://proceedings.mlr.press/v238/haasler24a.html": {
    "title": "Bures-Wasserstein Means of Graphs",
    "volume": "main",
    "abstract": "Finding the mean of sampled data is a fundamental task in machine learning and statistics. However, in cases where the data samples are graph objects, defining a mean is an inherently difficult task. We propose a novel framework for defining a graph mean via embeddings in the space of smooth graph signal distributions, where graph similarity can be measured using the Wasserstein metric. By finding a mean in this embedding space, we can recover a mean graph that preserves structural information. We establish the existence and uniqueness of the novel graph mean, and provide an iterative algorithm for computing it. To highlight the potential of our framework as a valuable tool for practical applications in machine learning, it is evaluated on various tasks, including k-means clustering of structured aligned graphs, classification of functional brain networks, and semi-supervised node classification in multi-layer graphs. Our experimental results demonstrate that our approach achieves consistent performance, outperforms existing baseline approaches, and improves the performance of state-of-the-art methods",
    "checked": true,
    "id": "4899bfa2d2281c610ccd60797bba34468928cdb1",
    "semantic_title": "bures-wasserstein means of graphs",
    "citation_count": 1,
    "authors": [
      "Isabel Haasler",
      "Pascal Frossard"
    ]
  },
  "https://proceedings.mlr.press/v238/nakis24a.html": {
    "title": "Time to Cite: Modeling Citation Networks using the Dynamic Impact Single-Event Embedding Model",
    "volume": "main",
    "abstract": "Understanding the structure and dynamics of scientific research, i.e., the science of science (SciSci), has become an important area of research in order to address imminent questions including how scholars interact to advance science, how disciplines are related and evolve, and how research impact can be quantified and predicted. Central to the study of SciSci has been the analysis of citation networks. Here, two prominent modeling methodologies have been employed: one is to assess the citation impact dynamics of papers using parametric distributions, and the other is to embed the citation networks in a latent space optimal for characterizing the static relations between papers in terms of their citations. Interestingly, citation networks are a prominent example of single-event dynamic networks, i.e., networks for which each dyad only has a single event (i.e., the point in time of citation). We presently propose a novel likelihood function for the characterization of such single-event networks. Using this likelihood, we propose the Dynamic Impact Single-Event Embedding model (DISEE). The DISEE model characterizes the scientific interactions in terms of a latent distance model in which random effects account for citation heterogeneity while the time-varying impact is characterized using existing parametric representations for assessment of dynamic impact. We highlight the proposed approach on several real citation networks finding that DISEE well reconciles static latent distance network embedding approaches with classical dynamic impact assessments",
    "checked": true,
    "id": "2428248c7e8e26b8500d906ad0f09d4a9de5ad1a",
    "semantic_title": "time to cite: modeling citation networks using the dynamic impact single-event embedding model",
    "citation_count": 0,
    "authors": [
      "Nikolaos Nakis",
      "Abdulkadir Celikkanat",
      "Louis Boucherie",
      "Sune Lehmann",
      "Morten Mørup"
    ]
  },
  "https://proceedings.mlr.press/v238/september24a.html": {
    "title": "Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks",
    "volume": "main",
    "abstract": "Data preprocessing is a crucial part of any machine learning pipeline, and it can have a significant impact on both performance and training efficiency. This is especially evident when using deep neural networks for time series prediction and classification: real-world time series data often exhibit irregularities such as multi-modality, skewness and outliers, and the model performance can degrade rapidly if these characteristics are not adequately addressed. In this work, we propose the EDAIN (Extended Deep Adaptive Input Normalization) layer, a novel adaptive neural layer that learns how to appropriately normalize irregular time series data for a given task in an end-to-end fashion, instead of using a fixed normalization scheme. This is achieved by optimizing its unknown parameters simultaneously with the deep neural network using back-propagation. Our experiments, conducted using synthetic data, a credit default prediction dataset, and a large-scale limit order book benchmark dataset, demonstrate the superior performance of the EDAIN layer when compared to conventional normalization methods and existing adaptive time series preprocessing layers",
    "checked": true,
    "id": "71a9a8ce020718915a88110a0ad3f11f6b714664",
    "semantic_title": "extended deep adaptive input normalization for preprocessing time series data for neural networks",
    "citation_count": 0,
    "authors": [
      "Marcus A. K. September",
      "Francesco Sanna Passino",
      "Leonie Goldmann",
      "Anton Hinel"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24d.html": {
    "title": "Restricted Isometry Property of Rank-One Measurements with Random Unit-Modulus Vectors",
    "volume": "main",
    "abstract": "The restricted isometry property (RIP) is essential for the linear map to guarantee the successful recovery of low-rank matrices. The existing works show that the linear map generated by the measurement matrices with independent and identically distributed (i.i.d.) entries satisfies RIP with high probability. However, when dealing with non-i.i.d. measurement matrices, such as the rank-one measurements, the RIP compliance may not be guaranteed. In this paper, we show that the RIP can still be achieved with high probability, when the rank-one measurement matrix is constructed by the random unit-modulus vectors. Compared to the existing works, we first address the challenge of establishing RIP for the linear map in non-i.i.d. scenarios. As validated in the experiments, this linear map is memory-efficient, and not only satisfies the RIP but also exhibits similar recovery performance of the low-rank matrices to that of conventional i.i.d. measurement matrices",
    "checked": true,
    "id": "5ce3bd19fdfb4a5b979c6a1a17e31004b5da1ff0",
    "semantic_title": "restricted isometry property of rank-one measurements with random unit-modulus vectors",
    "citation_count": 0,
    "authors": [
      "Wei Zhang",
      "Zhenni Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/verma24a.html": {
    "title": "Variational Gaussian Process Diffusion Processes",
    "volume": "main",
    "abstract": "Diffusion processes are a class of stochastic differential equations (SDEs) providing a rich family of expressive models that arise naturally in dynamic modelling tasks. Probabilistic inference and learning under generative models with latent processes endowed with a non-linear diffusion process prior are intractable problems. We build upon work within variational inference, approximating the posterior process as a linear diffusion process, and point out pathologies in the approach. We propose an alternative parameterization of the Gaussian variational process using a site-based exponential family description. This allows us to trade a slow inference algorithm with fixed-point iterations for a fast algorithm for convex optimization akin to natural gradient descent, which also provides a better objective for learning model parameters",
    "checked": true,
    "id": "59d733c1ae28fdc4a77fb821d17a79cb3eb0b0d4",
    "semantic_title": "variational gaussian process diffusion processes",
    "citation_count": 2,
    "authors": [
      "Prakhar Verma",
      "Vincent Adam",
      "Arno Solin"
    ]
  },
  "https://proceedings.mlr.press/v238/zhao24a.html": {
    "title": "Positivity-free Policy Learning with Observational Data",
    "volume": "main",
    "abstract": "Policy learning utilizing observational data is pivotal across various domains, with the objective of learning the optimal treatment assignment policy while adhering to specific constraints such as fairness, budget, and simplicity. This study introduces a novel positivity-free (stochastic) policy learning framework designed to address the challenges posed by the impracticality of the positivity assumption in real-world scenarios. This framework leverages incremental propensity score policies to adjust propensity score values instead of assigning fixed values to treatments. We characterize these incremental propensity score policies and establish identification conditions, employing semiparametric efficiency theory to propose efficient estimators capable of achieving rapid convergence rates, even when integrated with advanced machine learning algorithms. This paper provides a thorough exploration of the theoretical guarantees associated with policy learning and validates the proposed framework's finite-sample performance through comprehensive numerical experiments, ensuring the identification of causal effects from observational data is both robust and reliable",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pan Zhao",
      "Antoine Chambaz",
      "Julie Josse",
      "Shu Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/lorch24a.html": {
    "title": "Causal Modeling with Stationary Diffusions",
    "volume": "main",
    "abstract": "We develop a novel approach towards causal inference. Rather than structural equations over a causal graph, we learn stochastic differential equations (SDEs) whose stationary densities model a system's behavior under interventions. These stationary diffusion models do not require the formalism of causal graphs, let alone the common assumption of acyclicity. We show that in several cases, they generalize to unseen interventions on their variables, often better than classical approaches. Our inference method is based on a new theoretical result that expresses a stationarity condition on the diffusion's generator in a reproducing kernel Hilbert space. The resulting kernel deviation from stationarity (KDS) is an objective function of independent interest",
    "checked": true,
    "id": "90990e3f750958d91bd3d31085c641676f9e3e9e",
    "semantic_title": "causal modeling with stationary diffusions",
    "citation_count": 2,
    "authors": [
      "Lars Lorch",
      "Andreas Krause",
      "Bernhard Schölkopf"
    ]
  },
  "https://proceedings.mlr.press/v238/ichikawa24a.html": {
    "title": "Learning Dynamics in Linear VAE: Posterior Collapse Threshold, Superfluous Latent Space Pitfalls, and Speedup with KL Annealing",
    "volume": "main",
    "abstract": "Variational autoencoders (VAEs) face a notorious problem wherein the variational posterior often aligns closely with the prior, a phenomenon known as posterior collapse, which hinders the quality of representation learning. To mitigate this problem, an adjustable hyperparameter $\\beta$ and a strategy for annealing this parameter, called KL annealing, are proposed. This study presents a theoretical analysis of the learning dynamics in a minimal VAE. It is rigorously proved that the dynamics converge to a deterministic process within the limit of large input dimensions, thereby enabling a detailed dynamical analysis of the generalization error. Furthermore, the analysis shows that the VAE initially learns entangled representations and gradually acquires disentangled representations. A fixed-point analysis of the deterministic process reveals that when $\\beta$ exceeds a certain threshold, posterior collapse becomes inevitable regardless of the learning period. Additionally, the superfluous latent variables for the data-generative factors lead to overfitting of the background noise; this adversely affects both generalization and learning convergence. The analysis further unveiled that appropriately tuned KL annealing can accelerate convergence",
    "checked": true,
    "id": "7669fea710b955b6794a6b04ea77f06462a4751e",
    "semantic_title": "learning dynamics in linear vae: posterior collapse threshold, superfluous latent space pitfalls, and speedup with kl annealing",
    "citation_count": 0,
    "authors": [
      "Yuma Ichikawa",
      "Koji Hukushima"
    ]
  },
  "https://proceedings.mlr.press/v238/heidrich24a.html": {
    "title": "A 4-Approximation Algorithm for Min Max Correlation Clustering",
    "volume": "main",
    "abstract": "We introduce a lower bounding technique for the min max correlation clustering problem and, based on this technique, a combinatorial 4-approximation algorithm for complete graphs. This improves upon the previous best known approximation guarantees of 5, using a linear program formulation (Kalhan et al., 2019), and 40, for a combinatorial algorithm (Davies et al., 2023). We extend this algorithm by a greedy joining heuristic and show empirically that it improves the state of the art in solution quality and runtime on several benchmark datasets",
    "checked": true,
    "id": "30ddbcdbfe17efe2c57ba8e063ce6e66221ee2ba",
    "semantic_title": "a 4-approximation algorithm for min max correlation clustering",
    "citation_count": 3,
    "authors": [
      "Holger S. G. Heidrich",
      "Jannik Irmai",
      "Bjoern Andres"
    ]
  },
  "https://proceedings.mlr.press/v238/li24i.html": {
    "title": "Ethics in Action: Training Reinforcement Learning Agents for Moral Decision-making In Text-based Adventure Games",
    "volume": "main",
    "abstract": "Reinforcement Learning (RL) has demonstrated its potential in solving goal-oriented sequential tasks. However, with the increasing capabilities of RL agents, ensuring morally responsible agent behavior is becoming a pressing concern. Previous approaches have included moral considerations by statically assigning a moral score to each action at runtime. However, these methods do not account for the potential moral value of future states when evaluating immoral actions. This limits the ability to find trade-offs between different aspects of moral behavior and the utility of the action. In this paper, we aim to factor in moral scores by adding a constraint to the RL objective that is incorporated during training, thereby dynamically adapting the policy function. By combining Lagrangian optimization and meta-gradient learning, we develop an RL method that is able to find a trade-off between immoral behavior and performance in the decision-making process",
    "checked": true,
    "id": "c02d39a7a9068e4c9ef377e9c1b78b40f1678f8f",
    "semantic_title": "ethics in action: training reinforcement learning agents for moral decision-making in text-based adventure games",
    "citation_count": 1,
    "authors": [
      "Weichen Li",
      "Rati Devidze",
      "Waleed Mustafa",
      "Sophie Fellenz"
    ]
  },
  "https://proceedings.mlr.press/v238/waldchen24a.html": {
    "title": "Interpretability Guarantees with Merlin-Arthur Classifiers",
    "volume": "main",
    "abstract": "We propose an interactive multi-agent classifier that provides provable interpretability guarantees even for complex agents such as neural networks. These guarantees consist of lower bounds on the mutual information between selected features and the classification decision. Our results are inspired by the Merlin-Arthur protocol from Interactive Proof Systems and express these bounds in terms of measurable metrics such as soundness and completeness. Compared to existing interactive setups, we rely neither on optimal agents nor on the assumption that features are distributed independently. Instead, we use the relative strength of the agents as well as the new concept of Asymmetric Feature Correlation which captures the precise kind of correlations that make interpretability guarantees difficult. We evaluate our results on two small-scale datasets where high mutual information can be verified explicitly",
    "checked": true,
    "id": "00c5b992e7fe245131973eb64089e97c84417b46",
    "semantic_title": "interpretability guarantees with merlin-arthur classifiers",
    "citation_count": 3,
    "authors": [
      "Stephan Wäldchen",
      "Kartikey Sharma",
      "Berkant Turan",
      "Max Zimmer",
      "Sebastian Pokutta"
    ]
  },
  "https://proceedings.mlr.press/v238/berta24a.html": {
    "title": "Classifier Calibration with ROC-Regularized Isotonic Regression",
    "volume": "main",
    "abstract": "Calibration of machine learning classifiers is necessary to obtain reliable and interpretable predictions, bridging the gap between model outputs and actual probabilities. One prominent technique, isotonic regression (IR), aims at calibrating binary classifiers by minimizing the cross entropy with respect to monotone transformations. IR acts as an adaptive binning procedure that is able to achieve a calibration error of zero but leaves open the issue of the effect on performance. We first prove that IR preserves the convex hull of the ROC curve—an essential performance metric for binary classifiers. This ensures that a classifier is calibrated while controlling for over-fitting of the calibration set. We then present a novel generalization of isotonic regression to accommodate classifiers with $K$-classes. Our method constructs a multidimensional adaptive binning scheme on the probability simplex, again achieving a multi-class calibration error equal to zero. We regularize this algorithm by imposing a form of monotony that preserves the $K$-dimensional ROC surface of the classifier. We show empirically that this general monotony criterion is effective in striking a balance between reducing cross entropy loss and avoiding over-fitting of the calibration set",
    "checked": true,
    "id": "07342a5a85164d736a68d14b11253e615381655e",
    "semantic_title": "classifier calibration with roc-regularized isotonic regression",
    "citation_count": 1,
    "authors": [
      "Eugène Berta",
      "Francis Bach",
      "Michael Jordan"
    ]
  },
  "https://proceedings.mlr.press/v238/tighineanu24a.html": {
    "title": "Scalable Meta-Learning with Gaussian Processes",
    "volume": "main",
    "abstract": "Meta-learning is a powerful approach that exploits historical data to quickly solve new tasks from the same distribution. In the low-data regime, methods based on the closed-form posterior of Gaussian processes (GP) together with Bayesian optimization have achieved high performance. However, these methods are either computationally expensive or introduce assumptions that hinder a principled propagation of uncertainty between task models. This may disrupt the balance between exploration and exploitation during optimization. In this paper, we develop ScaML-GP, a modular GP model for meta-learning that is scalable in the number of tasks. Our core contribution is carefully designed multi-task kernel that enables hierarchical training and task scalability. Conditioning ScaML-GP on the meta-data exposes its modular nature yielding a test-task prior that combines the posteriors of meta-task GPs. In synthetic and real-world meta-learning experiments, we demonstrate that ScaML-GP can learn efficiently both with few and many meta-tasks",
    "checked": true,
    "id": "9fa998bd3ec4343f5889d2826513611a86218909",
    "semantic_title": "scalable meta-learning with gaussian processes",
    "citation_count": 1,
    "authors": [
      "Petru Tighineanu",
      "Lukas Grossberger",
      "Paul Baireuther",
      "Kathrin Skubch",
      "Stefan Falkner",
      "Julia Vinogradska",
      "Felix Berkenkamp"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24b.html": {
    "title": "An Efficient Stochastic Algorithm for Decentralized Nonconvex-Strongly-Concave Minimax Optimization",
    "volume": "main",
    "abstract": "This paper studies the stochastic nonconvex-strongly-concave minimax optimization over a multi-agent network. We propose an efficient algorithm, called Decentralized Recursive gradient descEnt Ascent Method (DREAM), which achieves the best-known theoretical guarantee for finding the $\\epsilon$-stationary points. Concretely, it requires $\\mathcal{O}(\\min (\\kappa^3\\epsilon^{-3},\\kappa^2 \\sqrt{N} \\epsilon^{-2} ))$ stochastic first-order oracle (SFO) calls and $\\tilde \\mathcal O(\\kappa^2 \\epsilon^{-2})$ communication rounds, where $\\kappa$ is the condition number and $N$ is the total number of individual functions. Our numerical experiments also validate the superiority of DREAM over previous methods",
    "checked": true,
    "id": "6055fb55be2e45689c5220b47693c9ff78ad983b",
    "semantic_title": "an efficient stochastic algorithm for decentralized nonconvex-strongly-concave minimax optimization",
    "citation_count": 5,
    "authors": [
      "Lesi Chen",
      "Haishan Ye",
      "Luo Luo"
    ]
  },
  "https://proceedings.mlr.press/v238/pegoraro24a.html": {
    "title": "Vector Quantile Regression on Manifolds",
    "volume": "main",
    "abstract": "Quantile regression (QR) is a statistical tool for distribution-free estimation of conditional quantiles of a target variable given explanatory features. QR is limited by the assumption that the target distribution is univariate and defined on an Euclidean domain. Although the notion of quantiles was recently extended to multi-variate distributions, QR for multi-variate distributions on manifolds remains underexplored, even though many important applications inherently involve data distributed on, e.g., spheres (climate and geological phenomena), and tori (dihedral angles in proteins). By leveraging optimal transport theory and c-concave functions, we meaningfully define conditional vector quantile functions of high-dimensional variables on manifolds (M-CVQFs). Our approach allows for quantile estimation, regression, and computation of conditional confidence sets and likelihoods. We demonstrate the approach's efficacy and provide insights regarding the meaning of non-Euclidean quantiles through synthetic and real data experiments",
    "checked": true,
    "id": "25dc5eb8460f888741c2ccd7b9e62eed246e3f99",
    "semantic_title": "vector quantile regression on manifolds",
    "citation_count": 1,
    "authors": [
      "Marco Pegoraro",
      "Sanketh Vedula",
      "Aviv A Rosenberg",
      "Irene Tallini",
      "Emanuele Rodola",
      "Alex Bronstein"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24d.html": {
    "title": "Near-Optimal Convex Simple Bilevel Optimization with a Bisection Method",
    "volume": "main",
    "abstract": "This paper studies a class of simple bilevel optimization problems where we minimize a composite convex function at the upper-level subject to a composite convex lower-level problem. Existing methods either provide asymptotic guarantees for the upper-level objective or attain slow sublinear convergence rates. We propose a bisection algorithm to find a solution that is $\\epsilon_f$-optimal for the upper-level objective and $\\epsilon_g$-optimal for the lower-level objective. In each iteration, the binary search narrows the interval by assessing inequality system feasibility. Under mild conditions, the total operation complexity of our method is ${{\\mathcal{O}}}\\left(\\max\\{\\sqrt{L_{f_1}/\\epsilon_f},\\sqrt{L_{g_1}/\\epsilon_g}\\} \\right)$. Here, a unit operation can be a function evaluation, gradient evaluation, or the invocation of the proximal mapping, $L_{f_1}$ and $L_{g_1}$ are the Lipschitz constants of the upper- and lower-level objectives' smooth components, and ${\\mathcal{O}}$ hides logarithmic terms. Our approach achieves a near-optimal rate in unconstrained smooth or composite convex optimization when disregarding logarithmic terms. Numerical experiments demonstrate the effectiveness of our method",
    "checked": true,
    "id": "d1df9e057a5e2450d12e4d14cfc3cd4d0dc414b0",
    "semantic_title": "near-optimal convex simple bilevel optimization with a bisection method",
    "citation_count": 0,
    "authors": [
      "Jiulin Wang",
      "Xu Shi",
      "Rujun Jiang"
    ]
  },
  "https://proceedings.mlr.press/v238/laberge24a.html": {
    "title": "Tackling the XAI Disagreement Problem with Regional Explanations",
    "volume": "main",
    "abstract": "The XAI Disagreement Problem concerns the fact that various explainability methods yield different local/global insights on model behavior. Thus, given the lack of ground truth in explainability, practitioners are left wondering \"Which explanation should I believe?\". In this work, we approach the Disagreement Problem from the point of view of Functional Decomposition (FD). First, we demonstrate that many XAI techniques disagree because they handle feature interactions differently. Secondly, we reduce interactions locally by fitting a so-called FD-Tree, which partitions the input space into regions where the model is approximately additive. Thus instead of providing global explanations aggregated over the whole dataset, we advocate reporting the FD-Tree structure as well as the regional explanations extracted from its leaves. The beneficial effects of FD-Trees on the Disagreement Problem are demonstrated on toy and real datasets",
    "checked": true,
    "id": "c580e998ced694f970d11ee0e5c2f47ea532ce8b",
    "semantic_title": "tackling the xai disagreement problem with regional explanations",
    "citation_count": 1,
    "authors": [
      "Gabriel Laberge",
      "Yann Batiste Pequignot",
      "Mario Marchand",
      "Foutse Khomh"
    ]
  },
  "https://proceedings.mlr.press/v238/frutos24a.html": {
    "title": "Training Implicit Generative Models via an Invariant Statistical Loss",
    "volume": "main",
    "abstract": "Implicit generative models have the capability to learn arbitrary complex data distributions. On the downside, training requires telling apart real data from artificially-generated ones using adversarial discriminators, leading to unstable training and mode-dropping issues. As reported by Zahee et al. (2017), even in the one-dimensional (1D) case, training a generative adversarial network (GAN) is challenging and often suboptimal. In this work, we develop a discriminator-free method for training one-dimensional (1D) generative implicit models and subsequently expand this method to accommodate multivariate cases. Our loss function is a discrepancy measure between a suitably chosen transformation of the model samples and a uniform distribution; hence, it is invariant with respect to the true distribution of the data. We first formulate our method for 1D random variables, providing an effective solution for approximate reparameterization of arbitrary complex distributions. Then, we consider the temporal setting (both univariate and multivariate), in which we model the conditional distribution of each sample given the history of the process. We demonstrate through numerical simulations that this new method yields promising results, successfully learning true distributions in a variety of scenarios and mitigating some of the well-known problems that state-of-the-art implicit methods present",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "José Manuel de Frutos",
      "Pablo Olmos",
      "Manuel Alberto Vazquez Lopez",
      "Joaquín Míguez"
    ]
  },
  "https://proceedings.mlr.press/v238/fan24b.html": {
    "title": "RL in Markov Games with Independent Function Approximation: Improved Sample Complexity Bound under the Local Access Model",
    "volume": "main",
    "abstract": "Efficiently learning equilibria with large state and action spaces in general-sum Markov games while overcoming the curse of multi-agency is a challenging problem. Recent works have attempted to solve this problem by employing independent linear function classes to approximate the marginal $Q$-value for each agent. However, existing sample complexity bounds under such a framework have a suboptimal dependency on the desired accuracy $\\varepsilon$ or the action space. In this work, we introduce a new algorithm, Lin-Confident-FTRL, for learning coarse correlated equilibria (CCE) with local access to the simulator, i.e., one can interact with the underlying environment on the visited states. Up to a logarithmic dependence on the size of the state space, Lin-Confident-FTRL learns $\\epsilon$-CCE with a provable optimal accuracy bound $O(\\epsilon^{-2})$ and gets rids of the linear dependency on the action space, while scaling polynomially with relevant problem parameters (such as the number of agents and time horizon). Moreover, our analysis of Linear-Confident-FTRL generalizes the virtual policy iteration technique in the single-agent local planning literature, which yields a new computationally efficient algorithm with a tighter sample complexity bound when assuming random access to the simulator",
    "checked": true,
    "id": "0e222481f10bac08513ecb3d027dba90972a65e0",
    "semantic_title": "rl in markov games with independent function approximation: improved sample complexity bound under the local access model",
    "citation_count": 1,
    "authors": [
      "Junyi Fan",
      "Yuxuan Han",
      "Jialin Zeng",
      "Jian-Feng Cai",
      "Yang Wang",
      "Yang Xiang",
      "Jiheng Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/dong24a.html": {
    "title": "Convergence to Nash Equilibrium and No-regret Guarantee in (Markov) Potential Games",
    "volume": "main",
    "abstract": "In this work, we study potential games and Markov potential games under stochastic cost and bandit feedback. We propose a variant of the Frank-Wolfe algorithm with sufficient exploration and recursive gradient estimation, which provably converges to the Nash equilibrium while attaining sublinear regret for each individual player. Our algorithm simultaneously achieves a Nash regret and a regret bound of $O(T^{4/5})$ for potential games, which matches the best available result, without using additional projection steps. Through carefully balancing the reuse of past samples and exploration of new samples, we then extend the results to Markov potential games and improve the best available Nash regret from $O(T^{5/6})$ to $O(T^{4/5})$. Moreover, our algorithm requires no knowledge of the game, such as the distribution mismatch coefficient, which provides more flexibility in its practical implementation. Experimental results corroborate our theoretical findings and underscore the practical effectiveness of our method",
    "checked": true,
    "id": "a4b24c6600d683c682cc8fbc1c38b3fbba0fdd78",
    "semantic_title": "convergence to nash equilibrium and no-regret guarantee in (markov) potential games",
    "citation_count": 0,
    "authors": [
      "Jing Dong",
      "Baoxiang Wang",
      "Yaoliang Yu"
    ]
  },
  "https://proceedings.mlr.press/v238/andrew24a.html": {
    "title": "GmGM: a fast multi-axis Gaussian graphical model",
    "volume": "main",
    "abstract": "This paper introduces the Gaussian multi-Graphical Model, a model to construct sparse graph representations of matrix- and tensor-variate data. We generalize prior work in this area by simultaneously learning this representation across several tensors that share axes, which is necessary to allow the analysis of multimodal datasets such as those encountered in multi-omics. Our algorithm uses only a single eigendecomposition per axis, achieving an order of magnitude speedup over prior work in the ungeneralized case. This allows the use of our methodology on large multi-modal datasets such as single-cell multi-omics data, which was challenging with previous approaches. We validate our model on synthetic data and five real-world datasets",
    "checked": true,
    "id": "2798a83f6be9a9aecee3c93f2ad20b489c40a637",
    "semantic_title": "gmgm: a fast multi-axis gaussian graphical model",
    "citation_count": 0,
    "authors": [
      "Ethan B. Andrew",
      "David Westhead",
      "Luisa Cutillo"
    ]
  },
  "https://proceedings.mlr.press/v238/ting-li24a.html": {
    "title": "On Convergence in Wasserstein Distance and f-divergence Minimization Problems",
    "volume": "main",
    "abstract": "The zero-sum game in generative adversarial networks (GANs) for learning the distribution of observed data is known to reduce to the minimization of a divergence measure between the underlying and generative models. However, the current theoretical understanding of the role of the target divergence in the characteristics of GANs' generated samples remains largely inadequate. In this work, we aim to analyze the influence of the divergence measure on the local optima and convergence properties of divergence minimization problems in learning a multi-modal data distribution. We show a mode-seeking f-divergence, e.g. the Jensen-Shannon (JS) divergence in the vanilla GAN, could lead to poor locally optimal solutions missing some underlying modes. On the other hand, we demonstrate that the optimization landscape of 1-Wasserstein distance in Wasserstein GANs does not suffer from such suboptimal local minima. Furthermore, we prove that a randomly-initialized gradient-based optimization of the Wasserstein distance will, with high probability, capture all the existing modes. We present numerical results on standard image datasets, revealing the success of Wasserstein GANs compared to JS-GANs in avoiding suboptimal local optima under a mixture model",
    "checked": true,
    "id": "cf5c5befd0e14809a54a749727b3c150784ba48b",
    "semantic_title": "on convergence in wasserstein distance and f-divergence minimization problems",
    "citation_count": 1,
    "authors": [
      "Cheuk Ting Li",
      "Jingwei Zhang",
      "Farzan Farnia"
    ]
  },
  "https://proceedings.mlr.press/v238/sun24b.html": {
    "title": "Sparse and Faithful Explanations Without Sparse Models",
    "volume": "main",
    "abstract": "Even if a model is not globally sparse, it is possible for decisions made from that model to be accurately and faithfully described by a small number of features. For instance, an application for a large loan might be denied to someone because they have no credit history, which overwhelms any evidence towards their creditworthiness. In this work, we introduce the Sparse Explanation Value (SEV), a new way of measuring sparsity in machine learning models. In the loan denial example above, the SEV is 1 because only one factor is needed to explain why the loan was denied. SEV is a measure of decision sparsity rather than overall model sparsity, and we are able to show that many machine learning models – even if they are not sparse – actually have low decision sparsity, as measured by SEV. SEV is defined using movements over a hypercube, allowing SEV to be defined consistently over various model classes, with movement restrictions reflecting real-world constraints. Our algorithms reduce SEV without sacrificing accuracy, providing sparse and completely faithful explanations, even without globally sparse models",
    "checked": true,
    "id": "94a6475fb90e7a2accdbfe9c597c1ce0bc3264e8",
    "semantic_title": "sparse and faithful explanations without sparse models",
    "citation_count": 1,
    "authors": [
      "Yiyang Sun",
      "Zhi Chen",
      "Vittorio Orlandi",
      "Tong Wang",
      "Cynthia Rudin"
    ]
  },
  "https://proceedings.mlr.press/v238/hu24c.html": {
    "title": "Extragradient Type Methods for Riemannian Variational Inequality Problems",
    "volume": "main",
    "abstract": "In this work, we consider monotone Riemannian Variational Inequality Problems (RVIPs), which encompass both Riemannian convex optimization and minimax optimization as particular cases. In Euclidean space, the last-iterates of both the extragradient (EG) and past extragradient (PEG) methods converge to the solution of monotone variational inequality problems at a rate of $O\\left(\\frac{1}{\\sqrt{T}}\\right)$ (Cai et al., 2022). However, analogous behavior on Riemannian manifolds remains open. To bridge this gap, we introduce the Riemannian extragradient (REG) and Riemannian past extragradient (RPEG) methods. We demonstrate that both exhibit $O\\left(\\frac{1}{\\sqrt{T}}\\right)$ last-iterate convergence and $O\\left(\\frac{1}{{T}}\\right)$ average-iterate convergence, aligning with observations in the Euclidean case. These results are enabled by judiciously addressing the holonomy effect so that additional complications in Riemannian cases can be reduced and the Euclidean proof inspired by the performance estimation problem (PEP) technique or the sum-of-squares (SOS) technique can be applied again",
    "checked": true,
    "id": "cc9510a1cba046ee46c70ee0085adc02d80642cb",
    "semantic_title": "extragradient type methods for riemannian variational inequality problems",
    "citation_count": 3,
    "authors": [
      "Zihao Hu",
      "Guanghui Wang",
      "Xi Wang",
      "Andre Wibisono",
      "Jacob D Abernethy",
      "Molei Tao"
    ]
  },
  "https://proceedings.mlr.press/v238/velychko24a.html": {
    "title": "Learning Sparse Codes with Entropy-Based ELBOs",
    "volume": "main",
    "abstract": "Standard probabilistic sparse coding assumes a Laplace prior, a linear mapping from latents to observables, and Gaussian observable distributions. We here derive a solely entropy-based learning objective for the parameters of standard sparse coding. The novel variational objective has the following features: (A) unlike MAP approximations, it uses non-trivial posterior approximations for probabilistic inference; (B) the novel objective is fully analytic; and (C) the objective allows for a novel principled form of annealing. The objective is derived by first showing that the standard ELBO objective converges to a sum of entropies, which matches similar recent results for generative models with Gaussian priors. The conditions under which the ELBO becomes equal to entropies are then shown to have analytic solutions, which leads to the fully analytic objective. Numerical experiments are used to demonstrate the feasibility of learning with such entropy-based ELBOs. We investigate different posterior approximations including Gaussians with correlated latents and deep amortized approximations. Furthermore, we numerically investigate entropy-based annealing which results in improved learning. Our main contributions are theoretical, however, and they are twofold: (1) we provide the first demonstration on how a recently shown convergence of the ELBO to entropy sums can be used for learning; and (2) using the entropy objective, we derive a fully analytic ELBO objective for the standard sparse coding generative model",
    "checked": true,
    "id": "87aee17642283a229c398dc388ff006db9860d31",
    "semantic_title": "learning sparse codes with entropy-based elbos",
    "citation_count": 1,
    "authors": [
      "Dmytro Velychko",
      "Simon Damm",
      "Asja Fischer",
      "Jörg Lücke"
    ]
  },
  "https://proceedings.mlr.press/v238/zuo24a.html": {
    "title": "Near Optimal Adversarial Attacks on Stochastic Bandits and Defenses with Smoothed Responses",
    "volume": "main",
    "abstract": "I study adversarial attacks against stochastic bandit algorithms. At each round, the learner chooses an arm, and a stochastic reward is generated. The adversary strategically adds corruption to the reward, and the learner is only able to observe the corrupted reward at each round. Two sets of results are presented in this paper. The first set studies the optimal attack strategies for the adversary. The adversary has a target arm he wishes to promote, and his goal is to manipulate the learner into choosing this target arm $T - o(T)$ times. I design attack strategies against UCB and Thompson Sampling that only spends $\\widehat{O}(\\sqrt{\\log T})$ cost. Matching lower bounds are presented, and the vulnerability of UCB, Thompson sampling and $\\varepsilon$-greedy are exactly characterized. The second set studies how the learner can defend against the adversary. Inspired by literature on smoothed analysis and behavioral economics, I present two simple algorithms that achieve a competitive ratio arbitrarily close to 1",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiliang Zuo"
    ]
  },
  "https://proceedings.mlr.press/v238/mauri24a.html": {
    "title": "Robust Approximate Sampling via Stochastic Gradient Barker Dynamics",
    "volume": "main",
    "abstract": "Stochastic Gradient (SG) Markov Chain Monte Carlo algorithms (MCMC) are popular algorithms for Bayesian sampling in the presence of large datasets. However, they come with little theoretical guarantees and assessing their empirical performances is non-trivial. In such context, it is crucial to develop algorithms that are robust to the choice of hyperparameters and to gradients heterogeneity since, in practice, both the choice of step-size and behaviour of target gradients induce hard-to-control biases in the invariant distribution. In this work we introduce the stochastic gradient Barker dynamics (SGBD) algorithm, extending the recently developed Barker MCMC scheme, a robust alternative to Langevin-based sampling algorithms, to the stochastic gradient framework. We characterize the impact of stochastic gradients on the Barker transition mechanism and develop a bias-corrected version that, under suitable assumptions, eliminates the error due to the gradient noise in the proposal. We illustrate the performance on a number of high-dimensional examples, showing that SGBD is more robust to hyperparameter tuning and to irregular behavior of the target gradients compared to the popular stochastic gradient Langevin dynamics algorithm",
    "checked": true,
    "id": "4b405b9b3a957affcb22625d7138e76daff3b05e",
    "semantic_title": "robust approximate sampling via stochastic gradient barker dynamics",
    "citation_count": 2,
    "authors": [
      "Lorenzo Mauri",
      "Giacomo Zanella"
    ]
  },
  "https://proceedings.mlr.press/v238/tang24b.html": {
    "title": "Solving General Noisy Inverse Problem via Posterior Sampling: A Policy Gradient Viewpoint",
    "volume": "main",
    "abstract": "Solving image inverse problems (e.g., super-resolution and inpainting) requires generating a high fidelity image that matches the given input (the low-resolution image or the masked image). By using the input image as guidance, we can leverage a pretrained diffusion generative model to solve a wide range of image inverse tasks without task specific model fine-tuning. To precisely estimate the guidance score function of the input image, we propose Diffusion Policy Gradient (DPG), a tractable computation method by viewing the intermediate noisy images as policies and the target image as the states selected by the policy. Experiments show that our method is robust to both Gaussian and Poisson noise degradation on multiple linear and non-linear inverse tasks, resulting into a higher image restoration quality on FFHQ, ImageNet and LSUN datasets",
    "checked": true,
    "id": "b19fdfa2d46f1a515705e3a15eb641930587b6a6",
    "semantic_title": "solving general noisy inverse problem via posterior sampling: a policy gradient viewpoint",
    "citation_count": 0,
    "authors": [
      "Haoyue Tang",
      "Tian Xie",
      "Aosong Feng",
      "Hanyu Wang",
      "Chenyang Zhang",
      "Yang Bai"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24c.html": {
    "title": "Enhancing Distributional Stability among Sub-populations",
    "volume": "main",
    "abstract": "Enhancing the stability of machine learning algorithms under distributional shifts is at the heart of the Out-of-Distribution (OOD) Generalization problem. Derived from causal learning, recent works of invariant learning pursue strict invariance with multiple training environments. Although intuitively reasonable, strong assumptions on the availability and quality of environments are made to learn the strict invariance property. In this work, we come up with the \"distributional stability\" notion to mitigate such limitations. It quantifies the stability of prediction mechanisms among sub-populations down to a prescribed scale. Based on this, we propose the learnability assumption and derive the generalization error bound under distribution shifts. Inspired by theoretical analyses, we propose our novel stable risk minimization (SRM) algorithm to enhance the model's stability w.r.t. shifts in prediction mechanisms (Y|X-shifts). Experimental results are consistent with our intuition and validate the effectiveness of our algorithm. The code can be found at https://github.com/LJSthu/SRM",
    "checked": true,
    "id": "3497ee17782e00f65410c30c4eb763545e01ae83",
    "semantic_title": "enhancing distributional stability among sub-populations",
    "citation_count": 1,
    "authors": [
      "Jiashuo Liu",
      "Jiayun Wu",
      "Jie Peng",
      "Xiaoyu Wu",
      "Yang Zheng",
      "Bo Li",
      "Peng Cui"
    ]
  },
  "https://proceedings.mlr.press/v238/parikh24a.html": {
    "title": "Safe and Interpretable Estimation of Optimal Treatment Regimes",
    "volume": "main",
    "abstract": "Recent advancements in statistical and reinforcement learning methods have contributed to superior patient care strategies. However, these methods face substantial challenges in high-stakes contexts, including missing data, stochasticity, and the need for interpretability and patient safety. Our work operationalizes a safe and interpretable approach for optimizing treatment regimes by matching patients with similar medical and pharmacological profiles. This allows us to construct optimal policies via interpolation. Our comprehensive simulation study demonstrates our method's effectiveness in complex scenarios. We use this approach to study seizure treatment in critically ill patients, advocating for personalized strategies based on medical history and pharmacological features. Our findings recommend reducing medication doses for mild, brief seizure episodes and adopting aggressive treatment strategies for severe cases, leading to improved outcomes",
    "checked": true,
    "id": "f7c43ccd2511d215e947f0369472514d2ee592f9",
    "semantic_title": "safe and interpretable estimation of optimal treatment regimes",
    "citation_count": 0,
    "authors": [
      "Harsh Parikh",
      "Quinn M Lanners",
      "Zade Akras",
      "Sahar Zafar",
      "M Brandon Westover",
      "Cynthia Rudin",
      "Alexander Volfovsky"
    ]
  },
  "https://proceedings.mlr.press/v238/gala24a.html": {
    "title": "Probabilistic Integral Circuits",
    "volume": "main",
    "abstract": "Continuous latent variables (LVs) are a key ingredient of many generative models, as they allow modelling expressive mixtures with an uncountable number of components. In contrast, probabilistic circuits (PCs) are hierarchical discrete mixtures represented as computational graphs composed of input, sum and product units. Unlike continuous LV models, PCs provide tractable inference but are limited to discrete LVs with categorical (i.e. unordered) states. We bridge these model classes by introducing probabilistic integral circuits (PICs), a new language of computational graphs that extends PCs with integral units representing continuous LVs. In the first place, PICs are symbolic computational graphs and are fully tractable in simple cases where analytical integration is possible. In practice, we parameterise PICs with light-weight neural nets delivering an intractable hierarchical continuous mixture that can be approximated arbitrarily well with large PCs using numerical quadrature. On several distribution estimation benchmarks, we show that such PIC-approximating PCs systematically outperform PCs commonly learned via expectation-maximization or SGD",
    "checked": true,
    "id": "9b2c07bb23db7f6258278e43a6ca1c1e33a5dc9d",
    "semantic_title": "probabilistic integral circuits",
    "citation_count": 2,
    "authors": [
      "Gennaro Gala",
      "Cassio de Campos",
      "Robert Peharz",
      "Antonio Vergari",
      "Erik Quaeghebeur"
    ]
  },
  "https://proceedings.mlr.press/v238/bernasconi24a.html": {
    "title": "Learning Extensive-Form Perfect Equilibria in Two-Player Zero-Sum Sequential Games",
    "volume": "main",
    "abstract": "Designing efficient algorithms for computing refinements of the Nash equilibrium (NE) in two-player zero-sum sequential games is of paramount importance, since the NE may prescribe sub-optimal actions off the equilibrium path. The extensive-form perfect equilibrium (EFPE) amends such a weakness by accounting for the possibility that players may make mistakes. This is crucial in the real world, which involves humans with bounded rationality, and it is also key in boosting superhuman agents for games like Poker. Nevertheless, there are only few algorithms for computing NE refinements, which either lack convergence guarantees to exact equilibria or do not scale to large games. We provide the first efficient iterative algorithm that provably converges to an EFPE in two-player zero-sum sequential games. Our algorithm works by tracking a sequence of equilibria of regularized-perturbed games, by using a procedure that is specifically tailored to converge last iterate to such equilibria. The procedure can be implemented efficiently by visiting the game tree, making our method computationally appealing. We also empirically evaluate our algorithm, showing that its strategies are much more robust to players' mistakes than those of state-of-the-art algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martino Bernasconi",
      "Alberto Marchesi",
      "Francesco Trovò"
    ]
  },
  "https://proceedings.mlr.press/v238/szlendak24a.html": {
    "title": "Understanding Progressive Training Through the Framework of Randomized Coordinate Descent",
    "volume": "main",
    "abstract": "We propose a Randomized Progressive Training algorithm (RPT)—a stochastic proxy for the well-known Progressive Training method (PT) (Karras et al., 2017). Originally designed to train GANs (Goodfellow et al., 2014), PT was proposed as a heuristic, with no convergence analysis even for the simplest objective functions. On the contrary, to the best of our knowledge, RPT is the first PT-type algorithm with rigorous and sound theoretical guarantees for general smooth objective functions. We cast our method into the established framework of Randomized Coordinate Descent (RCD) (Nesterov, 2012; Richtarik & Takac, 2014), for which (as a by-product of our investigations) we also propose a novel, simple and general convergence analysis encapsulating strongly-convex, convex and nonconvex objectives. We then use this framework to establish a convergence theory for RPT. Finally, we validate the effectiveness of our method through extensive computational experiments",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rafał Szlendak",
      "Elnur Gasanov",
      "Peter Richtarik"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24e.html": {
    "title": "Multiclass Learning from Noisy Labels for Non-decomposable Performance Measures",
    "volume": "main",
    "abstract": "There has been much interest in recent years in learning good classifiers from data with noisy labels. Most work on learning from noisy labels has focused on standard loss-based performance measures. However, many machine learning problems require using non-decomposable performance measures which cannot be expressed as the expectation or sum of a loss on individual examples; these include for example the H-mean, Q-mean and G-mean in class imbalance settings, and the Micro F1 in information retrieval. In this paper, we design algorithms to learn from noisy labels for two broad classes of multiclass non-decomposable performance measures, namely, monotonic convex and ratio-of-linear, which encompass all the above examples. Our work builds on the Frank-Wolfe and Bisection based methods of Narasimhan et al. (2015). In both cases, we develop noise-corrected versions of the algorithms under the widely studied family of class-conditional noise models. We provide regret (excess risk) bounds for our algorithms, establishing that even though they are trained on noisy data, they are Bayes consistent in the sense that their performance converges to the optimal performance w.r.t. the clean (non-noisy) distribution. Our experiments demonstrate the effectiveness of our algorithms in handling label noise",
    "checked": true,
    "id": "2baaf138e2b950e25782c431f82e6bb401913a73",
    "semantic_title": "multiclass learning from noisy labels for non-decomposable performance measures",
    "citation_count": 0,
    "authors": [
      "Mingyuan Zhang",
      "Shivani Agarwal"
    ]
  },
  "https://proceedings.mlr.press/v238/zhou24a.html": {
    "title": "On the Theoretical Expressive Power and the Design Space of Higher-Order Graph Transformers",
    "volume": "main",
    "abstract": "Graph transformers have recently received significant attention in graph learning, partly due to their ability to capture more global interaction via self-attention. Nevertheless, while higher-order graph neural networks have been reasonably well studied, the exploration of extending graph transformers to higher-order variants is just starting. Both theoretical understanding and empirical results are limited. In this paper, we provide a systematic study of the theoretical expressive power of order-$k$ graph transformers and sparse variants. We first show that, an order-$k$ graph transformer without additional structural information is less expressive than the $k$-Weisfeiler Lehman ($k$-WL) test despite its high computational cost. We then explore strategies to both sparsify and enhance the higher-order graph transformers, aiming to improve both their efficiency and expressiveness. Indeed, sparsification based on neighborhood information can enhance the expressive power, as it provides additional information about input graph structures. In particular, we show that a natural neighborhood-based sparse order-$k$ transformer model is not only computationally efficient, but also expressive – as expressive as $k$-WL test. We further study several other sparse graph attention models that are computationally efficient and provide their expressiveness analysis. Finally, we provide experimental results to show the effectiveness of the different sparsification strategies",
    "checked": true,
    "id": "eefa2776da90490b266ea017b62edf5541906996",
    "semantic_title": "on the theoretical expressive power and the design space of higher-order graph transformers",
    "citation_count": 2,
    "authors": [
      "Cai Zhou",
      "Rose Yu",
      "Yusu Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/janzing24a.html": {
    "title": "Quantifying intrinsic causal contributions via structure preserving interventions",
    "volume": "main",
    "abstract": "We propose a notion of causal influence that describes the ‘intrinsic' part of the contribution of a node on a target node in a DAG. By recursively writing each node as a function of the upstream noise terms, we separate the intrinsic information added by each node from the one obtained from its ancestors. To interpret the intrinsic information as a causal contribution, we consider ‘structure-preserving interventions' that randomize each node in a way that mimics the usual dependence on the parents and does not perturb the observed joint distribution. To get a measure that is invariant across arbitrary orderings of nodes we use Shapley based symmetrization and show that it reduces in the linear case to simple ANOVA after resolving the target node into noise variables. We describe our contribution analysis for variance and entropy, but contributions for other target metrics can be defined analogously",
    "checked": false,
    "id": "ae8b0784dfa3d4ecceb7e22f9ecdfbacdc9cb310",
    "semantic_title": "contributions of sub-community based on short and long-range white matter tracts in personalized age-associated neurocompensatory mechanism",
    "citation_count": 0,
    "authors": [
      "Dominik Janzing",
      "Patrick Blöbaum",
      "Atalanti A Mastakouri",
      "Philipp M Faller",
      "Lenon Minorics",
      "Kailash Budhathoki"
    ]
  },
  "https://proceedings.mlr.press/v238/draxler24a.html": {
    "title": "Free-form Flows: Make Any Architecture a Normalizing Flow",
    "volume": "main",
    "abstract": "Normalizing Flows are generative models that directly maximize the likelihood. Previously, the design of normalizing flows was largely constrained by the need for analytical invertibility. We overcome this constraint by a training procedure that uses an efficient estimator for the gradient of the change of variables formula. This enables any dimension-preserving neural network to serve as a generative model through maximum likelihood training. Our approach allows placing the emphasis on tailoring inductive biases precisely to the task at hand. Specifically, we achieve excellent results in molecule generation benchmarks utilizing E(n)-equivariant networks at greatly improved sampling speed. Moreover, our method is competitive in an inverse problem benchmark, while employing off-the-shelf ResNet architectures. We publish our code at https://github.com/vislearn/FFF",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felix Draxler",
      "Peter Sorrenson",
      "Lea Zimmermann",
      "Armand Rousselot",
      "Ullrich Köthe"
    ]
  },
  "https://proceedings.mlr.press/v238/moreno24a.html": {
    "title": "Efficient Model-Based Concave Utility Reinforcement Learning through Greedy Mirror Descent",
    "volume": "main",
    "abstract": "Many machine learning tasks can be solved by minimizing a convex function of an occupancy measure over the policies that generate them. These include reinforcement learning, imitation learning, among others. This more general paradigm is called the Concave Utility Reinforcement Learning problem (CURL). Since CURL invalidates classical Bellman equations, it requires new algorithms. We introduce MD-CURL, a new algorithm for CURL in a finite horizon Markov decision process. MD-CURL is inspired by mirror descent and uses a non-standard regularization to achieve convergence guarantees and a simple closed-form solution, eliminating the need for computationally expensive projection steps typically found in mirror descent approaches. We then extend CURL to an online learning scenario and present Greedy MD-CURL, a new method adapting MD-CURL to an online, episode-based setting with partially unknown dynamics. Like MD-CURL, the online version Greedy MD-CURL benefits from low computational complexity, while guaranteeing sub-linear or even logarithmic regret, depending on the level of information available on the underlying dynamics",
    "checked": true,
    "id": "e07c5534b00608599515ac41c9750071a0735470",
    "semantic_title": "efficient model-based concave utility reinforcement learning through greedy mirror descent",
    "citation_count": 2,
    "authors": [
      "Bianca M. Moreno",
      "Margaux Bregere",
      "Pierre Gaillard",
      "Nadia Oudjane"
    ]
  },
  "https://proceedings.mlr.press/v238/guo24b.html": {
    "title": "Online learning in bandits with predicted context",
    "volume": "main",
    "abstract": "We consider the contextual bandit problem where at each time, the agent only has access to a noisy version of the context and the error variance (or an estimator of this variance). This setting is motivated by a wide range of applications where the true context for decision-making is unobserved, and only a prediction of the context by a potentially complex machine learning algorithm is available. When the context error is non-vanishing, classical bandit algorithms fail to achieve sublinear regret. We propose the first online algorithm in this setting with sublinear regret guarantees under mild conditions. The key idea is to extend the measurement error model in classical statistics to the online decision-making setting, which is nontrivial due to the policy being dependent on the noisy context observations. We further demonstrate the benefits of the proposed approach in simulation environments based on synthetic and real digital intervention datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongyi Guo",
      "Ziping Xu",
      "Susan Murphy"
    ]
  },
  "https://proceedings.mlr.press/v238/so24a.html": {
    "title": "Optimising Distributions with Natural Gradient Surrogates",
    "volume": "main",
    "abstract": "Natural gradient methods have been used to optimise the parameters of probability distributions in a variety of settings, often resulting in fast-converging procedures. Unfortunately, for many distributions of interest, computing the natural gradient has a number of challenges. In this work we propose a novel technique for tackling such issues, which involves reframing the optimisation as one with respect to the parameters of a surrogate distribution, for which computing the natural gradient is easy. We give several examples of existing methods that can be interpreted as applying this technique, and propose a new method for applying it to a wide variety of problems. Our method expands the set of distributions that can be efficiently targeted with natural gradients. Furthermore, it is fast, easy to understand, simple to implement using standard autodiff software, and does not require lengthy model-specific derivations. We demonstrate our method on maximum likelihood estimation and variational inference tasks",
    "checked": true,
    "id": "a729caf3c2387dab019785c784ab0aa1ec3e82fb",
    "semantic_title": "optimising distributions with natural gradient surrogates",
    "citation_count": 1,
    "authors": [
      "Jonathan So",
      "Richard E. Turner"
    ]
  },
  "https://proceedings.mlr.press/v238/baker24a.html": {
    "title": "Monotone Operator Theory-Inspired Message Passing for Learning Long-Range Interaction on Graphs",
    "volume": "main",
    "abstract": "Learning long-range interactions (LRI) between distant nodes is crucial for many graph learning tasks. Predominant graph neural networks (GNNs) rely on local message passing and struggle to learn LRI. In this paper, we propose DRGNN to learn LRI leveraging monotone operator theory. DRGNN contains two key components: (1) we use a full node similarity matrix beyond adjacency matrix – drawing inspiration from the personalized PageRank matrix – as the aggregation matrix for message passing, and (2) we implement message-passing on graphs using Douglas-Rachford splitting to circumvent prohibitive matrix inversion. We demonstrate that DRGNN surpasses various advanced GNNs, including Transformer-based models, on several benchmark LRI learning tasks arising from different application domains, highlighting its efficacy in learning LRI. Code is available at \\url{https://github.com/Utah-Math-Data-Science/PR-inspired-aggregation}",
    "checked": true,
    "id": "0b70ada1dd20ec3b5d1b6012c919b98a16b0bf23",
    "semantic_title": "monotone operator theory-inspired message passing for learning long-range interaction on graphs",
    "citation_count": 0,
    "authors": [
      "Justin M. Baker",
      "Qingsong Wang",
      "Martin Berzins",
      "Thomas Strohmer",
      "Bao Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/ahmadi24a.html": {
    "title": "Agnostic Multi-Robust Learning using ERM",
    "volume": "main",
    "abstract": "A fundamental problem in robust learning is asymmetry: a learner needs to correctly classify every one of exponentially-many perturbations that an adversary might make to a test-time natural example. In contrast, the attacker only needs to find one successful perturbation. Xiang et al.[2022] proposed an algorithm that in the context of patch attacks for image classification, reduces the effective number of perturbations from an exponential to a polynomial number of perturbations and learns using an ERM oracle. However, to achieve its guarantee, their algorithm requires the natural examples to be robustly realizable. This prompts the natural question; can we extend their approach to the non-robustly-realizable case where there is no classifier with zero robust error? Our first contribution is to answer this question affirmatively by reducing this problem to a setting in which an algorithm proposed by Feige et al. [2015] can be applied, and in the process extend their guarantees. Next, we extend our results to a multi-group setting and introduce a novel agnostic multi-robust learning problem where the goal is to learn a predictor that achieves low robust loss on a (potentially) rich collection of subgroups",
    "checked": true,
    "id": "17d0cbaedfd82474da2c2b0e747370f5e0ce08f9",
    "semantic_title": "agnostic multi-robust learning using erm",
    "citation_count": 0,
    "authors": [
      "Saba Ahmadi",
      "Avrim Blum",
      "Omar Montasser",
      "Kevin M Stangl"
    ]
  },
  "https://proceedings.mlr.press/v238/dimlioglu24a.html": {
    "title": "GRAWA: Gradient-based Weighted Averaging for Distributed Training of Deep Learning Models",
    "volume": "main",
    "abstract": "We study distributed training of deep learning models in time-constrained environments. We propose a new algorithm that periodically pulls workers towards the center variable computed as a weighted average of workers, where the weights are inversely proportional to the gradient norms of the workers such that recovering the flat regions in the optimization landscape is prioritized. We develop two asynchronous variants of the proposed algorithm that we call Model-level and Layer-level Gradient-based Weighted Averaging (resp. MGRAWA and LGRAWA), which differ in terms of the weighting scheme that is either done with respect to the entire model or is applied layer-wise. On the theoretical front, we prove the convergence guarantee for the proposed approach in both convex and non-convex settings. We then experimentally demonstrate that our algorithms outperform the competitor methods by achieving faster convergence and recovering better quality and flatter local optima. We also carry out an ablation study to analyze the scalability of the proposed algorithms in more crowded distributed training environments. Finally, we report that our approach requires less frequent communication and fewer distributed updates compared to the state-of-the-art baselines",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tolga Dimlioglu",
      "Anna Choromanska"
    ]
  },
  "https://proceedings.mlr.press/v238/patil24a.html": {
    "title": "Failures and Successes of Cross-Validation for Early-Stopped Gradient Descent",
    "volume": "main",
    "abstract": "We analyze the statistical properties of generalized cross-validation (GCV) and leave-one-out cross-validation (LOOCV) applied to early-stopped gradient descent (GD) in high-dimensional least squares regression. We prove that GCV is generically inconsistent as an estimator of the prediction risk of early-stopped GD, even for a well-specified linear model with isotropic features. In contrast, we show that LOOCV converges uniformly along the GD trajectory to the prediction risk. Our theory requires only mild assumptions on the data distribution and does not require the underlying regression function to be linear. Furthermore, by leveraging the individual LOOCV errors, we construct consistent estimators for the entire prediction error distribution along the GD trajectory and consistent estimators for a wide class of error functionals. This in particular enables the construction of pathwise prediction intervals based on GD iterates that have asymptotically correct nominal coverage conditional on the training data",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pratik Patil",
      "Yuchen Wu",
      "Ryan Tibshirani"
    ]
  },
  "https://proceedings.mlr.press/v238/abroshan24a.html": {
    "title": "Imposing Fairness Constraints in Synthetic Data Generation",
    "volume": "main",
    "abstract": "In several real-world applications (e.g., online advertising, item recommendations, etc.) it may not be possible to release and share the real dataset due to privacy concerns. As a result, synthetic data generation (SDG) has emerged as a promising solution for data sharing. While the main goal of private SDG is to create a dataset that preserves the privacy of individuals contributing to the dataset, the use of synthetic data also creates an opportunity to improve fairness. Since there often exist historical biases in the datasets, using the original real data for training can lead to an unfair model. Using synthetic data, we can attempt to remove such biases from the dataset before releasing the data. In this work, we formalize the definition of fairness in synthetic data generation and provide a general framework to achieve fairness. Then we consider two notions of counterfactual fairness and information filtering fairness and show how our framework can be used for these definitions",
    "checked": true,
    "id": "986a72b393d803a705bc77b89d66b34fc6d37661",
    "semantic_title": "imposing fairness constraints in synthetic data generation",
    "citation_count": 0,
    "authors": [
      "Mahed Abroshan",
      "Andrew Elliott",
      "Mohammad Mahdi Khalili"
    ]
  },
  "https://proceedings.mlr.press/v238/choromanski24a.html": {
    "title": "Learning a Fourier Transform for Linear Relative Positional Encodings in Transformers",
    "volume": "main",
    "abstract": "We propose a new class of linear Transformers called FourierLearner-Transformers (FLTs), which incorporate a wide range of relative positional encoding mechanisms (RPEs). These include regular RPE techniques applied for sequential data, as well as novel RPEs operating on geometric data embedded in higher-dimensional Euclidean spaces. FLTs construct the optimal RPE mechanism implicitly by learning its spectral representation. As opposed to other architectures combining efficient low-rank linear attention with RPEs, FLTs remain practical in terms of their memory usage and do not require additional assumptions about the structure of the RPE mask. Besides, FLTs allow for applying certain structural inductive bias techniques to specify masking strategies, e.g. they provide a way to learn the so-called local RPEs introduced in this paper and give accuracy gains as compared with several other linear Transformers for language modeling. We also thoroughly test FLTs on other data modalities and tasks, such as image classification, 3D molecular modeling, and learnable optimizers. To the best of our knowledge, for 3D molecular data, FLTs are the first Transformer architectures providing linear attention and incorporating RPE masking",
    "checked": true,
    "id": "4ce987d4f8ae0f4680808c318980d42a82b9aa89",
    "semantic_title": "learning a fourier transform for linear relative positional encodings in transformers",
    "citation_count": 6,
    "authors": [
      "Krzysztof Choromanski",
      "Shanda Li",
      "Valerii Likhosherstov",
      "Kumar Avinava Dubey",
      "Shengjie Luo",
      "Di He",
      "Yiming Yang",
      "Tamas Sarlos",
      "Thomas Weingarten",
      "Adrian Weller"
    ]
  },
  "https://proceedings.mlr.press/v238/li24j.html": {
    "title": "Backward Filtering Forward Deciding in Linear Non-Gaussian State Space Models",
    "volume": "main",
    "abstract": "The paper considers linear state space models with non-Gaussian inputs and/or constraints. As shown previously, NUP representations (normal with unknown parameters) allow to compute MAP estimates in such models by iterating Kalman smoothing recursions. In this paper, we propose to compute such MAP estimates by iterating backward-forward recursions where the forward recursion amounts to coordinatewise input estimation. The advantages of the proposed approach include faster convergence, no \"zero-variance stucking\", and easier control of constraint satisfaction. The approach is demonstrated with simulation results of exemplary applications including (i) regression with non-Gaussian priors or constraints on k-th order differences and (ii) control with linearly constrained inputs",
    "checked": true,
    "id": "8284eac1d346f0c1c4e940203d68e3c0d2ac6334",
    "semantic_title": "backward filtering forward deciding in linear non-gaussian state space models",
    "citation_count": 0,
    "authors": [
      "Yun-Peng Li",
      "Hans-Andrea Loeliger"
    ]
  },
  "https://proceedings.mlr.press/v238/hoang-khoi-do24a.html": {
    "title": "MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization",
    "volume": "main",
    "abstract": "Multiplex influence maximization (MIM) asks us to identify a set of seed users such as to maximize the expected number of influenced users in a multiplex network. MIM has been one of central research topics, especially in nowadays social networking landscape where users participate in multiple online social networks (OSNs) and their influences can propagate among several OSNs simultaneously. Although there exist a couple combinatorial algorithms to MIM, learning-based solutions have been desired due to its generalization ability to heterogeneous networks and their diversified propagation characteristics. In this paper, we introduce MIM-Reasoner, coupling reinforcement learning with probabilistic graphical model, which effectively captures the complex propagation process within and between layers of a given multiplex network, thereby tackling the most challenging problem in MIM. We establish a theoretical guarantee for MIM-Reasoner as well as conduct extensive analyses on both synthetic and real-world datasets to validate our MIM-Reasoner's performance",
    "checked": true,
    "id": "7f274b59008a9b3e91e0dfa85f582d34ea8d08ab",
    "semantic_title": "mim-reasoner: learning with theoretical guarantees for multiplex influence maximization",
    "citation_count": 1,
    "authors": [
      "Nguyen Hoang Khoi Do",
      "Tanmoy Chowdhury",
      "Chen Ling",
      "Liang Zhao",
      "My T. Thai"
    ]
  },
  "https://proceedings.mlr.press/v238/kim24c.html": {
    "title": "A Doubly Robust Approach to Sparse Reinforcement Learning",
    "volume": "main",
    "abstract": "We propose a new regret minimization algorithm for episodic sparse linear Markov decision process (SMDP) where the state-transition distribution is a linear function of observed features. The only previously known algorithm for SMDP requires the knowledge of the sparsity parameter and oracle access to an unknown policy. We overcome these limitations by combining the doubly robust method that allows one to use feature vectors of \\emph{all} actions with a novel analysis technique that enables the algorithm to use data from all periods in all episodes. The regret of the proposed algorithm is $\\tilde{O}(\\sigma^{-1}_{\\min}s_{\\star} H \\sqrt{N})$, where $\\sigma_{\\min}$ denotes the restrictive the minimum eigenvalue of the average Gram matrix of feature vectors, $s_\\star$ is the sparsity parameter, $H$ is the length of an episode, and $N$ is the number of rounds. We provide a lower regret bound that matches the upper bound to logarithmic factors on a newly identified subclass of SMDPs. Our numerical experiments support our theoretical results and demonstrate the superior performance of our algorithm",
    "checked": true,
    "id": "2acad9a0c64c0e13b41b74408e5c389b5c400a49",
    "semantic_title": "a doubly robust approach to sparse reinforcement learning",
    "citation_count": 2,
    "authors": [
      "Wonyoung Kim",
      "Garud Iyengar",
      "Assaf Zeevi"
    ]
  },
  "https://proceedings.mlr.press/v238/varici24a.html": {
    "title": "General Identifiability and Achievability for Causal Representation Learning",
    "volume": "main",
    "abstract": "This paper focuses on causal representation learning (CRL) under a general nonparametric latent causal model and a general transformation model that maps the latent data to the observational data. It establishes identifiability and achievability results using two hard uncoupled interventions per node in the latent causal graph. Notably, one does not know which pair of intervention environments have the same node intervened (hence, uncoupled). For identifiability, the paper establishes that perfect recovery of the latent causal model and variables is guaranteed under uncoupled interventions. For achievability, an algorithm is designed that uses observational and interventional data and recovers the latent causal model and variables with provable guarantees. This algorithm leverages score variations across different environments to estimate the inverse of the transformer and, subsequently, the latent variables. The analysis, additionally, recovers the identifiability result for two hard coupled interventions, that is when metadata about the pair of environments that have the same node intervened is known. This paper also shows that when observational data is available, additional faithfulness assumptions that are adopted by the existing literature are unnecessary",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Burak Varici",
      "Emre Acartürk",
      "Karthikeyan Shanmugam",
      "Ali Tajer"
    ]
  },
  "https://proceedings.mlr.press/v238/pasteris24a.html": {
    "title": "Sum-max Submodular Bandits",
    "volume": "main",
    "abstract": "Many online decision-making problems correspond to maximizing a sequence of submodular functions. In this work, we introduce sum-max functions, a subclass of monotone submodular functions capturing several interesting problems, including best-of-$K$-bandits, combinatorial bandits, and the bandit versions on $M$-medians and hitting sets. We show that all functions in this class satisfy a key property that we call pseudo-concavity. This allows us to prove $\\big(1 - \\frac{1}{e}\\big)$-regret bounds for bandit feedback in the nonstochastic setting of the order of $\\sqrt{MKT}$ (ignoring log factors), where $T$ is the time horizon and $M$ is a cardinality constraint. This bound, attained by a simple and efficient algorithm, significantly improves on the $\\widetilde{\\mathcal{O}}\\big(T^{2/3}\\big)$ regret bound for online monotone submodular maximization with bandit feedback. We also extend our results to a bandit version of the facility location problem",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stephen U. Pasteris",
      "Alberto Rumi",
      "Fabio Vitale",
      "Nicolò Cesa-Bianchi"
    ]
  },
  "https://proceedings.mlr.press/v238/gruffaz24a.html": {
    "title": "Stochastic Approximation with Biased MCMC for Expectation Maximization",
    "volume": "main",
    "abstract": "The expectation maximization (EM) algorithm is a widespread method for empirical Bayesian inference, but its expectation step (E-step) is often intractable. Employing a stochastic approximation scheme with Markov chain Monte Carlo (MCMC) can circumvent this issue, resulting in an algorithm known as MCMC-SAEM. While theoretical guarantees for MCMC-SAEM have previously been established, these results are restricted to the case where asymptotically unbiased MCMC algorithms are used. In practice, MCMC-SAEM is often run with asymptotically biased MCMC, for which the consequences are theoretically less understood. In this work, we fill this gap by analyzing the asymptotics and non-asymptotics of SAEM with biased MCMC steps, particularly the effect of bias. We also provide numerical experiments comparing the Metropolis-adjusted Langevin algorithm (MALA), which is asymptotically unbiased, and the unadjusted Langevin algorithm (ULA), which is asymptotically biased, on synthetic and real datasets. Experimental results show that ULA is more stable with respect to the choice of Langevin stepsize and can sometimes result in faster convergence",
    "checked": true,
    "id": "f765e1a0b18b21b1534caeb7416909f107f78fb2",
    "semantic_title": "stochastic approximation with biased mcmc for expectation maximization",
    "citation_count": 2,
    "authors": [
      "Samuel Gruffaz",
      "Kyurae Kim",
      "Alain Durmus",
      "Jacob Gardner"
    ]
  },
  "https://proceedings.mlr.press/v238/reisizadeh24a.html": {
    "title": "EM for Mixture of Linear Regression with Clustered Data",
    "volume": "main",
    "abstract": "Modern data-driven and distributed learning frameworks deal with diverse massive data generated by clients spread across heterogeneous environments. Indeed, data heterogeneity is a major bottleneck in scaling up many distributed learning paradigms. In many settings however, heterogeneous data may be generated in clusters with shared structures, as is the case in several applications such as federated learning where a common latent variable governs the distribution of all the samples generated by a client. It is therefore natural to ask how the underlying clustered structures in distributed data can be exploited to improve learning schemes. In this paper, we tackle this question in the special case of estimating $d$-dimensional parameters of a two-component mixture of linear regressions problem where each of $m$ nodes generates $n$ samples with a shared latent variable. We employ the well-known Expectation-Maximization (EM) method to estimate the maximum likelihood parameters from m batches of dependent samples each containing n measurements. Discarding the clustered structure in the mixture model, EM is known to require $O(\\log(mn/d))$ iterations to reach the statistical accuracy of $O(\\sqrt{d/(mn)}$). In contrast, we show that if initialized properly, EM on the structured data requires only $O(1)$ iterations to reach the same statistical accuracy, as long as m grows up as $e^{o(n)}$. Our analysis establishes and combines novel asymptotic optimization and generalization guarantees for population and empirical EM with dependent samples, which may be of independent interest",
    "checked": true,
    "id": "ee8aa251ae5e7d1966868cc1b78164f514fd1b3c",
    "semantic_title": "em for mixture of linear regression with clustered data",
    "citation_count": 0,
    "authors": [
      "Amirhossein Reisizadeh",
      "Khashayar Gatmiry",
      "Asuman Ozdaglar"
    ]
  },
  "https://proceedings.mlr.press/v238/dvurechensky24a.html": {
    "title": "Analysis of Kernel Mirror Prox for Measure Optimization",
    "volume": "main",
    "abstract": "By choosing a suitable function space as the dual to the non-negative measure cone, we study in a unified framework a class of functional saddle-point optimization problems, which we term the Mixed Functional Nash Equilibrium (MFNE), that underlies several existing machine learning algorithms, such as implicit generative models, distributionally robust optimization (DRO), and Wasserstein barycenters. We model the saddle-point optimization dynamics as an interacting Fisher-Rao-RKHS gradient flow when the function space is chosen as a reproducing kernel Hilbert space (RKHS). As a discrete time counterpart, we propose a primal-dual kernel mirror prox (KMP) algorithm, which uses a dual step in the RKHS, and a primal entropic mirror prox step. We then provide a unified convergence analysis of KMP in an infinite-dimensional setting for this class of MFNE problems, which establishes a convergence rate of $O(1/N)$ in the deterministic case and $O(1/\\sqrt{N})$ in the stochastic case, where $N$ is the iteration counter. As a case study, we apply our analysis to DRO, providing algorithmic guarantees for DRO robustness and convergence",
    "checked": true,
    "id": "9cf2266d562622aeaaa9e02a2a396f67c12db969",
    "semantic_title": "analysis of kernel mirror prox for measure optimization",
    "citation_count": 1,
    "authors": [
      "Pavel Dvurechensky",
      "Jia-Jie Zhu"
    ]
  },
  "https://proceedings.mlr.press/v238/hariz24a.html": {
    "title": "Implicit Regularization in Deep Tucker Factorization: Low-Rankness via Structured Sparsity",
    "volume": "main",
    "abstract": "We theoretically analyze the implicit regularization of deep learning for tensor completion. We show that deep Tucker factorization trained by gradient descent induces a structured sparse regularization. This leads to a characterization of the effect of the depth of the neural network on the implicit regularization and provides a potential explanation for the bias of gradient descent towards solutions with low multilinear rank. Numerical experiments confirm our theoretical findings and give insights into the behavior of gradient descent in deep tensor factorization",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kais Hariz",
      "Hachem Kadri",
      "Stéphane Ayache",
      "Maher Moakher",
      "Thierry Artières"
    ]
  },
  "https://proceedings.mlr.press/v238/rizvi-martel24a.html": {
    "title": "Simulating weighted automata over sequences and trees with transformers",
    "volume": "main",
    "abstract": "Transformers are ubiquitous models in the natural language processing (NLP) community and have shown impressive empirical successes in the past few years. However, little is understood about how they reason and the limits of their computational capabilities. These models do not process data sequentially, and yet outperform sequential neural models such as RNNs. Recent work has shown that these models can compactly simulate the sequential reasoning abilities of deterministic finite automata (DFAs). This leads to the following question: can transformers simulate the reasoning of more complex finite state machines? In this work, we show that transformers can simulate weighted finite automata (WFAs), a class of models which subsumes DFAs, as well as weighted tree automata (WTA), a generalization of weighted automata to tree structured inputs. We prove these claims formally and provide upper bounds on the size of the transformer models needed as a function of the number of states of the target automata. Empirically, we perform synthetic experiments showing that transformers are able to learn these compact solutions via standard gradient-based training",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Rizvi-Martel",
      "Maude Lizaire",
      "Clara Lacroce",
      "Guillaume Rabusseau"
    ]
  },
  "https://proceedings.mlr.press/v238/auddy24a.html": {
    "title": "Approximate Leave-one-out Cross Validation for Regression with $\\ell_1$ Regularizers",
    "volume": "main",
    "abstract": "The out-of-sample error (OO) is the main quantity of interest in risk estimation and model selection. Leave-one-out cross validation (LO) offers a (nearly) distribution-free yet computationally demanding method to estimate OO. Recent theoretical work showed that approximate leave-one-out cross validation (ALO) is a computationally efficient and statistically reliable estimate of LO (and OO) for generalized linear models with twice differentiable regularizers. For problems involving non-differentiable regularizers, despite significant empirical evidence, the theoretical understanding of ALO's error remains unknown. In this paper, we present a novel theory for a wide class of problems in the generalized linear model family with the non-differentiable $\\ell_1$ regularizer. We bound the error \\(|{\\rm ALO}-{\\rm LO}|\\){in} terms of intuitive metrics such as the size of leave-\\(i\\)-out perturbations in active sets, sample size $n$, number of features $p$ and signal-to-noise ratio (SNR). As a consequence, for the $\\ell_1$ regularized problems, we show that $|{\\rm ALO}-{\\rm LO}| \\stackrel{p\\rightarrow \\infty}{\\longrightarrow} 0$ while $n/p$ and SNR remain bounded",
    "checked": false,
    "id": "51626f938bdf3f9ce7db5c094d853dcb0e4cd64e",
    "semantic_title": "approximate leave-one-out cross validation for regression with ℓ1 regularizers",
    "citation_count": 1,
    "authors": [
      "Arnab Auddy",
      "Haolin Zou",
      "Kamiar Rahnamarad",
      "Arian Maleki"
    ]
  },
  "https://proceedings.mlr.press/v238/lindner24a.html": {
    "title": "Learning Safety Constraints from Demonstrations with Unknown Rewards",
    "volume": "main",
    "abstract": "We propose Convex Constraint Learning for Reinforcement Learning (CoCoRL), a novel approach for inferring shared constraints in a Constrained Markov Decision Process (CMDP) from a set of safe demonstrations with possibly different reward functions. While previous work is limited to demonstrations with known rewards or fully known environment dynamics, CoCoRL can learn constraints from demonstrations with different unknown rewards without knowledge of the environment dynamics. CoCoRL constructs a convex safe set based on demonstrations, which provably guarantees safety even for potentially sub-optimal (but safe) demonstrations. For near-optimal demonstrations, CoCoRL converges to the true safe set with no policy regret. We evaluate CoCoRL in gridworld environments and a driving simulation with multiple constraints. CoCoRL learns constraints that lead to safe driving behavior. Importantly, we can safely transfer the learned constraints to different tasks and environments. In contrast, alternative methods based on Inverse Reinforcement Learning (IRL) often exhibit poor performance and learn unsafe policies",
    "checked": true,
    "id": "9e8a32813ba30ffb8691835ef6ec026d79d86138",
    "semantic_title": "learning safety constraints from demonstrations with unknown rewards",
    "citation_count": 7,
    "authors": [
      "David Lindner",
      "Xin Chen",
      "Sebastian Tschiatschek",
      "Katja Hofmann",
      "Andreas Krause"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24f.html": {
    "title": "Online Learning in Contextual Second-Price Pay-Per-Click Auctions",
    "volume": "main",
    "abstract": "We study online learning in contextual pay-per-click auctions where at each of the $T$ rounds, the learner receives some context along with a set of ads and needs to make an estimate on their click-through rate (CTR) in order to run a second-price pay-per-click auction. The learner's goal is to minimize her regret, defined as the gap between her total revenue and that of an oracle strategy that always makes perfect CTR predictions. We first show that $\\sqrt{T}$-regret is obtainable via a computationally inefficient algorithm and that it is unavoidable since our algorithm is no easier than the classical multi-armed bandit problem. A by-product of our results is a $\\sqrt{T}$-regret bound for the simpler non-contextual setting, improving upon a recent work of [Feng et al., 2023] by removing the inverse CTR dependency that could be arbitrarily large. Then, borrowing ideas from recent advances on efficient contextual bandit algorithms, we develop two practically efficient contextual auction algorithms: the first one uses the exponential weight scheme with optimistic square errors and maintains the same $\\sqrt{T}$-regret bound, while the second one reduces the problem to online regression via a simple epsilon-greedy strategy, albeit with a worse regret bound. Finally, we conduct experiments on a synthetic dataset to showcase the effectiveness and superior performance of our algorithms",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengxiao Zhang",
      "Haipeng Luo"
    ]
  },
  "https://proceedings.mlr.press/v238/fuentes24a.html": {
    "title": "Joint Selection: Adaptively Incorporating Public Information for Private Synthetic Data",
    "volume": "main",
    "abstract": "Mechanisms for generating differentially private synthetic data based on marginals and graphical models have been successful in a wide range of settings. However, one limitation of these methods is their inability to incorporate public data. Initializing a data generating model by pre-training on public data has shown to improve the quality of synthetic data, but this technique is not applicable when model structure is not determined a priori. We develop the mechanism JAM-PGM, which expands the adaptive measurements framework to jointly select between measuring public data and private data. This technique allows for public data to be included in a graphical-model-based mechanism. We show that JAM-PGM is able to outperform both publicly assisted and non publicly assisted synthetic data generation mechanisms even when the public data distribution is biased",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miguel Fuentes",
      "Brett C. Mullins",
      "Ryan McKenna",
      "Gerome Miklau",
      "Daniel Sheldon"
    ]
  },
  "https://proceedings.mlr.press/v238/long24a.html": {
    "title": "Equation Discovery with Bayesian Spike-and-Slab Priors and Efficient Kernels",
    "volume": "main",
    "abstract": "Discovering governing equations from data is important to many scientific and engineering applications. Despite promising successes, existing methods are still challenged by data sparsity and noise issues, both of which are ubiquitous in practice. Moreover, state-of-the-art methods lack uncertainty quantification and/or are costly in training. To overcome these limitations, we propose a novel equation discovery method based on Kernel learning and BAyesian Spike-and-Slab priors (KBASS). We use kernel regression to estimate the target function, which is flexible, expressive, and more robust to data sparsity and noises. We combine it with a Bayesian spike-and-slab prior — an ideal Bayesian sparse distribution — for effective operator selection and uncertainty quantification. We develop an expectation-propagation expectation-maximization (EP-EM) algorithm for efficient posterior inference and function estimation. To overcome the computational challenge of kernel regression, we place the function values on a mesh and induce a Kronecker product construction, and we use tensor algebra to enable efficient computation and optimization. We show the advantages of KBASS on a list of benchmark ODE and PDE discovery tasks. The code is available at \\url{https://github.com/long-da/KBASS}",
    "checked": true,
    "id": "609405f0a696426e876659356623f41dacb9feb5",
    "semantic_title": "equation discovery with bayesian spike-and-slab priors and efficient kernels",
    "citation_count": 0,
    "authors": [
      "Da Long",
      "Wei Xing",
      "Aditi Krishnapriyan",
      "Robert Kirby",
      "Shandian Zhe",
      "Michael W. Mahoney"
    ]
  },
  "https://proceedings.mlr.press/v238/mitchell-roddenberry24a.html": {
    "title": "An Impossibility Theorem for Node Embedding",
    "volume": "main",
    "abstract": "With the increasing popularity of graph-based methods for dimensionality reduction and representation learning, node embedding functions have become important objects of study in the literature. In this paper, we take an axiomatic approach to understanding node embedding methods. Motivated by desirable properties of node embeddings for encoding the role of a node in the structure of a network, we first state three properties for embedding dissimilarity networks. We then prove that no node embedding method can satisfy all three properties at once, reflecting fundamental difficulties inherent to the task. Having identified these difficulties, we show that mild relaxations of these axioms allow for certain node embedding methods to be admissible",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "T. Mitchell Roddenberry",
      "Yu Zhu",
      "Santiago Segarra"
    ]
  },
  "https://proceedings.mlr.press/v238/diluvi24a.html": {
    "title": "Mixed variational flows for discrete variables",
    "volume": "main",
    "abstract": "Variational flows allow practitioners to learn complex continuous distributions, but approximating discrete distributions remains a challenge. Current methodologies typically embed the discrete target in a continuous space—usually via continuous relaxation or dequantization—and then apply a continuous flow. These approaches involve a surrogate target that may not capture the original discrete target, might have biased or unstable gradients, and can create a difficult optimization problem. In this work, we develop a variational flow family for discrete distributions without any continuous embedding. First, we develop a measure-preserving and discrete (MAD) invertible map that leaves the discrete target invariant, and then create a mixed variational flow (MAD Mix) based on that map. Our family provides access to i.i.d. sampling and density evaluation with virtually no tuning effort. We also develop an extension to MAD Mix that handles joint discrete and continuous models. Our experiments suggest that MAD Mix produces more reliable approximations than continuous-embedding flows while requiring orders of magnitude less compute",
    "checked": true,
    "id": "83678d0dfdf174294f0c7b4101eb31f386e871b1",
    "semantic_title": "mixed variational flows for discrete variables",
    "citation_count": 0,
    "authors": [
      "Gian C. Diluvi",
      "Benjamin Bloem-Reddy",
      "Trevor Campbell"
    ]
  },
  "https://proceedings.mlr.press/v238/li24k.html": {
    "title": "Multi-Resolution Active Learning of Fourier Neural Operators",
    "volume": "main",
    "abstract": "Fourier Neural Operator (FNO) is a popular operator learning framework. It not only achieves the state-of-the-art performance in many tasks, but also is efficient in training and prediction. However, collecting training data for the FNO can be a costly bottleneck in practice, because it often demands expensive physical simulations. To overcome this problem, we propose Multi-Resolution Active Learning of FNO (MRA-FNO), which can dynamically select the input functions and resolutions to lower the data cost as much as possible while optimizing the learning efficiency. Specifically, we propose a probabilistic multi-resolution FNO and use ensemble Monte-Carlo to develop an effective posterior inference algorithm. To conduct active learning, we maximize a utility-cost ratio as the acquisition function to acquire new examples and resolutions at each step. We use moment matching and the matrix determinant lemma to enable tractable, efficient utility computation. Furthermore, we develop a cost annealing framework to avoid over-penalizing high-resolution queries at the early stage. The over-penalization is severe when the cost difference is significant between the resolutions, which renders active learning often stuck at low-resolution queries and inferior performance. Our method overcomes this problem and applies to general multi-fidelity active learning and optimization problems. We have shown the advantage of our method in several benchmark operator learning tasks. The code is available at https://github.com/shib0li/MRA-FNO",
    "checked": true,
    "id": "1753cae77e15c935b3587ef74a4150f567f23e08",
    "semantic_title": "multi-resolution active learning of fourier neural operators",
    "citation_count": 0,
    "authors": [
      "Shibo Li",
      "Xin Yu",
      "Wei Xing",
      "Robert Kirby",
      "Akil Narayan",
      "Shandian Zhe"
    ]
  },
  "https://proceedings.mlr.press/v238/grudzien24a.html": {
    "title": "Functional Graphical Models: Structure Enables Offline Data-Driven Optimization",
    "volume": "main",
    "abstract": "While machine learning models are typically trained to solve prediction problems, we might often want to use them for optimization problems. For example, given a dataset of proteins and their corresponding fluorescence levels, we might want to optimize for a new protein with the highest possible fluorescence. This kind of data-driven optimization (DDO) presents a range of challenges beyond those in standard prediction problems, since we need models that successfully predict the performance of new designs that are better than the best designs seen in the training set. It is not clear theoretically when existing approaches can even perform better than the na ïve approach that simply selects the best design in the dataset. In this paper, we study how structure can enable sample-efficient data-driven optimization. To formalize the notion of structure, we introduce functional graphical models (FGMs) and show theoretically how they can provide for principled data-driven optimization by decomposing the original high-dimensional optimization problem into smaller sub-problems. This allows us to derive much more practical regret bounds for DDO, and the result implies that DDO with FGMs can achieve nearly optimal designs in situations where naïve approaches fail due to insufficient coverage of the offline data. We further present a data-driven optimization algorithm that inferes the FGM structure itself, either over the original input variables or a latent variable representation of the inputs",
    "checked": true,
    "id": "f4bd3039087f8344c300abf59c310d9223f8ac88",
    "semantic_title": "functional graphical models: structure enables offline data-driven optimization",
    "citation_count": 1,
    "authors": [
      "Kuba Grudzien",
      "Masatoshi Uehara",
      "Sergey Levine",
      "Pieter Abbeel"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24c.html": {
    "title": "Federated Experiment Design under Distributed Differential Privacy",
    "volume": "main",
    "abstract": "Experiment design has a rich history dating back over a century and has found many critical applications across various fields since then. The use and collection of users' data in experiments often involve sensitive personal information, so additional measures to protect individual privacy are required during data collection, storage, and usage. In this work, we focus on the rigorous protection of users' privacy (under the notion of differential privacy (DP)) while minimizing the trust toward service providers. Specifically, we consider the estimation of the average treatment effect (ATE) under DP, while only allowing the analyst to collect population-level statistics via secure aggregation, a distributed protocol enabling a service provider to aggregate information without accessing individual data. Although a vital component in modern A/B testing workflows, private distributed experimentation has not previously been studied. To achieve DP, we design local privatization mechanisms that are compatible with secure aggregation and analyze the utility, in terms of the width of confidence intervals, both asymptotically and non-asymptotically. We show how these mechanisms can be scaled up to handle the very large number of participants commonly found in practice. In addition, when introducing DP noise, it is imperative to cleverly split privacy budgets to estimate both the mean and variance of the outcomes and carefully calibrate the confidence intervals according to the DP noise. Last, we present comprehensive experimental evaluations of our proposed schemes and show the privacy-utility trade-offs in experiment design",
    "checked": true,
    "id": "5e7c0f64a0f228362c69951c2157245ff227258d",
    "semantic_title": "federated experiment design under distributed differential privacy",
    "citation_count": 1,
    "authors": [
      "Wei-Ning Chen",
      "Graham Cormode",
      "Akash Bharadwaj",
      "Peter Romov",
      "Ayfer Ozgur"
    ]
  },
  "https://proceedings.mlr.press/v238/granese24a.html": {
    "title": "Optimal Zero-Shot Detector for Multi-Armed Attacks",
    "volume": "main",
    "abstract": "This research delves into a scenario where a malicious actor can manipulate data samples using a multi-armed attack strategy, providing them with multiple ways to introduce noise into the data sample. Our central objective is to protect the data by detecting any alterations to the input. We approach this defensive strategy with utmost caution, operating in an environment where the defender possesses significantly less information compared to the attacker. Specifically, the defender is unable to utilize any data samples for training a defense model or verifying the integrity of the channel. Instead, the defender relies exclusively on a set of pre-existing detectors readily available \"off the shelf.\" To tackle this challenge, we derive an innovative information-theoretic defense approach that optimally aggregates the decisions made by these detectors, eliminating the need for any training data. We further explore a practical use-case scenario for empirical evaluation, where the attacker possesses a pre-trained classifier and launches well-known adversarial attacks against it. Our experiments highlight the effectiveness of our proposed solution, even in scenarios that deviate from the optimal setup",
    "checked": true,
    "id": "924b0e5129d2da7c2d5ab5cf7546b23bd8fcb8e8",
    "semantic_title": "optimal zero-shot detector for multi-armed attacks",
    "citation_count": 0,
    "authors": [
      "Federica Granese",
      "Marco Romanelli",
      "Pablo Piantanida"
    ]
  },
  "https://proceedings.mlr.press/v238/kumar-krishnamurthy24a.html": {
    "title": "Towards Costless Model Selection in Contextual Bandits: A Bias-Variance Perspective",
    "volume": "main",
    "abstract": "Model selection in supervised learning provides costless guarantees as if the model that best balances bias and variance was known a priori. We study the feasibility of similar guarantees for cumulative regret minimization in the stochastic contextual bandit setting. Recent work [Marinov and Zimmert, 2021] identifies instances where no algorithm can guarantee costless regret bounds. Nevertheless, we identify benign conditions where costless model selection is feasible: gradually increasing class complexity, and diminishing marginal returns for best-in-class policy value with increasing class complexity. Our algorithm is based on a novel misspecification test, and our analysis demonstrates the benefits of using model selection for reward estimation. Unlike prior work on model selection in contextual bandits, our algorithm carefully adapts to the evolving bias-variance trade-off as more data is collected. In particular, our algorithm and analysis go beyond adapting to the complexity of the simplest realizable class and instead adapt to the complexity of the simplest class whose estimation variance dominates the bias. For short horizons, this provides improved regret guarantees that depend on the complexity of simpler classes",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanath Kumar Krishnamurthy",
      "Adrienne M Propp",
      "Susan Athey"
    ]
  },
  "https://proceedings.mlr.press/v238/patel24a.html": {
    "title": "Conformal Contextual Robust Optimization",
    "volume": "main",
    "abstract": "Data-driven approaches to predict-then-optimize decision-making problems seek to mitigate the risk of uncertainty region misspecification in safety-critical settings. Current approaches, however, suffer from considering overly conservative uncertainty regions, often resulting in suboptimal decision-making. To this end, we propose Conformal-Predict-Then-Optimize (CPO), a framework for leveraging highly informative, nonconvex conformal prediction regions over high-dimensional spaces based on conditional generative models, which have the desired distribution-free coverage guarantees. Despite guaranteeing robustness, such black-box optimization procedures alone inspire little confidence owing to the lack of explanation of why a particular decision was found to be optimal. We, therefore, augment CPO to additionally provide semantically meaningful visual summaries of the uncertainty regions to give qualitative intuition for the optimal decision. We highlight the CPO framework by demonstrating results on a suite of simulation-based inference benchmark tasks and a vehicle routing task based on probabilistic weather prediction",
    "checked": true,
    "id": "6c25d74b4bac304a097a6c49795273743923c065",
    "semantic_title": "conformal contextual robust optimization",
    "citation_count": 4,
    "authors": [
      "Yash P. Patel",
      "Sahana Rayan",
      "Ambuj Tewari"
    ]
  },
  "https://proceedings.mlr.press/v238/ren24a.html": {
    "title": "Learning Adaptive Kernels for Statistical Independence Tests",
    "volume": "main",
    "abstract": "We propose a novel framework for kernel-based statistical independence tests that enable adaptatively learning parameterized kernels to maximize test power. Our framework can effectively address the pitfall inherent in the existing signal-to-noise ratio criterion by modeling the change of the null distribution during the learning process. Based on the proposed framework, we design a new class of kernels that can adaptatively focus on the significant dimensions of variables to judge independence, which makes the tests more flexible than using simple kernels that are adaptive only in length-scale, and especially suitable for high-dimensional complex data. Theoretically, we demonstrate the consistency of our independence tests, and show that the non-convex objective function used for learning fits the L-smoothing condition, thus benefiting the optimization. Experimental results on both synthetic and real data show the superiority of our method. The source code and datasets are available at \\url{https://github.com/renyixin666/HSIC-LK.git}",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixin Ren",
      "Yewei Xia",
      "Hao Zhang",
      "Jihong Guan",
      "Shuigeng Zhou"
    ]
  },
  "https://proceedings.mlr.press/v238/abernethy24a.html": {
    "title": "Lexicographic Optimization: Algorithms and Stability",
    "volume": "main",
    "abstract": "A lexicographic maximum of a set $X \\subseteq R^n$ is a vector in $X$ whose smallest component is as large as possible, and subject to that requirement, whose second smallest component is as large as possible, and so on for the third smallest component, etc. Lexicographic maximization has numerous practical and theoretical applications, including fair resource allocation, analyzing the implicit regularization of learning algorithms, and characterizing refinements of game-theoretic equilibria. We prove that a minimizer in $X$ of the exponential loss function $L_c(x) = \\sum_i \\exp(-c x_i)$ converges to a lexicographic maximum of $X$ as $c \\to \\infty$, provided that $X$ is \\emph{stable} in the sense that a well-known iterative method for finding a lexicographic maximum of $X$ cannot be made to fail simply by reducing the required quality of each iterate by an arbitrarily tiny degree. Our result holds for both near and exact minimizers of the exponential loss, while earlier convergence results made much stronger assumptions about the set $X$ and only held for the exact minimizer. We are aware of no previous results showing a connection between the iterative method for computing a lexicographic maximum and exponential loss minimization. We show that every convex polytope is stable, but that there exist compact, convex sets that are not stable. We also provide the first analysis of the convergence rate of an exponential loss minimizer (near or exact) and discover a curious dichotomy: While the two smallest components of the vector converge to the lexicographically maximum values very quickly (at roughly the rate $\\frac{\\log n}{c}$), all other components can converge arbitrarily slowly",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacob A. Abernethy",
      "Robert Schapire",
      "Umar Syed"
    ]
  },
  "https://proceedings.mlr.press/v238/dai24b.html": {
    "title": "Can Probabilistic Feedback Drive User Impacts in Online Platforms?",
    "volume": "main",
    "abstract": "A common explanation for negative user impacts of content recommender systems is misalignment between the platform's objective and user welfare. In this work, we show that misalignment in the platform's objective is not the only potential cause of unintended impacts on users: even when the platform's objective is fully aligned with user welfare, the platform's learning algorithm can induce negative downstream impacts on users. The source of these user impacts is that different pieces of content may generate observable user reactions (feedback information) at different rates; these feedback rates may correlate with content properties, such as controversiality or demographic similarity of the creator, that affect the user experience. Since differences in feedback rates can impact how often the learning algorithm engages with different content, the learning algorithm may inadvertently promote content with certain such properties. Using the multi-armed bandit framework with probabilistic feedback, we examine the relationship between feedback rates and a learning algorithm's engagement with individual arms for different no-regret algorithms. We prove that no-regret algorithms can exhibit a wide range of dependencies: if the feedback rate of an arm increases, some no-regret algorithms engage with the arm more, some no-regret algorithms engage with the arm less, and other no-regret algorithms engage with the arm approximately the same number of times. From a platform design perspective, our results highlight the importance of looking beyond regret when measuring an algorithm's performance, and assessing the nature of a learning algorithm's engagement with different types of content as well as their resulting downstream impacts",
    "checked": true,
    "id": "b24dd8bcaf66991cfb4373aa02725014a48c863d",
    "semantic_title": "can probabilistic feedback drive user impacts in online platforms?",
    "citation_count": 1,
    "authors": [
      "Jessica Dai",
      "Bailey Flanigan",
      "Nika Haghtalab",
      "Meena Jagadeesan",
      "Chara Podimata"
    ]
  },
  "https://proceedings.mlr.press/v238/shi24a.html": {
    "title": "Learning Cartesian Product Graphs with Laplacian Constraints",
    "volume": "main",
    "abstract": "Graph Laplacian learning, also known as network topology inference, is a problem of great interest to multiple communities. In Gaussian graphical models (GM), graph learning amounts to endowing covariance selection with the Laplacian structure. In graph signal processing (GSP), it is essential to infer the unobserved graph from the outputs of a filtering system. In this paper, we study the problem of learning Cartesian product graphs under Laplacian constraints. The Cartesian graph product is a natural way for modeling higher-order conditional dependencies and is also the key for generalizing GSP to multi-way tensors. We establish statistical consistency for the penalized maximum likelihood estimation (MLE) of a Cartesian product Laplacian, and propose an efficient algorithm to solve the problem. We also extend our method for efficient joint graph learning and imputation in the presence of structural missing values. Experiments on synthetic and real-world datasets demonstrate that our method is superior to previous GSP and GM methods",
    "checked": true,
    "id": "12ee3cf9f2dd9168f224417d1efb616a200cdb9a",
    "semantic_title": "learning cartesian product graphs with laplacian constraints",
    "citation_count": 0,
    "authors": [
      "Changhao Shi",
      "Gal Mishne"
    ]
  },
  "https://proceedings.mlr.press/v238/yao24a.html": {
    "title": "Minimizing Convex Functionals over Space of Probability Measures via KL Divergence Gradient Flow",
    "volume": "main",
    "abstract": "Motivated by the computation of the non-parametric maximum likelihood estimator (NPMLE) and the Bayesian posterior in statistics, this paper explores the problem of convex optimization over the space of all probability distributions. We introduce an implicit scheme, called the implicit KL proximal descent (IKLPD) algorithm, for discretizing a continuous-time gradient flow relative to the Kullback–Leibler (KL) divergence for minimizing a convex target functional. We show that IKLPD converges to a global optimum at a polynomial rate from any initialization; moreover, if the objective functional is strongly convex relative to the KL divergence, for example, when the target functional itself is a KL divergence as in the context of Bayesian posterior computation, IKLPD exhibits globally exponential convergence. Computationally, we propose a numerical method based on normalizing flow to realize IKLPD. Conversely, our numerical method can also be viewed as a new approach that sequentially trains a normalizing flow for minimizing a convex functional with a strong theoretical guarantee",
    "checked": true,
    "id": "ea619465f306f93ebb596b6ce7390c965c2b4c07",
    "semantic_title": "minimizing convex functionals over space of probability measures via kl divergence gradient flow",
    "citation_count": 1,
    "authors": [
      "Rentian Yao",
      "Linjun Huang",
      "Yun Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/showalter24a.html": {
    "title": "Bayesian Online Learning for Consensus Prediction",
    "volume": "main",
    "abstract": "Given a pre-trained classifier and multiple human experts, we investigate the task of online classification where model predictions are provided for free but querying humans incurs a cost. In this practical but under-explored setting, oracle ground truth is not available. Instead, the prediction target is defined as the consensus vote of all experts. Given that querying full consensus can be costly, we propose a general framework for online Bayesian consensus estimation, leveraging properties of the multivariate hypergeometric distribution. Based on this framework, we propose a family of methods that dynamically estimate expert consensus from partial feedback by producing a posterior over expert and model beliefs. Analyzing this posterior induces an interpretable trade-off between querying cost and classification performance. We demonstrate the efficacy of our framework against a variety of baselines on CIFAR-10H and ImageNet-16H, two large-scale crowdsourced datasets",
    "checked": true,
    "id": "78d456cda93d472400b887daefa7351897b678d7",
    "semantic_title": "bayesian online learning for consensus prediction",
    "citation_count": 0,
    "authors": [
      "Samuel Showalter",
      "Alex J Boyd",
      "Padhraic Smyth",
      "Mark Steyvers"
    ]
  },
  "https://proceedings.mlr.press/v238/kone24a.html": {
    "title": "Bandit Pareto Set Identification: the Fixed Budget Setting",
    "volume": "main",
    "abstract": "We study a multi-objective pure exploration problem in a multi-armed bandit model. Each arm is associated to an unknown multi-variate distribution and the goal is to identify the distributions whose mean is not uniformly worse than that of another distribution: the Pareto optimal set. We propose and analyze the first algorithms for the \\emph{fixed budget} Pareto Set Identification task. We propose Empirical Gap Elimination, a family of algorithms combining a careful estimation of the \"hardness to classify\" each arm in or out of the Pareto set with a generic elimination scheme. We prove that two particular instances, EGE-SR and EGE-SH, have a probability of error that decays exponentially fast with the budget, with an exponent supported by an information theoretic lower-bound. We complement these findings with an empirical study using real-world and synthetic datasets, which showcase the good performance of our algorithms",
    "checked": true,
    "id": "2e6240e44fb5e6321b36790f00b9b89c3279fc88",
    "semantic_title": "bandit pareto set identification: the fixed budget setting",
    "citation_count": 1,
    "authors": [
      "Cyrille Kone",
      "Emilie Kaufmann",
      "Laura Richert"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24e.html": {
    "title": "Efficient Data Shapley for Weighted Nearest Neighbor Algorithms",
    "volume": "main",
    "abstract": "This work aims to address an open problem in data valuation literature concerning the efficient computation of Data Shapley for weighted $K$ nearest neighbor algorithm (WKNN-Shapley). By considering the accuracy of hard-label KNN with discretized weights as the utility function, we reframe the computation of WKNN-Shapley into a counting problem and introduce a quadratic-time algorithm, presenting a notable improvement from $O(N^K)$, the best result from existing literature. We develop a deterministic approximation algorithm that further improves computational efficiency while maintaining the key fairness properties of the Shapley value. Through extensive experiments, we demonstrate WKNN-Shapley's computational efficiency and its superior performance in discerning data quality compared to its unweighted counterpart",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiachen T. Wang",
      "Prateek Mittal",
      "Ruoxi Jia"
    ]
  },
  "https://proceedings.mlr.press/v238/hsiao24a.html": {
    "title": "Surrogate Bayesian Networks for Approximating Evolutionary Games",
    "volume": "main",
    "abstract": "Spatial evolutionary games are used to model large systems of interacting agents. In earlier work, a method was developed using Bayesian Networks to approximate the population dynamics in these games. One of the advantages of the Bayesian Network modeling approach is that it is possible to smoothly adjust the size of the network to get more accurate approximations. However, scaling the method up can be intractable if the number of strategies in the evolutionary game increases. In this paper, we propose a new method for computing more accurate approximations by using surrogate Bayesian Networks. Instead of computing inference on larger networks directly, we perform inference on a much smaller surrogate network extended with parameters that exploit the symmetry inherent to the domain. We learn the parameters on the surrogate network using KL-divergence as the loss function. We illustrate the value of this method empirically through a comparison on several evolutionary games",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Hsiao",
      "Dana S Nau",
      "Bobak Pezeshki",
      "Rina Dechter"
    ]
  },
  "https://proceedings.mlr.press/v238/ramos24a.html": {
    "title": "BlockBoost: Scalable and Efficient Blocking through Boosting",
    "volume": "main",
    "abstract": "As datasets grow larger, matching and merging entries from different databases has become a costly task in modern data pipelines. To avoid expensive comparisons between entries, blocking similar items is a popular preprocessing step. In this paper, we introduce BlockBoost, a novel boosting-based method that generates compact binary hash codes for database entries, through which blocking can be performed efficiently. The algorithm is fast and scalable, resulting in computational costs that are orders of magnitude lower than current benchmarks. Unlike existing alternatives, BlockBoost comes with associated feature importance measures for interpretability, and possesses strong theoretical guarantees, including lower bounds on critical performance metrics like recall and reduction ratio. Finally, we show that BlockBoost delivers great empirical results, outperforming state-of-the-art blocking benchmarks in terms of both performance metrics and computational cost",
    "checked": true,
    "id": "86149d23e2d30c309e24ab8565c26429a77a5d46",
    "semantic_title": "blockboost: scalable and efficient blocking through boosting",
    "citation_count": 0,
    "authors": [
      "Thiago Ramos",
      "Rodrigo Loro Schuller",
      "Alex Akira Okuno",
      "Lucas Nissenbaum",
      "Roberto I Oliveira",
      "Paulo Orenstein"
    ]
  },
  "https://proceedings.mlr.press/v238/shen24a.html": {
    "title": "Continual Domain Adversarial Adaptation via Double-Head Discriminators",
    "volume": "main",
    "abstract": "Domain adversarial adaptation in a continual setting poses significant challenges due to the limitations of accessing previous source domain data. Despite extensive research in continual learning, adversarial adaptation cannot be effectively accomplished using only a small number of stored source domain data, a standard setting in memory replay approaches. This limitation arises from the erroneous empirical estimation of $\\mathcal{H}$-divergence with few source domain samples. To tackle this problem, we propose a double-head discriminator algorithm by introducing an addition source-only domain discriminator trained solely on the source learning phase. We prove that by introducing a pre-trained source-only domain discriminator, the empirical estimation error of $\\mathcal{H}$-divergence related adversarial loss is reduced from the source domain side. Further experiments on existing domain adaptation benchmarks show that our proposed algorithm achieves more than 2$%$ improvement on all categories of target domain adaptation tasks while significantly mitigating the forgetting of the source domain",
    "checked": true,
    "id": "f7a84ea55bede46eba43fe8676ac91cd1445ff99",
    "semantic_title": "continual domain adversarial adaptation via double-head discriminators",
    "citation_count": 0,
    "authors": [
      "Yan Shen",
      "Zhanghexuan Ji",
      "Chunwei Ma",
      "Mingchen Gao"
    ]
  },
  "https://proceedings.mlr.press/v238/mohammadpour24a.html": {
    "title": "Maximum entropy GFlowNets with soft Q-learning",
    "volume": "main",
    "abstract": "Generative Flow Networks (GFNs) have emerged as a powerful tool for sampling discrete objects from unnormalized distributions, offering a scalable alternative to Markov Chain Monte Carlo (MCMC) methods. While GFNs draw inspiration from maximum entropy reinforcement learning (RL), the connection between the two has largely been unclear and seemingly applicable only in specific cases. This paper addresses the connection by constructing an appropriate reward function, thereby establishing an exact relationship between GFNs and maximum entropy RL. This construction allows us to introduce maximum entropy GFNs, which achieve the maximum entropy attainable by GFNs without constraints on the state space, in contrast to GFNs with uniform backward policy",
    "checked": true,
    "id": "6e63bc5ea2e6c326cea05e0fd7f750ef62dbfc63",
    "semantic_title": "maximum entropy gflownets with soft q-learning",
    "citation_count": 9,
    "authors": [
      "Sobhan Mohammadpour",
      "Emmanuel Bengio",
      "Emma Frejinger",
      "Pierre-Luc Bacon"
    ]
  },
  "https://proceedings.mlr.press/v238/maiti24a.html": {
    "title": "Near-Optimal Pure Exploration in Matrix Games: A Generalization of Stochastic Bandits & Dueling Bandits",
    "volume": "main",
    "abstract": "We study the sample complexity of identifying the pure strategy Nash equilibrium (PSNE) in a two-player zero-sum matrix game with noise. Formally, we are given a stochastic model where any learner can sample an entry $(i,j)$ of the input matrix $A\\in [-1,1]^{n\\times m}$ and observe $A_{i,j}+\\eta$ where $\\eta$ is a zero-mean $1$-sub-Gaussian noise. The aim of the learner is to identify the PSNE of $A$, whenever it exists, with high probability while taking as few samples as possible. Zhou et al., (2017) presents an instance-dependent sample complexity lower bound that depends only on the entries in the row and column in which the PSNE lies. We design a near-optimal algorithm whose sample complexity matches the lower bound, up to log factors. The problem of identifying the PSNE also generalizes the problem of pure exploration in stochastic multi-armed bandits and dueling bandits, and our result matches the optimal bounds, up to log factors, in both the settings",
    "checked": true,
    "id": "fd3e2f311df3077e79e304764ea815876e1650ec",
    "semantic_title": "near-optimal pure exploration in matrix games: a generalization of stochastic bandits & dueling bandits",
    "citation_count": 0,
    "authors": [
      "Arnab Maiti",
      "Ross Boczar",
      "Kevin Jamieson",
      "Lillian Ratliff"
    ]
  },
  "https://proceedings.mlr.press/v238/zheng24b.html": {
    "title": "Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo",
    "volume": "main",
    "abstract": "Approximate Thompson sampling with Langevin Monte Carlo broadens its reach from Gaussian posterior sampling to encompass more general smooth posteriors. However, it still encounters scalability issues in high-dimensional problems when demanding high accuracy. To address this, we propose an approximate Thompson sampling strategy, utilizing underdamped Langevin Monte Carlo, where the latter is the go-to workhorse for simulations of high-dimensional posteriors. Based on the standard smoothness and log-concavity conditions, we study the accelerated posterior concentration and sampling using a specific potential function. This design improves the sample complexity for realizing logarithmic regrets from $\\mathcal{\\tilde O}(d)$ to $\\mathcal{\\tilde O}(\\sqrt{d})$. The scalability and robustness of our algorithm are also empirically validated through synthetic experiments in high-dimensional bandit problems",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyang Zheng",
      "Wei Deng",
      "Christian Moya",
      "Guang Lin"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24d.html": {
    "title": "Large-Scale Gaussian Processes via Alternating Projection",
    "volume": "main",
    "abstract": "Training and inference in Gaussian processes (GPs) require solving linear systems with $n\\times n$ kernel matrices. To address the prohibitive $\\mathcal{O}(n^3)$ time complexity, recent work has employed fast iterative methods, like conjugate gradients (CG). However, as datasets increase in magnitude, the kernel matrices become increasingly ill-conditioned and still require $\\mathcal{O}(n^2)$ space without partitioning. Thus, while CG increases the size of datasets GPs can be trained on, modern datasets reach scales beyond its applicability. In this work, we propose an iterative method which only accesses subblocks of the kernel matrix, effectively enabling mini-batching. Our algorithm, based on alternating projection, has $\\mathcal{O}(n)$ per-iteration time and space complexity, solving many of the practical challenges of scaling GPs to very large datasets. Theoretically, we prove the method enjoys linear convergence. Empirically, we demonstrate its fast convergence in practice and robustness to ill-conditioning. On large-scale benchmark datasets with up to four million data points, our approach accelerates GP training and inference by speed-up factors up to $27\\times$ and $72 \\times$, respectively, compared to CG",
    "checked": true,
    "id": "6cbea710f76e2b2662d44df233f605a0629e2332",
    "semantic_title": "large-scale gaussian processes via alternating projection",
    "citation_count": 6,
    "authors": [
      "Kaiwen Wu",
      "Jonathan Wenger",
      "Haydn T Jones",
      "Geoff Pleiss",
      "Jacob Gardner"
    ]
  },
  "https://proceedings.mlr.press/v238/martinez24a.html": {
    "title": "Achieving Group Distributional Robustness and Minimax Group Fairness with Interpolating Classifiers",
    "volume": "main",
    "abstract": "Group distributional robustness optimization methods (GDRO) learn models that guarantee performance across a broad set of demographics. GDRO is often framed as a minimax game where an adversary proposes data distributions under which the model performs poorly; importance weights are used to mimic the adversarial distribution on finite samples. Prior work has show that applying GDRO with interpolating classifiers requires strong regularization to generalize to unseen data. Moreover, these classifiers are not responsive to importance weights in the asymptotic training regime. In this work we propose Bi-level GDRO, a provably convergent formulation that decouples the adversary's and model learner's objective and improves generalization guarantees. To address non-responsiveness of importance weights, we combine Bi-level GDRO with a learner that optimizes a temperature-scaled loss that can provably trade off performance between demographics, even on interpolating classifiers. We experimentally demonstrate the effectiveness of our proposed method on learning minimax classifiers on a variety of datasets. Code is available at github.com/MartinBertran/BiLevelGDRO",
    "checked": true,
    "id": "d8e156b4007f9ef1f4f71ada1634a9f26df0185d",
    "semantic_title": "achieving group distributional robustness and minimax group fairness with interpolating classifiers",
    "citation_count": 0,
    "authors": [
      "Natalia L. Martinez",
      "Martin A. Bertran",
      "Guillermo Sapiro"
    ]
  },
  "https://proceedings.mlr.press/v238/leiner24a.html": {
    "title": "Graph fission and cross-validation",
    "volume": "main",
    "abstract": "We introduce a technique called graph fission which takes in a graph which potentially contains only one observation per node (whose distribution lies in a known class) and produces two (or more) independent graphs with the same node/edge set in a way that splits the original graph's information amongst them in any desired proportion. Our proposal builds on data fission/thinning, a method that uses external randomization to create independent copies of an unstructured dataset. We extend this idea to the graph setting where there may be latent structure between observations. We demonstrate the utility of this framework via two applications: inference after structural trend estimation on graphs and a model selection procedure we term \"graph cross-validation\"'",
    "checked": true,
    "id": "fd7b142b00688a3f4cf849bc91aff569ea0bc512",
    "semantic_title": "graph fission and cross-validation",
    "citation_count": 0,
    "authors": [
      "James Leiner",
      "Aaditya Ramdas"
    ]
  },
  "https://proceedings.mlr.press/v238/lymperopoulos24a.html": {
    "title": "Graph Pruning for Enumeration of Minimal Unsatisfiable Subsets",
    "volume": "main",
    "abstract": "Finding Minimal Unsatisfiable Subsets (MUSes) of boolean constraints is a common problem in infeasibility analysis of over-constrained systems. However, because of the exponential search space of the problem, enumerating MUSes is extremely time-consuming in real applications. In this work, we propose to prune formulas using a learned model to speed up MUS enumeration. We represent formulas as graphs and then develop a graph-based learning model to predict which part of the formula should be pruned. Importantly, the training of our model does not require labeled data. It does not even require training data from the target application because it extrapolates to data with different distributions. In our experiments we combine our model with existing MUS enumerators and validate its effectiveness in multiple benchmarks including a set of real-world problems outside our training distribution. The experiment results show that our method significantly accelerates MUS enumeration on average on these benchmark problems",
    "checked": true,
    "id": "fdb4f1e715f339ddc8ea91fa98c2f6184dbe62fd",
    "semantic_title": "graph pruning for enumeration of minimal unsatisfiable subsets",
    "citation_count": 0,
    "authors": [
      "Panagiotis Lymperopoulos",
      "Liping Liu"
    ]
  },
  "https://proceedings.mlr.press/v238/shao24a.html": {
    "title": "Nonparametric Automatic Differentiation Variational Inference with Spline Approximation",
    "volume": "main",
    "abstract": "Automatic Differentiation Variational Inference (ADVI) is efficient in learning probabilistic models. Classic ADVI relies on the parametric approach to approximate the posterior. In this paper, we develop a spline-based nonparametric approximation approach that enables flexible posterior approximation for distributions with complicated structures, such as skewness, multimodality, and bounded support. Compared with widely-used nonparametric variational inference methods, the proposed method is easy to implement and adaptive to various data structures. By adopting the spline approximation, we derive a lower bound of the importance weighted autoencoder and establish the asymptotic consistency. Experiments demonstrate the efficiency of the proposed method in approximating complex posterior distributions and improving the performance of generative models with incomplete data",
    "checked": true,
    "id": "ed2b2bd664f10d8c2d3e396c71bf17c4c89e82ae",
    "semantic_title": "nonparametric automatic differentiation variational inference with spline approximation",
    "citation_count": 1,
    "authors": [
      "Yuda Shao",
      "Shan N Yu",
      "Tianshu Feng"
    ]
  },
  "https://proceedings.mlr.press/v238/shekhtman24a.html": {
    "title": "Strategic Usage in a Multi-Learner Setting",
    "volume": "main",
    "abstract": "Real-world systems often involve some pool of users choosing between a set of services. With the increase in popularity of online learning algorithms, these services can now self-optimize, leveraging data collected on users to maximize some reward such as service quality. On the flipside, users may strategically choose which services to use in order to pursue their own reward functions, in the process wielding power over which services can see and use their data. Extensive prior research has been conducted on the effects of strategic users in single-service settings, with strategic behavior manifesting in the manipulation of observable features to achieve a desired classification; however, this can often be costly or unattainable for users and fails to capture the full behavior of multi-service dynamic systems. As such, we analyze a setting in which strategic users choose among several available services in order to pursue positive classifications, while services seek to minimize loss functions on their observations. We focus our analysis on realizable settings, and show that naive retraining can still lead to oscillation even if all users are observed at different times; however, if this retraining uses memory of past observations, convergent behavior can be guaranteed for certain loss function classes. We provide results obtained from synthetic and real-world data to empirically validate our theoretical findings",
    "checked": true,
    "id": "970ff1974d3ba71d51b2cd0bb61c1dd1d765705e",
    "semantic_title": "strategic usage in a multi-learner setting",
    "citation_count": 1,
    "authors": [
      "Eliot Shekhtman",
      "Sarah Dean"
    ]
  },
  "https://proceedings.mlr.press/v238/nguyen24a.html": {
    "title": "On Parameter Estimation in Deviated Gaussian Mixture of Experts",
    "volume": "main",
    "abstract": "We consider the parameter estimation problem in the deviated Gaussian mixture of experts in which the data are generated from $(1 - \\lambda^{\\ast}) g_0(Y| X)+ \\lambda^{\\ast} \\sum_{i = 1}^{k_{\\ast}} p_{i}^{\\ast} f(Y|(a_{i}^{\\ast})^{\\top}X+b_i^{\\ast},\\sigma_{i}^{\\ast})$, where $X, Y$ are respectively a covariate vector and a response variable, $g_{0}(Y|X)$ is a known function, $\\lambda^{\\ast} \\in [0, 1]$ is true but unknown mixing proportion, and $(p_{i}^{\\ast}, a_{i}^{\\ast}, b_{i}^{\\ast}, \\sigma_{i}^{\\ast})$ for $1 \\leq i \\leq k^{\\ast}$ are unknown parameters of the Gaussian mixture of experts. This problem arises from the goodness-of-fit test when we would like to test whether the data are generated from $g_{0}(Y|X)$ (null hypothesis) or they are generated from the whole mixture (alternative hypothesis). Based on the algebraic structure of the expert functions and the distinguishability between $g_0$ and the mixture part, we construct novel Voronoi-based loss functions to capture the convergence rates of maximum likelihood estimation (MLE) for our models. We further demonstrate that our proposed loss functions characterize the local convergence rates of parameter estimation more accurately than the generalized Wasserstein, a loss function being commonly used for estimating parameters in the Gaussian mixture of experts",
    "checked": true,
    "id": "2f0e59b6639663559df5cfda6b871ec8fd768c50",
    "semantic_title": "on parameter estimation in deviated gaussian mixture of experts",
    "citation_count": 0,
    "authors": [
      "Huy Nguyen",
      "Khai Nguyen",
      "Nhat Ho"
    ]
  },
  "https://proceedings.mlr.press/v238/nguyen24b.html": {
    "title": "Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts",
    "volume": "main",
    "abstract": "Originally introduced as a neural network for ensemble learning, mixture of experts (MoE) has recently become a fundamental building block of highly successful modern deep neural networks for heterogeneous data analysis in several applications of machine learning and statistics. Despite its popularity in practice, a satisfactory level of theoretical understanding of the MoE model is far from complete. To shed new light on this problem, we provide a convergence analysis for maximum likelihood estimation (MLE) in the Gaussian-gated MoE model. The main challenge of that analysis comes from the inclusion of covariates in the Gaussian gating functions and expert networks, which leads to their intrinsic interaction via some partial differential equations with respect to their parameters. We tackle these issues by designing novel Voronoi loss functions among parameters to accurately capture the heterogeneity of parameter estimation rates. Our findings reveal that the MLE has distinct behaviors under two complement settings of location parameters of the Gaussian gating functions, namely when all these parameters are non-zero versus when at least one among them vanishes. Notably, these behaviors can be characterized by the solvability of two different systems of polynomial equations. Finally, we conduct a simulation study to empirically verify our theoretical results",
    "checked": true,
    "id": "37d90ae7b0dbfeded1cd1c38a722d40f5592f2c7",
    "semantic_title": "towards convergence rates for parameter estimation in gaussian-gated mixture of experts",
    "citation_count": 10,
    "authors": [
      "Huy Nguyen",
      "TrungTin Nguyen",
      "Khai Nguyen",
      "Nhat Ho"
    ]
  },
  "https://proceedings.mlr.press/v238/chakraborty24a.html": {
    "title": "PrIsing: Privacy-Preserving Peer Effect Estimation via Ising Model",
    "volume": "main",
    "abstract": "The Ising model, originally developed as a spin-glass model for ferromagnetic elements, has gained popularity as a network-based model for capturing dependencies in agents' outputs. Its increasing adoption in healthcare and the social sciences has raised privacy concerns regarding the confidentiality of agents' responses. In this paper, we present a novel $(\\varepsilon,\\delta)$-differentially private algorithm specifically designed to protect the privacy of individual agents' outcomes. Our algorithm allows for precise estimation of the natural parameter using a single network through an objective perturbation technique. Furthermore, we establish regret bounds for this algorithm and assess its performance on synthetic datasets and two real-world networks: one involving HIV status in a social network and the other concerning the political leaning of online blogs",
    "checked": true,
    "id": "18fea208638b22b3223aea630f2dac9c3c0f785a",
    "semantic_title": "prising: privacy-preserving peer effect estimation via ising model",
    "citation_count": 0,
    "authors": [
      "Abhinav Chakraborty",
      "Anirban Chatterjee",
      "Abhinandan Dalal"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24d.html": {
    "title": "Escaping Saddle Points in Heterogeneous Federated Learning via Distributed SGD with Communication Compression",
    "volume": "main",
    "abstract": "We consider the problem of finding second-order stationary points in the optimization of heterogeneous federated learning (FL). Previous works in FL mostly focus on first-order convergence guarantees, which do not rule out the scenario of unstable saddle points. Meanwhile, it is a key bottleneck of FL to achieve communication efficiency without compensating the learning accuracy, especially when local data are highly heterogeneous across different clients. Given this, we propose a novel algorithm PowerEF-SGD that only communicates compressed information via a novel error-feedback scheme. To our knowledge, PowerEF-SGD is the first distributed and compressed SGD algorithm that provably escapes saddle points in heterogeneous FL without any data homogeneity assumptions. In particular, PowerEF-SGD improves to second-order stationary points after visiting first-order (possibly saddle) points, using additional gradient queries and communication rounds only of almost the same order required by first-order convergence, and the convergence rate shows a linear-speedup pattern in terms of the number of workers. Our theory improves/recovers previous results, while extending to much more tolerant settings on the local data. Numerical experiments are provided to complement the theory",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sijin Chen",
      "Zhize Li",
      "Yuejie Chi"
    ]
  },
  "https://proceedings.mlr.press/v238/nguyen24c.html": {
    "title": "From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach",
    "volume": "main",
    "abstract": "We propose the Kuramoto Graph Neural Network (KuramotoGNN), a novel class of continuous-depth graph neural networks (GNNs) that employs the Kuramoto model to mitigate the over-smoothing phenomenon, in which node features in GNNs become indistinguishable as the number of layers increases. The Kuramoto model captures the synchronization behavior of non-linear coupled oscillators. Under the view of coupled oscillators, we first show the connection between Kuramoto model and basic GNN and then over-smoothing phenomenon in GNNs can be interpreted as phase synchronization in Kuramoto model. The KuramotoGNN replaces this phase synchronization with frequency synchronization to prevent the node features from converging into each other while allowing the system to still reach a stable synchronized state. We experimentally verify the advantages of the KuramotoGNN over the baseline GNNs and existing methods in reducing over-smoothing on various graph deep learning benchmark tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tuan Nguyen",
      "Hirotada Honda",
      "Takashi Sano",
      "Vinh Nguyen",
      "Shugo Nakamura",
      "Tan Minh Nguyen"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24d.html": {
    "title": "Distributionally Robust Off-Dynamics Reinforcement Learning: Provable Efficiency with Linear Function Approximation",
    "volume": "main",
    "abstract": "We study off-dynamics Reinforcement Learning (RL), where the policy is trained on a source domain and deployed to a distinct target domain. We aim to solve this problem via online distributionally robust Markov decision processes (DRMDPs), where the learning algorithm actively interacts with the source domain while seeking the optimal performance under the worst possible dynamics that is within an uncertainty set of the source domain's transition kernel. We provide the first study on online DRMDPs with function approximation for off-dynamics RL. We find that DRMDPs' dual formulation can induce nonlinearity, even when the nominal transition kernel is linear, leading to error propagation. By designing a $d$-rectangular uncertainty set using the total variation distance, we remove this additional nonlinearity and bypass the error propagation. We then introduce DR-LSVI-UCB, the first provably efficient online DRMDP algorithm for off-dynamics RL with function approximation, and establish a polynomial suboptimality bound that is independent of the state and action space sizes. Our work makes the first step towards a deeper understanding of the provable efficiency of online DRMDPs with linear function approximation. Finally, we substantiate the performance and robustness of DR-LSVI-UCB through different numerical experiments",
    "checked": true,
    "id": "f2adbfe8450ddb406f4082b6c75006eb0a09523c",
    "semantic_title": "distributionally robust off-dynamics reinforcement learning: provable efficiency with linear function approximation",
    "citation_count": 0,
    "authors": [
      "Zhishuai Liu",
      "Pan Xu"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24f.html": {
    "title": "Invariant Aggregator for Defending against Federated Backdoor Attacks",
    "volume": "main",
    "abstract": "Federated learning enables training high-utility models across several clients without directly sharing their private data. As a downside, the federated setting makes the model vulnerable to various adversarial attacks in the presence of malicious clients. Despite the theoretical and empirical success in defending against attacks that aim to degrade models' utility, defense against backdoor attacks that increase model accuracy on backdoor samples exclusively without hurting the utility on other samples remains challenging. To this end, we first analyze the failure modes of existing defenses over a flat loss landscape, which is common for well-designed neural networks such as Resnet (He et al., 2015) but is often overlooked by previous works. Then, we propose an invariant aggregator that redirects the aggregated update to invariant directions that are generally useful via selectively masking out the update elements that favor few and possibly malicious clients. Theoretical results suggest that our approach provably mitigates backdoor attacks and remains effective over flat loss landscapes. Empirical results on three datasets with different modalities and varying numbers of clients further demonstrate that our approach mitigates a broad class of backdoor attacks with a negligible cost on the model utility",
    "checked": true,
    "id": "cdb88b494fe1e3a93e60ec0661e9d2c7b97ec163",
    "semantic_title": "invariant aggregator for defending against federated backdoor attacks",
    "citation_count": 1,
    "authors": [
      "Xiaoyang Wang",
      "Dimitrios Dimitriadis",
      "Sanmi Koyejo",
      "Shruti Tople"
    ]
  },
  "https://proceedings.mlr.press/v238/li24l.html": {
    "title": "Policy Evaluation for Reinforcement Learning from Human Feedback: A Sample Complexity Analysis",
    "volume": "main",
    "abstract": "A recently popular approach to solving reinforcement learning is with data from human preferences. In fact, human preference data are now used with classic reinforcement learning algorithms such as actor-critic methods, which involve evaluating an intermediate policy over a reward learned from human preference data with distribution shift, known as off-policy evaluation (OPE). Such algorithm includes (i) learning reward function from human preference dataset, and (ii) learning expected cumulative reward of a target policy. Despite the huge empirical success, existing OPE methods with preference data often lack theoretical understandings and rely heavily on heuristics. In this paper, we study the sample efficiency of OPE with human preference and establish a statistical guarantee for it. Specifically, we approach OPE with learning the value function by fitted-Q-evaluation with a deep neural network. By appropriately selecting the size of a ReLU network, we show that one can leverage any low-dimensional manifold structure in the Markov decision process and obtain a sample-efficient estimator without suffering from the curse of high data ambient dimensionality. Under the assumption of high reward smoothness, our results almost align with the classical OPE results with observable reward data. To the best of our knowledge, this is the first result that establishes a provably efficient guarantee for off-policy evaluation with RLHF",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Li",
      "Xiang Ji",
      "Minshuo Chen",
      "Mengdi Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/adibi24a.html": {
    "title": "Stochastic Approximation with Delayed Updates: Finite-Time Rates under Markovian Sampling",
    "volume": "main",
    "abstract": "Motivated by applications in large-scale and multi-agent reinforcement learning, we study the non-asymptotic performance of stochastic approximation (SA) schemes with delayed updates under Markovian sampling. While the effect of delays has been extensively studied for optimization, the manner in which they interact with the underlying Markov process to shape the finite-time performance of SA remains poorly understood. In this context, our first main contribution is to show that under time-varying bounded delays, the delayed SA update rule guarantees exponentially fast convergence of the \\emph{last iterate} to a ball around the SA operator's fixed point. Notably, our bound is \\emph{tight} in its dependence on both the maximum delay $\\tau_{max}$, and the mixing time $\\tau_{mix}$. To achieve this tight bound, we develop a novel inductive proof technique that, unlike various existing delayed-optimization analyses, relies on establishing uniform boundedness of the iterates. As such, our proof may be of independent interest. Next, to mitigate the impact of the maximum delay on the convergence rate, we provide the first finite-time analysis of a delay-adaptive SA scheme under Markovian sampling. In particular, we show that the exponent of convergence of this scheme gets scaled down by $\\tau_{avg}$, as opposed to $\\tau_{max}$ for the vanilla delayed SA rule; here, $\\tau_{avg}$ denotes the average delay across all iterations. Moreover, the adaptive scheme requires no prior knowledge of the delay sequence for step-size tuning. Our theoretical findings shed light on the finite-time effects of delays for a broad class of algorithms, including TD learning, Q-learning, and stochastic gradient descent under Markovian sampling",
    "checked": true,
    "id": "dbe385206ecc44a8d06e0941af7219dd749df0d7",
    "semantic_title": "stochastic approximation with delayed updates: finite-time rates under markovian sampling",
    "citation_count": 3,
    "authors": [
      "Arman Adibi",
      "Nicolò Dal Fabbro",
      "Luca Schenato",
      "Sanjeev Kulkarni",
      "H. Vincent Poor",
      "George J. Pappas",
      "Hamed Hassani",
      "Aritra Mitra"
    ]
  },
  "https://proceedings.mlr.press/v238/ahmed24a.html": {
    "title": "Privacy-Preserving Decentralized Actor-Critic for Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "Multi-agent reinforcement learning has a wide range of applications in cooperative settings, but ensuring data privacy among agents is a significant challenge. To address this challenge, we propose Privacy-Preserving Decentralized Actor-Critic (PPDAC), an algorithm that motivates agents to cooperate while maintaining their data privacy. Leveraging trajectory ranking, PPDAC enables the agents to learn a cooperation reward that encourages agents to account for other agents' preferences. Subsequently, each agent trains a policy that maximizes not only its local reward as in independent actor-critic (IAC) but also the cooperation reward, hence, increasing cooperation. Importantly, communication among agents is restricted to their ranking of trajectories that only include public identifiers without any private local data. Moreover, as an additional layer of privacy, the agents can perturb their rankings with the randomized response method. We evaluate PPDAC on the level-based foraging (LBF) environment and a coin-gathering environment. We compare with IAC and Shared Experience Actor-Critic (SEAC) which achieves SOTA results for the LBF environment. The results show that PPDAC consistently outperforms IAC. In addition, PPDAC outperforms SEAC in the coin-gathering environment and achieves similar performance in the LBF environment, all while providing better privacy",
    "checked": true,
    "id": "8cb534eec05d74440067a339b6f838631c787087",
    "semantic_title": "privacy-preserving decentralized actor-critic for cooperative multi-agent reinforcement learning",
    "citation_count": 0,
    "authors": [
      "Maheed A. Ahmed",
      "Mahsa Ghasemi"
    ]
  },
  "https://proceedings.mlr.press/v238/li24m.html": {
    "title": "On the Model-Misspecification in Reinforcement Learning",
    "volume": "main",
    "abstract": "The success of reinforcement learning (RL) crucially depends on effective function approximation when dealing with complex ground-truth models. Existing sample-efficient RL algorithms primarily employ three approaches to function approximation: policy-based, value-based, and model-based methods. However, in the face of model misspecification—a disparity between the ground-truth and optimal function approximators—it is shown that policy-based approaches can be robust even when the policy function approximation is under a large \\emph{locally-bounded} misspecification error, with which the function class may exhibit a $\\Omega(1)$ approximation error in specific states and actions, but remains small on average within a policy-induced state distribution. Yet it remains an open question whether similar robustness can be achieved with value-based and model-based approaches, especially with general function approximation. To bridge this gap, in this paper we present a unified theoretical framework for addressing model misspecification in RL. We demonstrate that, through meticulous algorithm design and sophisticated analysis, value-based and model-based methods employing general function approximation can achieve robustness under local misspecification error bounds. In particular, they can attain a regret bound of $\\widetilde{O}\\left(\\mathrm{poly}(dH)\\cdot(\\sqrt{K} + K\\cdot\\zeta) \\right)$, where $d$ represents the complexity of the function class, $H$ is the episode length, $K$ is the total number of episodes, and $\\zeta$ denotes the local bound for misspecification error. Furthermore, we propose an algorithmic framework that can achieve the same order of regret bound without prior knowledge of $\\zeta$, thereby enhancing its practical applicability",
    "checked": true,
    "id": "3f9ddeadbce43d3a4adebd86233675023411b5bc",
    "semantic_title": "on the model-misspecification in reinforcement learning",
    "citation_count": 2,
    "authors": [
      "Yunfan Li",
      "Lin Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/levin24a.html": {
    "title": "Any-dimensional equivariant neural networks",
    "volume": "main",
    "abstract": "Traditional supervised learning aims to learn an unknown mapping by fitting a function to a set of input-output pairs with a fixed dimension. The fitted function is then defined on inputs of the same dimension. However, in many settings, the unknown mapping takes inputs in any dimension; examples include graph parameters defined on graphs of any size and physics quantities defined on an arbitrary number of particles. We leverage a newly-discovered phenomenon in algebraic topology, called representation stability, to define equivariant neural networks that can be trained with data in a fixed dimension and then extended to accept inputs in any dimension. Our approach is black-box and user-friendly, requiring only the network architecture and the groups for equivariance, and can be combined with any training procedure. We provide a simple open-source implementation of our methods and offer preliminary numerical experiments",
    "checked": true,
    "id": "7f40c2367569716f8dd14e83526657e30e3fe154",
    "semantic_title": "any-dimensional equivariant neural networks",
    "citation_count": 3,
    "authors": [
      "Eitan Levin",
      "Mateo Diaz"
    ]
  },
  "https://proceedings.mlr.press/v238/laplante24a.html": {
    "title": "Conditional Adjustment in a Markov Equivalence Class",
    "volume": "main",
    "abstract": "We consider the problem of identifying a conditional causal effect through covariate adjustment. We focus on the setting where the causal graph is known up to one of two types of graphs: a maximally oriented partially directed acyclic graph (MPDAG) or a partial ancestral graph (PAG). Both MPDAGs and PAGs represent equivalence classes of possible underlying causal models. After defining adjustment sets in this setting, we provide a necessary and sufficient graphical criterion – the conditional adjustment criterion – for finding these sets under conditioning on variables unaffected by treatment. We further provide explicit sets from the graph that satisfy the conditional adjustment criterion, and therefore, can be used as adjustment sets for conditional causal effect identification",
    "checked": true,
    "id": "ee9af2e6379511890f023a46214ae4baea68209a",
    "semantic_title": "conditional adjustment in a markov equivalence class",
    "citation_count": 0,
    "authors": [
      "Sara LaPlante",
      "Emilija Perkovic"
    ]
  },
  "https://proceedings.mlr.press/v238/arya24b.html": {
    "title": "Learning to Solve the Constrained Most Probable Explanation Task in Probabilistic Graphical Models",
    "volume": "main",
    "abstract": "We propose a self-supervised learning approach for solving the following constrained optimization task in log-linear models or Markov networks. Let $f$ and $g$ be two log-linear models defined over the sets $X$ and $Y$ of random variables. Given an assignment $x$ to all variables in $X$ (evidence or observations) and a real number $q$, the constrained most-probable explanation (CMPE) task seeks to find an assignment $y$ to all variables in $Y$ such that $f(x, y)$ is maximized and $g(x, y) \\leq q$. In our proposed self-supervised approach, given assignments $x$ to $X$ (data), we train a deep neural network that learns to output near-optimal solutions to the CMPE problem without requiring access to any pre-computed solutions. The key idea in our approach is to use first principles and approximate inference methods for CMPE to derive novel loss functions that seek to push infeasible solutions towards feasible ones and feasible solutions towards optimal ones. We analyze the properties of our proposed method and experimentally demonstrate its efficacy on several benchmark problems",
    "checked": true,
    "id": "151cc5cf9f5189b88070c71ce3bac3e9fe2e646b",
    "semantic_title": "learning to solve the constrained most probable explanation task in probabilistic graphical models",
    "citation_count": 0,
    "authors": [
      "Shivvrat Arya",
      "Tahrima Rahman",
      "Vibhav Gogate"
    ]
  },
  "https://proceedings.mlr.press/v238/shi24b.html": {
    "title": "Adaptive and non-adaptive minimax rates for weighted Laplacian-Eigenmap based nonparametric regression",
    "volume": "main",
    "abstract": "We show both adaptive and non-adaptive minimax rates of convergence for a family of weighted Laplacian-Eigenmap based nonparametric regression methods, when the true regression function belongs to a Sobolev space and the sampling density is bounded from above and below. The adaptation methodology is based on extensions of Lepski's method and is over both the smoothness parameter ($s\\in\\mathbb{N}_{+}$) and the norm parameter ($M>0$) determining the constraints on the Sobolev space. Our results extend the non-adaptive result in Green et al., (2023), established for a specific normalized graph Laplacian, to a wide class of weighted Laplacian matrices used in practice, including the unnormalized Laplacian and random walk Laplacian",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoyang Shi",
      "Krishna Balasubramanian",
      "Wolfgang Polonik"
    ]
  },
  "https://proceedings.mlr.press/v238/cundy24a.html": {
    "title": "Privacy-Constrained Policies via Mutual Information Regularized Policy Gradients",
    "volume": "main",
    "abstract": "As reinforcement learning techniques are increasingly applied to real-world decision problems, attention has turned to how these algorithms use potentially sensitive information. We consider the task of training a policy that maximizes reward while minimizing disclosure of certain sensitive state variables through the actions. We give examples of how this setting covers real-world problems in privacy for sequential decision-making. We solve this problem in the policy gradients framework by introducing a regularizer based on the mutual information (MI) between the sensitive state and the actions. We develop a model-based stochastic gradient estimator for optimization of privacy-constrained policies. We also discuss an alternative MI regularizer that serves as an upper bound to our main MI regularizer and can be optimized in a model-free setting, and a powerful direct estimator that can be used in an environment with differentiable dynamics. We contrast previous work in differentially-private RL to our mutual-information formulation of information disclosure. Experimental results show that our training method results in policies that hide the sensitive state, even in challenging high-dimensional tasks",
    "checked": false,
    "id": "711bbaa34ae370d7cfa8e900f9625bf38d2f0e4c",
    "semantic_title": "optimal coordination for multiple network-constrained vpps via multi-agent deep reinforcement learning",
    "citation_count": 9,
    "authors": [
      "Chris J. Cundy",
      "Rishi Desai",
      "Stefano Ermon"
    ]
  },
  "https://proceedings.mlr.press/v238/arya24a.html": {
    "title": "Deep Dependency Networks and Advanced Inference Schemes for Multi-Label Classification",
    "volume": "main",
    "abstract": "We present a unified framework called deep dependency networks (DDNs) that combines dependency networks and deep learning architectures for multi-label classification, with a particular emphasis on image and video data. The primary advantage of dependency networks is their ease of training, in contrast to other probabilistic graphical models like Markov networks. In particular, when combined with deep learning architectures, they provide an intuitive, easy-to-use loss function for multi-label classification. A drawback of DDNs compared to Markov networks is their lack of advanced inference schemes, necessitating the use of Gibbs sampling. To address this challenge, we propose novel inference schemes based on local search and integer linear programming for computing the most likely assignment to the labels given observations. We evaluate our novel methods on three video datasets (Charades, TACoS, Wetlab) and three image datasets (MS-COCO, PASCAL VOC, NUS-WIDE), comparing their performance with (a) basic neural architectures and (b) neural architectures combined with Markov networks equipped with advanced inference and learning techniques. Our results demonstrate the superiority of our new DDN methods over the two competing approaches",
    "checked": true,
    "id": "0c1eb2dda0bca92086f6bc69bb47feaadc3278d0",
    "semantic_title": "deep dependency networks and advanced inference schemes for multi-label classification",
    "citation_count": 0,
    "authors": [
      "Shivvrat Arya",
      "Yu Xiang",
      "Vibhav Gogate"
    ]
  },
  "https://proceedings.mlr.press/v238/nguyen24d.html": {
    "title": "Near-optimal Per-Action Regret Bounds for Sleeping Bandits",
    "volume": "main",
    "abstract": "We derive near-optimal per-action regret bounds for sleeping bandits, in which both the sets of available arms and their losses in every round are chosen by an adversary. In a setting with $K$ total arms and at most $A$ available arms in each round over $T$ rounds, the best known upper bound is $O(K\\sqrt{TA\\ln{K}})$, obtained indirectly via minimizing internal sleeping regrets. Compared to the minimax $\\Omega(\\sqrt{TA})$ lower bound, this upper bound contains an extra multiplicative factor of $K\\ln{K}$. We address this gap by directly minimizing the per-action regret using generalized versions of EXP3, EXP3-IX and FTRL with Tsallis entropy, thereby obtaining near-optimal bounds of order $O(\\sqrt{TA\\ln{K}})$ and $O(\\sqrt{T\\sqrt{AK}})$. We extend our results to the setting of bandits with advice from sleeping experts, generalizing EXP4 along the way. This leads to new proofs for a number of existing adaptive and tracking regret bounds for standard non-sleeping bandits. Extending our results to the bandit version of experts that report their confidences leads to new bounds for the confidence regret that depends primarily on the sum of experts' confidences. We prove a lower bound, showing that for any minimax optimal algorithms, there exists an action whose regret is sublinear in $T$ but linear in the number of its active rounds",
    "checked": true,
    "id": "e3da994891cc3e3b4b16a6213b950b1ab15f94b7",
    "semantic_title": "near-optimal per-action regret bounds for sleeping bandits",
    "citation_count": 0,
    "authors": [
      "Quan M. Nguyen",
      "Nishant Mehta"
    ]
  },
  "https://proceedings.mlr.press/v238/ruan24a.html": {
    "title": "Electronic Medical Records Assisted Digital Clinical Trial Design",
    "volume": "main",
    "abstract": "Randomized controlled trials (RCTs) are gold standards for assessing intervention efficacy. Yet, generalizing evidence from classical RCTs can be challenging and sometimes problematic due to their limited external validity under stringent eligibility criteria and inadequate statistical power resulting from limited sample sizes under budgetary constraints. \"Digital clinical trial,\" which utilizes digital technology and electronic medical records (EMRs) to expand eligibility criteria and enhance data collection efficiency, offers a promising concept for solving the above-mentioned conundrums encountered in classical RCTs. In this paper, we propose two novel digital clinical trial design strategies assisted by EMRs collected from diverse patient populations. On the one hand, leveraging digital technologies, our design strategies adaptively modify both the eligibility criteria and treatment assignment mechanism to enhance data collection efficiency. As a result, evidence gathered from our design can possess greater statistical power. On the other hand, since EMRs capture diverse patient populations and provide large sample sizes, our design not only broadens the trial's eligibility criteria but also enhances its statistical power, enabling us to collect more generalizable evidence with boosted statistical power for evaluating intervention efficacy than classical RCTs. We demonstrate the validity and merit of the proposed designs with detailed theoretical investigation, simulation studies, and a synthetic case study",
    "checked": true,
    "id": "a22df818527bbf14a571cbe1375c7635c20945af",
    "semantic_title": "electronic medical records assisted digital clinical trial design",
    "citation_count": 0,
    "authors": [
      "Xinrui Ruan",
      "Jingshen Wang",
      "Yingfei Wang",
      "Waverly Wei"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24g.html": {
    "title": "Multivariate Time Series Forecasting By Graph Attention Networks With Theoretical Guarantees",
    "volume": "main",
    "abstract": "Multivariate time series forecasting (MTSF) aims to predict future values of multiple variables based on past values of multivariate time series, and has been applied in fields including traffic flow prediction, stock price forecasting, and anomaly detection. Capturing the inter-dependencies among multiple series poses one significant challenge to MTSF. Recent works have considered modeling the correlated series as graph nodes and using graph neural network (GNN)-based approaches with attention mechanisms added to improve the test prediction accuracy, however, none of them have theoretical guarantees regarding the generalization error. In this paper, we develop a new norm-bounded graph attention network (GAT) for MTSF by upper-bounding the Frobenius norm of weights in each layer of the GAT model to enhance performance. We theoretically establish that the generalization error bound for our model is associated with various components of GAT models: the number of attention heads, the maximum number of neighbors, the upper bound of the Frobenius norm of the weight matrix in each layer, and the norm of the input features. Empirically, we investigate the impact of different components of GAT models on the generalization performance of MTSF on real data. Our experiment verifies our theoretical findings. We compare with multiple prior frequently cited graph-based methods for MTSF using real data sets and the experiment results show our method can achieve the best performance for MTSF. Our method provides novel perspectives for improving the generalization performance of MTSF, and our theoretical guarantees give substantial implications for designing graph-based methods with attention mechanisms for MTSF",
    "checked": true,
    "id": "586c56bb6d9dabbe26b143e2d7c5a706ca9d2685",
    "semantic_title": "multivariate time series forecasting by graph attention networks with theoretical guarantees",
    "citation_count": 0,
    "authors": [
      "Zhi Zhang",
      "Weijian Li",
      "Han Liu"
    ]
  },
  "https://proceedings.mlr.press/v238/ataee-tarzanagh24a.html": {
    "title": "Online Bilevel Optimization: Regret Analysis of Online Alternating Gradient Methods",
    "volume": "main",
    "abstract": "This paper introduces \\textit{online bilevel optimization} in which a sequence of time-varying bilevel problems is revealed one after the other. We extend the known regret bounds for single-level online algorithms to the bilevel setting. Specifically, we provide new notions of \\textit{bilevel regret}, develop an online alternating time-averaged gradient method that is capable of leveraging smoothness, and give regret bounds in terms of the path-length of the inner and outer minimizer sequences",
    "checked": true,
    "id": "97d36b4fdebcda401818e5b269c097f1ca897223",
    "semantic_title": "online bilevel optimization: regret analysis of online alternating gradient methods",
    "citation_count": 8,
    "authors": [
      "Davoud Ataee Tarzanagh",
      "Parvin Nazari",
      "Bojian Hou",
      "Li Shen",
      "Laura Balzano"
    ]
  },
  "https://proceedings.mlr.press/v238/ibrahim24a.html": {
    "title": "End-to-end Feature Selection Approach for Learning Skinny Trees",
    "volume": "main",
    "abstract": "We propose a new optimization-based approach for feature selection in tree ensembles, an important problem in statistics and machine learning. Popular tree ensemble toolkits e.g., Gradient Boosted Trees and Random Forests support feature selection post-training based on feature importance scores, while very popular, they are known to have drawbacks. We propose Skinny Trees: an end-to-end toolkit for feature selection in tree ensembles where we train a tree ensemble while controlling the number of selected features. Our optimization-based approach learns an ensemble of differentiable trees, and simultaneously performs feature selection using a grouped $\\ell_0$-regularizer. We use first-order methods for optimization and present convergence guarantees for our approach. We use a dense-to-sparse regularization scheduling scheme that can lead to more expressive and sparser tree ensembles. On 15 synthetic and real-world datasets, Skinny Trees can achieve $1.5{\\times}$–$620{\\times}$ feature compression rates, leading up to $10{\\times}$ faster inference over dense trees, without any loss in performance. Skinny Trees lead to superior feature selection than many existing toolkits e.g., in terms of AUC performance for 25% feature budget, Skinny Trees outperforms LightGBM by 10.2% (up to 37.7%), and Random Forests by 3% (up to 12.5%)",
    "checked": true,
    "id": "a1c8299b605cef756b3ef6e72ad9516422167e5e",
    "semantic_title": "end-to-end feature selection approach for learning skinny trees",
    "citation_count": 0,
    "authors": [
      "Shibal Ibrahim",
      "Kayhan Behdin",
      "Rahul Mazumder"
    ]
  },
  "https://proceedings.mlr.press/v238/thompson24a.html": {
    "title": "Contextual Directed Acyclic Graphs",
    "volume": "main",
    "abstract": "Estimating the structure of directed acyclic graphs (DAGs) from observational data remains a significant challenge in machine learning. Most research in this area concentrates on learning a single DAG for the entire population. This paper considers an alternative setting where the graph structure varies across individuals based on available \"contextual\" features. We tackle this contextual DAG problem via a neural network that maps the contextual features to a DAG, represented as a weighted adjacency matrix. The neural network is equipped with a novel projection layer that ensures the output matrices are sparse and satisfy a recently developed characterization of acyclicity. We devise a scalable computational framework for learning contextual DAGs and provide a convergence guarantee and an analytical gradient for backpropagating through the projection layer. Our experiments suggest that the new approach can recover the true context-specific graph where existing approaches fail",
    "checked": true,
    "id": "6d18782a837d0edc818ad69b98368bdd8d053815",
    "semantic_title": "contextual directed acyclic graphs",
    "citation_count": 0,
    "authors": [
      "Ryan Thompson",
      "Edwin V. Bonilla",
      "Robert Kohn"
    ]
  },
  "https://proceedings.mlr.press/v238/han24b.html": {
    "title": "Conformalized Semi-supervised Random Forest for Classification and Abnormality Detection",
    "volume": "main",
    "abstract": "The Random Forests classifier, a widely utilized off-the-shelf classification tool, assumes training and test samples come from the same distribution as other standard classifiers. However, in safety-critical scenarios like medical diagnosis and network attack detection, discrepancies between the training and test sets, including the potential presence of novel outlier samples not appearing during training, can pose significant challenges. To address this problem, we introduce the Conformalized Semi-Supervised Random Forest (CSForest), which couples the conformalization technique Jackknife+aB with semi-supervised tree ensembles to construct a set-valued prediction $C(x)$. Instead of optimizing over the training distribution, CSForest employs unlabeled test samples to enhance accuracy and flag unseen outliers by generating an empty set. Theoretically, we establish CSForest to cover true labels for previously observed inlier classes under arbitrarily label-shift in the test data. We compare CSForest with state-of-the-art methods using synthetic examples and various real-world datasets, under different types of distribution changes in the test domain. Our results highlight CSForest's effective prediction of inliers and its ability to detect outlier samples unique to the test data. In addition, CSForest shows persistently good performance as the sizes of the training and test sets vary. Codes of CSForest are available at https://github.com/yujinhan98/CSForest",
    "checked": true,
    "id": "d02424fd26bb8d8f65eab4187227740f11e1060e",
    "semantic_title": "conformalized semi-supervised random forest for classification and abnormality detection",
    "citation_count": 1,
    "authors": [
      "Yujin Han",
      "Mingwenchan Xu",
      "Leying Guan"
    ]
  },
  "https://proceedings.mlr.press/v238/sen-fong24a.html": {
    "title": "Multi-Level Symbolic Regression: Function Structure Learning for Multi-Level Data",
    "volume": "main",
    "abstract": "Symbolic Regression (SR) is an approach which learns a closed-form function relating the predictors to the outcome in a dataset. Datasets are often multi-level (MuL), meaning that certain features can be used to split data into groups for analysis (we refer to these features as levels). The advantage of viewing datasets as MuL is that we can exploit the high similarity of data within a group. SR is well-suited for MuL datasets, in which the learnt function structure serves as ‘shared information' between the groups while the learnt parameter values capture the unique relationships within each group. In this context, this paper makes three contributions: (i) We design an algorithm, Multi-level Symbolic Regression (MSR), which runs multiple parallel SR processes for each group and merges them to produce a single function structure. (ii) To tackle datasets that are not explicitly MuL, we develop a metric termed MLICC to select the best feature to serve as a level. (iii) We also release MSRBench, a database of MuL datasets (synthetic and real-world) which we developed and collated, that can be used to evaluate MSR. Our results and ablation studies demonstrate that MSR achieves a higher recovery rate and lower error on MSRBench compared to SOTA methods for SR and MuL datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kei Sen Fong",
      "Mehul Motani"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24e.html": {
    "title": "Non-Convex Joint Community Detection and Group Synchronization via Generalized Power Method",
    "volume": "main",
    "abstract": "This paper proposes a Generalized Power Method (GPM) to simultaneously solve the joint problem of community detection and group synchronization in a direct non-convex manner, in contrast to the existing method of semidefinite programming (SDP). Under a natural extension of stochastic block model (SBM), our theoretical analysis proves that the proposed algorithm is able to exactly recover the ground truth in $O(n\\log^2 n)$ time for problems of size $n$, sharply outperforming the $O(n^{3.5})$ runtime of SDP. Moreover, we give a lower bound of model parameters as a sufficient condition for the exact recovery of GPM. The new bound breaches the information-theoretic limit for pure community detection under SBM, thus demonstrating the superiority of our simultaneous optimization algorithm over any two-stage method that performs the two tasks in succession. We also conduct numerical experiments on GPM and SDP to corroborate our theoretical analysis",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sijin Chen",
      "Xiwei Cheng",
      "Anthony Man-Cho So"
    ]
  },
  "https://proceedings.mlr.press/v238/tsai24a.html": {
    "title": "Fast Minimization of Expected Logarithmic Loss via Stochastic Dual Averaging",
    "volume": "main",
    "abstract": "Consider the problem of minimizing an expected logarithmic loss over either the probability simplex or the set of quantum density matrices. This problem includes tasks such as solving the Poisson inverse problem, computing the maximum-likelihood estimate for quantum state tomography, and approximating positive semi-definite matrix permanents with the currently tightest approximation ratio. Although the optimization problem is convex, standard iteration complexity guarantees for first-order methods do not directly apply due to the absence of Lipschitz continuity and smoothness in the loss function. In this work, we propose a stochastic first-order algorithm named $B$-sample stochastic dual averaging with the logarithmic barrier. For the Poisson inverse problem, our algorithm attains an $\\varepsilon$-optimal solution in $\\smash{\\tilde{O}}(d^2/\\varepsilon^2)$ time, matching the state of the art, where $d$ denotes the dimension. When computing the maximum-likelihood estimate for quantum state tomography, our algorithm yields an $\\varepsilon$-optimal solution in $\\smash{\\tilde{O}}(d^3/\\varepsilon^2)$ time. This improves on the time complexities of existing stochastic first-order methods by a factor of $d^{\\omega-2}$ and those of batch methods by a factor of $d^2$, where $\\omega$ denotes the matrix multiplication exponent. Numerical experiments demonstrate that empirically, our algorithm outperforms existing methods with explicit complexity guarantees",
    "checked": true,
    "id": "aecf2a69bae7077acd3d927e3376fbdb6b28f93c",
    "semantic_title": "fast minimization of expected logarithmic loss via stochastic dual averaging",
    "citation_count": 0,
    "authors": [
      "Chung-En Tsai",
      "Hao-Chung Cheng",
      "Yen-Huan Li"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24h.html": {
    "title": "Discriminant Distance-Aware Representation on Deterministic Uncertainty Quantification Methods",
    "volume": "main",
    "abstract": "Uncertainty estimation is a crucial aspect of deploying dependable deep learning models in safety-critical systems. In this study, we introduce a novel and efficient method for deterministic uncertainty estimation called Discriminant Distance-Awareness Representation (DDAR). Our approach involves constructing a DNN model that incorporates a set of prototypes in its latent representations, enabling us to analyze valuable feature information from the input data. By leveraging a distinction maximization layer over optimal trainable prototypes, DDAR can learn a discriminant distance-awareness representation. We demonstrate that DDAR overcomes feature collapse by relaxing the Lipschitz constraint that hinders the practicality of deterministic uncertainty methods (DUMs) architectures. Our experiments show that DDAR is a flexible and architecture-agnostic method that can be easily integrated as a pluggable layer with distance-sensitive metrics, outperforming state-of-the-art uncertainty estimation methods on multiple benchmark problems",
    "checked": true,
    "id": "606fe3fe3a2ad7056835830a0b3699ea9bb4cdaa",
    "semantic_title": "discriminant distance-aware representation on deterministic uncertainty quantification methods",
    "citation_count": 0,
    "authors": [
      "Jiaxin Zhang",
      "Kamalika Das",
      "Sricharan Kumar"
    ]
  },
  "https://proceedings.mlr.press/v238/haussmann24a.html": {
    "title": "Estimating treatment effects from single-arm trials via latent-variable modeling",
    "volume": "main",
    "abstract": "Randomized controlled trials (RCTs) are the accepted standard for treatment effect estimation but they can be infeasible due to ethical reasons and prohibitive costs. Single-arm trials, where all patients belong to the treatment group, can be a viable alternative but require access to an external control group. We propose an identifiable deep latent-variable model for this scenario that can also account for missing covariate observations by modeling their structured missingness patterns. Our method uses amortized variational inference to learn both group-specific and identifiable shared latent representations, which can subsequently be used for {\\em (i)} patient matching if treatment outcomes are not available for the treatment group, or for {\\em (ii)} direct treatment effect estimation assuming outcomes are available for both groups. We evaluate the model on a public benchmark as well as on a data set consisting of a published RCT study and real-world electronic health records. Compared to previous methods, our results show improved performance both for direct treatment effect estimation as well as for effect estimation via patient matching",
    "checked": true,
    "id": "e2529c28b090e4b505e72edb28fb751f2957c286",
    "semantic_title": "estimating treatment effects from single-arm trials via latent-variable modeling",
    "citation_count": 0,
    "authors": [
      "Manuel Haussmann",
      "Tran Minh Son Le",
      "Viivi Halla-aho",
      "Samu Kurki",
      "Jussi Leinonen",
      "Miika Koskinen",
      "Samuel Kaski",
      "Harri Lähdesmäki"
    ]
  },
  "https://proceedings.mlr.press/v238/kuang24a.html": {
    "title": "Unveiling Latent Causal Rules: A Temporal Point Process Approach for Abnormal Event Explanation",
    "volume": "main",
    "abstract": "In high-stakes systems such as healthcare, it is critical to understand the causal reasons behind unusual events, such as sudden changes in patient's health. Unveiling the causal reasons helps with quick diagnoses and precise treatment planning. In this paper, we propose an automated method for uncovering \"if-then\" logic rules to explain observational events. We introduce {\\it temporal point processes} to model the events of interest, and discover the set of latent rules to explain the occurrence of events. To achieve this goal, we employ an Expectation-Maximization (EM) algorithm. In the E-step, we calculate the posterior probability of each event being explained by each discovered rule. In the M-step, we update both the rule set and model parameters to enhance the likelihood function's lower bound. Notably, we will optimize the rule set in a {\\it differential} manner. Our approach demonstrates accurate performance in both discovering rules and identifying root causes. We showcase its promising results using synthetic and real healthcare datasets",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiling Kuang",
      "Chao Yang",
      "Yang Yang",
      "Shuang Li"
    ]
  },
  "https://proceedings.mlr.press/v238/chaouki24a.html": {
    "title": "Online Learning of Decision Trees with Thompson Sampling",
    "volume": "main",
    "abstract": "Decision Trees are prominent prediction models for interpretable Machine Learning. They have been thoroughly researched, mostly in the batch setting with a fixed labelled dataset, leading to popular algorithms such as C4.5, ID3 and CART. Unfortunately, these methods are of heuristic nature, they rely on greedy splits offering no guarantees of global optimality and often leading to unnecessarily complex and hard-to-interpret Decision Trees. Recent breakthroughs addressed this suboptimality issue in the batch setting, but no such work has considered the online setting with data arriving in a stream. To this end, we devise a new Monte Carlo Tree Search algorithm, Thompson Sampling Decision Trees (TSDT), able to produce optimal Decision Trees in an online setting. We analyse our algorithm and prove its almost sure convergence to the optimal tree. Furthermore, we conduct extensive experiments to validate our findings empirically. The proposed TSDT outperforms existing algorithms on several benchmarks, all while presenting the practical advantage of being tailored to the online setting",
    "checked": true,
    "id": "374804565d6c1f8a4abbbe3edb08a293082426e1",
    "semantic_title": "online learning of decision trees with thompson sampling",
    "citation_count": 1,
    "authors": [
      "Ayman Chaouki",
      "Jesse Read",
      "Albert Bifet"
    ]
  },
  "https://proceedings.mlr.press/v238/yang24c.html": {
    "title": "Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias",
    "volume": "main",
    "abstract": "Neural networks trained with (stochastic) gradient descent have an inductive bias towards learning simpler solutions. This makes them highly prone to learning spurious correlations in the training data, that may not hold at test time. In this work, we provide the first theoretical analysis of the effect of simplicity bias on learning spurious correlations. Notably, we show that examples with spurious features are provably separable based on the model's output early in training. We further illustrate that if spurious features have a small enough noise-to-signal ratio, the network's output on majority of examples is almost exclusively determined by the spurious features, leading to poor worst-group test accuracy. Finally, we propose SPARE, which identifies spurious correlations early in training, and utilizes importance sampling to alleviate their effect. Empirically, we demonstrate that SPARE outperforms state-of-the-art methods by up to 21.1% in worst-group accuracy, while being up to 12x faster. We also show the applicability of SPARE, as a highly effective but lightweight method, to discover spurious correlations",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Yang",
      "Eric Gan",
      "Gintare Karolina Dziugaite",
      "Baharan Mirzasoleiman"
    ]
  },
  "https://proceedings.mlr.press/v238/mukherjee24a.html": {
    "title": "SPEED: Experimental Design for Policy Evaluation in Linear Heteroscedastic Bandits",
    "volume": "main",
    "abstract": "In this paper, we study the problem of optimal data collection for policy evaluation in linear bandits. In policy evaluation, we are given a \\textit{target} policy and asked to estimate the expected reward it will obtain when executed in a multi-armed bandit environment. Our work is the first work that focuses on such an optimal data collection strategy for policy evaluation involving heteroscedastic reward noise in the linear bandit setting. We first formulate an optimal design for weighted least squares estimates in the heteroscedastic linear bandit setting with the knowledge of noise variances. This design minimizes the mean squared error (MSE) of the estimated value of the target policy and is termed the oracle design. Since the noise variance is typically unknown, we then introduce a novel algorithm, SPEED (\\textbf{S}tructured \\textbf{P}olicy \\textbf{E}valuation \\textbf{E}xperimental \\textbf{D}esign), that tracks the oracle design and derive its regret with respect to the oracle design. We show that regret scales as $\\widetilde{O}_{}(d^3 n^{-3/2})$ and prove a matching lower bound of $\\Omega(d^2 n^{-3/2})$. Finally, we evaluate SPEED on a set of policy evaluation tasks and demonstrate that it achieves MSE comparable to an optimal oracle and much lower than simply running the target policy",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Subhojyoti Mukherjee",
      "Qiaomin Xie",
      "Josiah P Hanna",
      "Robert Nowak"
    ]
  },
  "https://proceedings.mlr.press/v238/ebrahimpour-boroojeny24a.html": {
    "title": "Spectrum Extraction and Clipping for Implicitly Linear Layers",
    "volume": "main",
    "abstract": "We show the effectiveness of automatic differentiation in efficiently and correctly computing and controlling the spectrum of implicitly linear operators, a rich family of layer types including all standard convolutional and dense layers. We provide the first clipping method which is correct for general convolution layers, and illuminate the representational limitation that caused correctness issues in prior work. We study the effect of the batch normalization layers when concatenated with convolutional layers and show how our clipping method can be applied to their composition. By comparing the accuracy and performance of our algorithms to the state-of-the-art methods, using various experiments, we show they are more precise and efficient and lead to better generalization and adversarial robustness. We provide the code for using our methods at https://github.com/Ali-E/FastClip",
    "checked": true,
    "id": "81e5a928d99bb7c23634ce7b0bb656224f3023a0",
    "semantic_title": "spectrum extraction and clipping for implicitly linear layers",
    "citation_count": 0,
    "authors": [
      "Ali Ebrahimpour Boroojeny",
      "Matus Telgarsky",
      "Hari Sundaram"
    ]
  },
  "https://proceedings.mlr.press/v238/alizadeh24a.html": {
    "title": "Pessimistic Off-Policy Multi-Objective Optimization",
    "volume": "main",
    "abstract": "Multi-objective optimization is a class of optimization problems with multiple conflicting objectives. We study offline optimization of multi-objective policies from data collected by a previously deployed policy. We propose a pessimistic estimator for policy values that can be easily plugged into existing formulas for hypervolume computation and optimized. The estimator is based on inverse propensity scores (IPS), and improves upon a naive IPS estimator in both theory and experiments. Our analysis is general, and applies beyond our IPS estimators and methods for optimizing them",
    "checked": true,
    "id": "9b1e473daac9c1452dae0c1465068a1f95eda51f",
    "semantic_title": "pessimistic off-policy multi-objective optimization",
    "citation_count": 0,
    "authors": [
      "Shima Alizadeh",
      "Aniruddha Bhargava",
      "Karthick Gopalswamy",
      "Lalit Jain",
      "Branislav Kveton",
      "Ge Liu"
    ]
  },
  "https://proceedings.mlr.press/v238/mogensen24a.html": {
    "title": "Faithful graphical representations of local independence",
    "volume": "main",
    "abstract": "Graphical models use graphs to represent conditional independence structure in the distribution of a random vector. In stochastic processes, graphs may represent so-called local independence or conditional Granger causality. Under some regularity conditions, a local independence graph implies a set of independences using a graphical criterion known as delta-separation, or using its generalization, mu-separation. This is a stochastic process analogue of d-separation in DAGs. However, there may be more independences than implied by this graph and this is a violation of so-called faithfulness. We characterize faithfulness in local independence graphs and give a method to construct a faithful graph from any local independence model such that the output equals the true graph when Markov and faithfulness assumptions hold. We discuss various assumptions that are weaker than faithfulness, and we explore different structure learning algorithms and their properties under varying assumptions",
    "checked": true,
    "id": "6eca433256fe68bb516aa264ab8ef50543158fec",
    "semantic_title": "faithful graphical representations of local independence",
    "citation_count": 0,
    "authors": [
      "Søren W. Mogensen"
    ]
  },
  "https://proceedings.mlr.press/v238/manh-bui24a.html": {
    "title": "Density-Regression: Efficient and Distance-aware Deep Regressor for Uncertainty Estimation under Distribution Shifts",
    "volume": "main",
    "abstract": "Morden deep ensembles technique achieves strong uncertainty estimation performance by going through multiple forward passes with different models. This is at the price of a high storage space and a slow speed in the inference (test) time. To address this issue, we propose Density-Regression, a method that leverages the density function in uncertainty estimation and achieves fast inference by a single forward pass. We prove it is distance aware on the feature space, which is a necessary condition for a neural network to produce high-quality uncertainty estimation under distribution shifts. Empirically, we conduct experiments on regression tasks with the cubic toy dataset, benchmark UCI, weather forecast with time series, and depth estimation under real-world shifted applications. We show that Density-Regression has competitive uncertainty estimation performance under distribution shifts with modern deep regressors while using a lower model size and a faster inference speed",
    "checked": true,
    "id": "7745c7ab26d68738f8932d88806a1e9701d99b7e",
    "semantic_title": "density-regression: efficient and distance-aware deep regressor for uncertainty estimation under distribution shifts",
    "citation_count": 2,
    "authors": [
      "Ha Manh Bui",
      "Anqi Liu"
    ]
  },
  "https://proceedings.mlr.press/v238/viallard24a.html": {
    "title": "Leveraging PAC-Bayes Theory and Gibbs Distributions for Generalization Bounds with Complexity Measures",
    "volume": "main",
    "abstract": "In statistical learning theory, a generalization bound usually involves a complexity measure imposed by the considered theoretical framework. This limits the scope of such bounds, as other forms of capacity measures or regularizations are used in algorithms. In this paper, we leverage the framework of disintegrated PAC-Bayes bounds to derive a general generalization bound instantiable with arbitrary complexity measures. One trick to prove such a result involves considering a commonly used family of distributions: the Gibbs distributions. Our bound stands in probability jointly over the hypothesis and the learning sample, which allows the complexity to be adapted to the generalization gap as it can be customized to fit both the hypothesis class and the task",
    "checked": true,
    "id": "96cbf6e1e15a4eec937e25e80b68e3985406ba42",
    "semantic_title": "leveraging pac-bayes theory and gibbs distributions for generalization bounds with complexity measures",
    "citation_count": 0,
    "authors": [
      "Paul Viallard",
      "Rémi Emonet",
      "Amaury Habrard",
      "Emilie Morvant",
      "Valentina Zantedeschi"
    ]
  },
  "https://proceedings.mlr.press/v238/olmin24a.html": {
    "title": "On the connection between Noise-Contrastive Estimation and Contrastive Divergence",
    "volume": "main",
    "abstract": "Noise-contrastive estimation (NCE) is a popular method for estimating unnormalised probabilistic models, such as energy-based models, which are effective for modelling complex data distributions. Unlike classical maximum likelihood (ML) estimation that relies on importance sampling (resulting in ML-IS) or MCMC (resulting in contrastive divergence, CD), NCE uses a proxy criterion to avoid the need for evaluating an often intractable normalisation constant. Despite apparent conceptual differences, we show that two NCE criteria, ranking NCE (RNCE) and conditional NCE (CNCE), can be viewed as ML estimation methods. Specifically, RNCE is equivalent to ML estimation combined with conditional importance sampling, and both RNCE and CNCE are special cases of CD. These findings bridge the gap between the two method classes and allow us to apply techniques from the ML-IS and CD literature to NCE, offering several advantageous extensions",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amanda Olmin",
      "Jakob Lindqvist",
      "Lennart Svensson",
      "Fredrik Lindsten"
    ]
  },
  "https://proceedings.mlr.press/v238/zhou24b.html": {
    "title": "Reward-Relevance-Filtered Linear Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Angela Zhou"
    ]
  },
  "https://proceedings.mlr.press/v238/rashid24a.html": {
    "title": "Preventing Arbitrarily High Confidence on Far-Away Data in Point-Estimated Discriminative Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmad Rashid",
      "Serena Hacker",
      "Guojun Zhang",
      "Agustinus Kristiadi",
      "Pascal Poupart"
    ]
  },
  "https://proceedings.mlr.press/v238/tang24c.html": {
    "title": "Stochastic Multi-Armed Bandits with Strongly Reward-Dependent Delays",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifu Tang",
      "Yingfei Wang",
      "Zeyu Zheng"
    ]
  },
  "https://proceedings.mlr.press/v238/grosse24a.html": {
    "title": "A Greedy Approximation for k-Determinantal Point Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julia Grosse",
      "Rahel Fischer",
      "Roman Garnett",
      "Philipp Hennig"
    ]
  },
  "https://proceedings.mlr.press/v238/li24n.html": {
    "title": "Improved Algorithm for Adversarial Linear Mixture MDPs with Bandit Feedback and Unknown Transition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Long-Fei Li",
      "Peng Zhao",
      "Zhi-Hua Zhou"
    ]
  },
  "https://proceedings.mlr.press/v238/karagozlu24a.html": {
    "title": "Learning the Pareto Set Under Incomplete Preferences: Pure Exploration in Vector Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Efe Mert Karagözlü",
      "Yaşar Cahit Yıldırım",
      "Cağın Ararat",
      "Cem Tekin"
    ]
  },
  "https://proceedings.mlr.press/v238/hendrikx24a.html": {
    "title": "The Relative Gaussian Mechanism and its Application to Private Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hadrien Hendrikx",
      "Paul Mangold",
      "Aurélien Bellet"
    ]
  },
  "https://proceedings.mlr.press/v238/haan24a.html": {
    "title": "Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pim de Haan",
      "Taco Cohen",
      "Johann Brehmer"
    ]
  },
  "https://proceedings.mlr.press/v238/mondal24a.html": {
    "title": "Improved Sample Complexity Analysis of Natural Policy Gradient Algorithm with General Parameterization for Infinite Horizon Discounted Reward Markov Decision Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Washim U. Mondal",
      "Vaneet Aggarwal"
    ]
  },
  "https://proceedings.mlr.press/v238/yamada24a.html": {
    "title": "Learning Fair Division from Bandit Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hakuei Yamada",
      "Junpei Komiyama",
      "Kenshi Abe",
      "Atsushi Iwasaki"
    ]
  },
  "https://proceedings.mlr.press/v238/le24a.html": {
    "title": "Optimal Transport for Measures with Noisy Tree Metric",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tam Le",
      "Truyen Nguyen",
      "Kenji Fukumizu"
    ]
  },
  "https://proceedings.mlr.press/v238/salaudeen24a.html": {
    "title": "Causally Inspired Regularization Enables Domain General Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Olawale Salaudeen",
      "Sanmi Koyejo"
    ]
  },
  "https://proceedings.mlr.press/v238/dheur24a.html": {
    "title": "Probabilistic Calibration by Design for Neural Network Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Victor Dheur",
      "Souhaib Ben Taieb"
    ]
  },
  "https://proceedings.mlr.press/v238/maddux24a.html": {
    "title": "Multi-Agent Learning in Contextual Games under Unknown Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anna M. Maddux",
      "Maryam Kamgarpour"
    ]
  },
  "https://proceedings.mlr.press/v238/bateni24a.html": {
    "title": "A Scalable Algorithm for Individually Fair k-Means Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "MohammadHossein Bateni",
      "Vincent Cohen-Addad",
      "Alessandro Epasto",
      "Silvio Lattanzi"
    ]
  },
  "https://proceedings.mlr.press/v238/eich24a.html": {
    "title": "Approximate Control for Continuous-Time POMDPs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yannick Eich",
      "Bastian Alt",
      "Heinz Koeppl"
    ]
  },
  "https://proceedings.mlr.press/v238/gabbianelli24a.html": {
    "title": "Offline Primal-Dual Reinforcement Learning for Linear MDPs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Germano Gabbianelli",
      "Gergely Neu",
      "Matteo Papini",
      "Nneka M Okolo"
    ]
  },
  "https://proceedings.mlr.press/v238/souveton24a.html": {
    "title": "Fixed-kinetic Neural Hamiltonian Flows for enhanced interpretability and reduced complexity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Souveton",
      "Arnaud Guillin",
      "Jens Jasche",
      "Guilhem Lavaux",
      "Manon Michel"
    ]
  },
  "https://proceedings.mlr.press/v238/yang24d.html": {
    "title": "Learning Unknown Intervention Targets in Structural Causal Models from Heterogeneous Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqin Yang",
      "Saber Salehkaleybar",
      "Negar Kiyavash"
    ]
  },
  "https://proceedings.mlr.press/v238/lee24b.html": {
    "title": "XB-MAML: Learning Expandable Basis Parameters for Effective Meta-Learning with Wide Task Coverage",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jae-Jun Lee",
      "Sung Whan Yoon"
    ]
  },
  "https://proceedings.mlr.press/v238/eldowa24a.html": {
    "title": "General Tail Bounds for Non-Smooth Stochastic Mirror Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khaled Eldowa",
      "Andrea Paudice"
    ]
  },
  "https://proceedings.mlr.press/v238/flach24a.html": {
    "title": "Symmetric Equilibrium Learning of VAEs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boris Flach",
      "Dmitrij Schlesinger",
      "Alexander Shekhovtsov"
    ]
  },
  "https://proceedings.mlr.press/v238/zhao24b.html": {
    "title": "On Feynman-Kac training of partial Bayesian neural networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Zhao",
      "Sebastian Mair",
      "Thomas B. Schön",
      "Jens Sjölund"
    ]
  },
  "https://proceedings.mlr.press/v238/losalka24a.html": {
    "title": "No-Regret Algorithms for Safe Bayesian Optimization with Monotonicity Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arpan Losalka",
      "Jonathan Scarlett"
    ]
  },
  "https://proceedings.mlr.press/v238/augusto-zagatti24a.html": {
    "title": "Learning multivariate temporal point processes via the time-change theorem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guilherme Augusto Zagatti",
      "See Kiong Ng",
      "Stéphane Bressan"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24g.html": {
    "title": "Model-based Policy Optimization under Approximate Bayesian Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoqi Wang",
      "Yuxin Chen",
      "Kevin Murphy"
    ]
  },
  "https://proceedings.mlr.press/v238/zeng24a.html": {
    "title": "SDMTR: A Brain-inspired Transformer for Relation Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyu Zeng",
      "Jie Lin",
      "Piao Hu",
      "Zhihao Li",
      "Tianxi Huang"
    ]
  },
  "https://proceedings.mlr.press/v238/ma24b.html": {
    "title": "Directed Hypergraph Representation Learning for Link Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zitong Ma",
      "Wenbo Zhao",
      "Zhe Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24i.html": {
    "title": "Formal Verification of Unknown Stochastic Systems via Non-parametric Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Zhang",
      "Chenyu Ma",
      "Saleh Soudijani",
      "Sadegh Soudjani"
    ]
  },
  "https://proceedings.mlr.press/v238/kviman24a.html": {
    "title": "Variational Resampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oskar Kviman",
      "Nicola Branchini",
      "Víctor Elvira",
      "Jens Lagergren"
    ]
  },
  "https://proceedings.mlr.press/v238/sander24a.html": {
    "title": "Implicit Bias in Noisy-SGD: With Applications to Differentially Private Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tom Sander",
      "Maxime Sylvestre",
      "Alain Durmus"
    ]
  },
  "https://proceedings.mlr.press/v238/peshekhonov24a.html": {
    "title": "Training a Tucker Model With Shared Factors: a Riemannian Optimization Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivan Peshekhonov",
      "Aleksey Arzhantsev",
      "Maxim Rakhuba"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24h.html": {
    "title": "Don't Be Pessimistic Too Early: Look K Steps Ahead!",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoqi Wang",
      "Ziyu Ye",
      "Kevin Murphy",
      "Yuxin Chen"
    ]
  },
  "https://proceedings.mlr.press/v238/garcia-carrasco24a.html": {
    "title": "How does GPT-2 Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jorge García-Carrasco",
      "Alejandro Maté",
      "Juan Carlos Trujillo"
    ]
  },
  "https://proceedings.mlr.press/v238/halva24a.html": {
    "title": "Identifiable Feature Learning for Spatial Data with Nonlinear ICA",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hermanni Hälvä",
      "Jonathan So",
      "Richard E. Turner",
      "Aapo Hyvärinen"
    ]
  },
  "https://proceedings.mlr.press/v238/katta24a.html": {
    "title": "Interpretable Causal Inference for Analyzing Wearable, Sensor, and Distributional Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Srikar Katta",
      "Harsh Parikh",
      "Cynthia Rudin",
      "Alexander Volfovsky"
    ]
  },
  "https://proceedings.mlr.press/v238/chandramoorthy24a.html": {
    "title": "Score Operator Newton transport",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nisha Chandramoorthy",
      "Florian T Schaefer",
      "Youssef M Marzouk"
    ]
  },
  "https://proceedings.mlr.press/v238/novitasari24a.html": {
    "title": "ALAS: Active Learning for Autoconversion Rates Prediction from Satellite Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maria C. Novitasari",
      "Johannes Quaas",
      "Miguel Rodrigues"
    ]
  },
  "https://proceedings.mlr.press/v238/verine24a.html": {
    "title": "Optimal Budgeted Rejection Sampling for Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexandre Verine",
      "Muni Sreenivas Pydi",
      "Benjamin Negrevergne",
      "Yann Chevaleyre"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24e.html": {
    "title": "Posterior Uncertainty Quantification in Neural Networks using Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luhuan Wu",
      "Sinead A Williamson"
    ]
  },
  "https://proceedings.mlr.press/v238/zhao24c.html": {
    "title": "DHMConv: Directed Hypergraph Momentum Convolution Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenbo Zhao",
      "Zitong Ma",
      "Zhe Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/jager24a.html": {
    "title": "From Data Imputation to Data Cleaning — Automated Cleaning of Tabular Data Improves Downstream Predictive Performance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sebastian Jäger",
      "Felix Biessmann"
    ]
  },
  "https://proceedings.mlr.press/v238/ekstrom-kelvinius24a.html": {
    "title": "Discriminator Guidance for Autoregressive Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Filip Ekström Kelvinius",
      "Fredrik Lindsten"
    ]
  },
  "https://proceedings.mlr.press/v238/ding24a.html": {
    "title": "Resilient Constrained Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongsheng Ding",
      "Zhengyan Huan",
      "Alejandro Ribeiro"
    ]
  },
  "https://proceedings.mlr.press/v238/jeong24a.html": {
    "title": "On-Demand Federated Learning for Arbitrary Target Class Distributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Isu Jeong",
      "Seulki Lee"
    ]
  },
  "https://proceedings.mlr.press/v238/shukla24a.html": {
    "title": "DiffRed: Dimensionality reduction guided by stable rank",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prarabdh Shukla",
      "Gagan Raj Gupta",
      "Kunal Dutta"
    ]
  },
  "https://proceedings.mlr.press/v238/tamas24a.html": {
    "title": "Data-Driven Confidence Intervals with Optimal Rates for the Mean of Heavy-Tailed Distributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ambrus Tamás",
      "Szabolcs Szentpéteri",
      "Balázs Csáji"
    ]
  },
  "https://proceedings.mlr.press/v238/zakerinia24a.html": {
    "title": "Communication-Efficient Federated Learning With Data and Client Heterogeneity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hossein Zakerinia",
      "Shayan Talaei",
      "Giorgi Nadiradze",
      "Dan Alistarh"
    ]
  },
  "https://proceedings.mlr.press/v238/fraboni24a.html": {
    "title": "SIFU: Sequential Informed Federated Unlearning for Efficient and Provable Client Unlearning in Federated Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yann Fraboni",
      "Martin Van Waerebeke",
      "Kevin Scaman",
      "Richard Vidal",
      "Laetitia Kameni",
      "Marco Lorenzi"
    ]
  },
  "https://proceedings.mlr.press/v238/popordanoska24a.html": {
    "title": "Consistent and Asymptotically Unbiased Estimation of Proper Calibration Errors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Teodora Popordanoska",
      "Sebastian Gregor Gruber",
      "Aleksei Tiulpin",
      "Florian Buettner",
      "Matthew B. Blaschko"
    ]
  },
  "https://proceedings.mlr.press/v238/tailor24a.html": {
    "title": "Learning to Defer to a Population: A Meta-Learning Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dharmesh Tailor",
      "Aditya Patra",
      "Rajeev Verma",
      "Putra Manggala",
      "Eric Nalisnick"
    ]
  },
  "https://proceedings.mlr.press/v238/li24o.html": {
    "title": "Trigonometric Quadrature Fourier Features for Scalable Gaussian Process Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin Li",
      "Max Balakirsky",
      "Simon Mak"
    ]
  },
  "https://proceedings.mlr.press/v238/fatkhullin24a.html": {
    "title": "Taming Nonconvex Stochastic Mirror Descent with General Bregman Divergence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ilyas Fatkhullin",
      "Niao He"
    ]
  },
  "https://proceedings.mlr.press/v238/rashidi24a.html": {
    "title": "Cylindrical Thompson Sampling for High-Dimensional Bayesian Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bahador Rashidi",
      "Kerrick Johnstonbaugh",
      "Chao Gao"
    ]
  },
  "https://proceedings.mlr.press/v238/patil24b.html": {
    "title": "On learning history-based policies for controlling Markov decision processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gandharv Patil",
      "Aditya Mahajan",
      "Doina Precup"
    ]
  },
  "https://proceedings.mlr.press/v238/kolpaczki24a.html": {
    "title": "SVARM-IQ: Efficient Approximation of Any-order Shapley Interactions through Stratification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patrick Kolpaczki",
      "Maximilian Muschalik",
      "Fabian Fumagalli",
      "Barbara Hammer",
      "Eyke Hüllermeier"
    ]
  },
  "https://proceedings.mlr.press/v238/chauhan24a.html": {
    "title": "Dynamic Inter-treatment Information Sharing for Individualized Treatment Effects Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vinod Kumar Chauhan",
      "Jiandong Zhou",
      "Ghadeer Ghosheh",
      "Soheila Molaei",
      "David A Clifton"
    ]
  },
  "https://proceedings.mlr.press/v238/hotti24a.html": {
    "title": "Benefits of Non-Linear Scale Parameterizations in Black Box Variational Inference through Smoothness Results and Gradient Variance Bounds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexandra Maria Hotti",
      "Lennart Alexander Van der Goten",
      "Jens Lagergren"
    ]
  },
  "https://proceedings.mlr.press/v238/mitarchuk24a.html": {
    "title": "Length independent PAC-Bayes bounds for Simple RNNs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Volodimir Mitarchuk",
      "Clara Lacroce",
      "Rémi Eyraud",
      "Rémi Emonet",
      "Amaury Habrard",
      "Guillaume Rabusseau"
    ]
  },
  "https://proceedings.mlr.press/v238/papazov24a.html": {
    "title": "Leveraging Continuous Time to Understand Momentum When Training Diagonal Linear Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hristo Papazov",
      "Scott Pesme",
      "Nicolas Flammarion"
    ]
  },
  "https://proceedings.mlr.press/v238/nitanda24a.html": {
    "title": "Why is parameter averaging beneficial in SGD? An objective smoothing perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atsushi Nitanda",
      "Ryuhei Kikuchi",
      "Shugo Maeda",
      "Denny Wu"
    ]
  },
  "https://proceedings.mlr.press/v238/shingaki24a.html": {
    "title": "Identification and Estimation of \"Causes of Effects\" using Covariate-Mediator Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryusei Shingaki",
      "Manabu Kuroki"
    ]
  },
  "https://proceedings.mlr.press/v238/crepon24a.html": {
    "title": "Sequential learning of the Pareto front for multi-objective bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "élise crepon",
      "Aurélien Garivier",
      "Wouter M Koolen"
    ]
  },
  "https://proceedings.mlr.press/v238/chakraborty24b.html": {
    "title": "Equivalence Testing: The Power of Bounded Adaptivity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Diptarka Chakraborty",
      "Sourav Chakraborty",
      "Gunjan Kumar",
      "Kuldeep Meel"
    ]
  },
  "https://proceedings.mlr.press/v238/kacprzyk24a.html": {
    "title": "Shape Arithmetic Expressions: Advancing Scientific Discovery Beyond Closed-Form Equations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Krzysztof Kacprzyk",
      "Mihaela van der Schaar"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24f.html": {
    "title": "On the estimation of persistence intensity functions and linear representations of persistence diagrams",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weichen Wu",
      "Jisu Kim",
      "Alessandro Rinaldo"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24i.html": {
    "title": "Optimal estimation of Gaussian (poly)trees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Wang",
      "Ming Gao",
      "Wai Ming Tai",
      "Bryon Aragam",
      "Arnab Bhattacharyya"
    ]
  },
  "https://proceedings.mlr.press/v238/lee24c.html": {
    "title": "Approximate Bayesian Class-Conditional Models under Continuous Representation Shift",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas L. Lee",
      "Amos Storkey"
    ]
  },
  "https://proceedings.mlr.press/v238/battellani24a.html": {
    "title": "Dissimilarity Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paolo Battellani",
      "Alberto Maria Metelli",
      "Francesco Trovò"
    ]
  },
  "https://proceedings.mlr.press/v238/manupriya24a.html": {
    "title": "Consistent Optimal Transport with Empirical Conditional Measures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Piyushi Manupriya",
      "Rachit K. Das",
      "Sayantan Biswas",
      "SakethaNath N Jagarlapudi"
    ]
  },
  "https://proceedings.mlr.press/v238/martin24a.html": {
    "title": "On the Impact of Overparameterization on the Training of a Shallow Neural Network in High Dimensions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Martin",
      "Francis Bach",
      "Giulio Biroli"
    ]
  },
  "https://proceedings.mlr.press/v238/engelmann24a.html": {
    "title": "Mixed Models with Multiple Instance Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan P. Engelmann",
      "Alessandro Palma",
      "Jakub M. Tomczak",
      "Fabian Theis",
      "Francesco Paolo Casale"
    ]
  },
  "https://proceedings.mlr.press/v238/huang24b.html": {
    "title": "Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Huang",
      "Han Zhong",
      "Liwei Wang",
      "Lin Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/emmanouilidis24a.html": {
    "title": "Stochastic Extragradient with Random Reshuffling: Improved Convergence for Variational Inequalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Konstantinos Emmanouilidis",
      "Rene Vidal",
      "Nicolas Loizou"
    ]
  },
  "https://proceedings.mlr.press/v238/lyu24a.html": {
    "title": "Inconsistency of Cross-Validation for Structure Learning in Gaussian Graphical Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhao Lyu",
      "Wai Ming Tai",
      "Mladen Kolar",
      "Bryon Aragam"
    ]
  },
  "https://proceedings.mlr.press/v238/kalemaj24a.html": {
    "title": "Differentially Private Conditional Independence Testing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Iden Kalemaj",
      "Shiva Kasiviswanathan",
      "Aaditya Ramdas"
    ]
  },
  "https://proceedings.mlr.press/v238/scaman24a.html": {
    "title": "Minimax Excess Risk of First-Order Methods for Statistical Learning with Data-Dependent Oracles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin Scaman",
      "Mathieu Even",
      "Batiste Le Bars",
      "Laurent Massoulie"
    ]
  },
  "https://proceedings.mlr.press/v238/abedsoltan24a.html": {
    "title": "On the Nyström Approximation for Preconditioning in Kernel Machines",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amirhesam Abedsoltan",
      "Parthe Pandit",
      "Luis Rademacher",
      "Mikhail Belkin"
    ]
  },
  "https://proceedings.mlr.press/v238/kamran24a.html": {
    "title": "Learning to Rank for Optimal Treatment Allocation Under Resource Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fahad Kamran",
      "Maggie Makar",
      "Jenna Wiens"
    ]
  },
  "https://proceedings.mlr.press/v238/oesterling24a.html": {
    "title": "Fair Machine Unlearning: Data Removal while Mitigating Disparities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Oesterling",
      "Jiaqi Ma",
      "Flavio Calmon",
      "Himabindu Lakkaraju"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24j.html": {
    "title": "On the Effect of Key Factors in Spurious Correlation: A theoretical Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yipei Wang",
      "Xiaoqian Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/yang24e.html": {
    "title": "Hodge-Compositional Edge Gaussian Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maosheng Yang",
      "Viacheslav Borovitskiy",
      "Elvin Isufi"
    ]
  },
  "https://proceedings.mlr.press/v238/tsiourvas24a.html": {
    "title": "Manifold-Aligned Counterfactual Explanations for Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Asterios Tsiourvas",
      "Wei Sun",
      "Georgia Perakis"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24j.html": {
    "title": "Fast and Accurate Estimation of Low-Rank Matrices from Noisy Measurements via Preconditioned Non-Convex Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialun Zhang",
      "Richard Y Zhang",
      "Hong-Ming Chiu"
    ]
  },
  "https://proceedings.mlr.press/v238/murti24a.html": {
    "title": "LP-based Construction of DC Decompositions for Efficient Inference of Markov Random Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaitanya Murti",
      "Dhruva Kashyap",
      "Chiranjib Bhattacharyya"
    ]
  },
  "https://proceedings.mlr.press/v238/nazaret24a.html": {
    "title": "On the Misspecification of Linear Assumptions in Synthetic Controls",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Achille O. R. Nazaret",
      "Claudia Shi",
      "David Blei"
    ]
  },
  "https://proceedings.mlr.press/v238/carmon24a.html": {
    "title": "The sample complexity of ERMs in stochastic convex optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Carmon",
      "Amir Yehudayoff",
      "Roi Livni"
    ]
  },
  "https://proceedings.mlr.press/v238/pasarkar24a.html": {
    "title": "Cousins Of The Vendi Score: A Family Of Similarity-Based Diversity Metrics For Science And Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amey P. Pasarkar",
      "Adji Bousso Dieng"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24k.html": {
    "title": "On cyclical MCMC sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liwei Wang",
      "Xinru Liu",
      "Aaron Smith",
      "Aguemon Y Atchade"
    ]
  },
  "https://proceedings.mlr.press/v238/john-ward24a.html": {
    "title": "FairRR: Pre-Processing for Group Fairness through Randomized Response",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joshua John Ward",
      "Xianli Zeng",
      "Guang Cheng"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24e.html": {
    "title": "Fitting ARMA Time Series Models without Identification: A Proximal Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yin Liu",
      "Sam Davanloo Tajbakhsh"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24g.html": {
    "title": "Unsupervised Change Point Detection in Multivariate Time Series",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daoping Wu",
      "Suhas Gundimeda",
      "Shaoshuai Mou",
      "Christopher Quinn"
    ]
  },
  "https://proceedings.mlr.press/v238/ferbach24a.html": {
    "title": "Proving Linear Mode Connectivity of Neural Networks via Optimal Transport",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Damien Ferbach",
      "Baptiste Goujaud",
      "Gauthier Gidel",
      "Aymeric Dieuleveut"
    ]
  },
  "https://proceedings.mlr.press/v238/ren24b.html": {
    "title": "Multi-objective Optimization via Wasserstein-Fisher-Rao Gradient Flow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinuo Ren",
      "Tesi Xiao",
      "Tanmay Gangwani",
      "Anshuka Rangi",
      "Holakou Rahmanian",
      "Lexing Ying",
      "Subhajit Sanyal"
    ]
  },
  "https://proceedings.mlr.press/v238/guilmeau24a.html": {
    "title": "Adaptive importance sampling for heavy-tailed distributions via $α$-divergence minimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Guilmeau",
      "Nicola Branchini",
      "Emilie Chouzenoux",
      "Victor Elvira"
    ]
  },
  "https://proceedings.mlr.press/v238/jafarnia-jahromi24a.html": {
    "title": "A Bayesian Learning Algorithm for Unknown Zero-sum Stochastic Games with an Arbitrary Opponent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehdi Jafarnia Jahromi",
      "Rahul A Jain",
      "Ashutosh Nayyar"
    ]
  },
  "https://proceedings.mlr.press/v238/cai24a.html": {
    "title": "Near-Optimal Policy Optimization for Correlated Equilibrium in General-Sum Markov Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Cai",
      "Haipeng Luo",
      "Chen-Yu Wei",
      "Weiqiang Zheng"
    ]
  },
  "https://proceedings.mlr.press/v238/hanna24a.html": {
    "title": "Multi-Agent Bandit Learning through Heterogeneous Action Erasure Channels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Osama A Hanna",
      "Merve Karakas",
      "Lin Yang",
      "Christina Fragouli"
    ]
  },
  "https://proceedings.mlr.press/v238/shen24b.html": {
    "title": "Efficient Variational Sequential Information Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianwei Shen",
      "Jason Pacheco"
    ]
  },
  "https://proceedings.mlr.press/v238/colaco-carr24a.html": {
    "title": "Conditions on Preference Relations that Guarantee the Existence of Optimal Policies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonathan Colaço Carr",
      "Prakash Panangaden",
      "Doina Precup"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24k.html": {
    "title": "Membership Testing in Markov Equivalence Classes via Independence Queries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqi Zhang",
      "Kirankumar Shiragur",
      "Caroline Uhler"
    ]
  },
  "https://proceedings.mlr.press/v238/kerrigan24a.html": {
    "title": "Functional Flow Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gavin Kerrigan",
      "Giosue Migliorini",
      "Padhraic Smyth"
    ]
  },
  "https://proceedings.mlr.press/v238/bansak24a.html": {
    "title": "Learning Under Random Distributional Shifts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kirk C. Bansak",
      "Elisabeth Paulson",
      "Dominik Rothenhaeusler"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24f.html": {
    "title": "Supervised Feature Selection via Ensemble Gradient Information from Sparse Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiting Liu",
      "Zahra Atashgahi",
      "Ghada Sokar",
      "Mykola Pechenizkiy",
      "Decebal Constantin Mocanu"
    ]
  },
  "https://proceedings.mlr.press/v238/tsai24b.html": {
    "title": "Proxy Methods for Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Katherine Tsai",
      "Stephen R Pfohl",
      "Olawale Salaudeen",
      "Nicole Chiou",
      "Matt Kusner",
      "Alexander D’Amour",
      "Sanmi Koyejo",
      "Arthur Gretton"
    ]
  },
  "https://proceedings.mlr.press/v238/gan24a.html": {
    "title": "Contextual Bandits with Budgeted Information Reveal",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyra Gan",
      "Esmaeil Keyvanshokooh",
      "Xueqing Liu",
      "Susan Murphy"
    ]
  },
  "https://proceedings.mlr.press/v238/zhou24c.html": {
    "title": "Timing as an Action: Learning When to Observe and Act",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Helen Zhou",
      "Audrey Huang",
      "Kamyar Azizzadenesheli",
      "David Childers",
      "Zachary Lipton"
    ]
  },
  "https://proceedings.mlr.press/v238/shen24c.html": {
    "title": "Stochastic Smoothed Gradient Descent Ascent for Federated Minimax Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Shen",
      "Minhui Huang",
      "Jiawei Zhang",
      "Cong Shen"
    ]
  },
  "https://proceedings.mlr.press/v238/xu24a.html": {
    "title": "Online multiple testing with e-values",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyu Xu",
      "Aaditya Ramdas"
    ]
  },
  "https://proceedings.mlr.press/v238/tan24a.html": {
    "title": "Informative Path Planning with Limited Adaptivity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rayen Tan",
      "Rohan Ghuge",
      "Viswanath Nagarajan"
    ]
  },
  "https://proceedings.mlr.press/v238/lion24a.html": {
    "title": "How Good is a Single Basin?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Lion",
      "Lorenzo Noci",
      "Thomas Hofmann",
      "Gregor Bachmann"
    ]
  },
  "https://proceedings.mlr.press/v238/jordan24a.html": {
    "title": "Independent Learning in Constrained Markov Potential Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philip Jordan",
      "Anas Barakat",
      "Niao He"
    ]
  },
  "https://proceedings.mlr.press/v238/erichson24a.html": {
    "title": "NoisyMix: Boosting Model Robustness to Common Corruptions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benjamin Erichson",
      "Soon Hoe Lim",
      "Winnie Xu",
      "Francisco Utrera",
      "Ziang Cao",
      "Michael Mahoney"
    ]
  },
  "https://proceedings.mlr.press/v238/mahmudul-alam24a.html": {
    "title": "Holographic Global Convolutional Networks for Long-Range Prediction Tasks in Malware Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Mahmudul Alam",
      "Edward Raff",
      "Stella R Biderman",
      "Tim Oates",
      "James Holt"
    ]
  },
  "https://proceedings.mlr.press/v238/pichler24a.html": {
    "title": "On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Georg Pichler",
      "Marco Romanelli",
      "Divya Prakash Manivannan",
      "Prashanth Krishnamurthy",
      "Farshad khorrami",
      "Siddharth Garg"
    ]
  },
  "https://proceedings.mlr.press/v238/maunu24a.html": {
    "title": "Acceleration and Implicit Regularization in Gaussian Phase Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tyler Maunu",
      "Martin Molina-Fructuoso"
    ]
  },
  "https://proceedings.mlr.press/v238/oprescu24a.html": {
    "title": "Low-rank MDPs with Continuous Action Spaces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miruna Oprescu",
      "Andrew Bennett",
      "Nathan Kallus"
    ]
  },
  "https://proceedings.mlr.press/v238/zhai24b.html": {
    "title": "Deep Learning-Based Alternative Route Computation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Zhai",
      "Dee Guo",
      "Sreenivas Gollapudi",
      "Kostas Kollias",
      "Daniel Delling"
    ]
  },
  "https://proceedings.mlr.press/v238/wright24a.html": {
    "title": "An Analytic Solution to Covariance Propagation in Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oren Wright",
      "Yorie Nakahira",
      "José M. F. Moura"
    ]
  },
  "https://proceedings.mlr.press/v238/blum24a.html": {
    "title": "On the Vulnerability of Fairness Constrained Learning to Malicious Noise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Avrim Blum",
      "Princewill Okoroafor",
      "Aadirupa Saha",
      "Kevin M. Stangl"
    ]
  },
  "https://proceedings.mlr.press/v238/xu24b.html": {
    "title": "Uncertainty-aware Continuous Implicit Neural Representations for Remote Sensing Object Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Xu",
      "Yucheng Wang",
      "Mingzhou Fan",
      "Byung-Jun Yoon",
      "Xiaoning Qian"
    ]
  },
  "https://proceedings.mlr.press/v238/olsen24a.html": {
    "title": "Think Global, Adapt Local: Learning Locally Adaptive K-Nearest Neighbor Kernel Density Estimators",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kenny Olsen",
      "Rasmus M. Hoeegh Lindrup",
      "Morten Mørup"
    ]
  },
  "https://proceedings.mlr.press/v238/vasileios-vlatakis-gkaragkounis24a.html": {
    "title": "Stochastic Methods in Variational Inequalities: Ergodicity, Bias and Refinements",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emmanouil Vasileios Vlatakis-Gkaragkounis",
      "Angeliki Giannou",
      "Yudong Chen",
      "Qiaomin Xie"
    ]
  },
  "https://proceedings.mlr.press/v238/faller24a.html": {
    "title": "Self-Compatibility: Evaluating Causal Discovery without Ground Truth",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philipp M. Faller",
      "Leena C. Vankadara",
      "Atalanti A. Mastakouri",
      "Francesco Locatello",
      "Dominik Janzing"
    ]
  },
  "https://proceedings.mlr.press/v238/pereyra24a.html": {
    "title": "Equivariant bootstrapping for uncertainty quantification in imaging inverse problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcelo Pereyra",
      "Julián Tachella"
    ]
  },
  "https://proceedings.mlr.press/v238/krichene24a.html": {
    "title": "Private Learning with Public Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Walid Krichene",
      "Nicolas E Mayoraz",
      "Steffen Rendle",
      "Shuang Song",
      "Abhradeep Thakurta",
      "Li Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/mazzetto24a.html": {
    "title": "An Improved Algorithm for Learning Drifting Discrete Distributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessio Mazzetto"
    ]
  },
  "https://proceedings.mlr.press/v238/chae24a.html": {
    "title": "Towards a Complete Benchmark on Video Moment Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyeong Chae",
      "Donghwa Kim",
      "Kwanseok Kim",
      "Doyeon Lee",
      "Sangho Lee",
      "Seongsu Ha",
      "Jonghwan Mun",
      "Wooyoung Kang",
      "Byungseok Roh",
      "Joonseok Lee"
    ]
  },
  "https://proceedings.mlr.press/v238/jali24a.html": {
    "title": "Efficient Reinforcement Learning for Routing Jobs in Heterogeneous Queueing Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neharika Jali",
      "Guannan Qu",
      "Weina Wang",
      "Gauri Joshi"
    ]
  },
  "https://proceedings.mlr.press/v238/reza-karimi24a.html": {
    "title": "Sinkhorn Flow as Mirror Flow: A Continuous-Time Framework for Generalizing the Sinkhorn Algorithm",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Reza Karimi",
      "Ya-Ping Hsieh",
      "Andreas Krause"
    ]
  },
  "https://proceedings.mlr.press/v238/dai24c.html": {
    "title": "SADI: Similarity-Aware Diffusion Model-Based Imputation for Incomplete Temporal EHR Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongyu Dai",
      "Emily Getzen",
      "Qi Long"
    ]
  },
  "https://proceedings.mlr.press/v238/shakerinava24a.html": {
    "title": "Weight-Sharing Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehran Shakerinava",
      "Motahareh MS Sohrabi",
      "Siamak Ravanbakhsh",
      "Simon Lacoste-Julien"
    ]
  },
  "https://proceedings.mlr.press/v238/tiapkin24a.html": {
    "title": "Generative Flow Networks as Entropy-Regularized RL",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniil Tiapkin",
      "Nikita Morozov",
      "Alexey Naumov",
      "Dmitry P Vetrov"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24l.html": {
    "title": "Multi-resolution Time-Series Transformer for Long-term Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yitian Zhang",
      "Liheng Ma",
      "Soumyasundar Pal",
      "Yingxue Zhang",
      "Mark Coates"
    ]
  },
  "https://proceedings.mlr.press/v238/karntikoon24a.html": {
    "title": "First Passage Percolation with Queried Hints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kritkorn Karntikoon",
      "Yiheng Shen",
      "Sreenivas Gollapudi",
      "Kostas Kollias",
      "Aaron Schild",
      "Ali K Sinop"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24g.html": {
    "title": "User-level Differentially Private Stochastic Convex Optimization: Efficient Algorithms with Optimal Rates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daogao Liu",
      "Hilal Asi"
    ]
  },
  "https://proceedings.mlr.press/v238/giaffar24a.html": {
    "title": "The Effective Number of Shared Dimensions Between Paired Datasets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hamza Giaffar",
      "Camille Rullán Buxó",
      "Mikio Aoi"
    ]
  },
  "https://proceedings.mlr.press/v238/luo24a.html": {
    "title": "DE-HNN: An effective neural model for Circuit Netlist representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhishang Luo",
      "Truong Son Hy",
      "Puoya Tabaghi",
      "Michaël Defferrard",
      "Elahe Rezaei",
      "Ryan M. Carey",
      "Rhett Davis",
      "Rajeev Jain",
      "Yusu Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/yao24b.html": {
    "title": "Simulation-Based Stacking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuling Yao",
      "Bruno Régaldo-Saint Blancard",
      "Justin Domke"
    ]
  },
  "https://proceedings.mlr.press/v238/gong24b.html": {
    "title": "Towards Practical Non-Adversarial Distribution Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyu Gong",
      "Ben Usman",
      "Han Zhao",
      "David I Inouye"
    ]
  },
  "https://proceedings.mlr.press/v238/demirel24a.html": {
    "title": "Benchmarking Observational Studies with Experimental Data under Right-Censoring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ilker Demirel",
      "Edward De Brouwer",
      "Zeshan M Hussain",
      "Michael Oberst",
      "Anthony A Philippakis",
      "David Sontag"
    ]
  },
  "https://proceedings.mlr.press/v238/kalantzis24a.html": {
    "title": "Asynchronous Randomized Trace Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vasileios Kalantzis",
      "Shashanka Ubaru",
      "Chai Wah Wu",
      "Georgios Kollias",
      "Lior Horesh"
    ]
  },
  "https://proceedings.mlr.press/v238/li24q.html": {
    "title": "Computing epidemic metrics with edge differential privacy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "George Z. Li",
      "Dung Nguyen",
      "Anil Vullikanti"
    ]
  },
  "https://proceedings.mlr.press/v238/mcnamara24a.html": {
    "title": "Sequential Monte Carlo for Inclusive KL Minimization in Amortized Variational Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Declan McNamara",
      "Jackson Loper",
      "Jeffrey Regier"
    ]
  },
  "https://proceedings.mlr.press/v238/mcmahan24a.html": {
    "title": "Anytime-Constrained Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeremy McMahan",
      "Xiaojin Zhu"
    ]
  },
  "https://proceedings.mlr.press/v238/wen24a.html": {
    "title": "Tensor-view Topological Graph Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Wen",
      "Elynn Chen",
      "Yuzhou Chen"
    ]
  },
  "https://proceedings.mlr.press/v238/byun24a.html": {
    "title": "Auditing Fairness under Unobserved Confounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yewon Byun",
      "Dylan Sam",
      "Michael Oberst",
      "Zachary Lipton",
      "Bryan Wilder"
    ]
  },
  "https://proceedings.mlr.press/v238/koelle24a.html": {
    "title": "Consistency of Dictionary-Based Manifold Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samson J. Koelle",
      "Hanyu Zhang",
      "Octavian-Vlad Murad",
      "Marina Meila"
    ]
  },
  "https://proceedings.mlr.press/v238/chang24a.html": {
    "title": "Probabilistic Modeling for Sequences of Sets in Continuous-Time",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxin Chang",
      "Alex J Boyd",
      "Padhraic Smyth"
    ]
  },
  "https://proceedings.mlr.press/v238/lan24a.html": {
    "title": "Causal Q-Aggregation for CATE Model Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hui Lan",
      "Vasilis Syrgkanis"
    ]
  },
  "https://proceedings.mlr.press/v238/zhao24d.html": {
    "title": "Self-Supervised Quantization-Aware Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiqi Zhao",
      "Ming Zhao"
    ]
  },
  "https://proceedings.mlr.press/v238/meng24a.html": {
    "title": "FALCON: FLOP-Aware Combinatorial Optimization for Neural Network Pruning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Meng",
      "Wenyu Chen",
      "Riade Benbaki",
      "Rahul Mazumder"
    ]
  },
  "https://proceedings.mlr.press/v238/guo24c.html": {
    "title": "The effect of Leaky ReLUs on the training and generalization of overparameterized networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinglong Guo",
      "Shaohan Li",
      "Gilad Lerman"
    ]
  },
  "https://proceedings.mlr.press/v238/gao24b.html": {
    "title": "Decentralized Multi-Level Compositional Optimization Algorithms with Level-Independent Convergence Rate",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongchang Gao"
    ]
  },
  "https://proceedings.mlr.press/v238/jiang24a.html": {
    "title": "Krylov Cubic Regularized Newton: A Subspace Second-Order Method with Dimension-Free Convergence Rate",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruichen Jiang",
      "Parameswaran Raman",
      "Shoham Sabach",
      "Aryan Mokhtari",
      "Mingyi Hong",
      "Volkan Cevher"
    ]
  },
  "https://proceedings.mlr.press/v238/suttle24a.html": {
    "title": "Sampling-based Safe Reinforcement Learning for Nonlinear Dynamical Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wesley Suttle",
      "Vipul Kumar Sharma",
      "Krishna Chaitanya Kosaraju",
      "Sivaranjani Seetharaman",
      "Ji Liu",
      "Vijay Gupta",
      "Brian M Sadler"
    ]
  },
  "https://proceedings.mlr.press/v238/garg24a.html": {
    "title": "Soft-constrained Schrödinger Bridge: a Stochastic Control Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jhanvi Garg",
      "Xianyang Zhang",
      "Quan Zhou"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24f.html": {
    "title": "Coreset Markov chain Monte Carlo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naitong Chen",
      "Trevor Campbell"
    ]
  },
  "https://proceedings.mlr.press/v238/gheshlaghi-azar24a.html": {
    "title": "A General Theoretical Paradigm to Understand Learning from Human Preferences",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Gheshlaghi Azar",
      "Zhaohan Daniel Guo",
      "Bilal Piot",
      "Remi Munos",
      "Mark Rowland",
      "Michal Valko",
      "Daniele Calandriello"
    ]
  },
  "https://proceedings.mlr.press/v238/marmarelis24a.html": {
    "title": "Policy Learning for Localized Interventions from Observational Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Myrl G. Marmarelis",
      "Fred Morstatter",
      "Aram Galstyan",
      "Greg Ver Steeg"
    ]
  },
  "https://proceedings.mlr.press/v238/ren24c.html": {
    "title": "Understanding the Generalization Benefits of Late Learning Rate Decay",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinuo Ren",
      "Chao Ma",
      "Lexing Ying"
    ]
  },
  "https://proceedings.mlr.press/v238/lee24d.html": {
    "title": "Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junghyun Lee",
      "Se-Young Yun",
      "Kwang-Sung Jun"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24l.html": {
    "title": "Near-Interpolators: Rapid Norm Growth and the Trade-Off between Interpolation and Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutong Wang",
      "Rishi Sonthalia",
      "Wei Hu"
    ]
  },
  "https://proceedings.mlr.press/v238/kant24a.html": {
    "title": "Identifiability of Product of Experts Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manav Kant",
      "Eric Y Ma",
      "Andrei Staicu",
      "Leonard J Schulman",
      "Spencer Gordon"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24g.html": {
    "title": "Gibbs-Based Information Criteria and the Over-Parameterized Regime",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haobo Chen",
      "Gregory W Wornell",
      "Yuheng Bu"
    ]
  },
  "https://proceedings.mlr.press/v238/puranik24a.html": {
    "title": "Improving Robustness via Tilted Exponential Layer: A Communication-Theoretic Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bhagyashree Puranik",
      "Ahmad Beirami",
      "Yao Qin",
      "Upamanyu Madhow"
    ]
  },
  "https://proceedings.mlr.press/v238/deng24b.html": {
    "title": "On the Generalization Ability of Unsupervised Pretraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyang Deng",
      "Junyuan Hong",
      "Jiayu Zhou",
      "Mehrdad Mahdavi"
    ]
  },
  "https://proceedings.mlr.press/v238/mustafa24a.html": {
    "title": "Non-vacuous Generalization Bounds for Adversarial Risk in Stochastic Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Waleed Mustafa",
      "Philipp Liznerski",
      "Antoine Ledent",
      "Dennis Wagner",
      "Puyu Wang",
      "Marius Kloft"
    ]
  },
  "https://proceedings.mlr.press/v238/xu24c.html": {
    "title": "BLIS-Net: Classifying and Analyzing Signals on Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Charles Xu",
      "Laney Goldman",
      "Valentina Guo",
      "Benjamin Hollander-Bodie",
      "Maedee Trank-Greene",
      "Ian Adelstein",
      "Edward De Brouwer",
      "Rex Ying",
      "Smita Krishnaswamy",
      "Michael Perlmutter"
    ]
  },
  "https://proceedings.mlr.press/v238/deb24a.html": {
    "title": "Think Before You Duel: Understanding Complexities of Preference Learning under Constrained Resources",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rohan Deb",
      "Aadirupa Saha",
      "Arindam Banerjee"
    ]
  },
  "https://proceedings.mlr.press/v238/warren24a.html": {
    "title": "Fast Fourier Bayesian Quadrature",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Houston Warren",
      "Fabio Ramos"
    ]
  },
  "https://proceedings.mlr.press/v238/inatsu24a.html": {
    "title": "Bounding Box-based Multi-objective Bayesian Optimization of Risk Measures under Input Uncertainty",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Inatsu",
      "Shion Takeno",
      "Hiroyuki Hanada",
      "Kazuki Iwata",
      "Ichiro Takeuchi"
    ]
  },
  "https://proceedings.mlr.press/v238/cousins24a.html": {
    "title": "To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cyrus Cousins",
      "I. Elizabeth Kumar",
      "Suresh Venkatasubramanian"
    ]
  },
  "https://proceedings.mlr.press/v238/kong24a.html": {
    "title": "Two Birds with One Stone: Enhancing Uncertainty Quantification and Interpretability with Graph Functional Neural Process",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingkai Kong",
      "Haotian Sun",
      "Yuchen Zhuang",
      "Haorui Wang",
      "Wenhao Mu",
      "Chao Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/heo24a.html": {
    "title": "Sample Efficient Learning of Factored Embeddings of Tensor Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taemin Heo",
      "Chandrajit Bajaj"
    ]
  },
  "https://proceedings.mlr.press/v238/biron-lattes24a.html": {
    "title": "autoMALA: Locally adaptive Metropolis-adjusted Langevin algorithm",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miguel Biron-Lattes",
      "Nikola Surjanovic",
      "Saifuddin Syed",
      "Trevor Campbell",
      "Alexandre Bouchard-Cote"
    ]
  },
  "https://proceedings.mlr.press/v238/yan24a.html": {
    "title": "Causal Bandits with General Causal Models and Interventions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zirui Yan",
      "Dennis Wei",
      "Dmitriy A Katz",
      "Prasanna Sattigeri",
      "Ali Tajer"
    ]
  },
  "https://proceedings.mlr.press/v238/wycoff24a.html": {
    "title": "Surrogate Active Subspaces for Jump-Discontinuous Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathan Wycoff"
    ]
  },
  "https://proceedings.mlr.press/v238/alacaoglu24a.html": {
    "title": "Complexity of Single Loop Algorithms for Nonlinear Programming with Stochastic Objective and Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmet Alacaoglu",
      "Stephen J Wright"
    ]
  },
  "https://proceedings.mlr.press/v238/shaikh-veedu24a.html": {
    "title": "Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mishfad Shaikh Veedu",
      "Deepjyoti Deka",
      "Murti Salapaka"
    ]
  },
  "https://proceedings.mlr.press/v238/lim24a.html": {
    "title": "Pathwise Explanation of ReLU Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seongwoo Lim",
      "Won Jo",
      "Joohyung Lee",
      "Jaesik Choi"
    ]
  },
  "https://proceedings.mlr.press/v238/hood24a.html": {
    "title": "The AL$\\ell_0$CORE Tensor Decomposition for Sparse Count Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "John Hood",
      "Aaron J. Schein"
    ]
  },
  "https://proceedings.mlr.press/v238/huang24c.html": {
    "title": "Adaptive Federated Minimax Optimization with Lower Complexities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feihu Huang",
      "Xinrui Wang",
      "Junyi Li",
      "Songcan Chen"
    ]
  },
  "https://proceedings.mlr.press/v238/ni24a.html": {
    "title": "Mixture-of-Linear-Experts for Long-term Time Series Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ronghao Ni",
      "Zinan Lin",
      "Shuaiqi Wang",
      "Giulia Fanti"
    ]
  },
  "https://proceedings.mlr.press/v238/mortazavi24a.html": {
    "title": "On the price of exact truthfulness in incentive-compatible online learning with bandit feedback: a regret lower bound for WSU-UX",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ali Mortazavi",
      "Junhao Lin",
      "Nishant Mehta"
    ]
  },
  "https://proceedings.mlr.press/v238/okoroafor24a.html": {
    "title": "Faster Recalibration of an Online Predictor via Approachability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Princewill Okoroafor",
      "Bobby Kleinberg",
      "Wen Sun"
    ]
  },
  "https://proceedings.mlr.press/v238/cheng24a.html": {
    "title": "Provable Policy Gradient Methods for Average-Reward Markov Potential Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min Cheng",
      "Ruida Zhou",
      "P. R. Kumar",
      "Chao Tian"
    ]
  },
  "https://proceedings.mlr.press/v238/maniyar24a.html": {
    "title": "A Cubic-regularized Policy Newton Algorithm for Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mizhaan P. Maniyar",
      "Prashanth L.A.",
      "Akash Mondal",
      "Shalabh Bhatnagar"
    ]
  },
  "https://proceedings.mlr.press/v238/lu24a.html": {
    "title": "Towards Generalizable and Interpretable Motion Prediction: A Deep Variational Bayes Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juanwu Lu",
      "Wei Zhan",
      "Masayoshi Tomizuka",
      "Yeping Hu"
    ]
  },
  "https://proceedings.mlr.press/v238/ildiz24a.html": {
    "title": "Understanding Inverse Scaling and Emergence in Multitask Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammed E. Ildiz",
      "Zhe Zhao",
      "Samet Oymak"
    ]
  },
  "https://proceedings.mlr.press/v238/sunil-lahoti24a.html": {
    "title": "Sharpened Lazy Incremental Quasi-Newton Method",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aakash Sunil Lahoti",
      "Spandan Senapati",
      "Ketan Rajawat",
      "Alec Koppel"
    ]
  },
  "https://proceedings.mlr.press/v238/li24p.html": {
    "title": "Efficient Active Learning Halfspaces with Tsybakov Noise: A Non-convex Optimization Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinan Li",
      "Chicheng Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/mao24a.html": {
    "title": "Theoretically Grounded Loss Functions and Algorithms for Score-Based Multi-Class Abstention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anqi Mao",
      "Mehryar Mohri",
      "Yutao Zhong"
    ]
  },
  "https://proceedings.mlr.press/v238/braun24b.html": {
    "title": "Deep Classifier Mimicry without Data Access",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Steven Braun",
      "Martin Mundt",
      "Kristian Kersting"
    ]
  },
  "https://proceedings.mlr.press/v238/bojkovic24a.html": {
    "title": "Data Driven Threshold and Potential Initialization for Spiking Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Velibor Bojkovic",
      "Srinivas Anumasa",
      "Giulia De Masi",
      "Bin Gu",
      "Huan Xiong"
    ]
  },
  "https://proceedings.mlr.press/v238/battash24a.html": {
    "title": "Revisiting the Noise Model of Stochastic Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Barak Battash",
      "Lior Wolf",
      "Ofir Lindenbaum"
    ]
  },
  "https://proceedings.mlr.press/v238/nakano24a.html": {
    "title": "Warped Diffusion for Latent Differentiation Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Masahiro Nakano",
      "Hiroki Sakuma",
      "Ryo Nishikimi",
      "Ryohei Shibue",
      "Takashi Sato",
      "Tomoharu Iwata",
      "Kunio Kashino"
    ]
  },
  "https://proceedings.mlr.press/v238/tsoy24a.html": {
    "title": "Provable Mutual Benefits from Federated Learning in Privacy-Sensitive Domains",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikita Tsoy",
      "Anna Mihalkova",
      "Teodora N Todorova",
      "Nikola Konstantinov"
    ]
  },
  "https://proceedings.mlr.press/v238/ceni24a.html": {
    "title": "Random Oscillators Network for Time Series Processing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrea Ceni",
      "Andrea Cossu",
      "Maximilian W Stölzle",
      "Jingyue Liu",
      "Cosimo Della Santina",
      "Davide Bacciu",
      "Claudio Gallicchio"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24h.html": {
    "title": "Mitigating Underfitting in Learning to Defer with Consistent Losses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuqi Liu",
      "Yuzhou Cao",
      "Qiaozhen Zhang",
      "Lei Feng",
      "Bo An"
    ]
  },
  "https://proceedings.mlr.press/v238/cao24a.html": {
    "title": "Consistent Hierarchical Classification with A Generalized Metric",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzhou Cao",
      "Lei Feng",
      "Bo An"
    ]
  },
  "https://proceedings.mlr.press/v238/monzio-compagnoni24a.html": {
    "title": "SDEs for Minimax Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Enea Monzio Compagnoni",
      "Antonio Orvieto",
      "Hans Kersting",
      "Frank Proske",
      "Aurelien Lucchi"
    ]
  },
  "https://proceedings.mlr.press/v238/ray-chowdhury24a.html": {
    "title": "Differentially Private Reward Estimation with Preference Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sayak Ray Chowdhury",
      "Xingyu Zhou",
      "Nagarajan Natarajan"
    ]
  },
  "https://proceedings.mlr.press/v238/morozov24a.html": {
    "title": "Differentiable Rendering with Reparameterized Volume Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikita Morozov",
      "Denis Rakitin",
      "Oleg Desheulin",
      "Dmitry P Vetrov",
      "Kirill Struminsky"
    ]
  },
  "https://proceedings.mlr.press/v238/hubler24a.html": {
    "title": "Parameter-Agnostic Optimization under Relaxed Smoothness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florian Hübler",
      "Junchi Yang",
      "Xiang Li",
      "Niao He"
    ]
  },
  "https://proceedings.mlr.press/v238/nazykov24a.html": {
    "title": "Stochastic Frank-Wolfe: Unified Analysis and Zoo of Special Cases",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruslan Nazykov",
      "Aleksandr Shestakov",
      "Vladimir Solodkin",
      "Aleksandr Beznosikov",
      "Gauthier Gidel",
      "Alexander Gasnikov"
    ]
  },
  "https://proceedings.mlr.press/v238/plassier24a.html": {
    "title": "Efficient Conformal Prediction under Data Heterogeneity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Plassier",
      "Nikita Kotelevskii",
      "Aleksandr Rubashevskii",
      "Fedor Noskov",
      "Maksim Velikanov",
      "Alexander Fishkov",
      "Samuel Horvath",
      "Martin Takac",
      "Eric Moulines",
      "Maxim Panov"
    ]
  },
  "https://proceedings.mlr.press/v238/ghosh24b.html": {
    "title": "Sample-efficient neural likelihood-free Bayesian inference of implicit HMMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanmitra Ghosh",
      "Paul Birrell",
      "Daniela De Angelis"
    ]
  },
  "https://proceedings.mlr.press/v238/mameche24a.html": {
    "title": "Identifying Confounding from Causal Mechanism Shifts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sarah Mameche",
      "Jilles Vreeken",
      "David Kaltenpoth"
    ]
  },
  "https://proceedings.mlr.press/v238/batten24a.html": {
    "title": "Tight Verification of Probabilistic Robustness in Bayesian Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ben Batten",
      "Mehran Hosseini",
      "Alessio Lomuscio"
    ]
  },
  "https://proceedings.mlr.press/v238/saha24b.html": {
    "title": "Testing exchangeability by pairwise betting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aytijhya Saha",
      "Aaditya Ramdas"
    ]
  },
  "https://proceedings.mlr.press/v238/m-buch24a.html": {
    "title": "Simple and scalable algorithms for cluster-aware precision medicine",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amanda M Buch",
      "Conor Liston",
      "Logan Grosenick"
    ]
  },
  "https://proceedings.mlr.press/v238/r-hands24a.html": {
    "title": "P-tensors: a General Framework for Higher Order Message Passing in Subgraph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrew R Hands",
      "Tianyi Sun",
      "Risi Kondor"
    ]
  },
  "https://proceedings.mlr.press/v238/a-cabannnes24a.html": {
    "title": "The Galerkin method beats Graph-Based Approaches for Spectral Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vivien A Cabannnes",
      "Francis Bach"
    ]
  },
  "https://proceedings.mlr.press/v238/j-holland24a.html": {
    "title": "Robust variance-regularized risk minimization with concomitant scaling",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew J Holland"
    ]
  },
  "https://proceedings.mlr.press/v238/d-kjaersgaard24a.html": {
    "title": "Fair Soft Clustering",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rune D. Kjærsgaard",
      "Pekka Parviainen",
      "Saket Saurabh",
      "Madhumita Kundu",
      "Line Clemmensen"
    ]
  },
  "https://proceedings.mlr.press/v238/y-tong24a.html": {
    "title": "Simulation-Free Schrödinger Bridges via Score and Flow Matching",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Y Tong",
      "Nikolay Malkin",
      "Kilian Fatras",
      "Lazar Atanackovic",
      "Yanlei Zhang",
      "Guillaume Huguet",
      "Guy Wolf",
      "Yoshua Bengio"
    ]
  },
  "https://proceedings.mlr.press/v238/c-cosier24a.html": {
    "title": "A Unifying Variational Framework for Gaussian Process Motion Planning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lucas C. Cosier",
      "Rares Iordan",
      "Sicelukwanda N.T. Zwane",
      "Giovanni Franzese",
      "James T. Wilson",
      "Marc Deisenroth",
      "Alexander Terenin",
      "Yasemin Bekiroglu"
    ]
  },
  "https://proceedings.mlr.press/v238/q-khan24a.html": {
    "title": "Analyzing Explainer Robustness via Probabilistic Lipschitzness of Prediction Functions",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zulqarnain Q Khan",
      "Davin Hill",
      "Aria Masoomi",
      "Joshua T Bone",
      "Jennifer Dy"
    ]
  },
  "https://proceedings.mlr.press/v238/a-k-september24a.html": {
    "title": "Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcus A K September",
      "Francesco Sanna Passino",
      "Leonie Goldmann",
      "Anton Hinel"
    ]
  },
  "https://proceedings.mlr.press/v238/s-g-heidrich24a.html": {
    "title": "A 4-Approximation Algorithm for Min Max Correlation Clustering",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Holger S.G. Heidrich",
      "Jannik Irmai",
      "Bjoern Andres"
    ]
  },
  "https://proceedings.mlr.press/v238/b-andrew24a.html": {
    "title": "GmGM: a fast multi-axis Gaussian graphical model",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ethan B Andrew",
      "David Westhead",
      "Luisa Cutillo"
    ]
  },
  "https://proceedings.mlr.press/v238/m-moreno24a.html": {
    "title": "Efficient Model-Based Concave Utility Reinforcement Learning through Greedy Mirror Descent",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bianca M Moreno",
      "Margaux Bregere",
      "Pierre Gaillard",
      "Nadia Oudjane"
    ]
  },
  "https://proceedings.mlr.press/v238/m-baker24a.html": {
    "title": "Monotone Operator Theory-Inspired Message Passing for Learning Long-Range Interaction on Graphs",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Justin M Baker",
      "Qingsong Wang",
      "Martin Berzins",
      "Thomas Strohmer",
      "Bao Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/u-pasteris24a.html": {
    "title": "Sum-max Submodular Bandits",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stephen U Pasteris",
      "Alberto Rumi",
      "Fabio Vitale",
      "Nicolò Cesa-Bianchi"
    ]
  },
  "https://proceedings.mlr.press/v238/c-diluvi24a.html": {
    "title": "Mixed variational flows for discrete variables",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gian C Diluvi",
      "Benjamin Bloem-Reddy",
      "Trevor Campbell"
    ]
  },
  "https://proceedings.mlr.press/v238/p-patel24a.html": {
    "title": "Conformal Contextual Robust Optimization",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yash P Patel",
      "Sahana Rayan",
      "Ambuj Tewari"
    ]
  },
  "https://proceedings.mlr.press/v238/d-abernethy24a.html": {
    "title": "Lexicographic Optimization: Algorithms and Stability",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacob D Abernethy",
      "Robert Schapire",
      "Umar Syed"
    ]
  },
  "https://proceedings.mlr.press/v238/t-wang24a.html": {
    "title": "Efficient Data Shapley for Weighted Nearest Neighbor Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiachen T. Wang",
      "Prateek Mittal",
      "Ruoxi Jia"
    ]
  },
  "https://proceedings.mlr.press/v238/l-martinez24a.html": {
    "title": "Achieving Group Distributional Robustness and Minimax Group Fairness with Interpolating Classifiers",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Natalia L Martinez",
      "Martin A Bertran",
      "Guillermo Sapiro"
    ]
  },
  "https://proceedings.mlr.press/v238/h-ahmed24a.html": {
    "title": "Privacy-Preserving Decentralized Actor-Critic for Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maheed H Ahmed",
      "Mahsa Ghasemi"
    ]
  },
  "https://proceedings.mlr.press/v238/j-cundy24a.html": {
    "title": "Privacy-Constrained Policies via Mutual Information Regularized Policy Gradients",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chris J Cundy",
      "Rishi Desai",
      "Stefano Ermon"
    ]
  },
  "https://proceedings.mlr.press/v238/m-nguyen24a.html": {
    "title": "Near-optimal Per-Action Regret Bounds for Sleeping Bandits",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quan M Nguyen",
      "Nishant Mehta"
    ]
  },
  "https://proceedings.mlr.press/v238/w-mogensen24a.html": {
    "title": "Faithful graphical representations of local independence",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Søren W Mogensen"
    ]
  },
  "https://proceedings.mlr.press/v238/u-mondal24a.html": {
    "title": "Improved Sample Complexity Analysis of Natural Policy Gradient Algorithm with General Parameterization for Infinite Horizon Discounted Reward Markov Decision Processes",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Washim U Mondal",
      "Vaneet Aggarwal"
    ]
  },
  "https://proceedings.mlr.press/v238/m-maddux24a.html": {
    "title": "Multi-Agent Learning in Contextual Games under Unknown Constraints",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anna M Maddux",
      "Maryam Kamgarpour"
    ]
  },
  "https://proceedings.mlr.press/v238/c-novitasari24a.html": {
    "title": "ALAS: Active Learning for Autoconversion Rates Prediction from Satellite Data",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maria C Novitasari",
      "Johannes Quaas",
      "Miguel Rodrigues"
    ]
  },
  "https://proceedings.mlr.press/v238/l-lee24a.html": {
    "title": "Approximate Bayesian Class-Conditional Models under Continuous Representation Shift",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas L Lee",
      "Amos Storkey"
    ]
  },
  "https://proceedings.mlr.press/v238/p-engelmann24a.html": {
    "title": "Mixed Models with Multiple Instance Learning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan P. Engelmann",
      "Alessandro Palma",
      "Jakub M Tomczak",
      "Fabian Theis",
      "Francesco Paolo Casale"
    ]
  },
  "https://proceedings.mlr.press/v238/p-pasarkar24a.html": {
    "title": "Cousins Of The Vendi Score: A Family Of Similarity-Based Diversity Metrics For Science And Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amey P Pasarkar",
      "Adji Bousso Dieng"
    ]
  },
  "https://proceedings.mlr.press/v238/a-hanna24a.html": {
    "title": "Multi-Agent Bandit Learning through Heterogeneous Action Erasure Channels",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Osama A Hanna",
      "Merve Karakas",
      "Lin Yang",
      "Christina Fragouli"
    ]
  },
  "https://proceedings.mlr.press/v238/c-bansak24a.html": {
    "title": "Learning Under Random Distributional Shifts",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kirk C Bansak",
      "Elisabeth Paulson",
      "Dominik Rothenhaeusler"
    ]
  },
  "https://proceedings.mlr.press/v238/m-faller24a.html": {
    "title": "Self-Compatibility: Evaluating Causal Discovery without Ground Truth",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philipp M Faller",
      "Leena C Vankadara",
      "Atalanti A Mastakouri",
      "Francesco Locatello",
      "Dominik Janzing"
    ]
  },
  "https://proceedings.mlr.press/v238/z-li24a.html": {
    "title": "Computing epidemic metrics with edge differential privacy",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "George Z Li",
      "Dung Nguyen",
      "Anil Vullikanti"
    ]
  },
  "https://proceedings.mlr.press/v238/j-koelle24a.html": {
    "title": "Consistency of Dictionary-Based Manifold Learning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samson J Koelle",
      "Hanyu Zhang",
      "Octavian-Vlad Murad",
      "Marina Meila"
    ]
  },
  "https://proceedings.mlr.press/v238/e-ildiz24a.html": {
    "title": "Understanding Inverse Scaling and Emergence in Multitask Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammed E Ildiz",
      "Zhe Zhao",
      "Samet Oymak"
    ]
  }
}