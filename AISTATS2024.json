{
  "https://proceedings.mlr.press/v238/ruegamer24a.html": {
    "title": "Scalable Higher-Order Tensor Product Spline Models",
    "volume": "main",
    "abstract": "In the current era of vast data and transparent machine learning, it is essential for techniques to operate at a large scale while providing a clear mathematical comprehension of the internal workings of the method. Although there already exist interpretable semi-parametric regression methods for large-scale applications that take into account non-linearity in the data, the complexity of the models is still often limited. One of the main challenges is the absence of interactions in these models, which are left out for the sake of better interpretability but also due to impractical computational costs. To overcome this limitation, we propose a new approach using a factorization method to derive a highly scalable higher-order tensor product spline model. Our method allows for the incorporation of all (higher-order) interactions of non-linear feature effects while having computational costs proportional to a model without interactions. We further develop a meaningful penalization scheme and examine the induced optimization problem. We conclude by evaluating the predictive and estimation performance of our method",
    "checked": true,
    "id": "dfacaf4f4de33745be4a1937e9b6d6708a496cf0",
    "semantic_title": "scalable higher-order tensor product spline models",
    "citation_count": 0,
    "authors": [
      "David Ruegamer"
    ]
  },
  "https://proceedings.mlr.press/v238/amagata24a.html": {
    "title": "Fair k-center Clustering with Outliers",
    "volume": "main",
    "abstract": "The importance of dealing with big data is further increasing, as machine learning (ML) systems obtain useful knowledge from big datasets. However, using all data is practically prohibitive because of the massive sizes of the datasets, so summarizing them by centers obtained from k-center clustering is a promising approach. We have two concerns here. One is fairness, because if the summary does not have some specific groups, subsequent applications may provide unfair results for the groups. The other is the presence of outliers, and if outliers dominate the summary, it cannot be useful. To overcome these concerns, we address the problem of fair k-center clustering with outliers. Although prior works studied the fair k-center clustering problem, they do not consider outliers. This paper yields a linear time algorithm that satisfies the fairness constraint of our problem and probabilistically guarantees the almost 3-approximation bound. Its empirical efficiency and effectiveness are also reported",
    "checked": true,
    "id": "3cf3d1e04481b34bb910e3e74afc0b9bc4cdc8d2",
    "semantic_title": "fair k-center clustering with outliers",
    "citation_count": 0,
    "authors": [
      "Daichi Amagata"
    ]
  },
  "https://proceedings.mlr.press/v238/shankar24a.html": {
    "title": "A/B testing under Interference with Partial Network Information",
    "volume": "main",
    "abstract": "A/B tests are often required to be conducted on subjects that might have social connections. For e.g., experiments on social media, or medical and social interventions to control the spread of an epidemic. In such settings, the SUTVA assumption for randomized-controlled trials is violated due to network interference, or spill-over effects, as treatments to group A can potentially also affect the control group B. When the underlying social network is known exactly, prior works have demonstrated how to conduct A/B tests adequately to estimate the global average treatment effect (GATE). However, in practice, it is often impossible to obtain knowledge about the exact underlying network. In this paper, we present UNITE: a novel estimator that relax this assumption and can identify GATE while only relying on knowledge of the superset of neighbors for any subject in the graph. Through theoretical analysis and extensive experiments, we show that the proposed approach performs better in comparison to standard estimators",
    "checked": true,
    "id": "23e9ddc6a752b966e10c8e60b59b491fb92fedad",
    "semantic_title": "a/b testing under interference with partial network information",
    "citation_count": 1,
    "authors": [
      "Shiv Shankar",
      "Ritwik Sinha",
      "Yash Chandak",
      "Saayan Mitra",
      "Madalina Fiterau"
    ]
  },
  "https://proceedings.mlr.press/v238/jang24a.html": {
    "title": "Achieving Fairness through Separability: A Unified Framework for Fair Representation Learning",
    "volume": "main",
    "abstract": "Fairness is a growing concern in machine learning as state-of-the-art models may amplify social prejudice by making biased predictions against specific demographics such as race and gender. Such discrimination raises issues in various fields such as employment, criminal justice, and trust score evaluation. To address the concerns, we propose learning fair representation through a straightforward yet effective approach to project intrinsic information while filtering sensitive information for downstream tasks. Our model consists of two goals: one is to ensure that the latent data from different demographic groups is non-separable (i.e., make the latent data distribution independent of the sensitive feature to improve fairness); the other is to maximize the separability of latent data from different classes (i.e., maintain the discriminative power of data for the sake of the downstream tasks like classification). Our method adopts a non-zero-sum adversarial game to minimize the distance between data from different demographic groups while maximizing the margin between data from different classes. Moreover, the proposed objective function can be easily generalized to multiple sensitive attributes and multi-class scenarios as it upper bounds popular fairness metrics in these cases. We provide theoretical analysis of the fairness of our model and validate w.r.t. both fairness and predictive performance on benchmark datasets",
    "checked": true,
    "id": "7696d4cc5f1ae70528e5fbd70bf14c3ea90b0891",
    "semantic_title": "achieving fairness through separability: a unified framework for fair representation learning",
    "citation_count": 0,
    "authors": [
      "Taeuk Jang",
      "Hongchang Gao",
      "Pengyi Shi",
      "Xiaoqian Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/li24a.html": {
    "title": "Personalized Federated X-armed Bandit",
    "volume": "main",
    "abstract": "In this work, we study the personalized federated $\\mathcal{X}$-armed bandit problem, where the heterogeneous local objectives of the clients are optimized simultaneously in the federated learning paradigm. We propose the \\texttt{PF-PNE} algorithm with a unique double elimination strategy, which safely eliminates the non-optimal regions while encouraging federated collaboration through biased but effective evaluations of the local objectives. The proposed \\texttt{PF-PNE} algorithm is able to optimize local objectives with arbitrary levels of heterogeneity, and its limited communications protects the confidentiality of the client-wise reward data. Our theoretical analysis shows the benefit of the proposed algorithm over single-client algorithms. Experimentally, \\texttt{PF-PNE} outperforms multiple baselines on both synthetic and real life datasets",
    "checked": false,
    "id": "186f745dc4518e1df276a57b5f57eda775c93034",
    "semantic_title": "personalized federated x -armed bandit",
    "citation_count": 0,
    "authors": [
      "Wenjie Li",
      "Qifan Song",
      "Jean Honorio"
    ]
  },
  "https://proceedings.mlr.press/v238/li24b.html": {
    "title": "Non-Neighbors Also Matter to Kriging: A New Contrastive-Prototypical Learning",
    "volume": "main",
    "abstract": "Kriging aims to estimate the attributes of unseen geo-locations from observations in the spatial vicinity or physical connections. Existing works assume that neighbors' information offers the basis for estimating the unobserved target while ignoring non-neighbors. However, neighbors could also be quite different or even misleading, and the non-neighbors could still offer constructive information. To this end, we propose \"Contrastive-Prototypical\" self-supervised learning for Kriging (KCP): (1) The neighboring contrastive module coarsely pushes neighbors together and non-neighbors apart. (2) In parallel, the prototypical module identifies similar representations via exchanged prediction, such that it refines the misleading neighbors and recycles the useful non-neighbors from the neighboring contrast component. As a result, not all the neighbors and some of the non-neighbors will be used to infer the target. (3) To learn general and robust representations, we design an adaptive augmentation module that encourages data diversity. Theoretical bound is derived for the proposed augmentation. Extensive experiments on real-world datasets demonstrate the superior performance of KCP compared to its peers with 6% improvements and exceptional transferability and robustness",
    "checked": true,
    "id": "074664024ec6005741748e4e3af7f1e3bfe22b77",
    "semantic_title": "non-neighbors also matter to kriging: a new contrastive-prototypical learning",
    "citation_count": 2,
    "authors": [
      "Zhishuai Li",
      "Yunhao Nie",
      "Ziyue Li",
      "Lei Bai",
      "Yisheng Lv",
      "Rui Zhao"
    ]
  },
  "https://proceedings.mlr.press/v238/hill24a.html": {
    "title": "Boundary-Aware Uncertainty for Feature Attribution Explainers",
    "volume": "main",
    "abstract": "Post-hoc explanation methods have become a critical tool for understanding black-box classifiers in high-stakes applications. However, high-performing classifiers are often highly nonlinear and can exhibit complex behavior around the decision boundary, leading to brittle or misleading local explanations. Therefore there is an impending need to quantify the uncertainty of such explanation methods in order to understand when explanations are trustworthy. In this work we propose the Gaussian Process Explanation unCertainty (GPEC) framework, which generates a unified uncertainty estimate combining decision boundary-aware uncertainty with explanation function approximation uncertainty. We introduce a novel geodesic-based kernel, which captures the complexity of the target black-box decision boundary. We show theoretically that the proposed kernel similarity increases with decision boundary complexity. The proposed framework is highly flexible; it can be used with any black-box classifier and feature attribution method. Empirical results on multiple tabular and image datasets show that the GPEC uncertainty estimate improves understanding of explanations as compared to existing methods",
    "checked": true,
    "id": "51cdedfb9850844e9f24235d5c79f624a93280a9",
    "semantic_title": "boundary-aware uncertainty for feature attribution explainers",
    "citation_count": 1,
    "authors": [
      "Davin Hill",
      "Aria Masoomi",
      "Max Torop",
      "Sandesh Ghimire",
      "Jennifer Dy"
    ]
  },
  "https://proceedings.mlr.press/v238/even24a.html": {
    "title": "Asynchronous SGD on Graphs: a Unified Framework for Asynchronous Decentralized and Federated Optimization",
    "volume": "main",
    "abstract": "Decentralized and asynchronous communications are two popular techniques to speedup communication complexity of distributed machine learning, by respectively removing the dependency over a central orchestrator and the need for synchronization. Yet, combining these two techniques together still remains a challenge. In this paper, we take a step in this direction and introduce Asynchronous SGD on Graphs (AGRAF SGD) — a general algorithmic framework that covers asynchronous versions of many popular algorithms including SGD, Decentralized SGD, Local SGD, FedBuff, thanks to its relaxed communication and computation assumptions. We provide rates of convergence under much milder assumptions than previous decentralized asynchronous works, while still recovering or even improving over the best know results for all the algorithms covered",
    "checked": true,
    "id": "0f9ded926e889e35695e2028a059c96476fc8daa",
    "semantic_title": "asynchronous sgd on graphs: a unified framework for asynchronous decentralized and federated optimization",
    "citation_count": 7,
    "authors": [
      "Mathieu Even",
      "Anastasia Koloskova",
      "Laurent Massoulie"
    ]
  },
  "https://proceedings.mlr.press/v238/hellstrom24a.html": {
    "title": "Comparing Comparators in Generalization Bounds",
    "volume": "main",
    "abstract": "We derive generic information-theoretic and PAC-Bayesian generalization bounds involving an arbitrary convex comparator function, which measures the discrepancy between the training loss and the population loss. The bounds hold under the assumption that the cumulant-generating function (CGF) of the comparator is upper-bounded by the corresponding CGF within a family of bounding distributions. We show that the tightest possible bound is obtained with the comparator being the convex conjugate of the CGF of the bounding distribution, also known as the Cramér function. This conclusion applies more broadly to generalization bounds with a similar structure. This confirms the near-optimality of known bounds for bounded and sub-Gaussian losses and leads to novel bounds under other bounding distributions",
    "checked": true,
    "id": "8ec2d05bdeb8820d656ffdc898aafb3bc8f92dab",
    "semantic_title": "comparing comparators in generalization bounds",
    "citation_count": 1,
    "authors": [
      "Fredrik Hellström",
      "Benjamin Guedj"
    ]
  },
  "https://proceedings.mlr.press/v238/dagreou24a.html": {
    "title": "A Lower Bound and a Near-Optimal Algorithm for Bilevel Empirical Risk Minimization",
    "volume": "main",
    "abstract": "Bilevel optimization problems, which are problems where two optimization problems are nested, have more and more applications in machine learning. In many practical cases, the upper and the lower objectives correspond to empirical risk minimization problems and therefore have a sum structure. In this context, we propose a bilevel extension of the celebrated SARAH algorithm. We demonstrate that the algorithm requires $O((n+m)^{1/2}\\epsilon^{-1})$ oracle calls to achieve $\\epsilon$-stationarity with $n+m$ the total number of samples, which improves over all previous bilevel algorithms. Moreover, we provide a lower bound on the number of oracle calls required to get an approximate stationary point of the objective function of the bilevel problem. This lower bound is attained by our algorithm, making it optimal in terms of sample complexity",
    "checked": true,
    "id": "d86c87c44071f149508b5b0f718c607e908966fd",
    "semantic_title": "a lower bound and a near-optimal algorithm for bilevel empirical risk minimization",
    "citation_count": 6,
    "authors": [
      "Mathieu Dagréou",
      "Thomas Moreau",
      "Samuel Vaiter",
      "Pierre Ablin"
    ]
  },
  "https://proceedings.mlr.press/v238/zheng24a.html": {
    "title": "Better Batch for Deep Probabilistic Time Series Forecasting",
    "volume": "main",
    "abstract": "Deep probabilistic time series forecasting has gained attention for its ability to provide nonlinear approximation and valuable uncertainty quantification for decision-making. However, existing models often oversimplify the problem by assuming a time-independent error process and overlooking serial correlation. To overcome this limitation, we propose an innovative training method that incorporates error autocorrelation to enhance probabilistic forecasting accuracy. Our method constructs a mini-batch as a collection of D consecutive time series segments for model training. It explicitly learns a time-varying covariance matrix over each mini-batch, encoding error correlation among adjacent time steps. The learned covariance matrix can be used to improve prediction accuracy and enhance uncertainty quantification. We evaluate our method on two different neural forecasting models and multiple public datasets. Experimental results confirm the effectiveness of the proposed approach in improving the performance of both models across a range of datasets, resulting in notable improvements in predictive accuracy",
    "checked": true,
    "id": "5a37896de7f956b6cff13e914db09f858d004b21",
    "semantic_title": "better batch for deep probabilistic time series forecasting",
    "citation_count": 1,
    "authors": [
      "Zhihao Zheng",
      "Seongjin Choi",
      "Lijun Sun"
    ]
  },
  "https://proceedings.mlr.press/v238/sundhar-ramesh24a.html": {
    "title": "Distributionally Robust Model-based Reinforcement Learning with Large State Spaces",
    "volume": "main",
    "abstract": "Three major challenges in reinforcement learning are the complex dynamical systems with large state spaces, the costly data acquisition processes, and the deviation of real-world dynamics from the training environment deployment. To overcome these issues, we study distributionally robust Markov decision processes with continuous state spaces under the widely used Kullback-Leibler, chi-square, and total variation uncertainty sets. We propose a model-based approach that utilizes Gaussian Processes and the maximum variance reduction algorithm to efficiently learn multi-output nominal transition dynamics, leveraging access to a generative model (i.e., simulator). We further demonstrate the statistical sample complexity of the proposed method for different uncertainty sets. These complexity bounds are independent of the number of states and extend beyond linear dynamics, ensuring the effectiveness of our approach in identifying near-optimal distributionally-robust policies. The proposed method can be further combined with other model-free distributionally robust reinforcement learning methods to obtain a near-optimal robust policy. Experimental results demonstrate the robustness of our algorithm to distributional shifts and its superior performance in terms of the number of samples needed",
    "checked": true,
    "id": "e3556000f28908e124c5facb6cb0a2dc55d0c373",
    "semantic_title": "distributionally robust model-based reinforcement learning with large state spaces",
    "citation_count": 6,
    "authors": [
      "Shyam Sundhar Ramesh",
      "Pier Giuseppe Sessa",
      "Yifan Hu",
      "Andreas Krause",
      "Ilija Bogunovic"
    ]
  },
  "https://proceedings.mlr.press/v238/el-ahmad24a.html": {
    "title": "Sketch In, Sketch Out: Accelerating both Learning and Inference for Structured Prediction with Kernels",
    "volume": "main",
    "abstract": "Leveraging the kernel trick in both the input and output spaces, surrogate kernel methods are a flexible and theoretically grounded solution to structured output prediction. If they provide state-of-the-art performance on complex data sets of moderate size (e.g., in chemoinformatics), these approaches however fail to scale. We propose to equip surrogate kernel methods with sketching-based approximations, applied to both the input and output feature maps. We prove excess risk bounds on the original structured prediction problem, showing how to attain close-to-optimal rates with a reduced sketch size that depends on the eigendecay of the input/output covariance operators. From a computational perspective, we show that the two approximations have distinct but complementary impacts: sketching the input kernel mostly reduces training time, while sketching the output kernel decreases the inference time. Empirically, our approach is shown to scale, achieving state-of-the-art performance on benchmark data sets where non-sketched methods are intractable",
    "checked": true,
    "id": "0e42aa9569404ed314ed9d6cb1142b62cd355b6e",
    "semantic_title": "sketch in, sketch out: accelerating both learning and inference for structured prediction with kernels",
    "citation_count": 4,
    "authors": [
      "Tamim El Ahmad",
      "Luc Brogat-Motte",
      "Pierre Laforgue",
      "Florence d’Alché-Buc"
    ]
  },
  "https://proceedings.mlr.press/v238/vadori24a.html": {
    "title": "Ordinal Potential-based Player Rating",
    "volume": "main",
    "abstract": "It was recently observed that Elo ratings fail at preserving transitive relations among strategies and therefore cannot correctly extract the transitive component of a game. We provide a characterization of transitive games as a weak variant of ordinal potential games and show that Elo ratings actually do preserve transitivity when computed in the right space, using suitable invertible mappings. Leveraging this insight, we introduce a new game decomposition of an arbitrary game into transitive and cyclic components that is learnt using a neural network-based architecture and that prioritises capturing the sign pattern of the game, namely transitive and cyclic relations among strategies. We link our approach to the known concept of sign-rank, and evaluate our methodology using both toy examples and empirical data from real-world games",
    "checked": true,
    "id": "c9a24d35bf506e2aac1aed5d5d6eedf209204b44",
    "semantic_title": "ordinal potential-based player rating",
    "citation_count": 1,
    "authors": [
      "Nelson Vadori",
      "Rahul Savani"
    ]
  },
  "https://proceedings.mlr.press/v238/rudner24a.html": {
    "title": "Mind the GAP: Improving Robustness to Subpopulation Shifts with Group-Aware Priors",
    "volume": "main",
    "abstract": "Machine learning models often perform poorly under subpopulation shifts in the data distribution. Developing methods that allow machine learning models to better generalize to such shifts is crucial for safe deployment in real-world settings. In this paper, we develop a family of group-aware prior (GAP) distributions over neural network parameters that explicitly favor models that generalize well under subpopulation shifts. We design a simple group-aware prior that only requires access to a small set of data with group information and demonstrate that training with this prior yields state-of-the-art performance—even when only retraining the final layer of a previously trained non-robust model. Group aware-priors are conceptually simple, complementary to existing approaches, such as attribute pseudo labeling and data reweighting, and open up promising new avenues for harnessing Bayesian inference to enable robustness to subpopulation shifts",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tim G. J. Rudner",
      "Ya Shi Zhang",
      "Andrew Gordon Wilson",
      "Julia Kempe"
    ]
  },
  "https://proceedings.mlr.press/v238/buch24a.html": {
    "title": "Simple and scalable algorithms for cluster-aware precision medicine",
    "volume": "main",
    "abstract": "AI-enabled precision medicine promises a transformational improvement in healthcare outcomes. However, training on biomedical data presents significant challenges as they are often high dimensional, clustered, and of limited sample size. To overcome these challenges, we propose a simple and scalable approach for cluster-aware embedding that combines latent factor methods with a convex clustering penalty in a modular way. Our novel approach overcomes the complexity and limitations of current joint embedding and clustering methods and enables hierarchically clustered principal component analysis (PCA), locally linear embedding (LLE), and canonical correlation analysis (CCA). Through numerical experiments and real-world examples, we demonstrate that our approach outperforms fourteen clustering methods on highly underdetermined problems (e.g., with limited sample size) as well as on large sample datasets. Importantly, our approach does not require the user to choose the desired number of clusters, yields improved model selection if they do, and yields interpretable hierarchically clustered embedding dendrograms. Thus, our approach improves significantly on existing methods for identifying patient subgroups in multiomics and neuroimaging data and enables scalable and interpretable biomarkers for precision medicine",
    "checked": true,
    "id": "18401e3c8b867c6fb822605cb41bd6e2e5ce7edc",
    "semantic_title": "simple and scalable algorithms for cluster-aware precision medicine",
    "citation_count": 0,
    "authors": [
      "Amanda M. Buch",
      "Conor Liston",
      "Logan Grosenick"
    ]
  },
  "https://proceedings.mlr.press/v238/lin24a.html": {
    "title": "A Specialized Semismooth Newton Method for Kernel-Based Optimal Transport",
    "volume": "main",
    "abstract": "Kernel-based optimal transport (OT) estimators offer an alternative, functional estimation procedure to address OT problems from samples. Recent works suggest that these estimators are more statistically efficient than plug-in (linear programming-based) OT estimators when comparing probability measures in high-dimensions (Vacher et al., 2021). Unfortunately,that statistical benefit comes at a very steep computational price: because their computation relies on the short-step interior-point method (SSIPM), which comes with a large iteration count in practice, these estimators quickly become intractable w.r.t. sample size $n$. To scale these estimators to larger $n$, we propose a nonsmooth fixedpoint model for the kernel-based OT problem, and show that it can be efficiently solved via a specialized semismooth Newton (SSN) method: We show, exploring the problem's structure, that the per-iteration cost of performing one SSN step can be significantly reduced in practice. We prove that our SSN method achieves a global convergence rate of $O(1/\\sqrt{k})$, and a local quadratic convergence rate under standard regularity conditions. We show substantial speedups over SSIPM on both synthetic and real datasets",
    "checked": true,
    "id": "157c69ef084364273ef763cb7058fca84828f9ee",
    "semantic_title": "a specialized semismooth newton method for kernel-based optimal transport",
    "citation_count": 0,
    "authors": [
      "Tianyi Lin",
      "Marco Cuturi",
      "Michael Jordan"
    ]
  },
  "https://proceedings.mlr.press/v238/dai24a.html": {
    "title": "Local Causal Discovery with Linear non-Gaussian Cyclic Models",
    "volume": "main",
    "abstract": "Local causal discovery is of great practical significance, as there are often situations where the discovery of the global causal structure is unnecessary, and the interest lies solely on a single target variable. Most existing local methods utilize conditional independence relations, providing only a partially directed graph, and assume acyclicity for the ground-truth structure, even though real-world scenarios often involve cycles like feedback mechanisms. In this work, we present a general, unified local causal discovery method with linear non-Gaussian models, whether they are cyclic or acyclic. We extend the application of independent component analysis from the global context to independent subspace analysis, enabling the exact identification of the equivalent local directed structures and causal strengths from the Markov blanket of the target variable. We also propose an alternative regression-based method in the particular acyclic scenarios. Our identifiability results are empirically validated using both synthetic and real-world datasets",
    "checked": true,
    "id": "1304f88cf92fecccbcf2c26aaac3d4f0a7964e05",
    "semantic_title": "local causal discovery with linear non-gaussian cyclic models",
    "citation_count": 2,
    "authors": [
      "Haoyue Dai",
      "Ignavier Ng",
      "Yujia Zheng",
      "Zhengqing Gao",
      "Kun Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/park24a.html": {
    "title": "Density Uncertainty Layers for Reliable Uncertainty Estimation",
    "volume": "main",
    "abstract": "Assessing the predictive uncertainty of deep neural networks is crucial for safety-related applications of deep learning. Although Bayesian deep learning offers a principled framework for estimating model uncertainty, the common approaches that approximate the parameter posterior often fail to deliver reliable estimates of predictive uncertainty. In this paper, we propose a novel criterion for reliable predictive uncertainty: a model's predictive variance should be grounded in the empirical density of the input. That is, the model should produce higher uncertainty for inputs that are improbable in the training data and lower uncertainty for inputs that are more probable. To operationalize this criterion, we develop the density uncertainty layer, a stochastic neural network architecture that satisfies the density uncertain criterion by design. We study density uncertainty layers on the UCI and CIFAR-10/100 uncertainty benchmarks. Compared to existing approaches, density uncertainty layers provide more reliable uncertainty estimates and robust out-of-distribution detection performance",
    "checked": true,
    "id": "3cb746ee9ab49920ead4bd832d94ca0bc1ee5d3b",
    "semantic_title": "density uncertainty layers for reliable uncertainty estimation",
    "citation_count": 1,
    "authors": [
      "Yookoon Park",
      "David Blei"
    ]
  },
  "https://proceedings.mlr.press/v238/carton24a.html": {
    "title": "Double InfoGAN for Contrastive Analysis",
    "volume": "main",
    "abstract": "Contrastive Analysis (CA) deals with the discovery of what is common and what is distinctive of a target domain compared to a background one. This is of great interest in many applications, such as medical imaging. Current state-of-the-art (SOTA) methods are latent variable models based on VAE (CA-VAEs). However, they all either ignore important constraints or they don't enforce fundamental assumptions. This may lead to sub-optimal solutions where distinctive factors are mistaken for common ones (or viceversa). Furthermore, the generated images have a rather poor quality, typical of VAEs, decreasing their interpretability and usefulness. Here, we propose Double InfoGAN, the first GAN based method for CA that leverages the high-quality synthesis of GAN and the separation power of InfoGAN. Experimental results on four visual datasets, from simple synthetic examples to complex medical images, show that the proposed method outperforms SOTA CA-VAEs in terms of latent separation and image quality. Datasets and code are available online",
    "checked": true,
    "id": "bcc1580fbd66a0c9f1a008537a02f190b1d07f57",
    "semantic_title": "double infogan for contrastive analysis",
    "citation_count": 2,
    "authors": [
      "Florence Carton",
      "Robin Louiset",
      "Pietro Gori"
    ]
  },
  "https://proceedings.mlr.press/v238/feng24a.html": {
    "title": "Is this model reliable for everyone? Testing for strong calibration",
    "volume": "main",
    "abstract": "In a well-calibrated risk prediction model, the average predicted probability is close to the true event rate for any given subgroup. Such models are reliable across heterogeneous populations and satisfy strong notions of algorithmic fairness. However, the task of auditing a model for strong calibration is well-known to be difficult—particularly for machine learning (ML) algorithms—due to the sheer number of potential subgroups. As such, common practice is to only assess calibration with respect to a few predefined subgroups. Recent developments in goodness-of-fit testing offer potential solutions but are not designed for settings with weak signal or where the poorly calibrated subgroup is small, as they either overly subdivide the data or fail to divide the data at all. We introduce a new testing procedure based on the following insight: if we can reorder observations by their expected residuals, there should be a change in the association between the predicted and observed residuals along this sequence if a poorly calibrated subgroup exists. This lets us reframe the problem of calibration testing into one of changepoint detection, for which powerful methods already exist. We begin with introducing a sample-splitting procedure where a portion of the data is used to train a suite of candidate models for predicting the residual, and the remaining data are used to perform a score-based cumulative sum (CUSUM) test. To further improve power, we then extend this adaptive CUSUM test to incorporate cross-validation, while maintaining Type I error control under minimal assumptions. Compared to existing methods, the proposed procedure consistently achieved higher power in empirical analyses",
    "checked": true,
    "id": "1c965a39aae320fb048ef7d8aa2cf55c8dfb49c1",
    "semantic_title": "is this model reliable for everyone? testing for strong calibration",
    "citation_count": 2,
    "authors": [
      "Jean Feng",
      "Alexej Gossmann",
      "Romain Pirracchio",
      "Nicholas Petrick",
      "Gene A Pennello",
      "Berkman Sahiner"
    ]
  },
  "https://proceedings.mlr.press/v238/palm24a.html": {
    "title": "An Online Bootstrap for Time Series",
    "volume": "main",
    "abstract": "Resampling methods such as the bootstrap have proven invaluable in the field of machine learning. However, the applicability of traditional bootstrap methods is limited when dealing with large streams of dependent data, such as time series or spatially correlated observations. In this paper, we propose a novel bootstrap method that is designed to account for data dependencies and can be executed online, making it particularly suitable for real-time applications. This method is based on an autoregressive sequence of increasingly dependent resampling weights. We prove the theoretical validity of the proposed bootstrap scheme under general conditions. We demonstrate the effectiveness of our approach through extensive simulations and show that it provides reliable uncertainty quantification even in the presence of complex data dependencies. Our work bridges the gap between classical resampling techniques and the demands of modern data analysis, providing a valuable tool for researchers and practitioners in dynamic, data-rich environments",
    "checked": true,
    "id": "80d7b73777ff734ab496f19a153872332d0eb55a",
    "semantic_title": "an online bootstrap for time series",
    "citation_count": 0,
    "authors": [
      "Nicolai Palm",
      "Thomas Nagler"
    ]
  },
  "https://proceedings.mlr.press/v238/xing24a.html": {
    "title": "Better Representations via Adversarial Training in Pre-Training: A Theoretical Perspective",
    "volume": "main",
    "abstract": "Pre-training is known to generate universal representations for downstream tasks in large-scale deep learning such as large language models. Existing literature, e.g., Kim et al. (2020), empirically observe that the downstream tasks can inherit the adversarial robustness of the pre-trained model. We provide theoretical justifications for this robustness inheritance phenomenon. Our theoretical results reveal that feature purification plays an important role in connecting the adversarial robustness of the pre-trained model and the downstream tasks in two-layer neural networks. Specifically, we show that (i) with adversarial training, each hidden node tends to pick only one (or a few) feature; (ii) without adversarial training, the hidden nodes can be vulnerable to attacks. This observation is valid for both supervised pre-training and contrastive learning. With purified nodes, it turns out that clean training is enough to achieve adversarial robustness in downstream tasks",
    "checked": true,
    "id": "56ce2e63d91c8ec1a999f552cbf9918c39006b12",
    "semantic_title": "better representations via adversarial training in pre-training: a theoretical perspective",
    "citation_count": 0,
    "authors": [
      "Yue Xing",
      "Xiaofeng Lin",
      "Qifan Song",
      "Yi Xu",
      "Belinda Zeng",
      "Guang Cheng"
    ]
  },
  "https://proceedings.mlr.press/v238/song24a.html": {
    "title": "Solving Attention Kernel Regression Problem via Pre-conditioner",
    "volume": "main",
    "abstract": "Attention mechanism is the key to large language models, and attention matrix serves as an algorithmic and computational bottleneck for such a scheme. In this paper, we define two problems, motivated by designing fast algorithms for \\emph{proxy} of attention matrix and solving regressions against them. Given an input matrix $A\\in \\mathbb{R}^{n\\times d}$ with $n\\gg d$ and a response vector $b$, we first consider the matrix exponential of the matrix $A^\\top A$ as a proxy, and we in turn design algorithms for two types of regression problems: $\\min_{x\\in \\mathbb{R}^d}\\|(A^\\top A)^jx-b\\|_2$ and $\\min_{x\\in \\mathbb{R}^d}\\|A(A^\\top A)^jx-b\\|_2$ for any positive integer $j$. Studying algorithms for these regressions is essential, as matrix exponential can be approximated term-by-term via these smaller problems. The second proxy is applying exponential entrywise to the Gram matrix, denoted by $\\exp(AA^\\top)$ and solving the regression $\\min_{x\\in \\mathbb{R}^n}\\|\\exp(AA^\\top)x-b \\|_2$. We call this problem the \\emph{attention kernel regression} problem, as the matrix $\\exp(AA^\\top)$ could be viewed as a kernel function with respect to $A$. We design fast algorithms for these regression problems, based on sketching and preconditioning. We hope these efforts will provide an alternative perspective of studying efficient approximation of attention matrices",
    "checked": true,
    "id": "420533d1fc0ef9e652a228a669a858ad7d7162ea",
    "semantic_title": "solving attention kernel regression problem via pre-conditioner",
    "citation_count": 5,
    "authors": [
      "Zhao Song",
      "Junze Yin",
      "Lichen Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/hu24a.html": {
    "title": "Pixel-wise Smoothing for Certified Robustness against Camera Motion Perturbations",
    "volume": "main",
    "abstract": "Deep learning-based visual perception models lack robustness when faced with camera motion perturbations in practice. The current certification process for assessing robustness is costly and time-consuming due to the extensive number of image projections required for Monte Carlo sampling in the 3D camera motion space. To address these challenges, we present a novel, efficient, and practical framework for certifying the robustness of 3D-2D projective transformations against camera motion perturbations. Our approach leverages a smoothing distribution over the 2D-pixel space instead of in the 3D physical space, eliminating the need for costly camera motion sampling and significantly enhancing the efficiency of robustness certifications. With the pixel-wise smoothed classifier, we are able to fully upper bound the projection errors using a technique of uniform partitioning in camera motion space. Additionally, we extend our certification framework to a more general scenario where only a single-frame point cloud is required in the projection oracle. Through extensive experimentation, we validate the trade-off between effectiveness and efficiency enabled by our proposed method. Remarkably, our approach achieves approximately 80% certified accuracy while utilizing only 30% of the projected image frames",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanjiang Hu",
      "Zuxin Liu",
      "Linyi Li",
      "Jiacheng Zhu",
      "Ding Zhao"
    ]
  },
  "https://proceedings.mlr.press/v238/bengs24a.html": {
    "title": "Identifying Copeland Winners in Dueling Bandits with Indifferences",
    "volume": "main",
    "abstract": "We consider the task of identifying the Copeland winner(s) in a dueling bandits problem with ternary feedback. This is an underexplored but practically relevant variant of the conventional dueling bandits problem, in which, in addition to strict preference between two arms, one may observe feedback in the form of an indifference. We provide a lower bound on the sample complexity for any learning algorithm finding the Copeland winner(s) with a fixed error probability. Moreover, we propose POCOWISTA, an algorithm with a sample complexity that almost matches this lower bound, and which shows excellent empirical performance, even for the conventional dueling bandits problem. For the case where the preference probabilities satisfy a specific type of stochastic transitivity, we provide a refined version with an improved worst case sample complexity",
    "checked": true,
    "id": "52d4a52de42491c2bc2c2414e959f9fde5be105f",
    "semantic_title": "identifying copeland winners in dueling bandits with indifferences",
    "citation_count": 0,
    "authors": [
      "Viktor Bengs",
      "Björn Haddenhorst",
      "Eyke Hüllermeier"
    ]
  },
  "https://proceedings.mlr.press/v238/kim24a.html": {
    "title": "Linear Convergence of Black-Box Variational Inference: Should We Stick the Landing?",
    "volume": "main",
    "abstract": "We prove that black-box variational inference (BBVI) with control variates, particularly the sticking-the-landing (STL) estimator, converges at a geometric (traditionally called \"linear\") rate under perfect variational family specification. In particular, we prove a quadratic bound on the gradient variance of the STL estimator, one which encompasses misspecified variational families. Combined with previous works on the quadratic variance condition, this directly implies convergence of BBVI with the use of projected stochastic gradient descent. For the projection operator, we consider a domain with triangular scale matrices, which the projection onto is computable in $\\theta(d)$ time, where $d$ is the dimensionality of the target posterior. We also improve existing analysis on the regular closed-form entropy gradient estimators, which enables comparison against the STL estimator, providing explicit non-asymptotic complexity guarantees for both",
    "checked": true,
    "id": "0e1e358a47a640667311787e54b013e6af505cd6",
    "semantic_title": "linear convergence of black-box variational inference: should we stick the landing?",
    "citation_count": 4,
    "authors": [
      "Kyurae Kim",
      "Yian Ma",
      "Jacob Gardner"
    ]
  },
  "https://proceedings.mlr.press/v238/song24b.html": {
    "title": "Fast Dynamic Sampling for Determinantal Point Processes",
    "volume": "main",
    "abstract": "n this work, we provide fast dynamic algorithms for repeatedly sampling from distributions characterized by Determinantal Point Processes (DPPs) and Nonsymmetric Determinantal Point Processes (NDPPs). DPPs are a very well-studied class of distributions on subsets of items drawn from a ground set of cardinality $n$ characterized by a symmetric $n \\times n$ kernel matrix $L$ such that the probability of any subset is proportional to the determinant of its corresponding principal submatrix. Recent work has shown that the kernel symmetry constraint can be relaxed, leading to NDPPs, which can better model data in several machine learning applications. Given a low-rank kernel matrix ${\\cal L}=L+L^\\top\\in \\mathbb{R}^{n\\times n}$ and its corresponding eigendecomposition specified by $\\{\\lambda_i, u_i \\}_{i=1}^d$ where $d\\leq n$ is the rank, we design a data structure that uses $O(nd)$ space and preprocesses data in $O(nd^{\\omega-1})$ time where $\\omega\\approx 2.37$ is the exponent of matrix multiplication. The data structure can generate a sample according to DPP distribution in time $O(|E|^3\\log n+|E|^{\\omega-1}d^2)$ or according to NDPP distribution in time $O((|E|^3 \\log n+ |E|^{\\omega-1}d^2)(1+w)^d)$ for $E$ being the sampled indices and $w$ is a data-dependent parameter. This improves upon the space and preprocessing time over prior works, and achieves a state-of-the-art sampling time when the sampling set is relatively dense. At the heart of our data structure is an efficient sampling tree that can leverage batch initialization and fast inner product query simultaneously",
    "checked": true,
    "id": "987ec3bbf4132cfb9477c2960702cb44dcf8af2f",
    "semantic_title": "fast dynamic sampling for determinantal point processes",
    "citation_count": 0,
    "authors": [
      "Zhao Song",
      "Junze Yin",
      "Lichen Zhang",
      "Ruizhe Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/li24c.html": {
    "title": "Best Arm Identification with Resource Constraints",
    "volume": "main",
    "abstract": "Motivated by the cost heterogeneity in experimentation across different alternatives, we study the Best Arm Identification with Resource Constraints (BAIwRC) problem. The agent aims to identify the best arm under resource constraints, where resources are consumed for each arm pull. We make two novel contributions. We design and analyze the Successive Halving with Resource Rationing algorithm (SH-RR). The SH-RR achieves a near-optimal non-asymptotic rate of convergence in terms of the probability of successively identifying an optimal arm. Interestingly, we identify a difference in convergence rates between the cases of deterministic and stochastic resource consumption",
    "checked": true,
    "id": "3cf60b3397bb216818fe3e907c5059be448b616b",
    "semantic_title": "best arm identification with resource constraints",
    "citation_count": 0,
    "authors": [
      "Zitian Li",
      "Wang Chi Cheung"
    ]
  },
  "https://proceedings.mlr.press/v238/yang24a.html": {
    "title": "Neural McKean-Vlasov Processes: Distributional Dependence in Diffusion Processes",
    "volume": "main",
    "abstract": "McKean-Vlasov stochastic differential equations (MV-SDEs) provide a mathematical description of the behavior of an infinite number of interacting particles by imposing a dependence on the particle density. We study the influence of explicitly including distributional information in the parameterization of the SDE. We propose a series of semi-parametric methods for representing MV-SDEs, and corresponding estimators for inferring parameters from data based on the properties of the MV-SDE. We analyze the characteristics of the different architectures and estimators, and consider their applicability in relevant machine learning problems. We empirically compare the performance of the different architectures and estimators on real and synthetic datasets for time series and probabilistic modeling. The results suggest that explicitly including distributional dependence in the parameterization of the SDE is effective in modeling temporal data with interaction under an exchangeability assumption while maintaining strong performance for standard Itô-SDEs due to the richer class of probability flows associated with MV-SDEs",
    "checked": true,
    "id": "e9c726973fc3ad0267c4646a40e6ca3910b2ed4f",
    "semantic_title": "neural mckean-vlasov processes: distributional dependence in diffusion processes",
    "citation_count": 1,
    "authors": [
      "Haoming Yang",
      "Ali Hasan",
      "Yuting Ng",
      "Vahid Tarokh"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24a.html": {
    "title": "HintMiner: Automatic Question Hints Mining From Q&A Web Posts with Language Model via Self-Supervised Learning",
    "volume": "main",
    "abstract": "Users often need ask questions and seek answers online. The Question - Answering (QA) forums such as Stack Overflow cannot always respond to the questions timely and properly. In this paper, we propose HintMiner, a novel automatic question hints mining tool for users to help them find answers. HintMiner leverages the machine comprehension and sequence generation techniques to automatically generate hints for users' questions. It firstly retrieve many web Q&A posts and then extract some hints from the posts using MiningNet that is built via a language model. Using the huge amount of online Q&A posts, we design a self-supervised objective to train the MiningNet that is a neural encoder-decoder model based on the transformer and copying mechanisms. We have evaluated HintMiner on 60,000 Stack Overflow questions. The experiment results show that the proposed approach is effective. For example, HintMiner achieves an average BLEU score of 36.17% and an average ROUGE-2 score of 36.29%. Our tool and experimental data are publicly available at \\url{https://github.com/zhangzhenyu13/HintMiner}",
    "checked": true,
    "id": "fd37e67e4c4ac05e0a314c240fb8dafb8b197579",
    "semantic_title": "hintminer: automatic question hints mining from q&a web posts with language model via self-supervised learning",
    "citation_count": 0,
    "authors": [
      "Zhenyu Zhang",
      "JiuDong Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/hong24a.html": {
    "title": "A Primal-Dual-Critic Algorithm for Offline Constrained Reinforcement Learning",
    "volume": "main",
    "abstract": "Offline constrained reinforcement learning (RL) aims to learn a policy that maximizes the expected cumulative reward subject to constraints on expected cumulative cost using an existing dataset. In this paper, we propose Primal-Dual-Critic Algorithm (PDCA), a novel algorithm for offline constrained RL with general function approximation. PDCA runs a primal-dual algorithm on the Lagrangian function estimated by critics. The primal player employs a no-regret policy optimization oracle to maximize the Lagrangian estimate and the dual player acts greedily to minimize the Lagrangian estimate. We show that PDCA finds a near saddle point of the Lagrangian, which is nearly optimal for the constrained RL problem. Unlike previous work that requires concentrability and a strong Bellman completeness assumption, PDCA only requires concentrability and realizability assumptions for sample-efficient learning",
    "checked": true,
    "id": "75605dfe587630c365d092db9f60094067c4110f",
    "semantic_title": "a primal-dual-critic algorithm for offline constrained reinforcement learning",
    "citation_count": 4,
    "authors": [
      "Kihyuk Hong",
      "Yuhang Li",
      "Ambuj Tewari"
    ]
  },
  "https://proceedings.mlr.press/v238/huang24a.html": {
    "title": "On the Statistical Efficiency of Mean-Field Reinforcement Learning with General Function Approximation",
    "volume": "main",
    "abstract": "In this paper, we study the fundamental statistical efficiency of Reinforcement Learning in Mean-Field Control (MFC) and Mean-Field Game (MFG) with general model-based function approximation. We introduce a new concept called Mean-Field Model-Based Eluder Dimension (MF-MBED), which characterizes the inherent complexity of mean-field model classes. We show that a rich family of Mean-Field RL problems exhibits low MF-MBED. Additionally, we propose algorithms based on maximal likelihood estimation, which can return an $\\epsilon$-optimal policy for MFC or an $\\epsilon$-Nash Equilibrium policy for MFG. The overall sample complexity depends only polynomially on MF-MBED, which is potentially much lower than the size of state-action space. Compared with previous works, our results only require the minimal assumptions including realizability and Lipschitz continuity",
    "checked": false,
    "id": "93c5963791eda842b1897a4660d737e76c852b25",
    "semantic_title": "on the statistical efficiency of mean field reinforcement learning with general function approximation",
    "citation_count": 6,
    "authors": [
      "Jiawei Huang",
      "Batuhan Yardim",
      "Niao He"
    ]
  },
  "https://proceedings.mlr.press/v238/demetci24a.html": {
    "title": "Breaking isometric ties and introducing priors in Gromov-Wasserstein distances",
    "volume": "main",
    "abstract": "Gromov-Wasserstein distance has many applications in machine learning due to its ability to compare measures across metric spaces and its invariance to isometric transformations. However, in certain applications, this invariant property can be too flexible, thus undesirable. Moreover, the Gromov-Wasserstein distance solely considers pairwise sample similarities in input datasets, disregarding the raw feature representations. We propose a new optimal transport formulation, called Augmented Gromov-Wasserstein (AGW), that allows for some control over the level of rigidity to transformations. It also incorporates feature alignments, enabling us to better leverage prior knowledge on the input data for improved performance. We first present theoretical insights into the proposed method. We then demonstrate its usefulness for single-cell multi-omic alignment tasks and heterogeneous domain adaptation in machine learning",
    "checked": true,
    "id": "385085f40b48070b4bcf557c7a2eb2c7b90192c2",
    "semantic_title": "breaking isometric ties and introducing priors in gromov-wasserstein distances",
    "citation_count": 0,
    "authors": [
      "Pinar Demetci",
      "Quang Huy Tran",
      "Ievgen Redko",
      "Ritambhara Singh"
    ]
  },
  "https://proceedings.mlr.press/v238/abbas24a.html": {
    "title": "Enhancing In-context Learning via Linear Probe Calibration",
    "volume": "main",
    "abstract": "In-context learning (ICL) is a new paradigm for natural language processing that utilizes Generative Pre-trained Transformer (GPT)-like models. This approach uses prompts that include in-context demonstrations to generate the corresponding output for a new query input. However, applying ICL in real cases does not scale with the number of samples, and lacks robustness to different prompt templates and demonstration permutations. In this paper, we first show that GPT-like models using ICL result in unreliable predictions based on a new metric based on Shannon entropy. Then, to solve this problem, we propose a new technique called the Linear Probe Calibration (LinC), a method that calibrates the model's output probabilities, resulting in reliable predictions and improved performance, while requiring only minimal additional samples (as few as five labeled data samples). LinC significantly enhances the ICL test performance of GPT models on various benchmark datasets, with an average improvement of up to 21%, and up to a 50% improvement in some cases, and significantly boosts the performance of PEFT methods, especially in the low resource regime. Moreover, LinC achieves lower expected calibration error, and is highly robust to varying label proportions, prompt templates, and demonstration permutations",
    "checked": true,
    "id": "2fd6d186eb5648c71eefbcd9baf83471aeefc92b",
    "semantic_title": "enhancing in-context learning via linear probe calibration",
    "citation_count": 3,
    "authors": [
      "Momin Abbas",
      "Yi Zhou",
      "Parikshit Ram",
      "Nathalie Baracaldo",
      "Horst Samulowitz",
      "Theodoros Salonidis",
      "Tianyi Chen"
    ]
  },
  "https://proceedings.mlr.press/v238/lin24b.html": {
    "title": "DNNLasso: Scalable Graph Learning for Matrix-Variate Data",
    "volume": "main",
    "abstract": "We consider the problem of jointly learning row-wise and column-wise dependencies of matrix-variate observations, which are modelled separately by two precision matrices. Due to the complicated structure of Kronecker-product precision matrices in the commonly used matrix-variate Gaussian graphical models, a sparser Kronecker-sum structure was proposed recently based on the Cartesian product of graphs. However, existing methods for estimating Kronecker-sum structured precision matrices do not scale well to large scale datasets. In this paper, we introduce DNNLasso, a diagonally non-negative graphical lasso model for estimating the Kronecker-sum structured precision matrix, which outperforms the state-of-the-art methods by a large margin in both accuracy and computational time",
    "checked": true,
    "id": "e799d36fe2750c994fedd80782bf8c6b5cc9064d",
    "semantic_title": "dnnlasso: scalable graph learning for matrix-variate data",
    "citation_count": 0,
    "authors": [
      "Meixia Lin",
      "Yangjing Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/houry24a.html": {
    "title": "Fast 1-Wasserstein distance approximations using greedy strategies",
    "volume": "main",
    "abstract": "Among numerous linear approximation methods proposed for optimal transport (OT), tree-based methods appear to be fairly reliable, notably for language processing applications. Inspired by these tree methods, we introduce several greedy heuristics aiming to compute even faster approximations of OT. We first explicitly establish the equivalence between greedy matching and optimal transport for tree metrics, and then we show that tree greedy matching can be reduced to greedy matching on a one-dimensional line. Next, we propose two new greedy-based algorithms in one dimension: the $k$-Greedy and 1D-ICT algorithms. This novel approach provides Wasserstein approximations with accuracy similar to the original tree methods on text datasets while being faster in practice. Finally, these algorithms are applicable beyond tree approximations: using sliced projections of the original data still provides fairly good accuracy while eliminating the need for embedding the data in a fixed and rigid tree structure. This property makes these approaches even more versatile than the original tree OT methods",
    "checked": true,
    "id": "cac1ea8c0376c199feaff683d24ed482ba770dcf",
    "semantic_title": "fast 1-wasserstein distance approximations using greedy strategies",
    "citation_count": 0,
    "authors": [
      "Guillaume Houry",
      "Han Bao",
      "Han Zhao",
      "Makoto Yamada"
    ]
  },
  "https://proceedings.mlr.press/v238/carlsson24a.html": {
    "title": "Pure Exploration in Bandits with Linear Constraints",
    "volume": "main",
    "abstract": "We address the problem of identifying the optimal policy with a fixed confidence level in a multi-armed bandit setup, when \\emph{the arms are subject to linear constraints}. Unlike the standard best-arm identification problem which is well studied, the optimal policy in this case may not be deterministic and could mix between several arms. This changes the geometry of the problem which we characterize via an information-theoretic lower bound. We introduce two asymptotically optimal algorithms for this setting, one based on the Track-and-Stop method and the other based on a game-theoretic approach. Both these algorithms try to track an optimal allocation based on the lower bound and computed by a weighted projection onto the boundary of a normal cone. Finally, we provide empirical results that validate our bounds and visualize how constraints change the hardness of the problem",
    "checked": true,
    "id": "2b0fc501d8a776263df434df499322c45933359f",
    "semantic_title": "pure exploration in bandits with linear constraints",
    "citation_count": 2,
    "authors": [
      "Emil Carlsson",
      "Debabrota Basu",
      "Fredrik Johansson",
      "Devdatt Dubhashi"
    ]
  },
  "https://proceedings.mlr.press/v238/dean24a.html": {
    "title": "Emergent specialization from participation dynamics and multi-learner retraining",
    "volume": "main",
    "abstract": "Numerous online services are data-driven: the behavior of users affects the system's parameters, and the system's parameters affect the users' experience of the service, which in turn affects the way users may interact with the system. For example, people may choose to use a service only for tasks that already works well, or they may choose to switch to a different service. These adaptations influence the ability of a system to learn about a population of users and tasks in order to improve its performance broadly. In this work, we analyze a class of such dynamics—where users allocate their participation amongst services to reduce the individual risk they experience, and services update their model parameters to reduce the service's risk on their current user population. We refer to these dynamics as \\emph{risk-reducing}, which cover a broad class of common model updates including gradient descent and multiplicative weights. For this general class of dynamics, we show that asymptotically stable equilibria are always segmented, with sub-populations allocated to a single learner. Under mild assumptions, the utilitarian social optimum is a stable equilibrium. In contrast to previous work, which shows that repeated risk minimization can result in representation disparity and high overall loss with a single learner (Hashimoto et al., 2018; Miller et al., 2021), we find that repeated myopic updates with multiple learners lead to better outcomes. We illustrate the phenomena via a simulated example initialized from real data",
    "checked": true,
    "id": "e42a3e626322f3fb46f31d40dacfc5142cdca044",
    "semantic_title": "emergent specialization from participation dynamics and multi-learner retraining",
    "citation_count": 2,
    "authors": [
      "Sarah Dean",
      "Mihaela Curmei",
      "Lillian Ratliff",
      "Jamie Morgenstern",
      "Maryam Fazel"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24b.html": {
    "title": "Optimal Sparse Survival Trees",
    "volume": "main",
    "abstract": "Interpretability is crucial for doctors, hospitals, pharmaceutical companies and biotechnology corporations to analyze and make decisions for high stakes problems that involve human health. Tree-based methods have been widely adopted for survival analysis due to their appealing interpretablility and their ability to capture complex relationships. However, most existing methods to produce survival trees rely on heuristic (or greedy) algorithms, which risk producing sub-optimal models. We present a dynamic-programming-with-bounds approach that finds provably-optimal sparse survival tree models, frequently in only a few seconds",
    "checked": true,
    "id": "360409a49002e741d350c0051eddec6bc1fa896f",
    "semantic_title": "optimal sparse survival trees",
    "citation_count": 0,
    "authors": [
      "Rui Zhang",
      "Rui Xin",
      "Margo Seltzer",
      "Cynthia Rudin"
    ]
  },
  "https://proceedings.mlr.press/v238/li24d.html": {
    "title": "TenGAN: Pure Transformer Encoders Make an Efficient Discrete GAN for De Novo Molecular Generation",
    "volume": "main",
    "abstract": "Deep generative models for de novo molecular generation using discrete data, such as the simplified molecular-input line-entry system (SMILES) strings, have attracted widespread attention in drug design. However, training instability often plagues generative adversarial networks (GANs), leading to problems such as mode collapse and low diversity. This study proposes a pure transformer encoder-based GAN (TenGAN) to solve these issues. The generator and discriminator of TenGAN are variants of the transformer encoders and are combined with reinforcement learning (RL) to generate molecules with the desired chemical properties. Besides, data augmentation of the variant SMILES is leveraged for the TenGAN training to learn the semantics and syntax of SMILES strings. Additionally, we introduce an enhanced variant of TenGAN, named Ten(W)GAN, which incorporates mini-batch discrimination and Wasserstein GAN to improve the ability to generate molecules. The experimental results and ablation studies on the QM9 and ZINC datasets showed that the proposed models generated highly valid and novel molecules with the desired chemical properties in a computationally efficient manner",
    "checked": true,
    "id": "4a7e8e7dfab88a4613eff758d74e023c12a73ef1",
    "semantic_title": "tengan: pure transformer encoders make an efficient discrete gan for de novo molecular generation",
    "citation_count": 1,
    "authors": [
      "Chen Li",
      "Yoshihiro Yamanishi"
    ]
  },
  "https://proceedings.mlr.press/v238/yoshikawa24a.html": {
    "title": "Explanation-based Training with Differentiable Insertion/Deletion Metric-aware Regularizers",
    "volume": "main",
    "abstract": "The quality of explanations for the predictions made by complex machine learning predictors is often measured using insertion and deletion metrics, which assess the faithfulness of the explanations, i.e., how accurately the explanations reflect the predictor's behavior. To improve the faithfulness, we propose insertion/deletion metric-aware explanation-based optimization (ID-ExpO), which optimizes differentiable predictors to improve both the insertion and deletion scores of the explanations while maintaining their predictive accuracy. Because the original insertion and deletion metrics are non-differentiable with respect to the explanations and directly unavailable for gradient-based optimization, we extend the metrics so that they are differentiable and use them to formalize insertion and deletion metric-based regularizers. Our experimental results on image and tabular datasets show that the deep neural network-based predictors that are fine-tuned using ID-ExpO enable popular post-hoc explainers to produce more faithful and easier-to-interpret explanations while maintaining high predictive accuracy. The code is available at https://github.com/yuyay/idexpo",
    "checked": true,
    "id": "4b0b320baf8f7d1b2d4c9b252d227116be935970",
    "semantic_title": "explanation-based training with differentiable insertion/deletion metric-aware regularizers",
    "citation_count": 0,
    "authors": [
      "Yuya Yoshikawa",
      "Tomoharu Iwata"
    ]
  },
  "https://proceedings.mlr.press/v238/baudry24a.html": {
    "title": "Multi-armed bandits with guaranteed revenue per arm",
    "volume": "main",
    "abstract": "We consider a Multi-Armed Bandit problem with covering constraints, where the primary goal is to ensure that each arm receives a minimum expected reward while maximizing the total cumulative reward. In this scenario, the optimal policy then belongs to some unknown feasible set. Unlike much of the existing literature, we do not assume the presence of a safe policy or a feasibility margin, which hinders the exclusive use of conservative approaches. Consequently, we propose and analyze an algorithm that switches between pessimism and optimism in the face of uncertainty. We prove both precise problem-dependent and problem-independent bounds, demonstrating that our algorithm achieves the best of the two approaches—depending on the presence or absence of a feasibility margin—in terms of constraint violation guarantees. Furthermore, our results indicate that playing greedily on the constraints actually outperforms pessimism when considering long-term violations rather than violations on a per-round basis",
    "checked": true,
    "id": "62eafea540141083378a1f83d3d8d42f0289539a",
    "semantic_title": "multi-armed bandits with guaranteed revenue per arm",
    "citation_count": 0,
    "authors": [
      "Dorian Baudry",
      "Nadav Merlis",
      "Mathieu Benjamin Molina",
      "Hugo Richard",
      "Vianney Perchet"
    ]
  },
  "https://proceedings.mlr.press/v238/richard24a.html": {
    "title": "Constant or Logarithmic Regret in Asynchronous Multiplayer Bandits with Limited Communication",
    "volume": "main",
    "abstract": "Multiplayer bandits have recently garnered significant attention due to their relevance in cognitive radio networks. While the existing body of literature predominantly focuses on synchronous players, real-world radio networks, such as those in IoT applications, often feature asynchronous (i.e., randomly activated) devices. This highlights the need for addressing the more challenging asynchronous multiplayer bandits problem. Our first result shows that a natural extension of UCB achieves a minimax regret of $\\mathcal{O}(\\sqrt{T\\log(T)})$ in the centralized setting. More significantly, we introduce Cautious Greedy, which uses $\\mathcal{O}(\\log(T))$ communications and whose instance-dependent regret is constant if the optimal policy assigns at least one player to each arm (a situation proven to occur when arm means are sufficiently close). Otherwise, the regret is, as usual, $\\log(T)$ times the sum of some inverse sub-optimality gaps. We substantiate the optimality of Cautious Greedy through lower-bound analysis based on data-dependent terms. Therefore, we establish a strong baseline for asynchronous multiplayer bandits, at least with $\\mathcal{O}(\\log(T))$ communications",
    "checked": true,
    "id": "b1ef4b93d38ddc77995383e9f99b9504144f5620",
    "semantic_title": "constant or logarithmic regret in asynchronous multiplayer bandits with limited communication",
    "citation_count": 0,
    "authors": [
      "Hugo Richard",
      "Etienne Boursier",
      "Vianney Perchet"
    ]
  },
  "https://proceedings.mlr.press/v238/savvides24a.html": {
    "title": "Error bounds for any regression model using Gaussian processes with gradient information",
    "volume": "main",
    "abstract": "We provide an upper bound for the expected quadratic loss on new data for any regression model. We derive the bound by modelling the underlying function by a Gaussian process (GP). Instead of a single kernel or family of kernels of the same form, we consider all GPs with translation-invariant and continuously twice differentiable kernels having a bounded signal variance and prior covariance of the gradient. To obtain a bound for the expected posterior loss, we present bounds for the posterior variance and squared bias. The squared bias bound depends on the regression model used, which can be arbitrary and not based on GPs. The bounds scale well with data size, in contrast to computing the GP posterior by a Cholesky factorisation of a large matrix. More importantly, our bounds do not require strong prior knowledge as we do not specify the exact kernel form. We validate our theoretical findings by numerical experiments and show that the bounds have applications in uncertainty estimation and concept drift detection",
    "checked": true,
    "id": "c975d41eb6b7e16d0e3c3740981ac44dc6679a2e",
    "semantic_title": "error bounds for any regression model using gaussian processes with gradient information",
    "citation_count": 0,
    "authors": [
      "Rafael Savvides",
      "Hoang Phuc Hau Luu",
      "Kai Puolamäki"
    ]
  },
  "https://proceedings.mlr.press/v238/guimera-cuevas24a.html": {
    "title": "Robust Non-linear Normalization of Heterogeneous Feature Distributions with Adaptive Tanh-Estimators",
    "volume": "main",
    "abstract": "Feature normalization is a crucial step in machine learning that scales numerical values to improve model effectiveness. Noisy or impure datasets can pose a challenge for traditional normalization methods as they may contain outliers that violate statistical assumptions, leading to reduced model performance and increased unpredictability. Non-linear Tanh-Estimators (TE) have been found to provide robust feature normalization, but their fixed scaling factor may not be appropriate for all distributions of feature values. This work presents a refinement to the TE that employs the Wasserstein distance to adaptively estimate the optimal scaling factor for each feature individually against a specified target distribution. The results demonstrate that this adaptive approach can outperform the current TE method in the literature in terms of convergence speed by enabling better initial training starts, thus reducing or eliminating the need to re-adjust model weights during early training phases due to inadequately scaled features. Empirical evaluation was done on synthetic data, standard toy computer vision datasets, and a real-world numeric tabular dataset",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felip Guimerà Cuevas",
      "Helmut Schmid"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24a.html": {
    "title": "Learning Granger Causality from Instance-wise Self-attentive Hawkes Processes",
    "volume": "main",
    "abstract": "We address the problem of learning Granger causality from asynchronous, interdependent, multi-type event sequences. In particular, we are interested in discovering instance-level causal structures in an unsupervised manner. Instance-level causality identifies causal relationships among individual events, providing more fine-grained information for decision-making. Existing work in the literature either requires strong assumptions, such as linearity in the intensity function, or heuristically defined model parameters that do not necessarily meet the requirements of Granger causality. We propose Instance-wise Self-Attentive Hawkes Processes (ISAHP), a novel deep learning framework that can directly infer the Granger causality at the event instance level. ISAHP is the first neural point process model that meets the requirements of Granger causality. It leverages the self-attention mechanism of the transformer to align with the principles of Granger causality. We empirically demonstrate that ISAHP is capable of discovering complex instance-level causal structures that cannot be handled by classical models. We also show that ISAHP achieves state-of-the-art performance in proxy tasks involving type-level causal discovery and instance-level event type prediction",
    "checked": true,
    "id": "5fcd8a50ae8ad279ebfe2566956815155b32a891",
    "semantic_title": "learning granger causality from instance-wise self-attentive hawkes processes",
    "citation_count": 0,
    "authors": [
      "Dongxia Wu",
      "Tsuyoshi Ide",
      "Georgios Kollias",
      "Jiri Navratil",
      "Aurelie Lozano",
      "Naoki Abe",
      "Yian Ma",
      "Rose Yu"
    ]
  },
  "https://proceedings.mlr.press/v238/hands24a.html": {
    "title": "P-tensors: a General Framework for Higher Order Message Passing in Subgraph Neural Networks",
    "volume": "main",
    "abstract": "Several recent papers have proposed increasing the expressiveness of graph neural networks by exploiting subgraphs or other topological structures. In parallel, researchers have investigated higher order permutation equivariant networks. In this paper we tie these two threads together by providing a general framework for higher order permutation equivariant message passing in subgraph neural networks. Our exposition hinges on so-called $P$-tensors, which provide a simple way to define the most general form of permutation equivariant message passing in this category of networks. We show that this paradigm can achieve state-of-the-art performance on benchmark molecular datasets",
    "checked": true,
    "id": "d795f9eac83f783151c7a610620c271433d2953d",
    "semantic_title": "p-tensors: a general framework for higher order message passing in subgraph neural networks",
    "citation_count": 0,
    "authors": [
      "Andrew R. Hands",
      "Tianyi Sun",
      "Risi Kondor"
    ]
  },
  "https://proceedings.mlr.press/v238/saha24a.html": {
    "title": "Faster Convergence with MultiWay Preferences",
    "volume": "main",
    "abstract": "We address the problem of convex optimization with preference feedback, where the goal is to minimize a convex function given a weaker form of comparison queries. Each query consists of two points and the dueling feedback returns a (noisy) single-bit binary comparison of the function values of the two queried points. Here we consider the sign-function-based comparison feedback model and analyze the convergence rates with batched and multiway (argmin of a set queried points) comparisons. Our main goal is to understand the improved convergence rates owing to parallelization in sign-feedback-based optimization problems. Our work is the first to study the problem of convex optimization with multiway preferences and analyze the optimal convergence rates. Our first contribution lies in designing efficient algorithms with a convergence rate of $\\smash{\\widetilde O}(\\frac{d}{\\min\\{m,d\\} \\epsilon})$ for $m$-batched preference feedback where the learner can query $m$-pairs in parallel. We next study a $m$-multiway comparison (‘battling') feedback, where the learner can get to see the argmin feedback of $m$-subset of queried points and show a convergence rate of $\\smash{\\widetilde O}(\\frac{d}{ \\min\\{\\log m,d\\}\\epsilon })$. We show further improved convergence rates with an additional assumption of strong convexity. Finally, we also study the convergence lower bounds for batched preferences and multiway feedback optimization showing the optimality of our convergence rates w.r.t. $m$",
    "checked": true,
    "id": "ebd5cee7c0b327360f8ffc2d1f002c88c20a02f0",
    "semantic_title": "faster convergence with multiway preferences",
    "citation_count": 0,
    "authors": [
      "Aadirupa Saha",
      "Vitaly Feldman",
      "Yishay Mansour",
      "Tomer Koren"
    ]
  },
  "https://proceedings.mlr.press/v238/gong24a.html": {
    "title": "Testing Generated Distributions in GANs to Penalize Mode Collapse",
    "volume": "main",
    "abstract": "Mode collapse remains the primary unresolved challenge within generative adversarial networks (GANs). In this work, we introduce an innovative approach that supplements the discriminator by additionally enforcing the similarity between the generated and real distributions. We implement a one-sample test on the generated samples and employ the resulting test statistic to penalize deviations from the real distribution. Our method encompasses a practical strategy to estimate distributions, compute the test statistic via a differentiable function, and seamlessly incorporate test outcomes into the training objective. Crucially, our approach preserves the convergence and theoretical integrity of GANs, as the introduced constraint represents a requisite condition for optimizing the generator training objective. Notably, our method circumvents reliance on regularization or network modules, enhancing compatibility and facilitating its practical application. Empirical evaluations on diverse public datasets validate the efficacy of our proposed approach",
    "checked": true,
    "id": "b601bbbd465c99af0217d52058f824e543d32523",
    "semantic_title": "testing generated distributions in gans to penalize mode collapse",
    "citation_count": 0,
    "authors": [
      "Yanxiang Gong",
      "Zhiwei Xie",
      "Mei Xie",
      "Xin Ma"
    ]
  },
  "https://proceedings.mlr.press/v238/cabannes24a.html": {
    "title": "The Galerkin method beats Graph-Based Approaches for Spectral Algorithms",
    "volume": "main",
    "abstract": "Historically, the machine learning community has derived spectral decompositions from graph-based approaches. We break with this approach and prove the statistical and computational superiority of the Galerkin method, which consists in restricting the study to a small set of test functions. In particular, we introduce implementation tricks to deal with differential operators in large dimensions with structured kernels. Finally, we extend on the core principles beyond our approach to apply them to non-linear spaces of functions, such as the ones parameterized by deep neural networks, through loss-based optimization procedures",
    "checked": true,
    "id": "c6fa9d1ec3ac195c5020c552c135b926b7713ba4",
    "semantic_title": "the galerkin method beats graph-based approaches for spectral algorithms",
    "citation_count": 2,
    "authors": [
      "Vivien A. Cabannes",
      "Francis Bach"
    ]
  },
  "https://proceedings.mlr.press/v238/sima24a.html": {
    "title": "Online Distribution Learning with Local Privacy Constraints",
    "volume": "main",
    "abstract": "We study the problem of online conditional distribution estimation with \\emph{unbounded} label sets under local differential privacy. The problem may be succinctly stated as follows. Let $\\mathcal{F}$ be a distribution-valued function class with an unbounded label set. Our aim is to estimate an \\emph{unknown} function $f\\in \\mathcal{F}$ in an online fashion. More precisely, at time $t$, given a sample ${\\mathbf{x}}_t$, we generate an estimate of $f({\\mathbf{x}}_t)$ using only a \\emph{privatized} version of the true \\emph{labels} sampled from $f({\\mathbf{x}}_t)$. The objective is to minimize the cumulative KL-risk of a finite horizon $T$. We show that under $(\\epsilon,0)$-local differential privacy for the labels, the KL-risk equals $\\tilde{\\Theta}(\\frac{1}{\\epsilon}\\sqrt{KT}),$ up to poly-logarithmic factors, where $K=|\\mathcal{F}|$. This result significantly differs from the $\\tilde{\\Theta}(\\sqrt{T\\log K})$ bound derived in Wu et al., (2023a) for \\emph{bounded} label sets. As a side-result, our approach recovers a nearly tight upper bound for the hypothesis selection problem of Gopi et al., (2020), which has only been established for the \\emph{batch} setting",
    "checked": true,
    "id": "076be151b0912594c601504da397759a9d60eedd",
    "semantic_title": "online distribution learning with local privacy constraints",
    "citation_count": 0,
    "authors": [
      "Jin Sima",
      "Changlong Wu",
      "Olgica Milenkovic",
      "Wojciech Szpankowski"
    ]
  },
  "https://proceedings.mlr.press/v238/kyu-kwon24a.html": {
    "title": "Minimax optimal density estimation using a shallow generative model with a one-dimensional latent variable",
    "volume": "main",
    "abstract": "A deep generative model yields an implicit estimator for the unknown distribution or density function of the observation. This paper investigates some statistical properties of the implicit density estimator pursued by VAE-type methods from a nonparametric density estimation framework. More specifically, we obtain convergence rates of the VAE-type density estimator under the assumption that the underlying true density function belongs to a locally Holder class. Remarkably, a near minimax optimal rate with respect to the Hellinger metric can be achieved by the simplest network architecture, a shallow generative model with a one-dimensional latent variable",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hyeok Kyu Kwon",
      "Minwoo Chae"
    ]
  },
  "https://proceedings.mlr.press/v238/ananthakrishnan24a.html": {
    "title": "Delegating Data Collection in Decentralized Machine Learning",
    "volume": "main",
    "abstract": "Motivated by the emergence of decentralized machine learning (ML) ecosystems, we study the delegation of data collection. Taking the field of contract theory as our starting point, we design optimal and near-optimal contracts that deal with two fundamental information asymmetries that arise in decentralized ML: uncertainty in the assessment of model quality and uncertainty regarding the optimal performance of any model. We show that a principal can cope with such asymmetry via simple linear contracts that achieve $1-1/\\epsilon$ fraction of the optimal utility. To address the lack of a priori knowledge regarding the optimal performance, we give a convex program that can adaptively and efficiently compute the optimal contract. We also analyze the optimal utility and linear contracts for the more complex setting of multiple interactions",
    "checked": true,
    "id": "a34bad7b02ba6572c020b4a0347872153392ec17",
    "semantic_title": "delegating data collection in decentralized machine learning",
    "citation_count": 3,
    "authors": [
      "Nivasini Ananthakrishnan",
      "Stephen Bates",
      "Michael Jordan",
      "Nika Haghtalab"
    ]
  },
  "https://proceedings.mlr.press/v238/isik24a.html": {
    "title": "Adaptive Compression in Federated Learning via Side Information",
    "volume": "main",
    "abstract": "The high communication cost of sending model updates from the clients to the server is a significant bottleneck for scalable federated learning (FL). Among existing approaches, state-of-the-art bitrate-accuracy tradeoffs have been achieved using stochastic compression methods – in which the client n sends a sample from a client-only probability distribution $q_{\\phi^{(n)}}$, and the server estimates the mean of the clients' distributions using these samples. However, such methods do not take full advantage of the FL setup where the server, throughout the training process, has side information in the form of a global distribution $p_{\\theta}$ that is close to the client-only distribution $q_{\\phi^{(n)}}$ in Kullback-Leibler (KL) divergence. In this work, we exploit this \\emph{closeness} between the clients' distributions $q_{\\phi^{(n)}}$'s and the side information $p_{\\theta}$ at the server, and propose a framework that requires approximately $D_{KL}(q_{\\phi^{(n)}}|| p_{\\theta})$ bits of communication. We show that our method can be integrated into many existing stochastic compression frameworks to attain the same (and often higher) test accuracy with up to 82 times smaller bitrate than the prior work – corresponding to 2,650 times overall compression",
    "checked": true,
    "id": "82b0100ee958fa6d831391cb4aa7b1bc8042a13b",
    "semantic_title": "adaptive compression in federated learning via side information",
    "citation_count": 4,
    "authors": [
      "Berivan Isik",
      "Francesco Pase",
      "Deniz Gunduz",
      "Sanmi Koyejo",
      "Tsachy Weissman",
      "Michele Zorzi"
    ]
  },
  "https://proceedings.mlr.press/v238/adachi24b.html": {
    "title": "Adaptive Batch Sizes for Active Learning: A Probabilistic Numerics Approach",
    "volume": "main",
    "abstract": "Active learning parallelization is widely used, but typically relies on fixing the batch size throughout experimentation. This fixed approach is inefficient because of a dynamic trade-off between cost and speed—larger batches are more costly, smaller batches lead to slower wall-clock run-times—and the trade-off may change over the run (larger batches are often preferable earlier). To address this trade-off, we propose a novel Probabilistic Numerics framework that adaptively changes batch sizes. By framing batch selection as a quadrature task, our integration-error-aware algorithm facilitates the automatic tuning of batch sizes to meet predefined quadrature precision objectives, akin to how typical optimizers terminate based on convergence thresholds. This approach obviates the necessity for exhaustive searches across all potential batch sizes. We also extend this to scenarios with constrained active learning and constrained optimization, interpreting constraint violations as reductions in the precision requirement, to subsequently adapt batch construction. Through extensive experiments, we demonstrate that our approach significantly enhances learning efficiency and flexibility in diverse Bayesian batch active learning and Bayesian optimization applications",
    "checked": true,
    "id": "a420222563da4ed3412ce3f453ec0b99bb3ca4db",
    "semantic_title": "adaptive batch sizes for active learning: a probabilistic numerics approach",
    "citation_count": 4,
    "authors": [
      "Masaki Adachi",
      "Satoshi Hayakawa",
      "Martin Jørgensen",
      "Xingchen Wan",
      "Vu Nguyen",
      "Harald Oberhauser",
      "Michael A. Osborne"
    ]
  },
  "https://proceedings.mlr.press/v238/adachi24a.html": {
    "title": "Looping in the Human: Collaborative and Explainable Bayesian Optimization",
    "volume": "main",
    "abstract": "Like many optimizers, Bayesian optimization often falls short of gaining user trust due to opacity. While attempts have been made to develop human-centric optimizers, they typically assume user knowledge is well-specified and error-free, employing users mainly as supervisors of the optimization process. We relax these assumptions and propose a more balanced human-AI partnership with our Collaborative and Explainable Bayesian Optimization (CoExBO) framework. Instead of explicitly requiring a user to provide a knowledge model, CoExBO employs preference learning to seamlessly integrate human insights into the optimization, resulting in algorithmic suggestions that resonate with user preference. CoExBO explains its candidate selection every iteration to foster trust, empowering users with a clearer grasp of the optimization. Furthermore, CoExBO offers a no-harm guarantee, allowing users to make mistakes; even with extreme adversarial interventions, the algorithm converges asymptotically to a vanilla Bayesian optimization. We validate CoExBO's efficacy through human-AI teaming experiments in lithium-ion battery design, highlighting substantial improvements over conventional methods. Code is available https://github.com/ma921/CoExBO",
    "checked": true,
    "id": "e74aae28c1295639d0c4f89b6778d978f0cff9d3",
    "semantic_title": "looping in the human: collaborative and explainable bayesian optimization",
    "citation_count": 6,
    "authors": [
      "Masaki Adachi",
      "Brady Planden",
      "David Howey",
      "Michael A. Osborne",
      "Sebastian Orbell",
      "Natalia Ares",
      "Krikamol Muandet",
      "Siu Lun Chau"
    ]
  },
  "https://proceedings.mlr.press/v238/chatterjee24a.html": {
    "title": "Efficient Quantum Agnostic Improper Learning of Decision Trees",
    "volume": "main",
    "abstract": "The agnostic setting is the hardest generalization of the PAC model since it is akin to learning with adversarial noise. In this paper, we give a poly $(n, t, 1/\\epsilon)$ quantum algorithm for learning size $t$ decision trees over $n$-bit inputs with uniform marginal over instances, in the agnostic setting, without membership queries (MQ). This is the first algorithm (classical or quantum) for efficiently learning decision trees without MQ. First, we construct a quantum agnostic weak learner by designing a quantum variant of the classical Goldreich-Levin algorithm that works with strongly biased function oracles. Next, we show how to quantize the agnostic boosting algorithm by Kalai and Kanade (2009) to obtain the first efficient quantum agnostic boosting algorithm (that has a polynomial speedup over existing adaptive quantum boosting algorithms). We then use the quantum agnostic boosting algorithm to boost the weak quantum agnostic learner constructed previously to obtain a quantum agnostic learner for decision trees. Using the above framework, we also give quantum decision tree learning algorithms without MQ in weaker noise models",
    "checked": true,
    "id": "d787681327d1f1d44ab608e4505592d386e14535",
    "semantic_title": "efficient quantum agnostic improper learning of decision trees",
    "citation_count": 1,
    "authors": [
      "Sagnik Chatterjee",
      "Tharrmashastha SAPV",
      "Debajyoti Bera"
    ]
  },
  "https://proceedings.mlr.press/v238/bilaj24a.html": {
    "title": "Meta Learning in Bandits within shared affine Subspaces",
    "volume": "main",
    "abstract": "We study the problem of meta-learning several contextual stochastic bandits tasks by leveraging their concentration around a low dimensional affine subspace, which we learn via online principal component analysis to reduce the expected regret over the encountered bandits. We propose and theoretically analyze two strategies that solve the problem: One based on the principle of optimism in the face of uncertainty and the other via Thompson sampling. Our framework is generic and includes previously proposed approaches as special cases. Besides, the empirical results show that our methods significantly reduce the regret on several bandit tasks",
    "checked": true,
    "id": "43b4c6e0e60d5b6ba7dc481755e114e4eb40ddbc",
    "semantic_title": "meta learning in bandits within shared affine subspaces",
    "citation_count": 1,
    "authors": [
      "Steven Bilaj",
      "Sofien Dhouib",
      "Setareh Maghsudi"
    ]
  },
  "https://proceedings.mlr.press/v238/braun24a.html": {
    "title": "VEC-SBM: Optimal Community Detection with Vectorial Edges Covariates",
    "volume": "main",
    "abstract": "Social networks are often associated with rich side information, such as texts and images. While numerous methods have been developed to identify communities from pairwise interactions, they usually ignore such side information. In this work, we study an extension of the Stochastic Block Model (SBM), a widely used statistical framework for community detection, that integrates vectorial edges covariates: the Vectorial Edges Covariates Stochastic Block Model (VEC-SBM). We propose a novel algorithm based on iterative refinement techniques and show that it optimally recovers the latent communities under the VEC-SBM. Furthermore, we rigorously assess the added value of leveraging edge's side information in the community detection process. We complement our theoretical results with numerical experiments on synthetic and semi-synthetic data",
    "checked": true,
    "id": "27c134900d10436cbd0025ea224b95c5d3594b36",
    "semantic_title": "vec-sbm: optimal community detection with vectorial edges covariates",
    "citation_count": 0,
    "authors": [
      "Guillaume Braun",
      "Masashi Sugiyama"
    ]
  },
  "https://proceedings.mlr.press/v238/zhu24a.html": {
    "title": "Robust Offline Reinforcement Learning with Heavy-Tailed Rewards",
    "volume": "main",
    "abstract": "This paper endeavors to augment the robustness of offline reinforcement learning (RL) in scenarios laden with heavy-tailed rewards, a prevalent circumstance in real-world applications. We propose two algorithmic frameworks, ROAM and ROOM, for robust off-policy evaluation and offline policy optimization (OPO), respectively. Central to our frameworks is the strategic incorporation of the median-of-means method with offline RL, enabling straightforward uncertainty estimation for the value function estimator. This not only adheres to the principle of pessimism in OPO but also adeptly manages heavy-tailed rewards. Theoretical results and extensive experiments demonstrate that our two frameworks outperform existing methods on the logged dataset exhibits heavy-tailed reward distributions. The implementation of the proposal is available at \\url{https://github.com/Mamba413/ROOM}",
    "checked": true,
    "id": "179addc882c4c977215a0125651119e8cefa4ccc",
    "semantic_title": "robust offline reinforcement learning with heavy-tailed rewards",
    "citation_count": 0,
    "authors": [
      "Jin Zhu",
      "Runzhe Wan",
      "Zhengling Qi",
      "Shikai Luo",
      "Chengchun Shi"
    ]
  },
  "https://proceedings.mlr.press/v238/fokkema24a.html": {
    "title": "The Risks of Recourse in Binary Classification",
    "volume": "main",
    "abstract": "Algorithmic recourse provides explanations that help users overturn an unfavorable decision by a machine learning system. But so far very little attention has been paid to whether providing recourse is beneficial or not. We introduce an abstract learning-theoretic framework that compares the risks (i.e., expected losses) for classification with and without algorithmic recourse. This allows us to answer the question of when providing recourse is beneficial or harmful at the population level. Surprisingly, we find that there are many plausible scenarios in which providing recourse turns out to be harmful, because it pushes users to regions of higher class uncertainty and therefore leads to more mistakes. We further study whether the party deploying the classifier has an incentive to strategize in anticipation of having to provide recourse, and we find that sometimes they do, to the detriment of their users. Providing algorithmic recourse may therefore also be harmful at the systemic level. We confirm our theoretical findings in experiments on simulated and real-world data. All in all, we conclude that the current concept of algorithmic recourse is not reliably beneficial, and therefore requires rethinking",
    "checked": true,
    "id": "a69f15c4659b8c69b9b3446c3cc45e27d3e10251",
    "semantic_title": "the risks of recourse in binary classification",
    "citation_count": 1,
    "authors": [
      "Hidde Fokkema",
      "Damien Garreau",
      "Tim van Erven"
    ]
  },
  "https://proceedings.mlr.press/v238/li24e.html": {
    "title": "Prior-dependent analysis of posterior sampling reinforcement learning with function approximation",
    "volume": "main",
    "abstract": "This work advances randomized exploration in reinforcement learning (RL) with function approximation modeled by linear mixture MDPs. We establish the first prior-dependent Bayesian regret bound for RL with function approximation; and refine the Bayesian regret analysis for posterior sampling reinforcement learning (PSRL), presenting an upper bound of $\\tilde{\\mathcal{O}}(d\\sqrt{H^3 T \\log T})$, where $d$ represents the dimensionality of the transition kernel, $H$ the planning horizon, and $T$ the total number of interactions. This signifies a methodological enhancement by optimizing the $\\mathcal{O}(\\sqrt{\\log T})$ factor over the previous benchmark (Osband and Van Roy, 2014) specified to linear mixture MDPs. Our approach, leveraging a value-targeted model learning perspective, introduces a decoupling argument and a variance reduction technique, moving beyond traditional analyses reliant on confidence sets and concentration inequalities to formalize Bayesian regret bounds more effectively",
    "checked": true,
    "id": "dd089f7e75f8e7fc12b0e8051b328fa6779d9632",
    "semantic_title": "prior-dependent analysis of posterior sampling reinforcement learning with function approximation",
    "citation_count": 0,
    "authors": [
      "Yingru Li",
      "Zhiquan Luo"
    ]
  },
  "https://proceedings.mlr.press/v238/dalirrooyfard24a.html": {
    "title": "Graph Partitioning with a Move Budget",
    "volume": "main",
    "abstract": "In many real world networks, there already exists a (not necessarily optimal) $k$-partitioning of the network. Oftentimes, for such networks, one aims to find a $k$-partitioning with a smaller cut value by moving only a few nodes across partitions. The number of nodes that can be moved across partitions is often a constraint forced by budgetary limitations. Motivated by such real-world applications, we introduce and study the $r$-move $k$-partitioning problem, a natural variant of the Multiway cut problem. Given a graph, a set of $k$ terminals and an initial partitioning of the graph, the $r$-move $k$-partitioning problem aims to find a $k$-partitioning with the minimum-weighted cut among all the $k$-partitionings that can be obtained by moving at most $r$ non-terminal nodes to partitions different from their initial ones. Our main result is a polynomial time $3(r+1)$ approximation algorithm for this problem. We further show that this problem is $W[1]$-hard, and give an FPTAS for when $r$ is a small constant",
    "checked": true,
    "id": "413f566badb404c45109ab07c1b49c645fbfa12b",
    "semantic_title": "graph partitioning with a move budget",
    "citation_count": 0,
    "authors": [
      "Mina Dalirrooyfard",
      "Elaheh Fata",
      "Majid Behbahani",
      "Yuriy Nevmyvaka"
    ]
  },
  "https://proceedings.mlr.press/v238/limnios24a.html": {
    "title": "On Ranking-based Tests of Independence",
    "volume": "main",
    "abstract": "In this paper we develop a novel nonparametric framework to test the independence of two random variables $X$ and $Y$ with unknown respective marginals $H(dx)$ and $G(dy)$ and joint distribution $F(dxdy)$, based on Receiver Operating Characteristic (ROC) analysis and bipartite ranking. The rationale behind our approach relies on the fact that, the independence hypothesis $\\mathcal{H}_0$ is necessarily false as soon as the optimal scoring function related to the pair of distributions $(H\\otimes G,;{F})$, obtained from a bipartite ranking algorithm, has a ROC curve that deviates from the main diagonal of the unit square. We consider a wide class of rank statistics encompassing many ways of deviating from the diagonal in the ROC space to build tests of independence. Beyond its great flexibility, this new method has theoretical properties that far surpass those of its competitors. Nonasymptotic bounds for the two types of testing errors are established. From an empirical perspective, the novel procedure we promote in this paper exhibits a remarkable ability to detect small departures, of various types, from the null assumption $\\mathcal{H}_0$, even in high dimension, as supported by the numerical experiments presented here",
    "checked": true,
    "id": "c40b4625730bfcc6ee9e30dd6aa136152256f8f6",
    "semantic_title": "on ranking-based tests of independence",
    "citation_count": 0,
    "authors": [
      "Myrto Limnios",
      "Stéphan Clémençon"
    ]
  },
  "https://proceedings.mlr.press/v238/sebbouh24a.html": {
    "title": "Structured Transforms Across Spaces with Cost-Regularized Optimal Transport",
    "volume": "main",
    "abstract": "Matching a source to a target probability measure is often solved by instantiating a linear optimal transport (OT) problem, parameterized by a ground cost function that quantifies discrepancy between points. When these measures live in the same metric space, the ground cost often defaults to its distance. When instantiated across two different spaces, however, choosing that cost in the absence of aligned data is a conundrum. As a result, practitioners often resort to solving instead a quadratic Gromow-Wasserstein (GW) problem. We exploit in this work a parallel between GW and cost-regularized OT, the regularized minimization of a linear OT objective parameterized by a ground cost. We use this cost-regularized formulation to match measures across two different Euclidean spaces, where the cost is evaluated between transformed source points and target points. We show that several quadratic OT problems fall in this category, and consider enforcing structure in linear transform (e.g., sparsity), by introducing structure-inducing regularizers. We provide a proximal algorithm to extract such transforms from unaligned data, and demonstrate its applicability to single-cell spatial transcriptomics/multiomics matching tasks",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Othmane Sebbouh",
      "Marco Cuturi",
      "Gabriel Peyré"
    ]
  },
  "https://proceedings.mlr.press/v238/odonnat24a.html": {
    "title": "Leveraging Ensemble Diversity for Robust Self-Training in the Presence of Sample Selection Bias",
    "volume": "main",
    "abstract": "Self-training is a well-known approach for semi-supervised learning. It consists of iteratively assigning pseudo-labels to unlabeled data for which the model is confident and treating them as labeled examples. For neural networks, \\texttt{softmax} prediction probabilities are often used as a confidence measure, although they are known to be overconfident, even for wrong predictions. This phenomenon is particularly intensified in the presence of sample selection bias, i.e., when data labeling is subject to some constraints. To address this issue, we propose a novel confidence measure, called $\\mathcal{T}$-similarity, built upon the prediction diversity of an ensemble of linear classifiers. We provide the theoretical analysis of our approach by studying stationary points and describing the relationship between the diversity of the individual members and their performance. We empirically demonstrate the benefit of our confidence measure for three different pseudo-labeling policies on classification datasets of various data modalities. The code is available at https://github.com/ambroiseodt/tsim",
    "checked": true,
    "id": "df51bc92af21e51b7a13b340722a9a0fff39a342",
    "semantic_title": "leveraging ensemble diversity for robust self-training in the presence of sample selection bias",
    "citation_count": 5,
    "authors": [
      "Ambroise Odonnat",
      "Vasilii Feofanov",
      "Ievgen Redko"
    ]
  },
  "https://proceedings.mlr.press/v238/gupta24a.html": {
    "title": "Clustering Items From Adaptively Collected Inconsistent Feedback",
    "volume": "main",
    "abstract": "We study clustering in a query-based model where the learner can repeatedly query an oracle to determine if two items belong to the same cluster. However, these queries are costly and the oracle's responses are marred by inconsistency and noise. The learner's goal is to adaptively make a small number of queries and return the correct clusters for \\emph{all} $n$ items with high confidence. We develop efficient algorithms for this problem using the sequential hypothesis testing framework. We derive high probability upper bounds on their sample complexity (the number of queries they make) and complement this analysis with an information-theoretic lower bound. In particular, we show that our algorithm for two clusters is nearly optimal when the oracle's error probability is a constant. Our experiments verify these findings and highlight a few shortcomings of our algorithms. Namely, we show that their sample complexity deviates from the lower bound when the error probability of the oracle depends on $n$. We suggest an improvement based on a more efficient sequential hypothesis test and demonstrate it empirically",
    "checked": true,
    "id": "ab6a4591f3a4f17cc61ec3151781913d19016833",
    "semantic_title": "clustering items from adaptively collected inconsistent feedback",
    "citation_count": 1,
    "authors": [
      "Shubham Gupta",
      "Peter W J Staar",
      "Christian de Sainte Marie"
    ]
  },
  "https://proceedings.mlr.press/v238/hegazy24a.html": {
    "title": "Compression with Exact Error Distribution for Federated Learning",
    "volume": "main",
    "abstract": "Compression schemes have been extensively used in Federated Learning (FL) to reduce the communication cost of distributed learning. While most approaches rely on a bounded variance assumption of the noise produced by the compressor, this paper investigates the use of compression and aggregation schemes that produce a specific error distribution, e.g., Gaussian or Laplace, on the aggregated data. We present and analyze different aggregation schemes based on layered quantizers achieving exact error distribution. We provide different methods to leverage the proposed compression schemes to obtain compression-for-free in differential privacy applications. Our general compression methods can recover and improve standard FL schemes with Gaussian perturbations such as Langevin dynamics and randomized smoothing",
    "checked": true,
    "id": "ebd8202d9b2ab5a4ea458a1062fe7a703cc17ab6",
    "semantic_title": "compression with exact error distribution for federated learning",
    "citation_count": 4,
    "authors": [
      "Mahmoud Hegazy",
      "Rémi Leluc",
      "Cheuk Ting Li",
      "Aymeric Dieuleveut"
    ]
  },
  "https://proceedings.mlr.press/v238/pandeva24a.html": {
    "title": "Deep anytime-valid hypothesis testing",
    "volume": "main",
    "abstract": "We propose a general framework for constructing powerful, sequential hypothesis tests for a large class of nonparametric testing problems. The null hypothesis for these problems is defined in an abstract form using the action of two known operators on the data distribution. This abstraction allows for a unified treatment of several classical tasks, such as two-sample testing, independence testing, and conditional-independence testing, as well as modern problems, such as testing for adversarial robustness of machine learning (ML) models. Our proposed framework has the following advantages over classical batch tests: 1) it continuously monitors online data streams and efficiently aggregates evidence against the null, 2) it provides tight control over the type I error without the need for multiple testing correction, 3) it adapts the sample size requirement to the unknown hardness of the problem. We develop a principled approach of leveraging the representation capability of ML models within the testing-by-betting framework, a game-theoretic approach for designing sequential tests. Empirical results on synthetic and real-world datasets demonstrate that tests instantiated using our general framework are competitive against specialized baselines on several tasks",
    "checked": true,
    "id": "6a59a8008852236c06ebf1739809d45ec3261f48",
    "semantic_title": "deep anytime-valid hypothesis testing",
    "citation_count": 0,
    "authors": [
      "Teodora Pandeva",
      "Patrick Forré",
      "Aaditya Ramdas",
      "Shubhanshu Shekhar"
    ]
  },
  "https://proceedings.mlr.press/v238/blaser24a.html": {
    "title": "Federated Linear Contextual Bandits with Heterogeneous Clients",
    "volume": "main",
    "abstract": "The demand for collaborative and private bandit learning across multiple agents is surging due to the growing quantity of data generated from distributed systems. Federated bandit learning has emerged as a promising framework for private, efficient, and decentralized online learning. However, almost all previous works rely on strong assumptions of client homogeneity, i.e., all participating clients shall share the same bandit model; otherwise, they all would suffer linear regret. This greatly restricts the application of federated bandit learning in practice. In this work, we introduce a new approach for federated bandits for heterogeneous clients, which clusters clients for collaborative bandit learning under the federated learning setting. Our proposed algorithm achieves non-trivial sub-linear regret and communication cost for all clients, subject to the communication protocol under federated learning that at anytime only one model can be shared by the server",
    "checked": true,
    "id": "c0f7c58216f357c4215a481b39d63957fb9c4e4f",
    "semantic_title": "federated linear contextual bandits with heterogeneous clients",
    "citation_count": 0,
    "authors": [
      "Ethan Blaser",
      "Chuanhao Li",
      "Hongning Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/vu-tran24a.html": {
    "title": "LEDetection: A Simple Framework for Semi-Supervised Few-Shot Object Detection",
    "volume": "main",
    "abstract": "Few-shot object detection (FSOD) is a challenging problem aimed at detecting novel concepts from few exemplars. Existing approaches to FSOD all assume abundant base labels to adapt to novel objects. This paper studies the new task of semi-supervised FSOD by considering a realistic scenario in which both base and novel labels are simultaneously scarce. We explore the utility of unlabeled data within our proposed label-efficient detection framework and discover its remarkable ability to boost semi-supervised FSOD by way of region proposals. Motivated by this finding, we introduce SoftER Teacher, a robust detector combining pseudo-labeling with consistency learning on region proposals, to harness unlabeled data for improved FSOD without relying on abundant labels. Rigorous experiments show that SoftER Teacher surpasses the novel performance of a strong supervised detector using only 10% of required base labels, without catastrophic forgetting observed in prior approaches. Our work also sheds light on a potential relationship between semi-supervised and few-shot detection suggesting that a stronger semi-supervised detector leads to a more effective few-shot detector",
    "checked": true,
    "id": "e9dc60acbf043116888603c35913f70b2386ebbf",
    "semantic_title": "ledetection: a simple framework for semi-supervised few-shot object detection",
    "citation_count": 0,
    "authors": [
      "Phi Vu Tran"
    ]
  },
  "https://proceedings.mlr.press/v238/islamov24a.html": {
    "title": "AsGrad: A Sharp Unified Analysis of Asynchronous-SGD Algorithms",
    "volume": "main",
    "abstract": "We analyze asynchronous-type algorithms for distributed SGD in the heterogeneous setting, where each worker has its own computation and communication speeds, as well as data distribution. In these algorithms, workers compute possibly stale and stochastic gradients associated with their local data at some iteration back in history and then return those gradients to the server without synchronizing with other workers. We present a unified convergence theory for non-convex smooth functions in the heterogeneous regime. The proposed analysis provides convergence for pure asynchronous SGD and its various modifications. Moreover, our theory explains what affects the convergence rate and what can be done to improve the performance of asynchronous algorithms. In particular, we introduce a novel asynchronous method based on worker shuffling. As a by-product of our analysis, we also demonstrate convergence guarantees for gradient-type algorithms such as SGD with random reshuffling and shuffle-once mini-batch SGD. The derived rates match the best-known results for those algorithms, highlighting the tightness of our approach. Finally, our numerical evaluations support theoretical findings and show the good practical performance of our method",
    "checked": true,
    "id": "ed91e54f56a2c9519e164f23e4eb7e531dec1132",
    "semantic_title": "asgrad: a sharp unified analysis of asynchronous-sgd algorithms",
    "citation_count": 6,
    "authors": [
      "Rustem Islamov",
      "Mher Safaryan",
      "Dan Alistarh"
    ]
  },
  "https://proceedings.mlr.press/v238/hutchinson24a.html": {
    "title": "Directional Optimism for Safe Linear Bandits",
    "volume": "main",
    "abstract": "The safe linear bandit problem is a version of the classical stochastic linear bandit problem where the learner's actions must satisfy an uncertain constraint at all rounds. Due its applicability to many real-world settings, this problem has received considerable attention in recent years. By leveraging a novel approach that we call directional optimism, we find that it is possible to achieve improved regret guarantees for both well-separated problem instances and action sets that are finite star convex sets. Furthermore, we propose a novel algorithm for this setting that improves on existing algorithms in terms of empirical performance, while enjoying matching regret guarantees. Lastly, we introduce a generalization of the safe linear bandit setting where the constraints are convex and adapt our algorithms and analyses to this setting by leveraging a novel convex-analysis based approach",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Spencer Hutchinson",
      "Berkay Turan",
      "Mahnoosh Alizadeh"
    ]
  },
  "https://proceedings.mlr.press/v238/cui24a.html": {
    "title": "Theory-guided Message Passing Neural Network for Probabilistic Inference",
    "volume": "main",
    "abstract": "Probabilistic inference can be tackled by minimizing a variational free energy through message passing. To improve performance, neural networks are adopted for message computation. Neural message learning is heuristic and requires strong guidance to perform well. In this work, we propose a {\\em theory-guided message passing neural network} (TMPNN) for probabilistic inference. Inspired by existing work, we consider a generalized Bethe free energy which allows for a learnable variational assumption. Instead of using a black-box neural network for message computation, we utilize a general message equation and introduce a symbolic message function with semantically meaningful parameters. The analytically derived symbolic message function is seamlessly integrated into the MPNN framework, giving rise to the proposed TMPNN. TMPNN is trained using algorithmic supervision without requiring exact inference results. Leveraging the theory-guided symbolic function, TMPNN offers strengthened theoretical guarantees compared to conventional heuristic neural models. It presents a novel contribution by demonstrating its applicability to both MAP and marginal inference tasks, outperforming SOTAs in both cases. Furthermore, TMPNN provides improved generalizability across various graph structures and exhibits enhanced data efficiency",
    "checked": true,
    "id": "bec1205132b8bf0a3abe1dd300ad5171d18ed730",
    "semantic_title": "theory-guided message passing neural network for probabilistic inference",
    "citation_count": 0,
    "authors": [
      "Zijun Cui",
      "Hanjing Wang",
      "Tian Gao",
      "Kartik Talamadupula",
      "Qiang Ji"
    ]
  },
  "https://proceedings.mlr.press/v238/sun24a.html": {
    "title": "Understanding Generalization of Federated Learning via Stability: Heterogeneity Matters",
    "volume": "main",
    "abstract": "Generalization performance is a key metric in evaluating machine learning models when applied to real-world applications. Good generalization indicates the model can predict unseen data correctly when trained under a limited number of data. Federated learning (FL), which has emerged as a popular distributed learning framework, allows multiple devices or clients to train a shared model without violating privacy requirements. While the existing literature has studied extensively the generalization performances of centralized machine learning algorithms, similar analysis in the federated settings is either absent or with very restrictive assumptions on the loss functions. In this paper, we aim to analyze the generalization performances of federated learning by means of algorithmic stability, which measures the change of the output model of an algorithm when perturbing one data point. Three widely-used algorithms are studied, including FedAvg, SCAFFOLD, and FedProx, under convex and non-convex loss functions. Our analysis shows that the generalization performances of models trained by these three algorithms are closely related to the heterogeneity of clients' datasets as well as the convergence behaviors of the algorithms. Particularly, in the i.i.d. setting, our results recover the classical results of stochastic gradient descent (SGD)",
    "checked": true,
    "id": "d66227cfab0c27fa759b4000d37643ac55af8eab",
    "semantic_title": "understanding generalization of federated learning via stability: heterogeneity matters",
    "citation_count": 5,
    "authors": [
      "Zhenyu Sun",
      "Xiaochun Niu",
      "Ermin Wei"
    ]
  },
  "https://proceedings.mlr.press/v238/li24f.html": {
    "title": "Mechanics of Next Token Prediction with Self-Attention",
    "volume": "main",
    "abstract": "Transformer-based language models are trained on large datasets to predict the next token given an input sequence. Despite this simple training objective, they have led to revolutionary advances in natural language processing. Underlying this success is the self-attention mechanism. In this work, we ask: What does a single self-attention layer learn from next-token prediction? We show that training self-attention with gradient descent learns an automaton which generates the next token in two distinct steps: (1) Hard retrieval: Given input sequence, self-attention precisely selects the high-priority input tokens associated with the last input token. (2) Soft composition: It then creates a convex combination of the high-priority tokens from which the next token can be sampled. Under suitable conditions, we rigorously characterize these mechanics through a directed graph over tokens extracted from the training data. We prove that gradient descent implicitly discovers the strongly-connected components (SCC) of this graph and self-attention learns to retrieve the tokens that belong to the highest-priority SCC available in the context window. Our theory relies on decomposing the model weights into a directional component and a finite component that correspond to hard retrieval and soft composition steps respectively. This also formalizes a related implicit bias formula conjectured in [Tarzanagh et al. 2023]. We hope that these findings shed light on how self-attention processes sequential data and pave the path toward demystifying more complex architectures",
    "checked": true,
    "id": "24a2468a1a16d6c332efc44be90854e4f748eeca",
    "semantic_title": "mechanics of next token prediction with self-attention",
    "citation_count": 7,
    "authors": [
      "Yingcong Li",
      "Yixiao Huang",
      "Muhammed E. Ildiz",
      "Ankit Singh Rawat",
      "Samet Oymak"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24c.html": {
    "title": "Generalization Bounds of Nonconvex-(Strongly)-Concave Stochastic Minimax Optimization",
    "volume": "main",
    "abstract": "This paper studies the generalization performance of algorithms for solving nonconvex-(strongly)-concave (NC-SC/NC-C) stochastic minimax optimization measured by the stationarity of primal functions. We first establish algorithm-agnostic generalization bounds via uniform convergence between the empirical minimax problem and the population minimax problem. The sample complexities for achieving $\\epsilon$-generalization are $\\tilde{\\mathcal{O}}(d\\kappa^2\\epsilon^{-2})$ and $\\tilde{\\mathcal{O}}(d\\epsilon^{-4})$ for NC-SC and NC-C settings, respectively, where $d$ is the dimension of the primal variable and $\\kappa$ is the condition number. We further study the algorithm-dependent generalization bounds via stability arguments of algorithms. In particular, we introduce a novel stability notion for minimax problems and build a connection between stability and generalization. As a result, we establish algorithm-dependent generalization bounds for stochastic gradient descent ascent (SGDA) and the more general sampling-determined algorithms (SDA)",
    "checked": true,
    "id": "c525a1ec675224bab3574fdb0fe3616078e186a0",
    "semantic_title": "generalization bounds of nonconvex-(strongly)-concave stochastic minimax optimization",
    "citation_count": 0,
    "authors": [
      "Siqi Zhang",
      "Yifan Hu",
      "Liang Zhang",
      "Niao He"
    ]
  },
  "https://proceedings.mlr.press/v238/he24a.html": {
    "title": "TransFusion: Covariate-Shift Robust Transfer Learning for High-Dimensional Regression",
    "volume": "main",
    "abstract": "The main challenge that sets transfer learning apart from traditional supervised learning is the distribution shift, reflected as the shift between the source and target models and that between the marginal covariate distributions. In this work, we tackle model shifts in the presence of covariate shifts in the high-dimensional regression setting. Specifically, we propose a two-step method with a novel fused regularizer that effectively leverages samples from source tasks to improve the learning performance on a target task with limited samples. Nonasymptotic bound is provided for the estimation error of the target model, showing the robustness of the proposed method to covariate shifts. We further establish conditions under which the estimator is minimax-optimal. Additionally, we extend the method to a distributed setting, allowing for a pretraining-finetuning strategy, requiring just one round of communication while retaining the estimation rate of the centralized version. Numerical tests validate our theory, highlighting the method's robustness to covariate shifts",
    "checked": true,
    "id": "f112786edff69388e46f549d4ce7964ad7695861",
    "semantic_title": "transfusion: covariate-shift robust transfer learning for high-dimensional regression",
    "citation_count": 0,
    "authors": [
      "Zelin He",
      "Ying Sun",
      "Runze Li"
    ]
  },
  "https://proceedings.mlr.press/v238/gao24a.html": {
    "title": "Fusing Individualized Treatment Rules Using Secondary Outcomes",
    "volume": "main",
    "abstract": "An individualized treatment rule (ITR) is a decision rule that recommends treatments for patients based on their individual feature variables. In many practices, the ideal ITR for the primary outcome is also expected to cause minimal harm to other secondary outcomes. Therefore, our objective is to learn an ITR that not only maximizes the value function for the primary outcome, but also approximates the optimal rule for the secondary outcomes as closely as possible. To achieve this goal, we introduce a fusion penalty to encourage the ITRs based on different outcomes to yield similar recommendations. Two algorithms are proposed to estimate the ITR using surrogate loss functions. We prove that the agreement rate between the estimated ITR of the primary outcome and the optimal ITRs of the secondary outcomes converges to the true agreement rate faster than if the secondary outcomes are not taken into consideration. Furthermore, we derive the non-asymptotic properties of the value function and misclassification rate for the proposed method. Finally, simulation studies and a real data example are used to demonstrate the finite-sample performance of the proposed method",
    "checked": true,
    "id": "96b7cfbdc109166b702a56a08bbc2a7afdf4f45e",
    "semantic_title": "fusing individualized treatment rules using secondary outcomes",
    "citation_count": 0,
    "authors": [
      "Daiqi Gao",
      "Yuanjia Wang",
      "Donglin Zeng"
    ]
  },
  "https://proceedings.mlr.press/v238/janz24a.html": {
    "title": "Exploration via linearly perturbed loss minimisation",
    "volume": "main",
    "abstract": "We introduce \\emph{exploration via linear loss perturbations} (EVILL), a randomised exploration method for structured stochastic bandit problems that works by solving for the minimiser of a linearly perturbed regularised negative log-likelihood function. We show that, for the case of generalised linear bandits, EVILL reduces to perturbed history exploration (PHE), a method where exploration is done by training on randomly perturbed rewards. In doing so, we provide a simple and clean explanation of when and why random reward perturbations give rise to good bandit algorithms. We propose data-dependent perturbations not present in previous PHE-type methods that allow EVILL to match the performance of Thompson-sampling-style parameter-perturbation methods, both in theory and in practice. Moreover, we show an example outside generalised linear bandits where PHE leads to inconsistent estimates, and thus linear regret, while EVILL remains performant. Like PHE, EVILL can be implemented in just a few lines of code",
    "checked": true,
    "id": "09b1555fc11a15ed3bbf727e65df6410d788aec8",
    "semantic_title": "exploration via linearly perturbed loss minimisation",
    "citation_count": 4,
    "authors": [
      "David Janz",
      "Shuai Liu",
      "Alex Ayoub",
      "Csaba Szepesvári"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24a.html": {
    "title": "Proximal Causal Inference for Synthetic Control with Surrogates",
    "volume": "main",
    "abstract": "The synthetic control method (SCM) has become a popular tool for estimating causal effects in policy evaluation, where a single treated unit is observed. However, SCM faces challenges in accurately predicting post-intervention potential outcomes had, contrary to fact, the treatment been withheld, when the pre-intervention period is short or the post-intervention period is long. To address these issues, we propose a novel method that leverages post-intervention information, specifically time-varying correlates of the causal effect called \"surrogates\", within the synthetic control framework. We establish conditions for identifying model parameters using the proximal inference framework and apply the generalized method of moments (GMM) approach for estimation and inference about the average treatment effect on the treated (ATT). Interestingly, we uncover specific conditions under which exclusively using post-intervention data suffices for estimation within our framework. Through a synthetic experiment and a real-world application, we demonstrate that our method can outperform other synthetic control methods in estimating both short-term and long-term effects, yielding more accurate inferences",
    "checked": true,
    "id": "5403c745d76bef75dc634f9b7e9ca6d772245f0d",
    "semantic_title": "proximal causal inference for synthetic control with surrogates",
    "citation_count": 2,
    "authors": [
      "Jizhou Liu",
      "Eric Tchetgen Tchetgen",
      "Carlos Varjão"
    ]
  },
  "https://proceedings.mlr.press/v238/jankowiak24a.html": {
    "title": "Reparameterized Variational Rejection Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martin Jankowiak",
      "Du Phan"
    ]
  },
  "https://proceedings.mlr.press/v238/anh-trang24a.html": {
    "title": "E(3)-Equivariant Mesh Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thuan Anh Trang",
      "Nhat Khang Ngo",
      "Daniel T. Levy",
      "Thieu Ngoc Vo",
      "Siamak Ravanbakhsh",
      "Truong Son Hy"
    ]
  },
  "https://proceedings.mlr.press/v238/qin24a.html": {
    "title": "A General Algorithm for Solving Rank-one Matrix Sensing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lianke Qin",
      "Zhao Song",
      "Ruizhe Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24a.html": {
    "title": "Oracle-Efficient Pessimism: Offline Policy Optimization In Contextual Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lequn Wang",
      "Akshay Krishnamurthy",
      "Alex Slivkins"
    ]
  },
  "https://proceedings.mlr.press/v238/dupuis24a.html": {
    "title": "The Solution Path of SLOPE",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xavier Dupuis",
      "Patrick Tardivel"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24a.html": {
    "title": "Lower-level Duality Based Reformulation and Majorization Minimization Algorithm for Hyperparameter Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "He Chen",
      "Haochen Xu",
      "Rujun Jiang",
      "Anthony Man-Cho So"
    ]
  },
  "https://proceedings.mlr.press/v238/karjol24a.html": {
    "title": "A Unified Framework for Discovering Discrete Symmetries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pavan Karjol",
      "Rohan Kashyap",
      "Aditya Gopalan",
      "A. P. Prathosh"
    ]
  },
  "https://proceedings.mlr.press/v238/amiraz24a.html": {
    "title": "Recovery Guarantees for Distributed-OMP",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chen Amiraz",
      "Robert Krauthgamer",
      "Boaz Nadler"
    ]
  },
  "https://proceedings.mlr.press/v238/vilucchio24a.html": {
    "title": "Asymptotic Characterisation of the Performance of Robust Linear Regression in the Presence of Outliers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matteo Vilucchio",
      "Emanuele Troiani",
      "Vittorio Erba",
      "Florent Krzakala"
    ]
  },
  "https://proceedings.mlr.press/v238/yu24a.html": {
    "title": "Riemannian Laplace Approximation with the Fisher Metric",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hanlin Yu",
      "Marcelo Hartmann",
      "Bernardo Williams Moreno Sanchez",
      "Mark Girolami",
      "Arto Klami"
    ]
  },
  "https://proceedings.mlr.press/v238/reichelt24a.html": {
    "title": "Beyond Bayesian Model Averaging over Paths in Probabilistic Programs with Stochastic Support",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tim Reichelt",
      "Luke Ong",
      "Tom Rainforth"
    ]
  },
  "https://proceedings.mlr.press/v238/aghbalou24a.html": {
    "title": "Sharp error bounds for imbalanced classification: how many examples in the minority class?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anass Aghbalou",
      "Anne Sabourin",
      "François Portier"
    ]
  },
  "https://proceedings.mlr.press/v238/bickford-smith24a.html": {
    "title": "Making Better Use of Unlabelled Data in Bayesian Active Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Freddie Bickford Smith",
      "Adam Foster",
      "Tom Rainforth"
    ]
  },
  "https://proceedings.mlr.press/v238/puchkin24a.html": {
    "title": "Breaking the Heavy-Tailed Noise Barrier in Stochastic Optimization Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikita Puchkin",
      "Eduard Gorbunov",
      "Nickolay Kutuzov",
      "Alexander Gasnikov"
    ]
  },
  "https://proceedings.mlr.press/v238/ahuja24a.html": {
    "title": "Multi-Domain Causal Representation Learning via Weak Distributional Invariances",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kartik Ahuja",
      "Amin Mansouri",
      "Yixin Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/ahmadian24a.html": {
    "title": "Unsupervised Novelty Detection in Pretrained Representation Space with Locally Adapted Likelihood Ratio",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amirhossein Ahmadian",
      "Yifan Ding",
      "Gabriel Eilertsen",
      "Fredrik Lindsten"
    ]
  },
  "https://proceedings.mlr.press/v238/scieur24a.html": {
    "title": "Adaptive Quasi-Newton and Anderson Acceleration Framework with Explicit Global (Accelerated) Convergence Rates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Damien Scieur"
    ]
  },
  "https://proceedings.mlr.press/v238/bao24a.html": {
    "title": "BOBA: Byzantine-Robust Federated Learning with Label Skewness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenxuan Bao",
      "Jun Wu",
      "Jingrui He"
    ]
  },
  "https://proceedings.mlr.press/v238/guo24a.html": {
    "title": "A White-Box False Positive Adversarial Attack Method on Contrastive Loss Based Offline Handwritten Signature Verification Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhongliang Guo",
      "Weiye Li",
      "Yifei Qian",
      "Ognjen Arandjelovic",
      "Lei Fang"
    ]
  },
  "https://proceedings.mlr.press/v238/regol24a.html": {
    "title": "Categorical Generative Model Evaluation via Synthetic Distribution Coarsening",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florence Regol",
      "Mark Coates"
    ]
  },
  "https://proceedings.mlr.press/v238/feng24b.html": {
    "title": "Monitoring machine learning-based risk prediction algorithms in the presence of performativity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jean Feng",
      "Alexej Gossmann",
      "Gene A Pennello",
      "Nicholas Petrick",
      "Berkman Sahiner",
      "Romain Pirracchio"
    ]
  },
  "https://proceedings.mlr.press/v238/depavia24a.html": {
    "title": "Learning-Based Algorithms for Graph Searching Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Adela F. DePavia",
      "Erasmo Tani",
      "Ali Vakilian"
    ]
  },
  "https://proceedings.mlr.press/v238/bacchiocchi24a.html": {
    "title": "Autoregressive Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Francesco Bacchiocchi",
      "Gianmarco Genalti",
      "Davide Maran",
      "Marco Mussi",
      "Marcello Restelli",
      "Nicola Gatti",
      "Alberto Maria Metelli"
    ]
  },
  "https://proceedings.mlr.press/v238/kim24b.html": {
    "title": "DeepFDR: A Deep Learning-based False Discovery Rate Control Method for Neuroimaging Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taehyo Kim",
      "Hai Shu",
      "Qiran Jia",
      "Mony de Leon"
    ]
  },
  "https://proceedings.mlr.press/v238/ye24a.html": {
    "title": "Enhancing Hypergradients Estimation: A Study of Preconditioning and Reparameterization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhenzhang Ye",
      "Gabriel Peyré",
      "Daniel Cremers",
      "Pierre Ablin"
    ]
  },
  "https://proceedings.mlr.press/v238/stempfle24a.html": {
    "title": "MINTY: Rule-based models that minimize the need for imputing features with missing values",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lena Stempfle",
      "Fredrik Johansson"
    ]
  },
  "https://proceedings.mlr.press/v238/zimerman24a.html": {
    "title": "Multi-Dimensional Hyena for Spatial Inductive Bias",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Itamar Zimerman",
      "Lior Wolf"
    ]
  },
  "https://proceedings.mlr.press/v238/yijia-zheng24a.html": {
    "title": "Graph Machine Learning through the Lens of Bilevel Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amber Yijia Zheng",
      "Tong He",
      "Yixuan Qiu",
      "Minjie Wang",
      "David Wipf"
    ]
  },
  "https://proceedings.mlr.press/v238/allouah24a.html": {
    "title": "Robust Sparse Voting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Youssef Allouah",
      "Rachid Guerraoui",
      "Lê-Nguyên Hoang",
      "Oscar Villemaud"
    ]
  },
  "https://proceedings.mlr.press/v238/joshi24a.html": {
    "title": "Data-Efficient Contrastive Language-Image Pretraining: Prioritizing Data Quality over Quantity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siddharth Joshi",
      "Arnav Jain",
      "Ali Payani",
      "Baharan Mirzasoleiman"
    ]
  },
  "https://proceedings.mlr.press/v238/min-kwon24a.html": {
    "title": "Efficient Low-Dimensional Compression of Overparameterized Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soo Min Kwon",
      "Zekai Zhang",
      "Dogyoon Song",
      "Laura Balzano",
      "Qing Qu"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24b.html": {
    "title": "Data-Adaptive Probabilistic Likelihood Approximation for Ordinary Differential Equations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohan Wu",
      "Martin Lysy"
    ]
  },
  "https://proceedings.mlr.press/v238/el-halabi24a.html": {
    "title": "Fairness in Submodular Maximization over a Matroid Constraint",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marwa El Halabi",
      "Jakub Tarnawski",
      "Ashkan Norouzi-Fard",
      "Thuy-Duong Vuong"
    ]
  },
  "https://proceedings.mlr.press/v238/shuo-liu24a.html": {
    "title": "Unified Transfer Learning in High-Dimensional Linear Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuo Shuo Liu"
    ]
  },
  "https://proceedings.mlr.press/v238/de-bartolomeis24a.html": {
    "title": "Hidden yet quantifiable: A lower bound for confounding strength using randomized trials",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Piersilvio De Bartolomeis",
      "Javier Abad Martinez",
      "Konstantin Donhauser",
      "Fanny Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/ghosh24a.html": {
    "title": "Towards Achieving Sub-linear Regret and Hard Constraint Violation in Model-free RL",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arnob Ghosh",
      "Xingyu Zhou",
      "Ness Shroff"
    ]
  },
  "https://proceedings.mlr.press/v238/xie24a.html": {
    "title": "Distributionally Robust Quickest Change Detection using Wasserstein Uncertainty Sets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liyan Xie",
      "Yuchen Liang",
      "Venugopal V. Veeravalli"
    ]
  },
  "https://proceedings.mlr.press/v238/harsha-tanneru24a.html": {
    "title": "Quantifying Uncertainty in Natural Language Explanations of Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sree Harsha Tanneru",
      "Chirag Agarwal",
      "Himabindu Lakkaraju"
    ]
  },
  "https://proceedings.mlr.press/v238/raed-mualem24a.html": {
    "title": "Submodular Minimax Optimization: Finding Effective Sets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Loay Raed Mualem",
      "Ethan R Elenberg",
      "Moran Feldman",
      "Amin Karbasi"
    ]
  },
  "https://proceedings.mlr.press/v238/haldar24a.html": {
    "title": "Effect of Ambient-Intrinsic Dimension Gap on Adversarial Vulnerability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rajdeep Haldar",
      "Yue Xing",
      "Qifan Song"
    ]
  },
  "https://proceedings.mlr.press/v238/futami24a.html": {
    "title": "Information-theoretic Analysis of Bayesian Test Data Sensitivity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Futoshi Futami",
      "Tomoharu Iwata"
    ]
  },
  "https://proceedings.mlr.press/v238/mosenzon24a.html": {
    "title": "Scalable Algorithms for Individual Preference Stable Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ron Mosenzon",
      "Ali Vakilian"
    ]
  },
  "https://proceedings.mlr.press/v238/yang24b.html": {
    "title": "Orthogonal Gradient Boosting for Simpler Additive Rule Ensembles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fan Yang",
      "Pierre Le Bodic",
      "Michael Kamp",
      "Mario Boley"
    ]
  },
  "https://proceedings.mlr.press/v238/li24g.html": {
    "title": "When No-Rejection Learning is Consistent for Regression with Rejection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaocheng Li",
      "Shang Liu",
      "Chunlin Sun",
      "Hanzhao Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/yi24a.html": {
    "title": "Filter, Rank, and Prune: Learning Linear Cyclic Gaussian Graphical Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soheun Yi",
      "Sanghack Lee"
    ]
  },
  "https://proceedings.mlr.press/v238/holland24a.html": {
    "title": "Robust variance-regularized risk minimization with concomitant scaling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew J. Holland"
    ]
  },
  "https://proceedings.mlr.press/v238/fan24a.html": {
    "title": "Fast and Adversarial Robust Kernelized SDU Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yajing Fan",
      "wanli shi",
      "Yi Chang",
      "Bin Gu"
    ]
  },
  "https://proceedings.mlr.press/v238/zhai24a.html": {
    "title": "Learning Sampling Policy to Achieve Fewer Queries for Zeroth-Order Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhou Zhai",
      "Wanli Shi",
      "Heng Huang",
      "Yi Chang",
      "Bin Gu"
    ]
  },
  "https://proceedings.mlr.press/v238/medvedovsky24a.html": {
    "title": "Efficient Graph Laplacian Estimation by Proximal Newton",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yakov Medvedovsky",
      "Eran Treister",
      "Tirza S Routtenberg"
    ]
  },
  "https://proceedings.mlr.press/v238/huyuk24a.html": {
    "title": "Adaptive Experiment Design with Synthetic Controls",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alihan Hüyük",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ]
  },
  "https://proceedings.mlr.press/v238/concha-duarte24a.html": {
    "title": "Online non-parametric likelihood-ratio estimation by Pearson-divergence functional minimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alejandro D. de la Concha Duarte",
      "Nicolas Vayatis",
      "Argyris Kalogeratos"
    ]
  },
  "https://proceedings.mlr.press/v238/barrainkua24a.html": {
    "title": "Uncertainty Matters: Stable Conclusions under Unstable Assessment of Fairness Results",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ainhize Barrainkua",
      "Paula Gordaliza",
      "Jose A. Lozano",
      "Novi Quadrianto"
    ]
  },
  "https://proceedings.mlr.press/v238/rammal24a.html": {
    "title": "Communication Compression for Byzantine Robust Learning: New Efficient Algorithms and Improved Rates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmad Rammal",
      "Kaja Gruntkowska",
      "Nikita Fedin",
      "Eduard Gorbunov",
      "Peter Richtarik"
    ]
  },
  "https://proceedings.mlr.press/v238/kuroki24a.html": {
    "title": "Best-of-Both-Worlds Algorithms for Linear Contextual Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuko Kuroki",
      "Alberto Rumi",
      "Taira Tsuchiya",
      "Fabio Vitale",
      "Nicolò Cesa-Bianchi"
    ]
  },
  "https://proceedings.mlr.press/v238/nakamura24a.html": {
    "title": "Fixed-Budget Real-Valued Combinatorial Pure Exploration of Multi-Armed Bandit",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shintaro Nakamura",
      "Masashi Sugiyama"
    ]
  },
  "https://proceedings.mlr.press/v238/frick24a.html": {
    "title": "Scalable Learning of Item Response Theory Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Susanne Frick",
      "Amer Krivosija",
      "Alexander Munteanu"
    ]
  },
  "https://proceedings.mlr.press/v238/nika24a.html": {
    "title": "Corruption-Robust Offline Two-Player Zero-Sum Markov Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andi Nika",
      "Debmalya Mandal",
      "Adish Singla",
      "Goran Radanovic"
    ]
  },
  "https://proceedings.mlr.press/v238/iwazaki24a.html": {
    "title": "Risk Seeking Bayesian Optimization under Uncertainty for Obtaining Extremum",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shogo Iwazaki",
      "Tomohiko Tanabe",
      "Mitsuru Irie",
      "Shion Takeno",
      "Yu Inatsu"
    ]
  },
  "https://proceedings.mlr.press/v238/wesel24a.html": {
    "title": "Quantized Fourier and Polynomial Features for more Expressive Tensor Network Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Frederiek Wesel",
      "Kim Batselier"
    ]
  },
  "https://proceedings.mlr.press/v238/kjaersgaard24a.html": {
    "title": "Fair Soft Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rune D. Kjærsgaard",
      "Pekka Parviainen",
      "Saket Saurabh",
      "Madhumita Kundu",
      "Line Clemmensen"
    ]
  },
  "https://proceedings.mlr.press/v238/tong24a.html": {
    "title": "Simulation-Free Schrödinger Bridges via Score and Flow Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Y. Tong",
      "Nikolay Malkin",
      "Kilian Fatras",
      "Lazar Atanackovic",
      "Yanlei Zhang",
      "Guillaume Huguet",
      "Guy Wolf",
      "Yoshua Bengio"
    ]
  },
  "https://proceedings.mlr.press/v238/jolicoeur-martineau24a.html": {
    "title": "Generating and Imputing Tabular Data via Diffusion and Flow-based Gradient-Boosted Trees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexia Jolicoeur-Martineau",
      "Kilian Fatras",
      "Tal Kachman"
    ]
  },
  "https://proceedings.mlr.press/v238/carpintero-perez24a.html": {
    "title": "Gaussian process regression with Sliced Wasserstein Weisfeiler-Lehman graph kernels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raphaël Carpintero Perez",
      "Sébastien Da Veiga",
      "Josselin Garnier",
      "Brian Staber"
    ]
  },
  "https://proceedings.mlr.press/v238/robert-nicoud24a.html": {
    "title": "Intrinsic Gaussian Vector Fields on Manifolds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Robert-Nicoud",
      "Andreas Krause",
      "Viacheslav Borovitskiy"
    ]
  },
  "https://proceedings.mlr.press/v238/cosier24a.html": {
    "title": "A Unifying Variational Framework for Gaussian Process Motion Planning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lucas C. Cosier",
      "Rares Iordan",
      "Sicelukwanda N. T. Zwane",
      "Giovanni Franzese",
      "James T. Wilson",
      "Marc Deisenroth",
      "Alexander Terenin",
      "Yasemin Bekiroglu"
    ]
  },
  "https://proceedings.mlr.press/v238/benard24a.html": {
    "title": "MMD-based Variable Importance for Distributional Random Forest",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Clément Bénard",
      "Jeffrey Näf",
      "Julie Josse"
    ]
  },
  "https://proceedings.mlr.press/v238/tebbe24a.html": {
    "title": "Efficiently Computable Safety Bounds for Gaussian Processes in Active Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jörn Tebbe",
      "Christoph Zimmer",
      "Ansgar Steland",
      "Markus Lange-Hegermann",
      "Fabian Mies"
    ]
  },
  "https://proceedings.mlr.press/v238/molaei24a.html": {
    "title": "Federated Learning For Heterogeneous Electronic Health Records Utilising Augmented Temporal Graph Attention Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soheila Molaei",
      "Anshul Thakur",
      "Ghazaleh Niknam",
      "Andrew Soltan",
      "Hadi Zare",
      "David A Clifton"
    ]
  },
  "https://proceedings.mlr.press/v238/hickey24a.html": {
    "title": "Adaptive Discretization for Event PredicTion (ADEPT)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jimmy Hickey",
      "Ricardo Henao",
      "Daniel Wojdyla",
      "Michael Pencina",
      "Matthew Engelhard"
    ]
  },
  "https://proceedings.mlr.press/v238/eun-huh24a.html": {
    "title": "Generalization Bounds for Label Noise Stochastic Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jung Eun Huh",
      "Patrick Rebeschini"
    ]
  },
  "https://proceedings.mlr.press/v238/heidari24a.html": {
    "title": "Adaptive Parametric Prototype Learning for Cross-Domain Few-Shot Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marzi Heidari",
      "Abdullah Alchihabi",
      "Qing En",
      "Yuhong Guo"
    ]
  },
  "https://proceedings.mlr.press/v238/khan24a.html": {
    "title": "Analyzing Explainer Robustness via Probabilistic Lipschitzness of Prediction Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zulqarnain Q. Khan",
      "Davin Hill",
      "Aria Masoomi",
      "Joshua T. Bone",
      "Jennifer Dy"
    ]
  },
  "https://proceedings.mlr.press/v238/phan24a.html": {
    "title": "Importance Matching Lemma for Lossy Compression with Side Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Buu Phan",
      "Ashish Khisti",
      "Christos Louizos"
    ]
  },
  "https://proceedings.mlr.press/v238/donhauser24a.html": {
    "title": "Certified private data release for sparse Lipschitz functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Konstantin Donhauser",
      "Johan Lokna",
      "Amartya Sanyal",
      "March Boedihardjo",
      "Robert Hönig",
      "Fanny Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/trauger24a.html": {
    "title": "Sequence Length Independent Norm-Based Generalization Bounds for Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacob Trauger",
      "Ambuj Tewari"
    ]
  },
  "https://proceedings.mlr.press/v238/jin24a.html": {
    "title": "Subsampling Error in Stochastic Gradient Langevin Diffusions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kexin Jin",
      "Chenguang Liu",
      "Jonas Latz"
    ]
  },
  "https://proceedings.mlr.press/v238/vu24a.html": {
    "title": "Analysis of Privacy Leakage in Federated Large Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Minh Vu",
      "Truc Nguyen",
      "Tre’ Jeter",
      "My T. Thai"
    ]
  },
  "https://proceedings.mlr.press/v238/qian24a.html": {
    "title": "Exploring the Power of Graph Neural Networks in Solving Linear Optimization Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chendi Qian",
      "Didier Chételat",
      "Christopher Morris"
    ]
  },
  "https://proceedings.mlr.press/v238/en24a.html": {
    "title": "Cross-model Mutual Learning for Exemplar-based Medical Image Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Qing En",
      "Yuhong Guo"
    ]
  },
  "https://proceedings.mlr.press/v238/deshpande24a.html": {
    "title": "Online Calibrated and Conformal Prediction Improves Bayesian Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shachi Deshpande",
      "Charles Marx",
      "Volodymyr Kuleshov"
    ]
  },
  "https://proceedings.mlr.press/v238/kausik24a.html": {
    "title": "Offline Policy Evaluation and Optimization Under Confounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chinmaya Kausik",
      "Yangyi Lu",
      "Kevin Tan",
      "Maggie Makar",
      "Yixin Wang",
      "Ambuj Tewari"
    ]
  },
  "https://proceedings.mlr.press/v238/neuhof24a.html": {
    "title": "Confident Feature Ranking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bitya Neuhof",
      "Yuval Benjamini"
    ]
  },
  "https://proceedings.mlr.press/v238/hu24b.html": {
    "title": "Central Limit Theorem for Two-Timescale Stochastic Approximation with Markovian Noise: Theory and Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jie Hu",
      "Vishwaraj Doshi",
      "Do Young Eun"
    ]
  },
  "https://proceedings.mlr.press/v238/vishwakarma24a.html": {
    "title": "Taming False Positives in Out-of-Distribution Detection with Human Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Harit Vishwakarma",
      "Heguang Lin",
      "Ramya Korlakai Vinayak"
    ]
  },
  "https://proceedings.mlr.press/v238/lebensold24a.html": {
    "title": "On the Privacy of Selection Mechanisms with Gaussian Noise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonathan Lebensold",
      "Doina Precup",
      "Borja Balle"
    ]
  },
  "https://proceedings.mlr.press/v238/gazin24a.html": {
    "title": "Transductive conformal inference with adaptive scores",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ulysse Gazin",
      "Gilles Blanchard",
      "Etienne Roquain"
    ]
  },
  "https://proceedings.mlr.press/v238/cohen-indelman24a.html": {
    "title": "Learning Latent Partial Matchings with Gumbel-IPF Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hedda Cohen Indelman",
      "Tamir Hazan"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24b.html": {
    "title": "On Counterfactual Metrics for Social Welfare: Incentives, Ranking, and Information Asymmetry",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Serena Wang",
      "Stephen Bates",
      "P Aronow",
      "Michael Jordan"
    ]
  },
  "https://proceedings.mlr.press/v238/dann24a.html": {
    "title": "Data-Driven Online Model Selection With Regret Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chris Dann",
      "Claudio Gentile",
      "Aldo Pacchiano"
    ]
  },
  "https://proceedings.mlr.press/v238/rossellini24a.html": {
    "title": "Integrating Uncertainty Awareness into Conformalized Quantile Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Raphael Rossellini",
      "Rina Foygel Barber",
      "Rebecca Willett"
    ]
  },
  "https://proceedings.mlr.press/v238/dhillon24a.html": {
    "title": "On the Expected Size of Conformal Prediction Sets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guneet S. Dhillon",
      "George Deligiannidis",
      "Tom Rainforth"
    ]
  },
  "https://proceedings.mlr.press/v238/sevilla24a.html": {
    "title": "Estimation of partially known Gaussian graphical models with score-based structural priors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martín Sevilla",
      "Antonio G. Marques",
      "Santiago Segarra"
    ]
  },
  "https://proceedings.mlr.press/v238/takemori24a.html": {
    "title": "Model-Based Best Arm Identification for Decreasing Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sho Takemori",
      "Yuhei Umeda",
      "Aditya Gopalan"
    ]
  },
  "https://proceedings.mlr.press/v238/ou24a.html": {
    "title": "Thompson Sampling Itself is Differentially Private",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tingting Ou",
      "Rachel Cummings",
      "Marco Avella Medina"
    ]
  },
  "https://proceedings.mlr.press/v238/xiong24a.html": {
    "title": "A/B Testing and Best-arm Identification for Linear Bandits with Robustness to Non-stationarity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhihan Xiong",
      "Romain Camilleri",
      "Maryam Fazel",
      "Lalit Jain",
      "Kevin Jamieson"
    ]
  },
  "https://proceedings.mlr.press/v238/sohn24a.html": {
    "title": "Fair Supervised Learning with A Simple Random Sampler of Sensitive Attributes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinwon Sohn",
      "Qifan Song",
      "Guang Lin"
    ]
  },
  "https://proceedings.mlr.press/v238/ma24a.html": {
    "title": "Absence of spurious solutions far from ground truth: A low-rank analysis with high-order losses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziye Ma",
      "Ying Chen",
      "Javad Lavaei",
      "Somayeh Sojoudi"
    ]
  },
  "https://proceedings.mlr.press/v238/jhunjhunwala24a.html": {
    "title": "FedFisher: Leveraging Fisher Information for One-Shot Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Divyansh Jhunjhunwala",
      "Shiqiang Wang",
      "Gauri Joshi"
    ]
  },
  "https://proceedings.mlr.press/v238/choo24a.html": {
    "title": "Causal Discovery under Off-Target Interventions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Davin Choo",
      "Kirankumar Shiragur",
      "Caroline Uhler"
    ]
  },
  "https://proceedings.mlr.press/v238/jin24b.html": {
    "title": "Feasible $Q$-Learning for Average Reward Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ying Jin",
      "Ramki Gummadi",
      "Zhengyuan Zhou",
      "Jose Blanchet"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24c.html": {
    "title": "Joint control variate for faster black-box variational inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xi Wang",
      "Tomas Geffner",
      "Justin Domke"
    ]
  },
  "https://proceedings.mlr.press/v238/tang24a.html": {
    "title": "Adaptivity of Diffusion Models to Manifold Structures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rong Tang",
      "Yun Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/diamant24a.html": {
    "title": "Conformalized Deep Splines for Optimal and Efficient Prediction Sets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathaniel Diamant",
      "Ehsan Hajiramezanali",
      "Tommaso Biancalani",
      "Gabriele Scalia"
    ]
  },
  "https://proceedings.mlr.press/v238/esaki24a.html": {
    "title": "Accuracy-Preserving Calibration via Statistical Modeling on Probability Simplex",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yasushi Esaki",
      "Akihiro Nakamura",
      "Keisuke Kawano",
      "Ryoko Tokuhisa",
      "Takuro Kutsuna"
    ]
  },
  "https://proceedings.mlr.press/v238/ye24b.html": {
    "title": "Smoothness-Adaptive Dynamic Pricing with Nonparametric Demand Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zeqi Ye",
      "Hansheng Jiang"
    ]
  },
  "https://proceedings.mlr.press/v238/li24h.html": {
    "title": "Optimal Exploration is no harder than Thompson Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoqi Li",
      "Kevin Jamieson",
      "Lalit Jain"
    ]
  },
  "https://proceedings.mlr.press/v238/deng24a.html": {
    "title": "Sample Complexity Characterization for Linear Contextual MDPs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junze Deng",
      "Yuan Cheng",
      "Shaofeng Zou",
      "Yingbin Liang"
    ]
  },
  "https://proceedings.mlr.press/v238/pal24a.html": {
    "title": "Sample-Efficient Personalization: Modeling User Parameters as Low Rank Plus Sparse Components",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Soumyabrata Pal",
      "Prateek Varshney",
      "Gagan Madan",
      "Prateek Jain",
      "Abhradeep Thakurta",
      "Gaurav Aggarwal",
      "Pradeep Shenoy",
      "Gaurav Srivastava"
    ]
  },
  "https://proceedings.mlr.press/v238/leconte24a.html": {
    "title": "Queuing dynamics of asynchronous Federated Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Louis Leconte",
      "Matthieu Jonckheere",
      "Sergey Samsonov",
      "Eric Moulines"
    ]
  },
  "https://proceedings.mlr.press/v238/tatli24a.html": {
    "title": "Learning Populations of Preferences via Pairwise Comparison Queries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gokcan Tatli",
      "Yi Chen",
      "Ramya Korlakai Vinayak"
    ]
  },
  "https://proceedings.mlr.press/v238/xiang24a.html": {
    "title": "A Neural Architecture Predictor based on GNN-Enhanced Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xunzhi Xiang",
      "Kun Jing",
      "Jungang Xu"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24b.html": {
    "title": "Efficient Neural Architecture Design via Capturing Architecture-Performance Joint Distribution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yue Liu",
      "Ziyi Yu",
      "Zitu Liu",
      "Wenjie Tian"
    ]
  },
  "https://proceedings.mlr.press/v238/lee24a.html": {
    "title": "Analysis of Using Sigmoid Loss for Contrastive Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chungpa Lee",
      "Joonhwan Chang",
      "Jy-yong Sohn"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24c.html": {
    "title": "Robust Data Clustering with Outliers via Transformed Tensor Low-Rank Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tong Wu"
    ]
  },
  "https://proceedings.mlr.press/v238/han24a.html": {
    "title": "Robust SVD Made Easy: A fast and reliable algorithm for large-scale data analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sangil Han",
      "Sungkyu Jung",
      "Kyoowon Kim"
    ]
  },
  "https://proceedings.mlr.press/v238/liang24a.html": {
    "title": "Regret Bounds for Risk-sensitive Reinforcement Learning with Lipschitz Dynamic Risk Measures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hao Liang",
      "Zhiquan Luo"
    ]
  },
  "https://proceedings.mlr.press/v238/frederik-thielmann24a.html": {
    "title": "Neural Additive Models for Location Scale and Shape: A Framework for Interpretable Neural Regression Beyond the Mean",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anton Frederik Thielmann",
      "René-Marcel Kruse",
      "Thomas Kneib",
      "Benjamin Säfken"
    ]
  },
  "https://proceedings.mlr.press/v238/eliasof24a.html": {
    "title": "On The Temporal Domain of Differential Equation Inspired Graph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Moshe Eliasof",
      "Eldad Haber",
      "Eran Treister",
      "Carola-Bibiane B Schönlieb"
    ]
  },
  "https://proceedings.mlr.press/v238/wagner24a.html": {
    "title": "Diagonalisation SGD: Fast & Convergent SGD for Non-Differentiable Models via Reparameterisation and Smoothing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dominik Wagner",
      "Basim Khajwal",
      "Luke Ong"
    ]
  },
  "https://proceedings.mlr.press/v238/sharrock24a.html": {
    "title": "Tuning-Free Maximum Likelihood Training of Latent Variable Models via Coin Betting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Louis Sharrock",
      "Daniel Dodd",
      "Christopher Nemeth"
    ]
  },
  "https://proceedings.mlr.press/v238/dold24a.html": {
    "title": "Bayesian Semi-structured Subspace Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Dold",
      "David Ruegamer",
      "Beate Sick",
      "Oliver Dürr"
    ]
  },
  "https://proceedings.mlr.press/v238/nguyen-le-duy24a.html": {
    "title": "CAD-DA: Controllable Anomaly Detection after Domain Adaptation by Statistical Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vo Nguyen Le Duy",
      "Hsuan-Tien Lin",
      "Ichiro Takeuchi"
    ]
  },
  "https://proceedings.mlr.press/v238/jaffard24a.html": {
    "title": "Provable local learning rule by expert aggregation for a Hawkes network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sophie Jaffard",
      "Samuel Vaiter",
      "Alexandre Muzy",
      "Patricia Reynaud-Bouret"
    ]
  },
  "https://proceedings.mlr.press/v238/achddou24a.html": {
    "title": "Multitask Online Learning: Listen to the Neighborhood Buzz",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juliette Achddou",
      "Nicolò Cesa-Bianchi",
      "Pierre Laforgue"
    ]
  },
  "https://proceedings.mlr.press/v238/korhonen24a.html": {
    "title": "Structural perspective on constraint-based learning of Markov networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tuukka Korhonen",
      "Fedor Fomin",
      "Pekka Parviainen"
    ]
  },
  "https://proceedings.mlr.press/v238/huynh24a.html": {
    "title": "DAGnosis: Localized Identification of Data Inconsistencies using Structures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nicolas Huynh",
      "Jeroen Berrevoets",
      "Nabeel Seedat",
      "Jonathan Crabbé",
      "Zhaozhi Qian",
      "Mihaela van der Schaar"
    ]
  },
  "https://proceedings.mlr.press/v238/haasler24a.html": {
    "title": "Bures-Wasserstein Means of Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Isabel Haasler",
      "Pascal Frossard"
    ]
  },
  "https://proceedings.mlr.press/v238/nakis24a.html": {
    "title": "Time to Cite: Modeling Citation Networks using the Dynamic Impact Single-Event Embedding Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikolaos Nakis",
      "Abdulkadir Celikkanat",
      "Louis Boucherie",
      "Sune Lehmann",
      "Morten Mørup"
    ]
  },
  "https://proceedings.mlr.press/v238/september24a.html": {
    "title": "Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcus A. K. September",
      "Francesco Sanna Passino",
      "Leonie Goldmann",
      "Anton Hinel"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24d.html": {
    "title": "Restricted Isometry Property of Rank-One Measurements with Random Unit-Modulus Vectors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Zhang",
      "Zhenni Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/verma24a.html": {
    "title": "Variational Gaussian Process Diffusion Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prakhar Verma",
      "Vincent Adam",
      "Arno Solin"
    ]
  },
  "https://proceedings.mlr.press/v238/zhao24a.html": {
    "title": "Positivity-free Policy Learning with Observational Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pan Zhao",
      "Antoine Chambaz",
      "Julie Josse",
      "Shu Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/lorch24a.html": {
    "title": "Causal Modeling with Stationary Diffusions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lars Lorch",
      "Andreas Krause",
      "Bernhard Schölkopf"
    ]
  },
  "https://proceedings.mlr.press/v238/ichikawa24a.html": {
    "title": "Learning Dynamics in Linear VAE: Posterior Collapse Threshold, Superfluous Latent Space Pitfalls, and Speedup with KL Annealing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuma Ichikawa",
      "Koji Hukushima"
    ]
  },
  "https://proceedings.mlr.press/v238/heidrich24a.html": {
    "title": "A 4-Approximation Algorithm for Min Max Correlation Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Holger S. G. Heidrich",
      "Jannik Irmai",
      "Bjoern Andres"
    ]
  },
  "https://proceedings.mlr.press/v238/li24i.html": {
    "title": "Ethics in Action: Training Reinforcement Learning Agents for Moral Decision-making In Text-based Adventure Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weichen Li",
      "Rati Devidze",
      "Waleed Mustafa",
      "Sophie Fellenz"
    ]
  },
  "https://proceedings.mlr.press/v238/waldchen24a.html": {
    "title": "Interpretability Guarantees with Merlin-Arthur Classifiers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stephan Wäldchen",
      "Kartikey Sharma",
      "Berkant Turan",
      "Max Zimmer",
      "Sebastian Pokutta"
    ]
  },
  "https://proceedings.mlr.press/v238/berta24a.html": {
    "title": "Classifier Calibration with ROC-Regularized Isotonic Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eugène Berta",
      "Francis Bach",
      "Michael Jordan"
    ]
  },
  "https://proceedings.mlr.press/v238/tighineanu24a.html": {
    "title": "Scalable Meta-Learning with Gaussian Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Petru Tighineanu",
      "Lukas Grossberger",
      "Paul Baireuther",
      "Kathrin Skubch",
      "Stefan Falkner",
      "Julia Vinogradska",
      "Felix Berkenkamp"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24b.html": {
    "title": "An Efficient Stochastic Algorithm for Decentralized Nonconvex-Strongly-Concave Minimax Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lesi Chen",
      "Haishan Ye",
      "Luo Luo"
    ]
  },
  "https://proceedings.mlr.press/v238/pegoraro24a.html": {
    "title": "Vector Quantile Regression on Manifolds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marco Pegoraro",
      "Sanketh Vedula",
      "Aviv A Rosenberg",
      "Irene Tallini",
      "Emanuele Rodola",
      "Alex Bronstein"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24d.html": {
    "title": "Near-Optimal Convex Simple Bilevel Optimization with a Bisection Method",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiulin Wang",
      "Xu Shi",
      "Rujun Jiang"
    ]
  },
  "https://proceedings.mlr.press/v238/laberge24a.html": {
    "title": "Tackling the XAI Disagreement Problem with Regional Explanations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gabriel Laberge",
      "Yann Batiste Pequignot",
      "Mario Marchand",
      "Foutse Khomh"
    ]
  },
  "https://proceedings.mlr.press/v238/frutos24a.html": {
    "title": "Training Implicit Generative Models via an Invariant Statistical Loss",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "José Manuel de Frutos",
      "Pablo Olmos",
      "Manuel Alberto Vazquez Lopez",
      "Joaquín Míguez"
    ]
  },
  "https://proceedings.mlr.press/v238/fan24b.html": {
    "title": "RL in Markov Games with Independent Function Approximation: Improved Sample Complexity Bound under the Local Access Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junyi Fan",
      "Yuxuan Han",
      "Jialin Zeng",
      "Jian-Feng Cai",
      "Yang Wang",
      "Yang Xiang",
      "Jiheng Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/dong24a.html": {
    "title": "Convergence to Nash Equilibrium and No-regret Guarantee in (Markov) Potential Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jing Dong",
      "Baoxiang Wang",
      "Yaoliang Yu"
    ]
  },
  "https://proceedings.mlr.press/v238/andrew24a.html": {
    "title": "GmGM: a fast multi-axis Gaussian graphical model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ethan B. Andrew",
      "David Westhead",
      "Luisa Cutillo"
    ]
  },
  "https://proceedings.mlr.press/v238/ting-li24a.html": {
    "title": "On Convergence in Wasserstein Distance and f-divergence Minimization Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cheuk Ting Li",
      "Jingwei Zhang",
      "Farzan Farnia"
    ]
  },
  "https://proceedings.mlr.press/v238/sun24b.html": {
    "title": "Sparse and Faithful Explanations Without Sparse Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiyang Sun",
      "Zhi Chen",
      "Vittorio Orlandi",
      "Tong Wang",
      "Cynthia Rudin"
    ]
  },
  "https://proceedings.mlr.press/v238/hu24c.html": {
    "title": "Extragradient Type Methods for Riemannian Variational Inequality Problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Hu",
      "Guanghui Wang",
      "Xi Wang",
      "Andre Wibisono",
      "Jacob D Abernethy",
      "Molei Tao"
    ]
  },
  "https://proceedings.mlr.press/v238/velychko24a.html": {
    "title": "Learning Sparse Codes with Entropy-Based ELBOs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dmytro Velychko",
      "Simon Damm",
      "Asja Fischer",
      "Jörg Lücke"
    ]
  },
  "https://proceedings.mlr.press/v238/zuo24a.html": {
    "title": "Near Optimal Adversarial Attacks on Stochastic Bandits and Defenses with Smoothed Responses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shiliang Zuo"
    ]
  },
  "https://proceedings.mlr.press/v238/mauri24a.html": {
    "title": "Robust Approximate Sampling via Stochastic Gradient Barker Dynamics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lorenzo Mauri",
      "Giacomo Zanella"
    ]
  },
  "https://proceedings.mlr.press/v238/tang24b.html": {
    "title": "Solving General Noisy Inverse Problem via Posterior Sampling: A Policy Gradient Viewpoint",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyue Tang",
      "Tian Xie",
      "Aosong Feng",
      "Hanyu Wang",
      "Chenyang Zhang",
      "Yang Bai"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24c.html": {
    "title": "Enhancing Distributional Stability among Sub-populations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiashuo Liu",
      "Jiayun Wu",
      "Jie Peng",
      "Xiaoyu Wu",
      "Yang Zheng",
      "Bo Li",
      "Peng Cui"
    ]
  },
  "https://proceedings.mlr.press/v238/parikh24a.html": {
    "title": "Safe and Interpretable Estimation of Optimal Treatment Regimes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Harsh Parikh",
      "Quinn M Lanners",
      "Zade Akras",
      "Sahar Zafar",
      "M Brandon Westover",
      "Cynthia Rudin",
      "Alexander Volfovsky"
    ]
  },
  "https://proceedings.mlr.press/v238/gala24a.html": {
    "title": "Probabilistic Integral Circuits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gennaro Gala",
      "Cassio de Campos",
      "Robert Peharz",
      "Antonio Vergari",
      "Erik Quaeghebeur"
    ]
  },
  "https://proceedings.mlr.press/v238/bernasconi24a.html": {
    "title": "Learning Extensive-Form Perfect Equilibria in Two-Player Zero-Sum Sequential Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Martino Bernasconi",
      "Alberto Marchesi",
      "Francesco Trovò"
    ]
  },
  "https://proceedings.mlr.press/v238/szlendak24a.html": {
    "title": "Understanding Progressive Training Through the Framework of Randomized Coordinate Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rafał Szlendak",
      "Elnur Gasanov",
      "Peter Richtarik"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24e.html": {
    "title": "Multiclass Learning from Noisy Labels for Non-decomposable Performance Measures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mingyuan Zhang",
      "Shivani Agarwal"
    ]
  },
  "https://proceedings.mlr.press/v238/zhou24a.html": {
    "title": "On the Theoretical Expressive Power and the Design Space of Higher-Order Graph Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cai Zhou",
      "Rose Yu",
      "Yusu Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/janzing24a.html": {
    "title": "Quantifying intrinsic causal contributions via structure preserving interventions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dominik Janzing",
      "Patrick Blöbaum",
      "Atalanti A Mastakouri",
      "Philipp M Faller",
      "Lenon Minorics",
      "Kailash Budhathoki"
    ]
  },
  "https://proceedings.mlr.press/v238/draxler24a.html": {
    "title": "Free-form Flows: Make Any Architecture a Normalizing Flow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Felix Draxler",
      "Peter Sorrenson",
      "Lea Zimmermann",
      "Armand Rousselot",
      "Ullrich Köthe"
    ]
  },
  "https://proceedings.mlr.press/v238/moreno24a.html": {
    "title": "Efficient Model-Based Concave Utility Reinforcement Learning through Greedy Mirror Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bianca M. Moreno",
      "Margaux Bregere",
      "Pierre Gaillard",
      "Nadia Oudjane"
    ]
  },
  "https://proceedings.mlr.press/v238/guo24b.html": {
    "title": "Online learning in bandits with predicted context",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yongyi Guo",
      "Ziping Xu",
      "Susan Murphy"
    ]
  },
  "https://proceedings.mlr.press/v238/so24a.html": {
    "title": "Optimising Distributions with Natural Gradient Surrogates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonathan So",
      "Richard E. Turner"
    ]
  },
  "https://proceedings.mlr.press/v238/baker24a.html": {
    "title": "Monotone Operator Theory-Inspired Message Passing for Learning Long-Range Interaction on Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Justin M. Baker",
      "Qingsong Wang",
      "Martin Berzins",
      "Thomas Strohmer",
      "Bao Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/ahmadi24a.html": {
    "title": "Agnostic Multi-Robust Learning using ERM",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Saba Ahmadi",
      "Avrim Blum",
      "Omar Montasser",
      "Kevin M Stangl"
    ]
  },
  "https://proceedings.mlr.press/v238/dimlioglu24a.html": {
    "title": "GRAWA: Gradient-based Weighted Averaging for Distributed Training of Deep Learning Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tolga Dimlioglu",
      "Anna Choromanska"
    ]
  },
  "https://proceedings.mlr.press/v238/patil24a.html": {
    "title": "Failures and Successes of Cross-Validation for Early-Stopped Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pratik Patil",
      "Yuchen Wu",
      "Ryan Tibshirani"
    ]
  },
  "https://proceedings.mlr.press/v238/abroshan24a.html": {
    "title": "Imposing Fairness Constraints in Synthetic Data Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mahed Abroshan",
      "Andrew Elliott",
      "Mohammad Mahdi Khalili"
    ]
  },
  "https://proceedings.mlr.press/v238/choromanski24a.html": {
    "title": "Learning a Fourier Transform for Linear Relative Positional Encodings in Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Krzysztof Choromanski",
      "Shanda Li",
      "Valerii Likhosherstov",
      "Kumar Avinava Dubey",
      "Shengjie Luo",
      "Di He",
      "Yiming Yang",
      "Tamas Sarlos",
      "Thomas Weingarten",
      "Adrian Weller"
    ]
  },
  "https://proceedings.mlr.press/v238/li24j.html": {
    "title": "Backward Filtering Forward Deciding in Linear Non-Gaussian State Space Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yun-Peng Li",
      "Hans-Andrea Loeliger"
    ]
  },
  "https://proceedings.mlr.press/v238/hoang-khoi-do24a.html": {
    "title": "MIM-Reasoner: Learning with Theoretical Guarantees for Multiplex Influence Maximization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nguyen Hoang Khoi Do",
      "Tanmoy Chowdhury",
      "Chen Ling",
      "Liang Zhao",
      "My T. Thai"
    ]
  },
  "https://proceedings.mlr.press/v238/kim24c.html": {
    "title": "A Doubly Robust Approach to Sparse Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wonyoung Kim",
      "Garud Iyengar",
      "Assaf Zeevi"
    ]
  },
  "https://proceedings.mlr.press/v238/varici24a.html": {
    "title": "General Identifiability and Achievability for Causal Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Burak Varici",
      "Emre Acartürk",
      "Karthikeyan Shanmugam",
      "Ali Tajer"
    ]
  },
  "https://proceedings.mlr.press/v238/pasteris24a.html": {
    "title": "Sum-max Submodular Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stephen U. Pasteris",
      "Alberto Rumi",
      "Fabio Vitale",
      "Nicolò Cesa-Bianchi"
    ]
  },
  "https://proceedings.mlr.press/v238/gruffaz24a.html": {
    "title": "Stochastic Approximation with Biased MCMC for Expectation Maximization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel Gruffaz",
      "Kyurae Kim",
      "Alain Durmus",
      "Jacob Gardner"
    ]
  },
  "https://proceedings.mlr.press/v238/reisizadeh24a.html": {
    "title": "EM for Mixture of Linear Regression with Clustered Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amirhossein Reisizadeh",
      "Khashayar Gatmiry",
      "Asuman Ozdaglar"
    ]
  },
  "https://proceedings.mlr.press/v238/dvurechensky24a.html": {
    "title": "Analysis of Kernel Mirror Prox for Measure Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pavel Dvurechensky",
      "Jia-Jie Zhu"
    ]
  },
  "https://proceedings.mlr.press/v238/hariz24a.html": {
    "title": "Implicit Regularization in Deep Tucker Factorization: Low-Rankness via Structured Sparsity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kais Hariz",
      "Hachem Kadri",
      "Stéphane Ayache",
      "Maher Moakher",
      "Thierry Artières"
    ]
  },
  "https://proceedings.mlr.press/v238/rizvi-martel24a.html": {
    "title": "Simulating weighted automata over sequences and trees with transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Michael Rizvi-Martel",
      "Maude Lizaire",
      "Clara Lacroce",
      "Guillaume Rabusseau"
    ]
  },
  "https://proceedings.mlr.press/v238/auddy24a.html": {
    "title": "Approximate Leave-one-out Cross Validation for Regression with $\\ell_1$ Regularizers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arnab Auddy",
      "Haolin Zou",
      "Kamiar Rahnamarad",
      "Arian Maleki"
    ]
  },
  "https://proceedings.mlr.press/v238/lindner24a.html": {
    "title": "Learning Safety Constraints from Demonstrations with Unknown Rewards",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "David Lindner",
      "Xin Chen",
      "Sebastian Tschiatschek",
      "Katja Hofmann",
      "Andreas Krause"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24f.html": {
    "title": "Online Learning in Contextual Second-Price Pay-Per-Click Auctions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mengxiao Zhang",
      "Haipeng Luo"
    ]
  },
  "https://proceedings.mlr.press/v238/fuentes24a.html": {
    "title": "Joint Selection: Adaptively Incorporating Public Information for Private Synthetic Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miguel Fuentes",
      "Brett C. Mullins",
      "Ryan McKenna",
      "Gerome Miklau",
      "Daniel Sheldon"
    ]
  },
  "https://proceedings.mlr.press/v238/long24a.html": {
    "title": "Equation Discovery with Bayesian Spike-and-Slab Priors and Efficient Kernels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Da Long",
      "Wei Xing",
      "Aditi Krishnapriyan",
      "Robert Kirby",
      "Shandian Zhe",
      "Michael W. Mahoney"
    ]
  },
  "https://proceedings.mlr.press/v238/mitchell-roddenberry24a.html": {
    "title": "An Impossibility Theorem for Node Embedding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "T. Mitchell Roddenberry",
      "Yu Zhu",
      "Santiago Segarra"
    ]
  },
  "https://proceedings.mlr.press/v238/diluvi24a.html": {
    "title": "Mixed variational flows for discrete variables",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gian C. Diluvi",
      "Benjamin Bloem-Reddy",
      "Trevor Campbell"
    ]
  },
  "https://proceedings.mlr.press/v238/li24k.html": {
    "title": "Multi-Resolution Active Learning of Fourier Neural Operators",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shibo Li",
      "Xin Yu",
      "Wei Xing",
      "Robert Kirby",
      "Akil Narayan",
      "Shandian Zhe"
    ]
  },
  "https://proceedings.mlr.press/v238/grudzien24a.html": {
    "title": "Functional Graphical Models: Structure Enables Offline Data-Driven Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kuba Grudzien",
      "Masatoshi Uehara",
      "Sergey Levine",
      "Pieter Abbeel"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24c.html": {
    "title": "Federated Experiment Design under Distributed Differential Privacy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei-Ning Chen",
      "Graham Cormode",
      "Akash Bharadwaj",
      "Peter Romov",
      "Ayfer Ozgur"
    ]
  },
  "https://proceedings.mlr.press/v238/granese24a.html": {
    "title": "Optimal Zero-Shot Detector for Multi-Armed Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Federica Granese",
      "Marco Romanelli",
      "Pablo Piantanida"
    ]
  },
  "https://proceedings.mlr.press/v238/kumar-krishnamurthy24a.html": {
    "title": "Towards Costless Model Selection in Contextual Bandits: A Bias-Variance Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanath Kumar Krishnamurthy",
      "Adrienne M Propp",
      "Susan Athey"
    ]
  },
  "https://proceedings.mlr.press/v238/patel24a.html": {
    "title": "Conformal Contextual Robust Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yash P. Patel",
      "Sahana Rayan",
      "Ambuj Tewari"
    ]
  },
  "https://proceedings.mlr.press/v238/ren24a.html": {
    "title": "Learning Adaptive Kernels for Statistical Independence Tests",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yixin Ren",
      "Yewei Xia",
      "Hao Zhang",
      "Jihong Guan",
      "Shuigeng Zhou"
    ]
  },
  "https://proceedings.mlr.press/v238/abernethy24a.html": {
    "title": "Lexicographic Optimization: Algorithms and Stability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacob A. Abernethy",
      "Robert Schapire",
      "Umar Syed"
    ]
  },
  "https://proceedings.mlr.press/v238/dai24b.html": {
    "title": "Can Probabilistic Feedback Drive User Impacts in Online Platforms?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jessica Dai",
      "Bailey Flanigan",
      "Nika Haghtalab",
      "Meena Jagadeesan",
      "Chara Podimata"
    ]
  },
  "https://proceedings.mlr.press/v238/shi24a.html": {
    "title": "Learning Cartesian Product Graphs with Laplacian Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Changhao Shi",
      "Gal Mishne"
    ]
  },
  "https://proceedings.mlr.press/v238/yao24a.html": {
    "title": "Minimizing Convex Functionals over Space of Probability Measures via KL Divergence Gradient Flow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rentian Yao",
      "Linjun Huang",
      "Yun Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/showalter24a.html": {
    "title": "Bayesian Online Learning for Consensus Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samuel Showalter",
      "Alex J Boyd",
      "Padhraic Smyth",
      "Mark Steyvers"
    ]
  },
  "https://proceedings.mlr.press/v238/kone24a.html": {
    "title": "Bandit Pareto Set Identification: the Fixed Budget Setting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cyrille Kone",
      "Emilie Kaufmann",
      "Laura Richert"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24e.html": {
    "title": "Efficient Data Shapley for Weighted Nearest Neighbor Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiachen T. Wang",
      "Prateek Mittal",
      "Ruoxi Jia"
    ]
  },
  "https://proceedings.mlr.press/v238/hsiao24a.html": {
    "title": "Surrogate Bayesian Networks for Approximating Evolutionary Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Hsiao",
      "Dana S Nau",
      "Bobak Pezeshki",
      "Rina Dechter"
    ]
  },
  "https://proceedings.mlr.press/v238/ramos24a.html": {
    "title": "BlockBoost: Scalable and Efficient Blocking through Boosting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thiago Ramos",
      "Rodrigo Loro Schuller",
      "Alex Akira Okuno",
      "Lucas Nissenbaum",
      "Roberto I Oliveira",
      "Paulo Orenstein"
    ]
  },
  "https://proceedings.mlr.press/v238/shen24a.html": {
    "title": "Continual Domain Adversarial Adaptation via Double-Head Discriminators",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yan Shen",
      "Zhanghexuan Ji",
      "Chunwei Ma",
      "Mingchen Gao"
    ]
  },
  "https://proceedings.mlr.press/v238/mohammadpour24a.html": {
    "title": "Maximum entropy GFlowNets with soft Q-learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sobhan Mohammadpour",
      "Emmanuel Bengio",
      "Emma Frejinger",
      "Pierre-Luc Bacon"
    ]
  },
  "https://proceedings.mlr.press/v238/maiti24a.html": {
    "title": "Near-Optimal Pure Exploration in Matrix Games: A Generalization of Stochastic Bandits & Dueling Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arnab Maiti",
      "Ross Boczar",
      "Kevin Jamieson",
      "Lillian Ratliff"
    ]
  },
  "https://proceedings.mlr.press/v238/zheng24b.html": {
    "title": "Accelerating Approximate Thompson Sampling with Underdamped Langevin Monte Carlo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haoyang Zheng",
      "Wei Deng",
      "Christian Moya",
      "Guang Lin"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24d.html": {
    "title": "Large-Scale Gaussian Processes via Alternating Projection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiwen Wu",
      "Jonathan Wenger",
      "Haydn T Jones",
      "Geoff Pleiss",
      "Jacob Gardner"
    ]
  },
  "https://proceedings.mlr.press/v238/martinez24a.html": {
    "title": "Achieving Group Distributional Robustness and Minimax Group Fairness with Interpolating Classifiers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Natalia L. Martinez",
      "Martin A. Bertran",
      "Guillermo Sapiro"
    ]
  },
  "https://proceedings.mlr.press/v238/leiner24a.html": {
    "title": "Graph fission and cross-validation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "James Leiner",
      "Aaditya Ramdas"
    ]
  },
  "https://proceedings.mlr.press/v238/lymperopoulos24a.html": {
    "title": "Graph Pruning for Enumeration of Minimal Unsatisfiable Subsets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Panagiotis Lymperopoulos",
      "Liping Liu"
    ]
  },
  "https://proceedings.mlr.press/v238/shao24a.html": {
    "title": "Nonparametric Automatic Differentiation Variational Inference with Spline Approximation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuda Shao",
      "Shan N Yu",
      "Tianshu Feng"
    ]
  },
  "https://proceedings.mlr.press/v238/shekhtman24a.html": {
    "title": "Strategic Usage in a Multi-Learner Setting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eliot Shekhtman",
      "Sarah Dean"
    ]
  },
  "https://proceedings.mlr.press/v238/nguyen24a.html": {
    "title": "On Parameter Estimation in Deviated Gaussian Mixture of Experts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huy Nguyen",
      "Khai Nguyen",
      "Nhat Ho"
    ]
  },
  "https://proceedings.mlr.press/v238/nguyen24b.html": {
    "title": "Towards Convergence Rates for Parameter Estimation in Gaussian-gated Mixture of Experts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Huy Nguyen",
      "TrungTin Nguyen",
      "Khai Nguyen",
      "Nhat Ho"
    ]
  },
  "https://proceedings.mlr.press/v238/chakraborty24a.html": {
    "title": "PrIsing: Privacy-Preserving Peer Effect Estimation via Ising Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Abhinav Chakraborty",
      "Anirban Chatterjee",
      "Abhinandan Dalal"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24d.html": {
    "title": "Escaping Saddle Points in Heterogeneous Federated Learning via Distributed SGD with Communication Compression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sijin Chen",
      "Zhize Li",
      "Yuejie Chi"
    ]
  },
  "https://proceedings.mlr.press/v238/nguyen24c.html": {
    "title": "From Coupled Oscillators to Graph Neural Networks: Reducing Over-smoothing via a Kuramoto Model-based Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tuan Nguyen",
      "Hirotada Honda",
      "Takashi Sano",
      "Vinh Nguyen",
      "Shugo Nakamura",
      "Tan Minh Nguyen"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24d.html": {
    "title": "Distributionally Robust Off-Dynamics Reinforcement Learning: Provable Efficiency with Linear Function Approximation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhishuai Liu",
      "Pan Xu"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24f.html": {
    "title": "Invariant Aggregator for Defending against Federated Backdoor Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiaoyang Wang",
      "Dimitrios Dimitriadis",
      "Sanmi Koyejo",
      "Shruti Tople"
    ]
  },
  "https://proceedings.mlr.press/v238/li24l.html": {
    "title": "Policy Evaluation for Reinforcement Learning from Human Feedback: A Sample Complexity Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zihao Li",
      "Xiang Ji",
      "Minshuo Chen",
      "Mengdi Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/adibi24a.html": {
    "title": "Stochastic Approximation with Delayed Updates: Finite-Time Rates under Markovian Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arman Adibi",
      "Nicolò Dal Fabbro",
      "Luca Schenato",
      "Sanjeev Kulkarni",
      "H. Vincent Poor",
      "George J. Pappas",
      "Hamed Hassani",
      "Aritra Mitra"
    ]
  },
  "https://proceedings.mlr.press/v238/ahmed24a.html": {
    "title": "Privacy-Preserving Decentralized Actor-Critic for Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maheed A. Ahmed",
      "Mahsa Ghasemi"
    ]
  },
  "https://proceedings.mlr.press/v238/li24m.html": {
    "title": "On the Model-Misspecification in Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yunfan Li",
      "Lin Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/levin24a.html": {
    "title": "Any-dimensional equivariant neural networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Eitan Levin",
      "Mateo Diaz"
    ]
  },
  "https://proceedings.mlr.press/v238/laplante24a.html": {
    "title": "Conditional Adjustment in a Markov Equivalence Class",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sara LaPlante",
      "Emilija Perkovic"
    ]
  },
  "https://proceedings.mlr.press/v238/arya24b.html": {
    "title": "Learning to Solve the Constrained Most Probable Explanation Task in Probabilistic Graphical Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shivvrat Arya",
      "Tahrima Rahman",
      "Vibhav Gogate"
    ]
  },
  "https://proceedings.mlr.press/v238/shi24b.html": {
    "title": "Adaptive and non-adaptive minimax rates for weighted Laplacian-Eigenmap based nonparametric regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhaoyang Shi",
      "Krishna Balasubramanian",
      "Wolfgang Polonik"
    ]
  },
  "https://proceedings.mlr.press/v238/cundy24a.html": {
    "title": "Privacy-Constrained Policies via Mutual Information Regularized Policy Gradients",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chris J. Cundy",
      "Rishi Desai",
      "Stefano Ermon"
    ]
  },
  "https://proceedings.mlr.press/v238/arya24a.html": {
    "title": "Deep Dependency Networks and Advanced Inference Schemes for Multi-Label Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shivvrat Arya",
      "Yu Xiang",
      "Vibhav Gogate"
    ]
  },
  "https://proceedings.mlr.press/v238/nguyen24d.html": {
    "title": "Near-optimal Per-Action Regret Bounds for Sleeping Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quan M. Nguyen",
      "Nishant Mehta"
    ]
  },
  "https://proceedings.mlr.press/v238/ruan24a.html": {
    "title": "Electronic Medical Records Assisted Digital Clinical Trial Design",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xinrui Ruan",
      "Jingshen Wang",
      "Yingfei Wang",
      "Waverly Wei"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24g.html": {
    "title": "Multivariate Time Series Forecasting By Graph Attention Networks With Theoretical Guarantees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Zhang",
      "Weijian Li",
      "Han Liu"
    ]
  },
  "https://proceedings.mlr.press/v238/ataee-tarzanagh24a.html": {
    "title": "Online Bilevel Optimization: Regret Analysis of Online Alternating Gradient Methods",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Davoud Ataee Tarzanagh",
      "Parvin Nazari",
      "Bojian Hou",
      "Li Shen",
      "Laura Balzano"
    ]
  },
  "https://proceedings.mlr.press/v238/ibrahim24a.html": {
    "title": "End-to-end Feature Selection Approach for Learning Skinny Trees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shibal Ibrahim",
      "Kayhan Behdin",
      "Rahul Mazumder"
    ]
  },
  "https://proceedings.mlr.press/v238/thompson24a.html": {
    "title": "Contextual Directed Acyclic Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryan Thompson",
      "Edwin V. Bonilla",
      "Robert Kohn"
    ]
  },
  "https://proceedings.mlr.press/v238/han24b.html": {
    "title": "Conformalized Semi-supervised Random Forest for Classification and Abnormality Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yujin Han",
      "Mingwenchan Xu",
      "Leying Guan"
    ]
  },
  "https://proceedings.mlr.press/v238/sen-fong24a.html": {
    "title": "Multi-Level Symbolic Regression: Function Structure Learning for Multi-Level Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kei Sen Fong",
      "Mehul Motani"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24e.html": {
    "title": "Non-Convex Joint Community Detection and Group Synchronization via Generalized Power Method",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sijin Chen",
      "Xiwei Cheng",
      "Anthony Man-Cho So"
    ]
  },
  "https://proceedings.mlr.press/v238/tsai24a.html": {
    "title": "Fast Minimization of Expected Logarithmic Loss via Stochastic Dual Averaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chung-En Tsai",
      "Hao-Chung Cheng",
      "Yen-Huan Li"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24h.html": {
    "title": "Discriminant Distance-Aware Representation on Deterministic Uncertainty Quantification Methods",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaxin Zhang",
      "Kamalika Das",
      "Sricharan Kumar"
    ]
  },
  "https://proceedings.mlr.press/v238/haussmann24a.html": {
    "title": "Estimating treatment effects from single-arm trials via latent-variable modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manuel Haussmann",
      "Tran Minh Son Le",
      "Viivi Halla-aho",
      "Samu Kurki",
      "Jussi Leinonen",
      "Miika Koskinen",
      "Samuel Kaski",
      "Harri Lähdesmäki"
    ]
  },
  "https://proceedings.mlr.press/v238/kuang24a.html": {
    "title": "Unveiling Latent Causal Rules: A Temporal Point Process Approach for Abnormal Event Explanation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yiling Kuang",
      "Chao Yang",
      "Yang Yang",
      "Shuang Li"
    ]
  },
  "https://proceedings.mlr.press/v238/chaouki24a.html": {
    "title": "Online Learning of Decision Trees with Thompson Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ayman Chaouki",
      "Jesse Read",
      "Albert Bifet"
    ]
  },
  "https://proceedings.mlr.press/v238/yang24c.html": {
    "title": "Identifying Spurious Biases Early in Training through the Lens of Simplicity Bias",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Yang",
      "Eric Gan",
      "Gintare Karolina Dziugaite",
      "Baharan Mirzasoleiman"
    ]
  },
  "https://proceedings.mlr.press/v238/mukherjee24a.html": {
    "title": "SPEED: Experimental Design for Policy Evaluation in Linear Heteroscedastic Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Subhojyoti Mukherjee",
      "Qiaomin Xie",
      "Josiah P Hanna",
      "Robert Nowak"
    ]
  },
  "https://proceedings.mlr.press/v238/ebrahimpour-boroojeny24a.html": {
    "title": "Spectrum Extraction and Clipping for Implicitly Linear Layers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ali Ebrahimpour Boroojeny",
      "Matus Telgarsky",
      "Hari Sundaram"
    ]
  },
  "https://proceedings.mlr.press/v238/alizadeh24a.html": {
    "title": "Pessimistic Off-Policy Multi-Objective Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shima Alizadeh",
      "Aniruddha Bhargava",
      "Karthick Gopalswamy",
      "Lalit Jain",
      "Branislav Kveton",
      "Ge Liu"
    ]
  },
  "https://proceedings.mlr.press/v238/mogensen24a.html": {
    "title": "Faithful graphical representations of local independence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Søren W. Mogensen"
    ]
  },
  "https://proceedings.mlr.press/v238/manh-bui24a.html": {
    "title": "Density-Regression: Efficient and Distance-aware Deep Regressor for Uncertainty Estimation under Distribution Shifts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ha Manh Bui",
      "Anqi Liu"
    ]
  },
  "https://proceedings.mlr.press/v238/viallard24a.html": {
    "title": "Leveraging PAC-Bayes Theory and Gibbs Distributions for Generalization Bounds with Complexity Measures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paul Viallard",
      "Rémi Emonet",
      "Amaury Habrard",
      "Emilie Morvant",
      "Valentina Zantedeschi"
    ]
  },
  "https://proceedings.mlr.press/v238/olmin24a.html": {
    "title": "On the connection between Noise-Contrastive Estimation and Contrastive Divergence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amanda Olmin",
      "Jakob Lindqvist",
      "Lennart Svensson",
      "Fredrik Lindsten"
    ]
  },
  "https://proceedings.mlr.press/v238/zhou24b.html": {
    "title": "Reward-Relevance-Filtered Linear Offline Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Angela Zhou"
    ]
  },
  "https://proceedings.mlr.press/v238/rashid24a.html": {
    "title": "Preventing Arbitrarily High Confidence on Far-Away Data in Point-Estimated Discriminative Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmad Rashid",
      "Serena Hacker",
      "Guojun Zhang",
      "Agustinus Kristiadi",
      "Pascal Poupart"
    ]
  },
  "https://proceedings.mlr.press/v238/tang24c.html": {
    "title": "Stochastic Multi-Armed Bandits with Strongly Reward-Dependent Delays",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yifu Tang",
      "Yingfei Wang",
      "Zeyu Zheng"
    ]
  },
  "https://proceedings.mlr.press/v238/grosse24a.html": {
    "title": "A Greedy Approximation for k-Determinantal Point Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Julia Grosse",
      "Rahel Fischer",
      "Roman Garnett",
      "Philipp Hennig"
    ]
  },
  "https://proceedings.mlr.press/v238/li24n.html": {
    "title": "Improved Algorithm for Adversarial Linear Mixture MDPs with Bandit Feedback and Unknown Transition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Long-Fei Li",
      "Peng Zhao",
      "Zhi-Hua Zhou"
    ]
  },
  "https://proceedings.mlr.press/v238/karagozlu24a.html": {
    "title": "Learning the Pareto Set Under Incomplete Preferences: Pure Exploration in Vector Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Efe Mert Karagözlü",
      "Yaşar Cahit Yıldırım",
      "Cağın Ararat",
      "Cem Tekin"
    ]
  },
  "https://proceedings.mlr.press/v238/hendrikx24a.html": {
    "title": "The Relative Gaussian Mechanism and its Application to Private Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hadrien Hendrikx",
      "Paul Mangold",
      "Aurélien Bellet"
    ]
  },
  "https://proceedings.mlr.press/v238/haan24a.html": {
    "title": "Euclidean, Projective, Conformal: Choosing a Geometric Algebra for Equivariant Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Pim de Haan",
      "Taco Cohen",
      "Johann Brehmer"
    ]
  },
  "https://proceedings.mlr.press/v238/mondal24a.html": {
    "title": "Improved Sample Complexity Analysis of Natural Policy Gradient Algorithm with General Parameterization for Infinite Horizon Discounted Reward Markov Decision Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Washim U. Mondal",
      "Vaneet Aggarwal"
    ]
  },
  "https://proceedings.mlr.press/v238/yamada24a.html": {
    "title": "Learning Fair Division from Bandit Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hakuei Yamada",
      "Junpei Komiyama",
      "Kenshi Abe",
      "Atsushi Iwasaki"
    ]
  },
  "https://proceedings.mlr.press/v238/le24a.html": {
    "title": "Optimal Transport for Measures with Noisy Tree Metric",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tam Le",
      "Truyen Nguyen",
      "Kenji Fukumizu"
    ]
  },
  "https://proceedings.mlr.press/v238/salaudeen24a.html": {
    "title": "Causally Inspired Regularization Enables Domain General Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Olawale Salaudeen",
      "Sanmi Koyejo"
    ]
  },
  "https://proceedings.mlr.press/v238/dheur24a.html": {
    "title": "Probabilistic Calibration by Design for Neural Network Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Victor Dheur",
      "Souhaib Ben Taieb"
    ]
  },
  "https://proceedings.mlr.press/v238/maddux24a.html": {
    "title": "Multi-Agent Learning in Contextual Games under Unknown Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anna M. Maddux",
      "Maryam Kamgarpour"
    ]
  },
  "https://proceedings.mlr.press/v238/bateni24a.html": {
    "title": "A Scalable Algorithm for Individually Fair k-Means Clustering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "MohammadHossein Bateni",
      "Vincent Cohen-Addad",
      "Alessandro Epasto",
      "Silvio Lattanzi"
    ]
  },
  "https://proceedings.mlr.press/v238/eich24a.html": {
    "title": "Approximate Control for Continuous-Time POMDPs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yannick Eich",
      "Bastian Alt",
      "Heinz Koeppl"
    ]
  },
  "https://proceedings.mlr.press/v238/gabbianelli24a.html": {
    "title": "Offline Primal-Dual Reinforcement Learning for Linear MDPs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Germano Gabbianelli",
      "Gergely Neu",
      "Matteo Papini",
      "Nneka M Okolo"
    ]
  },
  "https://proceedings.mlr.press/v238/souveton24a.html": {
    "title": "Fixed-kinetic Neural Hamiltonian Flows for enhanced interpretability and reduced complexity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Souveton",
      "Arnaud Guillin",
      "Jens Jasche",
      "Guilhem Lavaux",
      "Manon Michel"
    ]
  },
  "https://proceedings.mlr.press/v238/yang24d.html": {
    "title": "Learning Unknown Intervention Targets in Structural Causal Models from Heterogeneous Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuqin Yang",
      "Saber Salehkaleybar",
      "Negar Kiyavash"
    ]
  },
  "https://proceedings.mlr.press/v238/lee24b.html": {
    "title": "XB-MAML: Learning Expandable Basis Parameters for Effective Meta-Learning with Wide Task Coverage",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jae-Jun Lee",
      "Sung Whan Yoon"
    ]
  },
  "https://proceedings.mlr.press/v238/eldowa24a.html": {
    "title": "General Tail Bounds for Non-Smooth Stochastic Mirror Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Khaled Eldowa",
      "Andrea Paudice"
    ]
  },
  "https://proceedings.mlr.press/v238/flach24a.html": {
    "title": "Symmetric Equilibrium Learning of VAEs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Boris Flach",
      "Dmitrij Schlesinger",
      "Alexander Shekhovtsov"
    ]
  },
  "https://proceedings.mlr.press/v238/zhao24b.html": {
    "title": "On Feynman-Kac training of partial Bayesian neural networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zheng Zhao",
      "Sebastian Mair",
      "Thomas B. Schön",
      "Jens Sjölund"
    ]
  },
  "https://proceedings.mlr.press/v238/losalka24a.html": {
    "title": "No-Regret Algorithms for Safe Bayesian Optimization with Monotonicity Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Arpan Losalka",
      "Jonathan Scarlett"
    ]
  },
  "https://proceedings.mlr.press/v238/augusto-zagatti24a.html": {
    "title": "Learning multivariate temporal point processes via the time-change theorem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Guilherme Augusto Zagatti",
      "See Kiong Ng",
      "Stéphane Bressan"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24g.html": {
    "title": "Model-based Policy Optimization under Approximate Bayesian Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoqi Wang",
      "Yuxin Chen",
      "Kevin Murphy"
    ]
  },
  "https://proceedings.mlr.press/v238/zeng24a.html": {
    "title": "SDMTR: A Brain-inspired Transformer for Relation Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiangyu Zeng",
      "Jie Lin",
      "Piao Hu",
      "Zhihao Li",
      "Tianxi Huang"
    ]
  },
  "https://proceedings.mlr.press/v238/ma24b.html": {
    "title": "Directed Hypergraph Representation Learning for Link Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zitong Ma",
      "Wenbo Zhao",
      "Zhe Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24i.html": {
    "title": "Formal Verification of Unknown Stochastic Systems via Non-parametric Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhi Zhang",
      "Chenyu Ma",
      "Saleh Soudijani",
      "Sadegh Soudjani"
    ]
  },
  "https://proceedings.mlr.press/v238/kviman24a.html": {
    "title": "Variational Resampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oskar Kviman",
      "Nicola Branchini",
      "Víctor Elvira",
      "Jens Lagergren"
    ]
  },
  "https://proceedings.mlr.press/v238/sander24a.html": {
    "title": "Implicit Bias in Noisy-SGD: With Applications to Differentially Private Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tom Sander",
      "Maxime Sylvestre",
      "Alain Durmus"
    ]
  },
  "https://proceedings.mlr.press/v238/peshekhonov24a.html": {
    "title": "Training a Tucker Model With Shared Factors: a Riemannian Optimization Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ivan Peshekhonov",
      "Aleksey Arzhantsev",
      "Maxim Rakhuba"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24h.html": {
    "title": "Don't Be Pessimistic Too Early: Look K Steps Ahead!",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaoqi Wang",
      "Ziyu Ye",
      "Kevin Murphy",
      "Yuxin Chen"
    ]
  },
  "https://proceedings.mlr.press/v238/garcia-carrasco24a.html": {
    "title": "How does GPT-2 Predict Acronyms? Extracting and Understanding a Circuit via Mechanistic Interpretability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jorge García-Carrasco",
      "Alejandro Maté",
      "Juan Carlos Trujillo"
    ]
  },
  "https://proceedings.mlr.press/v238/halva24a.html": {
    "title": "Identifiable Feature Learning for Spatial Data with Nonlinear ICA",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hermanni Hälvä",
      "Jonathan So",
      "Richard E. Turner",
      "Aapo Hyvärinen"
    ]
  },
  "https://proceedings.mlr.press/v238/katta24a.html": {
    "title": "Interpretable Causal Inference for Analyzing Wearable, Sensor, and Distributional Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Srikar Katta",
      "Harsh Parikh",
      "Cynthia Rudin",
      "Alexander Volfovsky"
    ]
  },
  "https://proceedings.mlr.press/v238/chandramoorthy24a.html": {
    "title": "Score Operator Newton transport",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nisha Chandramoorthy",
      "Florian T Schaefer",
      "Youssef M Marzouk"
    ]
  },
  "https://proceedings.mlr.press/v238/novitasari24a.html": {
    "title": "ALAS: Active Learning for Autoconversion Rates Prediction from Satellite Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maria C. Novitasari",
      "Johannes Quaas",
      "Miguel Rodrigues"
    ]
  },
  "https://proceedings.mlr.press/v238/verine24a.html": {
    "title": "Optimal Budgeted Rejection Sampling for Generative Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexandre Verine",
      "Muni Sreenivas Pydi",
      "Benjamin Negrevergne",
      "Yann Chevaleyre"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24e.html": {
    "title": "Posterior Uncertainty Quantification in Neural Networks using Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Luhuan Wu",
      "Sinead A Williamson"
    ]
  },
  "https://proceedings.mlr.press/v238/zhao24c.html": {
    "title": "DHMConv: Directed Hypergraph Momentum Convolution Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wenbo Zhao",
      "Zitong Ma",
      "Zhe Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/jager24a.html": {
    "title": "From Data Imputation to Data Cleaning — Automated Cleaning of Tabular Data Improves Downstream Predictive Performance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sebastian Jäger",
      "Felix Biessmann"
    ]
  },
  "https://proceedings.mlr.press/v238/ekstrom-kelvinius24a.html": {
    "title": "Discriminator Guidance for Autoregressive Diffusion Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Filip Ekström Kelvinius",
      "Fredrik Lindsten"
    ]
  },
  "https://proceedings.mlr.press/v238/ding24a.html": {
    "title": "Resilient Constrained Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dongsheng Ding",
      "Zhengyan Huan",
      "Alejandro Ribeiro"
    ]
  },
  "https://proceedings.mlr.press/v238/jeong24a.html": {
    "title": "On-Demand Federated Learning for Arbitrary Target Class Distributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Isu Jeong",
      "Seulki Lee"
    ]
  },
  "https://proceedings.mlr.press/v238/shukla24a.html": {
    "title": "DiffRed: Dimensionality reduction guided by stable rank",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Prarabdh Shukla",
      "Gagan Raj Gupta",
      "Kunal Dutta"
    ]
  },
  "https://proceedings.mlr.press/v238/tamas24a.html": {
    "title": "Data-Driven Confidence Intervals with Optimal Rates for the Mean of Heavy-Tailed Distributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ambrus Tamás",
      "Szabolcs Szentpéteri",
      "Balázs Csáji"
    ]
  },
  "https://proceedings.mlr.press/v238/zakerinia24a.html": {
    "title": "Communication-Efficient Federated Learning With Data and Client Heterogeneity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hossein Zakerinia",
      "Shayan Talaei",
      "Giorgi Nadiradze",
      "Dan Alistarh"
    ]
  },
  "https://proceedings.mlr.press/v238/fraboni24a.html": {
    "title": "SIFU: Sequential Informed Federated Unlearning for Efficient and Provable Client Unlearning in Federated Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yann Fraboni",
      "Martin Van Waerebeke",
      "Kevin Scaman",
      "Richard Vidal",
      "Laetitia Kameni",
      "Marco Lorenzi"
    ]
  },
  "https://proceedings.mlr.press/v238/popordanoska24a.html": {
    "title": "Consistent and Asymptotically Unbiased Estimation of Proper Calibration Errors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Teodora Popordanoska",
      "Sebastian Gregor Gruber",
      "Aleksei Tiulpin",
      "Florian Buettner",
      "Matthew B. Blaschko"
    ]
  },
  "https://proceedings.mlr.press/v238/tailor24a.html": {
    "title": "Learning to Defer to a Population: A Meta-Learning Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Dharmesh Tailor",
      "Aditya Patra",
      "Rajeev Verma",
      "Putra Manggala",
      "Eric Nalisnick"
    ]
  },
  "https://proceedings.mlr.press/v238/li24o.html": {
    "title": "Trigonometric Quadrature Fourier Features for Scalable Gaussian Process Regression",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin Li",
      "Max Balakirsky",
      "Simon Mak"
    ]
  },
  "https://proceedings.mlr.press/v238/fatkhullin24a.html": {
    "title": "Taming Nonconvex Stochastic Mirror Descent with General Bregman Divergence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ilyas Fatkhullin",
      "Niao He"
    ]
  },
  "https://proceedings.mlr.press/v238/rashidi24a.html": {
    "title": "Cylindrical Thompson Sampling for High-Dimensional Bayesian Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bahador Rashidi",
      "Kerrick Johnstonbaugh",
      "Chao Gao"
    ]
  },
  "https://proceedings.mlr.press/v238/patil24b.html": {
    "title": "On learning history-based policies for controlling Markov decision processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gandharv Patil",
      "Aditya Mahajan",
      "Doina Precup"
    ]
  },
  "https://proceedings.mlr.press/v238/kolpaczki24a.html": {
    "title": "SVARM-IQ: Efficient Approximation of Any-order Shapley Interactions through Stratification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Patrick Kolpaczki",
      "Maximilian Muschalik",
      "Fabian Fumagalli",
      "Barbara Hammer",
      "Eyke Hüllermeier"
    ]
  },
  "https://proceedings.mlr.press/v238/chauhan24a.html": {
    "title": "Dynamic Inter-treatment Information Sharing for Individualized Treatment Effects Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vinod Kumar Chauhan",
      "Jiandong Zhou",
      "Ghadeer Ghosheh",
      "Soheila Molaei",
      "David A Clifton"
    ]
  },
  "https://proceedings.mlr.press/v238/hotti24a.html": {
    "title": "Benefits of Non-Linear Scale Parameterizations in Black Box Variational Inference through Smoothness Results and Gradient Variance Bounds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexandra Maria Hotti",
      "Lennart Alexander Van der Goten",
      "Jens Lagergren"
    ]
  },
  "https://proceedings.mlr.press/v238/mitarchuk24a.html": {
    "title": "Length independent PAC-Bayes bounds for Simple RNNs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Volodimir Mitarchuk",
      "Clara Lacroce",
      "Rémi Eyraud",
      "Rémi Emonet",
      "Amaury Habrard",
      "Guillaume Rabusseau"
    ]
  },
  "https://proceedings.mlr.press/v238/papazov24a.html": {
    "title": "Leveraging Continuous Time to Understand Momentum When Training Diagonal Linear Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hristo Papazov",
      "Scott Pesme",
      "Nicolas Flammarion"
    ]
  },
  "https://proceedings.mlr.press/v238/nitanda24a.html": {
    "title": "Why is parameter averaging beneficial in SGD? An objective smoothing perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Atsushi Nitanda",
      "Ryuhei Kikuchi",
      "Shugo Maeda",
      "Denny Wu"
    ]
  },
  "https://proceedings.mlr.press/v238/shingaki24a.html": {
    "title": "Identification and Estimation of \"Causes of Effects\" using Covariate-Mediator Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ryusei Shingaki",
      "Manabu Kuroki"
    ]
  },
  "https://proceedings.mlr.press/v238/crepon24a.html": {
    "title": "Sequential learning of the Pareto front for multi-objective bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "élise crepon",
      "Aurélien Garivier",
      "Wouter M Koolen"
    ]
  },
  "https://proceedings.mlr.press/v238/chakraborty24b.html": {
    "title": "Equivalence Testing: The Power of Bounded Adaptivity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Diptarka Chakraborty",
      "Sourav Chakraborty",
      "Gunjan Kumar",
      "Kuldeep Meel"
    ]
  },
  "https://proceedings.mlr.press/v238/kacprzyk24a.html": {
    "title": "Shape Arithmetic Expressions: Advancing Scientific Discovery Beyond Closed-Form Equations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Krzysztof Kacprzyk",
      "Mihaela van der Schaar"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24f.html": {
    "title": "On the estimation of persistence intensity functions and linear representations of persistence diagrams",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Weichen Wu",
      "Jisu Kim",
      "Alessandro Rinaldo"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24i.html": {
    "title": "Optimal estimation of Gaussian (poly)trees",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuhao Wang",
      "Ming Gao",
      "Wai Ming Tai",
      "Bryon Aragam",
      "Arnab Bhattacharyya"
    ]
  },
  "https://proceedings.mlr.press/v238/lee24c.html": {
    "title": "Approximate Bayesian Class-Conditional Models under Continuous Representation Shift",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas L. Lee",
      "Amos Storkey"
    ]
  },
  "https://proceedings.mlr.press/v238/battellani24a.html": {
    "title": "Dissimilarity Bandits",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Paolo Battellani",
      "Alberto Maria Metelli",
      "Francesco Trovò"
    ]
  },
  "https://proceedings.mlr.press/v238/manupriya24a.html": {
    "title": "Consistent Optimal Transport with Empirical Conditional Measures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Piyushi Manupriya",
      "Rachit K. Das",
      "Sayantan Biswas",
      "SakethaNath N Jagarlapudi"
    ]
  },
  "https://proceedings.mlr.press/v238/martin24a.html": {
    "title": "On the Impact of Overparameterization on the Training of a Shallow Neural Network in High Dimensions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Simon Martin",
      "Francis Bach",
      "Giulio Biroli"
    ]
  },
  "https://proceedings.mlr.press/v238/engelmann24a.html": {
    "title": "Mixed Models with Multiple Instance Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan P. Engelmann",
      "Alessandro Palma",
      "Jakub M. Tomczak",
      "Fabian Theis",
      "Francesco Paolo Casale"
    ]
  },
  "https://proceedings.mlr.press/v238/huang24b.html": {
    "title": "Horizon-Free and Instance-Dependent Regret Bounds for Reinforcement Learning with General Function Approximation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiayi Huang",
      "Han Zhong",
      "Liwei Wang",
      "Lin Yang"
    ]
  },
  "https://proceedings.mlr.press/v238/emmanouilidis24a.html": {
    "title": "Stochastic Extragradient with Random Reshuffling: Improved Convergence for Variational Inequalities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Konstantinos Emmanouilidis",
      "Rene Vidal",
      "Nicolas Loizou"
    ]
  },
  "https://proceedings.mlr.press/v238/lyu24a.html": {
    "title": "Inconsistency of Cross-Validation for Structure Learning in Gaussian Graphical Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhao Lyu",
      "Wai Ming Tai",
      "Mladen Kolar",
      "Bryon Aragam"
    ]
  },
  "https://proceedings.mlr.press/v238/kalemaj24a.html": {
    "title": "Differentially Private Conditional Independence Testing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Iden Kalemaj",
      "Shiva Kasiviswanathan",
      "Aaditya Ramdas"
    ]
  },
  "https://proceedings.mlr.press/v238/scaman24a.html": {
    "title": "Minimax Excess Risk of First-Order Methods for Statistical Learning with Data-Dependent Oracles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kevin Scaman",
      "Mathieu Even",
      "Batiste Le Bars",
      "Laurent Massoulie"
    ]
  },
  "https://proceedings.mlr.press/v238/abedsoltan24a.html": {
    "title": "On the Nyström Approximation for Preconditioning in Kernel Machines",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amirhesam Abedsoltan",
      "Parthe Pandit",
      "Luis Rademacher",
      "Mikhail Belkin"
    ]
  },
  "https://proceedings.mlr.press/v238/kamran24a.html": {
    "title": "Learning to Rank for Optimal Treatment Allocation Under Resource Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Fahad Kamran",
      "Maggie Makar",
      "Jenna Wiens"
    ]
  },
  "https://proceedings.mlr.press/v238/oesterling24a.html": {
    "title": "Fair Machine Unlearning: Data Removal while Mitigating Disparities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Oesterling",
      "Jiaqi Ma",
      "Flavio Calmon",
      "Himabindu Lakkaraju"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24j.html": {
    "title": "On the Effect of Key Factors in Spurious Correlation: A theoretical Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yipei Wang",
      "Xiaoqian Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/yang24e.html": {
    "title": "Hodge-Compositional Edge Gaussian Processes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maosheng Yang",
      "Viacheslav Borovitskiy",
      "Elvin Isufi"
    ]
  },
  "https://proceedings.mlr.press/v238/tsiourvas24a.html": {
    "title": "Manifold-Aligned Counterfactual Explanations for Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Asterios Tsiourvas",
      "Wei Sun",
      "Georgia Perakis"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24j.html": {
    "title": "Fast and Accurate Estimation of Low-Rank Matrices from Noisy Measurements via Preconditioned Non-Convex Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jialun Zhang",
      "Richard Y Zhang",
      "Hong-Ming Chiu"
    ]
  },
  "https://proceedings.mlr.press/v238/murti24a.html": {
    "title": "LP-based Construction of DC Decompositions for Efficient Inference of Markov Random Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chaitanya Murti",
      "Dhruva Kashyap",
      "Chiranjib Bhattacharyya"
    ]
  },
  "https://proceedings.mlr.press/v238/nazaret24a.html": {
    "title": "On the Misspecification of Linear Assumptions in Synthetic Controls",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Achille O. R. Nazaret",
      "Claudia Shi",
      "David Blei"
    ]
  },
  "https://proceedings.mlr.press/v238/carmon24a.html": {
    "title": "The sample complexity of ERMs in stochastic convex optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniel Carmon",
      "Amir Yehudayoff",
      "Roi Livni"
    ]
  },
  "https://proceedings.mlr.press/v238/pasarkar24a.html": {
    "title": "Cousins Of The Vendi Score: A Family Of Similarity-Based Diversity Metrics For Science And Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amey P. Pasarkar",
      "Adji Bousso Dieng"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24k.html": {
    "title": "On cyclical MCMC sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Liwei Wang",
      "Xinru Liu",
      "Aaron Smith",
      "Aguemon Y Atchade"
    ]
  },
  "https://proceedings.mlr.press/v238/john-ward24a.html": {
    "title": "FairRR: Pre-Processing for Group Fairness through Randomized Response",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Joshua John Ward",
      "Xianli Zeng",
      "Guang Cheng"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24e.html": {
    "title": "Fitting ARMA Time Series Models without Identification: A Proximal Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yin Liu",
      "Sam Davanloo Tajbakhsh"
    ]
  },
  "https://proceedings.mlr.press/v238/wu24g.html": {
    "title": "Unsupervised Change Point Detection in Multivariate Time Series",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daoping Wu",
      "Suhas Gundimeda",
      "Shaoshuai Mou",
      "Christopher Quinn"
    ]
  },
  "https://proceedings.mlr.press/v238/ferbach24a.html": {
    "title": "Proving Linear Mode Connectivity of Neural Networks via Optimal Transport",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Damien Ferbach",
      "Baptiste Goujaud",
      "Gauthier Gidel",
      "Aymeric Dieuleveut"
    ]
  },
  "https://proceedings.mlr.press/v238/ren24b.html": {
    "title": "Multi-objective Optimization via Wasserstein-Fisher-Rao Gradient Flow",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinuo Ren",
      "Tesi Xiao",
      "Tanmay Gangwani",
      "Anshuka Rangi",
      "Holakou Rahmanian",
      "Lexing Ying",
      "Subhajit Sanyal"
    ]
  },
  "https://proceedings.mlr.press/v238/guilmeau24a.html": {
    "title": "Adaptive importance sampling for heavy-tailed distributions via $α$-divergence minimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas Guilmeau",
      "Nicola Branchini",
      "Emilie Chouzenoux",
      "Victor Elvira"
    ]
  },
  "https://proceedings.mlr.press/v238/jafarnia-jahromi24a.html": {
    "title": "A Bayesian Learning Algorithm for Unknown Zero-sum Stochastic Games with an Arbitrary Opponent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehdi Jafarnia Jahromi",
      "Rahul A Jain",
      "Ashutosh Nayyar"
    ]
  },
  "https://proceedings.mlr.press/v238/cai24a.html": {
    "title": "Near-Optimal Policy Optimization for Correlated Equilibrium in General-Sum Markov Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yang Cai",
      "Haipeng Luo",
      "Chen-Yu Wei",
      "Weiqiang Zheng"
    ]
  },
  "https://proceedings.mlr.press/v238/hanna24a.html": {
    "title": "Multi-Agent Bandit Learning through Heterogeneous Action Erasure Channels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Osama A Hanna",
      "Merve Karakas",
      "Lin Yang",
      "Christina Fragouli"
    ]
  },
  "https://proceedings.mlr.press/v238/shen24b.html": {
    "title": "Efficient Variational Sequential Information Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jianwei Shen",
      "Jason Pacheco"
    ]
  },
  "https://proceedings.mlr.press/v238/colaco-carr24a.html": {
    "title": "Conditions on Preference Relations that Guarantee the Existence of Optimal Policies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jonathan Colaço Carr",
      "Prakash Panangaden",
      "Doina Precup"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24k.html": {
    "title": "Membership Testing in Markov Equivalence Classes via Independence Queries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiaqi Zhang",
      "Kirankumar Shiragur",
      "Caroline Uhler"
    ]
  },
  "https://proceedings.mlr.press/v238/kerrigan24a.html": {
    "title": "Functional Flow Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gavin Kerrigan",
      "Giosue Migliorini",
      "Padhraic Smyth"
    ]
  },
  "https://proceedings.mlr.press/v238/bansak24a.html": {
    "title": "Learning Under Random Distributional Shifts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kirk C. Bansak",
      "Elisabeth Paulson",
      "Dominik Rothenhaeusler"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24f.html": {
    "title": "Supervised Feature Selection via Ensemble Gradient Information from Sparse Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiting Liu",
      "Zahra Atashgahi",
      "Ghada Sokar",
      "Mykola Pechenizkiy",
      "Decebal Constantin Mocanu"
    ]
  },
  "https://proceedings.mlr.press/v238/tsai24b.html": {
    "title": "Proxy Methods for Domain Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Katherine Tsai",
      "Stephen R Pfohl",
      "Olawale Salaudeen",
      "Nicole Chiou",
      "Matt Kusner",
      "Alexander D’Amour",
      "Sanmi Koyejo",
      "Arthur Gretton"
    ]
  },
  "https://proceedings.mlr.press/v238/gan24a.html": {
    "title": "Contextual Bandits with Budgeted Information Reveal",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kyra Gan",
      "Esmaeil Keyvanshokooh",
      "Xueqing Liu",
      "Susan Murphy"
    ]
  },
  "https://proceedings.mlr.press/v238/zhou24c.html": {
    "title": "Timing as an Action: Learning When to Observe and Act",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Helen Zhou",
      "Audrey Huang",
      "Kamyar Azizzadenesheli",
      "David Childers",
      "Zachary Lipton"
    ]
  },
  "https://proceedings.mlr.press/v238/shen24c.html": {
    "title": "Stochastic Smoothed Gradient Descent Ascent for Federated Minimax Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wei Shen",
      "Minhui Huang",
      "Jiawei Zhang",
      "Cong Shen"
    ]
  },
  "https://proceedings.mlr.press/v238/xu24a.html": {
    "title": "Online multiple testing with e-values",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyu Xu",
      "Aaditya Ramdas"
    ]
  },
  "https://proceedings.mlr.press/v238/tan24a.html": {
    "title": "Informative Path Planning with Limited Adaptivity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rayen Tan",
      "Rohan Ghuge",
      "Viswanath Nagarajan"
    ]
  },
  "https://proceedings.mlr.press/v238/lion24a.html": {
    "title": "How Good is a Single Basin?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kai Lion",
      "Lorenzo Noci",
      "Thomas Hofmann",
      "Gregor Bachmann"
    ]
  },
  "https://proceedings.mlr.press/v238/jordan24a.html": {
    "title": "Independent Learning in Constrained Markov Potential Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philip Jordan",
      "Anas Barakat",
      "Niao He"
    ]
  },
  "https://proceedings.mlr.press/v238/erichson24a.html": {
    "title": "NoisyMix: Boosting Model Robustness to Common Corruptions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Benjamin Erichson",
      "Soon Hoe Lim",
      "Winnie Xu",
      "Francisco Utrera",
      "Ziang Cao",
      "Michael Mahoney"
    ]
  },
  "https://proceedings.mlr.press/v238/mahmudul-alam24a.html": {
    "title": "Holographic Global Convolutional Networks for Long-Range Prediction Tasks in Malware Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Mahmudul Alam",
      "Edward Raff",
      "Stella R Biderman",
      "Tim Oates",
      "James Holt"
    ]
  },
  "https://proceedings.mlr.press/v238/pichler24a.html": {
    "title": "On the (In)feasibility of ML Backdoor Detection as an Hypothesis Testing Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Georg Pichler",
      "Marco Romanelli",
      "Divya Prakash Manivannan",
      "Prashanth Krishnamurthy",
      "Farshad khorrami",
      "Siddharth Garg"
    ]
  },
  "https://proceedings.mlr.press/v238/maunu24a.html": {
    "title": "Acceleration and Implicit Regularization in Gaussian Phase Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tyler Maunu",
      "Martin Molina-Fructuoso"
    ]
  },
  "https://proceedings.mlr.press/v238/oprescu24a.html": {
    "title": "Low-rank MDPs with Continuous Action Spaces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miruna Oprescu",
      "Andrew Bennett",
      "Nathan Kallus"
    ]
  },
  "https://proceedings.mlr.press/v238/zhai24b.html": {
    "title": "Deep Learning-Based Alternative Route Computation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alex Zhai",
      "Dee Guo",
      "Sreenivas Gollapudi",
      "Kostas Kollias",
      "Daniel Delling"
    ]
  },
  "https://proceedings.mlr.press/v238/wright24a.html": {
    "title": "An Analytic Solution to Covariance Propagation in Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Oren Wright",
      "Yorie Nakahira",
      "José M. F. Moura"
    ]
  },
  "https://proceedings.mlr.press/v238/blum24a.html": {
    "title": "On the Vulnerability of Fairness Constrained Learning to Malicious Noise",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Avrim Blum",
      "Princewill Okoroafor",
      "Aadirupa Saha",
      "Kevin M. Stangl"
    ]
  },
  "https://proceedings.mlr.press/v238/xu24b.html": {
    "title": "Uncertainty-aware Continuous Implicit Neural Representations for Remote Sensing Object Counting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Siyuan Xu",
      "Yucheng Wang",
      "Mingzhou Fan",
      "Byung-Jun Yoon",
      "Xiaoning Qian"
    ]
  },
  "https://proceedings.mlr.press/v238/olsen24a.html": {
    "title": "Think Global, Adapt Local: Learning Locally Adaptive K-Nearest Neighbor Kernel Density Estimators",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kenny Olsen",
      "Rasmus M. Hoeegh Lindrup",
      "Morten Mørup"
    ]
  },
  "https://proceedings.mlr.press/v238/vasileios-vlatakis-gkaragkounis24a.html": {
    "title": "Stochastic Methods in Variational Inequalities: Ergodicity, Bias and Refinements",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Emmanouil Vasileios Vlatakis-Gkaragkounis",
      "Angeliki Giannou",
      "Yudong Chen",
      "Qiaomin Xie"
    ]
  },
  "https://proceedings.mlr.press/v238/faller24a.html": {
    "title": "Self-Compatibility: Evaluating Causal Discovery without Ground Truth",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philipp M. Faller",
      "Leena C. Vankadara",
      "Atalanti A. Mastakouri",
      "Francesco Locatello",
      "Dominik Janzing"
    ]
  },
  "https://proceedings.mlr.press/v238/pereyra24a.html": {
    "title": "Equivariant bootstrapping for uncertainty quantification in imaging inverse problems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcelo Pereyra",
      "Julián Tachella"
    ]
  },
  "https://proceedings.mlr.press/v238/krichene24a.html": {
    "title": "Private Learning with Public Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Walid Krichene",
      "Nicolas E Mayoraz",
      "Steffen Rendle",
      "Shuang Song",
      "Abhradeep Thakurta",
      "Li Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/mazzetto24a.html": {
    "title": "An Improved Algorithm for Learning Drifting Discrete Distributions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alessio Mazzetto"
    ]
  },
  "https://proceedings.mlr.press/v238/chae24a.html": {
    "title": "Towards a Complete Benchmark on Video Moment Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jinyeong Chae",
      "Donghwa Kim",
      "Kwanseok Kim",
      "Doyeon Lee",
      "Sangho Lee",
      "Seongsu Ha",
      "Jonghwan Mun",
      "Wooyoung Kang",
      "Byungseok Roh",
      "Joonseok Lee"
    ]
  },
  "https://proceedings.mlr.press/v238/jali24a.html": {
    "title": "Efficient Reinforcement Learning for Routing Jobs in Heterogeneous Queueing Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Neharika Jali",
      "Guannan Qu",
      "Weina Wang",
      "Gauri Joshi"
    ]
  },
  "https://proceedings.mlr.press/v238/reza-karimi24a.html": {
    "title": "Sinkhorn Flow as Mirror Flow: A Continuous-Time Framework for Generalizing the Sinkhorn Algorithm",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Reza Karimi",
      "Ya-Ping Hsieh",
      "Andreas Krause"
    ]
  },
  "https://proceedings.mlr.press/v238/dai24c.html": {
    "title": "SADI: Similarity-Aware Diffusion Model-Based Imputation for Incomplete Temporal EHR Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zongyu Dai",
      "Emily Getzen",
      "Qi Long"
    ]
  },
  "https://proceedings.mlr.press/v238/shakerinava24a.html": {
    "title": "Weight-Sharing Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mehran Shakerinava",
      "Motahareh MS Sohrabi",
      "Siamak Ravanbakhsh",
      "Simon Lacoste-Julien"
    ]
  },
  "https://proceedings.mlr.press/v238/tiapkin24a.html": {
    "title": "Generative Flow Networks as Entropy-Regularized RL",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daniil Tiapkin",
      "Nikita Morozov",
      "Alexey Naumov",
      "Dmitry P Vetrov"
    ]
  },
  "https://proceedings.mlr.press/v238/zhang24l.html": {
    "title": "Multi-resolution Time-Series Transformer for Long-term Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yitian Zhang",
      "Liheng Ma",
      "Soumyasundar Pal",
      "Yingxue Zhang",
      "Mark Coates"
    ]
  },
  "https://proceedings.mlr.press/v238/karntikoon24a.html": {
    "title": "First Passage Percolation with Queried Hints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kritkorn Karntikoon",
      "Yiheng Shen",
      "Sreenivas Gollapudi",
      "Kostas Kollias",
      "Aaron Schild",
      "Ali K Sinop"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24g.html": {
    "title": "User-level Differentially Private Stochastic Convex Optimization: Efficient Algorithms with Optimal Rates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Daogao Liu",
      "Hilal Asi"
    ]
  },
  "https://proceedings.mlr.press/v238/giaffar24a.html": {
    "title": "The Effective Number of Shared Dimensions Between Paired Datasets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hamza Giaffar",
      "Camille Rullán Buxó",
      "Mikio Aoi"
    ]
  },
  "https://proceedings.mlr.press/v238/luo24a.html": {
    "title": "DE-HNN: An effective neural model for Circuit Netlist representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zhishang Luo",
      "Truong Son Hy",
      "Puoya Tabaghi",
      "Michaël Defferrard",
      "Elahe Rezaei",
      "Ryan M. Carey",
      "Rhett Davis",
      "Rajeev Jain",
      "Yusu Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/yao24b.html": {
    "title": "Simulation-Based Stacking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuling Yao",
      "Bruno Régaldo-Saint Blancard",
      "Justin Domke"
    ]
  },
  "https://proceedings.mlr.press/v238/gong24b.html": {
    "title": "Towards Practical Non-Adversarial Distribution Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ziyu Gong",
      "Ben Usman",
      "Han Zhao",
      "David I Inouye"
    ]
  },
  "https://proceedings.mlr.press/v238/demirel24a.html": {
    "title": "Benchmarking Observational Studies with Experimental Data under Right-Censoring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ilker Demirel",
      "Edward De Brouwer",
      "Zeshan M Hussain",
      "Michael Oberst",
      "Anthony A Philippakis",
      "David Sontag"
    ]
  },
  "https://proceedings.mlr.press/v238/kalantzis24a.html": {
    "title": "Asynchronous Randomized Trace Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vasileios Kalantzis",
      "Shashanka Ubaru",
      "Chai Wah Wu",
      "Georgios Kollias",
      "Lior Horesh"
    ]
  },
  "https://proceedings.mlr.press/v238/li24q.html": {
    "title": "Computing epidemic metrics with edge differential privacy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "George Z. Li",
      "Dung Nguyen",
      "Anil Vullikanti"
    ]
  },
  "https://proceedings.mlr.press/v238/mcnamara24a.html": {
    "title": "Sequential Monte Carlo for Inclusive KL Minimization in Amortized Variational Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Declan McNamara",
      "Jackson Loper",
      "Jeffrey Regier"
    ]
  },
  "https://proceedings.mlr.press/v238/mcmahan24a.html": {
    "title": "Anytime-Constrained Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jeremy McMahan",
      "Xiaojin Zhu"
    ]
  },
  "https://proceedings.mlr.press/v238/wen24a.html": {
    "title": "Tensor-view Topological Graph Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Tao Wen",
      "Elynn Chen",
      "Yuzhou Chen"
    ]
  },
  "https://proceedings.mlr.press/v238/byun24a.html": {
    "title": "Auditing Fairness under Unobserved Confounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yewon Byun",
      "Dylan Sam",
      "Michael Oberst",
      "Zachary Lipton",
      "Bryan Wilder"
    ]
  },
  "https://proceedings.mlr.press/v238/koelle24a.html": {
    "title": "Consistency of Dictionary-Based Manifold Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samson J. Koelle",
      "Hanyu Zhang",
      "Octavian-Vlad Murad",
      "Marina Meila"
    ]
  },
  "https://proceedings.mlr.press/v238/chang24a.html": {
    "title": "Probabilistic Modeling for Sequences of Sets in Continuous-Time",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuxin Chang",
      "Alex J Boyd",
      "Padhraic Smyth"
    ]
  },
  "https://proceedings.mlr.press/v238/lan24a.html": {
    "title": "Causal Q-Aggregation for CATE Model Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hui Lan",
      "Vasilis Syrgkanis"
    ]
  },
  "https://proceedings.mlr.press/v238/zhao24d.html": {
    "title": "Self-Supervised Quantization-Aware Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kaiqi Zhao",
      "Ming Zhao"
    ]
  },
  "https://proceedings.mlr.press/v238/meng24a.html": {
    "title": "FALCON: FLOP-Aware Combinatorial Optimization for Neural Network Pruning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Xiang Meng",
      "Wenyu Chen",
      "Riade Benbaki",
      "Rahul Mazumder"
    ]
  },
  "https://proceedings.mlr.press/v238/guo24c.html": {
    "title": "The effect of Leaky ReLUs on the training and generalization of overparameterized networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinglong Guo",
      "Shaohan Li",
      "Gilad Lerman"
    ]
  },
  "https://proceedings.mlr.press/v238/gao24b.html": {
    "title": "Decentralized Multi-Level Compositional Optimization Algorithms with Level-Independent Convergence Rate",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Hongchang Gao"
    ]
  },
  "https://proceedings.mlr.press/v238/jiang24a.html": {
    "title": "Krylov Cubic Regularized Newton: A Subspace Second-Order Method with Dimension-Free Convergence Rate",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruichen Jiang",
      "Parameswaran Raman",
      "Shoham Sabach",
      "Aryan Mokhtari",
      "Mingyi Hong",
      "Volkan Cevher"
    ]
  },
  "https://proceedings.mlr.press/v238/suttle24a.html": {
    "title": "Sampling-based Safe Reinforcement Learning for Nonlinear Dynamical Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Wesley Suttle",
      "Vipul Kumar Sharma",
      "Krishna Chaitanya Kosaraju",
      "Sivaranjani Seetharaman",
      "Ji Liu",
      "Vijay Gupta",
      "Brian M Sadler"
    ]
  },
  "https://proceedings.mlr.press/v238/garg24a.html": {
    "title": "Soft-constrained Schrödinger Bridge: a Stochastic Control Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jhanvi Garg",
      "Xianyang Zhang",
      "Quan Zhou"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24f.html": {
    "title": "Coreset Markov chain Monte Carlo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Naitong Chen",
      "Trevor Campbell"
    ]
  },
  "https://proceedings.mlr.press/v238/gheshlaghi-azar24a.html": {
    "title": "A General Theoretical Paradigm to Understand Learning from Human Preferences",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mohammad Gheshlaghi Azar",
      "Zhaohan Daniel Guo",
      "Bilal Piot",
      "Remi Munos",
      "Mark Rowland",
      "Michal Valko",
      "Daniele Calandriello"
    ]
  },
  "https://proceedings.mlr.press/v238/marmarelis24a.html": {
    "title": "Policy Learning for Localized Interventions from Observational Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Myrl G. Marmarelis",
      "Fred Morstatter",
      "Aram Galstyan",
      "Greg Ver Steeg"
    ]
  },
  "https://proceedings.mlr.press/v238/ren24c.html": {
    "title": "Understanding the Generalization Benefits of Late Learning Rate Decay",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinuo Ren",
      "Chao Ma",
      "Lexing Ying"
    ]
  },
  "https://proceedings.mlr.press/v238/lee24d.html": {
    "title": "Improved Regret Bounds of (Multinomial) Logistic Bandits via Regret-to-Confidence-Set Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Junghyun Lee",
      "Se-Young Yun",
      "Kwang-Sung Jun"
    ]
  },
  "https://proceedings.mlr.press/v238/wang24l.html": {
    "title": "Near-Interpolators: Rapid Norm Growth and the Trade-Off between Interpolation and Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yutong Wang",
      "Rishi Sonthalia",
      "Wei Hu"
    ]
  },
  "https://proceedings.mlr.press/v238/kant24a.html": {
    "title": "Identifiability of Product of Experts Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Manav Kant",
      "Eric Y Ma",
      "Andrei Staicu",
      "Leonard J Schulman",
      "Spencer Gordon"
    ]
  },
  "https://proceedings.mlr.press/v238/chen24g.html": {
    "title": "Gibbs-Based Information Criteria and the Over-Parameterized Regime",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Haobo Chen",
      "Gregory W Wornell",
      "Yuheng Bu"
    ]
  },
  "https://proceedings.mlr.press/v238/puranik24a.html": {
    "title": "Improving Robustness via Tilted Exponential Layer: A Communication-Theoretic Perspective",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bhagyashree Puranik",
      "Ahmad Beirami",
      "Yao Qin",
      "Upamanyu Madhow"
    ]
  },
  "https://proceedings.mlr.press/v238/deng24b.html": {
    "title": "On the Generalization Ability of Unsupervised Pretraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuyang Deng",
      "Junyuan Hong",
      "Jiayu Zhou",
      "Mehrdad Mahdavi"
    ]
  },
  "https://proceedings.mlr.press/v238/mustafa24a.html": {
    "title": "Non-vacuous Generalization Bounds for Adversarial Risk in Stochastic Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Waleed Mustafa",
      "Philipp Liznerski",
      "Antoine Ledent",
      "Dennis Wagner",
      "Puyu Wang",
      "Marius Kloft"
    ]
  },
  "https://proceedings.mlr.press/v238/xu24c.html": {
    "title": "BLIS-Net: Classifying and Analyzing Signals on Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Charles Xu",
      "Laney Goldman",
      "Valentina Guo",
      "Benjamin Hollander-Bodie",
      "Maedee Trank-Greene",
      "Ian Adelstein",
      "Edward De Brouwer",
      "Rex Ying",
      "Smita Krishnaswamy",
      "Michael Perlmutter"
    ]
  },
  "https://proceedings.mlr.press/v238/deb24a.html": {
    "title": "Think Before You Duel: Understanding Complexities of Preference Learning under Constrained Resources",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rohan Deb",
      "Aadirupa Saha",
      "Arindam Banerjee"
    ]
  },
  "https://proceedings.mlr.press/v238/warren24a.html": {
    "title": "Fast Fourier Bayesian Quadrature",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Houston Warren",
      "Fabio Ramos"
    ]
  },
  "https://proceedings.mlr.press/v238/inatsu24a.html": {
    "title": "Bounding Box-based Multi-objective Bayesian Optimization of Risk Measures under Input Uncertainty",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yu Inatsu",
      "Shion Takeno",
      "Hiroyuki Hanada",
      "Kazuki Iwata",
      "Ichiro Takeuchi"
    ]
  },
  "https://proceedings.mlr.press/v238/cousins24a.html": {
    "title": "To Pool or Not To Pool: Analyzing the Regularizing Effects of Group-Fair Training on Shared Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Cyrus Cousins",
      "I. Elizabeth Kumar",
      "Suresh Venkatasubramanian"
    ]
  },
  "https://proceedings.mlr.press/v238/kong24a.html": {
    "title": "Two Birds with One Stone: Enhancing Uncertainty Quantification and Interpretability with Graph Functional Neural Process",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lingkai Kong",
      "Haotian Sun",
      "Yuchen Zhuang",
      "Haorui Wang",
      "Wenhao Mu",
      "Chao Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/heo24a.html": {
    "title": "Sample Efficient Learning of Factored Embeddings of Tensor Fields",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Taemin Heo",
      "Chandrajit Bajaj"
    ]
  },
  "https://proceedings.mlr.press/v238/biron-lattes24a.html": {
    "title": "autoMALA: Locally adaptive Metropolis-adjusted Langevin algorithm",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Miguel Biron-Lattes",
      "Nikola Surjanovic",
      "Saifuddin Syed",
      "Trevor Campbell",
      "Alexandre Bouchard-Cote"
    ]
  },
  "https://proceedings.mlr.press/v238/yan24a.html": {
    "title": "Causal Bandits with General Causal Models and Interventions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zirui Yan",
      "Dennis Wei",
      "Dmitriy A Katz",
      "Prasanna Sattigeri",
      "Ali Tajer"
    ]
  },
  "https://proceedings.mlr.press/v238/wycoff24a.html": {
    "title": "Surrogate Active Subspaces for Jump-Discontinuous Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nathan Wycoff"
    ]
  },
  "https://proceedings.mlr.press/v238/alacaoglu24a.html": {
    "title": "Complexity of Single Loop Algorithms for Nonlinear Programming with Stochastic Objective and Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ahmet Alacaoglu",
      "Stephen J Wright"
    ]
  },
  "https://proceedings.mlr.press/v238/shaikh-veedu24a.html": {
    "title": "Information Theoretically Optimal Sample Complexity of Learning Dynamical Directed Acyclic Graphs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mishfad Shaikh Veedu",
      "Deepjyoti Deka",
      "Murti Salapaka"
    ]
  },
  "https://proceedings.mlr.press/v238/lim24a.html": {
    "title": "Pathwise Explanation of ReLU Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Seongwoo Lim",
      "Won Jo",
      "Joohyung Lee",
      "Jaesik Choi"
    ]
  },
  "https://proceedings.mlr.press/v238/hood24a.html": {
    "title": "The AL$\\ell_0$CORE Tensor Decomposition for Sparse Count Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "John Hood",
      "Aaron J. Schein"
    ]
  },
  "https://proceedings.mlr.press/v238/huang24c.html": {
    "title": "Adaptive Federated Minimax Optimization with Lower Complexities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Feihu Huang",
      "Xinrui Wang",
      "Junyi Li",
      "Songcan Chen"
    ]
  },
  "https://proceedings.mlr.press/v238/ni24a.html": {
    "title": "Mixture-of-Linear-Experts for Long-term Time Series Forecasting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ronghao Ni",
      "Zinan Lin",
      "Shuaiqi Wang",
      "Giulia Fanti"
    ]
  },
  "https://proceedings.mlr.press/v238/mortazavi24a.html": {
    "title": "On the price of exact truthfulness in incentive-compatible online learning with bandit feedback: a regret lower bound for WSU-UX",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ali Mortazavi",
      "Junhao Lin",
      "Nishant Mehta"
    ]
  },
  "https://proceedings.mlr.press/v238/okoroafor24a.html": {
    "title": "Faster Recalibration of an Online Predictor via Approachability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Princewill Okoroafor",
      "Bobby Kleinberg",
      "Wen Sun"
    ]
  },
  "https://proceedings.mlr.press/v238/cheng24a.html": {
    "title": "Provable Policy Gradient Methods for Average-Reward Markov Potential Games",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Min Cheng",
      "Ruida Zhou",
      "P. R. Kumar",
      "Chao Tian"
    ]
  },
  "https://proceedings.mlr.press/v238/maniyar24a.html": {
    "title": "A Cubic-regularized Policy Newton Algorithm for Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Mizhaan P. Maniyar",
      "Prashanth L.A.",
      "Akash Mondal",
      "Shalabh Bhatnagar"
    ]
  },
  "https://proceedings.mlr.press/v238/lu24a.html": {
    "title": "Towards Generalizable and Interpretable Motion Prediction: A Deep Variational Bayes Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Juanwu Lu",
      "Wei Zhan",
      "Masayoshi Tomizuka",
      "Yeping Hu"
    ]
  },
  "https://proceedings.mlr.press/v238/ildiz24a.html": {
    "title": "Understanding Inverse Scaling and Emergence in Multitask Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammed E. Ildiz",
      "Zhe Zhao",
      "Samet Oymak"
    ]
  },
  "https://proceedings.mlr.press/v238/sunil-lahoti24a.html": {
    "title": "Sharpened Lazy Incremental Quasi-Newton Method",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aakash Sunil Lahoti",
      "Spandan Senapati",
      "Ketan Rajawat",
      "Alec Koppel"
    ]
  },
  "https://proceedings.mlr.press/v238/li24p.html": {
    "title": "Efficient Active Learning Halfspaces with Tsybakov Noise: A Non-convex Optimization Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yinan Li",
      "Chicheng Zhang"
    ]
  },
  "https://proceedings.mlr.press/v238/mao24a.html": {
    "title": "Theoretically Grounded Loss Functions and Algorithms for Score-Based Multi-Class Abstention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anqi Mao",
      "Mehryar Mohri",
      "Yutao Zhong"
    ]
  },
  "https://proceedings.mlr.press/v238/braun24b.html": {
    "title": "Deep Classifier Mimicry without Data Access",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Steven Braun",
      "Martin Mundt",
      "Kristian Kersting"
    ]
  },
  "https://proceedings.mlr.press/v238/bojkovic24a.html": {
    "title": "Data Driven Threshold and Potential Initialization for Spiking Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Velibor Bojkovic",
      "Srinivas Anumasa",
      "Giulia De Masi",
      "Bin Gu",
      "Huan Xiong"
    ]
  },
  "https://proceedings.mlr.press/v238/battash24a.html": {
    "title": "Revisiting the Noise Model of Stochastic Gradient Descent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Barak Battash",
      "Lior Wolf",
      "Ofir Lindenbaum"
    ]
  },
  "https://proceedings.mlr.press/v238/nakano24a.html": {
    "title": "Warped Diffusion for Latent Differentiation Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Masahiro Nakano",
      "Hiroki Sakuma",
      "Ryo Nishikimi",
      "Ryohei Shibue",
      "Takashi Sato",
      "Tomoharu Iwata",
      "Kunio Kashino"
    ]
  },
  "https://proceedings.mlr.press/v238/tsoy24a.html": {
    "title": "Provable Mutual Benefits from Federated Learning in Privacy-Sensitive Domains",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikita Tsoy",
      "Anna Mihalkova",
      "Teodora N Todorova",
      "Nikola Konstantinov"
    ]
  },
  "https://proceedings.mlr.press/v238/ceni24a.html": {
    "title": "Random Oscillators Network for Time Series Processing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrea Ceni",
      "Andrea Cossu",
      "Maximilian W Stölzle",
      "Jingyue Liu",
      "Cosimo Della Santina",
      "Davide Bacciu",
      "Claudio Gallicchio"
    ]
  },
  "https://proceedings.mlr.press/v238/liu24h.html": {
    "title": "Mitigating Underfitting in Learning to Defer with Consistent Losses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Shuqi Liu",
      "Yuzhou Cao",
      "Qiaozhen Zhang",
      "Lei Feng",
      "Bo An"
    ]
  },
  "https://proceedings.mlr.press/v238/cao24a.html": {
    "title": "Consistent Hierarchical Classification with A Generalized Metric",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yuzhou Cao",
      "Lei Feng",
      "Bo An"
    ]
  },
  "https://proceedings.mlr.press/v238/monzio-compagnoni24a.html": {
    "title": "SDEs for Minimax Optimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Enea Monzio Compagnoni",
      "Antonio Orvieto",
      "Hans Kersting",
      "Frank Proske",
      "Aurelien Lucchi"
    ]
  },
  "https://proceedings.mlr.press/v238/ray-chowdhury24a.html": {
    "title": "Differentially Private Reward Estimation with Preference Feedback",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sayak Ray Chowdhury",
      "Xingyu Zhou",
      "Nagarajan Natarajan"
    ]
  },
  "https://proceedings.mlr.press/v238/morozov24a.html": {
    "title": "Differentiable Rendering with Reparameterized Volume Sampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Nikita Morozov",
      "Denis Rakitin",
      "Oleg Desheulin",
      "Dmitry P Vetrov",
      "Kirill Struminsky"
    ]
  },
  "https://proceedings.mlr.press/v238/hubler24a.html": {
    "title": "Parameter-Agnostic Optimization under Relaxed Smoothness",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Florian Hübler",
      "Junchi Yang",
      "Xiang Li",
      "Niao He"
    ]
  },
  "https://proceedings.mlr.press/v238/nazykov24a.html": {
    "title": "Stochastic Frank-Wolfe: Unified Analysis and Zoo of Special Cases",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ruslan Nazykov",
      "Aleksandr Shestakov",
      "Vladimir Solodkin",
      "Aleksandr Beznosikov",
      "Gauthier Gidel",
      "Alexander Gasnikov"
    ]
  },
  "https://proceedings.mlr.press/v238/plassier24a.html": {
    "title": "Efficient Conformal Prediction under Data Heterogeneity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vincent Plassier",
      "Nikita Kotelevskii",
      "Aleksandr Rubashevskii",
      "Fedor Noskov",
      "Maksim Velikanov",
      "Alexander Fishkov",
      "Samuel Horvath",
      "Martin Takac",
      "Eric Moulines",
      "Maxim Panov"
    ]
  },
  "https://proceedings.mlr.press/v238/ghosh24b.html": {
    "title": "Sample-efficient neural likelihood-free Bayesian inference of implicit HMMs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sanmitra Ghosh",
      "Paul Birrell",
      "Daniela De Angelis"
    ]
  },
  "https://proceedings.mlr.press/v238/mameche24a.html": {
    "title": "Identifying Confounding from Causal Mechanism Shifts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Sarah Mameche",
      "Jilles Vreeken",
      "David Kaltenpoth"
    ]
  },
  "https://proceedings.mlr.press/v238/batten24a.html": {
    "title": "Tight Verification of Probabilistic Robustness in Bayesian Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ben Batten",
      "Mehran Hosseini",
      "Alessio Lomuscio"
    ]
  },
  "https://proceedings.mlr.press/v238/saha24b.html": {
    "title": "Testing exchangeability by pairwise betting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Aytijhya Saha",
      "Aaditya Ramdas"
    ]
  },
  "https://proceedings.mlr.press/v238/m-buch24a.html": {
    "title": "Simple and scalable algorithms for cluster-aware precision medicine",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amanda M Buch",
      "Conor Liston",
      "Logan Grosenick"
    ]
  },
  "https://proceedings.mlr.press/v238/r-hands24a.html": {
    "title": "P-tensors: a General Framework for Higher Order Message Passing in Subgraph Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Andrew R Hands",
      "Tianyi Sun",
      "Risi Kondor"
    ]
  },
  "https://proceedings.mlr.press/v238/a-cabannnes24a.html": {
    "title": "The Galerkin method beats Graph-Based Approaches for Spectral Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Vivien A Cabannnes",
      "Francis Bach"
    ]
  },
  "https://proceedings.mlr.press/v238/j-holland24a.html": {
    "title": "Robust variance-regularized risk minimization with concomitant scaling",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Matthew J Holland"
    ]
  },
  "https://proceedings.mlr.press/v238/d-kjaersgaard24a.html": {
    "title": "Fair Soft Clustering",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Rune D. Kjærsgaard",
      "Pekka Parviainen",
      "Saket Saurabh",
      "Madhumita Kundu",
      "Line Clemmensen"
    ]
  },
  "https://proceedings.mlr.press/v238/y-tong24a.html": {
    "title": "Simulation-Free Schrödinger Bridges via Score and Flow Matching",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Alexander Y Tong",
      "Nikolay Malkin",
      "Kilian Fatras",
      "Lazar Atanackovic",
      "Yanlei Zhang",
      "Guillaume Huguet",
      "Guy Wolf",
      "Yoshua Bengio"
    ]
  },
  "https://proceedings.mlr.press/v238/c-cosier24a.html": {
    "title": "A Unifying Variational Framework for Gaussian Process Motion Planning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Lucas C. Cosier",
      "Rares Iordan",
      "Sicelukwanda N.T. Zwane",
      "Giovanni Franzese",
      "James T. Wilson",
      "Marc Deisenroth",
      "Alexander Terenin",
      "Yasemin Bekiroglu"
    ]
  },
  "https://proceedings.mlr.press/v238/q-khan24a.html": {
    "title": "Analyzing Explainer Robustness via Probabilistic Lipschitzness of Prediction Functions",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Zulqarnain Q Khan",
      "Davin Hill",
      "Aria Masoomi",
      "Joshua T Bone",
      "Jennifer Dy"
    ]
  },
  "https://proceedings.mlr.press/v238/a-k-september24a.html": {
    "title": "Extended Deep Adaptive Input Normalization for Preprocessing Time Series Data for Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Marcus A K September",
      "Francesco Sanna Passino",
      "Leonie Goldmann",
      "Anton Hinel"
    ]
  },
  "https://proceedings.mlr.press/v238/s-g-heidrich24a.html": {
    "title": "A 4-Approximation Algorithm for Min Max Correlation Clustering",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Holger S.G. Heidrich",
      "Jannik Irmai",
      "Bjoern Andres"
    ]
  },
  "https://proceedings.mlr.press/v238/b-andrew24a.html": {
    "title": "GmGM: a fast multi-axis Gaussian graphical model",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Ethan B Andrew",
      "David Westhead",
      "Luisa Cutillo"
    ]
  },
  "https://proceedings.mlr.press/v238/m-moreno24a.html": {
    "title": "Efficient Model-Based Concave Utility Reinforcement Learning through Greedy Mirror Descent",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Bianca M Moreno",
      "Margaux Bregere",
      "Pierre Gaillard",
      "Nadia Oudjane"
    ]
  },
  "https://proceedings.mlr.press/v238/m-baker24a.html": {
    "title": "Monotone Operator Theory-Inspired Message Passing for Learning Long-Range Interaction on Graphs",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Justin M Baker",
      "Qingsong Wang",
      "Martin Berzins",
      "Thomas Strohmer",
      "Bao Wang"
    ]
  },
  "https://proceedings.mlr.press/v238/u-pasteris24a.html": {
    "title": "Sum-max Submodular Bandits",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Stephen U Pasteris",
      "Alberto Rumi",
      "Fabio Vitale",
      "Nicolò Cesa-Bianchi"
    ]
  },
  "https://proceedings.mlr.press/v238/c-diluvi24a.html": {
    "title": "Mixed variational flows for discrete variables",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Gian C Diluvi",
      "Benjamin Bloem-Reddy",
      "Trevor Campbell"
    ]
  },
  "https://proceedings.mlr.press/v238/p-patel24a.html": {
    "title": "Conformal Contextual Robust Optimization",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Yash P Patel",
      "Sahana Rayan",
      "Ambuj Tewari"
    ]
  },
  "https://proceedings.mlr.press/v238/d-abernethy24a.html": {
    "title": "Lexicographic Optimization: Algorithms and Stability",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jacob D Abernethy",
      "Robert Schapire",
      "Umar Syed"
    ]
  },
  "https://proceedings.mlr.press/v238/t-wang24a.html": {
    "title": "Efficient Data Shapley for Weighted Nearest Neighbor Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jiachen T. Wang",
      "Prateek Mittal",
      "Ruoxi Jia"
    ]
  },
  "https://proceedings.mlr.press/v238/l-martinez24a.html": {
    "title": "Achieving Group Distributional Robustness and Minimax Group Fairness with Interpolating Classifiers",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Natalia L Martinez",
      "Martin A Bertran",
      "Guillermo Sapiro"
    ]
  },
  "https://proceedings.mlr.press/v238/h-ahmed24a.html": {
    "title": "Privacy-Preserving Decentralized Actor-Critic for Cooperative Multi-Agent Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maheed H Ahmed",
      "Mahsa Ghasemi"
    ]
  },
  "https://proceedings.mlr.press/v238/j-cundy24a.html": {
    "title": "Privacy-Constrained Policies via Mutual Information Regularized Policy Gradients",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Chris J Cundy",
      "Rishi Desai",
      "Stefano Ermon"
    ]
  },
  "https://proceedings.mlr.press/v238/m-nguyen24a.html": {
    "title": "Near-optimal Per-Action Regret Bounds for Sleeping Bandits",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Quan M Nguyen",
      "Nishant Mehta"
    ]
  },
  "https://proceedings.mlr.press/v238/w-mogensen24a.html": {
    "title": "Faithful graphical representations of local independence",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Søren W Mogensen"
    ]
  },
  "https://proceedings.mlr.press/v238/u-mondal24a.html": {
    "title": "Improved Sample Complexity Analysis of Natural Policy Gradient Algorithm with General Parameterization for Infinite Horizon Discounted Reward Markov Decision Processes",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Washim U Mondal",
      "Vaneet Aggarwal"
    ]
  },
  "https://proceedings.mlr.press/v238/m-maddux24a.html": {
    "title": "Multi-Agent Learning in Contextual Games under Unknown Constraints",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Anna M Maddux",
      "Maryam Kamgarpour"
    ]
  },
  "https://proceedings.mlr.press/v238/c-novitasari24a.html": {
    "title": "ALAS: Active Learning for Autoconversion Rates Prediction from Satellite Data",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Maria C Novitasari",
      "Johannes Quaas",
      "Miguel Rodrigues"
    ]
  },
  "https://proceedings.mlr.press/v238/l-lee24a.html": {
    "title": "Approximate Bayesian Class-Conditional Models under Continuous Representation Shift",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Thomas L Lee",
      "Amos Storkey"
    ]
  },
  "https://proceedings.mlr.press/v238/p-engelmann24a.html": {
    "title": "Mixed Models with Multiple Instance Learning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Jan P. Engelmann",
      "Alessandro Palma",
      "Jakub M Tomczak",
      "Fabian Theis",
      "Francesco Paolo Casale"
    ]
  },
  "https://proceedings.mlr.press/v238/p-pasarkar24a.html": {
    "title": "Cousins Of The Vendi Score: A Family Of Similarity-Based Diversity Metrics For Science And Machine Learning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Amey P Pasarkar",
      "Adji Bousso Dieng"
    ]
  },
  "https://proceedings.mlr.press/v238/a-hanna24a.html": {
    "title": "Multi-Agent Bandit Learning through Heterogeneous Action Erasure Channels",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Osama A Hanna",
      "Merve Karakas",
      "Lin Yang",
      "Christina Fragouli"
    ]
  },
  "https://proceedings.mlr.press/v238/c-bansak24a.html": {
    "title": "Learning Under Random Distributional Shifts",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Kirk C Bansak",
      "Elisabeth Paulson",
      "Dominik Rothenhaeusler"
    ]
  },
  "https://proceedings.mlr.press/v238/m-faller24a.html": {
    "title": "Self-Compatibility: Evaluating Causal Discovery without Ground Truth",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Philipp M Faller",
      "Leena C Vankadara",
      "Atalanti A Mastakouri",
      "Francesco Locatello",
      "Dominik Janzing"
    ]
  },
  "https://proceedings.mlr.press/v238/z-li24a.html": {
    "title": "Computing epidemic metrics with edge differential privacy",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "George Z Li",
      "Dung Nguyen",
      "Anil Vullikanti"
    ]
  },
  "https://proceedings.mlr.press/v238/j-koelle24a.html": {
    "title": "Consistency of Dictionary-Based Manifold Learning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Samson J Koelle",
      "Hanyu Zhang",
      "Octavian-Vlad Murad",
      "Marina Meila"
    ]
  },
  "https://proceedings.mlr.press/v238/e-ildiz24a.html": {
    "title": "Understanding Inverse Scaling and Emergence in Multitask Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": null,
    "id": null,
    "semantic_title": "",
    "citation_count": 0,
    "authors": [
      "Muhammed E Ildiz",
      "Zhe Zhao",
      "Samet Oymak"
    ]
  }
}