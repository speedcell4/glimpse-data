<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="utf-8">
    <meta name="viewport" content="width=device-width, initial-scale=1, shrink-to-fit=no">

    <link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/css/bootstrap.min.css"
          integrity="sha384-xOolHFLEh07PJGoPkLv1IbcEPTNtaed2xpHsD9ESMhqIYd0nLMwNLD69Npy4HI+N" crossorigin="anonymous">

    <title>Glimpse - CVPR2021</title>
</head>

<body>

<header class="container">
    <h1>Glimpse - CVPR2021</h1>
    <p>Last Update: March 2, 2023 - 21:21:41</p>
</header>

<main>
    <section class="container">
        <div class="row">
            

                <div class="col">
                    <dl>
                        
                            <dt>
                                <a>COLT</a>
                            </dt>
                            <dd>
                                
                                    <a href="COLT2016.html">16</a>
                                
                                    <a href="COLT2017.html">17</a>
                                
                                    <a href="COLT2018.html">18</a>
                                
                                    <a href="COLT2019.html">19</a>
                                
                                    <a href="COLT2020.html">20</a>
                                
                                    <a href="COLT2021.html">21</a>
                                
                                    <a href="COLT2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ICLR</a>
                            </dt>
                            <dd>
                                
                                    <a href="ICLR2016.html">16</a>
                                
                                    <a href="ICLR2017.html">17</a>
                                
                                    <a href="ICLR2018.html">18</a>
                                
                                    <a href="ICLR2019.html">19</a>
                                
                                    <a href="ICLR2020.html">20</a>
                                
                                    <a href="ICLR2021.html">21</a>
                                
                                    <a href="ICLR2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ICML</a>
                            </dt>
                            <dd>
                                
                                    <a href="ICML2016.html">16</a>
                                
                                    <a href="ICML2017.html">17</a>
                                
                                    <a href="ICML2018.html">18</a>
                                
                                    <a href="ICML2019.html">19</a>
                                
                                    <a href="ICML2020.html">20</a>
                                
                                    <a href="ICML2021.html">21</a>
                                
                                    <a href="ICML2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>NeurIPS</a>
                            </dt>
                            <dd>
                                
                                    <a href="NeurIPS2016.html">16</a>
                                
                                    <a href="NeurIPS2017.html">17</a>
                                
                                    <a href="NeurIPS2018.html">18</a>
                                
                                    <a href="NeurIPS2019.html">19</a>
                                
                                    <a href="NeurIPS2020.html">20</a>
                                
                                    <a href="NeurIPS2021.html">21</a>
                                
                                    <a href="NeurIPS2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>IJCAI</a>
                            </dt>
                            <dd>
                                
                                    <a href="IJCAI2017.html">17</a>
                                
                                    <a href="IJCAI2018.html">18</a>
                                
                                    <a href="IJCAI2019.html">19</a>
                                
                                    <a href="IJCAI2020.html">20</a>
                                
                                    <a href="IJCAI2021.html">21</a>
                                
                                    <a href="IJCAI2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>AAAI</a>
                            </dt>
                            <dd>
                                
                                    <a href="AAAI2016.html">16</a>
                                
                                    <a href="AAAI2017.html">17</a>
                                
                                    <a href="AAAI2018.html">18</a>
                                
                                    <a href="AAAI2019.html">19</a>
                                
                                    <a href="AAAI2020.html">20</a>
                                
                                    <a href="AAAI2021.html">21</a>
                                
                                    <a href="AAAI2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>UAI</a>
                            </dt>
                            <dd>
                                
                                    <a href="UAI2019.html">19</a>
                                
                                    <a href="UAI2020.html">20</a>
                                
                                    <a href="UAI2021.html">21</a>
                                
                                    <a href="UAI2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>AISTATS</a>
                            </dt>
                            <dd>
                                
                                    <a href="AISTATS2016.html">16</a>
                                
                                    <a href="AISTATS2017.html">17</a>
                                
                                    <a href="AISTATS2018.html">18</a>
                                
                                    <a href="AISTATS2019.html">19</a>
                                
                                    <a href="AISTATS2020.html">20</a>
                                
                                    <a href="AISTATS2021.html">21</a>
                                
                                    <a href="AISTATS2022.html">22</a>
                                
                            </dd>
                        
                    </dl>
                </div>

            

                <div class="col">
                    <dl>
                        
                            <dt>
                                <a>TACL</a>
                            </dt>
                            <dd>
                                
                                    <a href="TACL2016.html">16</a>
                                
                                    <a href="TACL2017.html">17</a>
                                
                                    <a href="TACL2018.html">18</a>
                                
                                    <a href="TACL2019.html">19</a>
                                
                                    <a href="TACL2020.html">20</a>
                                
                                    <a href="TACL2021.html">21</a>
                                
                                    <a href="TACL2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ACL</a>
                            </dt>
                            <dd>
                                
                                    <a href="ACL2016.html">16</a>
                                
                                    <a href="ACL2017.html">17</a>
                                
                                    <a href="ACL2018.html">18</a>
                                
                                    <a href="ACL2019.html">19</a>
                                
                                    <a href="ACL2020.html">20</a>
                                
                                    <a href="ACL2021.html">21</a>
                                
                                    <a href="ACL2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>EMNLP</a>
                            </dt>
                            <dd>
                                
                                    <a href="EMNLP2016.html">16</a>
                                
                                    <a href="EMNLP2017.html">17</a>
                                
                                    <a href="EMNLP2018.html">18</a>
                                
                                    <a href="EMNLP2019.html">19</a>
                                
                                    <a href="EMNLP2020.html">20</a>
                                
                                    <a href="EMNLP2021.html">21</a>
                                
                                    <a href="EMNLP2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>NAACL</a>
                            </dt>
                            <dd>
                                
                                    <a href="NAACL2016.html">16</a>
                                
                                    <a href="NAACL2018.html">18</a>
                                
                                    <a href="NAACL2019.html">19</a>
                                
                                    <a href="NAACL2021.html">21</a>
                                
                                    <a href="NAACL2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>COLING</a>
                            </dt>
                            <dd>
                                
                                    <a href="COLING2016.html">16</a>
                                
                                    <a href="COLING2018.html">18</a>
                                
                                    <a href="COLING2020.html">20</a>
                                
                                    <a href="COLING2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>EACL</a>
                            </dt>
                            <dd>
                                
                                    <a href="EACL2017.html">17</a>
                                
                                    <a href="EACL2021.html">21</a>
                                
                            </dd>
                        
                            <dt>
                                <a>AACL</a>
                            </dt>
                            <dd>
                                
                                    <a href="AACL2020.html">20</a>
                                
                                    <a href="AACL2022.html">22</a>
                                
                            </dd>
                        
                    </dl>
                </div>

            

                <div class="col">
                    <dl>
                        
                            <dt>
                                <a>CVPR</a>
                            </dt>
                            <dd>
                                
                                    <a href="CVPR2016.html">16</a>
                                
                                    <a href="CVPR2017.html">17</a>
                                
                                    <a href="CVPR2018.html">18</a>
                                
                                    <a href="CVPR2019.html">19</a>
                                
                                    <a href="CVPR2020.html">20</a>
                                
                                    <a href="CVPR2021.html">21</a>
                                
                                    <a href="CVPR2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ICCV</a>
                            </dt>
                            <dd>
                                
                                    <a href="ICCV2017.html">17</a>
                                
                                    <a href="ICCV2019.html">19</a>
                                
                                    <a href="ICCV2021.html">21</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ECCV</a>
                            </dt>
                            <dd>
                                
                                    <a href="ECCV2018.html">18</a>
                                
                                    <a href="ECCV2020.html">20</a>
                                
                                    <a href="ECCV2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>ACCV</a>
                            </dt>
                            <dd>
                                
                                    <a href="ACCV2020.html">20</a>
                                
                                    <a href="ACCV2022.html">22</a>
                                
                            </dd>
                        
                            <dt>
                                <a>WACV</a>
                            </dt>
                            <dd>
                                
                                    <a href="WACV2020.html">20</a>
                                
                                    <a href="WACV2021.html">21</a>
                                
                                    <a href="WACV2022.html">22</a>
                                
                                    <a href="WACV2023.html">23</a>
                                
                            </dd>
                        
                    </dl>
                </div>

            
        </div>
    </section>


    <section class="container">
        <h2>2177 Papers (0 missing)</h2>

        
            <div class="row progress">
                <div class="progress-bar progress-bar-striped progress-bar-animated" role="progressbar"
                     aria-valuenow="70.55581074873679" aria-valuemin="0" aria-valuemax="100"
                     style="width: 70.55581074873679%"></div>
            </div>
        

        <div class="row">
            <table class="table table-hover">
                <thead>
                <tr>
                    <th scope="col" class="align-middle text-right">Citations</th>
                    <th scope="col" class="align-middle text-center">Volume</th>
                    <th scope="col" class="align-middle text-left">Title</th>
                </tr>
                </thead>
                <tbody>
                
                    <tr id="0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e23d2f14e7e56e81538f4a63e11689d8ac1eb9d">1574</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Exploring_Simple_Siamese_Representation_Learning_CVPR_2021_paper.html">Exploring Simple Siamese Representation Learning</a></th>
                    </tr>
                
                    <tr id="d29430adccb805ab57b349afa8553954347b3197">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d29430adccb805ab57b349afa8553954347b3197">816</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Rethinking_Semantic_Segmentation_From_a_Sequence-to-Sequence_Perspective_With_Transformers_CVPR_2021_paper.html">Rethinking Semantic Segmentation from a Sequence-to-Sequence Perspective with Transformers</a></th>
                    </tr>
                
                    <tr id="43cb4886a8056d5005702edbc51be327542b2124">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/43cb4886a8056d5005702edbc51be327542b2124">581</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Pre-Trained_Image_Processing_Transformer_CVPR_2021_paper.html">Pre-Trained Image Processing Transformer</a></th>
                    </tr>
                
                    <tr id="47f7ec3d0a5e6e83b6768ece35206a94dc81919c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47f7ec3d0a5e6e83b6768ece35206a94dc81919c">567</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Esser_Taming_Transformers_for_High-Resolution_Image_Synthesis_CVPR_2021_paper.html">Taming Transformers for High-Resolution Image Synthesis</a></th>
                    </tr>
                
                    <tr id="70cf7c785952375e8061c92235aa20e94b02ecd4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70cf7c785952375e8061c92235aa20e94b02ecd4">535</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Coordinate_Attention_for_Efficient_Mobile_Network_Design_CVPR_2021_paper.html">Coordinate Attention for Efficient Mobile Network Design</a></th>
                    </tr>
                
                    <tr id="45557cc70cd6989ab6b03e5aeb787e34299099f7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/45557cc70cd6989ab6b03e5aeb787e34299099f7">484</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hendrycks_Natural_Adversarial_Examples_CVPR_2021_paper.html">Natural Adversarial Examples</a></th>
                    </tr>
                
                    <tr id="4cc32db67ff82cf1aa160631c35bb315c5add749">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4cc32db67ff82cf1aa160631c35bb315c5add749">484</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Richardson_Encoding_in_Style_A_StyleGAN_Encoder_for_Image-to-Image_Translation_CVPR_2021_paper.html">Encoding in Style: A StyleGAN Encoder for Image-to-Image Translation</a></th>
                    </tr>
                
                    <tr id="691eddbfaebbc71f6a12d3c99d5c155042459434">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/691eddbfaebbc71f6a12d3c99d5c155042459434">461</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Martin-Brualla_NeRF_in_the_Wild_Neural_Radiance_Fields_for_Unconstrained_Photo_CVPR_2021_paper.html">NeRF in the Wild: Neural Radiance Fields for Unconstrained Photo Collections</a></th>
                    </tr>
                
                    <tr id="4365f51fc270c55005adb794002685078a6fca1d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4365f51fc270c55005adb794002685078a6fca1d">453</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_pixelNeRF_Neural_Radiance_Fields_From_One_or_Few_Images_CVPR_2021_paper.html">pixelNeRF: Neural Radiance Fields From One or Few Images</a></th>
                    </tr>
                
                    <tr id="16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16f2d2f2b8103ed0c4a4e6f339a21247e58c5e78">426</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Srinivas_Bottleneck_Transformers_for_Visual_Recognition_CVPR_2021_paper.html">Bottleneck Transformers for Visual Recognition</a></th>
                    </tr>
                
                    <tr id="126d36f17cae3e5210a6f62e5c6a23ddec0ef350">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/126d36f17cae3e5210a6f62e5c6a23ddec0ef350">426</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Scaled-YOLOv4_Scaling_Cross_Stage_Partial_Network_CVPR_2021_paper.html">Scaled-YOLOv4: Scaling Cross Stage Partial Network</a></th>
                    </tr>
                
                    <tr id="92d50602db5746f03b91562e2cc8a98bec584e9b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/92d50602db5746f03b91562e2cc8a98bec584e9b">396</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zamir_Multi-Stage_Progressive_Image_Restoration_CVPR_2021_paper.html">Multi-Stage Progressive Image Restoration</a></th>
                    </tr>
                
                    <tr id="694bdf6e5906992dad2987a3cc8d1a176de691c9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/694bdf6e5906992dad2987a3cc8d1a176de691c9">375</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pumarola_D-NeRF_Neural_Radiance_Fields_for_Dynamic_Scenes_CVPR_2021_paper.html">D-NeRF: Neural Radiance Fields for Dynamic Scenes</a></th>
                    </tr>
                
                    <tr id="69a1d72bac9dfb18940ff97ae91643d6c8158e6d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/69a1d72bac9dfb18940ff97ae91643d6c8158e6d">359</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Niemeyer_GIRAFFE_Representing_Scenes_As_Compositional_Generative_Neural_Feature_Fields_CVPR_2021_paper.html">GIRAFFE: Representing Scenes As Compositional Generative Neural Feature Fields</a></th>
                    </tr>
                
                    <tr id="2ac7999cce9f415ee87643f56631b55ed26aa10e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ac7999cce9f415ee87643f56631b55ed26aa10e">359</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_End-to-End_Video_Instance_Segmentation_With_Transformers_CVPR_2021_paper.html">End-to-End Video Instance Segmentation With Transformers</a></th>
                    </tr>
                
                    <tr id="914a593b7f2e980470075a9955f1407641669a8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/914a593b7f2e980470075a9955f1407641669a8f">358</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ghiasi_Simple_Copy-Paste_Is_a_Strong_Data_Augmentation_Method_for_Instance_CVPR_2021_paper.html">Simple Copy-Paste Is a Strong Data Augmentation Method for Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="63c74d15940af1af9b386b5762e4445e54c73719">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/63c74d15940af1af9b386b5762e4445e54c73719">351</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_VinVL_Revisiting_Visual_Representations_in_Vision-Language_Models_CVPR_2021_paper.html">VinVL: Revisiting Visual Representations in Vision-Language Models</a></th>
                    </tr>
                
                    <tr id="6d5f423164cd5ef9324281652987c8a65009e98e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6d5f423164cd5ef9324281652987c8a65009e98e">343</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Sparse_R-CNN_End-to-End_Object_Detection_With_Learnable_Proposals_CVPR_2021_paper.html">Sparse R-CNN: End-to-End Object Detection With Learnable Proposals</a></th>
                    </tr>
                
                    <tr id="2b8088253e2378fce001a090fe923b81e8dedf25">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b8088253e2378fce001a090fe923b81e8dedf25">328</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ding_RepVGG_Making_VGG-Style_ConvNets_Great_Again_CVPR_2021_paper.html">RepVGG: Making VGG-Style ConvNets Great Again</a></th>
                    </tr>
                
                    <tr id="44e6a301714a17b05908da426411b43fa3ebedf0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/44e6a301714a17b05908da426411b43fa3ebedf0">324</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chan_Pi-GAN_Periodic_Implicit_Generative_Adversarial_Networks_for_3D-Aware_Image_Synthesis_CVPR_2021_paper.html">Pi-GAN: Periodic Implicit Generative Adversarial Networks for 3D-Aware Image Synthesis</a></th>
                    </tr>
                
                    <tr id="43497fe8aa7c730e075b08facc2aa560a6d4dd85">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/43497fe8aa7c730e075b08facc2aa560a6d4dd85">324</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pham_Meta_Pseudo_Labels_CVPR_2021_paper.html">Meta Pseudo Labels</a></th>
                    </tr>
                
                    <tr id="22d40963e633e1b4af4a9fefda68e1b8dc96ba63">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/22d40963e633e1b4af4a9fefda68e1b8dc96ba63">322</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Center-Based_3D_Object_Detection_and_Tracking_CVPR_2021_paper.html">Center-Based 3D Object Detection and Tracking</a></th>
                    </tr>
                
                    <tr id="4c1ebb3cbd6d218cda8a7f2844ffada6eed41efc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c1ebb3cbd6d218cda8a7f2844ffada6eed41efc">314</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qiao_DetectoRS_Detecting_Objects_With_Recursive_Feature_Pyramid_and_Switchable_Atrous_CVPR_2021_paper.html">DetectoRS: Detecting Objects With Recursive Feature Pyramid and Switchable Atrous Convolution</a></th>
                    </tr>
                
                    <tr id="dc0092d06ab76465431edfd51b08d823b7d1ff3f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dc0092d06ab76465431edfd51b08d823b7d1ff3f">311</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Closed-Form_Factorization_of_Latent_Semantics_in_GANs_CVPR_2021_paper.html">Closed-Form Factorization of Latent Semantics in GANs</a></th>
                    </tr>
                
                    <tr id="6f92dcefc5f6b4346f619ae7546a8bd2d6decade">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6f92dcefc5f6b4346f619ae7546a8bd2d6decade">295</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Dense_Contrastive_Learning_for_Self-Supervised_Visual_Pre-Training_CVPR_2021_paper.html">Dense Contrastive Learning for Self-Supervised Visual Pre-Training</a></th>
                    </tr>
                
                    <tr id="13034a395d5c6728c9b11e777828d9998018cbf6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/13034a395d5c6728c9b11e777828d9998018cbf6">278</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Neural_Scene_Flow_Fields_for_Space-Time_View_Synthesis_of_Dynamic_CVPR_2021_paper.html">Neural Scene Flow Fields for Space-Time View Synthesis of Dynamic Scenes</a></th>
                    </tr>
                
                    <tr id="9717f7d873859ca0080caf944f7a2d9b456be121">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9717f7d873859ca0080caf944f7a2d9b456be121">253</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bhat_AdaBins_Depth_Estimation_Using_Adaptive_Bins_CVPR_2021_paper.html">AdaBins: Depth Estimation Using Adaptive Bins</a></th>
                    </tr>
                
                    <tr id="7c3ce1b3ad598a282546e03e2dc8b52c338caed6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c3ce1b3ad598a282546e03e2dc8b52c338caed6">251</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Transformer_Tracking_CVPR_2021_paper.html">Transformer Tracking</a></th>
                    </tr>
                
                    <tr id="787119e3c3f819244c82b7d97779473773e60696">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/787119e3c3f819244c82b7d97779473773e60696">250</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_MaX-DeepLab_End-to-End_Panoptic_Segmentation_With_Mask_Transformers_CVPR_2021_paper.html">MaX-DeepLab: End-to-End Panoptic Segmentation With Mask Transformers</a></th>
                    </tr>
                
                    <tr id="ba4a4d31d2af23eefadbf19e5efd5a7d4fd89143">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ba4a4d31d2af23eefadbf19e5efd5a7d4fd89143">249</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lei_Less_Is_More_ClipBERT_for_Video-and-Language_Learning_via_Sparse_Sampling_CVPR_2021_paper.html">Less Is More: ClipBERT for Video-and-Language Learning via Sparse Sampling</a></th>
                    </tr>
                
                    <tr id="1f3a9a431dc5bf813455ac89df5c0a4e747bc553">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1f3a9a431dc5bf813455ac89df5c0a4e747bc553">246</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qian_Spatiotemporal_Contrastive_Video_Representation_Learning_CVPR_2021_paper.html">Spatiotemporal Contrastive Video Representation Learning</a></th>
                    </tr>
                
                    <tr id="95d85fec8a2e9ac024b08c7d34c5f9de41f02b26">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/95d85fec8a2e9ac024b08c7d34c5f9de41f02b26">239</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dai_UP-DETR_Unsupervised_Pre-Training_for_Object_Detection_With_Transformers_CVPR_2021_paper.html">UP-DETR: Unsupervised Pre-Training for Object Detection With Transformers</a></th>
                    </tr>
                
                    <tr id="394be105b87e9bfe72c20efe6338de10604e1a11">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/394be105b87e9bfe72c20efe6338de10604e1a11">236</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Changpinyo_Conceptual_12M_Pushing_Web-Scale_Image-Text_Pre-Training_To_Recognize_Long-Tail_Visual_CVPR_2021_paper.html">Conceptual 12M: Pushing Web-Scale Image-Text Pre-Training To Recognize Long-Tail Visual Concepts</a></th>
                    </tr>
                
                    <tr id="af8faec7c0b8f4b2a28d42a86e0e7d499016c560">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/af8faec7c0b8f4b2a28d42a86e0e7d499016c560">233</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Peng_Neural_Body_Implicit_Neural_Representations_With_Structured_Latent_Codes_for_CVPR_2021_paper.html">Neural Body: Implicit Neural Representations With Structured Latent Codes for Novel View Synthesis of Dynamic Humans</a></th>
                    </tr>
                
                    <tr id="ecb34053270d0a1667f95dab682cce650871ab69">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ecb34053270d0a1667f95dab682cce650871ab69">226</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_StyleSpace_Analysis_Disentangled_Controls_for_StyleGAN_Image_Generation_CVPR_2021_paper.html">StyleSpace Analysis: Disentangled Controls for StyleGAN Image Generation</a></th>
                    </tr>
                
                    <tr id="6102a12b22ec3e44f9bbdae76185ca6e8a358f83">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6102a12b22ec3e44f9bbdae76185ca6e8a358f83">224</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_End-to-End_Human_Pose_and_Mesh_Reconstruction_with_Transformers_CVPR_2021_paper.html">End-to-End Human Pose and Mesh Reconstruction with Transformers</a></th>
                    </tr>
                
                    <tr id="74978168a087df56b67966aa57ead81fd79afe91">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/74978168a087df56b67966aa57ead81fd79afe91">219</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Propagate_Yourself_Exploring_Pixel-Level_Consistency_for_Unsupervised_Visual_Representation_Learning_CVPR_2021_paper.html">Propagate Yourself: Exploring Pixel-Level Consistency for Unsupervised Visual Representation Learning</a></th>
                    </tr>
                
                    <tr id="4b266567253da27b2cbdb6bb7e450565032a35ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4b266567253da27b2cbdb6bb7e450565032a35ab">217</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Srinivasan_NeRV_Neural_Reflectance_and_Visibility_Fields_for_Relighting_and_View_CVPR_2021_paper.html">NeRV: Neural Reflectance and Visibility Fields for Relighting and View Synthesis</a></th>
                    </tr>
                
                    <tr id="3e86f5a0e2a97894de1cf1f1587799ac79bad0f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3e86f5a0e2a97894de1cf1f1587799ac79bad0f2">212</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Desai_VirTex_Learning_Visual_Representations_From_Textual_Annotations_CVPR_2021_paper.html">VirTex: Learning Visual Representations From Textual Annotations</a></th>
                    </tr>
                
                    <tr id="b91de7d12ec1103f6ef9eb0720d697a9e7ecc9fe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b91de7d12ec1103f6ef9eb0720d697a9e7ecc9fe">208</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_LoFTR_Detector-Free_Local_Feature_Matching_With_Transformers_CVPR_2021_paper.html">LoFTR: Detector-Free Local Feature Matching With Transformers</a></th>
                    </tr>
                
                    <tr id="57eaad10369de402d3363c1d99c93810463eb03c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/57eaad10369de402d3363c1d99c93810463eb03c">190</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Understanding_the_Behaviour_of_Contrastive_Loss_CVPR_2021_paper.html">Understanding the Behaviour of Contrastive Loss</a></th>
                    </tr>
                
                    <tr id="414da5e0716eb4707e033b7967d7671dfe71ab71">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/414da5e0716eb4707e033b7967d7671dfe71ab71">190</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xian_Space-Time_Neural_Irradiance_Fields_for_Free-Viewpoint_Video_CVPR_2021_paper.html">Space-Time Neural Irradiance Fields for Free-Viewpoint Video</a></th>
                    </tr>
                
                    <tr id="0acd7ff5817d29839b40197f7a4b600b7fba24e4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0acd7ff5817d29839b40197f7a4b600b7fba24e4">188</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chefer_Transformer_Interpretability_Beyond_Attention_Visualization_CVPR_2021_paper.html">Transformer Interpretability Beyond Attention Visualization</a></th>
                    </tr>
                
                    <tr id="767a6054796e2e6c1de453afab0e05e55aadf825">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/767a6054796e2e6c1de453afab0e05e55aadf825">188</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_Continuous_Image_Representation_With_Local_Implicit_Image_Function_CVPR_2021_paper.html">Learning Continuous Image Representation With Local Implicit Image Function</a></th>
                    </tr>
                
                    <tr id="07fdff9dae9ea9ba32c251669b3b7a66269930f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/07fdff9dae9ea9ba32c251669b3b7a66269930f9">187</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Semi-Supervised_Semantic_Segmentation_With_Cross_Pseudo_Supervision_CVPR_2021_paper.html">Semi-Supervised Semantic Segmentation With Cross Pseudo Supervision</a></th>
                    </tr>
                
                    <tr id="6ca0a80111fed68b8a5b7eac5ecdc3d258f0fea6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6ca0a80111fed68b8a5b7eac5ecdc3d258f0fea6">186</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Takikawa_Neural_Geometric_Level_of_Detail_Real-Time_Rendering_With_Implicit_3D_CVPR_2021_paper.html">Neural Geometric Level of Detail: Real-Time Rendering With Implicit 3D Shapes</a></th>
                    </tr>
                
                    <tr id="7cbc3dd0280b8c4551ac934af42dc227d43754f7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7cbc3dd0280b8c4551ac934af42dc227d43754f7">184</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_IBRNet_Learning_Multi-View_Image-Based_Rendering_CVPR_2021_paper.html">IBRNet: Learning Multi-View Image-Based Rendering</a></th>
                    </tr>
                
                    <tr id="ceb9959528a96718f1e82660dc8b28b3bdde9cde">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ceb9959528a96718f1e82660dc8b28b3bdde9cde">179</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_You_Only_Look_One-Level_Feature_CVPR_2021_paper.html">You Only Look One-Level Feature</a></th>
                    </tr>
                
                    <tr id="91e8117e7ebc966bc76de2cb52ec717d2acdb1a4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/91e8117e7ebc966bc76de2cb52ec717d2acdb1a4">178</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Vaswani_Scaling_Local_Self-Attention_for_Parameter_Efficient_Visual_Backbones_CVPR_2021_paper.html">Scaling Local Self-Attention for Parameter Efficient Visual Backbones</a></th>
                    </tr>
                
                    <tr id="78d80c343d36baaf89f18e12d325cf6309fb6c8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/78d80c343d36baaf89f18e12d325cf6309fb6c8f">177</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_CutPaste_Self-Supervised_Learning_for_Anomaly_Detection_and_Localization_CVPR_2021_paper.html">CutPaste: Self-Supervised Learning for Anomaly Detection and Localization</a></th>
                    </tr>
                
                    <tr id="890398bb6364141f8b4a798fbc1c1605a871bd1d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/890398bb6364141f8b4a798fbc1c1605a871bd1d">173</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gafni_Dynamic_Neural_Radiance_Fields_for_Monocular_4D_Facial_Avatar_Reconstruction_CVPR_2021_paper.html">Dynamic Neural Radiance Fields for Monocular 4D Facial Avatar Reconstruction</a></th>
                    </tr>
                
                    <tr id="14c3510e4f4b370d5cd0420037406024533f4b6f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/14c3510e4f4b370d5cd0420037406024533f4b6f">170</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_VarifocalNet_An_IoU-Aware_Dense_Object_Detector_CVPR_2021_paper.html">VarifocalNet: An IoU-Aware Dense Object Detector</a></th>
                    </tr>
                
                    <tr id="3e3f55cb25b919c4e8158195fd3ce2f23cfa7723">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3e3f55cb25b919c4e8158195fd3ce2f23cfa7723">169</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Niu_Counterfactual_VQA_A_Cause-Effect_Look_at_Language_Bias_CVPR_2021_paper.html">Counterfactual VQA: A Cause-Effect Look at Language Bias</a></th>
                    </tr>
                
                    <tr id="48764f8f64986cf690ce0f1040b2e6bbf06fd23c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/48764f8f64986cf690ce0f1040b2e6bbf06fd23c">164</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Prototypical_Pseudo_Label_Denoising_and_Target_Structure_Learning_for_Domain_CVPR_2021_paper.html">Prototypical Pseudo Label Denoising and Target Structure Learning for Domain Adaptive Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="915bd0363fb1b7d6e6a3a85471a324fde870337b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/915bd0363fb1b7d6e6a3a85471a324fde870337b">159</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Meng_MagFace_A_Universal_Representation_for_Face_Recognition_and_Quality_Assessment_CVPR_2021_paper.html">MagFace: A Universal Representation for Face Recognition and Quality Assessment</a></th>
                    </tr>
                
                    <tr id="748c4f1945b0d994ecef38c8aac01db1c6dc7029">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/748c4f1945b0d994ecef38c8aac01db1c6dc7029">159</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Model-Contrastive_Federated_Learning_CVPR_2021_paper.html">Model-Contrastive Federated Learning</a></th>
                    </tr>
                
                    <tr id="0fd50e1483f761ba2bae44de54c5e8db6e35de5a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0fd50e1483f761ba2bae44de54c5e8db6e35de5a">156</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yin_See_Through_Gradients_Image_Batch_Recovery_via_GradInversion_CVPR_2021_paper.html">See Through Gradients: Image Batch Recovery via GradInversion</a></th>
                    </tr>
                
                    <tr id="bf872d5e3fcf46f44a1b9dd76ee0db9a8cc98e06">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bf872d5e3fcf46f44a1b9dd76ee0db9a8cc98e06">154</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Cylindrical_and_Asymmetrical_3D_Convolution_Networks_for_LiDAR_Segmentation_CVPR_2021_paper.html">Cylindrical and Asymmetrical 3D Convolution Networks for LiDAR Segmentation</a></th>
                    </tr>
                
                    <tr id="bd519be5f86187eb98ab1234b60afe94949bbca5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bd519be5f86187eb98ab1234b60afe94949bbca5">152</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Reading_Categorical_Depth_Distribution_Network_for_Monocular_3D_Object_Detection_CVPR_2021_paper.html">Categorical Depth Distribution Network for Monocular 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="fc5ed765f8a07d265936994a3ef2b2ac441e7283">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc5ed765f8a07d265936994a3ef2b2ac441e7283">151</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Contrastive_Learning_for_Compact_Single_Image_Dehazing_CVPR_2021_paper.html">Contrastive Learning for Compact Single Image Dehazing</a></th>
                    </tr>
                
                    <tr id="c0559fc7e7d6ea0f783ba791ddd5deaa74cf58a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c0559fc7e7d6ea0f783ba791ddd5deaa74cf58a9">151</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Prakash_Multi-Modal_Fusion_Transformer_for_End-to-End_Autonomous_Driving_CVPR_2021_paper.html">Multi-Modal Fusion Transformer for End-to-End Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="75284d5e4dfe1cd8a9ce69085210319e14fcfa3d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/75284d5e4dfe1cd8a9ce69085210319e14fcfa3d">151</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Transformer_Meets_Tracker_Exploiting_Temporal_Context_for_Robust_Visual_Tracking_CVPR_2021_paper.html">Transformer Meets Tracker: Exploiting Temporal Context for Robust Visual Tracking</a></th>
                    </tr>
                
                    <tr id="169983a72aced7faac5536de2a0b12b7975e2dd0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/169983a72aced7faac5536de2a0b12b7975e2dd0">147</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Joseph_Towards_Open_World_Object_Detection_CVPR_2021_paper.html">Towards Open World Object Detection</a></th>
                    </tr>
                
                    <tr id="85089ce8830e9fcd24ee6b157c22bfa34d7d828a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/85089ce8830e9fcd24ee6b157c22bfa34d7d828a">143</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_One-Shot_Free-View_Neural_Talking-Head_Synthesis_for_Video_Conferencing_CVPR_2021_paper.html">One-Shot Free-View Neural Talking-Head Synthesis for Video Conferencing</a></th>
                    </tr>
                
                    <tr id="652032fbb744da4f279e8f30eef2323155878ac4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/652032fbb744da4f279e8f30eef2323155878ac4">143</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Cross-Modal_Contrastive_Learning_for_Text-to-Image_Generation_CVPR_2021_paper.html">Cross-Modal Contrastive Learning for Text-to-Image Generation</a></th>
                    </tr>
                
                    <tr id="2ad2981a53393dc5987419a22cbe1ee3d7fa6e42">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ad2981a53393dc5987419a22cbe1ee3d7fa6e42">140</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_TDN_Temporal_Difference_Networks_for_Efficient_Action_Recognition_CVPR_2021_paper.html">TDN: Temporal Difference Networks for Efficient Action Recognition</a></th>
                    </tr>
                
                    <tr id="4f9a4afc0ba500d839f7ee245513af9b87add8be">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f9a4afc0ba500d839f7ee245513af9b87add8be">140</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Morgado_Audio-Visual_Instance_Discrimination_with_Cross-Modal_Agreement_CVPR_2021_paper.html">Audio-Visual Instance Discrimination with Cross-Modal Agreement</a></th>
                    </tr>
                
                    <tr id="c32fd8ea1b3f2df410410fb18d569dede102c53a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c32fd8ea1b3f2df410410fb18d569dede102c53a">139</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Diffusion_Probabilistic_Models_for_3D_Point_Cloud_Generation_CVPR_2021_paper.html">Diffusion Probabilistic Models for 3D Point Cloud Generation</a></th>
                    </tr>
                
                    <tr id="084576d2b607dfe3796b2fd5db2de9eb541e9aa9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/084576d2b607dfe3796b2fd5db2de9eb541e9aa9">135</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chan_BasicVSR_The_Search_for_Essential_Components_in_Video_Super-Resolution_and_CVPR_2021_paper.html">BasicVSR: The Search for Essential Components in Video Super-Resolution and Beyond</a></th>
                    </tr>
                
                    <tr id="16ecba2d6e6907dce95560e5d3448d8bc7559b39">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16ecba2d6e6907dce95560e5d3448d8bc7559b39">135</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pan_3D_Object_Detection_With_Pointformer_CVPR_2021_paper.html">3D Object Detection With Pointformer</a></th>
                    </tr>
                
                    <tr id="720ecbc16f94add77579b38d7276a279782df17d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/720ecbc16f94add77579b38d7276a279782df17d">134</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Dual-Stream_Multiple_Instance_Learning_Network_for_Whole_Slide_Image_Classification_CVPR_2021_paper.html">Dual-Stream Multiple Instance Learning Network for Whole Slide Image Classification With Self-Supervised Contrastive Learning</a></th>
                    </tr>
                
                    <tr id="00969b4dcf8f9b21895bd038a51a038018da84f0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00969b4dcf8f9b21895bd038a51a038018da84f0">134</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ericsson_How_Well_Do_Self-Supervised_Models_Transfer_CVPR_2021_paper.html">How Well Do Self-Supervised Models Transfer?</a></th>
                    </tr>
                
                    <tr id="3cf833c45a6d56896a0487d332099e1646a16472">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3cf833c45a6d56896a0487d332099e1646a16472">132</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_PAConv_Position_Adaptive_Convolution_With_Dynamic_Kernel_Assembling_on_Point_CVPR_2021_paper.html">PAConv: Position Adaptive Convolution With Dynamic Kernel Assembling on Point Clouds</a></th>
                    </tr>
                
                    <tr id="0fdb3478b2db17de56ff9c7d338e95559a4caf12">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0fdb3478b2db17de56ff9c7d338e95559a4caf12">131</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Han_ReDet_A_Rotation-Equivariant_Detector_for_Aerial_Object_Detection_CVPR_2021_paper.html">ReDet: A Rotation-Equivariant Detector for Aerial Object Detection</a></th>
                    </tr>
                
                    <tr id="1ee1160b8c7c70ded02e786c184a6da651e88bed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ee1160b8c7c70ded02e786c184a6da651e88bed">130</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dai_Dynamic_Head_Unifying_Object_Detection_Heads_With_Attentions_CVPR_2021_paper.html">Dynamic Head: Unifying Object Detection Heads With Attentions</a></th>
                    </tr>
                
                    <tr id="4fc6e9545d30539fac6a6a0dcac1418ad4dd9a9f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4fc6e9545d30539fac6a6a0dcac1418ad4dd9a9f">129</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lindell_AutoInt_Automatic_Integration_for_Fast_Neural_Volume_Rendering_CVPR_2021_paper.html">AutoInt: Automatic Integration for Fast Neural Volume Rendering</a></th>
                    </tr>
                
                    <tr id="06d0515d11386bb1572187f81af5abda655c941e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/06d0515d11386bb1572187f81af5abda655c941e">128</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Predator_Registration_of_3D_Point_Clouds_With_Low_Overlap_CVPR_2021_paper.html">Predator: Registration of 3D Point Clouds With Low Overlap</a></th>
                    </tr>
                
                    <tr id="0283d3ace44c0deeb9c56039989eeb072c54f825">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0283d3ace44c0deeb9c56039989eeb072c54f825">128</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wizadwongsa_NeX_Real-Time_View_Synthesis_With_Neural_Basis_Expansion_CVPR_2021_paper.html">NeX: Real-Time View Synthesis With Neural Basis Expansion</a></th>
                    </tr>
                
                    <tr id="463e5c147fe2ab987925768c4b6b00de9d000d30">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/463e5c147fe2ab987925768c4b6b00de9d000d30">128</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tancik_Learned_Initializations_for_Optimizing_Coordinate-Based_Neural_Representations_CVPR_2021_paper.html">Learned Initializations for Optimizing Coordinate-Based Neural Representations</a></th>
                    </tr>
                
                    <tr id="54483c5672bbee68cb77969d9cf6681209230b95">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/54483c5672bbee68cb77969d9cf6681209230b95">128</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Towards_Real-World_Blind_Face_Restoration_With_Generative_Facial_Prior_CVPR_2021_paper.html">Towards Real-World Blind Face Restoration With Generative Facial Prior</a></th>
                    </tr>
                
                    <tr id="2fa4938001b18f464c62aa38a5a469bb92569d57">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2fa4938001b18f464c62aa38a5a469bb92569d57">128</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Seeing_Out_of_the_Box_End-to-End_Pre-Training_for_Vision-Language_Representation_CVPR_2021_paper.html">Seeing Out of the Box: End-to-End Pre-Training for Vision-Language Representation Learning</a></th>
                    </tr>
                
                    <tr id="b13cbe9f3dca05eead110d59ce51087f3b7e1d24">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b13cbe9f3dca05eead110d59ce51087f3b7e1d24">127</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xia_TediGAN_Text-Guided_Diverse_Face_Image_Generation_and_Manipulation_CVPR_2021_paper.html">TediGAN: Text-Guided Diverse Face Image Generation and Manipulation</a></th>
                    </tr>
                
                    <tr id="4f09843e22a085af935f0a31329e90cb1d5441ee">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f09843e22a085af935f0a31329e90cb1d5441ee">124</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Multi-Attentional_Deepfake_Detection_CVPR_2021_paper.html">Multi-Attentional Deepfake Detection</a></th>
                    </tr>
                
                    <tr id="6ed5a7fb19d0fae0b7c8b47b007db194e43c2592">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6ed5a7fb19d0fae0b7c8b47b007db194e43c2592">123</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Feichtenhofer_A_Large-Scale_Study_on_Unsupervised_Spatiotemporal_Representation_Learning_CVPR_2021_paper.html">A Large-Scale Study on Unsupervised Spatiotemporal Representation Learning</a></th>
                    </tr>
                
                    <tr id="e51b5153df01ed6b634cfc6180661cba5c84e62b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e51b5153df01ed6b634cfc6180661cba5c84e62b">121</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Rethinking_BiSeNet_for_Real-Time_Semantic_Segmentation_CVPR_2021_paper.html">Rethinking BiSeNet for Real-Time Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="3bc6e930f0114202f668d35cd733c29f6dca7ebb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3bc6e930f0114202f668d35cd733c29f6dca7ebb">115</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ge_OTA_Optimal_Transport_Assignment_for_Object_Detection_CVPR_2021_paper.html">OTA: Optimal Transport Assignment for Object Detection</a></th>
                    </tr>
                
                    <tr id="9833833941dd64af2314ab81f49ccc725f7d2a0b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9833833941dd64af2314ab81f49ccc725f7d2a0b">114</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_FSCE_Few-Shot_Object_Detection_via_Contrastive_Proposal_Encoding_CVPR_2021_paper.html">FSCE: Few-Shot Object Detection via Contrastive Proposal Encoding</a></th>
                    </tr>
                
                    <tr id="0b39ba4486be10319c250760cde4644160b4b30f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0b39ba4486be10319c250760cde4644160b4b30f">112</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_SE-SSD_Self-Ensembling_Single-Stage_Object_Detector_From_Point_Cloud_CVPR_2021_paper.html">SE-SSD: Self-Ensembling Single-Stage Object Detector From Point Cloud</a></th>
                    </tr>
                
                    <tr id="827455225f598f5444b8025073cefeb9bb3d4a85">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/827455225f598f5444b8025073cefeb9bb3d4a85">110</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Track_To_Detect_and_Segment_An_Online_Multi-Object_Tracker_CVPR_2021_paper.html">Track To Detect and Segment: An Online Multi-Object Tracker</a></th>
                    </tr>
                
                    <tr id="786cb74290340443e9d02ffd9669f5e2a18878b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/786cb74290340443e9d02ffd9669f5e2a18878b5">108</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_DatasetGAN_Efficient_Labeled_Data_Factory_With_Minimal_Human_Effort_CVPR_2021_paper.html">DatasetGAN: Efficient Labeled Data Factory With Minimal Human Effort</a></th>
                    </tr>
                
                    <tr id="4a3bb2a12261007eca393fbf4d2f97663c99f4c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4a3bb2a12261007eca393fbf4d2f97663c99f4c0">107</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Involution_Inverting_the_Inherence_of_Convolution_for_Visual_Recognition_CVPR_2021_paper.html">Involution: Inverting the Inherence of Convolution for Visual Recognition</a></th>
                    </tr>
                
                    <tr id="e92817cc3eed1ec0e1a17db88bb7da9ae78dec72">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e92817cc3eed1ec0e1a17db88bb7da9ae78dec72">107</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Unsupervised_Degradation_Representation_Learning_for_Blind_Super-Resolution_CVPR_2021_paper.html">Unsupervised Degradation Representation Learning for Blind Super-Resolution</a></th>
                    </tr>
                
                    <tr id="a1269062dd119704390a9148b839e06935711d85">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a1269062dd119704390a9148b839e06935711d85">106</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Riegler_Stable_View_Synthesis_CVPR_2021_paper.html">Stable View Synthesis</a></th>
                    </tr>
                
                    <tr id="94001e6bdf94fd61be3fba6ab9e6e77fbd888867">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/94001e6bdf94fd61be3fba6ab9e6e77fbd888867">106</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nam_Reducing_Domain_Gap_by_Reducing_Style_Bias_CVPR_2021_paper.html">Reducing Domain Gap by Reducing Style Bias</a></th>
                    </tr>
                
                    <tr id="b903eaeff1955d168e3521bd4e84f1d5c11e18d8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b903eaeff1955d168e3521bd4e84f1d5c11e18d8">105</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yan_DER_Dynamically_Expandable_Representation_for_Class_Incremental_Learning_CVPR_2021_paper.html">DER: Dynamically Expandable Representation for Class Incremental Learning</a></th>
                    </tr>
                
                    <tr id="4586e787deb9ae3230f132d0368a89bb3887af9f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4586e787deb9ae3230f132d0368a89bb3887af9f">104</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pang_Quasi-Dense_Similarity_Learning_for_Multiple_Object_Tracking_CVPR_2021_paper.html">Quasi-Dense Similarity Learning for Multiple Object Tracking</a></th>
                    </tr>
                
                    <tr id="37929e9283d214a1688bd6fa9759cd6e89b2312d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/37929e9283d214a1688bd6fa9759cd6e89b2312d">104</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Graph_Attention_Tracking_CVPR_2021_paper.html">Graph Attention Tracking</a></th>
                    </tr>
                
                    <tr id="42bf65a6eb1cb5fda999373c3ce7d79690133c92">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/42bf65a6eb1cb5fda999373c3ce7d79690133c92">103</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Saito_SCANimate_Weakly_Supervised_Learning_of_Skinned_Clothed_Avatar_Networks_CVPR_2021_paper.html">SCANimate: Weakly Supervised Learning of Skinned Clothed Avatar Networks</a></th>
                    </tr>
                
                    <tr id="cd9a2b4578fbd812fea5d31e5b8e778f13e352c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd9a2b4578fbd812fea5d31e5b8e778f13e352c0">101</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Generalized_Focal_Loss_V2_Learning_Reliable_Localization_Quality_Estimation_for_CVPR_2021_paper.html">Generalized Focal Loss V2: Learning Reliable Localization Quality Estimation for Dense Object Detection</a></th>
                    </tr>
                
                    <tr id="5b27e6d2fa2705730b2af8ad7652b2bfaa0b80a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b27e6d2fa2705730b2af8ad7652b2bfaa0b80a0">101</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_A_Fourier-Based_Framework_for_Domain_Generalization_CVPR_2021_paper.html">A Fourier-Based Framework for Domain Generalization</a></th>
                    </tr>
                
                    <tr id="17f8918095e3586b884549e920b136d552761bd4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/17f8918095e3586b884549e920b136d552761bd4">100</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mei_Image_Super-Resolution_With_Non-Local_Sparse_Attention_CVPR_2021_paper.html">Image Super-Resolution With Non-Local Sparse Attention</a></th>
                    </tr>
                
                    <tr id="c7a2b5cd46c0a3e51b5751dd3902d26aa2b02602">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c7a2b5cd46c0a3e51b5751dd3902d26aa2b02602">99</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hausler_Patch-NetVLAD_Multi-Scale_Fusion_of_Locally-Global_Descriptors_for_Place_Recognition_CVPR_2021_paper.html">Patch-NetVLAD: Multi-Scale Fusion of Locally-Global Descriptors for Place Recognition</a></th>
                    </tr>
                
                    <tr id="604e0c54580a0530392f86b48a6183581a47b66d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/604e0c54580a0530392f86b48a6183581a47b66d">99</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_VLN_BERT_A_Recurrent_Vision-and-Language_BERT_for_Navigation_CVPR_2021_paper.html">VLN BERT: A Recurrent Vision-and-Language BERT for Navigation</a></th>
                    </tr>
                
                    <tr id="22ad3545d78f2acfe7de1b2c38ec72efc9faa0d6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/22ad3545d78f2acfe7de1b2c38ec72efc9faa0d6">99</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Multimodal_Motion_Prediction_With_Stacked_Transformers_CVPR_2021_paper.html">Multimodal Motion Prediction With Stacked Transformers</a></th>
                    </tr>
                
                    <tr id="2236197ab23e5a9a4de37b76b82d61068843b83b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2236197ab23e5a9a4de37b76b82d61068843b83b">96</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Diverse_Part_Discovery_Occluded_Person_Re-Identification_With_Part-Aware_Transformer_CVPR_2021_paper.html">Diverse Part Discovery: Occluded Person Re-Identification With Part-Aware Transformer</a></th>
                    </tr>
                
                    <tr id="73c401e29cb83157bc6dfb33d5ce4364a7d2731b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/73c401e29cb83157bc6dfb33d5ce4364a7d2731b">96</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ojha_Few-Shot_Image_Generation_via_Cross-Domain_Correspondence_CVPR_2021_paper.html">Few-Shot Image Generation via Cross-Domain Correspondence</a></th>
                    </tr>
                
                    <tr id="45187881878cd6c21b944312b77e62cefed46b39">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/45187881878cd6c21b944312b77e62cefed46b39">96</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Spatial-Phase_Shallow_Learning_Rethinking_Face_Forgery_Detection_in_Frequency_Domain_CVPR_2021_paper.html">Spatial-Phase Shallow Learning: Rethinking Face Forgery Detection in Frequency Domain</a></th>
                    </tr>
                
                    <tr id="6a19558fb01ded2ebd4885e9c8d59f29355fcf9a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a19558fb01ded2ebd4885e9c8d59f29355fcf9a">95</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_HOTR_End-to-End_Human-Object_Interaction_Detection_With_Transformers_CVPR_2021_paper.html">HOTR: End-to-End Human-Object Interaction Detection With Transformers</a></th>
                    </tr>
                
                    <tr id="e56a3dc015d18421a7ce35eaa4d5513d953df6c7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e56a3dc015d18421a7ce35eaa4d5513d953df6c7">94</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pan_VideoMoCo_Contrastive_Video_Representation_Learning_With_Temporally_Adversarial_Examples_CVPR_2021_paper.html">VideoMoCo: Contrastive Video Representation Learning With Temporally Adversarial Examples</a></th>
                    </tr>
                
                    <tr id="82c05a83e56fa6ad089ba7d4aad2bec85b9b4edf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/82c05a83e56fa6ad089ba7d4aad2bec85b9b4edf">94</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Rebain_DeRF_Decomposed_Radiance_Fields_CVPR_2021_paper.html">DeRF: Decomposed Radiance Fields</a></th>
                    </tr>
                
                    <tr id="0cbfd6647f906c9cf82ecafdfbbdc2a317af8467">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0cbfd6647f906c9cf82ecafdfbbdc2a317af8467">92</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Adaptive_Prototype_Learning_and_Allocation_for_Few-Shot_Segmentation_CVPR_2021_paper.html">Adaptive Prototype Learning and Allocation for Few-Shot Segmentation</a></th>
                    </tr>
                
                    <tr id="b9ec0bb70a2425493f187ccaf8ea0461e90a7381">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b9ec0bb70a2425493f187ccaf8ea0461e90a7381">92</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_PatchmatchNet_Learned_Multi-View_Patchmatch_Stereo_CVPR_2021_paper.html">PatchmatchNet: Learned Multi-View Patchmatch Stereo</a></th>
                    </tr>
                
                    <tr id="729559024cc246c4bb7b33e395d2957b27662eb4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/729559024cc246c4bb7b33e395d2957b27662eb4">91</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Dense_Label_Encoding_for_Boundary_Discontinuity_Free_Rotation_Detection_CVPR_2021_paper.html">Dense Label Encoding for Boundary Discontinuity Free Rotation Detection</a></th>
                    </tr>
                
                    <tr id="51a33b04933f932c3a1425339c4412be89a2bdb5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/51a33b04933f932c3a1425339c4412be89a2bdb5">90</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Distribution_Alignment_A_Unified_Framework_for_Long-Tail_Visual_Recognition_CVPR_2021_paper.html">Distribution Alignment: A Unified Framework for Long-Tail Visual Recognition</a></th>
                    </tr>
                
                    <tr id="60da51ec04259eafe6866c34304d4ad61385ffd8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/60da51ec04259eafe6866c34304d4ad61385ffd8">89</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_CausalVAE_Disentangled_Representation_Learning_via_Neural_Structural_Causal_Models_CVPR_2021_paper.html">CausalVAE: Disentangled Representation Learning via Neural Structural Causal Models</a></th>
                    </tr>
                
                    <tr id="4306e545978bb653b2c9ac1a6f704428482877b6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4306e545978bb653b2c9ac1a6f704428482877b6">88</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Retinex-Inspired_Unrolling_With_Cooperative_Prior_Architecture_Search_for_Low-Light_Image_CVPR_2021_paper.html">Retinex-Inspired Unrolling With Cooperative Prior Architecture Search for Low-Light Image Enhancement</a></th>
                    </tr>
                
                    <tr id="0593d3da080f886fa020541a1e1c675f4fdd37c6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0593d3da080f886fa020541a1e1c675f4fdd37c6">88</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Djolonga_On_Robustness_and_Transferability_of_Convolutional_Neural_Networks_CVPR_2021_paper.html">On Robustness and Transferability of Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="d6a6d8f56c5db24bfae7c614f21195dc0e89f4a8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d6a6d8f56c5db24bfae7c614f21195dc0e89f4a8">88</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_FedDG_Federated_Domain_Generalization_on_Medical_Image_Segmentation_via_Episodic_CVPR_2021_paper.html">FedDG: Federated Domain Generalization on Medical Image Segmentation via Episodic Learning in Continuous Frequency Space</a></th>
                    </tr>
                
                    <tr id="a633ea2dea6a9bd24942e1f7c0cea4f7a94670df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a633ea2dea6a9bd24942e1f7c0cea4f7a94670df">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Source-Free_Domain_Adaptation_for_Semantic_Segmentation_CVPR_2021_paper.html">Source-Free Domain Adaptation for Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="053b96e162724fa10d8639196a99856d60de5214">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/053b96e162724fa10d8639196a99856d60de5214">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Exploring_Data-Efficient_3D_Scene_Understanding_With_Contrastive_Scene_Contexts_CVPR_2021_paper.html">Exploring Data-Efficient 3D Scene Understanding With Contrastive Scene Contexts</a></th>
                    </tr>
                
                    <tr id="122d8f3209c8c0e2516181efda7fa6c911ebd70b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/122d8f3209c8c0e2516181efda7fa6c911ebd70b">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Pose-Controllable_Talking_Face_Generation_by_Implicitly_Modularized_Audio-Visual_Representation_CVPR_2021_paper.html">Pose-Controllable Talking Face Generation by Implicitly Modularized Audio-Visual Representation</a></th>
                    </tr>
                
                    <tr id="2d918385542213b5fef3fda7542d64509c433495">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d918385542213b5fef3fda7542d64509c433495">87</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Unbiased_Mean_Teacher_for_Cross-Domain_Object_Detection_CVPR_2021_paper.html">Unbiased Mean Teacher for Cross-Domain Object Detection</a></th>
                    </tr>
                
                    <tr id="9b8cbe9a636b00b3543d8e1f98c24de12d6c3d17">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9b8cbe9a636b00b3543d8e1f98c24de12d6c3d17">86</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Chen_HINet_Half_Instance_Normalization_Network_for_Image_Restoration_CVPRW_2021_paper.html">HINet: Half Instance Normalization Network for Image Restoration</a></th>
                    </tr>
                
                    <tr id="26f3ee78b1ff4041e7a8e9ecffc95a9185a17caa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26f3ee78b1ff4041e7a8e9ecffc95a9185a17caa">85</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_GAN_Prior_Embedded_Network_for_Blind_Face_Restoration_in_the_CVPR_2021_paper.html">GAN Prior Embedded Network for Blind Face Restoration in the Wild</a></th>
                    </tr>
                
                    <tr id="8a1453ab579871f1b595e4415fee8a5fdd2a13f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8a1453ab579871f1b595e4415fee8a5fdd2a13f1">85</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Anokhin_Image_Generators_With_Conditionally-Independent_Pixel_Synthesis_CVPR_2021_paper.html">Image Generators With Conditionally-Independent Pixel Synthesis</a></th>
                    </tr>
                
                    <tr id="d3be0a12a16c3bb4de17202d09a83cf92b3f6209">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d3be0a12a16c3bb4de17202d09a83cf92b3f6209">85</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Skorokhodov_Adversarial_Generation_of_Continuous_Images_CVPR_2021_paper.html">Adversarial Generation of Continuous Images</a></th>
                    </tr>
                
                    <tr id="c544c12fe8b637ae81caabb7ca1f50ab71336cff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c544c12fe8b637ae81caabb7ca1f50ab71336cff">85</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zou_End-to-End_Human_Object_Interaction_Detection_With_HOI_Transformer_CVPR_2021_paper.html">End-to-End Human Object Interaction Detection With HOI Transformer</a></th>
                    </tr>
                
                    <tr id="5c5a9b8eec9edc5a5bc0a600e68a5442e4d7cd6a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c5a9b8eec9edc5a5bc0a600e68a5442e4d7cd6a">84</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_End-to-End_Object_Detection_With_Fully_Convolutional_Network_CVPR_2021_paper.html">End-to-End Object Detection With Fully Convolutional Network</a></th>
                    </tr>
                
                    <tr id="dd2c89052f4dfb1f1d060b08374469aa1e0f57a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dd2c89052f4dfb1f1d060b08374469aa1e0f57a6">84</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_AF2-S3Net_Attentive_Feature_Fusion_With_Adaptive_Feature_Selection_for_Sparse_CVPR_2021_paper.html">(AF)2-S3Net: Attentive Feature Fusion With Adaptive Feature Selection for Sparse Semantic Segmentation Network</a></th>
                    </tr>
                
                    <tr id="50bca2632e973fc6a60cdd7da1d64f3fc5ddd9b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50bca2632e973fc6a60cdd7da1d64f3fc5ddd9b1">83</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_PhySG_Inverse_Rendering_With_Spherical_Gaussians_for_Physics-Based_Material_Editing_CVPR_2021_paper.html">PhySG: Inverse Rendering With Spherical Gaussians for Physics-Based Material Editing and Relighting</a></th>
                    </tr>
                
                    <tr id="01460c9fa85d030f1789ad65513d22380e58fcb2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01460c9fa85d030f1789ad65513d22380e58fcb2">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sarlin_Back_to_the_Feature_Learning_Robust_Camera_Localization_From_Pixels_CVPR_2021_paper.html">Back to the Feature: Learning Robust Camera Localization From Pixels To Pose</a></th>
                    </tr>
                
                    <tr id="78661cecf81340be9bd5720ac5ae97dc0e037bb9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/78661cecf81340be9bd5720ac5ae97dc0e037bb9">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Reiss_PANDA_Adapting_Pretrained_Features_for_Anomaly_Detection_and_Segmentation_CVPR_2021_paper.html">PANDA: Adapting Pretrained Features for Anomaly Detection and Segmentation</a></th>
                    </tr>
                
                    <tr id="89ef5bce65e80d3da0ccfa80b542680cf8570dd2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/89ef5bce65e80d3da0ccfa80b542680cf8570dd2">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Delving_Into_Localization_Errors_for_Monocular_3D_Object_Detection_CVPR_2021_paper.html">Delving Into Localization Errors for Monocular 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="395f76ffadf04c9711358b70928d0a313351985c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/395f76ffadf04c9711358b70928d0a313351985c">82</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lanchantin_General_Multi-Label_Image_Classification_With_Transformers_CVPR_2021_paper.html">General Multi-Label Image Classification With Transformers</a></th>
                    </tr>
                
                    <tr id="497d765b1eccbc9e99a37592a1860744559695db">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/497d765b1eccbc9e99a37592a1860744559695db">81</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zareian_Open-Vocabulary_Object_Detection_Using_Captions_CVPR_2021_paper.html">Open-Vocabulary Object Detection Using Captions</a></th>
                    </tr>
                
                    <tr id="2c929659578d1fe4726d30f082d8b9604920f5d5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c929659578d1fe4726d30f082d8b9604920f5d5">81</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Haliassos_Lips_Dont_Lie_A_Generalisable_and_Robust_Approach_To_Face_CVPR_2021_paper.html">Lips Don&#39;t Lie: A Generalisable and Robust Approach To Face Forgery Detection</a></th>
                    </tr>
                
                    <tr id="30dd21d9ba914ecf4896a51ce5e900d54abd4895">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/30dd21d9ba914ecf4896a51ce5e900d54abd4895">81</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_FFB6D_A_Full_Flow_Bidirectional_Fusion_Network_for_6D_Pose_CVPR_2021_paper.html">FFB6D: A Full Flow Bidirectional Fusion Network for 6D Pose Estimation</a></th>
                    </tr>
                
                    <tr id="3d7b0ee51b2fb0cd46762ce04681405df30c1d29">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3d7b0ee51b2fb0cd46762ce04681405df30c1d29">81</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_WebFace260M_A_Benchmark_Unveiling_the_Power_of_Million-Scale_Deep_Face_CVPR_2021_paper.html">WebFace260M: A Benchmark Unveiling the Power of Million-Scale Deep Face Recognition</a></th>
                    </tr>
                
                    <tr id="adcd6edd52bd9d42cb38ae3d1019d6dc6cbd96d0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/adcd6edd52bd9d42cb38ae3d1019d6dc6cbd96d0">80</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Objects_Are_Different_Flexible_Monocular_3D_Object_Detection_CVPR_2021_paper.html">Objects Are Different: Flexible Monocular 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="1f476738e6d2950ab2ca08ac852764640c8e9d93">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1f476738e6d2950ab2ca08ac852764640c8e9d93">80</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Real-Time_High-Resolution_Background_Matting_CVPR_2021_paper.html">Real-Time High-Resolution Background Matting</a></th>
                    </tr>
                
                    <tr id="fdf8fa52c889d70a1a43b1cf241f24736584f948">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fdf8fa52c889d70a1a43b1cf241f24736584f948">80</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Watson_The_Temporal_Opportunist_Self-Supervised_Multi-Frame_Monocular_Depth_CVPR_2021_paper.html">The Temporal Opportunist: Self-Supervised Multi-Frame Monocular Depth</a></th>
                    </tr>
                
                    <tr id="1d3258abdfdc9262a3c5736a4619869a39d17120">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d3258abdfdc9262a3c5736a4619869a39d17120">79</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yue_Counterfactual_Zero-Shot_and_Open-Set_Visual_Recognition_CVPR_2021_paper.html">Counterfactual Zero-Shot and Open-Set Visual Recognition</a></th>
                    </tr>
                
                    <tr id="f5fc6db18cfcd2f26fb700194bfdd07b0cfca2a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f5fc6db18cfcd2f26fb700194bfdd07b0cfca2a5">79</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Contrastive_Learning_Based_Hybrid_Networks_for_Long-Tailed_Image_Classification_CVPR_2021_paper.html">Contrastive Learning Based Hybrid Networks for Long-Tailed Image Classification</a></th>
                    </tr>
                
                    <tr id="463c3e13c2d6fb3148bb2a1f0328b484d8a353f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/463c3e13c2d6fb3148bb2a1f0328b484d8a353f9">79</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Distilling_Knowledge_via_Knowledge_Review_CVPR_2021_paper.html">Distilling Knowledge via Knowledge Review</a></th>
                    </tr>
                
                    <tr id="363c260b6044bd35b0c200a4481228bbc6eb49a7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/363c260b6044bd35b0c200a4481228bbc6eb49a7">79</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Boundary_IoU_Improving_Object-Centric_Image_Segmentation_Evaluation_CVPR_2021_paper.html">Boundary IoU: Improving Object-Centric Image Segmentation Evaluation</a></th>
                    </tr>
                
                    <tr id="85376095b9e1a6763192c288747b203996b8d427">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/85376095b9e1a6763192c288747b203996b8d427">79</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Exploiting_Spatial_Dimensions_of_Latent_in_GAN_for_Real-Time_Image_CVPR_2021_paper.html">Exploiting Spatial Dimensions of Latent in GAN for Real-Time Image Editing</a></th>
                    </tr>
                
                    <tr id="845ea5c0243074174e3a4979d2f2fcf7e19eaace">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/845ea5c0243074174e3a4979d2f2fcf7e19eaace">78</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Distilling_Causal_Effect_of_Data_in_Class-Incremental_Learning_CVPR_2021_paper.html">Distilling Causal Effect of Data in Class-Incremental Learning</a></th>
                    </tr>
                
                    <tr id="f105afbb27ebb78a2ee8c420b712a528c38994d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f105afbb27ebb78a2ee8c420b712a528c38994d2">78</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wertheimer_Few-Shot_Classification_With_Feature_Map_Reconstruction_Networks_CVPR_2021_paper.html">Few-Shot Classification With Feature Map Reconstruction Networks</a></th>
                    </tr>
                
                    <tr id="aef7f3c942b2c8ff44434962809fa76f08f91030">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aef7f3c942b2c8ff44434962809fa76f08f91030">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_PD-GAN_Probabilistic_Diverse_GAN_for_Image_Inpainting_CVPR_2021_paper.html">PD-GAN: Probabilistic Diverse GAN for Image Inpainting</a></th>
                    </tr>
                
                    <tr id="e3d81ed56fad9bd348712c480e9651007d6c2226">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e3d81ed56fad9bd348712c480e9651007d6c2226">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fang_Read_Like_Humans_Autonomous_Bidirectional_and_Iterative_Language_Modeling_for_CVPR_2021_paper.html">Read Like Humans: Autonomous, Bidirectional and Iterative Language Modeling for Scene Text Recognition</a></th>
                    </tr>
                
                    <tr id="6c0f9090fa119009047e49e5530cae28f0dd2c7e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c0f9090fa119009047e49e5530cae28f0dd2c7e">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ao_SpinNet_Learning_a_General_Surface_Descriptor_for_3D_Point_Cloud_CVPR_2021_paper.html">SpinNet: Learning a General Surface Descriptor for 3D Point Cloud Registration</a></th>
                    </tr>
                
                    <tr id="8acce85836a5f6ee31d83e90a7d47b8cfa72a128">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8acce85836a5f6ee31d83e90a7d47b8cfa72a128">77</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ost_Neural_Scene_Graphs_for_Dynamic_Scenes_CVPR_2021_paper.html">Neural Scene Graphs for Dynamic Scenes</a></th>
                    </tr>
                
                    <tr id="7301d58eb8a750e44b7da5ab0266b134d1651237">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7301d58eb8a750e44b7da5ab0266b134d1651237">76</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Enhancing_the_Transferability_of_Adversarial_Attacks_Through_Variance_Tuning_CVPR_2021_paper.html">Enhancing the Transferability of Adversarial Attacks Through Variance Tuning</a></th>
                    </tr>
                
                    <tr id="2d029e88d045fed07ea6a6d01b56a6fc6df38474">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d029e88d045fed07ea6a6d01b56a6fc6df38474">76</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chibane_Stereo_Radiance_Fields_SRF_Learning_View_Synthesis_for_Sparse_Views_CVPR_2021_paper.html">Stereo Radiance Fields (SRF): Learning View Synthesis for Sparse Views of Novel Scenes</a></th>
                    </tr>
                
                    <tr id="6e66e4c22a7e28cc4d07ae153b3f030aa980a023">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6e66e4c22a7e28cc4d07ae153b3f030aa980a023">76</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Deep_Stable_Learning_for_Out-of-Distribution_Generalization_CVPR_2021_paper.html">Deep Stable Learning for Out-of-Distribution Generalization</a></th>
                    </tr>
                
                    <tr id="8db0bf0fa406254d4cd57eb413443a0b96bd12b8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8db0bf0fa406254d4cd57eb413443a0b96bd12b8">76</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_NeuralRecon_Real-Time_Coherent_3D_Reconstruction_From_Monocular_Video_CVPR_2021_paper.html">NeuralRecon: Real-Time Coherent 3D Reconstruction From Monocular Video</a></th>
                    </tr>
                
                    <tr id="8188240d537f714240f3c13897f121063882bc87">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8188240d537f714240f3c13897f121063882bc87">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Pose_Recognition_With_Cascade_Transformers_CVPR_2021_paper.html">Pose Recognition With Cascade Transformers</a></th>
                    </tr>
                
                    <tr id="d9a447690ba5845cc466f42e96962ee3aee732eb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d9a447690ba5845cc466f42e96962ee3aee732eb">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Learning_Salient_Boundary_Feature_for_Anchor-free_Temporal_Action_Localization_CVPR_2021_paper.html">Learning Salient Boundary Feature for Anchor-free Temporal Action Localization</a></th>
                    </tr>
                
                    <tr id="d9714b7fe6234fdb465b1e12a76e1ebbd8c0b29d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d9714b7fe6234fdb465b1e12a76e1ebbd8c0b29d">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_HybrIK_A_Hybrid_Analytical-Neural_Inverse_Kinematics_Solution_for_3D_Human_CVPR_2021_paper.html">HybrIK: A Hybrid Analytical-Neural Inverse Kinematics Solution for 3D Human Pose and Shape Estimation</a></th>
                    </tr>
                
                    <tr id="8cf51059c87a9b5abf04cf959bbf75ab6ffff8c3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8cf51059c87a9b5abf04cf959bbf75ab6ffff8c3">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qing_Temporal_Context_Aggregation_Network_for_Temporal_Action_Proposal_Refinement_CVPR_2021_paper.html">Temporal Context Aggregation Network for Temporal Action Proposal Refinement</a></th>
                    </tr>
                
                    <tr id="2c4c237fb21c4367a355e2542d6dd38b51325b6f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c4c237fb21c4367a355e2542d6dd38b51325b6f">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Na_FixBi_Bridging_Domain_Spaces_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html">FixBi: Bridging Domain Spaces for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="08bbe9ee1271ff8e0fd7bdbb1d87a995cc4509c6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/08bbe9ee1271ff8e0fd7bdbb1d87a995cc4509c6">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yun_Re-Labeling_ImageNet_From_Single_to_Multi-Labels_From_Global_to_Localized_CVPR_2021_paper.html">Re-Labeling ImageNet: From Single to Multi-Labels, From Global to Localized Labels</a></th>
                    </tr>
                
                    <tr id="747a2bbe3765f488eedac33a2ac7a0069020da57">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/747a2bbe3765f488eedac33a2ac7a0069020da57">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_PointAugmenting_Cross-Modal_Augmentation_for_3D_Object_Detection_CVPR_2021_paper.html">PointAugmenting: Cross-Modal Augmentation for 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="eee5dcd8ce65bba83b653957009ecc028ff3b887">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eee5dcd8ce65bba83b653957009ecc028ff3b887">75</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kellnhofer_Neural_Lumigraph_Rendering_CVPR_2021_paper.html">Neural Lumigraph Rendering</a></th>
                    </tr>
                
                    <tr id="9041ba8b5451b02b6790a1cabdc15b29f67fda63">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9041ba8b5451b02b6790a1cabdc15b29f67fda63">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Few-Shot_Incremental_Learning_With_Continually_Evolved_Classifiers_CVPR_2021_paper.html">Few-Shot Incremental Learning With Continually Evolved Classifiers</a></th>
                    </tr>
                
                    <tr id="ac4d4414f7555346dfad7c6a441e8d0e675a30a4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ac4d4414f7555346dfad7c6a441e8d0e675a30a4">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Corona_SMPLicit_Topology-Aware_Generative_Model_for_Clothed_People_CVPR_2021_paper.html">SMPLicit: Topology-Aware Generative Model for Clothed People</a></th>
                    </tr>
                
                    <tr id="30f586f3c9639236b2cc12070d7a352d1f102e1b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/30f586f3c9639236b2cc12070d7a352d1f102e1b">74</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_AdCo_Adversarial_Contrast_for_Efficient_Learning_of_Unsupervised_Representations_From_CVPR_2021_paper.html">AdCo: Adversarial Contrast for Efficient Learning of Unsupervised Representations From Self-Trained Negative Adversaries</a></th>
                    </tr>
                
                    <tr id="297e83bc6d4498ad2e2906092e2b3df1b7621c26">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/297e83bc6d4498ad2e2906092e2b3df1b7621c26">73</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Feng_MIST_Multiple_Instance_Self-Training_Framework_for_Video_Anomaly_Detection_CVPR_2021_paper.html">MIST: Multiple Instance Self-Training Framework for Video Anomaly Detection</a></th>
                    </tr>
                
                    <tr id="09acced5fcb49322f5a26ac7a4cbe9f1308657c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/09acced5fcb49322f5a26ac7a4cbe9f1308657c4">73</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wei_CReST_A_Class-Rebalancing_Self-Training_Framework_for_Imbalanced_Semi-Supervised_Learning_CVPR_2021_paper.html">CReST: A Class-Rebalancing Self-Training Framework for Imbalanced Semi-Supervised Learning</a></th>
                    </tr>
                
                    <tr id="5937d7c2c10da2418f7979cd55ad12fa1b93a58e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5937d7c2c10da2418f7979cd55ad12fa1b93a58e">73</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/VS_MeGA-CDA_Memory_Guided_Attention_for_Category-Aware_Unsupervised_Domain_Adaptive_Object_CVPR_2021_paper.html">MeGA-CDA: Memory Guided Attention for Category-Aware Unsupervised Domain Adaptive Object Detection</a></th>
                    </tr>
                
                    <tr id="5f6fccc32953f57fe29b2316eb8351e84b0179dc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f6fccc32953f57fe29b2316eb8351e84b0179dc">73</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_The_Lottery_Tickets_Hypothesis_for_Supervised_and_Self-Supervised_Pre-Training_in_CVPR_2021_paper.html">The Lottery Tickets Hypothesis for Supervised and Self-Supervised Pre-Training in Computer Vision Models</a></th>
                    </tr>
                
                    <tr id="464890394a85587ca8499f4f56cba0add7dcde9a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/464890394a85587ca8499f4f56cba0add7dcde9a">73</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ahmadyan_Objectron_A_Large_Scale_Dataset_of_Object-Centric_Videos_in_the_CVPR_2021_paper.html">Objectron: A Large Scale Dataset of Object-Centric Videos in the Wild With Pose Annotations</a></th>
                    </tr>
                
                    <tr id="cd8394d8b6679bb446cf154a6d123cf9a00e561e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd8394d8b6679bb446cf154a6d123cf9a00e561e">72</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Choi_RobustNet_Improving_Domain_Generalization_in_Urban-Scene_Segmentation_via_Instance_Selective_CVPR_2021_paper.html">RobustNet: Improving Domain Generalization in Urban-Scene Segmentation via Instance Selective Whitening</a></th>
                    </tr>
                
                    <tr id="a1267ad88ec0f72e554673edeca750e0825f7d14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a1267ad88ec0f72e554673edeca750e0825f7d14">72</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yi_Complete__Label_A_Domain_Adaptation_Approach_to_Semantic_Segmentation_CVPR_2021_paper.html">Complete &amp; Label: A Domain Adaptation Approach to Semantic Segmentation of LiDAR Point Clouds</a></th>
                    </tr>
                
                    <tr id="cad9c06c23aca7d974a20c2111e6007032384cd8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cad9c06c23aca7d974a20c2111e6007032384cd8">72</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Generalized_Few-Shot_Object_Detection_Without_Forgetting_CVPR_2021_paper.html">Generalized Few-Shot Object Detection Without Forgetting</a></th>
                    </tr>
                
                    <tr id="34e170f868551d35788099ce02c3c2d03e06f0d5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/34e170f868551d35788099ce02c3c2d03e06f0d5">72</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pan_Variational_Relational_Point_Completion_Network_CVPR_2021_paper.html">Variational Relational Point Completion Network</a></th>
                    </tr>
                
                    <tr id="0449c88867dec952945fc99749cc656df25c38b2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0449c88867dec952945fc99749cc656df25c38b2">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xiong_MobileDets_Searching_for_Object_Detection_Architectures_for_Mobile_Accelerators_CVPR_2021_paper.html">MobileDets: Searching for Object Detection Architectures for Mobile Accelerators</a></th>
                    </tr>
                
                    <tr id="0e366b85205cfcc9915a75d46db2bdd3805522b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e366b85205cfcc9915a75d46db2bdd3805522b1">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Araslanov_Self-Supervised_Augmentation_Consistency_for_Adapting_Semantic_Segmentation_CVPR_2021_paper.html">Self-Supervised Augmentation Consistency for Adapting Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="62dfb5fabe1e1d2d31e8a7e8e89c87072969b793">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/62dfb5fabe1e1d2d31e8a7e8e89c87072969b793">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Semantic_Relation_Reasoning_for_Shot-Stable_Few-Shot_Object_Detection_CVPR_2021_paper.html">Semantic Relation Reasoning for Shot-Stable Few-Shot Object Detection</a></th>
                    </tr>
                
                    <tr id="00b0f67a932ca1d71206063cce86c6acf82b31d8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00b0f67a932ca1d71206063cce86c6acf82b31d8">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tabelini_Keep_Your_Eyes_on_the_Lane_Real-Time_Attention-Guided_Lane_Detection_CVPR_2021_paper.html">Keep Your Eyes on the Lane: Real-Time Attention-Guided Lane Detection</a></th>
                    </tr>
                
                    <tr id="68a820f738046c41b075f4aa2e47663a465c648b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/68a820f738046c41b075f4aa2e47663a465c648b">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Group-aware_Label_Transfer_for_Domain_Adaptive_Person_Re-identification_CVPR_2021_paper.html">Group-aware Label Transfer for Domain Adaptive Person Re-identification</a></th>
                    </tr>
                
                    <tr id="46803220e5f6b636b65ef0ff87c0c9c4b95dec31">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/46803220e5f6b636b65ef0ff87c0c9c4b95dec31">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_On_Feature_Normalization_and_Data_Augmentation_CVPR_2021_paper.html">On Feature Normalization and Data Augmentation</a></th>
                    </tr>
                
                    <tr id="209fadc6f7fdbb92404ef69d2ee01df8e475d692">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/209fadc6f7fdbb92404ef69d2ee01df8e475d692">71</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bang_Rainbow_Memory_Continual_Learning_With_a_Memory_of_Diverse_Samples_CVPR_2021_paper.html">Rainbow Memory: Continual Learning With a Memory of Diverse Samples</a></th>
                    </tr>
                
                    <tr id="0d28e828f933f7eff37d7ad56b5ba63ad9558c55">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0d28e828f933f7eff37d7ad56b5ba63ad9558c55">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dai_General_Instance_Distillation_for_Object_Detection_CVPR_2021_paper.html">General Instance Distillation for Object Detection</a></th>
                    </tr>
                
                    <tr id="94080d9344523abe3730c383c41ef2311d591c6e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/94080d9344523abe3730c383c41ef2311d591c6e">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Neighbor2Neighbor_Self-Supervised_Denoising_From_Single_Noisy_Images_CVPR_2021_paper.html">Neighbor2Neighbor: Self-Supervised Denoising From Single Noisy Images</a></th>
                    </tr>
                
                    <tr id="52b1ceaf9ef4f88387557f80278bb976fce5a4c1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/52b1ceaf9ef4f88387557f80278bb976fce5a4c1">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_VisualVoice_Audio-Visual_Speech_Separation_With_Cross-Modal_Consistency_CVPR_2021_paper.html">VisualVoice: Audio-Visual Speech Separation With Cross-Modal Consistency</a></th>
                    </tr>
                
                    <tr id="389ee0934b5da420e51d1c77a12834c24ceec060">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/389ee0934b5da420e51d1c77a12834c24ceec060">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Douillard_PLOP_Learning_Without_Forgetting_for_Continual_Semantic_Segmentation_CVPR_2021_paper.html">PLOP: Learning Without Forgetting for Continual Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="18bf61eb27c146f8e11ea0590c9b6787d8274ce6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/18bf61eb27c146f8e11ea0590c9b6787d8274ce6">70</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chan_GLEAN_Generative_Latent_Bank_for_Large-Factor_Image_Super-Resolution_CVPR_2021_paper.html">GLEAN: Generative Latent Bank for Large-Factor Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="77a330c73f6959a8e135517733511f8a4ccb8b16">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/77a330c73f6959a8e135517733511f8a4ccb8b16">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mei_Camouflaged_Object_Segmentation_With_Distraction_Mining_CVPR_2021_paper.html">Camouflaged Object Segmentation With Distraction Mining</a></th>
                    </tr>
                
                    <tr id="c1a0a2fb788124bd4eae398f0e56db5ed8ec41fb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c1a0a2fb788124bd4eae398f0e56db5ed8ec41fb">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Exploring_Sparsity_in_Image_Super-Resolution_for_Efficient_Inference_CVPR_2021_paper.html">Exploring Sparsity in Image Super-Resolution for Efficient Inference</a></th>
                    </tr>
                
                    <tr id="3cf2a7f796921e01e6e794da193a244c3b793b04">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3cf2a7f796921e01e6e794da193a244c3b793b04">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Learning_Placeholders_for_Open-Set_Recognition_CVPR_2021_paper.html">Learning Placeholders for Open-Set Recognition</a></th>
                    </tr>
                
                    <tr id="f3d8f0062307c22cc241436e71253c5466c03364">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f3d8f0062307c22cc241436e71253c5466c03364">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Humble_Teachers_Teach_Better_Students_for_Semi-Supervised_Object_Detection_CVPR_2021_paper.html">Humble Teachers Teach Better Students for Semi-Supervised Object Detection</a></th>
                    </tr>
                
                    <tr id="2c1228e79722728fe292f2e8bdc7b7fb9ac9c454">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c1228e79722728fe292f2e8bdc7b7fb9ac9c454">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Alpha-Refine_Boosting_Tracking_Performance_by_Precise_Bounding_Box_Estimation_CVPR_2021_paper.html">Alpha-Refine: Boosting Tracking Performance by Precise Bounding Box Estimation</a></th>
                    </tr>
                
                    <tr id="58b4202b7174ed4cfae24c284d4003d74ac5371f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/58b4202b7174ed4cfae24c284d4003d74ac5371f">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Fully_Convolutional_Networks_for_Panoptic_Segmentation_CVPR_2021_paper.html">Fully Convolutional Networks for Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="4278352f3d7eecaac716378acb5cc44b3863315b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4278352f3d7eecaac716378acb5cc44b3863315b">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Adaptive_Aggregation_Networks_for_Class-Incremental_Learning_CVPR_2021_paper.html">Adaptive Aggregation Networks for Class-Incremental Learning</a></th>
                    </tr>
                
                    <tr id="943f0e5a21afc1d576d08aa40f93cea8d51f2bbe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/943f0e5a21afc1d576d08aa40f93cea8d51f2bbe">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_FSDR_Frequency_Space_Domain_Randomization_for_Domain_Generalization_CVPR_2021_paper.html">FSDR: Frequency Space Domain Randomization for Domain Generalization</a></th>
                    </tr>
                
                    <tr id="878e858b199a8529769657332730620da526de6f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/878e858b199a8529769657332730620da526de6f">69</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_GDR-Net_Geometry-Guided_Direct_Regression_Network_for_Monocular_6D_Object_Pose_CVPR_2021_paper.html">GDR-Net: Geometry-Guided Direct Regression Network for Monocular 6D Object Pose Estimation</a></th>
                    </tr>
                
                    <tr id="ae6a6e9977030074100c15b2d90f574d307b4e6b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae6a6e9977030074100c15b2d90f574d307b4e6b">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ji_Calibrated_RGB-D_Salient_Object_Detection_CVPR_2021_paper.html">Calibrated RGB-D Salient Object Detection</a></th>
                    </tr>
                
                    <tr id="2690c4254be2b6d5517f13c320191fb0f7fc7d1d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2690c4254be2b6d5517f13c320191fb0f7fc7d1d">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Distilling_Object_Detectors_via_Decoupled_Features_CVPR_2021_paper.html">Distilling Object Detectors via Decoupled Features</a></th>
                    </tr>
                
                    <tr id="e12a28f8a742b6b3c29fe2ace39068033a07f761">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e12a28f8a742b6b3c29fe2ace39068033a07f761">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tankovich_HITNet_Hierarchical_Iterative_Tile_Refinement_Network_for_Real-time_Stereo_Matching_CVPR_2021_paper.html">HITNet: Hierarchical Iterative Tile Refinement Network for Real-time Stereo Matching</a></th>
                    </tr>
                
                    <tr id="4644b8204ff7fcc3b0835ffad2f4216911ac9426">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4644b8204ff7fcc3b0835ffad2f4216911ac9426">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Seesaw_Loss_for_Long-Tailed_Instance_Segmentation_CVPR_2021_paper.html">Seesaw Loss for Long-Tailed Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="53b224126e7abe03e21186f47fcf9681e1ef5909">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/53b224126e7abe03e21186f47fcf9681e1ef5909">68</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nauta_Neural_Prototype_Trees_for_Interpretable_Fine-Grained_Image_Recognition_CVPR_2021_paper.html">Neural Prototype Trees for Interpretable Fine-Grained Image Recognition</a></th>
                    </tr>
                
                    <tr id="608006b0c6c223ef449cbafdc064afdb52bf4410">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/608006b0c6c223ef449cbafdc064afdb52bf4410">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_the_Best_Pooling_Strategy_for_Visual_Semantic_Embedding_CVPR_2021_paper.html">Learning the Best Pooling Strategy for Visual Semantic Embedding</a></th>
                    </tr>
                
                    <tr id="47639595307cfb411d8dee12fa1ae281d17bfe1d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47639595307cfb411d8dee12fa1ae281d17bfe1d">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lai_Semi-Supervised_Semantic_Segmentation_With_Directional_Context-Aware_Consistency_CVPR_2021_paper.html">Semi-Supervised Semantic Segmentation With Directional Context-Aware Consistency</a></th>
                    </tr>
                
                    <tr id="f6b20a2e83d1959ae30fed9adf143f99efcda970">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f6b20a2e83d1959ae30fed9adf143f99efcda970">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Suhail_Energy-Based_Learning_for_Scene_Graph_Generation_CVPR_2021_paper.html">Energy-Based Learning for Scene Graph Generation</a></th>
                    </tr>
                
                    <tr id="bf9386df7a517cb888f0229a1815b76e3826f150">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bf9386df7a517cb888f0229a1815b76e3826f150">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Disentangling_Label_Distribution_for_Long-Tailed_Visual_Recognition_CVPR_2021_paper.html">Disentangling Label Distribution for Long-Tailed Visual Recognition</a></th>
                    </tr>
                
                    <tr id="4ac318309807b5a7a50a1a292ced43e6f5f0ffbb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ac318309807b5a7a50a1a292ced43e6f5f0ffbb">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Learning_To_Recover_3D_Scene_Shape_From_a_Single_Image_CVPR_2021_paper.html">Learning To Recover 3D Scene Shape From a Single Image</a></th>
                    </tr>
                
                    <tr id="175f8509b1a9641ef011b26df393a5f4f65d6185">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/175f8509b1a9641ef011b26df393a5f4f65d6185">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qian_PU-GCN_Point_Cloud_Upsampling_Using_Graph_Convolutional_Networks_CVPR_2021_paper.html">PU-GCN: Point Cloud Upsampling Using Graph Convolutional Networks</a></th>
                    </tr>
                
                    <tr id="8f2221bc4da30a56bfcd3ebe481952a981b81e49">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f2221bc4da30a56bfcd3ebe481952a981b81e49">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Duke_SSTVOS_Sparse_Spatiotemporal_Transformers_for_Video_Object_Segmentation_CVPR_2021_paper.html">SSTVOS: Sparse Spatiotemporal Transformers for Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="f27eb4628711d1d4230e2ce285c1e658e9487798">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f27eb4628711d1d4230e2ce285c1e658e9487798">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_COMPLETER_Incomplete_Multi-View_Clustering_via_Contrastive_Prediction_CVPR_2021_paper.html">COMPLETER: Incomplete Multi-View Clustering via Contrastive Prediction</a></th>
                    </tr>
                
                    <tr id="57b2198f9a8df773425aa6cc88c9870cb07779e2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/57b2198f9a8df773425aa6cc88c9870cb07779e2">67</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Georgescu_Anomaly_Detection_in_Video_via_Self-Supervised_and_Multi-Task_Learning_CVPR_2021_paper.html">Anomaly Detection in Video via Self-Supervised and Multi-Task Learning</a></th>
                    </tr>
                
                    <tr id="35c6c542164c31f9572a495422815c32a85fa4f6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/35c6c542164c31f9572a495422815c32a85fa4f6">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yao_Non-Salient_Region_Object_Mining_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2021_paper.html">Non-Salient Region Object Mining for Weakly Supervised Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="954121c58819c9348518e241bb4a6a7ce19aaee1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/954121c58819c9348518e241bb4a6a7ce19aaee1">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Peng_Generating_Diverse_Structure_for_Image_Inpainting_With_Hierarchical_VQ-VAE_CVPR_2021_paper.html">Generating Diverse Structure for Image Inpainting With Hierarchical VQ-VAE</a></th>
                    </tr>
                
                    <tr id="9868cbb66312c7790602d4e3fe44af1482d5ce54">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9868cbb66312c7790602d4e3fe44af1482d5ce54">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Suo_TrafficSim_Learning_To_Simulate_Realistic_Multi-Agent_Behaviors_CVPR_2021_paper.html">TrafficSim: Learning To Simulate Realistic Multi-Agent Behaviors</a></th>
                    </tr>
                
                    <tr id="611472dcfa60e2d62ccd6fc787ee8951cef8a117">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/611472dcfa60e2d62ccd6fc787ee8951cef8a117">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_LiDAR_R-CNN_An_Efficient_and_Universal_3D_Object_Detector_CVPR_2021_paper.html">LiDAR R-CNN: An Efficient and Universal 3D Object Detector</a></th>
                    </tr>
                
                    <tr id="8b9058db5114ce96b079d28e079c3600bce0b290">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b9058db5114ce96b079d28e079c3600bce0b290">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xuan_Intra-Inter_Camera_Similarity_for_Unsupervised_Person_Re-Identification_CVPR_2021_paper.html">Intra-Inter Camera Similarity for Unsupervised Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="8deceb13cb3afcfbaab06a2c655f1935445635fe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8deceb13cb3afcfbaab06a2c655f1935445635fe">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_TAP_Text-Aware_Pre-Training_for_Text-VQA_and_Text-Caption_CVPR_2021_paper.html">TAP: Text-Aware Pre-Training for Text-VQA and Text-Caption</a></th>
                    </tr>
                
                    <tr id="db848dda8e07d76b5fe006a79d909026584c44b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db848dda8e07d76b5fe006a79d909026584c44b1">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Lite-HRNet_A_Lightweight_High-Resolution_Network_CVPR_2021_paper.html">Lite-HRNet: A Lightweight High-Resolution Network</a></th>
                    </tr>
                
                    <tr id="756940081880a162c59c6db40a9e7f39b2dc68b6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/756940081880a162c59c6db40a9e7f39b2dc68b6">66</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Boudiaf_Few-Shot_Segmentation_Without_Meta-Learning_A_Good_Transductive_Inference_Is_All_CVPR_2021_paper.html">Few-Shot Segmentation Without Meta-Learning: A Good Transductive Inference Is All You Need?</a></th>
                    </tr>
                
                    <tr id="05700d2674a8522417122c81d88af43aa3e9e417">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05700d2674a8522417122c81d88af43aa3e9e417">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qi_Offboard_3D_Object_Detection_From_Point_Cloud_Sequences_CVPR_2021_paper.html">Offboard 3D Object Detection From Point Cloud Sequences</a></th>
                    </tr>
                
                    <tr id="0d41f1ad664d568ce847740080a7fc3861b7e51f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0d41f1ad664d568ce847740080a7fc3861b7e51f">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mihajlovic_LEAP_Learning_Articulated_Occupancy_of_People_CVPR_2021_paper.html">LEAP: Learning Articulated Occupancy of People</a></th>
                    </tr>
                
                    <tr id="86f88bc71034122eb9d4f8ea16371ebd3efd42cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/86f88bc71034122eb9d4f8ea16371ebd3efd42cc">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qiao_VIP-DeepLab_Learning_Visual_Perception_With_Depth-Aware_Video_Panoptic_Segmentation_CVPR_2021_paper.html">VIP-DeepLab: Learning Visual Perception With Depth-Aware Video Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="9e75112b213fcdb3253b18da84d85cca2250036b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9e75112b213fcdb3253b18da84d85cca2250036b">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wenger_Backdoor_Attacks_Against_Deep_Learning_Systems_in_the_Physical_World_CVPR_2021_paper.html">Backdoor Attacks Against Deep Learning Systems in the Physical World</a></th>
                    </tr>
                
                    <tr id="279925dbe2ebe4e38d6cfa646f726aa8d6d9a122">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/279925dbe2ebe4e38d6cfa646f726aa8d6d9a122">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Exploring_and_Distilling_Posterior_and_Prior_Knowledge_for_Radiology_Report_CVPR_2021_paper.html">Exploring and Distilling Posterior and Prior Knowledge for Radiology Report Generation</a></th>
                    </tr>
                
                    <tr id="634cc3a29b4818ace36c955b3995ce8c13dffb85">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/634cc3a29b4818ace36c955b3995ce8c13dffb85">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cho_PiCIE_Unsupervised_Semantic_Segmentation_Using_Invariance_and_Equivariance_in_Clustering_CVPR_2021_paper.html">PiCIE: Unsupervised Semantic Segmentation Using Invariance and Equivariance in Clustering</a></th>
                    </tr>
                
                    <tr id="4f7a77d04e7e1cff1f6e306f082217be78203643">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f7a77d04e7e1cff1f6e306f082217be78203643">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Instance_Localization_for_Self-Supervised_Detection_Pretraining_CVPR_2021_paper.html">Instance Localization for Self-Supervised Detection Pretraining</a></th>
                    </tr>
                
                    <tr id="1ba56df34200b028eace2f6cbdd62cb8bc2de20c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ba56df34200b028eace2f6cbdd62cb8bc2de20c">65</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Casas_MP3_A_Unified_Model_To_Map_Perceive_Predict_and_Plan_CVPR_2021_paper.html">MP3: A Unified Model To Map, Perceive, Predict and Plan</a></th>
                    </tr>
                
                    <tr id="40f449590886f64de4bd94d6d4a9ef3a01ce88e8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/40f449590886f64de4bd94d6d4a9ef3a01ce88e8">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Choi_Beyond_Static_Features_for_Temporally_Consistent_3D_Human_Pose_and_CVPR_2021_paper.html">Beyond Static Features for Temporally Consistent 3D Human Pose and Shape From a Video</a></th>
                    </tr>
                
                    <tr id="983d2b3ef5dca83338907da73983b41a5c6adc7c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/983d2b3ef5dca83338907da73983b41a5c6adc7c">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Miech_Thinking_Fast_and_Slow_Efficient_Text-to-Visual_Retrieval_With_Transformers_CVPR_2021_paper.html">Thinking Fast and Slow: Efficient Text-to-Visual Retrieval With Transformers</a></th>
                    </tr>
                
                    <tr id="d98b074b37b2ce6551af320c36d506462640d977">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d98b074b37b2ce6551af320c36d506462640d977">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Fashion_IQ_A_New_Dataset_Towards_Retrieving_Images_by_Natural_CVPR_2021_paper.html">Fashion IQ: A New Dataset Towards Retrieving Images by Natural Language Feedback</a></th>
                    </tr>
                
                    <tr id="66dcefe879253a25e53c6319a9d395baac8cc9e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/66dcefe879253a25e53c6319a9d395baac8cc9e3">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Dense_Relation_Distillation_With_Context-Aware_Aggregation_for_Few-Shot_Object_Detection_CVPR_2021_paper.html">Dense Relation Distillation With Context-Aware Aggregation for Few-Shot Object Detection</a></th>
                    </tr>
                
                    <tr id="88f868de54c7207368006fe056ebe4713c9fb33d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/88f868de54c7207368006fe056ebe4713c9fb33d">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Miangoleh_Boosting_Monocular_Depth_Estimation_Models_to_High-Resolution_via_Content-Adaptive_Multi-Resolution_CVPR_2021_paper.html">Boosting Monocular Depth Estimation Models to High-Resolution via Content-Adaptive Multi-Resolution Merging</a></th>
                    </tr>
                
                    <tr id="58685b702d73af2413cb46ac5529a8c0dc4f4150">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/58685b702d73af2413cb46ac5529a8c0dc4f4150">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Bipartite_Graph_Network_With_Adaptive_Message_Passing_for_Unbiased_Scene_CVPR_2021_paper.html">Bipartite Graph Network With Adaptive Message Passing for Unbiased Scene Graph Generation</a></th>
                    </tr>
                
                    <tr id="08b6f8cdaaa3d090f0ffab2c41fc1261a24d7b76">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/08b6f8cdaaa3d090f0ffab2c41fc1261a24d7b76">64</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Fourier_Contour_Embedding_for_Arbitrary-Shaped_Text_Detection_CVPR_2021_paper.html">Fourier Contour Embedding for Arbitrary-Shaped Text Detection</a></th>
                    </tr>
                
                    <tr id="40bd7b09a6d893b5d1c5d4615614cf65a79ad769">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/40bd7b09a6d893b5d1c5d4615614cf65a79ad769">63</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Railroad_Is_Not_a_Train_Saliency_As_Pseudo-Pixel_Supervision_for_CVPR_2021_paper.html">Railroad Is Not a Train: Saliency As Pseudo-Pixel Supervision for Weakly Supervised Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="4e35f47d7658d0cf6bfd97cc66045691bd596246">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4e35f47d7658d0cf6bfd97cc66045691bd596246">63</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_HoHoNet_360_Indoor_Holistic_Understanding_With_Latent_Horizontal_Features_CVPR_2021_paper.html">HoHoNet: 360 Indoor Holistic Understanding With Latent Horizontal Features</a></th>
                    </tr>
                
                    <tr id="0820694e95d1a9bfe364727a5f568f139cf5a980">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0820694e95d1a9bfe364727a5f568f139cf5a980">63</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kondratyuk_MoViNets_Mobile_Video_Networks_for_Efficient_Video_Recognition_CVPR_2021_paper.html">MoViNets: Mobile Video Networks for Efficient Video Recognition</a></th>
                    </tr>
                
                    <tr id="0cd8108c6d87df71c0722f380dff90d6188678fe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0cd8108c6d87df71c0722f380dff90d6188678fe">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bai_PointDSC_Robust_Point_Cloud_Registration_Using_Deep_Spatial_Consistency_CVPR_2021_paper.html">PointDSC: Robust Point Cloud Registration Using Deep Spatial Consistency</a></th>
                    </tr>
                
                    <tr id="a24a0a2b3ddbddc406ea6791dbef8f980447eb43">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a24a0a2b3ddbddc406ea6791dbef8f980447eb43">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_T2VLAD_Global-Local_Sequence_Alignment_for_Text-Video_Retrieval_CVPR_2021_paper.html">T2VLAD: Global-Local Sequence Alignment for Text-Video Retrieval</a></th>
                    </tr>
                
                    <tr id="0fc9efef74fdc686d36fa7d13e05c4d4f57b9451">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0fc9efef74fdc686d36fa7d13e05c4d4f57b9451">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lv_Simultaneously_Localize_Segment_and_Rank_the_Camouflaged_Objects_CVPR_2021_paper.html">Simultaneously Localize, Segment and Rank the Camouflaged Objects</a></th>
                    </tr>
                
                    <tr id="85928cbe218808f5ea8846e939d804f72ee5843a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/85928cbe218808f5ea8846e939d804f72ee5843a">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qiu_Semantic_Segmentation_for_Real_Point_Cloud_Scenes_via_Bilateral_Augmentation_CVPR_2021_paper.html">Semantic Segmentation for Real Point Cloud Scenes via Bilateral Augmentation and Adaptive Fusion</a></th>
                    </tr>
                
                    <tr id="8dc94728873e6365524d98840303a5e9f7d0e283">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8dc94728873e6365524d98840303a5e9f7d0e283">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Convolutional_Neural_Network_Pruning_With_Structural_Redundancy_Reduction_CVPR_2021_paper.html">Convolutional Neural Network Pruning With Structural Redundancy Reduction</a></th>
                    </tr>
                
                    <tr id="4ac423a13184ce3f3505853dd92e9ab79518eadd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ac423a13184ce3f3505853dd92e9ab79518eadd">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Task-Aware_Variational_Adversarial_Active_Learning_CVPR_2021_paper.html">Task-Aware Variational Adversarial Active Learning</a></th>
                    </tr>
                
                    <tr id="417c02bf1fe483559bb8f386d29aea1088627e68">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/417c02bf1fe483559bb8f386d29aea1088627e68">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Han_Contrastive_Embedding_for_Generalized_Zero-Shot_Learning_CVPR_2021_paper.html">Contrastive Embedding for Generalized Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6885c45614f78f9d2e7cc8ef11b3c38b34e67f7d">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Salehi_Multiresolution_Knowledge_Distillation_for_Anomaly_Detection_CVPR_2021_paper.html">Multiresolution Knowledge Distillation for Anomaly Detection</a></th>
                    </tr>
                
                    <tr id="09ce0a5073dde62e6cff2d5dfed1944e024e951e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/09ce0a5073dde62e6cff2d5dfed1944e024e951e">62</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Improving_Calibration_for_Long-Tailed_Recognition_CVPR_2021_paper.html">Improving Calibration for Long-Tailed Recognition</a></th>
                    </tr>
                
                    <tr id="88a3579aecc1f0c7a3d5b57a5c07cd51c242b3c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/88a3579aecc1f0c7a3d5b57a5c07cd51c242b3c4">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Multiple_Object_Tracking_With_Correlation_Learning_CVPR_2021_paper.html">Multiple Object Tracking With Correlation Learning</a></th>
                    </tr>
                
                    <tr id="82dc9a015ebcd4162a1d4bc525e032bd6a9abe90">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/82dc9a015ebcd4162a1d4bc525e032bd6a9abe90">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Learning_to_Generalize_Unseen_Domains_via_Memory-based_Multi-Source_Meta-Learning_for_CVPR_2021_paper.html">Learning to Generalize Unseen Domains via Memory-based Multi-Source Meta-Learning for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="55db23c0f61de1a739f6e8f8708357acfdd6ece2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/55db23c0f61de1a739f6e8f8708357acfdd6ece2">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shen_CFNet_Cascade_and_Fused_Cost_Volume_for_Robust_Stereo_Matching_CVPR_2021_paper.html">CFNet: Cascade and Fused Cost Volume for Robust Stereo Matching</a></th>
                    </tr>
                
                    <tr id="1f122f73182db2f71fac27e014a23ae9b268138d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1f122f73182db2f71fac27e014a23ae9b268138d">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Siarohin_Motion_Representations_for_Articulated_Animation_CVPR_2021_paper.html">Motion Representations for Articulated Animation</a></th>
                    </tr>
                
                    <tr id="457573d719fd38ae133f516274c7cecd28916639">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/457573d719fd38ae133f516274c7cecd28916639">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Prototype_Augmentation_and_Self-Supervision_for_Incremental_Learning_CVPR_2021_paper.html">Prototype Augmentation and Self-Supervision for Incremental Learning</a></th>
                    </tr>
                
                    <tr id="3e423b4391b356b09713fa8409aa8b7aca7acfa2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3e423b4391b356b09713fa8409aa8b7aca7acfa2">61</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Robust_Point_Cloud_Registration_Framework_Based_on_Deep_Graph_Matching_CVPR_2021_paper.html">Robust Point Cloud Registration Framework Based on Deep Graph Matching</a></th>
                    </tr>
                
                    <tr id="8589aa697cd170c793c4c729b81b6f6dfacb012c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8589aa697cd170c793c4c729b81b6f6dfacb012c">61</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Hanzlik_MLCapsule_Guarded_Offline_Deployment_of_Machine_Learning_as_a_Service_CVPRW_2021_paper.html">MLCapsule: Guarded Offline Deployment of Machine Learning as a Service</a></th>
                    </tr>
                
                    <tr id="d38e1225476f5a035e6661c360365c30506e5804">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d38e1225476f5a035e6661c360365c30506e5804">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Geng_Bottom-Up_Human_Pose_Estimation_via_Disentangled_Keypoint_Regression_CVPR_2021_paper.html">Bottom-Up Human Pose Estimation via Disentangled Keypoint Regression</a></th>
                    </tr>
                
                    <tr id="811ffb185bc90ac5d02d6dbfbcdb6173756b52ef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/811ffb185bc90ac5d02d6dbfbcdb6173756b52ef">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fu_STMTrack_Template-Free_Visual_Tracking_With_Space-Time_Memory_Networks_CVPR_2021_paper.html">STMTrack: Template-Free Visual Tracking With Space-Time Memory Networks</a></th>
                    </tr>
                
                    <tr id="adf34b98727b0f17604705d8a3b988daef0776ef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/adf34b98727b0f17604705d8a3b988daef0776ef">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_FVC_A_New_Framework_Towards_Deep_Video_Compression_in_Feature_CVPR_2021_paper.html">FVC: A New Framework Towards Deep Video Compression in Feature Space</a></th>
                    </tr>
                
                    <tr id="a5fed2f5eb28a8ac6312b31bcd566c510d765b10">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a5fed2f5eb28a8ac6312b31bcd566c510d765b10">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_Multimodal_Contrastive_Training_for_Visual_Representation_Learning_CVPR_2021_paper.html">Multimodal Contrastive Training for Visual Representation Learning</a></th>
                    </tr>
                
                    <tr id="800928c91d451307befda8aec5a87d60b62e4ec6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/800928c91d451307befda8aec5a87d60b62e4ec6">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Van_Horn_Benchmarking_Representation_Learning_for_Natural_World_Image_Collections_CVPR_2021_paper.html">Benchmarking Representation Learning for Natural World Image Collections</a></th>
                    </tr>
                
                    <tr id="aee9693db23c63afd9ead39e0fe06ca4000c52dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aee9693db23c63afd9ead39e0fe06ca4000c52dd">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ramaswamy_Fair_Attribute_Classification_Through_Latent_Space_De-Biasing_CVPR_2021_paper.html">Fair Attribute Classification Through Latent Space De-Biasing</a></th>
                    </tr>
                
                    <tr id="1a9015e511ec3da873f6114eeb542905a92d7d62">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a9015e511ec3da873f6114eeb542905a92d7d62">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Marino_KRISP_Integrating_Implicit_and_Symbolic_Knowledge_for_Open-Domain_Knowledge-Based_VQA_CVPR_2021_paper.html">KRISP: Integrating Implicit and Symbolic Knowledge for Open-Domain Knowledge-Based VQA</a></th>
                    </tr>
                
                    <tr id="a9b87cdfe7c821d6b3c5a924b97c935e17d88595">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a9b87cdfe7c821d6b3c5a924b97c935e17d88595">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Beyond_Max-Margin_Class_Margin_Equilibrium_for_Few-Shot_Object_Detection_CVPR_2021_paper.html">Beyond Max-Margin: Class Margin Equilibrium for Few-Shot Object Detection</a></th>
                    </tr>
                
                    <tr id="b8ea0e14177d018b0a5cfd525235afc451bd072e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b8ea0e14177d018b0a5cfd525235afc451bd072e">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wen_PMP-Net_Point_Cloud_Completion_by_Learning_Multi-Step_Point_Moving_Paths_CVPR_2021_paper.html">PMP-Net: Point Cloud Completion by Learning Multi-step Point Moving Paths</a></th>
                    </tr>
                
                    <tr id="bbb55014a9b7310f8efa3bc09982af3d0cdd57df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bbb55014a9b7310f8efa3bc09982af3d0cdd57df">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Instant-Teaching_An_End-to-End_Semi-Supervised_Object_Detection_Framework_CVPR_2021_paper.html">Instant-Teaching: An End-to-End Semi-Supervised Object Detection Framework</a></th>
                    </tr>
                
                    <tr id="71f5e48323ab65bd93579b2b0ca48a5660c86cc3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/71f5e48323ab65bd93579b2b0ca48a5660c86cc3">60</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Generative_Hierarchical_Features_From_Synthesizing_Images_CVPR_2021_paper.html">Generative Hierarchical Features from Synthesizing Images</a></th>
                    </tr>
                
                    <tr id="2ec987448d8c8b82dd01d35838ebf0d15f38a9f8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ec987448d8c8b82dd01d35838ebf0d15f38a9f8">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ji_Audio-Driven_Emotional_Video_Portraits_CVPR_2021_paper.html">Audio-Driven Emotional Video Portraits</a></th>
                    </tr>
                
                    <tr id="a83a62da1564721cc41b8ae037ba17563c233955">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a83a62da1564721cc41b8ae037ba17563c233955">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Deep_RGB-D_Saliency_Detection_With_Depth-Sensitive_Attention_and_Automatic_Multi-Modal_CVPR_2021_paper.html">Deep RGB-D Saliency Detection With Depth-Sensitive Attention and Automatic Multi-Modal Fusion</a></th>
                    </tr>
                
                    <tr id="2a4b0f6f50ab629a183a77ac8b69851208e5f3bc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2a4b0f6f50ab629a183a77ac8b69851208e5f3bc">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shit_clDice_-_A_Novel_Topology-Preserving_Loss_Function_for_Tubular_Structure_CVPR_2021_paper.html">clDice - A Novel Topology-Preserving Loss Function for Tubular Structure Segmentation</a></th>
                    </tr>
                
                    <tr id="f19092561296244e1dafe7d799e7906e96a63773">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f19092561296244e1dafe7d799e7906e96a63773">59</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_MOS_Towards_Scaling_Out-of-Distribution_Detection_for_Large_Semantic_Space_CVPR_2021_paper.html">MOS: Towards Scaling Out-of-Distribution Detection for Large Semantic Space</a></th>
                    </tr>
                
                    <tr id="25df50d299ffdcb91ff1f236087ccdec514cb9ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/25df50d299ffdcb91ff1f236087ccdec514cb9ce">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chun_Probabilistic_Embeddings_for_Cross-Modal_Retrieval_CVPR_2021_paper.html">Probabilistic Embeddings for Cross-Modal Retrieval</a></th>
                    </tr>
                
                    <tr id="b6d6223bfa9de61d675d2fd4dd43c5924f393a55">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b6d6223bfa9de61d675d2fd4dd43c5924f393a55">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tamura_QPIC_Query-Based_Pairwise_Human-Object_Interaction_Detection_With_Image-Wide_Contextual_Information_CVPR_2021_paper.html">QPIC: Query-Based Pairwise Human-Object Interaction Detection With Image-Wide Contextual Information</a></th>
                    </tr>
                
                    <tr id="50eb5344f5a7cbc9b40b8a515cc941a29e8b4f41">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50eb5344f5a7cbc9b40b8a515cc941a29e8b4f41">58</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Self-Guided_and_Cross-Guided_Learning_for_Few-Shot_Segmentation_CVPR_2021_paper.html">Self-Guided and Cross-Guided Learning for Few-Shot Segmentation</a></th>
                    </tr>
                
                    <tr id="84c784b88b21cd58b8c8c2d3de6f3012bb539197">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/84c784b88b21cd58b8c8c2d3de6f3012bb539197">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Albiero_img2pose_Face_Alignment_and_Detection_via_6DoF_Face_Pose_Estimation_CVPR_2021_paper.html">img2pose: Face Alignment and Detection via 6DoF, Face Pose Estimation</a></th>
                    </tr>
                
                    <tr id="7e5fefa74f383ec2d77b72b639e3d6f30dea2970">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e5fefa74f383ec2d77b72b639e3d6f30dea2970">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Function4D_Real-Time_Human_Volumetric_Capture_From_Very_Sparse_Consumer_RGBD_CVPR_2021_paper.html">Function4D: Real-Time Human Volumetric Capture From Very Sparse Consumer RGBD Sensors</a></th>
                    </tr>
                
                    <tr id="423d5f1065d818142f2b5ecd10c90ee9572c7300">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/423d5f1065d818142f2b5ecd10c90ee9572c7300">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_FS-Net_Fast_Shape-Based_Network_for_Category-Level_6D_Object_Pose_Estimation_CVPR_2021_paper.html">FS-Net: Fast Shape-Based Network for Category-Level 6D Object Pose Estimation With Decoupled Rotation Mechanism</a></th>
                    </tr>
                
                    <tr id="936fbcce8edfc4c09e8bbbd05bba81b6c965a1b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/936fbcce8edfc4c09e8bbbd05bba81b6c965a1b5">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_SG-Net_Spatial_Granularity_Network_for_One-Stage_Video_Instance_Segmentation_CVPR_2021_paper.html">SG-Net: Spatial Granularity Network for One-Stage Video Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="248fb23e283ed739ee20c956cd935fbdc983d46f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/248fb23e283ed739ee20c956cd935fbdc983d46f">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Patel_AGORA_Avatars_in_Geography_Optimized_for_Regression_Analysis_CVPR_2021_paper.html">AGORA: Avatars in Geography Optimized for Regression Analysis</a></th>
                    </tr>
                
                    <tr id="f21aa5f92699e621b2a4110cc00fd61f41469347">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f21aa5f92699e621b2a4110cc00fd61f41469347">57</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tan_Equalization_Loss_v2_A_New_Gradient_Balance_Approach_for_Long-Tailed_CVPR_2021_paper.html">Equalization Loss v2: A New Gradient Balance Approach for Long-Tailed Object Detection</a></th>
                    </tr>
                
                    <tr id="cb2bd9549791520deccadfde221f8ca699675a96">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cb2bd9549791520deccadfde221f8ca699675a96">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tseng_Regularizing_Generative_Adversarial_Networks_Under_Limited_Data_CVPR_2021_paper.html">Regularizing Generative Adversarial Networks Under Limited Data</a></th>
                    </tr>
                
                    <tr id="906af0b014dc86e9fb232a983c5a2f8fc712743b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/906af0b014dc86e9fb232a983c5a2f8fc712743b">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Context-Aware_Biaffine_Localizing_Network_for_Temporal_Sentence_Grounding_CVPR_2021_paper.html">Context-Aware Biaffine Localizing Network for Temporal Sentence Grounding</a></th>
                    </tr>
                
                    <tr id="38489e185cafc2a6ff87843984ed23f273a15f1f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38489e185cafc2a6ff87843984ed23f273a15f1f">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Joint_Generative_and_Contrastive_Learning_for_Unsupervised_Person_Re-Identification_CVPR_2021_paper.html">Joint Generative and Contrastive Learning for Unsupervised Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="013b3dfbd70f964014a8b9c513bef782613c1be3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/013b3dfbd70f964014a8b9c513bef782613c1be3">56</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_RSN_Range_Sparse_Net_for_Efficient_Accurate_LiDAR_3D_Object_CVPR_2021_paper.html">RSN: Range Sparse Net for Efficient, Accurate LiDAR 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="097fcd76adb0447ec3525af154e37739d809f04f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/097fcd76adb0447ec3525af154e37739d809f04f">56</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Lomonaco_Avalanche_An_End-to-End_Library_for_Continual_Learning_CVPRW_2021_paper.html">Avalanche: An End-to-End Library for Continual Learning</a></th>
                    </tr>
                
                    <tr id="2e08702b428d7948052a05ccf20ed0ecb261aacc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e08702b428d7948052a05ccf20ed0ecb261aacc">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Greedy_Hierarchical_Variational_Autoencoders_for_Large-Scale_Video_Prediction_CVPR_2021_paper.html">Greedy Hierarchical Variational Autoencoders for Large-Scale Video Prediction</a></th>
                    </tr>
                
                    <tr id="791899dd5b3c4fdfc8c1823fb2332e6f04d02fd6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/791899dd5b3c4fdfc8c1823fb2332e6f04d02fd6">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ji_Learning_Calibrated_Medical_Image_Segmentation_via_Multi-Rater_Agreement_Modeling_CVPR_2021_paper.html">Learning Calibrated Medical Image Segmentation via Multi-Rater Agreement Modeling</a></th>
                    </tr>
                
                    <tr id="7a5be45c05299f535640b116273981eb44d810b7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a5be45c05299f535640b116273981eb44d810b7">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Scale-Aware_Graph_Neural_Network_for_Few-Shot_Semantic_Segmentation_CVPR_2021_paper.html">Scale-Aware Graph Neural Network for Few-Shot Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="3de0bff7ff185041862f79936fde9ae756a369a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3de0bff7ff185041862f79936fde9ae756a369a5">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nirkin_HyperSeg_Patch-Wise_Hypernetwork_for_Real-Time_Semantic_Segmentation_CVPR_2021_paper.html">HyperSeg: Patch-Wise Hypernetwork for Real-Time Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="451272a0cc069ebc2f16357f1686a23c818ea027">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/451272a0cc069ebc2f16357f1686a23c818ea027">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shuai_SiamMOT_Siamese_Multi-Object_Tracking_CVPR_2021_paper.html">SiamMOT: Siamese Multi-Object Tracking</a></th>
                    </tr>
                
                    <tr id="47062861716adf45bb7cbe1fc5bf6b6d414adad7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47062861716adf45bb7cbe1fc5bf6b6d414adad7">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheraghian_Semantic-Aware_Knowledge_Distillation_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.html">Semantic-Aware Knowledge Distillation for Few-Shot Class-Incremental Learning</a></th>
                    </tr>
                
                    <tr id="0db79fa4f25545e57213e9acf22f2e72100d563f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0db79fa4f25545e57213e9acf22f2e72100d563f">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Semantic_Segmentation_With_Generative_Models_Semi-Supervised_Learning_and_Strong_Out-of-Domain_CVPR_2021_paper.html">Semantic Segmentation With Generative Models: Semi-Supervised Learning and Strong Out-of-Domain Generalization</a></th>
                    </tr>
                
                    <tr id="3ec60b07eae5c09c4bd9eb93945d0d7c276143a7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ec60b07eae5c09c4bd9eb93945d0d7c276143a7">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Frequency-Aware_Discriminative_Feature_Learning_Supervised_by_Single-Center_Loss_for_Face_CVPR_2021_paper.html">Frequency-Aware Discriminative Feature Learning Supervised by Single-Center Loss for Face Forgery Detection</a></th>
                    </tr>
                
                    <tr id="1c620dbb3a9e2e1cf24df9cdd3d0b199b27a70b0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1c620dbb3a9e2e1cf24df9cdd3d0b199b27a70b0">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chao_DexYCB_A_Benchmark_for_Capturing_Hand_Grasping_of_Objects_CVPR_2021_paper.html">DexYCB: A Benchmark for Capturing Hand Grasping of Objects</a></th>
                    </tr>
                
                    <tr id="809b231e915c35db47cb81abfd8600f4c0f9fa10">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/809b231e915c35db47cb81abfd8600f4c0f9fa10">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhuge_Kaleido-BERT_Vision-Language_Pre-Training_on_Fashion_Domain_CVPR_2021_paper.html">Kaleido-BERT: Vision-Language Pre-Training on Fashion Domain</a></th>
                    </tr>
                
                    <tr id="39d087cd6a27a72174f365407cf82ac4450c552d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39d087cd6a27a72174f365407cf82ac4450c552d">55</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_A_Second-Order_Approach_to_Learning_With_Instance-Dependent_Label_Noise_CVPR_2021_paper.html">A Second-Order Approach to Learning With Instance-Dependent Label Noise</a></th>
                    </tr>
                
                    <tr id="147756438919051f46b39de1957cd90db3096b88">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/147756438919051f46b39de1957cd90db3096b88">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Localizing_Visual_Sounds_the_Hard_Way_CVPR_2021_paper.html">Localizing Visual Sounds the Hard Way</a></th>
                    </tr>
                
                    <tr id="650b5a65a80029a649ecbf0d85f97ec2881f0203">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/650b5a65a80029a649ecbf0d85f97ec2881f0203">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Efficient_Regional_Memory_Network_for_Video_Object_Segmentation_CVPR_2021_paper.html">Efficient Regional Memory Network for Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="e81a2177dc5d3338a159d850ab49ee2ba33e7138">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e81a2177dc5d3338a159d850ab49ee2ba33e7138">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Deformed_Implicit_Field_Modeling_3D_Shapes_With_Learned_Dense_Correspondence_CVPR_2021_paper.html">Deformed Implicit Field: Modeling 3D Shapes With Learned Dense Correspondence</a></th>
                    </tr>
                
                    <tr id="3552638ae2e9e98d270210be9970511ab7d09399">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3552638ae2e9e98d270210be9970511ab7d09399">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhai_Mutual_Graph_Learning_for_Camouflaged_Object_Detection_CVPR_2021_paper.html">Mutual Graph Learning for Camouflaged Object Detection</a></th>
                    </tr>
                
                    <tr id="8a9ccbeee235a0276196d7b05f1163425e482082">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8a9ccbeee235a0276196d7b05f1163425e482082">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_ACTION-Net_Multipath_Excitation_for_Action_Recognition_CVPR_2021_paper.html">ACTION-Net: Multipath Excitation for Action Recognition</a></th>
                    </tr>
                
                    <tr id="6b0c138127dae2bfc9f9542298f5e81032c033f0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6b0c138127dae2bfc9f9542298f5e81032c033f0">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Graph_Stacked_Hourglass_Networks_for_3D_Human_Pose_Estimation_CVPR_2021_paper.html">Graph Stacked Hourglass Networks for 3D Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="0a15a7ea04aaa4a0e20ab3ff46576e92026788cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a15a7ea04aaa4a0e20ab3ff46576e92026788cc">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kopf_Robust_Consistent_Video_Depth_Estimation_CVPR_2021_paper.html">Robust Consistent Video Depth Estimation</a></th>
                    </tr>
                
                    <tr id="fc4defdfb3410bc0ebda8ffc7d7a9258519c6cd8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc4defdfb3410bc0ebda8ffc7d7a9258519c6cd8">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Generalizing_Face_Forgery_Detection_With_High-Frequency_Features_CVPR_2021_paper.html">Generalizing Face Forgery Detection with High-frequency Features</a></th>
                    </tr>
                
                    <tr id="543600e3c933c843704b551a6e0bcd28cfd50bed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/543600e3c933c843704b551a6e0bcd28cfd50bed">54</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tian_BoxInst_High-Performance_Instance_Segmentation_With_Box_Annotations_CVPR_2021_paper.html">BoxInst: High-Performance Instance Segmentation with Box Annotations</a></th>
                    </tr>
                
                    <tr id="3d611852a0b25dd6d8d863d7c5d5c710630543f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3d611852a0b25dd6d8d863d7c5d5c710630543f2">54</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/HVU/html/Dzabraev_MDMMT_Multidomain_Multimodal_Transformer_for_Video_Retrieval_CVPRW_2021_paper.html">MDMMT: Multidomain Multimodal Transformer for Video Retrieval</a></th>
                    </tr>
                
                    <tr id="ccbb9a0c11f707bd15611f0b3f227cf7a8040876">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ccbb9a0c11f707bd15611f0b3f227cf7a8040876">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liang_Flow-Based_Kernel_Prior_With_Application_to_Blind_Super-Resolution_CVPR_2021_paper.html">Flow-Based Kernel Prior With Application to Blind Super-Resolution</a></th>
                    </tr>
                
                    <tr id="0ecd8b34e9dc7df9635821b9329bbe54a19bf5fc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ecd8b34e9dc7df9635821b9329bbe54a19bf5fc">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Towards_Semantic_Segmentation_of_Urban-Scale_3D_Point_Clouds_A_Dataset_CVPR_2021_paper.html">Towards Semantic Segmentation of Urban-Scale 3D Point Clouds: A Dataset, Benchmarks and Challenges</a></th>
                    </tr>
                
                    <tr id="787991d630fbe638aa1c545ebb90ab90b8f8b5c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/787991d630fbe638aa1c545ebb90ab90b8f8b5c0">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/An_ArtFlow_Unbiased_Image_Style_Transfer_via_Reversible_Neural_Flows_CVPR_2021_paper.html">ArtFlow: Unbiased Image Style Transfer via Reversible Neural Flows</a></th>
                    </tr>
                
                    <tr id="1f34aee634327c6d4f13f9018c34df4d3239ecb6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1f34aee634327c6d4f13f9018c34df4d3239ecb6">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ding_Diverse_Branch_Block_Building_a_Convolution_as_an_Inception-Like_Unit_CVPR_2021_paper.html">Diverse Branch Block: Building a Convolution as an Inception-Like Unit</a></th>
                    </tr>
                
                    <tr id="13ee7edff6242c02db698bbfbeb12a638cfd3ad5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/13ee7edff6242c02db698bbfbeb12a638cfd3ad5">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_MonoRUn_Monocular_3D_Object_Detection_by_Reconstruction_and_Uncertainty_Propagation_CVPR_2021_paper.html">MonoRUn: Monocular 3D Object Detection by Reconstruction and Uncertainty Propagation</a></th>
                    </tr>
                
                    <tr id="38de501e09a4a32e6d5e38dc1b2c711d4e0acd96">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38de501e09a4a32e6d5e38dc1b2c711d4e0acd96">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_ST3D_Self-Training_for_Unsupervised_Domain_Adaptation_on_3D_Object_Detection_CVPR_2021_paper.html">ST3D: Self-Training for Unsupervised Domain Adaptation on 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="7ffbc531bbb0f1cf38b47e1d728a0e297f8b4dec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ffbc531bbb0f1cf38b47e1d728a0e297f8b4dec">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dai_Generalizable_Person_Re-Identification_With_Relevance-Aware_Mixture_of_Experts_CVPR_2021_paper.html">Generalizable Person Re-Identification With Relevance-Aware Mixture of Experts</a></th>
                    </tr>
                
                    <tr id="04733e633493d5adc31f5f507ebf54a5e509fae4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/04733e633493d5adc31f5f507ebf54a5e509fae4">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Rizve_Exploring_Complementary_Strengths_of_Invariant_and_Equivariant_Representations_for_Few-Shot_CVPR_2021_paper.html">Exploring Complementary Strengths of Invariant and Equivariant Representations for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="c9e8cb4bb2c8e5d6dd4e631fc347f7f1415f2150">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c9e8cb4bb2c8e5d6dd4e631fc347f7f1415f2150">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Flow-Guided_One-Shot_Talking_Face_Generation_With_a_High-Resolution_Audio-Visual_Dataset_CVPR_2021_paper.html">Flow-Guided One-Shot Talking Face Generation With a High-Resolution Audio-Visual Dataset</a></th>
                    </tr>
                
                    <tr id="bbe7029a82a9cf8a52d393929e3aa224c0060555">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bbe7029a82a9cf8a52d393929e3aa224c0060555">53</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ke_Deep_Occlusion-Aware_Instance_Segmentation_With_Overlapping_BiLayers_CVPR_2021_paper.html">Deep Occlusion-Aware Instance Segmentation with Overlapping BiLayers</a></th>
                    </tr>
                
                    <tr id="b82c9e6f5e588e0ecf7dac5f54baabdd9ee4bbcd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b82c9e6f5e588e0ecf7dac5f54baabdd9ee4bbcd">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_ReNAS_Relativistic_Evaluation_of_Neural_Architecture_Search_CVPR_2021_paper.html">ReNAS: Relativistic Evaluation of Neural Architecture Search</a></th>
                    </tr>
                
                    <tr id="72fe90517d8df2894a955ad01568ab7586495fda">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/72fe90517d8df2894a955ad01568ab7586495fda">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_SimPLE_Similar_Pseudo_Label_Exploitation_for_Semi-Supervised_Classification_CVPR_2021_paper.html">SimPLE: Similar Pseudo Label Exploitation for Semi-Supervised Classification</a></th>
                    </tr>
                
                    <tr id="5960dd670496a6dfc37dac1d0b14b55a17ac527a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5960dd670496a6dfc37dac1d0b14b55a17ac527a">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Afifi_Learning_Multi-Scale_Photo_Exposure_Correction_CVPR_2021_paper.html">Learning Multi-Scale Photo Exposure Correction</a></th>
                    </tr>
                
                    <tr id="19a34d0a79dd2eda93a5c013cb7cdd5f4638c57f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/19a34d0a79dd2eda93a5c013cb7cdd5f4638c57f">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Positional_Encoding_As_Spatial_Inductive_Bias_in_GANs_CVPR_2021_paper.html">Positional Encoding As Spatial Inductive Bias in GANs</a></th>
                    </tr>
                
                    <tr id="1234884eaa12ec566318c498a9e324b29a8cbeab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1234884eaa12ec566318c498a9e324b29a8cbeab">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nishi_Augmentation_Strategies_for_Learning_With_Noisy_Labels_CVPR_2021_paper.html">Augmentation Strategies for Learning With Noisy Labels</a></th>
                    </tr>
                
                    <tr id="40ecf66be02272b5964435e983f8d8e0f1e0705a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/40ecf66be02272b5964435e983f8d8e0f1e0705a">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yao_Cross-Iteration_Batch_Normalization_CVPR_2021_paper.html">Cross-Iteration Batch Normalization</a></th>
                    </tr>
                
                    <tr id="3d3fc7d86c09fd2c2806603d8d553cb7761b7811">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3d3fc7d86c09fd2c2806603d8d553cb7761b7811">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_3D_Human_Action_Representation_Learning_via_Cross-View_Consistency_Pursuit_CVPR_2021_paper.html">3D Human Action Representation Learning via Cross-View Consistency Pursuit</a></th>
                    </tr>
                
                    <tr id="245df7d8e53b3860107edc76b467e055eb80744d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/245df7d8e53b3860107edc76b467e055eb80744d">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Multi-Institutional_Collaborations_for_Improving_Deep_Learning-Based_Magnetic_Resonance_Image_Reconstruction_CVPR_2021_paper.html">Multi-Institutional Collaborations for Improving Deep Learning-Based Magnetic Resonance Image Reconstruction Using Federated Learning</a></th>
                    </tr>
                
                    <tr id="775574ef8f910356421e8624202fb6b70a4e4488">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/775574ef8f910356421e8624202fb6b70a4e4488">52</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Modular_Interactive_Video_Object_Segmentation_Interaction-to-Mask_Propagation_and_Difference-Aware_Fusion_CVPR_2021_paper.html">Modular Interactive Video Object Segmentation: Interaction-to-Mask, Propagation and Difference-Aware Fusion</a></th>
                    </tr>
                
                    <tr id="98ab4fe4d59798b9b9df35c9e7f3a1c2ae757b97">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/98ab4fe4d59798b9b9df35c9e7f3a1c2ae757b97">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Invertible_Denoising_Network_A_Light_Solution_for_Real_Noise_Removal_CVPR_2021_paper.html">Invertible Denoising Network: A Light Solution for Real Noise Removal</a></th>
                    </tr>
                
                    <tr id="42015a24cfb99e87c76cd74860d1fccb265f32fb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/42015a24cfb99e87c76cd74860d1fccb265f32fb">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Patch2Pix_Epipolar-Guided_Pixel-Level_Correspondences_CVPR_2021_paper.html">Patch2Pix: Epipolar-Guided Pixel-Level Correspondences</a></th>
                    </tr>
                
                    <tr id="29eb6a232a9c08651024e5eebdb8e44f084d3d09">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/29eb6a232a9c08651024e5eebdb8e44f084d3d09">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Reformulating_HOI_Detection_As_Adaptive_Set_Prediction_CVPR_2021_paper.html">Reformulating HOI Detection As Adaptive Set Prediction</a></th>
                    </tr>
                
                    <tr id="1bc2232a8d6e210a3ccefc473a414d6d9c08d003">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1bc2232a8d6e210a3ccefc473a414d6d9c08d003">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kong_ClassSR_A_General_Framework_to_Accelerate_Super-Resolution_Networks_by_Data_CVPR_2021_paper.html">ClassSR: A General Framework to Accelerate Super-Resolution Networks by Data Characteristic</a></th>
                    </tr>
                
                    <tr id="b4fe9d6b018d820a82b0710d312af84b585a695b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b4fe9d6b018d820a82b0710d312af84b585a695b">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liang_Domain_Adaptation_With_Auxiliary_Target_Domain-Oriented_Classifier_CVPR_2021_paper.html">Domain Adaptation With Auxiliary Target Domain-Oriented Classifier</a></th>
                    </tr>
                
                    <tr id="75a2bff8da88ab0efcfbc3c032087f007df6080f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/75a2bff8da88ab0efcfbc3c032087f007df6080f">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ye_TPCN_Temporal_Point_Cloud_Networks_for_Motion_Forecasting_CVPR_2021_paper.html">TPCN: Temporal Point Cloud Networks for Motion Forecasting</a></th>
                    </tr>
                
                    <tr id="536eed27be9162436358f1e55e4fd9931037cdf2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/536eed27be9162436358f1e55e4fd9931037cdf2">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ma_SCALE_Modeling_Clothed_Humans_with_a_Surface_Codec_of_Articulated_CVPR_2021_paper.html">SCALE: Modeling Clothed Humans with a Surface Codec of Articulated Local Elements</a></th>
                    </tr>
                
                    <tr id="01637f04eac8523b6c4887d419bd718f65860982">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01637f04eac8523b6c4887d419bd718f65860982">51</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Removing_the_Background_by_Adding_the_Background_Towards_Background_Robust_CVPR_2021_paper.html">Removing the Background by Adding the Background: Towards Background Robust Self-Supervised Video Representation Learning</a></th>
                    </tr>
                
                    <tr id="1615180831ce2e5bfed0583c6d83e3ae84d003e0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1615180831ce2e5bfed0583c6d83e3ae84d003e0">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Monocular_3D_Object_Detection_An_Extrinsic_Parameter_Free_Approach_CVPR_2021_paper.html">Monocular 3D Object Detection: An Extrinsic Parameter Free Approach</a></th>
                    </tr>
                
                    <tr id="5a68d41046b1fdc4cab5aa23e2045d7ee7246f6d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5a68d41046b1fdc4cab5aa23e2045d7ee7246f6d">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Deep_Implicit_Templates_for_3D_Shape_Representation_CVPR_2021_paper.html">Deep Implicit Templates for 3D Shape Representation</a></th>
                    </tr>
                
                    <tr id="6262cbb1089024b6bf1be579d33f70dd04a7fd07">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6262cbb1089024b6bf1be579d33f70dd04a7fd07">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Interactive_Self-Training_With_Mean_Teachers_for_Semi-Supervised_Object_Detection_CVPR_2021_paper.html">Interactive Self-Training With Mean Teachers for Semi-Supervised Object Detection</a></th>
                    </tr>
                
                    <tr id="1564ee7e4d0d17177b4c199a22ba9783e16a785e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1564ee7e4d0d17177b4c199a22ba9783e16a785e">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_One_Shot_Face_Swapping_on_Megapixels_CVPR_2021_paper.html">One Shot Face Swapping on Megapixels</a></th>
                    </tr>
                
                    <tr id="6bd247938c4067bf94c12462cd0501912cb2ccdb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6bd247938c4067bf94c12462cd0501912cb2ccdb">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wei_Unsupervised_Real-World_Image_Super_Resolution_via_Domain-Distance_Aware_Training_CVPR_2021_paper.html">Unsupervised Real-World Image Super Resolution via Domain-Distance Aware Training</a></th>
                    </tr>
                
                    <tr id="f6b813c336525704f1427a5b1c5d740c5496df1d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f6b813c336525704f1427a5b1c5d740c5496df1d">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nan_Interventional_Video_Grounding_With_Dual_Contrastive_Learning_CVPR_2021_paper.html">Interventional Video Grounding With Dual Contrastive Learning</a></th>
                    </tr>
                
                    <tr id="ae713ed2c0c65ae98a5fd7a576214cfd2cd03f63">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae713ed2c0c65ae98a5fd7a576214cfd2cd03f63">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_NBNet_Noise_Basis_Learning_for_Image_Denoising_With_Subspace_Projection_CVPR_2021_paper.html">NBNet: Noise Basis Learning for Image Denoising With Subspace Projection</a></th>
                    </tr>
                
                    <tr id="17434687858b8c90a9d2a96c7e9141a3d009a875">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/17434687858b8c90a9d2a96c7e9141a3d009a875">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ling_Region-Aware_Adaptive_Instance_Normalization_for_Image_Harmonization_CVPR_2021_paper.html">Region-Aware Adaptive Instance Normalization for Image Harmonization</a></th>
                    </tr>
                
                    <tr id="89bf75817b118f75cae61efcfc7656f96e8a63a4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/89bf75817b118f75cae61efcfc7656f96e8a63a4">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_One_Thing_One_Click_A_Self-Training_Approach_for_Weakly_Supervised_CVPR_2021_paper.html">One Thing One Click: A Self-Training Approach for Weakly Supervised 3D Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="1f089508bbcd0a5c083cb6077adb133774eca5d7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1f089508bbcd0a5c083cb6077adb133774eca5d7">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sverrisson_Fast_End-to-End_Learning_on_Protein_Surfaces_CVPR_2021_paper.html">Fast End-to-End Learning on Protein Surfaces</a></th>
                    </tr>
                
                    <tr id="540f718e7d085fadfcce0c7649ab604a36995776">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/540f718e7d085fadfcce0c7649ab604a36995776">50</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dai_Learning_a_Proposal_Classifier_for_Multiple_Object_Tracking_CVPR_2021_paper.html">Learning a Proposal Classifier for Multiple Object Tracking</a></th>
                    </tr>
                
                    <tr id="47b5b4c7d00cfcd980f67e62ed4f27193c088296">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47b5b4c7d00cfcd980f67e62ed4f27193c088296">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Deep_Analysis_of_CNN-Based_Spatio-Temporal_Representations_for_Action_Recognition_CVPR_2021_paper.html">Deep Analysis of CNN-Based Spatio-Temporal Representations for Action Recognition</a></th>
                    </tr>
                
                    <tr id="12a1598a2861c647f0551454f8cbb2b1d55917b8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/12a1598a2861c647f0551454f8cbb2b1d55917b8">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pan_Actor-Context-Actor_Relation_Network_for_Spatio-Temporal_Action_Localization_CVPR_2021_paper.html">Actor-Context-Actor Relation Network for Spatio-Temporal Action Localization</a></th>
                    </tr>
                
                    <tr id="2e59a0d9af25e26c2481096fd1dc6202826606cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e59a0d9af25e26c2481096fd1dc6202826606cc">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Embedded_Discriminative_Attention_Mechanism_for_Weakly_Supervised_Semantic_Segmentation_CVPR_2021_paper.html">Embedded Discriminative Attention Mechanism for Weakly Supervised Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="645262cf43f7b94eb63022fc71af3c977480a9fe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/645262cf43f7b94eb63022fc71af3c977480a9fe">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xiao_Dynamic_Weighted_Learning_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html">Dynamic Weighted Learning for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="9960d13255259c66812dd130e08c17720ff60c18">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9960d13255259c66812dd130e08c17720ff60c18">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ni_M3P_Learning_Universal_Representations_via_Multitask_Multilingual_Multimodal_Pre-Training_CVPR_2021_paper.html">M3P: Learning Universal Representations via Multitask Multilingual Multimodal Pre-Training</a></th>
                    </tr>
                
                    <tr id="d9e8ac993cd75c1ab9364ba30a86444f2537a9c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d9e8ac993cd75c1ab9364ba30a86444f2537a9c4">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_SimPoE_Simulated_Character_Control_for_3D_Human_Pose_Estimation_CVPR_2021_paper.html">SimPoE: Simulated Character Control for 3D Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="45b98ccc785f9ef7e6b7c98b88ec770b49828dd2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/45b98ccc785f9ef7e6b7c98b88ec770b49828dd2">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_UAV-Human_A_Large_Benchmark_for_Human_Behavior_Understanding_With_Unmanned_CVPR_2021_paper.html">UAV-Human: A Large Benchmark for Human Behavior Understanding With Unmanned Aerial Vehicles</a></th>
                    </tr>
                
                    <tr id="1d6a611e30c2783859b687684135475dd2aff963">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d6a611e30c2783859b687684135475dd2aff963">49</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wan_A_Generalized_Loss_Function_for_Crowd_Counting_and_Localization_CVPR_2021_paper.html">A Generalized Loss Function for Crowd Counting and Localization</a></th>
                    </tr>
                
                    <tr id="ffba7fc5a4b350d50c406b8e52a57cc31ac971dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ffba7fc5a4b350d50c406b8e52a57cc31ac971dd">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lassner_Pulsar_Efficient_Sphere-Based_Neural_Rendering_CVPR_2021_paper.html">Pulsar: Efficient Sphere-Based Neural Rendering</a></th>
                    </tr>
                
                    <tr id="a34903e70832bd2cac64a84464c6ff6d2a2c7124">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a34903e70832bd2cac64a84464c6ff6d2a2c7124">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/She_Dive_Into_Ambiguity_Latent_Distribution_Mining_and_Pairwise_Uncertainty_Estimation_CVPR_2021_paper.html">Dive Into Ambiguity: Latent Distribution Mining and Pairwise Uncertainty Estimation for Facial Expression Recognition</a></th>
                    </tr>
                
                    <tr id="e61c4f9f6c10e5c65aa7ab4b6e12e0c7afaf1f16">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e61c4f9f6c10e5c65aa7ab4b6e12e0c7afaf1f16">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_DoDNet_Learning_To_Segment_Multi-Organ_and_Tumors_From_Multiple_Partially_CVPR_2021_paper.html">DoDNet: Learning To Segment Multi-Organ and Tumors From Multiple Partially Labeled Datasets</a></th>
                    </tr>
                
                    <tr id="98710344620c8f7c3a61e7cb18db8e1c9da3a351">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/98710344620c8f7c3a61e7cb18db8e1c9da3a351">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Michieli_Continual_Semantic_Segmentation_via_Repulsion-Attraction_of_Sparse_and_Disentangled_Latent_CVPR_2021_paper.html">Continual Semantic Segmentation via Repulsion-Attraction of Sparse and Disentangled Latent Representations</a></th>
                    </tr>
                
                    <tr id="4ba19d402c3067dd63224f4267bc1f7a574a9379">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ba19d402c3067dd63224f4267bc1f7a574a9379">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tartaglione_EnD_Entangling_and_Disentangling_Deep_Representations_for_Bias_Correction_CVPR_2021_paper.html">EnD: Entangling and Disentangling Deep Representations for Bias Correction</a></th>
                    </tr>
                
                    <tr id="39e502f7d74eeb041601d7d6e165f324e194c5dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39e502f7d74eeb041601d7d6e165f324e194c5dd">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hasan_Generalizable_Pedestrian_Detection_The_Elephant_in_the_Room_CVPR_2021_paper.html">Generalizable Pedestrian Detection: The Elephant in the Room</a></th>
                    </tr>
                
                    <tr id="c0a17e62bb45de3e3d9ae835b86796af08949e9f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c0a17e62bb45de3e3d9ae835b86796af08949e9f">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Auto-Exposure_Fusion_for_Single-Image_Shadow_Removal_CVPR_2021_paper.html">Auto-Exposure Fusion for Single-Image Shadow Removal</a></th>
                    </tr>
                
                    <tr id="4ef921f4f61f5463bd51ed9f4c1cf56a121311e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ef921f4f61f5463bd51ed9f4c1cf56a121311e3">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_BBAM_Bounding_Box_Attribution_Map_for_Weakly_Supervised_Semantic_and_CVPR_2021_paper.html">BBAM: Bounding Box Attribution Map for Weakly Supervised Semantic and Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="0887d1edc0a9c7a0e0ed60e8c4d22406af679b64">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0887d1edc0a9c7a0e0ed60e8c4d22406af679b64">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ge_Parser-Free_Virtual_Try-On_via_Distilling_Appearance_Flows_CVPR_2021_paper.html">Parser-Free Virtual Try-On via Distilling Appearance Flows</a></th>
                    </tr>
                
                    <tr id="d64945650501eaccd842ed5f93fe0e8932cac50c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d64945650501eaccd842ed5f93fe0e8932cac50c">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_Checkerboard_Context_Model_for_Efficient_Learned_Image_Compression_CVPR_2021_paper.html">Checkerboard Context Model for Efficient Learned Image Compression</a></th>
                    </tr>
                
                    <tr id="6500df35e30461d857103b3e3fa72b2913049a56">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6500df35e30461d857103b3e3fa72b2913049a56">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Weihs_Visual_Room_Rearrangement_CVPR_2021_paper.html">Visual Room Rearrangement</a></th>
                    </tr>
                
                    <tr id="e09e44fd1812444c950b7ffbc5716365d7e22219">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e09e44fd1812444c950b7ffbc5716365d7e22219">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Point_4D_Transformer_Networks_for_Spatio-Temporal_Modeling_in_Point_Cloud_CVPR_2021_paper.html">Point 4D Transformer Networks for Spatio-Temporal Modeling in Point Cloud Videos</a></th>
                    </tr>
                
                    <tr id="47d62aff50c6cc27c2718d918c5b666ce6fcff08">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47d62aff50c6cc27c2718d918c5b666ce6fcff08">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Roh_Spatially_Consistent_Representation_Learning_CVPR_2021_paper.html">Spatially Consistent Representation Learning</a></th>
                    </tr>
                
                    <tr id="094b1c9bfd4ae833bac080032cd91813da42ee17">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/094b1c9bfd4ae833bac080032cd91813da42ee17">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wandt_CanonPose_Self-Supervised_Monocular_3D_Human_Pose_Estimation_in_the_Wild_CVPR_2021_paper.html">CanonPose: Self-Supervised Monocular 3D Human Pose Estimation in the Wild</a></th>
                    </tr>
                
                    <tr id="3b65b8ed14ccb6ed102e0290adc57d00e27218c9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3b65b8ed14ccb6ed102e0290adc57d00e27218c9">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Truong_Learning_Accurate_Dense_Correspondences_and_When_To_Trust_Them_CVPR_2021_paper.html">Learning Accurate Dense Correspondences and When To Trust Them</a></th>
                    </tr>
                
                    <tr id="afa76fedf8701e057b2bf7a228bf41980ac2d1c9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/afa76fedf8701e057b2bf7a228bf41980ac2d1c9">48</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_RSTNet_Captioning_With_Adaptive_Attention_on_Visual_and_Non-Visual_Words_CVPR_2021_paper.html">RSTNet: Captioning with Adaptive Attention on Visual and Non-Visual Words</a></th>
                    </tr>
                
                    <tr id="2f287d9a3658152385e1714b7aa784f3ca1b1296">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2f287d9a3658152385e1714b7aa784f3ca1b1296">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Paredes-Valles_Back_to_Event_Basics_Self-Supervised_Learning_of_Image_Reconstruction_for_CVPR_2021_paper.html">Back to Event Basics: Self-Supervised Learning of Image Reconstruction for Event Cameras via Photometric Constancy</a></th>
                    </tr>
                
                    <tr id="998b6103c4dac7c05c35cd9537b0ccd267060da6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/998b6103c4dac7c05c35cd9537b0ccd267060da6">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Learning_Dynamic_Alignment_via_Meta-Filter_for_Few-Shot_Learning_CVPR_2021_paper.html">Learning Dynamic Alignment via Meta-Filter for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="667faaae364b2aa2404276fe1f71d52e24f07f04">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/667faaae364b2aa2404276fe1f71d52e24f07f04">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Dynamic_Slimmable_Network_CVPR_2021_paper.html">Dynamic Slimmable Network</a></th>
                    </tr>
                
                    <tr id="6518b0e6334c6ffb9b94c551c57ad79c7008cbb5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6518b0e6334c6ffb9b94c551c57ad79c7008cbb5">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/S_Uncertainty_Reduction_for_Model_Adaptation_in_Semantic_Segmentation_CVPR_2021_paper.html">Uncertainty Reduction for Model Adaptation in Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="0592b3df99b9fd032e7adf94727a58aaf66bef38">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0592b3df99b9fd032e7adf94727a58aaf66bef38">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_DCNAS_Densely_Connected_Neural_Architecture_Search_for_Semantic_Image_Segmentation_CVPR_2021_paper.html">DCNAS: Densely Connected Neural Architecture Search for Semantic Image Segmentation</a></th>
                    </tr>
                
                    <tr id="1c757868d20742d9105df6858665183a8c8e133c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1c757868d20742d9105df6858665183a8c8e133c">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Learning_Compositional_Radiance_Fields_of_Dynamic_Human_Heads_CVPR_2021_paper.html">Learning Compositional Radiance Fields of Dynamic Human Heads</a></th>
                    </tr>
                
                    <tr id="7131aa4e3ac52618891a837db5ba9aed02d5d21a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7131aa4e3ac52618891a837db5ba9aed02d5d21a">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gong_PoseAug_A_Differentiable_Pose_Augmentation_Framework_for_3D_Human_Pose_CVPR_2021_paper.html">PoseAug: A Differentiable Pose Augmentation Framework for 3D Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="2d862044d74662fd5428a05ee220f71b659db1ed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d862044d74662fd5428a05ee220f71b659db1ed">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Dual_Attention_Suppression_Attack_Generate_Adversarial_Camouflage_in_Physical_World_CVPR_2021_paper.html">Dual Attention Suppression Attack: Generate Adversarial Camouflage in Physical World</a></th>
                    </tr>
                
                    <tr id="069acdd03090c794c0867a76e286ede90f6b9e30">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/069acdd03090c794c0867a76e286ede90f6b9e30">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yenamandra_i3DMM_Deep_Implicit_3D_Morphable_Model_of_Human_Heads_CVPR_2021_paper.html">i3DMM: Deep Implicit 3D Morphable Model of Human Heads</a></th>
                    </tr>
                
                    <tr id="aa1b109f7d3d7e64b5fc539ce7d2642fb8972c8d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aa1b109f7d3d7e64b5fc539ce7d2642fb8972c8d">47</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Manifold_Regularized_Dynamic_Network_Pruning_CVPR_2021_paper.html">Manifold Regularized Dynamic Network Pruning</a></th>
                    </tr>
                
                    <tr id="d63e4d867d97b7de9eec6d86b25c067c0dc29489">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d63e4d867d97b7de9eec6d86b25c067c0dc29489">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Exponential_Moving_Average_Normalization_for_Self-Supervised_and_Semi-Supervised_Learning_CVPR_2021_paper.html">Exponential Moving Average Normalization for Self-Supervised and Semi-Supervised Learning</a></th>
                    </tr>
                
                    <tr id="6e90cabc26b345b595b1572383fc23fa903d9f35">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6e90cabc26b345b595b1572383fc23fa903d9f35">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Hallucination_Improves_Few-Shot_Object_Detection_CVPR_2021_paper.html">Hallucination Improves Few-Shot Object Detection</a></th>
                    </tr>
                
                    <tr id="d128dde66b604534465c13e603b26762797c0138">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d128dde66b604534465c13e603b26762797c0138">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yao_Jo-SRC_A_Contrastive_Approach_for_Combating_Noisy_Labels_CVPR_2021_paper.html">Jo-SRC: A Contrastive Approach for Combating Noisy Labels</a></th>
                    </tr>
                
                    <tr id="1e1d697d5d00c77b010c2eb5b90e0e5d773bf3f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1e1d697d5d00c77b010c2eb5b90e0e5d773bf3f2">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Rethinking_the_Heatmap_Regression_for_Bottom-Up_Human_Pose_Estimation_CVPR_2021_paper.html">Rethinking the Heatmap Regression for Bottom-Up Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="07a3676fac0208133639993f8a3c3d87ac33bcda">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/07a3676fac0208133639993f8a3c3d87ac33bcda">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Naeem_Learning_Graph_Embeddings_for_Compositional_Zero-Shot_Learning_CVPR_2021_paper.html">Learning Graph Embeddings for Compositional Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="1941a6e2d4fd61b63d1df518a40cb47cab19c0e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1941a6e2d4fd61b63d1df518a40cb47cab19c0e6">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Semantic_Audio-Visual_Navigation_CVPR_2021_paper.html">Semantic Audio-Visual Navigation</a></th>
                    </tr>
                
                    <tr id="2fbcd7f1705105c4e94dce7a3f35440c79db5724">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2fbcd7f1705105c4e94dce7a3f35440c79db5724">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Cross-Modal_Collaborative_Representation_Learning_and_a_Large-Scale_RGBT_Benchmark_for_CVPR_2021_paper.html">Cross-Modal Collaborative Representation Learning and a Large-Scale RGBT Benchmark for Crowd Counting</a></th>
                    </tr>
                
                    <tr id="94655c1a6b94438439658a3b95b7bfbf7b6aebd9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/94655c1a6b94438439658a3b95b7bfbf7b6aebd9">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gong_Mitigating_Face_Recognition_Bias_via_Group_Adaptive_Classifier_CVPR_2021_paper.html">Mitigating Face Recognition Bias via Group Adaptive Classifier</a></th>
                    </tr>
                
                    <tr id="a9dc44231239ef010dc2617bc4c373c00e4bee72">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a9dc44231239ef010dc2617bc4c373c00e4bee72">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Topological_Planning_With_Transformers_for_Vision-and-Language_Navigation_CVPR_2021_paper.html">Topological Planning With Transformers for Vision-and-Language Navigation</a></th>
                    </tr>
                
                    <tr id="05c77ccfc785abd31f38f3b46bafb81f786f871f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05c77ccfc785abd31f38f3b46bafb81f786f871f">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Uncertainty-Aware_Joint_Salient_Object_and_Camouflaged_Object_Detection_CVPR_2021_paper.html">Uncertainty-Aware Joint Salient Object and Camouflaged Object Detection</a></th>
                    </tr>
                
                    <tr id="428b671d9b5e5f571497ce164e205e1a130cd068">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/428b671d9b5e5f571497ce164e205e1a130cd068">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_We_Are_More_Than_Our_Joints_Predicting_How_3D_Bodies_CVPR_2021_paper.html">We Are More Than Our Joints: Predicting How 3D Bodies Move</a></th>
                    </tr>
                
                    <tr id="0a3efe0cf3ddb0ddbb560e4ebb01ff9626982ee5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a3efe0cf3ddb0ddbb560e4ebb01ff9626982ee5">46</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Bidirectional_Projection_Network_for_Cross_Dimension_Scene_Understanding_CVPR_2021_paper.html">Bidirectional Projection Network for Cross Dimension Scene Understanding</a></th>
                    </tr>
                
                    <tr id="3f62ee37fa21b8e1de9b1d3c948f349720423d0d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f62ee37fa21b8e1de9b1d3c948f349720423d0d">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Song_AdderSR_Towards_Energy_Efficient_Image_Super-Resolution_CVPR_2021_paper.html">AdderSR: Towards Energy Efficient Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="61dbbff771eee236a1116e69fab3674529fc3cc7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61dbbff771eee236a1116e69fab3674529fc3cc7">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Regularizing_Neural_Networks_via_Adversarial_Model_Perturbation_CVPR_2021_paper.html">Regularizing Neural Networks via Adversarial Model Perturbation</a></th>
                    </tr>
                
                    <tr id="2309f2c7db994dc8aeb1da3288cdf75dc8ec0194">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2309f2c7db994dc8aeb1da3288cdf75dc8ec0194">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Unsupervised_Pre-Training_for_Person_Re-Identification_CVPR_2021_paper.html">Unsupervised Pre-Training for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="b44313836f435c8c774f9123cc29a38ad8deb7bd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b44313836f435c8c774f9123cc29a38ad8deb7bd">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Di_Biase_Pixel-Wise_Anomaly_Detection_in_Complex_Driving_Scenes_CVPR_2021_paper.html">Pixel-Wise Anomaly Detection in Complex Driving Scenes</a></th>
                    </tr>
                
                    <tr id="f8b1f0ba84b4684e4f523f9baf1fbf3924f08368">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f8b1f0ba84b4684e4f523f9baf1fbf3924f08368">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Choi_VITON-HD_High-Resolution_Virtual_Try-On_via_Misalignment-Aware_Normalization_CVPR_2021_paper.html">VITON-HD: High-Resolution Virtual Try-On via Misalignment-Aware Normalization</a></th>
                    </tr>
                
                    <tr id="3e86599d179ae530a31e6a7012c15777c88f21d1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3e86599d179ae530a31e6a7012c15777c88f21d1">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yan_LightTrack_Finding_Lightweight_Neural_Networks_for_Object_Tracking_via_One-Shot_CVPR_2021_paper.html">LightTrack: Finding Lightweight Neural Networks for Object Tracking via One-Shot Architecture Search</a></th>
                    </tr>
                
                    <tr id="26a8e0c99574ade64b9c02a69cb0df1c8c840c50">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26a8e0c99574ade64b9c02a69cb0df1c8c840c50">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liao_Image_Inpainting_Guided_by_Coherence_Priors_of_Semantics_and_Textures_CVPR_2021_paper.html">Image Inpainting Guided by Coherence Priors of Semantics and Textures</a></th>
                    </tr>
                
                    <tr id="2c5d0dc8798563c6adc27050ac60120e43f0c956">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c5d0dc8798563c6adc27050ac60120e43f0c956">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Style-Based_Point_Generator_With_Adversarial_Rendering_for_Point_Cloud_Completion_CVPR_2021_paper.html">Style-Based Point Generator With Adversarial Rendering for Point Cloud Completion</a></th>
                    </tr>
                
                    <tr id="1ee89af0c5fc6255e255c90dbd4d95576a2d58f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ee89af0c5fc6255e255c90dbd4d95576a2d58f9">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Morgado_Robust_Audio-Visual_Instance_Discrimination_CVPR_2021_paper.html">Robust Audio-Visual Instance Discrimination</a></th>
                    </tr>
                
                    <tr id="1cb314bbc7eec504d29632941331e3eaef9a82b0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1cb314bbc7eec504d29632941331e3eaef9a82b0">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Deep_Gaussian_Scale_Mixture_Prior_for_Spectral_Compressive_Imaging_CVPR_2021_paper.html">Deep Gaussian Scale Mixture Prior for Spectral Compressive Imaging</a></th>
                    </tr>
                
                    <tr id="11fcbc38b3fc4cf9f17dcd4b97e15b84c283c9f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/11fcbc38b3fc4cf9f17dcd4b97e15b84c283c9f5">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Choi_Meta_Batch-Instance_Normalization_for_Generalizable_Person_Re-Identification_CVPR_2021_paper.html">Meta Batch-Instance Normalization for Generalizable Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="32fb3dd5601977cb8d6de6ffa12f223ad3097d71">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/32fb3dd5601977cb8d6de6ffa12f223ad3097d71">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_SelfDoc_Self-Supervised_Document_Representation_Learning_CVPR_2021_paper.html">SelfDoc: Self-Supervised Document Representation Learning</a></th>
                    </tr>
                
                    <tr id="bd807fdada8eb0d5e003b237338c3100acfc409b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bd807fdada8eb0d5e003b237338c3100acfc409b">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Neural_Feature_Search_for_RGB-Infrared_Person_Re-Identification_CVPR_2021_paper.html">Neural Feature Search for RGB-Infrared Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="70116719b7e4d8f5dfe9729b37bebb3e731f0dd2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70116719b7e4d8f5dfe9729b37bebb3e731f0dd2">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_DANNet_A_One-Stage_Domain_Adaptation_Network_for_Unsupervised_Nighttime_Semantic_CVPR_2021_paper.html">DANNet: A One-Stage Domain Adaptation Network for Unsupervised Nighttime Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="55cd31f1a88f4d53152aad8fa3fe1cec17b59f68">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/55cd31f1a88f4d53152aad8fa3fe1cec17b59f68">45</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Paschalidou_Neural_Parts_Learning_Expressive_3D_Shape_Abstractions_With_Invertible_Neural_CVPR_2021_paper.html">Neural Parts: Learning Expressive 3D Shape Abstractions With Invertible Neural Networks</a></th>
                    </tr>
                
                    <tr id="8af459df7b775ee53a69c69dea6643e644bcba70">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8af459df7b775ee53a69c69dea6643e644bcba70">45</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Stojnic_Self-Supervised_Learning_of_Remote_Sensing_Scene_Representations_Using_Contrastive_Multiview_CVPRW_2021_paper.html">Self-Supervised Learning of Remote Sensing Scene Representations Using Contrastive Multiview Coding</a></th>
                    </tr>
                
                    <tr id="066ab4e4128979fb199ecdaf1a8a4c5c52963057">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/066ab4e4128979fb199ecdaf1a8a4c5c52963057">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gong_KeepAugment_A_Simple_Information-Preserving_Data_Augmentation_Approach_CVPR_2021_paper.html">KeepAugment: A Simple Information-Preserving Data Augmentation Approach</a></th>
                    </tr>
                
                    <tr id="7bd363db6630e5e908c989f4c10661abf2f09f85">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7bd363db6630e5e908c989f4c10661abf2f09f85">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yue_Prototypical_Cross-Domain_Self-Supervised_Learning_for_Few-Shot_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html">Prototypical Cross-Domain Self-Supervised Learning for Few-Shot Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="d1485d298906364c4434454d25c0ed4389420892">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d1485d298906364c4434454d25c0ed4389420892">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Large-Capacity_Image_Steganography_Based_on_Invertible_Neural_Networks_CVPR_2021_paper.html">Large-Capacity Image Steganography Based on Invertible Neural Networks</a></th>
                    </tr>
                
                    <tr id="3c42954c4e57758baead679717388deea49b2cfd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3c42954c4e57758baead679717388deea49b2cfd">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Ultra-High-Definition_Image_Dehazing_via_Multi-Guided_Bilateral_Learning_CVPR_2021_paper.html">Ultra-High-Definition Image Dehazing via Multi-Guided Bilateral Learning</a></th>
                    </tr>
                
                    <tr id="b7fedec1bd1ca479fda8314a107cac10c89ad7e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b7fedec1bd1ca479fda8314a107cac10c89ad7e3">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Learning_Position_and_Target_Consistency_for_Memory-Based_Video_Object_Segmentation_CVPR_2021_paper.html">Learning Position and Target Consistency for Memory-Based Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="80848ccfc8d88b3230fff07c834d23c28f2d3364">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/80848ccfc8d88b3230fff07c834d23c28f2d3364">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bhat_Deep_Burst_Super-Resolution_CVPR_2021_paper.html">Deep Burst Super-Resolution</a></th>
                    </tr>
                
                    <tr id="778a9ea322b8ef56c93f7f2aeb1402b54aa443fa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/778a9ea322b8ef56c93f7f2aeb1402b54aa443fa">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cordonnier_Differentiable_Patch_Selection_for_Image_Recognition_CVPR_2021_paper.html">Differentiable Patch Selection for Image Recognition</a></th>
                    </tr>
                
                    <tr id="9b175ff0549462007d050680b1ae46fe9dbf4bea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9b175ff0549462007d050680b1ae46fe9dbf4bea">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shi_SGCN_Sparse_Graph_Convolution_Network_for_Pedestrian_Trajectory_Prediction_CVPR_2021_paper.html">SGCN: Sparse Graph Convolution Network for Pedestrian Trajectory Prediction</a></th>
                    </tr>
                
                    <tr id="6ba27b38f82052fd450091cd25fbf1ec92ddf79e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6ba27b38f82052fd450091cd25fbf1ec92ddf79e">44</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Image-to-Image_Translation_via_Hierarchical_Style_Disentanglement_CVPR_2021_paper.html">Image-to-Image Translation via Hierarchical Style Disentanglement</a></th>
                    </tr>
                
                    <tr id="24aaaf2010f764bafdce49eca95cc31f0eec0e70">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/24aaaf2010f764bafdce49eca95cc31f0eec0e70">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Golatkar_Mixed-Privacy_Forgetting_in_Deep_Networks_CVPR_2021_paper.html">Mixed-Privacy Forgetting in Deep Networks</a></th>
                    </tr>
                
                    <tr id="f09826d6ce8b11cf425793853a708b6d107bb79d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f09826d6ce8b11cf425793853a708b6d107bb79d">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Singh_TextOCR_Towards_Large-Scale_End-to-End_Reasoning_for_Arbitrary-Shaped_Scene_Text_CVPR_2021_paper.html">TextOCR: Towards Large-Scale End-to-End Reasoning for Arbitrary-Shaped Scene Text</a></th>
                    </tr>
                
                    <tr id="287e82b08cc5b8c8aae03825b466fcb73860b0c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/287e82b08cc5b8c8aae03825b466fcb73860b0c4">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Truong_Data-Free_Model_Extraction_CVPR_2021_paper.html">Data-Free Model Extraction</a></th>
                    </tr>
                
                    <tr id="80ac12b2de9685a753b069bb36ad250ba842b872">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/80ac12b2de9685a753b069bb36ad250ba842b872">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_DivCo_Diverse_Conditional_Image_Synthesis_via_Contrastive_Generative_Adversarial_Network_CVPR_2021_paper.html">DivCo: Diverse Conditional Image Synthesis via Contrastive Generative Adversarial Network</a></th>
                    </tr>
                
                    <tr id="6c7c7dbbb703689285a61ec3a5d43857d53021ea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c7c7dbbb703689285a61ec3a5d43857d53021ea">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Improving_Multiple_Object_Tracking_With_Single_Object_Tracking_CVPR_2021_paper.html">Improving Multiple Object Tracking With Single Object Tracking</a></th>
                    </tr>
                
                    <tr id="88ce9fb5fe020092bfc576f63ebb382aaf9a4905">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/88ce9fb5fe020092bfc576f63ebb382aaf9a4905">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Selvaraju_CASTing_Your_Model_Learning_To_Localize_Improves_Self-Supervised_Representations_CVPR_2021_paper.html">CASTing Your Model: Learning To Localize Improves Self-Supervised Representations</a></th>
                    </tr>
                
                    <tr id="59969ec4a68dbca4144b66b9f496ab86af4ebce5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/59969ec4a68dbca4144b66b9f496ab86af4ebce5">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Duarte_How2Sign_A_Large-Scale_Multimodal_Dataset_for_Continuous_American_Sign_Language_CVPR_2021_paper.html">How2Sign: A Large-Scale Multimodal Dataset for Continuous American Sign Language</a></th>
                    </tr>
                
                    <tr id="8d908939833f8bef1ee0c2820f546aca6bc947b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8d908939833f8bef1ee0c2820f546aca6bc947b5">43</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_PSD_Principled_Synthetic-to-Real_Dehazing_Guided_by_Physical_Priors_CVPR_2021_paper.html">PSD: Principled Synthetic-to-Real Dehazing Guided by Physical Priors</a></th>
                    </tr>
                
                    <tr id="70a79ded7818ba8ae807102b00643e331e344ee8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70a79ded7818ba8ae807102b00643e331e344ee8">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_UC2_Universal_Cross-Lingual_Cross-Modal_Vision-and-Language_Pre-Training_CVPR_2021_paper.html">UC2: Universal Cross-Lingual Cross-Modal Vision-and-Language Pre-Training</a></th>
                    </tr>
                
                    <tr id="e850d04207d87734991a8441d6fbe5f8cc3b18ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e850d04207d87734991a8441d6fbe5f8cc3b18ce">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Raj_ANR_Articulated_Neural_Rendering_for_Virtual_Avatars_CVPR_2021_paper.html">ANR: Articulated Neural Rendering for Virtual Avatars</a></th>
                    </tr>
                
                    <tr id="86b017d5081c4a41ad5e1e4de6f863532e2e4aea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/86b017d5081c4a41ad5e1e4de6f863532e2e4aea">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hassan_Populating_3D_Scenes_by_Learning_Human-Scene_Interaction_CVPR_2021_paper.html">Populating 3D Scenes by Learning Human-Scene Interaction</a></th>
                    </tr>
                
                    <tr id="b69b60445fa0d5093b6aebb3372afcaa79b01585">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b69b60445fa0d5093b6aebb3372afcaa79b01585">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Melas-Kyriazi_PixMatch_Unsupervised_Domain_Adaptation_via_Pixelwise_Consistency_Training_CVPR_2021_paper.html">PixMatch: Unsupervised Domain Adaptation via Pixelwise Consistency Training</a></th>
                    </tr>
                
                    <tr id="e34ba5f2eeb8c39ee8369f66df9798648ede3e5a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e34ba5f2eeb8c39ee8369f66df9798648ede3e5a">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Towards_Long-Form_Video_Understanding_CVPR_2021_paper.html">Towards Long-Form Video Understanding</a></th>
                    </tr>
                
                    <tr id="49181f7eb7e39c566fabbe8a2ffcae2496b0f47a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/49181f7eb7e39c566fabbe8a2ffcae2496b0f47a">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Du_Cross-Domain_Gradient_Discrepancy_Minimization_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html">Cross-Domain Gradient Discrepancy Minimization for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="30e9137438408de1aeafb9edd3aba35c9cf14ff2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/30e9137438408de1aeafb9edd3aba35c9cf14ff2">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Neighborhood_Contrastive_Learning_for_Novel_Class_Discovery_CVPR_2021_paper.html">Neighborhood Contrastive Learning for Novel Class Discovery</a></th>
                    </tr>
                
                    <tr id="2916938cced9c4936fe7b6f9cc65f1ee3fcc4f47">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2916938cced9c4936fe7b6f9cc65f1ee3fcc4f47">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_SwiftNet_Real-Time_Video_Object_Segmentation_CVPR_2021_paper.html">SwiftNet: Real-Time Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="763eb8707c26347c259f6523c22e4590fec69306">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/763eb8707c26347c259f6523c22e4590fec69306">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shu_Open_Domain_Generalization_with_Domain-Augmented_Meta-Learning_CVPR_2021_paper.html">Open Domain Generalization with Domain-Augmented Meta-Learning</a></th>
                    </tr>
                
                    <tr id="0e3be473c72d9449d13dace5c9c21d9310163630">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e3be473c72d9449d13dace5c9c21d9310163630">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Dynamic_Region-Aware_Convolution_CVPR_2021_paper.html">Dynamic Region-Aware Convolution</a></th>
                    </tr>
                
                    <tr id="bb062e251ab0eea25de4d90c7a6896009030d36b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bb062e251ab0eea25de4d90c7a6896009030d36b">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Que_VoxelContext-Net_An_Octree_Based_Framework_for_Point_Cloud_Compression_CVPR_2021_paper.html">VoxelContext-Net: An Octree Based Framework for Point Cloud Compression</a></th>
                    </tr>
                
                    <tr id="5e9a9710674de21b00ea7ca32efe9a82c7ce1b88">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5e9a9710674de21b00ea7ca32efe9a82c7ce1b88">42</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Cycle4Completion_Unpaired_Point_Cloud_Completion_Using_Cycle_Transformation_With_Missing_CVPR_2021_paper.html">Cycle4Completion: Unpaired Point Cloud Completion Using Cycle Transformation With Missing Region Coding</a></th>
                    </tr>
                
                    <tr id="6b45c8d03a20c5ae4fe5d6136cf01748b4bd7489">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6b45c8d03a20c5ae4fe5d6136cf01748b4bd7489">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ehsani_ManipulaTHOR_A_Framework_for_Visual_Object_Manipulation_CVPR_2021_paper.html">ManipulaTHOR: A Framework for Visual Object Manipulation</a></th>
                    </tr>
                
                    <tr id="0ddfdbf470c961bcf9ecbba42e9afebcbab044ee">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ddfdbf470c961bcf9ecbba42e9afebcbab044ee">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Afifi_HistoGAN_Controlling_Colors_of_GAN-Generated_and_Real_Images_via_Color_CVPR_2021_paper.html">HistoGAN: Controlling Colors of GAN-Generated and Real Images via Color Histograms</a></th>
                    </tr>
                
                    <tr id="6637c28fdf6ab7e3e37f1727725d41ca54549876">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6637c28fdf6ab7e3e37f1727725d41ca54549876">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Semi-Supervised_3D_Hand-Object_Poses_Estimation_With_Interactions_in_Time_CVPR_2021_paper.html">Semi-Supervised 3D Hand-Object Poses Estimation With Interactions in Time</a></th>
                    </tr>
                
                    <tr id="1b8e9c1cc34846e4396f4accd4114bab686829f4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1b8e9c1cc34846e4396f4accd4114bab686829f4">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Progressive_Semantic-Aware_Style_Transformation_for_Blind_Face_Restoration_CVPR_2021_paper.html">Progressive Semantic-Aware Style Transformation for Blind Face Restoration</a></th>
                    </tr>
                
                    <tr id="8bf28d36e624f9a3c647d8eae7e09095c9c7511b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8bf28d36e624f9a3c647d8eae7e09095c9c7511b">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_CoLA_Weakly-Supervised_Temporal_Action_Localization_With_Snippet_Contrastive_Learning_CVPR_2021_paper.html">CoLA: Weakly-Supervised Temporal Action Localization With Snippet Contrastive Learning</a></th>
                    </tr>
                
                    <tr id="981239bc3b93af0e9913d05ffb2aca1edbe216fe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/981239bc3b93af0e9913d05ffb2aca1edbe216fe">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Rethinking_and_Improving_the_Robustness_of_Image_Style_Transfer_CVPR_2021_paper.html">Rethinking and Improving the Robustness of Image Style Transfer</a></th>
                    </tr>
                
                    <tr id="0c3229c54cff26a00c148bba88b0e82122c90020">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c3229c54cff26a00c148bba88b0e82122c90020">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_OpenMix_Reviving_Known_Knowledge_for_Discovering_Novel_Visual_Categories_in_CVPR_2021_paper.html">OpenMix: Reviving Known Knowledge for Discovering Novel Visual Categories in an Open World</a></th>
                    </tr>
                
                    <tr id="309b641044e094a85d9006df51a15f296e153978">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/309b641044e094a85d9006df51a15f296e153978">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kumar_GrooMeD-NMS_Grouped_Mathematically_Differentiable_NMS_for_Monocular_3D_Object_Detection_CVPR_2021_paper.html">GrooMeD-NMS: Grouped Mathematically Differentiable NMS for Monocular 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="01d275c9c7a4f182b7ee9ad2c0868a632d838a4e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01d275c9c7a4f182b7ee9ad2c0868a632d838a4e">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_Multi-Source_Domain_Adaptation_With_Collaborative_Learning_for_Semantic_Segmentation_CVPR_2021_paper.html">Multi-Source Domain Adaptation With Collaborative Learning for Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="0efe94eb4a035ee29c69a80248517a9b12678bc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0efe94eb4a035ee29c69a80248517a9b12678bc1">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fan_SCF-Net_Learning_Spatial_Contextual_Features_for_Large-Scale_Point_Cloud_Segmentation_CVPR_2021_paper.html">SCF-Net: Learning Spatial Contextual Features for Large-Scale Point Cloud Segmentation</a></th>
                    </tr>
                
                    <tr id="d22f0bc26292d9f7a8e8e1699e02fc00f73c9961">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d22f0bc26292d9f7a8e8e1699e02fc00f73c9961">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_3DIoUMatch_Leveraging_IoU_Prediction_for_Semi-Supervised_3D_Object_Detection_CVPR_2021_paper.html">3DIoUMatch: Leveraging IoU Prediction for Semi-Supervised 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="05a92beee49ac2008ea281bf46c45f71d82e4eee">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05a92beee49ac2008ea281bf46c45f71d82e4eee">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_PISE_Person_Image_Synthesis_and_Editing_With_Decoupled_GAN_CVPR_2021_paper.html">PISE: Person Image Synthesis and Editing With Decoupled GAN</a></th>
                    </tr>
                
                    <tr id="3afbc6386026fe2e694337d0316d3979df7911e5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3afbc6386026fe2e694337d0316d3979df7911e5">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Decoupled_Dynamic_Filter_Networks_CVPR_2021_paper.html">Decoupled Dynamic Filter Networks</a></th>
                    </tr>
                
                    <tr id="df37e254a5e2d966680d9c4ef70b44d43a073eb9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/df37e254a5e2d966680d9c4ef70b44d43a073eb9">41</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Video_Prediction_Recalling_Long-Term_Motion_Context_via_Memory_Alignment_Learning_CVPR_2021_paper.html">Video Prediction Recalling Long-Term Motion Context via Memory Alignment Learning</a></th>
                    </tr>
                
                    <tr id="385989aa0af17998ba9f08b5c2c081360f84dcd5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/385989aa0af17998ba9f08b5c2c081360f84dcd5">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mancini_Open_World_Compositional_Zero-Shot_Learning_CVPR_2021_paper.html">Open World Compositional Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="2e41d8b57af02799b4f9e89977f62c748eb995fe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e41d8b57af02799b4f9e89977f62c748eb995fe">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ying_Patch-VQ_Patching_Up_the_Video_Quality_Problem_CVPR_2021_paper.html">Patch-VQ: &#39;Patching Up&#39; the Video Quality Problem</a></th>
                    </tr>
                
                    <tr id="63cc6611b06d57e5e8e3a8a22d62697b23737888">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/63cc6611b06d57e5e8e3a8a22d62697b23737888">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Toker_Coming_Down_to_Earth_Satellite-to-Street_View_Synthesis_for_Geo-Localization_CVPR_2021_paper.html">Coming Down to Earth: Satellite-to-Street View Synthesis for Geo-Localization</a></th>
                    </tr>
                
                    <tr id="95cb3e6b628a3a0220b8c80fde4f9f4a3d2e7221">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/95cb3e6b628a3a0220b8c80fde4f9f4a3d2e7221">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kervadec_Roses_Are_Red_Violets_Are_Blue..._but_Should_VQA_Expect_CVPR_2021_paper.html">Roses Are Red, Violets Are Blue... but Should VQA Expect Them To?</a></th>
                    </tr>
                
                    <tr id="ee0de77c9bbe4a60fdbba09e2d37b3db842312df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ee0de77c9bbe4a60fdbba09e2d37b3db842312df">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Structured_Scene_Memory_for_Vision-Language_Navigation_CVPR_2021_paper.html">Structured Scene Memory for Vision-Language Navigation</a></th>
                    </tr>
                
                    <tr id="329f9972e42ad78854282d50161c8f208c8e4983">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/329f9972e42ad78854282d50161c8f208c8e4983">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Stammer_Right_for_the_Right_Concept_Revising_Neuro-Symbolic_Concepts_by_Interacting_CVPR_2021_paper.html">Right for the Right Concept: Revising Neuro-Symbolic Concepts by Interacting With Their Explanations</a></th>
                    </tr>
                
                    <tr id="b08199b3d35a5f6972cb356dd355b2aea408d3ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b08199b3d35a5f6972cb356dd355b2aea408d3ff">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Projecting_Your_View_Attentively_Monocular_Road_Scene_Layout_Estimation_via_CVPR_2021_paper.html">Projecting Your View Attentively: Monocular Road Scene Layout Estimation via Cross-View Transformation</a></th>
                    </tr>
                
                    <tr id="07a7a0421c1f604f6b1dd26bf7789c7fa28f104e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/07a7a0421c1f604f6b1dd26bf7789c7fa28f104e">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hoyer_Three_Ways_To_Improve_Semantic_Segmentation_With_Self-Supervised_Depth_Estimation_CVPR_2021_paper.html">Three Ways To Improve Semantic Segmentation With Self-Supervised Depth Estimation</a></th>
                    </tr>
                
                    <tr id="20843b783299bb8a14d53b31a35c971990a09eac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/20843b783299bb8a14d53b31a35c971990a09eac">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Park_Improving_Unsupervised_Image_Clustering_With_Robust_Learning_CVPR_2021_paper.html">Improving Unsupervised Image Clustering With Robust Learning</a></th>
                    </tr>
                
                    <tr id="327b155ab8e0c065f9f51e7f12ecc28bd68efdc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/327b155ab8e0c065f9f51e7f12ecc28bd68efdc1">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Meyer_An_Alternative_Probabilistic_Interpretation_of_the_Huber_Loss_CVPR_2021_paper.html">An Alternative Probabilistic Interpretation of the Huber Loss</a></th>
                    </tr>
                
                    <tr id="758fb62a9ce0cabfce71b0020a662522ca8ceabf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/758fb62a9ce0cabfce71b0020a662522ca8ceabf">40</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Learning_Invariant_Representations_and_Risks_for_Semi-Supervised_Domain_Adaptation_CVPR_2021_paper.html">Learning Invariant Representations and Risks for Semi-Supervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="16282981d35e696afc70724b6cc6a186a404fe92">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16282981d35e696afc70724b6cc6a186a404fe92">40</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/Deliege_SoccerNet-v2_A_Dataset_and_Benchmarks_for_Holistic_Understanding_of_Broadcast_CVPRW_2021_paper.html">SoccerNet-v2: A Dataset and Benchmarks for Holistic Understanding of Broadcast Soccer Videos</a></th>
                    </tr>
                
                    <tr id="1b937ff4b05e2b56c2c2fcdfa5baa3085cd5a08c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1b937ff4b05e2b56c2c2fcdfa5baa3085cd5a08c">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xiao_NExT-QA_Next_Phase_of_Question-Answering_to_Explaining_Temporal_Actions_CVPR_2021_paper.html">NExT-QA: Next Phase of Question-Answering to Explaining Temporal Actions</a></th>
                    </tr>
                
                    <tr id="4cef9c35ad6bfb092dbca8e064bcfcb440a35b47">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4cef9c35ad6bfb092dbca8e064bcfcb440a35b47">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Representative_Forgery_Mining_for_Fake_Face_Detection_CVPR_2021_paper.html">Representative Forgery Mining for Fake Face Detection</a></th>
                    </tr>
                
                    <tr id="26bb9d36557977192404aa16ad3833e47d8daf48">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26bb9d36557977192404aa16ad3833e47d8daf48">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yoon_Pose-Guided_Human_Animation_From_a_Single_Image_in_the_Wild_CVPR_2021_paper.html">Pose-Guided Human Animation From a Single Image in the Wild</a></th>
                    </tr>
                
                    <tr id="531dc47db45563c6879a41c3a6f5657043e30325">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/531dc47db45563c6879a41c3a6f5657043e30325">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Few-Shot_Object_Detection_via_Classification_Refinement_and_Distractor_Retreatment_CVPR_2021_paper.html">Few-Shot Object Detection via Classification Refinement and Distractor Retreatment</a></th>
                    </tr>
                
                    <tr id="775a1a2eadac7fd672551aae78af2eb7a4d234ae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/775a1a2eadac7fd672551aae78af2eb7a4d234ae">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ahmed_Unsupervised_Multi-Source_Domain_Adaptation_Without_Access_to_Source_Data_CVPR_2021_paper.html">Unsupervised Multi-Source Domain Adaptation Without Access to Source Data</a></th>
                    </tr>
                
                    <tr id="226c8a6a89978a506c31415cc3db645521907ddc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/226c8a6a89978a506c31415cc3db645521907ddc">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Deep_Dual_Consecutive_Network_for_Human_Pose_Estimation_CVPR_2021_paper.html">Deep Dual Consecutive Network for Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="cd5d931ac67008d6469a8fe189339bcae776f48b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd5d931ac67008d6469a8fe189339bcae776f48b">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Temporal_Query_Networks_for_Fine-Grained_Video_Understanding_CVPR_2021_paper.html">Temporal Query Networks for Fine-Grained Video Understanding</a></th>
                    </tr>
                
                    <tr id="7a4ba78d377eea9650e5e399a0878e30bd22f648">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a4ba78d377eea9650e5e399a0878e30bd22f648">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Scan2Cap_Context-Aware_Dense_Captioning_in_RGB-D_Scans_CVPR_2021_paper.html">Scan2Cap: Context-Aware Dense Captioning in RGB-D Scans</a></th>
                    </tr>
                
                    <tr id="43d9627fdf1436d827788cd95105112a57b53696">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/43d9627fdf1436d827788cd95105112a57b53696">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Anycost_GANs_for_Interactive_Image_Synthesis_and_Editing_CVPR_2021_paper.html">Anycost GANs for Interactive Image Synthesis and Editing</a></th>
                    </tr>
                
                    <tr id="852d8ef289fe03bf74af253a85fcb880508a2411">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/852d8ef289fe03bf74af253a85fcb880508a2411">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Line_Segment_Detection_Using_Transformers_Without_Edges_CVPR_2021_paper.html">Line Segment Detection Using Transformers Without Edges</a></th>
                    </tr>
                
                    <tr id="9c4beab3630e744e28a4aca309614d8e6db411be">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c4beab3630e744e28a4aca309614d8e6db411be">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Discover_Cross-Modality_Nuances_for_Visible-Infrared_Person_Re-Identification_CVPR_2021_paper.html">Discover Cross-Modality Nuances for Visible-Infrared Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="99eeeca965c4384fa242d706b7db790111e0f233">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/99eeeca965c4384fa242d706b7db790111e0f233">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Diversifying_Sample_Generation_for_Accurate_Data-Free_Quantization_CVPR_2021_paper.html">Diversifying Sample Generation for Accurate Data-Free Quantization</a></th>
                    </tr>
                
                    <tr id="984e8d127bf2721ff403b6aaf5ce65097c2951e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/984e8d127bf2721ff403b6aaf5ce65097c2951e3">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Partially_View-Aligned_Representation_Learning_With_Noise-Robust_Contrastive_Loss_CVPR_2021_paper.html">Partially View-Aligned Representation Learning With Noise-Robust Contrastive Loss</a></th>
                    </tr>
                
                    <tr id="19c79ca9898266404623312dfbdad9b4331ee051">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/19c79ca9898266404623312dfbdad9b4331ee051">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Learning_Statistical_Texture_for_Semantic_Segmentation_CVPR_2021_paper.html">Learning Statistical Texture for Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="4bf61c74542d62edb5716c7668e1be1fbae21d0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4bf61c74542d62edb5716c7668e1be1fbae21d0c">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ruan_Feature_Decomposition_and_Reconstruction_Learning_for_Effective_Facial_Expression_Recognition_CVPR_2021_paper.html">Feature Decomposition and Reconstruction Learning for Effective Facial Expression Recognition</a></th>
                    </tr>
                
                    <tr id="0e3d3a4f3302a76edc93c2c62319881223684142">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e3d3a4f3302a76edc93c2c62319881223684142">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Anchor-Free_Person_Search_CVPR_2021_paper.html">Anchor-Free Person Search</a></th>
                    </tr>
                
                    <tr id="8bc31ba68e02f8acfb04ed38e69bd7b469d2dae7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8bc31ba68e02f8acfb04ed38e69bd7b469d2dae7">39</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jeong_Interpolation-Based_Semi-Supervised_Learning_for_Object_Detection_CVPR_2021_paper.html">Interpolation-based Semi-supervised Learning for Object Detection</a></th>
                    </tr>
                
                    <tr id="47cd947b70d5c6d90a5ecf0a76a6199fd2541175">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47cd947b70d5c6d90a5ecf0a76a6199fd2541175">39</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Hu_v2e_From_Video_Frames_to_Realistic_DVS_Events_CVPRW_2021_paper.html">v2e: From Video Frames to Realistic DVS Events</a></th>
                    </tr>
                
                    <tr id="c0b29e11d0770f96b409555cba99e785a3316f96">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c0b29e11d0770f96b409555cba99e785a3316f96">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pan_Unveiling_the_Potential_of_Structure_Preserving_for_Weakly_Supervised_Object_CVPR_2021_paper.html">Unveiling the Potential of Structure Preserving for Weakly Supervised Object Localization</a></th>
                    </tr>
                
                    <tr id="c6134edae495482f82c3c5137892ce424d3bd9e4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c6134edae495482f82c3c5137892ce424d3bd9e4">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ge_Disentangled_Cycle_Consistency_for_Highly-Realistic_Virtual_Try-On_CVPR_2021_paper.html">Disentangled Cycle Consistency for Highly-Realistic Virtual Try-On</a></th>
                    </tr>
                
                    <tr id="cda4b1035702a4e69d46c88f86c9091da20e5592">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cda4b1035702a4e69d46c88f86c9091da20e5592">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Temporal_Modulation_Network_for_Controllable_Space-Time_Video_Super-Resolution_CVPR_2021_paper.html">Temporal Modulation Network for Controllable Space-Time Video Super-Resolution</a></th>
                    </tr>
                
                    <tr id="988084a2165eef88ae2efceda9c4bd52c2abe834">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/988084a2165eef88ae2efceda9c4bd52c2abe834">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Transferable_Semantic_Augmentation_for_Domain_Adaptation_CVPR_2021_paper.html">Transferable Semantic Augmentation for Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="590073947a4cd7cb2f1c8840076e047a35704fb9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/590073947a4cd7cb2f1c8840076e047a35704fb9">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Teed_RAFT-3D_Scene_Flow_Using_Rigid-Motion_Embeddings_CVPR_2021_paper.html">RAFT-3D: Scene Flow Using Rigid-Motion Embeddings</a></th>
                    </tr>
                
                    <tr id="888600a4a584a217a3baf120683e62dacf3afb27">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/888600a4a584a217a3baf120683e62dacf3afb27">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_CoCosNet_v2_Full-Resolution_Correspondence_Learning_for_Image_Translation_CVPR_2021_paper.html">CoCosNet v2: Full-Resolution Correspondence Learning for Image Translation</a></th>
                    </tr>
                
                    <tr id="7f90aa9c2c52f99635b65a1e45f9d64608d8c6fd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7f90aa9c2c52f99635b65a1e45f9d64608d8c6fd">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Multi-Shot_Temporal_Event_Localization_A_Benchmark_CVPR_2021_paper.html">Multi-Shot Temporal Event Localization: A Benchmark</a></th>
                    </tr>
                
                    <tr id="3471032918f2e6fd65677ad491a79ffa14b1c289">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3471032918f2e6fd65677ad491a79ffa14b1c289">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_MOOD_Multi-Level_Out-of-Distribution_Detection_CVPR_2021_paper.html">MOOD: Multi-Level Out-of-Distribution Detection</a></th>
                    </tr>
                
                    <tr id="9d684bb5a121699a12adabbf83a816075991a1b9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9d684bb5a121699a12adabbf83a816075991a1b9">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Goal-Oriented_Gaze_Estimation_for_Zero-Shot_Learning_CVPR_2021_paper.html">Goal-Oriented Gaze Estimation for Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="9ee5045f42d7fbd4f848e91a354d63793365fdd1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9ee5045f42d7fbd4f848e91a354d63793365fdd1">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_AutoFlow_Learning_a_Better_Training_Set_for_Optical_Flow_CVPR_2021_paper.html">AutoFlow: Learning a Better Training Set for Optical Flow</a></th>
                    </tr>
                
                    <tr id="74d9586dc0593cddae3223a841213c9ea7038bf6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/74d9586dc0593cddae3223a841213c9ea7038bf6">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dai_FBNetV3_Joint_Architecture-Recipe_Search_Using_Predictor_Pretraining_CVPR_2021_paper.html">FBNetV3: Joint Architecture-Recipe Search Using Predictor Pretraining</a></th>
                    </tr>
                
                    <tr id="15d03f744bf611d0acab94351d7bc7584c4c42ed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15d03f744bf611d0acab94351d7bc7584c4c42ed">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Duan_Adversarial_Laser_Beam_Effective_Physical-World_Attack_to_DNNs_in_a_CVPR_2021_paper.html">Adversarial Laser Beam: Effective Physical-World Attack to DNNs in a Blink</a></th>
                    </tr>
                
                    <tr id="4bb58f0780bd3812d81cf2ca927e18e313aec89d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4bb58f0780bd3812d81cf2ca927e18e313aec89d">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Point_Cloud_Upsampling_via_Disentangled_Refinement_CVPR_2021_paper.html">Point Cloud Upsampling via Disentangled Refinement</a></th>
                    </tr>
                
                    <tr id="0457852644ac60568aba800147af224dd2d547a1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0457852644ac60568aba800147af224dd2d547a1">38</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Soteria_Provable_Defense_Against_Privacy_Leakage_in_Federated_Learning_From_CVPR_2021_paper.html">Soteria: Provable Defense against Privacy Leakage in Federated Learning from Representation Perspective</a></th>
                    </tr>
                
                    <tr id="1347a70411485366480b0a25e86d3ebe6aaec30b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1347a70411485366480b0a25e86d3ebe6aaec30b">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Deep_Gradient_Projection_Networks_for_Pan-sharpening_CVPR_2021_paper.html">Deep Gradient Projection Networks for Pan-sharpening</a></th>
                    </tr>
                
                    <tr id="7a004509ef2212fbd7e887f842b3cc4d84d48397">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a004509ef2212fbd7e887f842b3cc4d84d48397">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Grady_ContactOpt_Optimizing_Contact_To_Improve_Grasps_CVPR_2021_paper.html">ContactOpt: Optimizing Contact To Improve Grasps</a></th>
                    </tr>
                
                    <tr id="d291f7ce81164a2c5a0b9f71ef9227617fbe100c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d291f7ce81164a2c5a0b9f71ef9227617fbe100c">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Domain_Consensus_Clustering_for_Universal_Domain_Adaptation_CVPR_2021_paper.html">Domain Consensus Clustering for Universal Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="01a7b0fa501e0319f3f3bbaf5d8caaee159663cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01a7b0fa501e0319f3f3bbaf5d8caaee159663cc">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ortego_Multi-Objective_Interpolation_Training_for_Robustness_To_Label_Noise_CVPR_2021_paper.html">Multi-Objective Interpolation Training for Robustness To Label Noise</a></th>
                    </tr>
                
                    <tr id="b0d8650d08e6041c8851bfbba70097536fc4fbcb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b0d8650d08e6041c8851bfbba70097536fc4fbcb">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_LASR_Learning_Articulated_Shape_Reconstruction_From_a_Monocular_Video_CVPR_2021_paper.html">LASR: Learning Articulated Shape Reconstruction From a Monocular Video</a></th>
                    </tr>
                
                    <tr id="de43c2ecbe8c117a8174866535d387d67b0709a7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/de43c2ecbe8c117a8174866535d387d67b0709a7">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_RGB-D_Local_Implicit_Function_for_Depth_Completion_of_Transparent_Objects_CVPR_2021_paper.html">RGB-D Local Implicit Function for Depth Completion of Transparent Objects</a></th>
                    </tr>
                
                    <tr id="6b3d2873dbfca7669c107e9f38653e6c1cb10475">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6b3d2873dbfca7669c107e9f38653e6c1cb10475">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bozic_Neural_Deformation_Graphs_for_Globally-Consistent_Non-Rigid_Reconstruction_CVPR_2021_paper.html">Neural Deformation Graphs for Globally-Consistent Non-Rigid Reconstruction</a></th>
                    </tr>
                
                    <tr id="463b78ebe227dbb901645e45ad00ec7264652168">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/463b78ebe227dbb901645e45ad00ec7264652168">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_The_Spatially-Correlative_Loss_for_Various_Image_Translation_Tasks_CVPR_2021_paper.html">The Spatially-Correlative Loss for Various Image Translation Tasks</a></th>
                    </tr>
                
                    <tr id="017fb5cccc1bc47e070d0e26c7c3351792940c6c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/017fb5cccc1bc47e070d0e26c7c3351792940c6c">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ding_CDFI_Compression-Driven_Network_Design_for_Frame_Interpolation_CVPR_2021_paper.html">CDFI: Compression-Driven Network Design for Frame Interpolation</a></th>
                    </tr>
                
                    <tr id="1f0a8526a7e88a6fa316a3e2baa7b2b840b5c985">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1f0a8526a7e88a6fa316a3e2baa7b2b840b5c985">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Arroyo_Variational_Transformer_Networks_for_Layout_Generation_CVPR_2021_paper.html">Variational Transformer Networks for Layout Generation</a></th>
                    </tr>
                
                    <tr id="7515d56bf86c279b394c27f68fd73346db54b572">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7515d56bf86c279b394c27f68fd73346db54b572">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ren_Adaptive_Consistency_Prior_Based_Deep_Network_for_Image_Denoising_CVPR_2021_paper.html">Adaptive Consistency Prior Based Deep Network for Image Denoising</a></th>
                    </tr>
                
                    <tr id="648c13c77a94d46b2dbd75c8073cca4b8870bd9f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/648c13c77a94d46b2dbd75c8073cca4b8870bd9f">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Adversarially_Adaptive_Normalization_for_Single_Domain_Generalization_CVPR_2021_paper.html">Adversarially Adaptive Normalization for Single Domain Generalization</a></th>
                    </tr>
                
                    <tr id="9efa13bc02bed2e41b3e425dd2ce15d7f2336714">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9efa13bc02bed2e41b3e425dd2ce15d7f2336714">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Network_Pruning_via_Performance_Maximization_CVPR_2021_paper.html">Network Pruning via Performance Maximization</a></th>
                    </tr>
                
                    <tr id="19283aec5193393053babbe2f5a59021f63575a3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/19283aec5193393053babbe2f5a59021f63575a3">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cui_Asymmetric_Gained_Deep_Image_Compression_With_Continuous_Rate_Adaptation_CVPR_2021_paper.html">Asymmetric Gained Deep Image Compression With Continuous Rate Adaptation</a></th>
                    </tr>
                
                    <tr id="51340cfcd24d54ee6acac0b4586e55f81d5de6bc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/51340cfcd24d54ee6acac0b4586e55f81d5de6bc">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shaham_Spatially-Adaptive_Pixelwise_Networks_for_Fast_Image_Translation_CVPR_2021_paper.html">Spatially-Adaptive Pixelwise Networks for Fast Image Translation</a></th>
                    </tr>
                
                    <tr id="2930659d61db41bc77aabc1bc4e9da52076b25bb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2930659d61db41bc77aabc1bc4e9da52076b25bb">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Simon_On_Learning_the_Geodesic_Path_for_Incremental_Learning_CVPR_2021_paper.html">On Learning the Geodesic Path for Incremental Learning</a></th>
                    </tr>
                
                    <tr id="4c3970d9eeb2687e0dce819bcf3f89ef41d7decd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c3970d9eeb2687e0dce819bcf3f89ef41d7decd">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Activate_or_Not_Learning_Customized_Activation_CVPR_2021_paper.html">Activate or Not: Learning Customized Activation</a></th>
                    </tr>
                
                    <tr id="47500d72f1e878a2c1d1987823e2810a12c35ec0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47500d72f1e878a2c1d1987823e2810a12c35ec0">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Deep_Implicit_Moving_Least-Squares_Functions_for_3D_Reconstruction_CVPR_2021_paper.html">Deep Implicit Moving Least-Squares Functions for 3D Reconstruction</a></th>
                    </tr>
                
                    <tr id="8b55b106aae751553ec44fb30ec780e05ca74980">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b55b106aae751553ec44fb30ec780e05ca74980">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jaume_Quantifying_Explainers_of_Graph_Neural_Networks_in_Computational_Pathology_CVPR_2021_paper.html">Quantifying Explainers of Graph Neural Networks in Computational Pathology</a></th>
                    </tr>
                
                    <tr id="a7dd97b37acaecfc21d129d603d6a54fc997e6cb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a7dd97b37acaecfc21d129d603d6a54fc997e6cb">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wei_MetaAlign_Coordinating_Domain_Alignment_and_Classification_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html">MetaAlign: Coordinating Domain Alignment and Classification for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="bf56ef26c641af5c5018cf8b9b96ed0ac00dc717">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bf56ef26c641af5c5018cf8b9b96ed0ac00dc717">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Capturing_Omni-Range_Context_for_Omnidirectional_Segmentation_CVPR_2021_paper.html">Capturing Omni-Range Context for Omnidirectional Segmentation</a></th>
                    </tr>
                
                    <tr id="864d5cc8a5330819de33f3690ed71d6654499710">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/864d5cc8a5330819de33f3690ed71d6654499710">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jacob_Facial_Action_Unit_Detection_With_Transformers_CVPR_2021_paper.html">Facial Action Unit Detection With Transformers</a></th>
                    </tr>
                
                    <tr id="a34a77bd53e752c4ecfe8c5ddbf1c218e2e8ac31">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a34a77bd53e752c4ecfe8c5ddbf1c218e2e8ac31">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_AttentiveNAS_Improving_Neural_Architecture_Search_via_Attentive_Sampling_CVPR_2021_paper.html">AttentiveNAS: Improving Neural Architecture Search via Attentive Sampling</a></th>
                    </tr>
                
                    <tr id="895e890b7b21863421ae849c0599aa747bff31ba">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/895e890b7b21863421ae849c0599aa747bff31ba">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Perrett_Temporal-Relational_CrossTransformers_for_Few-Shot_Action_Recognition_CVPR_2021_paper.html">Temporal-Relational CrossTransformers for Few-Shot Action Recognition</a></th>
                    </tr>
                
                    <tr id="dfc7b2059754fec0564ff8be437bbb3b653701b9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dfc7b2059754fec0564ff8be437bbb3b653701b9">37</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Anti-Adversarially_Manipulated_Attributions_for_Weakly_and_Semi-Supervised_Semantic_Segmentation_CVPR_2021_paper.html">Anti-Adversarially Manipulated Attributions for Weakly and Semi-Supervised Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="a70b555c03c0a7b8928f23d0f16dc86509c2bf3e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a70b555c03c0a7b8928f23d0f16dc86509c2bf3e">37</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Perez-Pellitero_NTIRE_2021_Challenge_on_High_Dynamic_Range_Imaging_Dataset_Methods_CVPRW_2021_paper.html">NTIRE 2021 Challenge on High Dynamic Range Imaging: Dataset, Methods and Results</a></th>
                    </tr>
                
                    <tr id="05f870bedcb2ac422be7ba3460229a6604420082">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05f870bedcb2ac422be7ba3460229a6604420082">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_STaR_Self-Supervised_Tracking_and_Reconstruction_of_Rigid_Objects_in_Motion_CVPR_2021_paper.html">STaR: Self-Supervised Tracking and Reconstruction of Rigid Objects in Motion With Neural Rendering</a></th>
                    </tr>
                
                    <tr id="2dd4b5e8633a5587ce2ebf73284134f21d1bc6a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2dd4b5e8633a5587ce2ebf73284134f21d1bc6a9">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Mask_Guided_Matting_via_Progressive_Refinement_Network_CVPR_2021_paper.html">Mask Guided Matting via Progressive Refinement Network</a></th>
                    </tr>
                
                    <tr id="203d80a576abe268fc66420f8721ebcce57a0e7c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/203d80a576abe268fc66420f8721ebcce57a0e7c">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_M3DSSD_Monocular_3D_Single_Stage_Object_Detector_CVPR_2021_paper.html">M3DSSD: Monocular 3D Single Stage Object Detector</a></th>
                    </tr>
                
                    <tr id="64499484b88e4766cf078aecbadea20f171c0921">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/64499484b88e4766cf078aecbadea20f171c0921">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dabouei_SuperMix_Supervising_the_Mixing_Data_Augmentation_CVPR_2021_paper.html">SuperMix: Supervising the Mixing Data Augmentation</a></th>
                    </tr>
                
                    <tr id="eb2cfb7597f839cb89166a06af7ecb0f074c0103">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eb2cfb7597f839cb89166a06af7ecb0f074c0103">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pang_Recorrupted-to-Recorrupted_Unsupervised_Deep_Learning_for_Image_Denoising_CVPR_2021_paper.html">Recorrupted-to-Recorrupted: Unsupervised Deep Learning for Image Denoising</a></th>
                    </tr>
                
                    <tr id="57f2468c6cdc52a0645f6e4c9ada726602cfc814">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/57f2468c6cdc52a0645f6e4c9ada726602cfc814">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lahiri_LipSync3D_Data-Efficient_Learning_of_Personalized_3D_Talking_Faces_From_Video_CVPR_2021_paper.html">LipSync3D: Data-Efficient Learning of Personalized 3D Talking Faces From Video Using Pose and Lighting Normalization</a></th>
                    </tr>
                
                    <tr id="9a93fadaa32bd688d88125c09f143737e252cbfa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9a93fadaa32bd688d88125c09f143737e252cbfa">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_ARVo_Learning_All-Range_Volumetric_Correspondence_for_Video_Deblurring_CVPR_2021_paper.html">ARVo: Learning All-Range Volumetric Correspondence for Video Deblurring</a></th>
                    </tr>
                
                    <tr id="a2bd735bf9f93fe447cddd68e0a38e01937fdaf3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a2bd735bf9f93fe447cddd68e0a38e01937fdaf3">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kariyappa_MAZE_Data-Free_Model_Stealing_Attack_Using_Zeroth-Order_Gradient_Estimation_CVPR_2021_paper.html">MAZE: Data-Free Model Stealing Attack Using Zeroth-Order Gradient Estimation</a></th>
                    </tr>
                
                    <tr id="15616c4024d83e6ada02fc01768846e81e21b07c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15616c4024d83e6ada02fc01768846e81e21b07c">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Dual-GAN_Joint_BVP_and_Noise_Modeling_for_Remote_Physiological_Measurement_CVPR_2021_paper.html">Dual-GAN: Joint BVP and Noise Modeling for Remote Physiological Measurement</a></th>
                    </tr>
                
                    <tr id="505422c6e07b356969e641cdb0985ab2c85ccae4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/505422c6e07b356969e641cdb0985ab2c85ccae4">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_MetaSAug_Meta_Semantic_Augmentation_for_Long-Tailed_Visual_Recognition_CVPR_2021_paper.html">MetaSAug: Meta Semantic Augmentation for Long-Tailed Visual Recognition</a></th>
                    </tr>
                
                    <tr id="0ef56a25b685f929e6151f705bd3f65c7df5c889">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ef56a25b685f929e6151f705bd3f65c7df5c889">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_XProtoNet_Diagnosis_in_Chest_Radiography_With_Global_and_Local_Explanations_CVPR_2021_paper.html">XProtoNet: Diagnosis in Chest Radiography With Global and Local Explanations</a></th>
                    </tr>
                
                    <tr id="85aa1da78aba3552fa4a89df1dc0a8fa425f36b8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/85aa1da78aba3552fa4a89df1dc0a8fa425f36b8">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Durasov_Masksembles_for_Uncertainty_Estimation_CVPR_2021_paper.html">Masksembles for Uncertainty Estimation</a></th>
                    </tr>
                
                    <tr id="fe9bc34b3e3b181de6caee3ff79e9c5bf1bbcf98">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fe9bc34b3e3b181de6caee3ff79e9c5bf1bbcf98">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Punnakkal_BABEL_Bodies_Action_and_Behavior_With_English_Labels_CVPR_2021_paper.html">BABEL: Bodies, Action and Behavior With English Labels</a></th>
                    </tr>
                
                    <tr id="c1cbdf90813c8da1f46019748b1316986d83da0a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c1cbdf90813c8da1f46019748b1316986d83da0a">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_ProSelfLC_Progressive_Self_Label_Correction_for_Training_Robust_Deep_Neural_CVPR_2021_paper.html">ProSelfLC: Progressive Self Label Correction for Training Robust Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="b01db336a8ead672700a406f5c12d1edb9fb2697">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b01db336a8ead672700a406f5c12d1edb9fb2697">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Self-Supervised_Learning_for_Semi-Supervised_Temporal_Action_Proposal_CVPR_2021_paper.html">Self-Supervised Learning for Semi-Supervised Temporal Action Proposal</a></th>
                    </tr>
                
                    <tr id="2713adc5d2d043054f4346c647103017e012eade">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2713adc5d2d043054f4346c647103017e012eade">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_MetaCorrection_Domain-Aware_Meta_Loss_Correction_for_Unsupervised_Domain_Adaptation_in_CVPR_2021_paper.html">MetaCorrection: Domain-Aware Meta Loss Correction for Unsupervised Domain Adaptation in Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="cd01b41b7440802f9df5b3bef8b250d1703a7463">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd01b41b7440802f9df5b3bef8b250d1703a7463">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Back-Tracing_Representative_Points_for_Voting-Based_3D_Object_Detection_in_Point_CVPR_2021_paper.html">Back-Tracing Representative Points for Voting-Based 3D Object Detection in Point Clouds</a></th>
                    </tr>
                
                    <tr id="f32eba787a3bce247adebf2265792afdcf187696">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f32eba787a3bce247adebf2265792afdcf187696">36</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xiang_NeuTex_Neural_Texture_Mapping_for_Volumetric_Neural_Rendering_CVPR_2021_paper.html">NeuTex: Neural Texture Mapping for Volumetric Neural Rendering</a></th>
                    </tr>
                
                    <tr id="149ed92d2e52acc6645aec45cbda486e071e5fe4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/149ed92d2e52acc6645aec45cbda486e071e5fe4">36</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Nah_NTIRE_2021_Challenge_on_Image_Deblurring_CVPRW_2021_paper.html">NTIRE 2021 Challenge on Image Deblurring</a></th>
                    </tr>
                
                    <tr id="9898b3d600b3881bde162b7e4b668a3c063cba10">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9898b3d600b3881bde162b7e4b668a3c063cba10">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Caramalau_Sequential_Graph_Convolutional_Network_for_Active_Learning_CVPR_2021_paper.html">Sequential Graph Convolutional Network for Active Learning</a></th>
                    </tr>
                
                    <tr id="3c6a6adffc390f56942b0c8f9b1d246acc7dd1e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3c6a6adffc390f56942b0c8f9b1d246acc7dd1e1">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Achlioptas_ArtEmis_Affective_Language_for_Visual_Art_CVPR_2021_paper.html">ArtEmis: Affective Language for Visual Art</a></th>
                    </tr>
                
                    <tr id="01263f15e0724ed145f7ebd421702c883b0949b9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01263f15e0724ed145f7ebd421702c883b0949b9">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Pareto_Self-Supervised_Training_for_Few-Shot_Learning_CVPR_2021_paper.html">Pareto Self-Supervised Training for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="15f21dd5b74905f2fd978c73fd3e159d34634b68">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15f21dd5b74905f2fd978c73fd3e159d34634b68">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Fully_Convolutional_Scene_Graph_Generation_CVPR_2021_paper.html">Fully Convolutional Scene Graph Generation</a></th>
                    </tr>
                
                    <tr id="c809418bf663e4db9f659ee862e6f80777dcddc8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c809418bf663e4db9f659ee862e6f80777dcddc8">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_RefineMask_Towards_High-Quality_Instance_Segmentation_With_Fine-Grained_Features_CVPR_2021_paper.html">RefineMask: Towards High-Quality Instance Segmentation With Fine-Grained Features</a></th>
                    </tr>
                
                    <tr id="8606bd5060b3529ab1c4c778d7335ed1ddced60d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8606bd5060b3529ab1c4c778d7335ed1ddced60d">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Beyond_Bounding-Box_Convex-Hull_Feature_Adaptation_for_Oriented_and_Densely_Packed_CVPR_2021_paper.html">Beyond Bounding-Box: Convex-Hull Feature Adaptation for Oriented and Densely Packed Object Detection</a></th>
                    </tr>
                
                    <tr id="13788315f36274c43da1605605e6c24bbd5479f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/13788315f36274c43da1605605e6c24bbd5479f5">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Point_Cloud_Instance_Segmentation_Using_Probabilistic_Embeddings_CVPR_2021_paper.html">Point Cloud Instance Segmentation Using Probabilistic Embeddings</a></th>
                    </tr>
                
                    <tr id="c0fb0dec29714658950cc5b69bdea50508cfdf10">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c0fb0dec29714658950cc5b69bdea50508cfdf10">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Synthesizing_Long-Term_3D_Human_Motion_and_Interaction_in_3D_Scenes_CVPR_2021_paper.html">Synthesizing Long-Term 3D Human Motion and Interaction in 3D Scenes</a></th>
                    </tr>
                
                    <tr id="c6c867f3585fdc403cf6b53aedb069f8cef8473b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c6c867f3585fdc403cf6b53aedb069f8cef8473b">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chang_Your_Flamingo_is_My_Bird_Fine-Grained_or_Not_CVPR_2021_paper.html">Your &#34;Flamingo&#34; is My &#34;Bird&#34;: Fine-Grained, or Not</a></th>
                    </tr>
                
                    <tr id="1cbec5efa0bf040c7fa608d021f8a6e1b6b84d8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1cbec5efa0bf040c7fa608d021f8a6e1b6b84d8f">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Singh_Semi-Supervised_Action_Recognition_With_Temporal_Contrastive_Learning_CVPR_2021_paper.html">Semi-Supervised Action Recognition With Temporal Contrastive Learning</a></th>
                    </tr>
                
                    <tr id="05a066cc2b041c1176a755b1b2e16f16ec4553a7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05a066cc2b041c1176a755b1b2e16f16ec4553a7">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Muller_On_Self-Contact_and_Human_Pose_CVPR_2021_paper.html">On Self-Contact and Human Pose</a></th>
                    </tr>
                
                    <tr id="a2eb935cefe681d0176111e508b413281480a395">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a2eb935cefe681d0176111e508b413281480a395">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Coarse-To-Fine_Domain_Adaptive_Semantic_Segmentation_With_Photometric_Alignment_and_Category-Center_CVPR_2021_paper.html">Coarse-To-Fine Domain Adaptive Semantic Segmentation With Photometric Alignment and Category-Center Regularization</a></th>
                    </tr>
                
                    <tr id="3a6efa6da0e3ae06c66681956f34384080023c2b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3a6efa6da0e3ae06c66681956f34384080023c2b">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Prototype_Completion_With_Primitive_Knowledge_for_Few-Shot_Learning_CVPR_2021_paper.html">Prototype Completion With Primitive Knowledge for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="53ff6c6df65c55ea1bd0cf3f07ce79c649d916a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/53ff6c6df65c55ea1bd0cf3f07ce79c649d916a5">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_VIGOR_Cross-View_Image_Geo-Localization_Beyond_One-to-One_Retrieval_CVPR_2021_paper.html">VIGOR: Cross-View Image Geo-Localization Beyond One-to-One Retrieval</a></th>
                    </tr>
                
                    <tr id="7c0f1366b4cb803ef4ebad7ef665bfbee6e54ea2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c0f1366b4cb803ef4ebad7ef665bfbee6e54ea2">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_Temporal_Consistency_for_Low_Light_Video_Enhancement_From_Single_CVPR_2021_paper.html">Learning Temporal Consistency for Low Light Video Enhancement From Single Images</a></th>
                    </tr>
                
                    <tr id="73d5dbfebca74e5ef8a7333c842a2a9ee5c07fd6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/73d5dbfebca74e5ef8a7333c842a2a9ee5c07fd6">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dollar_Fast_and_Accurate_Model_Scaling_CVPR_2021_paper.html">Fast and Accurate Model Scaling</a></th>
                    </tr>
                
                    <tr id="61fe756024c98226b57b2ee4ba7fe8dddfabb0ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61fe756024c98226b57b2ee4ba7fe8dddfabb0ab">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Petsiuk_Black-Box_Explanation_of_Object_Detectors_via_Saliency_Maps_CVPR_2021_paper.html">Black-box Explanation of Object Detectors via Saliency Maps</a></th>
                    </tr>
                
                    <tr id="7c433a5b62ae4bc76f69de49cc644ed360e76b65">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c433a5b62ae4bc76f69de49cc644ed360e76b65">35</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_AdvSim_Generating_Safety-Critical_Scenarios_for_Self-Driving_Vehicles_CVPR_2021_paper.html">AdvSim: Generating Safety-Critical Scenarios for Self-Driving Vehicles</a></th>
                    </tr>
                
                    <tr id="76c5df8cef7c758c656d4afb08ab0b5e50eb51c1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/76c5df8cef7c758c656d4afb08ab0b5e50eb51c1">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Data-Uncertainty_Guided_Multi-Phase_Learning_for_Semi-Supervised_Object_Detection_CVPR_2021_paper.html">Data-Uncertainty Guided Multi-Phase Learning for Semi-Supervised Object Detection</a></th>
                    </tr>
                
                    <tr id="1403fd998f477256482474a0876d4341075ebd4b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1403fd998f477256482474a0876d4341075ebd4b">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nuriel_Permuted_AdaIN_Reducing_the_Bias_Towards_Global_Statistics_in_Image_CVPR_2021_paper.html">Permuted AdaIN: Reducing the Bias Towards Global Statistics in Image Classification</a></th>
                    </tr>
                
                    <tr id="8d2c07a282714e32b35ff51839b52eaa11c1fb2f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8d2c07a282714e32b35ff51839b52eaa11c1fb2f">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ye_Shelf-Supervised_Mesh_Prediction_in_the_Wild_CVPR_2021_paper.html">Shelf-Supervised Mesh Prediction in the Wild</a></th>
                    </tr>
                
                    <tr id="de9eee38b81021b3689046f72ab7c58fd7277325">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/de9eee38b81021b3689046f72ab7c58fd7277325">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Aberdam_Sequence-to-Sequence_Contrastive_Learning_for_Text_Recognition_CVPR_2021_paper.html">Sequence-to-Sequence Contrastive Learning for Text Recognition</a></th>
                    </tr>
                
                    <tr id="3e6998b2d2b4289202ddbc07036fd0a8f407cdf0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3e6998b2d2b4289202ddbc07036fd0a8f407cdf0">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Saleh_Probabilistic_Tracklet_Scoring_and_Inpainting_for_Multiple_Object_Tracking_CVPR_2021_paper.html">Probabilistic Tracklet Scoring and Inpainting for Multiple Object Tracking</a></th>
                    </tr>
                
                    <tr id="a53e73139d9d6474ef8a002ee9c1dea49755ebc6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a53e73139d9d6474ef8a002ee9c1dea49755ebc6">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Parmar_Dual_Contradistinctive_Generative_Autoencoder_CVPR_2021_paper.html">Dual Contradistinctive Generative Autoencoder</a></th>
                    </tr>
                
                    <tr id="2e025461fa02b3939f151ad17690ecfe3be728bd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e025461fa02b3939f151ad17690ecfe3be728bd">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_PointGuard_Provably_Robust_3D_Point_Cloud_Classification_CVPR_2021_paper.html">PointGuard: Provably Robust 3D Point Cloud Classification</a></th>
                    </tr>
                
                    <tr id="4d0620ba57ba064876f05fe5cb2c3fe04062fa03">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4d0620ba57ba064876f05fe5cb2c3fe04062fa03">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guzov_Human_POSEitioning_System_HPS_3D_Human_Pose_Estimation_and_Self-Localization_CVPR_2021_paper.html">Human POSEitioning System (HPS): 3D Human Pose Estimation and Self-Localization in Large Scenes From Body-Mounted Sensors</a></th>
                    </tr>
                
                    <tr id="7407c18bde013ba3d1acd9bea30954e782cd8d5f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7407c18bde013ba3d1acd9bea30954e782cd8d5f">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Open-Book_Video_Captioning_With_Retrieve-Copy-Generate_Network_CVPR_2021_paper.html">Open-Book Video Captioning With Retrieve-Copy-Generate Network</a></th>
                    </tr>
                
                    <tr id="1cc39d2dcd395725288f3a1bcbb392d6aa73af75">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1cc39d2dcd395725288f3a1bcbb392d6aa73af75">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Joint_Noise-Tolerant_Learning_and_Meta_Camera_Shift_Adaptation_for_Unsupervised_CVPR_2021_paper.html">Joint Noise-Tolerant Learning and Meta Camera Shift Adaptation for Unsupervised Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="4a37f3705d9adba0debea2636d2229282dec94cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4a37f3705d9adba0debea2636d2229282dec94cc">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Lifting_2D_StyleGAN_for_3D-Aware_Face_Generation_CVPR_2021_paper.html">Lifting 2D StyleGAN for 3D-Aware Face Generation</a></th>
                    </tr>
                
                    <tr id="1614645a0fa9689a187dedefa36bdf5be43734f6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1614645a0fa9689a187dedefa36bdf5be43734f6">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Valverde_There_Is_More_Than_Meets_the_Eye_Self-Supervised_Multi-Object_Detection_CVPR_2021_paper.html">There Is More Than Meets the Eye: Self-Supervised Multi-Object Detection and Tracking With Sound by Distilling Multimodal Knowledge</a></th>
                    </tr>
                
                    <tr id="472fb54ea252d56bc28b2a5f7f4726fa9619e649">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/472fb54ea252d56bc28b2a5f7f4726fa9619e649">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ding_HR-NAS_Searching_Efficient_High-Resolution_Neural_Architectures_With_Lightweight_Transformers_CVPR_2021_paper.html">HR-NAS: Searching Efficient High-Resolution Neural Architectures With Lightweight Transformers</a></th>
                    </tr>
                
                    <tr id="312e5af5f35f744bb51bc236db632a234d3b369d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/312e5af5f35f744bb51bc236db632a234d3b369d">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_Multiple_Instance_Active_Learning_for_Object_Detection_CVPR_2021_paper.html">Multiple Instance Active Learning for Object Detection</a></th>
                    </tr>
                
                    <tr id="898b985a55ae2e5d2ee43b7642dad7c4fe80afbb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/898b985a55ae2e5d2ee43b7642dad7c4fe80afbb">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tulyakov_Time_Lens_Event-Based_Video_Frame_Interpolation_CVPR_2021_paper.html">Time Lens: Event-based Video Frame Interpolation</a></th>
                    </tr>
                
                    <tr id="e6cf7c8a624d85448745d11f9b01011506db032e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e6cf7c8a624d85448745d11f9b01011506db032e">34</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Causal_Attention_for_Vision-Language_Tasks_CVPR_2021_paper.html">Causal Attention for Vision-Language Tasks</a></th>
                    </tr>
                
                    <tr id="13e26cb3742fd4a3b848a48b64c2383caf833bb5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/13e26cb3742fd4a3b848a48b64c2383caf833bb5">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Generative_PointNet_Deep_Energy-Based_Learning_on_Unordered_Point_Sets_for_CVPR_2021_paper.html">Generative PointNet: Deep Energy-Based Learning on Unordered Point Sets for 3D Generation, Reconstruction and Classification</a></th>
                    </tr>
                
                    <tr id="2e68ee0a288c3697afd209306d353f2db22892f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e68ee0a288c3697afd209306d353f2db22892f5">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Rethinking_Class_Relations_Absolute-Relative_Supervised_and_Unsupervised_Few-Shot_Learning_CVPR_2021_paper.html">Rethinking Class Relations: Absolute-Relative Supervised and Unsupervised Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="ec0d0553e9a72237497a08a3c271777302e8aea3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ec0d0553e9a72237497a08a3c271777302e8aea3">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Exploring_Heterogeneous_Clues_for_Weakly-Supervised_Audio-Visual_Video_Parsing_CVPR_2021_paper.html">Exploring Heterogeneous Clues for Weakly-Supervised Audio-Visual Video Parsing</a></th>
                    </tr>
                
                    <tr id="9d96a5aa2631d22d6f1b48c5b1a5f8e6f5214969">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9d96a5aa2631d22d6f1b48c5b1a5f8e6f5214969">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Panoptic-PolarNet_Proposal-Free_LiDAR_Point_Cloud_Panoptic_Segmentation_CVPR_2021_paper.html">Panoptic-PolarNet: Proposal-Free LiDAR Point Cloud Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="4f0448ccdfc9f9711c8677a87bf4b778861111ae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f0448ccdfc9f9711c8677a87bf4b778861111ae">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xia_SOE-Net_A_Self-Attention_and_Orientation_Encoding_Network_for_Point_Cloud_CVPR_2021_paper.html">SOE-Net: A Self-Attention and Orientation Encoding Network for Point Cloud Based Place Recognition</a></th>
                    </tr>
                
                    <tr id="38de97bf6efd47eb8381ffc33d8b5325d7746e2c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38de97bf6efd47eb8381ffc33d8b5325d7746e2c">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Duzceker_DeepVideoMVS_Multi-View_Stereo_on_Video_With_Recurrent_Spatio-Temporal_Fusion_CVPR_2021_paper.html">DeepVideoMVS: Multi-View Stereo on Video With Recurrent Spatio-Temporal Fusion</a></th>
                    </tr>
                
                    <tr id="ffcad957bd60d51f65828d68acda48e9327e5d60">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ffcad957bd60d51f65828d68acda48e9327e5d60">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gojcic_Weakly_Supervised_Learning_of_Rigid_3D_Scene_Flow_CVPR_2021_paper.html">Weakly Supervised Learning of Rigid 3D Scene Flow</a></th>
                    </tr>
                
                    <tr id="fc56ced05759ba1b2024ca77da8774439aefe93d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc56ced05759ba1b2024ca77da8774439aefe93d">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bai_Unsupervised_Multi-Source_Domain_Adaptation_for_Person_Re-Identification_CVPR_2021_paper.html">Unsupervised Multi-Source Domain Adaptation for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="863c9081dc9ab622a4830bbea6b3740073a26a4b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/863c9081dc9ab622a4830bbea6b3740073a26a4b">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Distilling_Audio-Visual_Knowledge_by_Compositional_Contrastive_Learning_CVPR_2021_paper.html">Distilling Audio-Visual Knowledge by Compositional Contrastive Learning</a></th>
                    </tr>
                
                    <tr id="c5ec16be37131398704bab98b71a154028733731">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c5ec16be37131398704bab98b71a154028733731">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wray_On_Semantic_Similarity_in_Video_Retrieval_CVPR_2021_paper.html">On Semantic Similarity in Video Retrieval</a></th>
                    </tr>
                
                    <tr id="384526a5813489ffd098aa0cd9908d9c292c23a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/384526a5813489ffd098aa0cd9908d9c292c23a2">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Han_Rethinking_Channel_Dimensions_for_Efficient_Model_Design_CVPR_2021_paper.html">Rethinking Channel Dimensions for Efficient Model Design</a></th>
                    </tr>
                
                    <tr id="8e201bdf5b69113d53462312bdb16f270a35f346">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e201bdf5b69113d53462312bdb16f270a35f346">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_SceneGraphFusion_Incremental_3D_Scene_Graph_Prediction_From_RGB-D_Sequences_CVPR_2021_paper.html">SceneGraphFusion: Incremental 3D Scene Graph Prediction From RGB-D Sequences</a></th>
                    </tr>
                
                    <tr id="949f092ea9852173ce8d014f4d6345e7e849b745">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/949f092ea9852173ce8d014f4d6345e7e849b745">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ji_Refine_Myself_by_Teaching_Myself_Feature_Refinement_via_Self-Knowledge_Distillation_CVPR_2021_paper.html">Refine Myself by Teaching Myself: Feature Refinement via Self-Knowledge Distillation</a></th>
                    </tr>
                
                    <tr id="6a371df5f9d22244834ff5078fc8f5687f618f9e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a371df5f9d22244834ff5078fc8f5687f618f9e">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Simulating_Unknown_Target_Models_for_Query-Efficient_Black-Box_Attacks_CVPR_2021_paper.html">Simulating Unknown Target Models for Query-Efficient Black-Box Attacks</a></th>
                    </tr>
                
                    <tr id="c5f8295c34bcadfcd252ed347fe1cd2329fd02c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c5f8295c34bcadfcd252ed347fe1cd2329fd02c0">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_Learnable_Graph_Matching_Incorporating_Graph_Partitioning_With_Deep_Feature_Learning_CVPR_2021_paper.html">Learnable Graph Matching: Incorporating Graph Partitioning With Deep Feature Learning for Multiple Object Tracking</a></th>
                    </tr>
                
                    <tr id="0ff365964b022c8f2479bc79ba7d93d69c6f209d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ff365964b022c8f2479bc79ba7d93d69c6f209d">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cole_Multi-Label_Learning_From_Single_Positive_Labels_CVPR_2021_paper.html">Multi-Label Learning From Single Positive Labels</a></th>
                    </tr>
                
                    <tr id="2bc53e2eb532b46057bd435be30aabb6fd3b4a03">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2bc53e2eb532b46057bd435be30aabb6fd3b4a03">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lu_MASA-SR_Matching_Acceleration_and_Spatial_Adaptation_for_Reference-Based_Image_Super-Resolution_CVPR_2021_paper.html">MASA-SR: Matching Acceleration and Spatial Adaptation for Reference-Based Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="ae793443a5c209dbfab7fd16a02a6c55ef49bb45">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae793443a5c209dbfab7fd16a02a6c55ef49bb45">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Santesteban_Self-Supervised_Collision_Handling_via_Generative_3D_Garment_Models_for_Virtual_CVPR_2021_paper.html">Self-Supervised Collision Handling via Generative 3D Garment Models for Virtual Try-On</a></th>
                    </tr>
                
                    <tr id="100c45070074d8b596c5534a45db4634afdeeb52">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/100c45070074d8b596c5534a45db4634afdeeb52">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Improving_the_Efficiency_and_Robustness_of_Deepfakes_Detection_Through_Precise_CVPR_2021_paper.html">Improving the Efficiency and Robustness of Deepfakes Detection Through Precise Geometric Features</a></th>
                    </tr>
                
                    <tr id="8ce65937232b5083f0e9da47ce1d6220bc385c49">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8ce65937232b5083f0e9da47ce1d6220bc385c49">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Suris_Learning_the_Predictability_of_the_Future_CVPR_2021_paper.html">Learning the Predictability of the Future</a></th>
                    </tr>
                
                    <tr id="aeeebcd872856b4a4db00319bbf8df37b62bc9f7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aeeebcd872856b4a4db00319bbf8df37b62bc9f7">33</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Are_Labels_Always_Necessary_for_Classifier_Accuracy_Evaluation_CVPR_2021_paper.html">Are Labels Always Necessary for Classifier Accuracy Evaluation?</a></th>
                    </tr>
                
                    <tr id="e68cf18d0003fde723ecf6b31157d5934010ffd5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e68cf18d0003fde723ecf6b31157d5934010ffd5">33</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Cheon_Perceptual_Image_Quality_Assessment_With_Transformers_CVPRW_2021_paper.html">Perceptual Image Quality Assessment With Transformers</a></th>
                    </tr>
                
                    <tr id="078ff90be5cff10a547d97ea533d69c5e5b56f61">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/078ff90be5cff10a547d97ea533d69c5e5b56f61">33</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Elhoushi_DeepShift_Towards_Multiplication-Less_Neural_Networks_CVPRW_2021_paper.html">DeepShift: Towards Multiplication-Less Neural Networks</a></th>
                    </tr>
                
                    <tr id="ef1a229d21b414dee63b9bea9ab16bbe6c7459c6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ef1a229d21b414dee63b9bea9ab16bbe6c7459c6">33</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Naphade_The_5th_AI_City_Challenge_CVPRW_2021_paper.html">The 5th AI City Challenge</a></th>
                    </tr>
                
                    <tr id="aabac0a80253ba2f05ec69abefc710cf81c59eaf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aabac0a80253ba2f05ec69abefc710cf81c59eaf">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Holistic_3D_Scene_Understanding_From_a_Single_Image_With_Implicit_CVPR_2021_paper.html">Holistic 3D Scene Understanding From a Single Image With Implicit Representation</a></th>
                    </tr>
                
                    <tr id="ada35e2c099fbde9d07a279311f4abe698341cd8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ada35e2c099fbde9d07a279311f4abe698341cd8">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Human-Like_Controllable_Image_Captioning_With_Verb-Specific_Semantic_Roles_CVPR_2021_paper.html">Human-Like Controllable Image Captioning With Verb-Specific Semantic Roles</a></th>
                    </tr>
                
                    <tr id="9bdc662c280119422e5303d874ace4bc81c3488b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9bdc662c280119422e5303d874ace4bc81c3488b">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_S3_Neural_Shape_Skeleton_and_Skinning_Fields_for_3D_Human_CVPR_2021_paper.html">S3: Neural Shape, Skeleton, and Skinning Fields for 3D Human Modeling</a></th>
                    </tr>
                
                    <tr id="833ea2e7c56cc4208f9c7bb61a8c2ed01e040081">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/833ea2e7c56cc4208f9c7bb61a8c2ed01e040081">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Robust_Representation_Learning_With_Feedback_for_Single_Image_Deraining_CVPR_2021_paper.html">Robust Representation Learning With Feedback for Single Image Deraining</a></th>
                    </tr>
                
                    <tr id="8f9d1de9e1bd60783eb75fd80c42bf99ec67363a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f9d1de9e1bd60783eb75fd80c42bf99ec67363a">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chai_Ensembling_With_Deep_Generative_Views_CVPR_2021_paper.html">Ensembling With Deep Generative Views</a></th>
                    </tr>
                
                    <tr id="552a91e5207ed4c5e6bf998b1f86d631d2a02de2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/552a91e5207ed4c5e6bf998b1f86d631d2a02de2">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zou_Stylized_Neural_Painting_CVPR_2021_paper.html">Stylized Neural Painting</a></th>
                    </tr>
                
                    <tr id="75b7967d3e89478d067120deb1cefea76fb7562a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/75b7967d3e89478d067120deb1cefea76fb7562a">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fernando_Anticipating_Human_Actions_by_Correlating_Past_With_the_Future_With_CVPR_2021_paper.html">Anticipating Human Actions by Correlating Past With the Future With Jaccard Similarity Measures</a></th>
                    </tr>
                
                    <tr id="a19a1d3dabeddf923b678a51994c652480272bbb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a19a1d3dabeddf923b678a51994c652480272bbb">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Look_Closer_To_Segment_Better_Boundary_Patch_Refinement_for_Instance_CVPR_2021_paper.html">Look Closer To Segment Better: Boundary Patch Refinement for Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="5c6407c5a357c187dd1bc1c03a83b3994d96e1e7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c6407c5a357c187dd1bc1c03a83b3994d96e1e7">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Adaptive_Class_Suppression_Loss_for_Long-Tail_Object_Detection_CVPR_2021_paper.html">Adaptive Class Suppression Loss for Long-Tail Object Detection</a></th>
                    </tr>
                
                    <tr id="15b48b3e540ca647bfc7bad1ecd937d5e1d8af15">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15b48b3e540ca647bfc7bad1ecd937d5e1d8af15">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Vx2Text_End-to-End_Learning_of_Video-Based_Text_Generation_From_Multimodal_Inputs_CVPR_2021_paper.html">Vx2Text: End-to-End Learning of Video-Based Text Generation From Multimodal Inputs</a></th>
                    </tr>
                
                    <tr id="55ea1c014e914f79a072a3c5587faad50cd9a92b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/55ea1c014e914f79a072a3c5587faad50cd9a92b">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/George_Cross_Modal_Focal_Loss_for_RGBD_Face_Anti-Spoofing_CVPR_2021_paper.html">Cross Modal Focal Loss for RGBD Face Anti-Spoofing</a></th>
                    </tr>
                
                    <tr id="7af77f8a95abfac03383519efb471d0a8582139a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7af77f8a95abfac03383519efb471d0a8582139a">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_LiDAR-Based_Panoptic_Segmentation_via_Dynamic_Shifting_Network_CVPR_2021_paper.html">LiDAR-Based Panoptic Segmentation via Dynamic Shifting Network</a></th>
                    </tr>
                
                    <tr id="f894d4aed5613314c407857ca02c25862651b381">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f894d4aed5613314c407857ca02c25862651b381">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ou_SDD-FIQA_Unsupervised_Face_Image_Quality_Assessment_With_Similarity_Distribution_Distance_CVPR_2021_paper.html">SDD-FIQA: Unsupervised Face Image Quality Assessment With Similarity Distribution Distance</a></th>
                    </tr>
                
                    <tr id="a2da30d43dc7cb5be880d656a37ce20e83897a37">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a2da30d43dc7cb5be880d656a37ce20e83897a37">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Self-Promoted_Prototype_Refinement_for_Few-Shot_Class-Incremental_Learning_CVPR_2021_paper.html">Self-Promoted Prototype Refinement for Few-Shot Class-Incremental Learning</a></th>
                    </tr>
                
                    <tr id="9c58550759a7aa9924228273f41ba946eee55aca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c58550759a7aa9924228273f41ba946eee55aca">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Towards_Compact_CNNs_via_Collaborative_Compression_CVPR_2021_paper.html">Towards Compact CNNs via Collaborative Compression</a></th>
                    </tr>
                
                    <tr id="747d1936f8318edcbf658fce5aa8256f1d7489c5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/747d1936f8318edcbf658fce5aa8256f1d7489c5">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhan_Unbalanced_Feature_Transport_for_Exemplar-Based_Image_Translation_CVPR_2021_paper.html">Unbalanced Feature Transport for Exemplar-Based Image Translation</a></th>
                    </tr>
                
                    <tr id="65c826271c6d352d92d0519a569763d6ff913c27">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/65c826271c6d352d92d0519a569763d6ff913c27">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Girish_The_Lottery_Ticket_Hypothesis_for_Object_Recognition_CVPR_2021_paper.html">The Lottery Ticket Hypothesis for Object Recognition</a></th>
                    </tr>
                
                    <tr id="600983dec4a14e52ac894851a79ea9675d49a5f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/600983dec4a14e52ac894851a79ea9675d49a5f2">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Glance_and_Gaze_Inferring_Action-Aware_Points_for_One-Stage_Human-Object_Interaction_CVPR_2021_paper.html">Glance and Gaze: Inferring Action-Aware Points for One-Stage Human-Object Interaction Detection</a></th>
                    </tr>
                
                    <tr id="cdcca029ee6afe2e9cec6fabb9cecff6c529d0d1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cdcca029ee6afe2e9cec6fabb9cecff6c529d0d1">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zolfi_The_Translucent_Patch_A_Physical_and_Universal_Attack_on_Object_CVPR_2021_paper.html">The Translucent Patch: A Physical and Universal Attack on Object Detectors</a></th>
                    </tr>
                
                    <tr id="5f625ad20b5aa170d612d3b8f4733e6067f7cfb4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f625ad20b5aa170d612d3b8f4733e6067f7cfb4">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_LaPred_Lane-Aware_Prediction_of_Multi-Modal_Future_Trajectories_of_Dynamic_Agents_CVPR_2021_paper.html">LaPred: Lane-Aware Prediction of Multi-Modal Future Trajectories of Dynamic Agents</a></th>
                    </tr>
                
                    <tr id="cf2b945be7b695d01a9abc5b099c54d8cdabac2a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cf2b945be7b695d01a9abc5b099c54d8cdabac2a">32</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Grunde-McLaughlin_AGQA_A_Benchmark_for_Compositional_Spatio-Temporal_Reasoning_CVPR_2021_paper.html">AGQA: A Benchmark for Compositional Spatio-Temporal Reasoning</a></th>
                    </tr>
                
                    <tr id="102cbf1eb78b2c0bdb998ac514dcbae27143c85a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/102cbf1eb78b2c0bdb998ac514dcbae27143c85a">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Encoder_Fusion_Network_With_Co-Attention_Embedding_for_Referring_Image_Segmentation_CVPR_2021_paper.html">Encoder Fusion Network With Co-Attention Embedding for Referring Image Segmentation</a></th>
                    </tr>
                
                    <tr id="035e8629608329a494247a667f43ef124544d4a8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/035e8629608329a494247a667f43ef124544d4a8">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Detection_Tracking_and_Counting_Meets_Drones_in_Crowds_A_Benchmark_CVPR_2021_paper.html">Detection, Tracking, and Counting Meets Drones in Crowds: A Benchmark</a></th>
                    </tr>
                
                    <tr id="8ee00a4dc4e6d3b8ac617eae30c70973bf37d63d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8ee00a4dc4e6d3b8ac617eae30c70973bf37d63d">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Semi-Supervised_Domain_Adaptation_Based_on_Dual-Level_Domain_Mixing_for_Semantic_CVPR_2021_paper.html">Semi-Supervised Domain Adaptation Based on Dual-Level Domain Mixing for Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="f9acc725e070b362fc02430f9a5b475831757b84">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f9acc725e070b362fc02430f9a5b475831757b84">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Learning_To_Filter_Siamese_Relation_Network_for_Robust_Tracking_CVPR_2021_paper.html">Learning To Filter: Siamese Relation Network for Robust Tracking</a></th>
                    </tr>
                
                    <tr id="a844cf0584ad80ba4ee497b2dfc4672648c6eb8c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a844cf0584ad80ba4ee497b2dfc4672648c6eb8c">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Robust_and_Accurate_Object_Detection_via_Adversarial_Learning_CVPR_2021_paper.html">Robust and Accurate Object Detection via Adversarial Learning</a></th>
                    </tr>
                
                    <tr id="61502aa4665add575eced99ccd159758ad5a8c4b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61502aa4665add575eced99ccd159758ad5a8c4b">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Noh_HVPR_Hybrid_Voxel-Point_Representation_for_Single-Stage_3D_Object_Detection_CVPR_2021_paper.html">HVPR: Hybrid Voxel-Point Representation for Single-Stage 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="7fe9575df3ced24994121dea3a0171fd29445b6c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7fe9575df3ced24994121dea3a0171fd29445b6c">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_DI-Fusion_Online_Implicit_3D_Reconstruction_With_Deep_Priors_CVPR_2021_paper.html">DI-Fusion: Online Implicit 3D Reconstruction With Deep Priors</a></th>
                    </tr>
                
                    <tr id="7c8029d45b25190f45fb27b400ced0868c5db3be">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c8029d45b25190f45fb27b400ced0868c5db3be">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dai_Progressive_Contour_Regression_for_Arbitrary-Shape_Scene_Text_Detection_CVPR_2021_paper.html">Progressive Contour Regression for Arbitrary-Shape Scene Text Detection</a></th>
                    </tr>
                
                    <tr id="28b2b34f31238d657ded15a81bbce22e3b96b1ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/28b2b34f31238d657ded15a81bbce22e3b96b1ad">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Equivariant_Point_Network_for_3D_Point_Cloud_Analysis_CVPR_2021_paper.html">Equivariant Point Network for 3D Point Cloud Analysis</a></th>
                    </tr>
                
                    <tr id="146d462e7372d985dc1e6cf18a1543ada451ee09">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/146d462e7372d985dc1e6cf18a1543ada451ee09">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Song_AdaStereo_A_Simple_and_Efficient_Approach_for_Adaptive_Stereo_Matching_CVPR_2021_paper.html">AdaStereo: A Simple and Efficient Approach for Adaptive Stereo Matching</a></th>
                    </tr>
                
                    <tr id="498b323fc8d2eaf9e5a29a8b33d18971c3ed1408">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/498b323fc8d2eaf9e5a29a8b33d18971c3ed1408">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Representative_Batch_Normalization_With_Feature_Calibration_CVPR_2021_paper.html">Representative Batch Normalization With Feature Calibration</a></th>
                    </tr>
                
                    <tr id="975a888b018d73aa51e31ebd84daaf4ca4e0e7e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/975a888b018d73aa51e31ebd84daaf4ca4e0e7e6">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Unsupervised_Feature_Learning_by_Cross-Level_Instance-Group_Discrimination_CVPR_2021_paper.html">Unsupervised Feature Learning by Cross-Level Instance-Group Discrimination</a></th>
                    </tr>
                
                    <tr id="bf5bbcb455e9d8976a04dd5bcdd74e5773c96b0f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bf5bbcb455e9d8976a04dd5bcdd74e5773c96b0f">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_When_Age-Invariant_Face_Recognition_Meets_Face_Age_Synthesis_A_Multi-Task_CVPR_2021_paper.html">When Age-Invariant Face Recognition Meets Face Age Synthesis: A Multi-Task Learning Framework</a></th>
                    </tr>
                
                    <tr id="35549d6a4c5e09e8d2b3de95940dde38e41905ec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/35549d6a4c5e09e8d2b3de95940dde38e41905ec">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Few-Shot_3D_Point_Cloud_Semantic_Segmentation_CVPR_2021_paper.html">Few-Shot 3D Point Cloud Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="5eb5002046b604d2ee29a5af2e29f352eee21609">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5eb5002046b604d2ee29a5af2e29f352eee21609">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Cross-Domain_Adaptive_Clustering_for_Semi-Supervised_Domain_Adaptation_CVPR_2021_paper.html">Cross-Domain Adaptive Clustering for Semi-Supervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="cef2370a769df907e0badcf1c80081f7efcdb1f3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cef2370a769df907e0badcf1c80081f7efcdb1f3">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xiao_Improving_Transferability_of_Adversarial_Patches_on_Face_Recognition_With_Generative_CVPR_2021_paper.html">Improving Transferability of Adversarial Patches on Face Recognition With Generative Models</a></th>
                    </tr>
                
                    <tr id="7f6189b061500b7c60e14f4c4e8492d70f5a79ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7f6189b061500b7c60e14f4c4e8492d70f5a79ab">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Miao_VSPW_A_Large-scale_Dataset_for_Video_Scene_Parsing_in_the_CVPR_2021_paper.html">VSPW: A Large-scale Dataset for Video Scene Parsing in the Wild</a></th>
                    </tr>
                
                    <tr id="336b31c3f26317dfe0222cad9818534ac753fb97">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/336b31c3f26317dfe0222cad9818534ac753fb97">31</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Stadler_Improving_Multiple_Pedestrian_Tracking_by_Track_Management_and_Occlusion_Handling_CVPR_2021_paper.html">Improving Multiple Pedestrian Tracking by Track Management and Occlusion Handling</a></th>
                    </tr>
                
                    <tr id="ca2073cc1907cd1f357fdda8de71ff1405628ce1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ca2073cc1907cd1f357fdda8de71ff1405628ce1">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Body_Meshes_as_Points_CVPR_2021_paper.html">Body Meshes as Points</a></th>
                    </tr>
                
                    <tr id="61d6408a3a811df01ace0f3f0b028102ac0c91b3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61d6408a3a811df01ace0f3f0b028102ac0c91b3">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kotovenko_Rethinking_Style_Transfer_From_Pixels_to_Parameterized_Brushstrokes_CVPR_2021_paper.html">Rethinking Style Transfer: From Pixels to Parameterized Brushstrokes</a></th>
                    </tr>
                
                    <tr id="65b166c644478c83c745ce8befc084411048d424">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/65b166c644478c83c745ce8befc084411048d424">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lv_Learning_Normal_Dynamics_in_Videos_With_Meta_Prototype_Network_CVPR_2021_paper.html">Learning Normal Dynamics in Videos With Meta Prototype Network</a></th>
                    </tr>
                
                    <tr id="10dcd02c7ad3c319ca566d7b86f2b06591a3da29">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/10dcd02c7ad3c319ca566d7b86f2b06591a3da29">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Spatial_Feature_Calibration_and_Temporal_Fusion_for_Effective_One-Stage_Video_CVPR_2021_paper.html">Spatial Feature Calibration and Temporal Fusion for Effective One-Stage Video Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="e0e72ce5d83dc4a0c419b4b55ff97340d6035d8c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e0e72ce5d83dc4a0c419b4b55ff97340d6035d8c">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Henzler_Unsupervised_Learning_of_3D_Object_Categories_From_Videos_in_the_CVPR_2021_paper.html">Unsupervised Learning of 3D Object Categories From Videos in the Wild</a></th>
                    </tr>
                
                    <tr id="a270f1ad1e0b641c56905948e13a803bbfcd0d14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a270f1ad1e0b641c56905948e13a803bbfcd0d14">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Group_Collaborative_Learning_for_Co-Salient_Object_Detection_CVPR_2021_paper.html">Group Collaborative Learning for Co-Salient Object Detection</a></th>
                    </tr>
                
                    <tr id="598b2441396f5287b462bf1684ffc4be5ec8d800">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/598b2441396f5287b462bf1684ffc4be5ec8d800">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Faster_Meta_Update_Strategy_for_Noise-Robust_Deep_Learning_CVPR_2021_paper.html">Faster Meta Update Strategy for Noise-Robust Deep Learning</a></th>
                    </tr>
                
                    <tr id="ad895df5cff59dd340c90a78ee3d084b0dd52087">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ad895df5cff59dd340c90a78ee3d084b0dd52087">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tritrong_Repurposing_GANs_for_One-Shot_Semantic_Part_Segmentation_CVPR_2021_paper.html">Repurposing GANs for One-Shot Semantic Part Segmentation</a></th>
                    </tr>
                
                    <tr id="022b59b652b6f10f832144d622a2cc6beb6290af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/022b59b652b6f10f832144d622a2cc6beb6290af">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tian_Cyclic_Co-Learning_of_Sounding_Object_Visual_Grounding_and_Sound_Separation_CVPR_2021_paper.html">Cyclic Co-Learning of Sounding Object Visual Grounding and Sound Separation</a></th>
                    </tr>
                
                    <tr id="68e9e5fbc268426237ddd09c3e1b12e4207b38ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/68e9e5fbc268426237ddd09c3e1b12e4207b38ff">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Refining_Pseudo_Labels_With_Clustering_Consensus_Over_Generations_for_Unsupervised_CVPR_2021_paper.html">Refining Pseudo Labels With Clustering Consensus Over Generations for Unsupervised Object Re-Identification</a></th>
                    </tr>
                
                    <tr id="a629321af8e3ee34e4a4e65c23c4d949b89380af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a629321af8e3ee34e4a4e65c23c4d949b89380af">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Grigorev_StylePeople_A_Generative_Model_of_Fullbody_Human_Avatars_CVPR_2021_paper.html">StylePeople: A Generative Model of Fullbody Human Avatars</a></th>
                    </tr>
                
                    <tr id="f603d181652341ce0c2bb858d4d0ae4c0778eee9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f603d181652341ce0c2bb858d4d0ae4c0778eee9">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Discriminative_Appearance_Modeling_With_Multi-Track_Pooling_for_Real-Time_Multi-Object_Tracking_CVPR_2021_paper.html">Discriminative Appearance Modeling With Multi-Track Pooling for Real-Time Multi-Object Tracking</a></th>
                    </tr>
                
                    <tr id="7a1f5c13adc6577f4eb6278a374fa55ed30decc2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a1f5c13adc6577f4eb6278a374fa55ed30decc2">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_Towards_Fast_and_Accurate_Real-World_Depth_Super-Resolution_Benchmark_Dataset_and_CVPR_2021_paper.html">Towards Fast and Accurate Real-World Depth Super-Resolution: Benchmark Dataset and Baseline</a></th>
                    </tr>
                
                    <tr id="5c4d6efef862e753cfecc8c6fcaab8df176d7db6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c4d6efef862e753cfecc8c6fcaab8df176d7db6">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Combined_Depth_Space_Based_Architecture_Search_for_Person_Re-Identification_CVPR_2021_paper.html">Combined Depth Space Based Architecture Search for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="0f85c82683fef2ec5321c061b170cebc23f4bc2d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0f85c82683fef2ec5321c061b170cebc23f4bc2d">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Zero-Shot_Adversarial_Quantization_CVPR_2021_paper.html">Zero-Shot Adversarial Quantization</a></th>
                    </tr>
                
                    <tr id="adcb8cad96a2f73e0a2ef8b7ed1737af804de30b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/adcb8cad96a2f73e0a2ef8b7ed1737af804de30b">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chaman_Truly_Shift-Invariant_Convolutional_Neural_Networks_CVPR_2021_paper.html">Truly Shift-Invariant Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="823a7823d01ab3db8d73ed7a5e87bbe1b28d2394">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/823a7823d01ab3db8d73ed7a5e87bbe1b28d2394">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_GeoSim_Realistic_Video_Simulation_via_Geometry-Aware_Composition_for_Self-Driving_CVPR_2021_paper.html">GeoSim: Realistic Video Simulation via Geometry-Aware Composition for Self-Driving</a></th>
                    </tr>
                
                    <tr id="ec83119d0a37970d26185b6837aa677ca5fa6649">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ec83119d0a37970d26185b6837aa677ca5fa6649">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_3D-MAN_3D_Multi-Frame_Attention_Network_for_Object_Detection_CVPR_2021_paper.html">3D-MAN: 3D Multi-Frame Attention Network for Object Detection</a></th>
                    </tr>
                
                    <tr id="455c5e74b1652d8b341c475b22e11c95f92a233d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/455c5e74b1652d8b341c475b22e11c95f92a233d">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Drafting_and_Revision_Laplacian_Pyramid_Network_for_Fast_High-Quality_Artistic_CVPR_2021_paper.html">Drafting and Revision: Laplacian Pyramid Network for Fast High-Quality Artistic Style Transfer</a></th>
                    </tr>
                
                    <tr id="f0b5bee519034c9fa3bf664432542c14e414cdcb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f0b5bee519034c9fa3bf664432542c14e414cdcb">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ghodrati_FrameExit_Conditional_Early_Exiting_for_Efficient_Video_Recognition_CVPR_2021_paper.html">FrameExit: Conditional Early Exiting for Efficient Video Recognition</a></th>
                    </tr>
                
                    <tr id="58875ecfe5ad502bab1fffa24ca2c08cf3d47586">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/58875ecfe5ad502bab1fffa24ca2c08cf3d47586">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Differentiable_Multi-Granularity_Human_Representation_Learning_for_Instance-Aware_Human_Semantic_Parsing_CVPR_2021_paper.html">Differentiable Multi-Granularity Human Representation Learning for Instance-Aware Human Semantic Parsing</a></th>
                    </tr>
                
                    <tr id="d033c802467b2dd8e91a69abaf62a2e5b941d3a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d033c802467b2dd8e91a69abaf62a2e5b941d3a6">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ye_Closing_the_Loop_Joint_Rain_Generation_and_Removal_via_Disentangled_CVPR_2021_paper.html">Closing the Loop: Joint Rain Generation and Removal via Disentangled Image Translation</a></th>
                    </tr>
                
                    <tr id="ba04bfa1ee12acb2fda47bbf537b3bb0b6478590">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ba04bfa1ee12acb2fda47bbf537b3bb0b6478590">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_PointFlow_Flowing_Semantics_Through_Points_for_Aerial_Image_Segmentation_CVPR_2021_paper.html">PointFlow: Flowing Semantics Through Points for Aerial Image Segmentation</a></th>
                    </tr>
                
                    <tr id="b1f6397717d3cbf84e89081a47205f8ed8395d22">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b1f6397717d3cbf84e89081a47205f8ed8395d22">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Seo_Look_Before_You_Speak_Visually_Contextualized_Utterances_CVPR_2021_paper.html">Look Before You Speak: Visually Contextualized Utterances</a></th>
                    </tr>
                
                    <tr id="a5e56209623c52f3f7ddfaa92f9e44cfc6ffc972">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a5e56209623c52f3f7ddfaa92f9e44cfc6ffc972">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Effective_Sparsification_of_Neural_Networks_With_Global_Sparsity_Constraint_CVPR_2021_paper.html">Effective Sparsification of Neural Networks With Global Sparsity Constraint</a></th>
                    </tr>
                
                    <tr id="03a3f5159394856aac1b7d481e576000818d452d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/03a3f5159394856aac1b7d481e576000818d452d">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qian_Robust_Multimodal_Vehicle_Detection_in_Foggy_Weather_Using_Complementary_Lidar_CVPR_2021_paper.html">Robust Multimodal Vehicle Detection in Foggy Weather Using Complementary Lidar and Radar Signals</a></th>
                    </tr>
                
                    <tr id="a4fcd3ff4a766e17e3959c1b10b2455960716dff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a4fcd3ff4a766e17e3959c1b10b2455960716dff">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Rezaei_On_the_Difficulty_of_Membership_Inference_Attacks_CVPR_2021_paper.html">On the Difficulty of Membership Inference Attacks</a></th>
                    </tr>
                
                    <tr id="7be3206f6e5635565b45e002de29766673660a68">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7be3206f6e5635565b45e002de29766673660a68">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_MotionRNN_A_Flexible_Model_for_Video_Prediction_With_Spacetime-Varying_Motions_CVPR_2021_paper.html">MotionRNN: A Flexible Model for Video Prediction With Spacetime-Varying Motions</a></th>
                    </tr>
                
                    <tr id="45346c3ec5ac368e86f63502fa87bbd98b12cc81">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/45346c3ec5ac368e86f63502fa87bbd98b12cc81">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Memory_Oriented_Transfer_Learning_for_Semi-Supervised_Image_Deraining_CVPR_2021_paper.html">Memory Oriented Transfer Learning for Semi-Supervised Image Deraining</a></th>
                    </tr>
                
                    <tr id="701c56592f6b4132f5869f175a46c88df12a3340">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/701c56592f6b4132f5869f175a46c88df12a3340">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Siyao_Deep_Animation_Video_Interpolation_in_the_Wild_CVPR_2021_paper.html">Deep Animation Video Interpolation in the Wild</a></th>
                    </tr>
                
                    <tr id="738bee4cdfe7ef0489ab15bb26aac7fdf010b348">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/738bee4cdfe7ef0489ab15bb26aac7fdf010b348">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Improving_Weakly_Supervised_Visual_Grounding_by_Contrastive_Knowledge_Distillation_CVPR_2021_paper.html">Improving Weakly Supervised Visual Grounding by Contrastive Knowledge Distillation</a></th>
                    </tr>
                
                    <tr id="4d98a44c7c99ef55f4e1febcc817ad39c184e3d6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4d98a44c7c99ef55f4e1febcc817ad39c184e3d6">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Narayanan_Divide-and-Conquer_for_Lane-Aware_Diverse_Trajectory_Prediction_CVPR_2021_paper.html">Divide-and-Conquer for Lane-Aware Diverse Trajectory Prediction</a></th>
                    </tr>
                
                    <tr id="6ab82d3abe6c1b09ca9695f901ed927a0171a875">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6ab82d3abe6c1b09ca9695f901ed927a0171a875">30</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Progressive_Domain_Expansion_Network_for_Single_Domain_Generalization_CVPR_2021_paper.html">Progressive Domain Expansion Network for Single Domain Generalization</a></th>
                    </tr>
                
                    <tr id="cd423b798967c42f9efc7aa5efe09917a5c37fd3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd423b798967c42f9efc7aa5efe09917a5c37fd3">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Han_Dual_Contrastive_Learning_for_Unsupervised_Image-to-Image_Translation_CVPRW_2021_paper.html">Dual Contrastive Learning for Unsupervised Image-to-Image Translation</a></th>
                    </tr>
                
                    <tr id="59a5e92a036097af01a2c1cc690162a4951584f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/59a5e92a036097af01a2c1cc690162a4951584f5">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Gu_NTIRE_2021_Challenge_on_Perceptual_Image_Quality_Assessment_CVPRW_2021_paper.html">NTIRE 2021 Challenge on Perceptual Image Quality Assessment</a></th>
                    </tr>
                
                    <tr id="4c4246390cbb9c81264c7e89afe89afef7c69610">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c4246390cbb9c81264c7e89afe89afef7c69610">30</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ChaLearn/html/Jiang_Skeleton_Aware_Multi-Modal_Sign_Language_Recognition_CVPRW_2021_paper.html">Skeleton Aware Multi-Modal Sign Language Recognition</a></th>
                    </tr>
                
                    <tr id="6e574db0923c1d6e364c9b655ba7da831a9afd1d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6e574db0923c1d6e364c9b655ba7da831a9afd1d">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Maho_SurFree_A_Fast_Surrogate-Free_Black-Box_Attack_CVPR_2021_paper.html">SurFree: A Fast Surrogate-Free Black-Box Attack</a></th>
                    </tr>
                
                    <tr id="8e44fc1e4ee0ff81040b9beafb6ce5a4ce049c50">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e44fc1e4ee0ff81040b9beafb6ce5a4ce049c50">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pang_Trajectory_Prediction_With_Latent_Belief_Energy-Based_Model_CVPR_2021_paper.html">Trajectory Prediction With Latent Belief Energy-Based Model</a></th>
                    </tr>
                
                    <tr id="db88a97c8fe011f3069f5f3e48ce297680a751ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db88a97c8fe011f3069f5f3e48ce297680a751ab">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Towards_Efficient_Tensor_Decomposition-Based_DNN_Model_Compression_With_Optimization_Framework_CVPR_2021_paper.html">Towards Efficient Tensor Decomposition-Based DNN Model Compression With Optimization Framework</a></th>
                    </tr>
                
                    <tr id="7a14cf615f30feb0a650a7ffa1c0a3d650736899">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a14cf615f30feb0a650a7ffa1c0a3d650736899">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cherepkov_Navigating_the_GAN_Parameter_Space_for_Semantic_Image_Editing_CVPR_2021_paper.html">Navigating the GAN Parameter Space for Semantic Image Editing</a></th>
                    </tr>
                
                    <tr id="ad1bbb2cc0fc7ea460cb8af6bf0c6e10cbffb66b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ad1bbb2cc0fc7ea460cb8af6bf0c6e10cbffb66b">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Reiss_Every_Annotation_Counts_Multi-Label_Deep_Supervision_for_Medical_Image_Segmentation_CVPR_2021_paper.html">Every Annotation Counts: Multi-Label Deep Supervision for Medical Image Segmentation</a></th>
                    </tr>
                
                    <tr id="5b990c4e07e315b44a8e15c2e9d9290bbd5240b6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b990c4e07e315b44a8e15c2e9d9290bbd5240b6">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Park_Bridge_To_Answer_Structure-Aware_Graph_Interaction_Network_for_Video_Question_CVPR_2021_paper.html">Bridge To Answer: Structure-Aware Graph Interaction Network for Video Question Answering</a></th>
                    </tr>
                
                    <tr id="66428bc1f1344e6d393a7dac2fde0e2fac73a7f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/66428bc1f1344e6d393a7dac2fde0e2fac73a7f9">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Structured_Multi-Level_Interaction_Network_for_Video_Moment_Localization_via_Language_CVPR_2021_paper.html">Structured Multi-Level Interaction Network for Video Moment Localization via Language Query</a></th>
                    </tr>
                
                    <tr id="1b20d22cebe2d591530abd297b7d519176ebdfe5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1b20d22cebe2d591530abd297b7d519176ebdfe5">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_ForgeryNet_A_Versatile_Benchmark_for_Comprehensive_Forgery_Analysis_CVPR_2021_paper.html">ForgeryNet: A Versatile Benchmark for Comprehensive Forgery Analysis</a></th>
                    </tr>
                
                    <tr id="7f3c4a3fe5bb372be36334deb928362ddfc35e03">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7f3c4a3fe5bb372be36334deb928362ddfc35e03">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dubey_Adaptive_Methods_for_Real-World_Domain_Generalization_CVPR_2021_paper.html">Adaptive Methods for Real-World Domain Generalization</a></th>
                    </tr>
                
                    <tr id="09f3c809cfaab3340baa92619f4bfdbb3669d00b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/09f3c809cfaab3340baa92619f4bfdbb3669d00b">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Wasserstein_Contrastive_Representation_Distillation_CVPR_2021_paper.html">Wasserstein Contrastive Representation Distillation</a></th>
                    </tr>
                
                    <tr id="2ecc8ef9277bf4e69287c732dacf5a6018716f64">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ecc8ef9277bf4e69287c732dacf5a6018716f64">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zanfir_Neural_Descent_for_Visual_3D_Human_Pose_and_Shape_CVPR_2021_paper.html">Neural Descent for Visual 3D Human Pose and Shape</a></th>
                    </tr>
                
                    <tr id="8395cff3684f3b19537defc2a9e9a71f9b01ee29">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8395cff3684f3b19537defc2a9e9a71f9b01ee29">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Van_Etten_The_Multi-Temporal_Urban_Development_SpaceNet_Dataset_CVPR_2021_paper.html">The Multi-Temporal Urban Development SpaceNet Dataset</a></th>
                    </tr>
                
                    <tr id="ae56c020fd4a24043492deeed24f516c3156ecd3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae56c020fd4a24043492deeed24f516c3156ecd3">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Takahashi_Densely_Connected_Multi-Dilated_Convolutional_Networks_for_Dense_Prediction_Tasks_CVPR_2021_paper.html">Densely connected multidilated convolutional networks for dense prediction tasks</a></th>
                    </tr>
                
                    <tr id="0a5bbf19489815a0b652232ead78a8cca99731d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a5bbf19489815a0b652232ead78a8cca99731d2">29</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Depth-Conditioned_Dynamic_Message_Propagation_for_Monocular_3D_Object_Detection_CVPR_2021_paper.html">Depth-conditioned Dynamic Message Propagation for Monocular 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="fdbcea7e83dbfee949438585f51c2791b4eea8a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fdbcea7e83dbfee949438585f51c2791b4eea8a2">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Raj_Pixel-Aligned_Volumetric_Avatars_CVPR_2021_paper.html">Pixel-Aligned Volumetric Avatars</a></th>
                    </tr>
                
                    <tr id="9fdfc2df42a159dbf1134ad9b367c2afd904ecd0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9fdfc2df42a159dbf1134ad9b367c2afd904ecd0">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jalwana_CAMERAS_Enhanced_Resolution_and_Sanity_Preserving_Class_Activation_Mapping_for_CVPR_2021_paper.html">CAMERAS: Enhanced Resolution and Sanity Preserving Class Activation Mapping for Image Saliency</a></th>
                    </tr>
                
                    <tr id="850b9f5c10050a95158456e3f465f9a40eef9cf6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/850b9f5c10050a95158456e3f465f9a40eef9cf6">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Cascaded_Prediction_Network_via_Segment_Tree_for_Temporal_Video_Grounding_CVPR_2021_paper.html">Cascaded Prediction Network via Segment Tree for Temporal Video Grounding</a></th>
                    </tr>
                
                    <tr id="75f1eaba8515684c77f97f58b198585332858df2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/75f1eaba8515684c77f97f58b198585332858df2">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Monocular_Real-Time_Full_Body_Capture_With_Inter-Part_Correlations_CVPR_2021_paper.html">Monocular Real-Time Full Body Capture With Inter-Part Correlations</a></th>
                    </tr>
                
                    <tr id="382ee3b55d4a9e93b0fb7565fba693799e26f082">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/382ee3b55d4a9e93b0fb7565fba693799e26f082">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_3D-to-2D_Distillation_for_Indoor_Scene_Parsing_CVPR_2021_paper.html">3D-to-2D Distillation for Indoor Scene Parsing</a></th>
                    </tr>
                
                    <tr id="3f1244a9f3142e03d412673b45b8245cad49b245">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f1244a9f3142e03d412673b45b8245cad49b245">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tian_Farewell_to_Mutual_Information_Variational_Distillation_for_Cross-Modal_Person_Re-Identification_CVPR_2021_paper.html">Farewell to Mutual Information: Variational Distillation for Cross-Modal Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="ee3ec7893003ba55175a183b13baad845e5375e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ee3ec7893003ba55175a183b13baad845e5375e1">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bhunia_More_Photos_Are_All_You_Need_Semi-Supervised_Learning_for_Fine-Grained_CVPR_2021_paper.html">More Photos Are All You Need: Semi-Supervised Learning for Fine-Grained Sketch Based Image Retrieval</a></th>
                    </tr>
                
                    <tr id="99b7a308e82165890e0a14e577715f81e11e8f89">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/99b7a308e82165890e0a14e577715f81e11e8f89">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Reinforced_Attention_for_Few-Shot_Learning_and_Beyond_CVPR_2021_paper.html">Reinforced Attention for Few-Shot Learning and Beyond</a></th>
                    </tr>
                
                    <tr id="1e3074c3dac8f924e21c79a3eb606606d0c0a70a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1e3074c3dac8f924e21c79a3eb606606d0c0a70a">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kittenplon_FlowStep3D_Model_Unrolling_for_Self-Supervised_Scene_Flow_Estimation_CVPR_2021_paper.html">FlowStep3D: Model Unrolling for Self-Supervised Scene Flow Estimation</a></th>
                    </tr>
                
                    <tr id="08a184f5fd27cb168b054a35e6768066380dbe05">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/08a184f5fd27cb168b054a35e6768066380dbe05">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Regularization_Strategy_for_Point_Cloud_via_Rigidly_Mixed_Sample_CVPR_2021_paper.html">Regularization Strategy for Point Cloud via Rigidly Mixed Sample</a></th>
                    </tr>
                
                    <tr id="bd3357341ca482665a2e101b426125365a0f4852">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bd3357341ca482665a2e101b426125365a0f4852">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Locally_Aware_Piecewise_Transformation_Fields_for_3D_Human_Mesh_Registration_CVPR_2021_paper.html">Locally Aware Piecewise Transformation Fields for 3D Human Mesh Registration</a></th>
                    </tr>
                
                    <tr id="33660d7dc0e786bdedd811281b88f2253d512f4e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/33660d7dc0e786bdedd811281b88f2253d512f4e">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Karkus_Differentiable_SLAM-Net_Learning_Particle_SLAM_for_Visual_Navigation_CVPR_2021_paper.html">Differentiable SLAM-Net: Learning Particle SLAM for Visual Navigation</a></th>
                    </tr>
                
                    <tr id="29b9ef8660e4a9d01af7ea498efca4f8fc712010">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/29b9ef8660e4a9d01af7ea498efca4f8fc712010">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Cross-View_Cross-Scene_Multi-View_Crowd_Counting_CVPR_2021_paper.html">Cross-View Cross-Scene Multi-View Crowd Counting</a></th>
                    </tr>
                
                    <tr id="c8a8e810ccc0d07fc04b66b525bab3c3beaf9b1f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c8a8e810ccc0d07fc04b66b525bab3c3beaf9b1f">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dang_Nearest_Neighbor_Matching_for_Deep_Clustering_CVPR_2021_paper.html">Nearest Neighbor Matching for Deep Clustering</a></th>
                    </tr>
                
                    <tr id="3728ac58c3a72f0d630cff8d977665b8a4b5f10d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3728ac58c3a72f0d630cff8d977665b8a4b5f10d">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Affordance_Transfer_Learning_for_Human-Object_Interaction_Detection_CVPR_2021_paper.html">Affordance Transfer Learning for Human-Object Interaction Detection</a></th>
                    </tr>
                
                    <tr id="857c2aa4341de38bf035ac266a9f6789e42a08a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/857c2aa4341de38bf035ac266a9f6789e42a08a0">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Multi-Stage_Aggregated_Transformer_Network_for_Temporal_Language_Localization_in_Videos_CVPR_2021_paper.html">Multi-Stage Aggregated Transformer Network for Temporal Language Localization in Videos</a></th>
                    </tr>
                
                    <tr id="4c7971c08180edcce73819baaebac76e19949edd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c7971c08180edcce73819baaebac76e19949edd">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_ORDisCo_Effective_and_Efficient_Usage_of_Incremental_Unlabeled_Data_for_CVPR_2021_paper.html">ORDisCo: Effective and Efficient Usage of Incremental Unlabeled Data for Semi-Supervised Continual Learning</a></th>
                    </tr>
                
                    <tr id="32e3b75c147ca76b926d9784658da3e8f06a1f80">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/32e3b75c147ca76b926d9784658da3e8f06a1f80">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liang_High-Resolution_Photorealistic_Image_Translation_in_Real-Time_A_Laplacian_Pyramid_Translation_CVPR_2021_paper.html">High-Resolution Photorealistic Image Translation in Real-Time: A Laplacian Pyramid Translation Network</a></th>
                    </tr>
                
                    <tr id="7628818bba9229c364aa9024fe216afbd69d1979">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7628818bba9229c364aa9024fe216afbd69d1979">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wei_Shallow_Feature_Matters_for_Weakly_Supervised_Object_Localization_CVPR_2021_paper.html">Shallow Feature Matters for Weakly Supervised Object Localization</a></th>
                    </tr>
                
                    <tr id="6116cde7fc65eff29a1b8118b034f87909f2237f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6116cde7fc65eff29a1b8118b034f87909f2237f">28</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Singla_Understanding_Failures_of_Deep_Networks_via_Robust_Feature_Extraction_CVPR_2021_paper.html">Understanding Failures of Deep Networks via Robust Feature Extraction</a></th>
                    </tr>
                
                    <tr id="b345d9055cde572ba9ed4705ff5b8c6420c10d12">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b345d9055cde572ba9ed4705ff5b8c6420c10d12">28</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Chen_HDRUNet_Single_Image_HDR_Reconstruction_With_Denoising_and_Dequantization_CVPRW_2021_paper.html">HDRUNet: Single Image HDR Reconstruction With Denoising and Dequantization</a></th>
                    </tr>
                
                    <tr id="9c9b45857fb2b27067a38ee0d2e80aad07de211b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c9b45857fb2b27067a38ee0d2e80aad07de211b">28</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Ignatov_Real-Time_Video_Super-Resolution_on_Smartphones_With_Deep_Learning_Mobile_AI_CVPRW_2021_paper.html">Real-Time Video Super-Resolution on Smartphones With Deep Learning, Mobile AI 2021 Challenge: Report</a></th>
                    </tr>
                
                    <tr id="a868b61f141bce392a15b8db1a79a658ad03661e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a868b61f141bce392a15b8db1a79a658ad03661e">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pintore_SliceNet_Deep_Dense_Depth_Estimation_From_a_Single_Indoor_Panorama_CVPR_2021_paper.html">SliceNet: Deep Dense Depth Estimation From a Single Indoor Panorama Using a Slice-Based Representation</a></th>
                    </tr>
                
                    <tr id="dd063f255191a4dbce9f34c32c26a09d28603c3e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dd063f255191a4dbce9f34c32c26a09d28603c3e">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_From_Synthetic_to_Real_Unsupervised_Domain_Adaptation_for_Animal_Pose_CVPR_2021_paper.html">From Synthetic to Real: Unsupervised Domain Adaptation for Animal Pose Estimation</a></th>
                    </tr>
                
                    <tr id="9d0f18f1a92a1ec5fac9dd8d0089f621e7130981">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9d0f18f1a92a1ec5fac9dd8d0089f621e7130981">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_TransFill_Reference-Guided_Image_Inpainting_by_Merging_Multiple_Color_and_Spatial_CVPR_2021_paper.html">TransFill: Reference-Guided Image Inpainting by Merging Multiple Color and Spatial Transformations</a></th>
                    </tr>
                
                    <tr id="fc79ea4a0895078f3958f697c075d347d57b4c8a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc79ea4a0895078f3958f697c075d347d57b4c8a">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Iterative_Filter_Adaptive_Network_for_Single_Image_Defocus_Deblurring_CVPR_2021_paper.html">Iterative Filter Adaptive Network for Single Image Defocus Deblurring</a></th>
                    </tr>
                
                    <tr id="bcbdb67e861ed6afd99e6b88d73318d979fd87ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bcbdb67e861ed6afd99e6b88d73318d979fd87ac">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Haresh_Learning_by_Aligning_Videos_in_Time_CVPR_2021_paper.html">Learning by Aligning Videos in Time</a></th>
                    </tr>
                
                    <tr id="2cc471bc4f1aaa8009c62a867ab90265c6749c19">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2cc471bc4f1aaa8009c62a867ab90265c6749c19">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Positive_Sample_Propagation_Along_the_Audio-Visual_Event_Line_CVPR_2021_paper.html">Positive Sample Propagation Along the Audio-Visual Event Line</a></th>
                    </tr>
                
                    <tr id="5590ca49c1fd9487a844368ac1c7760912bc65e9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5590ca49c1fd9487a844368ac1c7760912bc65e9">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Network_Quantization_With_Element-Wise_Gradient_Scaling_CVPR_2021_paper.html">Network Quantization With Element-Wise Gradient Scaling</a></th>
                    </tr>
                
                    <tr id="31d5494ad29e93dc22a00965e7bbc21c77e7634f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/31d5494ad29e93dc22a00965e7bbc21c77e7634f">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Adversarial_Robustness_Under_Long-Tailed_Distribution_CVPR_2021_paper.html">Adversarial Robustness Under Long-Tailed Distribution</a></th>
                    </tr>
                
                    <tr id="e88d3e5e2ea364322581ed341a6c4941f05e213f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e88d3e5e2ea364322581ed341a6c4941f05e213f">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Cross-View_Regularization_for_Domain_Adaptive_Panoptic_Segmentation_CVPR_2021_paper.html">Cross-View Regularization for Domain Adaptive Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="289ac3c18b4d5282440643a78c8e595256b14cd4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/289ac3c18b4d5282440643a78c8e595256b14cd4">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Towards_Improving_the_Consistency_Efficiency_and_Flexibility_of_Differentiable_Neural_CVPR_2021_paper.html">Towards Improving the Consistency, Efficiency, and Flexibility of Differentiable Neural Architecture Search</a></th>
                    </tr>
                
                    <tr id="e3d096aa5a077e03d4eb52d2e93f0deeb83f9531">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e3d096aa5a077e03d4eb52d2e93f0deeb83f9531">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Transformation_Invariant_Few-Shot_Object_Detection_CVPR_2021_paper.html">Transformation Invariant Few-Shot Object Detection</a></th>
                    </tr>
                
                    <tr id="a6721a2fd36f1d6432024a15385a26309379b078">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a6721a2fd36f1d6432024a15385a26309379b078">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Probabilistic_Modeling_of_Semantic_Ambiguity_for_Scene_Graph_Generation_CVPR_2021_paper.html">Probabilistic Modeling of Semantic Ambiguity for Scene Graph Generation</a></th>
                    </tr>
                
                    <tr id="c66af3b80fdd6e87cb5ad5d54195d61513b29bc6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c66af3b80fdd6e87cb5ad5d54195d61513b29bc6">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Neural_Architecture_Search_With_Random_Labels_CVPR_2021_paper.html">Neural Architecture Search With Random Labels</a></th>
                    </tr>
                
                    <tr id="664916f59e508a04ba5046c10143f1ac183cd393">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/664916f59e508a04ba5046c10143f1ac183cd393">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_High-Fidelity_and_Arbitrary_Face_Editing_CVPR_2021_paper.html">High-Fidelity and Arbitrary Face Editing</a></th>
                    </tr>
                
                    <tr id="0fa3bea314ce57187a55c242222a56d9d598fcb0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0fa3bea314ce57187a55c242222a56d9d598fcb0">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Primitive_Representation_Learning_for_Scene_Text_Recognition_CVPR_2021_paper.html">Primitive Representation Learning for Scene Text Recognition</a></th>
                    </tr>
                
                    <tr id="1b945b488732aff7583319b8e962854c5c327926">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1b945b488732aff7583319b8e962854c5c327926">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Long_Multi-view_Depth_Estimation_using_Epipolar_Spatio-Temporal_Networks_CVPR_2021_paper.html">Multi-view Depth Estimation using Epipolar Spatio-Temporal Networks</a></th>
                    </tr>
                
                    <tr id="6c1e4ad26ad80872b17436f1d4b419a93f3fb58d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c1e4ad26ad80872b17436f1d4b419a93f3fb58d">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Baek_What_if_We_Only_Use_Real_Datasets_for_Scene_Text_CVPR_2021_paper.html">What if We Only Use Real Datasets for Scene Text Recognition? Toward Scene Text Recognition With Fewer Labels</a></th>
                    </tr>
                
                    <tr id="01d7ee36fb8a04a694ef9ff9f6077fba4eecd6c3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01d7ee36fb8a04a694ef9ff9f6077fba4eecd6c3">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_a_Facial_Expression_Embedding_Disentangled_From_Identity_CVPR_2021_paper.html">Learning a Facial Expression Embedding Disentangled From Identity</a></th>
                    </tr>
                
                    <tr id="489f9126e1b82d332f10a7f5a9ded0162e832f88">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/489f9126e1b82d332f10a7f5a9ded0162e832f88">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Choi_Shared_Cross-Modal_Trajectory_Prediction_for_Autonomous_Driving_CVPR_2021_paper.html">Shared Cross-Modal Trajectory Prediction for Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="5ed692fb9f93ea1cb8a982be58634a5a4cbfb5da">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5ed692fb9f93ea1cb8a982be58634a5a4cbfb5da">27</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Han_Learning_To_Fuse_Asymmetric_Feature_Maps_in_Siamese_Trackers_CVPR_2021_paper.html">Learning To Fuse Asymmetric Feature Maps in Siamese Trackers</a></th>
                    </tr>
                
                    <tr id="bb9dbd14f83c45cdb20c6b4c90b9493a6ed11605">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bb9dbd14f83c45cdb20c6b4c90b9493a6ed11605">27</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Yang_NTIRE_2021_Challenge_on_Quality_Enhancement_of_Compressed_Video_Methods_CVPRW_2021_paper.html">NTIRE 2021 Challenge on Quality Enhancement of Compressed Video: Methods and Results</a></th>
                    </tr>
                
                    <tr id="574e3aeda32b096876a4a91b2468d18beef427ae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/574e3aeda32b096876a4a91b2468d18beef427ae">27</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Liu_NTIRE_2021_Multi-Modal_Aerial_View_Object_Classification_Challenge_CVPRW_2021_paper.html">NTIRE 2021 Multi-Modal Aerial View Object Classification Challenge</a></th>
                    </tr>
                
                    <tr id="84421139efaae7862116f39d4df1cd5ea27103fc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/84421139efaae7862116f39d4df1cd5ea27103fc">27</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Neekhara_Adversarial_Threats_to_DeepFake_Detection_A_Practical_Perspective_CVPRW_2021_paper.html">Adversarial Threats to DeepFake Detection: A Practical Perspective</a></th>
                    </tr>
                
                    <tr id="ca3adceb565b5a68648f9bf8f44f6b7520b02b4a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ca3adceb565b5a68648f9bf8f44f6b7520b02b4a">27</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Ignatov_Real-Time_Quantized_Image_Super-Resolution_on_Mobile_NPUs_Mobile_AI_2021_CVPRW_2021_paper.html">Real-Time Quantized Image Super-Resolution on Mobile NPUs, Mobile AI 2021 Challenge: Report</a></th>
                    </tr>
                
                    <tr id="125169330bf7c0dac2d5b653a32a04f71518ed02">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/125169330bf7c0dac2d5b653a32a04f71518ed02">27</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Mittal_Essentials_for_Class_Incremental_Learning_CVPRW_2021_paper.html">Essentials for Class Incremental Learning</a></th>
                    </tr>
                
                    <tr id="cf7a3e3a9872b7bf90182a65b68d485c7fec5fbc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cf7a3e3a9872b7bf90182a65b68d485c7fec5fbc">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Image_Inpainting_With_External-Internal_Learning_and_Monochromic_Bottleneck_CVPR_2021_paper.html">Image Inpainting With External-Internal Learning and Monochromic Bottleneck</a></th>
                    </tr>
                
                    <tr id="c9a3da3b7fccdb474869f44c3af1d16b3ca88420">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c9a3da3b7fccdb474869f44c3af1d16b3ca88420">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shafiee_Introvert_Human_Trajectory_Prediction_via_Conditional_3D_Attention_CVPR_2021_paper.html">Introvert: Human Trajectory Prediction via Conditional 3D Attention</a></th>
                    </tr>
                
                    <tr id="02f316857c1d20649b18e5fec3e92dda8ef1d0a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/02f316857c1d20649b18e5fec3e92dda8ef1d0a0">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_DriveGAN_Towards_a_Controllable_High-Quality_Neural_Simulation_CVPR_2021_paper.html">DriveGAN: Towards a Controllable High-Quality Neural Simulation</a></th>
                    </tr>
                
                    <tr id="239dd1c5945aea8286afa4e8ca72dff9733576f4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/239dd1c5945aea8286afa4e8ca72dff9733576f4">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_MultiBodySync_Multi-Body_Segmentation_and_Motion_Estimation_via_3D_Scan_Synchronization_CVPR_2021_paper.html">MultiBodySync: Multi-Body Segmentation and Motion Estimation via 3D Scan Synchronization</a></th>
                    </tr>
                
                    <tr id="baa729c248566dfdb2948eba50918e915fa98ed7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/baa729c248566dfdb2948eba50918e915fa98ed7">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hou_BiCnet-TKS_Learning_Efficient_Spatial-Temporal_Representation_for_Video_Person_Re-Identification_CVPR_2021_paper.html">BiCnet-TKS: Learning Efficient Spatial-Temporal Representation for Video Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="2f5bfc88ca6418d9b1a44c9c60db8e5cf28d4ef7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2f5bfc88ca6418d9b1a44c9c60db8e5cf28d4ef7">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Information_Bottleneck_Disentanglement_for_Identity_Swapping_CVPR_2021_paper.html">Information Bottleneck Disentanglement for Identity Swapping</a></th>
                    </tr>
                
                    <tr id="63508e386705e1340944db73e4d690dbc7febb37">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/63508e386705e1340944db73e4d690dbc7febb37">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deng_3D_AffordanceNet_A_Benchmark_for_Visual_Object_Affordance_Understanding_CVPR_2021_paper.html">3D AffordanceNet: A Benchmark for Visual Object Affordance Understanding</a></th>
                    </tr>
                
                    <tr id="fae1c655db26a9a4bfe4c0d1bfc7a0cbcbb3f9a3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fae1c655db26a9a4bfe4c0d1bfc7a0cbcbb3f9a3">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lv_Learning_Semantic_Person_Image_Generation_by_Region-Adaptive_Normalization_CVPR_2021_paper.html">Learning Semantic Person Image Generation by Region-Adaptive Normalization</a></th>
                    </tr>
                
                    <tr id="8c63b98161df3088b4eb8f6b0472675f2bf87338">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c63b98161df3088b4eb8f6b0472675f2bf87338">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qu_Focus_on_Local_Detecting_Lane_Marker_From_Bottom_Up_via_CVPR_2021_paper.html">Focus on Local: Detecting Lane Marker From Bottom Up via Key Point</a></th>
                    </tr>
                
                    <tr id="f3159775dc51ac3955bc9d542278e7280f1f9893">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f3159775dc51ac3955bc9d542278e7280f1f9893">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ramamonjisoa_Single_Image_Depth_Prediction_With_Wavelet_Decomposition_CVPR_2021_paper.html">Single Image Depth Prediction With Wavelet Decomposition</a></th>
                    </tr>
                
                    <tr id="70e966da0d31a358f52482f8a73e00b1a36fda99">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70e966da0d31a358f52482f8a73e00b1a36fda99">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Reddy_TesseTrack_End-to-End_Learnable_Multi-Person_Articulated_3D_Pose_Tracking_CVPR_2021_paper.html">TesseTrack: End-to-End Learnable Multi-Person Articulated 3D Pose Tracking</a></th>
                    </tr>
                
                    <tr id="0902323bb4fa97561276c4d15c5b4e19b38f76b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0902323bb4fa97561276c4d15c5b4e19b38f76b5">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Borse_InverseForm_A_Loss_Function_for_Structured_Boundary-Aware_Segmentation_CVPR_2021_paper.html">InverseForm: A Loss Function for Structured Boundary-Aware Segmentation</a></th>
                    </tr>
                
                    <tr id="ffd08400bc56ebed24aba3a3666429bbc6b48b25">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ffd08400bc56ebed24aba3a3666429bbc6b48b25">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_D2IM-Net_Learning_Detail_Disentangled_Implicit_Fields_From_Single_Images_CVPR_2021_paper.html">D2IM-Net: Learning Detail Disentangled Implicit Fields From Single Images</a></th>
                    </tr>
                
                    <tr id="99c91e28292e4cfdbd40331a2d52e7e703310fb5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/99c91e28292e4cfdbd40331a2d52e7e703310fb5">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shen_DCT-Mask_Discrete_Cosine_Transform_Mask_Representation_for_Instance_Segmentation_CVPR_2021_paper.html">DCT-Mask: Discrete Cosine Transform Mask Representation for Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="7ce8f0dda13a434314562f92d56147c7970f1c62">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ce8f0dda13a434314562f92d56147c7970f1c62">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Su_A_Realistic_Evaluation_of_Semi-Supervised_Learning_for_Fine-Grained_Classification_CVPR_2021_paper.html">A Realistic Evaluation of Semi-Supervised Learning for Fine-Grained Classification</a></th>
                    </tr>
                
                    <tr id="283b9ddf5df01cdd96aa8244e84b4aa1734e9deb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/283b9ddf5df01cdd96aa8244e84b4aa1734e9deb">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Song_Spatio-temporal_Contrastive_Domain_Adaptation_for_Action_Recognition_CVPR_2021_paper.html">Spatio-temporal Contrastive Domain Adaptation for Action Recognition</a></th>
                    </tr>
                
                    <tr id="a7b7eed040046fba519230218e550dfd71185d86">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a7b7eed040046fba519230218e550dfd71185d86">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_by_Watching_CVPR_2021_paper.html">Learning by Watching</a></th>
                    </tr>
                
                    <tr id="fbe34c9add92077f1ea0dc2d3cad1ab95c49f7d5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fbe34c9add92077f1ea0dc2d3cad1ab95c49f7d5">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Suo_NeuralHumanFVV_Real-Time_Neural_Volumetric_Human_Performance_Rendering_Using_RGB_Cameras_CVPR_2021_paper.html">NeuralHumanFVV: Real-Time Neural Volumetric Human Performance Rendering Using RGB Cameras</a></th>
                    </tr>
                
                    <tr id="8b8ea4bb311f4a46cb654bc4d34cb07f49ed45ca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b8ea4bb311f4a46cb654bc4d34cb07f49ed45ca">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Towards_More_Flexible_and_Accurate_Object_Tracking_With_Natural_Language_CVPR_2021_paper.html">Towards More Flexible and Accurate Object Tracking With Natural Language: Algorithms and Benchmark</a></th>
                    </tr>
                
                    <tr id="aed928e573a64c67666df46e3ef994f8afc57ecf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aed928e573a64c67666df46e3ef994f8afc57ecf">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_DyCo3D_Robust_Instance_Segmentation_of_3D_Point_Clouds_Through_Dynamic_CVPR_2021_paper.html">DyCo3D: Robust Instance Segmentation of 3D Point Clouds Through Dynamic Convolution</a></th>
                    </tr>
                
                    <tr id="7165bd148bfd290593f0932b40290d9be2009df4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7165bd148bfd290593f0932b40290d9be2009df4">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Stone_SMURF_Self-Teaching_Multi-Frame_Unsupervised_RAFT_With_Full-Image_Warping_CVPR_2021_paper.html">SMURF: Self-Teaching Multi-Frame Unsupervised RAFT With Full-Image Warping</a></th>
                    </tr>
                
                    <tr id="a503fa52c2962d68f8f9b8bea48bd595f1298973">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a503fa52c2962d68f8f9b8bea48bd595f1298973">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Roy_Curriculum_Graph_Co-Teaching_for_Multi-Target_Domain_Adaptation_CVPR_2021_paper.html">Curriculum Graph Co-Teaching for Multi-Target Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="fc6b42ea4b2fb6692889f3fc4c635b6a6fea70a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc6b42ea4b2fb6692889f3fc4c635b6a6fea70a2">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jing_Amalgamating_Knowledge_From_Heterogeneous_Graph_Neural_Networks_CVPR_2021_paper.html">Amalgamating Knowledge From Heterogeneous Graph Neural Networks</a></th>
                    </tr>
                
                    <tr id="816bf6ef7d4c41cd243fdba471306503c8b2f58e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/816bf6ef7d4c41cd243fdba471306503c8b2f58e">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Deep_Convolutional_Dictionary_Learning_for_Image_Denoising_CVPR_2021_paper.html">Deep Convolutional Dictionary Learning for Image Denoising</a></th>
                    </tr>
                
                    <tr id="54f5e54a90e7f74dfadbc5b3cc08fa43e4851290">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/54f5e54a90e7f74dfadbc5b3cc08fa43e4851290">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wei_PV-RAFT_Point-Voxel_Correlation_Fields_for_Scene_Flow_Estimation_of_Point_CVPR_2021_paper.html">PV-RAFT: Point-Voxel Correlation Fields for Scene Flow Estimation of Point Clouds</a></th>
                    </tr>
                
                    <tr id="f5374749912031107f4e92593e8bbd69f1842565">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f5374749912031107f4e92593e8bbd69f1842565">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_DualAST_Dual_Style-Learning_Networks_for_Artistic_Style_Transfer_CVPR_2021_paper.html">DualAST: Dual Style-Learning Networks for Artistic Style Transfer</a></th>
                    </tr>
                
                    <tr id="8e61e1bb9857d050288ee9a12222076356e3a500">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e61e1bb9857d050288ee9a12222076356e3a500">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Intrinsic_Image_Harmonization_CVPR_2021_paper.html">Intrinsic Image Harmonization</a></th>
                    </tr>
                
                    <tr id="ccfcbd01df382d32ac88da9f49b1e20c7cb411da">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ccfcbd01df382d32ac88da9f49b1e20c7cb411da">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Quan_Removing_Raindrops_and_Rain_Streaks_in_One_Go_CVPR_2021_paper.html">Removing Raindrops and Rain Streaks in One Go</a></th>
                    </tr>
                
                    <tr id="4d8cafbb4d66fb7f3e6efdf2107974a823be4dbf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4d8cafbb4d66fb7f3e6efdf2107974a823be4dbf">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gu_Interpreting_Super-Resolution_Networks_With_Local_Attribution_Maps_CVPR_2021_paper.html">Interpreting Super-Resolution Networks with Local Attribution Maps</a></th>
                    </tr>
                
                    <tr id="543903c216f92046518761f8dbac68717aa2c302">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/543903c216f92046518761f8dbac68717aa2c302">26</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Face_Forgery_Detection_by_3D_Decomposition_CVPR_2021_paper.html">Face Forgery Detection by 3D Decomposition</a></th>
                    </tr>
                
                    <tr id="66326e4b34337a1896c431b5b4cc84e99eeb4c5d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/66326e4b34337a1896c431b5b4cc84e99eeb4c5d">26</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Lugmayr_NTIRE_2021_Learning_the_Super-Resolution_Space_Challenge_CVPRW_2021_paper.html">NTIRE 2021 Learning the Super-Resolution Space Challenge</a></th>
                    </tr>
                
                    <tr id="76bbe1af7194b2daaa413b513a008287f949dc1b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/76bbe1af7194b2daaa413b513a008287f949dc1b">26</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Bhat_NTIRE_2021_Challenge_on_Burst_Super-Resolution_Methods_and_Results_CVPRW_2021_paper.html">NTIRE 2021 Challenge on Burst Super-Resolution: Methods and Results</a></th>
                    </tr>
                
                    <tr id="11de7ce5e800d5b901e516f9301f52e4634d7ee6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/11de7ce5e800d5b901e516f9301f52e4634d7ee6">26</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Liu_ADNet_Attention-Guided_Deformable_Convolutional_Network_for_High_Dynamic_Range_Imaging_CVPRW_2021_paper.html">ADNet: Attention-Guided Deformable Convolutional Network for High Dynamic Range Imaging</a></th>
                    </tr>
                
                    <tr id="069b9321f85b6bc005fff3c254d34c791f6c0741">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/069b9321f85b6bc005fff3c254d34c791f6c0741">26</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ISIC/html/Groh_Evaluating_Deep_Neural_Networks_Trained_on_Clinical_Images_in_Dermatology_CVPRW_2021_paper.html">Evaluating Deep Neural Networks Trained on Clinical Images in Dermatology With the Fitzpatrick 17k Dataset</a></th>
                    </tr>
                
                    <tr id="86ce8a4ea8963591d9d18751c0f2e0c9446cefae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/86ce8a4ea8963591d9d18751c0f2e0c9446cefae">26</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Ignatov_Learned_Smartphone_ISP_on_Mobile_NPUs_With_Deep_Learning_Mobile_CVPRW_2021_paper.html">Learned Smartphone ISP on Mobile NPUs With Deep Learning, Mobile AI 2021 Challenge: Report</a></th>
                    </tr>
                
                    <tr id="4d0e0ee3f4eaf224f0a958694d6c8683f4b1ef79">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4d0e0ee3f4eaf224f0a958694d6c8683f4b1ef79">26</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Mai_Supervised_Contrastive_Replay_Revisiting_the_Nearest_Class_Mean_Classifier_in_CVPRW_2021_paper.html">Supervised Contrastive Replay: Revisiting the Nearest Class Mean Classifier in Online Class-Incremental Continual Learning</a></th>
                    </tr>
                
                    <tr id="a9d76b31589529dd8a5ae7c1774d2c4c55ff9ad0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a9d76b31589529dd8a5ae7c1774d2c4c55ff9ad0">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_I3Net_Implicit_Instance-Invariant_Network_for_Adapting_One-Stage_Object_Detectors_CVPR_2021_paper.html">I3Net: Implicit Instance-Invariant Network for Adapting One-Stage Object Detectors</a></th>
                    </tr>
                
                    <tr id="8b817a28d880e4688956d6e1769475a9f22c7411">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b817a28d880e4688956d6e1769475a9f22c7411">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tan_SceneGen_Learning_To_Generate_Realistic_Traffic_Scenes_CVPR_2021_paper.html">SceneGen: Learning To Generate Realistic Traffic Scenes</a></th>
                    </tr>
                
                    <tr id="0c93ba7c58864fc401cd2711a1c6769dd3f97053">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c93ba7c58864fc401cd2711a1c6769dd3f97053">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Camera-Space_Hand_Mesh_Recovery_via_Semantic_Aggregation_and_Adaptive_2D-1D_CVPR_2021_paper.html">Camera-Space Hand Mesh Recovery via Semantic Aggregation and Adaptive 2D-1D Registration</a></th>
                    </tr>
                
                    <tr id="7b332de15ba865284fbd2c7943ca3110bc067ef7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b332de15ba865284fbd2c7943ca3110bc067ef7">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Volpi_Continual_Adaptation_of_Visual_Representations_via_Domain_Randomization_and_Meta-Learning_CVPR_2021_paper.html">Continual Adaptation of Visual Representations via Domain Randomization and Meta-Learning</a></th>
                    </tr>
                
                    <tr id="b4a0ec01ddc7e71893764cd8f57b63dc6d7f1996">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b4a0ec01ddc7e71893764cd8f57b63dc6d7f1996">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ren_Reciprocal_Transformations_for_Unsupervised_Video_Object_Segmentation_CVPR_2021_paper.html">Reciprocal Transformations for Unsupervised Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="01ee7442d08aee162a8b72fd0911ee128271507e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01ee7442d08aee162a8b72fd0911ee128271507e">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Semantic_Image_Matting_CVPR_2021_paper.html">Semantic Image Matting</a></th>
                    </tr>
                
                    <tr id="1c1fe491e2203fb86715ff58f4f1bfc77c7e9edd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1c1fe491e2203fb86715ff58f4f1bfc77c7e9edd">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Accurate_Few-Shot_Object_Detection_With_Support-Query_Mutual_Guidance_and_Hybrid_CVPR_2021_paper.html">Accurate Few-Shot Object Detection With Support-Query Mutual Guidance and Hybrid Loss</a></th>
                    </tr>
                
                    <tr id="564878c396cff0c1b429bc575adf18b61e28c476">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/564878c396cff0c1b429bc575adf18b61e28c476">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_RPN_Prototype_Alignment_for_Domain_Adaptive_Object_Detector_CVPR_2021_paper.html">RPN Prototype Alignment for Domain Adaptive Object Detector</a></th>
                    </tr>
                
                    <tr id="1b7f08aa46bc4343405ca4a0b78d5599772831c6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1b7f08aa46bc4343405ca4a0b78d5599772831c6">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cruz_Zillow_Indoor_Dataset_Annotated_Floor_Plans_With_360deg_Panoramas_and_CVPR_2021_paper.html">Zillow Indoor Dataset: Annotated Floor Plans With 360deg Panoramas and 3D Room Layouts</a></th>
                    </tr>
                
                    <tr id="e1261ca36feec83c2f5a8bd95b7bd46da7c62c23">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e1261ca36feec83c2f5a8bd95b7bd46da7c62c23">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Slimmable_Compressive_Autoencoders_for_Practical_Neural_Image_Compression_CVPR_2021_paper.html">Slimmable Compressive Autoencoders for Practical Neural Image Compression</a></th>
                    </tr>
                
                    <tr id="fcc646584c0b8c5f7c78b743f55371c15699e9a8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fcc646584c0b8c5f7c78b743f55371c15699e9a8">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Lesion-Aware_Transformers_for_Diabetic_Retinopathy_Grading_CVPR_2021_paper.html">Lesion-Aware Transformers for Diabetic Retinopathy Grading</a></th>
                    </tr>
                
                    <tr id="053d5214f392963e84360f889ece0860d08f26f7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/053d5214f392963e84360f889ece0860d08f26f7">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ng_Body2Hands_Learning_To_Infer_3D_Hands_From_Conversational_Gesture_Body_CVPR_2021_paper.html">Body2Hands: Learning To Infer 3D Hands From Conversational Gesture Body Dynamics</a></th>
                    </tr>
                
                    <tr id="31f52f1581b72e16d4dcc0500bcab16824766346">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/31f52f1581b72e16d4dcc0500bcab16824766346">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huo_ATSO_Asynchronous_Teacher-Student_Optimization_for_Semi-Supervised_Image_Segmentation_CVPR_2021_paper.html">ATSO: Asynchronous Teacher-Student Optimization for Semi-Supervised Image Segmentation</a></th>
                    </tr>
                
                    <tr id="2ff07e55f61a65bf423cc9b3bc1e7c6b2011b793">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ff07e55f61a65bf423cc9b3bc1e7c6b2011b793">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Watching_You_Global-Guided_Reciprocal_Learning_for_Video-Based_Person_Re-Identification_CVPR_2021_paper.html">Watching You: Global-Guided Reciprocal Learning for Video-Based Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="311573e38ef43b482efcfcc1b5470e6105a1b668">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/311573e38ef43b482efcfcc1b5470e6105a1b668">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Imran_Depth_Completion_With_Twin_Surface_Extrapolation_at_Occlusion_Boundaries_CVPR_2021_paper.html">Depth Completion With Twin Surface Extrapolation at Occlusion Boundaries</a></th>
                    </tr>
                
                    <tr id="daaec87f2aa04cabc026a936f27dd2162c422a23">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/daaec87f2aa04cabc026a936f27dd2162c422a23">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Anti-Aliasing_Semantic_Reconstruction_for_Few-Shot_Semantic_Segmentation_CVPR_2021_paper.html">Anti-Aliasing Semantic Reconstruction for Few-Shot Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="f50059bc2388ef69c8e2453701c7e684d1a7ebf7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f50059bc2388ef69c8e2453701c7e684d1a7ebf7">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Banani_UnsupervisedRR_Unsupervised_Point_Cloud_Registration_via_Differentiable_Rendering_CVPR_2021_paper.html">UnsupervisedR&amp;R: Unsupervised Point Cloud Registration via Differentiable Rendering</a></th>
                    </tr>
                
                    <tr id="fe3e55e6b6db8c127e5931e089b74982fd307964">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fe3e55e6b6db8c127e5931e089b74982fd307964">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Eckart_Self-Supervised_Learning_on_3D_Point_Clouds_by_Learning_Discrete_Generative_CVPR_2021_paper.html">Self-Supervised Learning on 3D Point Clouds by Learning Discrete Generative Models</a></th>
                    </tr>
                
                    <tr id="a122250dddb137f41ffbb534878794f46f740e00">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a122250dddb137f41ffbb534878794f46f740e00">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bhunia_Vectorization_and_Rasterization_Self-Supervised_Learning_for_Sketch_and_Handwriting_CVPR_2021_paper.html">Vectorization and Rasterization: Self-Supervised Learning for Sketch and Handwriting</a></th>
                    </tr>
                
                    <tr id="6fe06809f5c5e1c402a9dc287a9aef00aeec7a7a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6fe06809f5c5e1c402a9dc287a9aef00aeec7a7a">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Temporal_Action_Segmentation_From_Timestamp_Supervision_CVPR_2021_paper.html">Temporal Action Segmentation From Timestamp Supervision</a></th>
                    </tr>
                
                    <tr id="b01a1b537f7f2d38aa8460235b7f4b3566cf65f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b01a1b537f7f2d38aa8460235b7f4b3566cf65f1">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gidaris_OBoW_Online_Bag-of-Visual-Words_Generation_for_Self-Supervised_Learning_CVPR_2021_paper.html">OBoW: Online Bag-of-Visual-Words Generation for Self-Supervised Learning</a></th>
                    </tr>
                
                    <tr id="ea5f7e806d870f237d9556d37a307ef0d9905ac7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ea5f7e806d870f237d9556d37a307ef0d9905ac7">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Training_Networks_in_Null_Space_of_Feature_Covariance_for_Continual_CVPR_2021_paper.html">Training Networks in Null Space of Feature Covariance for Continual Learning</a></th>
                    </tr>
                
                    <tr id="588a3b90556069ec02cd40c93b8092e21d10bb1c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/588a3b90556069ec02cd40c93b8092e21d10bb1c">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sadhu_Visual_Semantic_Role_Labeling_for_Video_Understanding_CVPR_2021_paper.html">Visual Semantic Role Labeling for Video Understanding</a></th>
                    </tr>
                
                    <tr id="c502b3d801a687ad26f592aa3416a6b2520d0f7c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c502b3d801a687ad26f592aa3416a6b2520d0f7c">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jung_Fair_Feature_Distillation_for_Visual_Recognition_CVPR_2021_paper.html">Fair Feature Distillation for Visual Recognition</a></th>
                    </tr>
                
                    <tr id="7ce9e213dfa22ea1bc9167679f1a55edcd58bfca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ce9e213dfa22ea1bc9167679f1a55edcd58bfca">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pu_Lifelong_Person_Re-Identification_via_Adaptive_Knowledge_Accumulation_CVPR_2021_paper.html">Lifelong Person Re-Identification via Adaptive Knowledge Accumulation</a></th>
                    </tr>
                
                    <tr id="7718d74845248d46c611882b43982f10ae545a0f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7718d74845248d46c611882b43982f10ae545a0f">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kaya_Uncalibrated_Neural_Inverse_Rendering_for_Photometric_Stereo_of_General_Surfaces_CVPR_2021_paper.html">Uncalibrated Neural Inverse Rendering for Photometric Stereo of General Surfaces</a></th>
                    </tr>
                
                    <tr id="cb9ea69a4a6c86c3ac2be7243cf170bf31441bda">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cb9ea69a4a6c86c3ac2be7243cf170bf31441bda">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_StyleMix_Separating_Content_and_Style_for_Enhanced_Data_Augmentation_CVPR_2021_paper.html">StyleMix: Separating Content and Style for Enhanced Data Augmentation</a></th>
                    </tr>
                
                    <tr id="37cab88678e3e0139d6110f3fcb51145e61e3c90">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/37cab88678e3e0139d6110f3fcb51145e61e3c90">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Consistent_Instance_False_Positive_Improves_Fairness_in_Face_Recognition_CVPR_2021_paper.html">Consistent Instance False Positive Improves Fairness in Face Recognition</a></th>
                    </tr>
                
                    <tr id="1a617a58ab3f80a7d78fca9e0f6497ce4a5314eb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a617a58ab3f80a7d78fca9e0f6497ce4a5314eb">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Global2Local_Efficient_Structure_Search_for_Video_Action_Segmentation_CVPR_2021_paper.html">Global2Local: Efficient Structure Search for Video Action Segmentation</a></th>
                    </tr>
                
                    <tr id="99f2cadcaed68ad07d5377d15c7af8a5422af680">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/99f2cadcaed68ad07d5377d15c7af8a5422af680">25</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Unsupervised_3D_Shape_Completion_Through_GAN_Inversion_CVPR_2021_paper.html">Unsupervised 3D Shape Completion through GAN Inversion</a></th>
                    </tr>
                
                    <tr id="06a48439d4eab9d73f440c1db57fa67bf023f030">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/06a48439d4eab9d73f440c1db57fa67bf023f030">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Visually_Informed_Binaural_Audio_Generation_without_Binaural_Audios_CVPR_2021_paper.html">Visually Informed Binaural Audio Generation without Binaural Audios</a></th>
                    </tr>
                
                    <tr id="570a8da4a181d60c06afee6fd7668bd56714595a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/570a8da4a181d60c06afee6fd7668bd56714595a">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Points_As_Queries_Weakly_Semi-Supervised_Object_Detection_by_Points_CVPR_2021_paper.html">Points As Queries: Weakly Semi-Supervised Object Detection by Points</a></th>
                    </tr>
                
                    <tr id="a8d8c6ea99ff998bf19dbff8f9052a4245f4a95b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a8d8c6ea99ff998bf19dbff8f9052a4245f4a95b">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Prototype-Guided_Saliency_Feature_Learning_for_Person_Search_CVPR_2021_paper.html">Prototype-Guided Saliency Feature Learning for Person Search</a></th>
                    </tr>
                
                    <tr id="345130ba4057dbde6634f329bcf294faa3697866">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/345130ba4057dbde6634f329bcf294faa3697866">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zeng_CorrNet3D_Unsupervised_End-to-End_Learning_of_Dense_Correspondence_for_3D_Point_CVPR_2021_paper.html">CorrNet3D: Unsupervised End-to-End Learning of Dense Correspondence for 3D Point Clouds</a></th>
                    </tr>
                
                    <tr id="7811df11a75f58646d04b3132d35f0656e50a109">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7811df11a75f58646d04b3132d35f0656e50a109">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Improving_Sign_Language_Translation_With_Monolingual_Data_by_Sign_Back-Translation_CVPR_2021_paper.html">Improving Sign Language Translation With Monolingual Data by Sign Back-Translation</a></th>
                    </tr>
                
                    <tr id="d01ca0b8b6d02e2833b8d1a71b28de153cdbc397">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d01ca0b8b6d02e2833b8d1a71b28de153cdbc397">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Duan_TransNAS-Bench-101_Improving_Transferability_and_Generalizability_of_Cross-Task_Neural_Architecture_Search_CVPR_2021_paper.html">TransNAS-Bench-101: Improving Transferability and Generalizability of Cross-Task Neural Architecture Search</a></th>
                    </tr>
                
                    <tr id="c4827bea40963c5fb57754a80d58235d7e78b288">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c4827bea40963c5fb57754a80d58235d7e78b288">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Graph-Based_High-Order_Relation_Discovery_for_Fine-Grained_Recognition_CVPR_2021_paper.html">Graph-Based High-Order Relation Discovery for Fine-Grained Recognition</a></th>
                    </tr>
                
                    <tr id="9d63ae3de750d63691b3d0ee22766d63078b21c7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9d63ae3de750d63691b3d0ee22766d63078b21c7">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Strengthen_Learning_Tolerance_for_Weakly_Supervised_Object_Localization_CVPR_2021_paper.html">Strengthen Learning Tolerance for Weakly Supervised Object Localization</a></th>
                    </tr>
                
                    <tr id="196702d087f2422c75be5cfcd46e9b9baa34b6d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/196702d087f2422c75be5cfcd46e9b9baa34b6d2">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_UnrealPerson_An_Adaptive_Pipeline_Towards_Costless_Person_Re-Identification_CVPR_2021_paper.html">UnrealPerson: An Adaptive Pipeline Towards Costless Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="55d7325804bfc1b362b9d2a9613f996b9e9be29f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/55d7325804bfc1b362b9d2a9613f996b9e9be29f">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_UPFlow_Upsampling_Pyramid_for_Unsupervised_Optical_Flow_Learning_CVPR_2021_paper.html">UPFlow: Upsampling Pyramid for Unsupervised Optical Flow Learning</a></th>
                    </tr>
                
                    <tr id="5b532b9f7219d25f4bed745ba709c1c03d44f25c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b532b9f7219d25f4bed745ba709c1c03d44f25c">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huynh_Progressive_Semantic_Segmentation_CVPR_2021_paper.html">Progressive Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="134661b95ce5b54b1a8586e00eaa11e83998857a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/134661b95ce5b54b1a8586e00eaa11e83998857a">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_KOALAnet_Blind_Super-Resolution_Using_Kernel-Oriented_Adaptive_Local_Adjustment_CVPR_2021_paper.html">KOALAnet: Blind Super-Resolution Using Kernel-Oriented Adaptive Local Adjustment</a></th>
                    </tr>
                
                    <tr id="79f78ca11aac28731e0c3e7594238829b1ec80c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/79f78ca11aac28731e0c3e7594238829b1ec80c4">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Song_Hybrid_Message_Passing_With_Performance-Driven_Structures_for_Facial_Action_Unit_CVPR_2021_paper.html">Hybrid Message Passing With Performance-Driven Structures for Facial Action Unit Detection</a></th>
                    </tr>
                
                    <tr id="17e695d7b00600e0fd6599e1d7703d9f76e796e8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/17e695d7b00600e0fd6599e1d7703d9f76e796e8">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Towards_Accurate_Text-Based_Image_Captioning_With_Content_Diversity_Exploration_CVPR_2021_paper.html">Towards Accurate Text-Based Image Captioning With Content Diversity Exploration</a></th>
                    </tr>
                
                    <tr id="c75df37c413ad0a466a30a444bc172434ef110e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c75df37c413ad0a466a30a444bc172434ef110e1">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Eisenberger_NeuroMorph_Unsupervised_Shape_Interpolation_and_Correspondence_in_One_Go_CVPR_2021_paper.html">NeuroMorph: Unsupervised Shape Interpolation and Correspondence in One Go</a></th>
                    </tr>
                
                    <tr id="a0d53bccf169c77042ffed93587fe60b0cf7b96d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a0d53bccf169c77042ffed93587fe60b0cf7b96d">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Reddy_Im2Vec_Synthesizing_Vector_Graphics_Without_Vector_Supervision_CVPR_2021_paper.html">Im2Vec: Synthesizing Vector Graphics Without Vector Supervision</a></th>
                    </tr>
                
                    <tr id="15b28c6653aa7f749aefa2a13af7d40a9228e215">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15b28c6653aa7f749aefa2a13af7d40a9228e215">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Abuduweili_Adaptive_Consistency_Regularization_for_Semi-Supervised_Transfer_Learning_CVPR_2021_paper.html">Adaptive Consistency Regularization for Semi-Supervised Transfer Learning</a></th>
                    </tr>
                
                    <tr id="d79c307495b8e584c46e3a4422f1d4d3df71269b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d79c307495b8e584c46e3a4422f1d4d3df71269b">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Deep_Compositional_Metric_Learning_CVPR_2021_paper.html">Deep Compositional Metric Learning</a></th>
                    </tr>
                
                    <tr id="39a61e4cf4ec61ecc097290075a5dd2a0f7a5d4e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39a61e4cf4ec61ecc097290075a5dd2a0f7a5d4e">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Domain-Specific_Suppression_for_Adaptive_Object_Detection_CVPR_2021_paper.html">Domain-Specific Suppression for Adaptive Object Detection</a></th>
                    </tr>
                
                    <tr id="178a5726bccf0d9422609c74ba07b3b8b2c6ac37">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/178a5726bccf0d9422609c74ba07b3b8b2c6ac37">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hosseini_DSRNA_Differentiable_Search_of_Robust_Neural_Architectures_CVPR_2021_paper.html">DSRNA: Differentiable Search of Robust Neural Architectures</a></th>
                    </tr>
                
                    <tr id="4889c524a435fd86f915f8d8cc6e04e76e52b561">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4889c524a435fd86f915f8d8cc6e04e76e52b561">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_From_Rain_Generation_to_Rain_Removal_CVPR_2021_paper.html">From Rain Generation to Rain Removal</a></th>
                    </tr>
                
                    <tr id="a2747713f57e89d584df128af16c44f1898a1d5f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a2747713f57e89d584df128af16c44f1898a1d5f">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_DECOR-GAN_3D_Shape_Detailization_by_Conditional_Refinement_CVPR_2021_paper.html">DECOR-GAN: 3D Shape Detailization by Conditional Refinement</a></th>
                    </tr>
                
                    <tr id="365c4be3cbf50881d5dd1e12e30e659f2f1cfc4f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/365c4be3cbf50881d5dd1e12e30e659f2f1cfc4f">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xie_DG-Font_Deformable_Generative_Networks_for_Unsupervised_Font_Generation_CVPR_2021_paper.html">DG-Font: Deformable Generative Networks for Unsupervised Font Generation</a></th>
                    </tr>
                
                    <tr id="468876b83da2eb1f98adc35af6129a326bdda8ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/468876b83da2eb1f98adc35af6129a326bdda8ce">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_SOON_Scenario_Oriented_Object_Navigation_With_Graph-Based_Exploration_CVPR_2021_paper.html">SOON: Scenario Oriented Object Navigation With Graph-Based Exploration</a></th>
                    </tr>
                
                    <tr id="f10e85fd14921f7efd87170445218547f2fe8766">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f10e85fd14921f7efd87170445218547f2fe8766">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Min_Convolutional_Hough_Matching_Networks_CVPR_2021_paper.html">Convolutional Hough Matching Networks</a></th>
                    </tr>
                
                    <tr id="766d74b0a611f06e66af539a1543f003c94f931a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/766d74b0a611f06e66af539a1543f003c94f931a">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Weder_NeuralFusion_Online_Depth_Fusion_in_Latent_Space_CVPR_2021_paper.html">NeuralFusion: Online Depth Fusion in Latent Space</a></th>
                    </tr>
                
                    <tr id="526e3296159280ebead34fb2d15422b674a8336d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/526e3296159280ebead34fb2d15422b674a8336d">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chandrasegaran_A_Closer_Look_at_Fourier_Spectrum_Discrepancies_for_CNN-Generated_Images_CVPR_2021_paper.html">A Closer Look at Fourier Spectrum Discrepancies for CNN-Generated Images Detection</a></th>
                    </tr>
                
                    <tr id="4cc7c0cf3321897286e4e087b465b7276a675643">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4cc7c0cf3321897286e4e087b465b7276a675643">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Spherical_Confidence_Learning_for_Face_Recognition_CVPR_2021_paper.html">Spherical Confidence Learning for Face Recognition</a></th>
                    </tr>
                
                    <tr id="41ba014710b4d86dfd01560b73b7fe0b6af210b0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/41ba014710b4d86dfd01560b73b7fe0b6af210b0">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chai_To_the_Point_Efficient_3D_Object_Detection_in_the_Range_CVPR_2021_paper.html">To the Point: Efficient 3D Object Detection in the Range Image With Graph Convolution Kernels</a></th>
                    </tr>
                
                    <tr id="55779e4727e562dfc3fbbc547747a585e985dc4c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/55779e4727e562dfc3fbbc547747a585e985dc4c">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Detecting_Human-Object_Interaction_via_Fabricated_Compositional_Learning_CVPR_2021_paper.html">Detecting Human-Object Interaction via Fabricated Compositional Learning</a></th>
                    </tr>
                
                    <tr id="aebddaca7ea5cc78fe7abd6fe4d24eb6bfb0cf65">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aebddaca7ea5cc78fe7abd6fe4d24eb6bfb0cf65">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Memory-Efficient_Network_for_Large-Scale_Video_Compressive_Sensing_CVPR_2021_paper.html">Memory-Efficient Network for Large-Scale Video Compressive Sensing</a></th>
                    </tr>
                
                    <tr id="caf146b244da72523d0ebdd94a8a220b1aa7d946">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/caf146b244da72523d0ebdd94a8a220b1aa7d946">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jing_Locate_Then_Segment_A_Strong_Pipeline_for_Referring_Image_Segmentation_CVPR_2021_paper.html">Locate Then Segment: A Strong Pipeline for Referring Image Segmentation</a></th>
                    </tr>
                
                    <tr id="370ff19f0d5983ec61d490a17da47095ee4a29cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/370ff19f0d5983ec61d490a17da47095ee4a29cd">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bukchin_Fine-Grained_Angular_Contrastive_Learning_With_Coarse_Labels_CVPR_2021_paper.html">Fine-Grained Angular Contrastive Learning With Coarse Labels</a></th>
                    </tr>
                
                    <tr id="9e5dd10d0706cec7d16e03f45f8a347c194d5888">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9e5dd10d0706cec7d16e03f45f8a347c194d5888">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Improving_the_Transferability_of_Adversarial_Samples_With_Adversarial_Transformations_CVPR_2021_paper.html">Improving the Transferability of Adversarial Samples With Adversarial Transformations</a></th>
                    </tr>
                
                    <tr id="6051a8a0f121820801b2f27d86de4c4fbaf2bf91">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6051a8a0f121820801b2f27d86de4c4fbaf2bf91">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pai_Fast_Sinkhorn_Filters_Using_Matrix_Scaling_for_Non-Rigid_Shape_Correspondence_CVPR_2021_paper.html">Fast Sinkhorn Filters: Using Matrix Scaling for Non-Rigid Shape Correspondence With Functional Maps</a></th>
                    </tr>
                
                    <tr id="3dc996928c4e4c64cb98b877cf827ce8413f5c4b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3dc996928c4e4c64cb98b877cf827ce8413f5c4b">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_LED2-Net_Monocular_360deg_Layout_Estimation_via_Differentiable_Depth_Rendering_CVPR_2021_paper.html">LED2-Net: Monocular 360deg Layout Estimation via Differentiable Depth Rendering</a></th>
                    </tr>
                
                    <tr id="2a36f16822d7a7c8aba6099fa5c80988445b7192">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2a36f16822d7a7c8aba6099fa5c80988445b7192">24</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gong_MaxUp_Lightweight_Adversarial_Training_With_Data_Augmentation_Improves_Neural_Network_CVPR_2021_paper.html">MaxUp: Lightweight Adversarial Training with Data Augmentation Improves Neural Network Training</a></th>
                    </tr>
                
                    <tr id="8678f99022174c7e319dd590420241d3d1678d1f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8678f99022174c7e319dd590420241d3d1678d1f">24</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Wang_Symmetric_Parallax_Attention_for_Stereo_Image_Super-Resolution_CVPRW_2021_paper.html">Symmetric Parallax Attention for Stereo Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="ef4549c94e1ee3e2a132c63bde4c2de51396febc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ef4549c94e1ee3e2a132c63bde4c2de51396febc">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pony_Over-the-Air_Adversarial_Flickering_Attacks_Against_Video_Recognition_Networks_CVPR_2021_paper.html">Over-the-Air Adversarial Flickering Attacks Against Video Recognition Networks</a></th>
                    </tr>
                
                    <tr id="31fac8d48ee0f1dd40dc66bd5c63471dd9eb4827">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/31fac8d48ee0f1dd40dc66bd5c63471dd9eb4827">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Visualizing_Adapted_Knowledge_in_Domain_Transfer_CVPR_2021_paper.html">Visualizing Adapted Knowledge in Domain Transfer</a></th>
                    </tr>
                
                    <tr id="ac18cf85f5bcc16cc16fe645ec3df35c032776dc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ac18cf85f5bcc16cc16fe645ec3df35c032776dc">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Contrastive_Neural_Architecture_Search_With_Neural_Architecture_Comparators_CVPR_2021_paper.html">Contrastive Neural Architecture Search With Neural Architecture Comparators</a></th>
                    </tr>
                
                    <tr id="37cced394b717fee619a88dfd4a04cf8303ef5de">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/37cced394b717fee619a88dfd4a04cf8303ef5de">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kothari_Interpretable_Social_Anchors_for_Human_Trajectory_Forecasting_in_Crowds_CVPR_2021_paper.html">Interpretable Social Anchors for Human Trajectory Forecasting in Crowds</a></th>
                    </tr>
                
                    <tr id="8d07b1b2ec7fafff063d4b7686442adb54d0d934">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8d07b1b2ec7fafff063d4b7686442adb54d0d934">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_A2-FPN_Attention_Aggregation_Based_Feature_Pyramid_Network_for_Instance_Segmentation_CVPR_2021_paper.html">A2-FPN: Attention Aggregation Based Feature Pyramid Network for Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="54423c91d0db22193439f21d424302eab2d83b24">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/54423c91d0db22193439f21d424302eab2d83b24">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Ego-Exo_Transferring_Visual_Representations_From_Third-Person_to_First-Person_Videos_CVPR_2021_paper.html">Ego-Exo: Transferring Visual Representations From Third-Person to First-Person Videos</a></th>
                    </tr>
                
                    <tr id="efaafa035064c2ef0a011d3f70752273e198c021">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/efaafa035064c2ef0a011d3f70752273e198c021">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_CoSMo_Content-Style_Modulation_for_Image_Retrieval_With_Text_Feedback_CVPR_2021_paper.html">CoSMo: Content-Style Modulation for Image Retrieval With Text Feedback</a></th>
                    </tr>
                
                    <tr id="5e17da61b4c7565a8b2a91780fcda456cf6af705">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5e17da61b4c7565a8b2a91780fcda456cf6af705">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zeng_Multi-Modal_Relational_Graph_for_Cross-Modal_Video_Moment_Retrieval_CVPR_2021_paper.html">Multi-Modal Relational Graph for Cross-Modal Video Moment Retrieval</a></th>
                    </tr>
                
                    <tr id="133be7a7e81d7c282ed676a125c6815a985394ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/133be7a7e81d7c282ed676a125c6815a985394ce">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_StereoPIFu_Depth_Aware_Clothed_Human_Digitization_via_Stereo_Vision_CVPR_2021_paper.html">StereoPIFu: Depth Aware Clothed Human Digitization via Stereo Vision</a></th>
                    </tr>
                
                    <tr id="6dabaaa86f97d0f1563b2a1a3ca61d4b416fcaed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6dabaaa86f97d0f1563b2a1a3ca61d4b416fcaed">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Exploiting_Semantic_Embedding_and_Visual_Feature_for_Facial_Action_Unit_CVPR_2021_paper.html">Exploiting Semantic Embedding and Visual Feature for Facial Action Unit Detection</a></th>
                    </tr>
                
                    <tr id="c7e644cc3a7d3c364b658a4126d3bcf3b2e0bf36">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c7e644cc3a7d3c364b658a4126d3bcf3b2e0bf36">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ren_Learning_From_the_Master_Distilling_Cross-Modal_Advanced_Knowledge_for_Lip_CVPR_2021_paper.html">Learning From the Master: Distilling Cross-Modal Advanced Knowledge for Lip Reading</a></th>
                    </tr>
                
                    <tr id="4a2a12de8c7d00746710c321cc62b53c4f5a517f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4a2a12de8c7d00746710c321cc62b53c4f5a517f">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hadji_Representation_Learning_via_Global_Temporal_Alignment_and_Cycle-Consistency_CVPR_2021_paper.html">Representation Learning via Global Temporal Alignment and Cycle-Consistency</a></th>
                    </tr>
                
                    <tr id="06ee10f008eaa0ef989965da4b1f1eacf4ec84d0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/06ee10f008eaa0ef989965da4b1f1eacf4ec84d0">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Williams_Neural_Splines_Fitting_3D_Surfaces_With_Infinitely-Wide_Neural_Networks_CVPR_2021_paper.html">Neural Splines: Fitting 3D Surfaces With Infinitely-Wide Neural Networks</a></th>
                    </tr>
                
                    <tr id="63e177d062d4f6168fdd20fc41b2992f4e4d40fe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/63e177d062d4f6168fdd20fc41b2992f4e4d40fe">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Scalable_Differential_Privacy_With_Sparse_Network_Finetuning_CVPR_2021_paper.html">Scalable Differential Privacy With Sparse Network Finetuning</a></th>
                    </tr>
                
                    <tr id="0bd0ac6b4e6eb154d32216e1793295ebea1002a7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0bd0ac6b4e6eb154d32216e1793295ebea1002a7">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Orthogonal_Over-Parameterized_Training_CVPR_2021_paper.html">Orthogonal Over-Parameterized Training</a></th>
                    </tr>
                
                    <tr id="80bc0d36c80d05898c661876bb0f092f2c29aea5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/80bc0d36c80d05898c661876bb0f092f2c29aea5">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ma_IQDet_Instance-Wise_Quality_Distribution_Sampling_for_Object_Detection_CVPR_2021_paper.html">IQDet: Instance-Wise Quality Distribution Sampling for Object Detection</a></th>
                    </tr>
                
                    <tr id="d5e61fb0c41580a52d9e5cebdf36652012c7fc46">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d5e61fb0c41580a52d9e5cebdf36652012c7fc46">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_DyStaB_Unsupervised_Object_Segmentation_via_Dynamic-Static_Bootstrapping_CVPR_2021_paper.html">DyStaB: Unsupervised Object Segmentation via Dynamic-Static Bootstrapping</a></th>
                    </tr>
                
                    <tr id="353da519633135683fe65ccab6c73983db9187dc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/353da519633135683fe65ccab6c73983db9187dc">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yifan_Iso-Points_Optimizing_Neural_Implicit_Surfaces_With_Hybrid_Representations_CVPR_2021_paper.html">Iso-Points: Optimizing Neural Implicit Surfaces With Hybrid Representations</a></th>
                    </tr>
                
                    <tr id="4758baad6b22c61682e7f7182bb93723046f36f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4758baad6b22c61682e7f7182bb93723046f36f5">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Glancing_at_the_Patch_Anomaly_Localization_With_Global_and_Local_CVPR_2021_paper.html">Glancing at the Patch: Anomaly Localization With Global and Local Feature Comparison</a></th>
                    </tr>
                
                    <tr id="3c519e3ffdd43bce506a6de9c8ed9ef4b9dbe66b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3c519e3ffdd43bce506a6de9c8ed9ef4b9dbe66b">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Deep_Optimized_Priors_for_3D_Shape_Modeling_and_Reconstruction_CVPR_2021_paper.html">Deep Optimized Priors for 3D Shape Modeling and Reconstruction</a></th>
                    </tr>
                
                    <tr id="d3016ec204d775364d040c61fb4229938cc38ff9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d3016ec204d775364d040c61fb4229938cc38ff9">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_ViPNAS_Efficient_Video_Pose_Estimation_via_Neural_Architecture_Search_CVPR_2021_paper.html">ViPNAS: Efficient Video Pose Estimation via Neural Architecture Search</a></th>
                    </tr>
                
                    <tr id="62d1ad6f8cdaa80e995f24a8871397118f050b5a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/62d1ad6f8cdaa80e995f24a8871397118f050b5a">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yamamoto_Learnable_Companding_Quantization_for_Accurate_Low-Bit_Neural_Networks_CVPR_2021_paper.html">Learnable Companding Quantization for Accurate Low-Bit Neural Networks</a></th>
                    </tr>
                
                    <tr id="945aa2eb4b7ceecebf0562dfc12fcadb8fd38970">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/945aa2eb4b7ceecebf0562dfc12fcadb8fd38970">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mao_Generative_Interventions_for_Causal_Learning_CVPR_2021_paper.html">Generative Interventions for Causal Learning</a></th>
                    </tr>
                
                    <tr id="a43f7d6a751a6ad8667272f1176d2f15dbd8feb6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a43f7d6a751a6ad8667272f1176d2f15dbd8feb6">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zaeemzadeh_Out-of-Distribution_Detection_Using_Union_of_1-Dimensional_Subspaces_CVPR_2021_paper.html">Out-of-Distribution Detection Using Union of 1-Dimensional Subspaces</a></th>
                    </tr>
                
                    <tr id="ec77953e349395a9abf807f466f3375d2824970c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ec77953e349395a9abf807f466f3375d2824970c">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Depth_Completion_Using_Plane-Residual_Representation_CVPR_2021_paper.html">Depth Completion Using Plane-Residual Representation</a></th>
                    </tr>
                
                    <tr id="ba71b7005f2a94bf1519d88ae6f825e5b6aa8915">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ba71b7005f2a94bf1519d88ae6f825e5b6aa8915">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Isobe_Multi-Target_Domain_Adaptation_With_Collaborative_Consistency_Learning_CVPR_2021_paper.html">Multi-Target Domain Adaptation with Collaborative Consistency Learning</a></th>
                    </tr>
                
                    <tr id="7c4dbc479c6f123947687a1e9ab0fa03d6369146">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c4dbc479c6f123947687a1e9ab0fa03d6369146">23</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Reed_SelfAugment_Automatic_Augmentation_Policies_for_Self-Supervised_Learning_CVPR_2021_paper.html">SelfAugment: Automatic Augmentation Policies for Self-Supervised Learning</a></th>
                    </tr>
                
                    <tr id="b8eb0dd0f698d4a51488532931912851b36665f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b8eb0dd0f698d4a51488532931912851b36665f9">23</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Cui_Dressing_in_Order_Recurrent_Person_Image_Generation_for_Pose_Transfer_CVPRW_2021_paper.html">Dressing in Order: Recurrent Person Image Generation for Pose Transfer, Virtual Try-On and Outfit Editing</a></th>
                    </tr>
                
                    <tr id="dc3c161fee18dfe879279bbf931f0b5f5176c3d8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dc3c161fee18dfe879279bbf931f0b5f5176c3d8">23</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Conde_CLIP-Art_Contrastive_Pre-Training_for_Fine-Grained_Art_Classification_CVPRW_2021_paper.html">CLIP-Art: Contrastive Pre-Training for Fine-Grained Art Classification</a></th>
                    </tr>
                
                    <tr id="d76b8eabc407d2da632d05cef42aeef7c40ca7f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d76b8eabc407d2da632d05cef42aeef7c40ca7f1">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bai_Person30K_A_Dual-Meta_Generalization_Network_for_Person_Re-Identification_CVPR_2021_paper.html">Person30K: A Dual-Meta Generalization Network for Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="34f883f31a6132e44775791e0919fba9abe9efbd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/34f883f31a6132e44775791e0919fba9abe9efbd">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sayles_Invisible_Perturbations_Physical_Adversarial_Examples_Exploiting_the_Rolling_Shutter_Effect_CVPR_2021_paper.html">Invisible Perturbations: Physical Adversarial Examples Exploiting the Rolling Shutter Effect</a></th>
                    </tr>
                
                    <tr id="29b243edfd4ee898d19bcd88fa57bd4afaa74440">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/29b243edfd4ee898d19bcd88fa57bd4afaa74440">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gu_DOTS_Decoupling_Operation_and_Topology_in_Differentiable_Architecture_Search_CVPR_2021_paper.html">DOTS: Decoupling Operation and Topology in Differentiable Architecture Search</a></th>
                    </tr>
                
                    <tr id="0eea710d388cb0bae1e6a2ebe1691eafcf5da5d3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0eea710d388cb0bae1e6a2ebe1691eafcf5da5d3">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Style-Aware_Normalized_Loss_for_Improving_Arbitrary_Style_Transfer_CVPR_2021_paper.html">Style-Aware Normalized Loss for Improving Arbitrary Style Transfer</a></th>
                    </tr>
                
                    <tr id="62c27f0432bb76362c8adac7ee0da06cbfa83409">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/62c27f0432bb76362c8adac7ee0da06cbfa83409">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Delving_into_Data_Effectively_Substitute_Training_for_Black-box_Attack_CVPR_2021_paper.html">Delving into Data: Effectively Substitute Training for Black-box Attack</a></th>
                    </tr>
                
                    <tr id="f550f9471454bdf6a2524b2048b31df6a69f05c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f550f9471454bdf6a2524b2048b31df6a69f05c4">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Look_Before_You_Leap_Learning_Landmark_Features_for_One-Stage_Visual_CVPR_2021_paper.html">Look Before You Leap: Learning Landmark Features for One-Stage Visual Grounding</a></th>
                    </tr>
                
                    <tr id="35be4fa81b98b5b5a7381892706f8613876d2155">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/35be4fa81b98b5b5a7381892706f8613876d2155">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Engelmann_From_Points_to_Multi-Object_3D_Reconstruction_CVPR_2021_paper.html">From Points to Multi-Object 3D Reconstruction</a></th>
                    </tr>
                
                    <tr id="86fa97fec1f7efd0264c87423fc752cf311a007d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/86fa97fec1f7efd0264c87423fc752cf311a007d">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Pixel_Codec_Avatars_CVPR_2021_paper.html">Pixel Codec Avatars</a></th>
                    </tr>
                
                    <tr id="ac4c07984041a7c63d04bcf0a210d0dca29115f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ac4c07984041a7c63d04bcf0a210d0dca29115f5">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/R_Learning_Complete_3D_Morphable_Face_Models_From_Images_and_Videos_CVPR_2021_paper.html">Learning Complete 3D Morphable Face Models From Images and Videos</a></th>
                    </tr>
                
                    <tr id="ac58c308ba2a2dc7daddc44254386961a67dc5c9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ac58c308ba2a2dc7daddc44254386961a67dc5c9">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Trosten_Reconsidering_Representation_Alignment_for_Multi-View_Clustering_CVPR_2021_paper.html">Reconsidering Representation Alignment for Multi-View Clustering</a></th>
                    </tr>
                
                    <tr id="939680487a049e02ad617042f07b9529b2e5bb2d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/939680487a049e02ad617042f07b9529b2e5bb2d">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Bi-GCN_Binary_Graph_Convolutional_Network_CVPR_2021_paper.html">Bi-GCN: Binary Graph Convolutional Network</a></th>
                    </tr>
                
                    <tr id="3649b7349c6d8e92e185c94115b3ceda9fcb8062">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3649b7349c6d8e92e185c94115b3ceda9fcb8062">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ganea_Incremental_Few-Shot_Instance_Segmentation_CVPR_2021_paper.html">Incremental Few-Shot Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="ab191ff5ae5d92f2156fbe1e5ae453680dfd6ef6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ab191ff5ae5d92f2156fbe1e5ae453680dfd6ef6">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deng_PML_Progressive_Margin_Loss_for_Long-Tailed_Age_Classification_CVPR_2021_paper.html">PML: Progressive Margin Loss for Long-Tailed Age Classification</a></th>
                    </tr>
                
                    <tr id="8b77c6499139840e8f9287840d1a9feb1975fe74">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b77c6499139840e8f9287840d1a9feb1975fe74">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jakab_KeypointDeformer_Unsupervised_3D_Keypoint_Discovery_for_Shape_Control_CVPR_2021_paper.html">KeypointDeformer: Unsupervised 3D Keypoint Discovery for Shape Control</a></th>
                    </tr>
                
                    <tr id="f3b63c764246a36cf5ed57ae377965836ab350d7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f3b63c764246a36cf5ed57ae377965836ab350d7">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_POSEFusion_Pose-Guided_Selective_Fusion_for_Single-View_Human_Volumetric_Capture_CVPR_2021_paper.html">POSEFusion: Pose-Guided Selective Fusion for Single-View Human Volumetric Capture</a></th>
                    </tr>
                
                    <tr id="437b62b46cd2001e13756c25e00f0d6c8c6a2d49">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/437b62b46cd2001e13756c25e00f0d6c8c6a2d49">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Jigsaw_Clustering_for_Unsupervised_Visual_Representation_Learning_CVPR_2021_paper.html">Jigsaw Clustering for Unsupervised Visual Representation Learning</a></th>
                    </tr>
                
                    <tr id="c6c14a3cffab09fd12096dbe9db6cb41a5f90293">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c6c14a3cffab09fd12096dbe9db6cb41a5f90293">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_DiNTS_Differentiable_Neural_Network_Topology_Search_for_3D_Medical_Image_CVPR_2021_paper.html">DiNTS: Differentiable Neural Network Topology Search for 3D Medical Image Segmentation</a></th>
                    </tr>
                
                    <tr id="88902ac3b7bcadef6998fbd56988df2f51be6edf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/88902ac3b7bcadef6998fbd56988df2f51be6edf">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liang_OPANAS_One-Shot_Path_Aggregation_Network_Architecture_Search_for_Object_Detection_CVPR_2021_paper.html">OPANAS: One-Shot Path Aggregation Network Architecture Search for Object Detection</a></th>
                    </tr>
                
                    <tr id="04c2c577bc035bd07d4d1459ee279a9798d80ac0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/04c2c577bc035bd07d4d1459ee279a9798d80ac0">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fang_Reconstructing_3D_Human_Pose_by_Watching_Humans_in_the_Mirror_CVPR_2021_paper.html">Reconstructing 3D Human Pose by Watching Humans in the Mirror</a></th>
                    </tr>
                
                    <tr id="664ee0fb78e1a5ea53b3b7a23bd96db30772908d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/664ee0fb78e1a5ea53b3b7a23bd96db30772908d">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Learning_Dynamics_via_Graph_Neural_Networks_for_Human_Pose_Estimation_CVPR_2021_paper.html">Learning Dynamics via Graph Neural Networks for Human Pose Estimation and Tracking</a></th>
                    </tr>
                
                    <tr id="4073f0678c3f89afd322400f960a4d17e684f968">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4073f0678c3f89afd322400f960a4d17e684f968">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Embracing_Uncertainty_Decoupling_and_De-Bias_for_Robust_Temporal_Grounding_CVPR_2021_paper.html">Embracing Uncertainty: Decoupling and De-Bias for Robust Temporal Grounding</a></th>
                    </tr>
                
                    <tr id="b6ef2604bb1f4bc76ede8e70d811ba54099adc53">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b6ef2604bb1f4bc76ede8e70d811ba54099adc53">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lv_Progressive_Modality_Reinforcement_for_Human_Multimodal_Emotion_Recognition_From_Unaligned_CVPR_2021_paper.html">Progressive Modality Reinforcement for Human Multimodal Emotion Recognition From Unaligned Multimodal Sequences</a></th>
                    </tr>
                
                    <tr id="c2cb17e35548191597159ba062687416c19ac4a7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c2cb17e35548191597159ba062687416c19ac4a7">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Context_Modeling_in_3D_Human_Pose_Estimation_A_Unified_Perspective_CVPR_2021_paper.html">Context Modeling in 3D Human Pose Estimation: A Unified Perspective</a></th>
                    </tr>
                
                    <tr id="3431f5388997495840a081d2aa0860c5b97c08c9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3431f5388997495840a081d2aa0860c5b97c08c9">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Learning_Cross-Modal_Retrieval_With_Noisy_Labels_CVPR_2021_paper.html">Learning Cross-Modal Retrieval With Noisy Labels</a></th>
                    </tr>
                
                    <tr id="daa6f5f3683f217a2543518e1039b524027412b9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/daa6f5f3683f217a2543518e1039b524027412b9">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mayo_Visual_Navigation_With_Spatial_Attention_CVPR_2021_paper.html">Visual Navigation With Spatial Attention</a></th>
                    </tr>
                
                    <tr id="67be4b5ee2acb1cffbd335d48ac37794857a09e7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/67be4b5ee2acb1cffbd335d48ac37794857a09e7">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Model-Based_3D_Hand_Reconstruction_via_Self-Supervised_Learning_CVPR_2021_paper.html">Model-Based 3D Hand Reconstruction via Self-Supervised Learning</a></th>
                    </tr>
                
                    <tr id="b115783455ef4d9f01e32e207ef15ca4623b4a5f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b115783455ef4d9f01e32e207ef15ca4623b4a5f">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tan_Diverse_Semantic_Image_Synthesis_via_Probability_Distribution_Modeling_CVPR_2021_paper.html">Diverse Semantic Image Synthesis via Probability Distribution Modeling</a></th>
                    </tr>
                
                    <tr id="5b2d801b525a0fd29f43dd3b57df95026406e8f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b2d801b525a0fd29f43dd3b57df95026406e8f2">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Face_Forensics_in_the_Wild_CVPR_2021_paper.html">Face Forensics in the Wild</a></th>
                    </tr>
                
                    <tr id="4c4bc20a6b9f6b2dfdc30ae89df02d22831aa987">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c4bc20a6b9f6b2dfdc30ae89df02d22831aa987">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deschaintre_Deep_Polarization_Imaging_for_3D_Shape_and_SVBRDF_Acquisition_CVPR_2021_paper.html">Deep Polarization Imaging for 3D Shape and SVBRDF Acquisition</a></th>
                    </tr>
                
                    <tr id="a763be874960999ad5ce9a3830b5eecaa50126b8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a763be874960999ad5ce9a3830b5eecaa50126b8">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kapishnikov_Guided_Integrated_Gradients_An_Adaptive_Path_Method_for_Removing_Noise_CVPR_2021_paper.html">Guided Integrated Gradients: An Adaptive Path Method for Removing Noise</a></th>
                    </tr>
                
                    <tr id="a369c9646f432fc410b8ce520a50b0c77dd98c4c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a369c9646f432fc410b8ce520a50b0c77dd98c4c">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Wide-Baseline_Relative_Camera_Pose_Estimation_With_Directional_Learning_CVPR_2021_paper.html">Wide-Baseline Relative Camera Pose Estimation With Directional Learning</a></th>
                    </tr>
                
                    <tr id="0e8eb0ed81cca79aa8828e1411d04d3d84acc8ef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e8eb0ed81cca79aa8828e1411d04d3d84acc8ef">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Verma_Efficient_Feature_Transformations_for_Discriminative_and_Generative_Continual_Learning_CVPR_2021_paper.html">Efficient Feature Transformations for Discriminative and Generative Continual Learning</a></th>
                    </tr>
                
                    <tr id="15df058b93ea028d21a9ffe8d78e5f0da826d4c9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15df058b93ea028d21a9ffe8d78e5f0da826d4c9">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Long-Tailed_Multi-Label_Visual_Recognition_by_Collaborative_Training_on_Uniform_and_CVPR_2021_paper.html">Long-Tailed Multi-Label Visual Recognition by Collaborative Training on Uniform and Re-Balanced Samplings</a></th>
                    </tr>
                
                    <tr id="18869a25a3b860e942a442d6782b39983c1ad484">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/18869a25a3b860e942a442d6782b39983c1ad484">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sarfraz_Temporally-Weighted_Hierarchical_Clustering_for_Unsupervised_Action_Segmentation_CVPR_2021_paper.html">Temporally-Weighted Hierarchical Clustering for Unsupervised Action Segmentation</a></th>
                    </tr>
                
                    <tr id="2f41bef726b6c53dcb209ff04505526b47b52117">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2f41bef726b6c53dcb209ff04505526b47b52117">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Single-View_3D_Object_Reconstruction_From_Shape_Priors_in_Memory_CVPR_2021_paper.html">Single-View 3D Object Reconstruction From Shape Priors in Memory</a></th>
                    </tr>
                
                    <tr id="156ddb6feea4339d4258049aa840efbbd92ad705">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/156ddb6feea4339d4258049aa840efbbd92ad705">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Omnimatte_Associating_Objects_and_Their_Effects_in_Video_CVPR_2021_paper.html">Omnimatte: Associating Objects and Their Effects in Video</a></th>
                    </tr>
                
                    <tr id="2ddcf5bf4d25fa0e5bb52ad67d138bf89d271732">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ddcf5bf4d25fa0e5bb52ad67d138bf89d271732">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yue_Semi-Supervised_Video_Deraining_With_Dynamical_Rain_Generator_CVPR_2021_paper.html">Semi-Supervised Video Deraining With Dynamical Rain Generator</a></th>
                    </tr>
                
                    <tr id="654f6a350951f16464c42fecd02380b6f72428ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/654f6a350951f16464c42fecd02380b6f72428ad">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_PointNetLK_Revisited_CVPR_2021_paper.html">PointNetLK Revisited</a></th>
                    </tr>
                
                    <tr id="5490b06619c20bf83fdbf2187f157f7008add1fd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5490b06619c20bf83fdbf2187f157f7008add1fd">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_EvDistill_Asynchronous_Events_To_End-Task_Learning_via_Bidirectional_Reconstruction-Guided_Cross-Modal_CVPR_2021_paper.html">EvDistill: Asynchronous Events To End-Task Learning via Bidirectional Reconstruction-Guided Cross-Modal Knowledge Distillation</a></th>
                    </tr>
                
                    <tr id="3c486df457e7c40f823a53666963d14af6792e75">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3c486df457e7c40f823a53666963d14af6792e75">22</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bahri_Binary_Graph_Neural_Networks_CVPR_2021_paper.html">Binary Graph Neural Networks</a></th>
                    </tr>
                
                    <tr id="6fdadc633e32be92b91898e4a3ccc09a09bd43f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6fdadc633e32be92b91898e4a3ccc09a09bd43f5">22</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Abuolaim_NTIRE_2021_Challenge_for_Defocus_Deblurring_Using_Dual-Pixel_Images_Methods_CVPRW_2021_paper.html">NTIRE 2021 Challenge for Defocus Deblurring Using Dual-Pixel Images: Methods and Results</a></th>
                    </tr>
                
                    <tr id="a0d53bccf169c77042ffed93587fe60b0cf7b96d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a0d53bccf169c77042ffed93587fe60b0cf7b96d">22</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SketchDL/html/Reddy_Im2Vec_Synthesizing_Vector_Graphics_Without_Vector_Supervision_CVPRW_2021_paper.html">Im2Vec: Synthesizing Vector Graphics Without Vector Supervision</a></th>
                    </tr>
                
                    <tr id="8dd715a0c8bf0de502b63bdb7d1ac2ed1ac455da">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8dd715a0c8bf0de502b63bdb7d1ac2ed1ac455da">22</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Ignatov_Fast_and_Accurate_Single-Image_Depth_Estimation_on_Mobile_Devices_Mobile_CVPRW_2021_paper.html">Fast and Accurate Single-Image Depth Estimation on Mobile Devices, Mobile AI 2021 Challenge: Report</a></th>
                    </tr>
                
                    <tr id="d5a11c9ce83b6b79172d724cf2ca77a8c415bdba">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d5a11c9ce83b6b79172d724cf2ca77a8c415bdba">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nie_RfD-Net_Point_Scene_Understanding_by_Semantic_Instance_Reconstruction_CVPR_2021_paper.html">RfD-Net: Point Scene Understanding by Semantic Instance Reconstruction</a></th>
                    </tr>
                
                    <tr id="18d292a702a981ff6d27a6728d19a525da6b40a4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/18d292a702a981ff6d27a6728d19a525da6b40a4">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_When_Human_Pose_Estimation_Meets_Robustness_Adversarial_Algorithms_and_Benchmarks_CVPR_2021_paper.html">When Human Pose Estimation Meets Robustness: Adversarial Algorithms and Benchmarks</a></th>
                    </tr>
                
                    <tr id="dc92717385ea7c2f3b2d385ccc4bc90f19720d8c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dc92717385ea7c2f3b2d385ccc4bc90f19720d8c">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Rich_Features_for_Perceptual_Quality_Assessment_of_UGC_Videos_CVPR_2021_paper.html">Rich Features for Perceptual Quality Assessment of UGC Videos</a></th>
                    </tr>
                
                    <tr id="624ab884243e3c9e97ac159064d4ad3ecbe19ff1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/624ab884243e3c9e97ac159064d4ad3ecbe19ff1">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Task_Programming_Learning_Data_Efficient_Behavior_Representations_CVPR_2021_paper.html">Task Programming: Learning Data Efficient Behavior Representations</a></th>
                    </tr>
                
                    <tr id="1a38b992d776436299e92bc2c34ad63c723fc75b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a38b992d776436299e92bc2c34ad63c723fc75b">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Birdal_Quantum_Permutation_Synchronization_CVPR_2021_paper.html">Quantum Permutation Synchronization</a></th>
                    </tr>
                
                    <tr id="bc320788232352b9b245b4e8271e492964cb1620">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bc320788232352b9b245b4e8271e492964cb1620">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Sketch_Ground_and_Refine_Top-Down_Dense_Video_Captioning_CVPR_2021_paper.html">Sketch, Ground, and Refine: Top-Down Dense Video Captioning</a></th>
                    </tr>
                
                    <tr id="0e58ab9fd5bfc862ebf69dc7d2e641bfc65c4cba">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e58ab9fd5bfc862ebf69dc7d2e641bfc65c4cba">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Bottom-Up_Shift_and_Reasoning_for_Referring_Image_Segmentation_CVPR_2021_paper.html">Bottom-Up Shift and Reasoning for Referring Image Segmentation</a></th>
                    </tr>
                
                    <tr id="d5527bd5cd55023b685f31cd1e0af611d9729a6b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d5527bd5cd55023b685f31cd1e0af611d9729a6b">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guizilini_Sparse_Auxiliary_Networks_for_Unified_Monocular_Depth_Prediction_and_Completion_CVPR_2021_paper.html">Sparse Auxiliary Networks for Unified Monocular Depth Prediction and Completion</a></th>
                    </tr>
                
                    <tr id="52bffd428b3f0c14509d6e68699ece7c46f7cf0b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/52bffd428b3f0c14509d6e68699ece7c46f7cf0b">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sain_StyleMeUp_Towards_Style-Agnostic_Sketch-Based_Image_Retrieval_CVPR_2021_paper.html">StyleMeUp: Towards Style-Agnostic Sketch-Based Image Retrieval</a></th>
                    </tr>
                
                    <tr id="6e7f13e205494e5ec0dfeb9a2ca7d27e9d5db65f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6e7f13e205494e5ec0dfeb9a2ca7d27e9d5db65f">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Self-Supervised_Geometric_Perception_CVPR_2021_paper.html">Self-Supervised Geometric Perception</a></th>
                    </tr>
                
                    <tr id="fdc369b826bafb1eb0c4e1ff03dff3517896f80b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fdc369b826bafb1eb0c4e1ff03dff3517896f80b">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Complementary_Relation_Contrastive_Distillation_CVPR_2021_paper.html">Complementary Relation Contrastive Distillation</a></th>
                    </tr>
                
                    <tr id="1a0d5ce6e27d981662742775aa4475b7929d013d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a0d5ce6e27d981662742775aa4475b7929d013d">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nauata_House-GAN_Generative_Adversarial_Layout_Refinement_Network_towards_Intelligent_Computational_Agent_CVPR_2021_paper.html">House-GAN++: Generative Adversarial Layout Refinement Network towards Intelligent Computational Agent for Professional Architects</a></th>
                    </tr>
                
                    <tr id="90b9239176962fc490396ed1c224695b7c126120">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/90b9239176962fc490396ed1c224695b7c126120">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Variational_Prototype_Learning_for_Deep_Face_Recognition_CVPR_2021_paper.html">Variational Prototype Learning for Deep Face Recognition</a></th>
                    </tr>
                
                    <tr id="64671b3f871e7d1cddc472d9fa3b740f4fc2325b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/64671b3f871e7d1cddc472d9fa3b740f4fc2325b">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Relevance-CAM_Your_Model_Already_Knows_Where_To_Look_CVPR_2021_paper.html">Relevance-CAM: Your Model Already Knows Where To Look</a></th>
                    </tr>
                
                    <tr id="6cb88ffac9d4422dace9c40fdc986997dce1f2a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6cb88ffac9d4422dace9c40fdc986997dce1f2a5">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Towards_High_Fidelity_Face_Relighting_With_Realistic_Shadows_CVPR_2021_paper.html">Towards High Fidelity Face Relighting With Realistic Shadows</a></th>
                    </tr>
                
                    <tr id="1c9cea1cfc9183f51e617b3cdfe6b1d045c23286">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1c9cea1cfc9183f51e617b3cdfe6b1d045c23286">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Room-and-Object_Aware_Knowledge_Reasoning_for_Remote_Embodied_Referring_Expression_CVPR_2021_paper.html">Room-and-Object Aware Knowledge Reasoning for Remote Embodied Referring Expression</a></th>
                    </tr>
                
                    <tr id="abb106037923df747076f0d15795e637bab923a4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/abb106037923df747076f0d15795e637bab923a4">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Oh_Background-Aware_Pooling_and_Noise-Aware_Loss_for_Weakly-Supervised_Semantic_Segmentation_CVPR_2021_paper.html">Background-Aware Pooling and Noise-Aware Loss for Weakly-Supervised Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="453170a3fada768913a84b9ed52951e3299c9d03">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/453170a3fada768913a84b9ed52951e3299c9d03">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Rai_Home_Action_Genome_Cooperative_Compositional_Action_Understanding_CVPR_2021_paper.html">Home Action Genome: Cooperative Compositional Action Understanding</a></th>
                    </tr>
                
                    <tr id="4c3dca70c4b3091498f9608f7b0ccebc8854dfb5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c3dca70c4b3091498f9608f7b0ccebc8854dfb5">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Saha_LOHO_Latent_Optimization_of_Hairstyles_via_Orthogonalization_CVPR_2021_paper.html">LOHO: Latent Optimization of Hairstyles via Orthogonalization</a></th>
                    </tr>
                
                    <tr id="31714ffb9b31bed33f48fa07dcf36fd88ba4f2af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/31714ffb9b31bed33f48fa07dcf36fd88ba4f2af">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lambourne_BRepNet_A_Topological_Message_Passing_System_for_Solid_Models_CVPR_2021_paper.html">BRepNet: A Topological Message Passing System for Solid Models</a></th>
                    </tr>
                
                    <tr id="92df862c24d6436eeca777870ad853bf692eee2b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/92df862c24d6436eeca777870ad853bf692eee2b">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pham_Learning_To_Predict_Visual_Attributes_in_the_Wild_CVPR_2021_paper.html">Learning To Predict Visual Attributes in the Wild</a></th>
                    </tr>
                
                    <tr id="6d6148c5d4298c8ac6c374c4997ad143e76e8a16">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6d6148c5d4298c8ac6c374c4997ad143e76e8a16">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Positive-Congruent_Training_Towards_Regression-Free_Model_Updates_CVPR_2021_paper.html">Positive-Congruent Training: Towards Regression-Free Model Updates</a></th>
                    </tr>
                
                    <tr id="0ed74f5eca823811347c20efa38b0af28c75fbb7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ed74f5eca823811347c20efa38b0af28c75fbb7">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_S2R-DepthNet_Learning_a_Generalizable_Depth-Specific_Structural_Representation_CVPR_2021_paper.html">S2R-DepthNet: Learning a Generalizable Depth-Specific Structural Representation</a></th>
                    </tr>
                
                    <tr id="415267fe3d8e1779ef3b71cd9d6574a15a910f43">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/415267fe3d8e1779ef3b71cd9d6574a15a910f43">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xiao_Space-Time_Distillation_for_Video_Super-Resolution_CVPR_2021_paper.html">Space-Time Distillation for Video Super-Resolution</a></th>
                    </tr>
                
                    <tr id="d0829986bd7d8904ee855117c974140de3be742c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d0829986bd7d8904ee855117c974140de3be742c">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jafarian_Learning_High_Fidelity_Depths_of_Dressed_Humans_by_Watching_Social_CVPR_2021_paper.html">Learning High Fidelity Depths of Dressed Humans by Watching Social Media Dance Videos</a></th>
                    </tr>
                
                    <tr id="33db9e6630d95d6087ce92390082787248867310">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/33db9e6630d95d6087ce92390082787248867310">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Neubert_Hyperdimensional_Computing_as_a_Framework_for_Systematic_Aggregation_of_Image_CVPR_2021_paper.html">Hyperdimensional Computing as a Framework for Systematic Aggregation of Image Descriptors</a></th>
                    </tr>
                
                    <tr id="77d2963441c35514fcc10465b46025cc94797a76">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/77d2963441c35514fcc10465b46025cc94797a76">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Budnik_Asymmetric_Metric_Learning_for_Knowledge_Transfer_CVPR_2021_paper.html">Asymmetric Metric Learning for Knowledge Transfer</a></th>
                    </tr>
                
                    <tr id="6ac8e0915df41692bdceef7f18bc1c50271630fc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6ac8e0915df41692bdceef7f18bc1c50271630fc">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Collier_Correlated_Input-Dependent_Label_Noise_in_Large-Scale_Image_Classification_CVPR_2021_paper.html">Correlated Input-Dependent Label Noise in Large-Scale Image Classification</a></th>
                    </tr>
                
                    <tr id="fa904504a5ab2a2fa6f59638e6dec37714d729bb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fa904504a5ab2a2fa6f59638e6dec37714d729bb">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Menapace_Playable_Video_Generation_CVPR_2021_paper.html">Playable Video Generation</a></th>
                    </tr>
                
                    <tr id="441885cdbd1212eeb017da894749fb11bebec21a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/441885cdbd1212eeb017da894749fb11bebec21a">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Revisiting_Superpixels_for_Active_Learning_in_Semantic_Segmentation_With_Realistic_CVPR_2021_paper.html">Revisiting Superpixels for Active Learning in Semantic Segmentation With Realistic Annotation Costs</a></th>
                    </tr>
                
                    <tr id="72411df7bfc8c4b704d5c5146981ae26df3244a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/72411df7bfc8c4b704d5c5146981ae26df3244a6">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Person_Re-Identification_Using_Heterogeneous_Local_Graph_Attention_Networks_CVPR_2021_paper.html">Person Re-Identification Using Heterogeneous Local Graph Attention Networks</a></th>
                    </tr>
                
                    <tr id="575b6c34f978c72415d7f86fce01803bd2374431">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/575b6c34f978c72415d7f86fce01803bd2374431">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Heitz_A_Sliced_Wasserstein_Loss_for_Neural_Texture_Synthesis_CVPR_2021_paper.html">A Sliced Wasserstein Loss for Neural Texture Synthesis</a></th>
                    </tr>
                
                    <tr id="914a4686c365c1f24935abcd8de9d117450e0b43">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/914a4686c365c1f24935abcd8de9d117450e0b43">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Shot_Contrastive_Self-Supervised_Learning_for_Scene_Boundary_Detection_CVPR_2021_paper.html">Shot Contrastive Self-Supervised Learning for Scene Boundary Detection</a></th>
                    </tr>
                
                    <tr id="6a156289c7758ff5ce53cdab0931267e59725d7c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a156289c7758ff5ce53cdab0931267e59725d7c">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_L2M-GAN_Learning_To_Manipulate_Latent_Space_Semantics_for_Facial_Attribute_CVPR_2021_paper.html">L2M-GAN: Learning To Manipulate Latent Space Semantics for Facial Attribute Editing</a></th>
                    </tr>
                
                    <tr id="81cb286b73a69846cf5e02dd7d58d4694453194e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/81cb286b73a69846cf5e02dd7d58d4694453194e">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jin_Teachers_Do_More_Than_Teach_Compressing_Image-to-Image_Models_CVPR_2021_paper.html">Teachers Do More Than Teach: Compressing Image-to-Image Models</a></th>
                    </tr>
                
                    <tr id="eae9cda1e0c5fd9eb6342e6935eeb8d36dab2b75">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eae9cda1e0c5fd9eb6342e6935eeb8d36dab2b75">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ren_3D_Spatial_Recognition_Without_Spatially_Labeled_3D_CVPR_2021_paper.html">3D Spatial Recognition without Spatially Labeled 3D</a></th>
                    </tr>
                
                    <tr id="c989afabe737ed7dfeba2a0793506a09ffae867b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c989afabe737ed7dfeba2a0793506a09ffae867b">21</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_MetaSCI_Scalable_and_Adaptive_Reconstruction_for_Video_Compressive_Sensing_CVPR_2021_paper.html">MetaSCI: Scalable and Adaptive Reconstruction for Video Compressive Sensing</a></th>
                    </tr>
                
                    <tr id="efedff6481bd67ffe7f1924512d97742f0d34c9a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/efedff6481bd67ffe7f1924512d97742f0d34c9a">21</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Kim_FReTAL_Generalizing_Deepfake_Detection_Using_Knowledge_Distillation_and_Representation_Learning_CVPRW_2021_paper.html">FReTAL: Generalizing Deepfake Detection Using Knowledge Distillation and Representation Learning</a></th>
                    </tr>
                
                    <tr id="0fa9737f048f9e58f0155bf8e4d1604a0c49aec3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0fa9737f048f9e58f0155bf8e4d1604a0c49aec3">21</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Boguszewski_LandCover.ai_Dataset_for_Automatic_Mapping_of_Buildings_Woodlands_Water_and_CVPRW_2021_paper.html">LandCover.ai: Dataset for Automatic Mapping of Buildings, Woodlands, Water and Roads From Aerial Imagery</a></th>
                    </tr>
                
                    <tr id="00e1f1f45b57ca5b9ae4f910fcbe521ecca9c54b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00e1f1f45b57ca5b9ae4f910fcbe521ecca9c54b">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kalischek_In_the_Light_of_Feature_Distributions_Moment_Matching_for_Neural_CVPR_2021_paper.html">In the Light of Feature Distributions: Moment Matching for Neural Style Transfer</a></th>
                    </tr>
                
                    <tr id="40d0356051a96e55ca1ae8914ccc3da224150ed0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/40d0356051a96e55ca1ae8914ccc3da224150ed0">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gecer_OSTeC_One-Shot_Texture_Completion_CVPR_2021_paper.html">OSTeC: One-Shot Texture Completion</a></th>
                    </tr>
                
                    <tr id="6b291dea9bb80fea41f4ffa17aaad52ab5d26ada">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6b291dea9bb80fea41f4ffa17aaad52ab5d26ada">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ranjan_Learning_To_Count_Everything_CVPR_2021_paper.html">Learning To Count Everything</a></th>
                    </tr>
                
                    <tr id="3f7e066ed49d5734308d2f562ab6ee4ba18ed1ed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f7e066ed49d5734308d2f562ab6ee4ba18ed1ed">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_DRANet_Disentangling_Representation_and_Adaptation_Networks_for_Unsupervised_Cross-Domain_Adaptation_CVPR_2021_paper.html">DRANet: Disentangling Representation and Adaptation Networks for Unsupervised Cross-Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="3961acb8c63a46ab5fa54e79cb59b37288a8d8ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3961acb8c63a46ab5fa54e79cb59b37288a8d8ad">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jiang_Regressive_Domain_Adaptation_for_Unsupervised_Keypoint_Detection_CVPR_2021_paper.html">Regressive Domain Adaptation for Unsupervised Keypoint Detection</a></th>
                    </tr>
                
                    <tr id="b05917ed01ac958fde819c00c14ea0f7f3ff84d3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b05917ed01ac958fde819c00c14ea0f7f3ff84d3">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deng_LiBRe_A_Practical_Bayesian_Approach_to_Adversarial_Detection_CVPR_2021_paper.html">LiBRe: A Practical Bayesian Approach to Adversarial Detection</a></th>
                    </tr>
                
                    <tr id="446b07b8aaaaa75f0352be89bd97498ee5f69e36">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/446b07b8aaaaa75f0352be89bd97498ee5f69e36">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_QAIR_Practical_Query-Efficient_Black-Box_Attacks_for_Image_Retrieval_CVPR_2021_paper.html">QAIR: Practical Query-Efficient Black-Box Attacks for Image Retrieval</a></th>
                    </tr>
                
                    <tr id="d00bfacebef0cc5abae0cff1c552664a30179648">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d00bfacebef0cc5abae0cff1c552664a30179648">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chandran_Adaptive_Convolutions_for_Structure-Aware_Style_Transfer_CVPR_2021_paper.html">Adaptive Convolutions for Structure-Aware Style Transfer</a></th>
                    </tr>
                
                    <tr id="56bf0c8f29857fb10bf5c8418cad79b72a98dc7b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/56bf0c8f29857fb10bf5c8418cad79b72a98dc7b">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Mutual_CRF-GNN_for_Few-Shot_Learning_CVPR_2021_paper.html">Mutual CRF-GNN for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="16f079eb1bfbf453f0757bdd33fa64f35bc717e8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16f079eb1bfbf453f0757bdd33fa64f35bc717e8">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Maggioni_Efficient_Multi-Stage_Video_Denoising_With_Recurrent_Spatio-Temporal_Fusion_CVPR_2021_paper.html">Efficient Multi-Stage Video Denoising With Recurrent Spatio-Temporal Fusion</a></th>
                    </tr>
                
                    <tr id="31b865ba60fa98de2f0af38cc3eb9d07fd994f06">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/31b865ba60fa98de2f0af38cc3eb9d07fd994f06">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Weakly_Supervised_Video_Salient_Object_Detection_CVPR_2021_paper.html">Weakly Supervised Video Salient Object Detection</a></th>
                    </tr>
                
                    <tr id="aeaa9ba2a453a60478d66acbb15678a5dd882686">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aeaa9ba2a453a60478d66acbb15678a5dd882686">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Teed_Tangent_Space_Backpropagation_for_3D_Transformation_Groups_CVPR_2021_paper.html">Tangent Space Backpropagation for 3D Transformation Groups</a></th>
                    </tr>
                
                    <tr id="4df25f8bada0bdc6dbb9294660b898503ba271bc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4df25f8bada0bdc6dbb9294660b898503ba271bc">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_HLA-Face_Joint_High-Low_Adaptation_for_Low_Light_Face_Detection_CVPR_2021_paper.html">HLA-Face: Joint High-Low Adaptation for Low Light Face Detection</a></th>
                    </tr>
                
                    <tr id="b9aec7d67f75c85df54339d1abb0a40ffb3a8885">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b9aec7d67f75c85df54339d1abb0a40ffb3a8885">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sundararaman_Tracking_Pedestrian_Heads_in_Dense_Crowd_CVPR_2021_paper.html">Tracking Pedestrian Heads in Dense Crowd</a></th>
                    </tr>
                
                    <tr id="6be64445935dcdf4053a6e78b623b80a314d9bbc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6be64445935dcdf4053a6e78b623b80a314d9bbc">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Whitehead_Separating_Skills_and_Concepts_for_Novel_Visual_Question_Answering_CVPR_2021_paper.html">Separating Skills and Concepts for Novel Visual Question Answering</a></th>
                    </tr>
                
                    <tr id="6488d5f138e33612a6edb67e4981b503ee3f0f3f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6488d5f138e33612a6edb67e4981b503ee3f0f3f">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ge_Video_Object_Segmentation_Using_Global_and_Instance_Embedding_Learning_CVPR_2021_paper.html">Video Object Segmentation Using Global and Instance Embedding Learning</a></th>
                    </tr>
                
                    <tr id="7ccb6f2af77e49925fbe3817350b3951d565ee2f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ccb6f2af77e49925fbe3817350b3951d565ee2f">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xing_End-to-End_Learning_for_Joint_Image_Demosaicing_Denoising_and_Super-Resolution_CVPR_2021_paper.html">End-to-End Learning for Joint Image Demosaicing, Denoising and Super-Resolution</a></th>
                    </tr>
                
                    <tr id="5ff3f7b147dffb35b8fc2caf7493419705bdb47d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5ff3f7b147dffb35b8fc2caf7493419705bdb47d">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tan_OTCE_A_Transferability_Metric_for_Cross-Domain_Cross-Task_Representations_CVPR_2021_paper.html">OTCE: A Transferability Metric for Cross-Domain Cross-Task Representations</a></th>
                    </tr>
                
                    <tr id="68dfbbbc82deae29d37559b750762244517c2c94">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/68dfbbbc82deae29d37559b750762244517c2c94">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bai_Riggable_3D_Face_Reconstruction_via_In-Network_Optimization_CVPR_2021_paper.html">Riggable 3D Face Reconstruction via In-Network Optimization</a></th>
                    </tr>
                
                    <tr id="8912d80a422f483644cb7b2116353a97e2a5cc5b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8912d80a422f483644cb7b2116353a97e2a5cc5b">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Weng_Holistic_3D_Human_and_Scene_Mesh_Estimation_From_Single_View_CVPR_2021_paper.html">Holistic 3D Human and Scene Mesh Estimation From Single View Images</a></th>
                    </tr>
                
                    <tr id="8d1782218b82f321b54608297dcadd242eb9beb3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8d1782218b82f321b54608297dcadd242eb9beb3">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Thames_Nutrition5k_Towards_Automatic_Nutritional_Understanding_of_Generic_Food_CVPR_2021_paper.html">Nutrition5k: Towards Automatic Nutritional Understanding of Generic Food</a></th>
                    </tr>
                
                    <tr id="333657bcebfaa42aa45d9c3e1afe7ff0a2cecb83">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/333657bcebfaa42aa45d9c3e1afe7ff0a2cecb83">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Scale-Aware_Automatic_Augmentation_for_Object_Detection_CVPR_2021_paper.html">Scale-Aware Automatic Augmentation for Object Detection</a></th>
                    </tr>
                
                    <tr id="2f5d358481b170282f8cd0d97b6387ed521fffd4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2f5d358481b170282f8cd0d97b6387ed521fffd4">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Su_Prioritized_Architecture_Sampling_With_Monto-Carlo_Tree_Search_CVPR_2021_paper.html">Prioritized Architecture Sampling With Monto-Carlo Tree Search</a></th>
                    </tr>
                
                    <tr id="a17d27c8213bf17f1d06f774874ba4ddc7494ef0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a17d27c8213bf17f1d06f774874ba4ddc7494ef0">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chi_Test-Time_Fast_Adaptation_for_Dynamic_Scene_Deblurring_via_Meta-Auxiliary_Learning_CVPR_2021_paper.html">Test-Time Fast Adaptation for Dynamic Scene Deblurring via Meta-Auxiliary Learning</a></th>
                    </tr>
                
                    <tr id="2ec3e9cea0cfd70e89a11d3052cd86a8f66ebd3c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ec3e9cea0cfd70e89a11d3052cd86a8f66ebd3c">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_MR_Image_Super-Resolution_With_Squeeze_and_Excitation_Reasoning_Attention_Network_CVPR_2021_paper.html">MR Image Super-Resolution With Squeeze and Excitation Reasoning Attention Network</a></th>
                    </tr>
                
                    <tr id="5b95063f3ecdb8883550120c44d98f7e0e783f4f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b95063f3ecdb8883550120c44d98f7e0e783f4f">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tosi_SMD-Nets_Stereo_Mixture_Density_Networks_CVPR_2021_paper.html">SMD-Nets: Stereo Mixture Density Networks</a></th>
                    </tr>
                
                    <tr id="ffa83a98b2a2fdf98d3430bfab68baf21c33d525">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ffa83a98b2a2fdf98d3430bfab68baf21c33d525">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jia_Leveraging_Line-Point_Consistence_To_Preserve_Structures_for_Wide_Parallax_Image_CVPR_2021_paper.html">Leveraging Line-Point Consistence To Preserve Structures for Wide Parallax Image Stitching</a></th>
                    </tr>
                
                    <tr id="1f7ffcc54a507379b373f60ba2db17797117757d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1f7ffcc54a507379b373f60ba2db17797117757d">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Saha_Learning_To_Relate_Depth_and_Semantics_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html">Learning To Relate Depth and Semantics for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="8c05c8b57605c76fbbe3492c24478d29621ef6c1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c05c8b57605c76fbbe3492c24478d29621ef6c1">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Learning_To_Segment_Rigid_Motions_From_Two_Frames_CVPR_2021_paper.html">Learning To Segment Rigid Motions From Two Frames</a></th>
                    </tr>
                
                    <tr id="970cb7b5b25da0f1f8b000add10960680fe8cd2e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/970cb7b5b25da0f1f8b000add10960680fe8cd2e">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Searching_for_Fast_Model_Families_on_Datacenter_Accelerators_CVPR_2021_paper.html">Searching for Fast Model Families on Datacenter Accelerators</a></th>
                    </tr>
                
                    <tr id="59b8a2a1b88ce8dc15a6603f135f7b4d04820a55">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/59b8a2a1b88ce8dc15a6603f135f7b4d04820a55">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Discovering_Interpretable_Latent_Space_Directions_of_GANs_Beyond_Binary_Attributes_CVPR_2021_paper.html">Discovering Interpretable Latent Space Directions of GANs Beyond Binary Attributes</a></th>
                    </tr>
                
                    <tr id="dbc023b52618972847e2dcbd641949daeaabfc9d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dbc023b52618972847e2dcbd641949daeaabfc9d">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Deep_Learning_in_Latent_Space_for_Video_Prediction_and_Compression_CVPR_2021_paper.html">Deep Learning in Latent Space for Video Prediction and Compression</a></th>
                    </tr>
                
                    <tr id="bc91c8ab9bd496a5934e228dbcb55b6ad4d1032b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bc91c8ab9bd496a5934e228dbcb55b6ad4d1032b">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tran_Explore_Image_Deblurring_via_Encoded_Blur_Kernel_Space_CVPR_2021_paper.html">Explore Image Deblurring via Encoded Blur Kernel Space</a></th>
                    </tr>
                
                    <tr id="aff1d5e76663fd1f3f5e5a9caccc12b0959be6cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aff1d5e76663fd1f3f5e5a9caccc12b0959be6cc">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nguyen_Lipstick_Aint_Enough_Beyond_Color_Matching_for_In-the-Wild_Makeup_Transfer_CVPR_2021_paper.html">Lipstick Ain&#39;t Enough: Beyond Color Matching for In-the-Wild Makeup Transfer</a></th>
                    </tr>
                
                    <tr id="5f439061d2d020b8c67953cb0391dfb72c312bb5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f439061d2d020b8c67953cb0391dfb72c312bb5">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_ABMDRNet_Adaptive-Weighted_Bi-Directional_Modality_Difference_Reduction_Network_for_RGB-T_Semantic_CVPR_2021_paper.html">ABMDRNet: Adaptive-Weighted Bi-Directional Modality Difference Reduction Network for RGB-T Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="5fda8a8bc80ee26cbf618fc555ea41b9950a5725">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5fda8a8bc80ee26cbf618fc555ea41b9950a5725">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Monfort_Spoken_Moments_Learning_Joint_Audio-Visual_Representations_From_Video_Descriptions_CVPR_2021_paper.html">Spoken Moments: Learning Joint Audio-Visual Representations From Video Descriptions</a></th>
                    </tr>
                
                    <tr id="2050ca7f9535710f74d698f4fc227eade31d546b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2050ca7f9535710f74d698f4fc227eade31d546b">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Image_Restoration_for_Under-Display_Camera_CVPR_2021_paper.html">Image Restoration for Under-Display Camera</a></th>
                    </tr>
                
                    <tr id="d3b27cb435dc2a72471b996409bc8ecba80896d9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d3b27cb435dc2a72471b996409bc8ecba80896d9">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Abdelsalam_IIRC_Incremental_Implicitly-Refined_Classification_CVPR_2021_paper.html">IIRC: Incremental Implicitly-Refined Classification</a></th>
                    </tr>
                
                    <tr id="2bb6dad01d726e4c828a05b113c7d00f4c9ec74c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2bb6dad01d726e4c828a05b113c7d00f4c9ec74c">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nassar_All_Labels_Are_Not_Created_Equal_Enhancing_Semi-Supervision_via_Label_CVPR_2021_paper.html">All Labels Are Not Created Equal: Enhancing Semi-supervision via Label Grouping and Co-training</a></th>
                    </tr>
                
                    <tr id="4c6924c3a480b6afb2dd8cc8d0db92c2f908ff14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c6924c3a480b6afb2dd8cc8d0db92c2f908ff14">20</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Uncertainty_Guided_Collaborative_Training_for_Weakly_Supervised_Temporal_Action_Detection_CVPR_2021_paper.html">Uncertainty Guided Collaborative Training for Weakly Supervised Temporal Action Detection</a></th>
                    </tr>
                
                    <tr id="8382e7195bd698dee19ba3f0bc7b3f2934f6ef8c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8382e7195bd698dee19ba3f0bc7b3f2934f6ef8c">20</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Helou_NTIRE_2021_Depth_Guided_Image_Relighting_Challenge_CVPRW_2021_paper.html">NTIRE 2021 Depth Guided Image Relighting Challenge</a></th>
                    </tr>
                
                    <tr id="2b4d1d2108d708830899e31fd0eae553b0bf1713">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b4d1d2108d708830899e31fd0eae553b0bf1713">20</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SketchDL/html/Willis_Engineering_Sketch_Generation_for_Computer-Aided_Design_CVPRW_2021_paper.html">Engineering Sketch Generation for Computer-Aided Design</a></th>
                    </tr>
                
                    <tr id="f66d6defa4b6ba3cfb09b410ec5127e3b65a5f66">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f66d6defa4b6ba3cfb09b410ec5127e3b65a5f66">20</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Zunino_Explainable_Deep_Classification_Models_for_Domain_Generalization_CVPRW_2021_paper.html">Explainable Deep Classification Models for Domain Generalization</a></th>
                    </tr>
                
                    <tr id="1054d77eb8fb1b3ea020c101f9501c148b8844f6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1054d77eb8fb1b3ea020c101f9501c148b8844f6">20</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/Cioppa_Camera_Calibration_and_Player_Localization_in_SoccerNet-v2_and_Investigation_of_CVPRW_2021_paper.html">Camera Calibration and Player Localization in SoccerNet-v2 and Investigation of Their Representations for Action Spotting</a></th>
                    </tr>
                
                    <tr id="b8277ce2b880b97fa251057c14003aacec2d7a9b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b8277ce2b880b97fa251057c14003aacec2d7a9b">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_DeepI2P_Image-to-Point_Cloud_Registration_via_Deep_Classification_CVPR_2021_paper.html">DeepI2P: Image-to-Point Cloud Registration via Deep Classification</a></th>
                    </tr>
                
                    <tr id="4f7e800d16cbe969b7f4b0797988e61e0059d003">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f7e800d16cbe969b7f4b0797988e61e0059d003">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_CondenseNet_V2_Sparse_Feature_Reactivation_for_Deep_Networks_CVPR_2021_paper.html">CondenseNet V2: Sparse Feature Reactivation for Deep Networks</a></th>
                    </tr>
                
                    <tr id="04d70c5e2f16b7825c1247938d339e325725c270">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/04d70c5e2f16b7825c1247938d339e325725c270">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Parida_Beyond_Image_to_Depth_Improving_Depth_Prediction_Using_Echoes_CVPR_2021_paper.html">Beyond Image to Depth: Improving Depth Prediction Using Echoes</a></th>
                    </tr>
                
                    <tr id="94c22c98d38d983fdbd41d75488e2de5176082aa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/94c22c98d38d983fdbd41d75488e2de5176082aa">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Self-Supervised_Pillar_Motion_Learning_for_Autonomous_Driving_CVPR_2021_paper.html">Self-Supervised Pillar Motion Learning for Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="81e220a387d59fd713e8afda38a015b575ed6206">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/81e220a387d59fd713e8afda38a015b575ed6206">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hwang_Exemplar-Based_Open-Set_Panoptic_Segmentation_Network_CVPR_2021_paper.html">Exemplar-Based Open-Set Panoptic Segmentation Network</a></th>
                    </tr>
                
                    <tr id="ad3e87d99d2945658acffbd1b356758cf3e332eb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ad3e87d99d2945658acffbd1b356758cf3e332eb">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Online_Multiple_Object_Tracking_With_Cross-Task_Synergy_CVPR_2021_paper.html">Online Multiple Object Tracking With Cross-Task Synergy</a></th>
                    </tr>
                
                    <tr id="e0df00ae5d921da18e12523cd753614e08156e94">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e0df00ae5d921da18e12523cd753614e08156e94">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Schmidtke_Unsupervised_Human_Pose_Estimation_Through_Transforming_Shape_Templates_CVPR_2021_paper.html">Unsupervised Human Pose Estimation Through Transforming Shape Templates</a></th>
                    </tr>
                
                    <tr id="12f0734af81da9f2f893aa5102489053f915a949">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/12f0734af81da9f2f893aa5102489053f915a949">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ibing_3D_Shape_Generation_With_Grid-Based_Implicit_Functions_CVPR_2021_paper.html">3D Shape Generation With Grid-Based Implicit Functions</a></th>
                    </tr>
                
                    <tr id="4899ad7b2f43afe03dad34e0c4fbd51f2a77320f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4899ad7b2f43afe03dad34e0c4fbd51f2a77320f">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Action_Shuffle_Alternating_Learning_for_Unsupervised_Action_Segmentation_CVPR_2021_paper.html">Action Shuffle Alternating Learning for Unsupervised Action Segmentation</a></th>
                    </tr>
                
                    <tr id="4372af4b7be18f92d7269eba8d5c802de272c964">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4372af4b7be18f92d7269eba8d5c802de272c964">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hur_Self-Supervised_Multi-Frame_Monocular_Scene_Flow_CVPR_2021_paper.html">Self-Supervised Multi-Frame Monocular Scene Flow</a></th>
                    </tr>
                
                    <tr id="773c6bc786defc77d0ec284042a65d275d9297a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/773c6bc786defc77d0ec284042a65d275d9297a9">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Girard_Polygonal_Building_Extraction_by_Frame_Field_Learning_CVPR_2021_paper.html">Polygonal Building Extraction by Frame Field Learning</a></th>
                    </tr>
                
                    <tr id="cbd3649fdf84c7b289d3534ed9375b5d2ef1fc15">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cbd3649fdf84c7b289d3534ed9375b5d2ef1fc15">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Hijack-GAN_Unintended-Use_of_Pretrained_Black-Box_GANs_CVPR_2021_paper.html">Hijack-GAN: Unintended-Use of Pretrained, Black-Box GANs</a></th>
                    </tr>
                
                    <tr id="0e43d528ae20785ea8adc4c3a03e47470b884af9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e43d528ae20785ea8adc4c3a03e47470b884af9">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liang_RangeIoUDet_Range_Image_Based_Real-Time_3D_Object_Detector_Optimized_by_CVPR_2021_paper.html">RangeIoUDet: Range Image Based Real-Time 3D Object Detector Optimized by Intersection Over Union</a></th>
                    </tr>
                
                    <tr id="68f94662dabce3478924aa88decac130a7da5eb0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/68f94662dabce3478924aa88decac130a7da5eb0">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dai_A_Hyperbolic-to-Hyperbolic_Graph_Convolutional_Network_CVPR_2021_paper.html">A Hyperbolic-to-Hyperbolic Graph Convolutional Network</a></th>
                    </tr>
                
                    <tr id="62e9dadf5f1ccd36a875a5c626ac676985457848">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/62e9dadf5f1ccd36a875a5c626ac676985457848">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jun_Joint_Deep_Model-Based_MR_Image_and_Coil_Sensitivity_Reconstruction_Network_CVPR_2021_paper.html">Joint Deep Model-Based MR Image and Coil Sensitivity Reconstruction Network (Joint-ICNet) for Fast MRI</a></th>
                    </tr>
                
                    <tr id="4815a69abc190444cb42ad7c7b077b9669dd9549">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4815a69abc190444cb42ad7c7b077b9669dd9549">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Rethinking_Graph_Neural_Architecture_Search_From_Message-Passing_CVPR_2021_paper.html">Rethinking Graph Neural Architecture Search From Message-Passing</a></th>
                    </tr>
                
                    <tr id="e94d4b4c7b16cd9713aaf6d9dc31dea0f484abfb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e94d4b4c7b16cd9713aaf6d9dc31dea0f484abfb">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_LAFEAT_Piercing_Through_Adversarial_Defenses_With_Latent_Features_CVPR_2021_paper.html">LAFEAT: Piercing Through Adversarial Defenses With Latent Features</a></th>
                    </tr>
                
                    <tr id="18dec3207b6bdd9e4b61c50bf63c0329a990706b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/18dec3207b6bdd9e4b61c50bf63c0329a990706b">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pang_TearingNet_Point_Cloud_Autoencoder_To_Learn_Topology-Friendly_Representations_CVPR_2021_paper.html">TearingNet: Point Cloud Autoencoder To Learn Topology-Friendly Representations</a></th>
                    </tr>
                
                    <tr id="8e74da9a4a3dd231ad277b033172e5cd1700cb0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e74da9a4a3dd231ad277b033172e5cd1700cb0c">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mehra_How_Robust_Are_Randomized_Smoothing_Based_Defenses_to_Data_Poisoning_CVPR_2021_paper.html">How Robust Are Randomized Smoothing Based Defenses to Data Poisoning?</a></th>
                    </tr>
                
                    <tr id="4ffddfa047a18e9153cb0b798f4187b93d39d9a3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ffddfa047a18e9153cb0b798f4187b93d39d9a3">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Normalized_Avatar_Synthesis_Using_StyleGAN_and_Perceptual_Refinement_CVPR_2021_paper.html">Normalized Avatar Synthesis Using StyleGAN and Perceptual Refinement</a></th>
                    </tr>
                
                    <tr id="3336270d6eaa8435f8382b30150c3e78ada194a8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3336270d6eaa8435f8382b30150c3e78ada194a8">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yao_Joint-DetNAS_Upgrade_Your_Detector_With_NAS_Pruning_and_Dynamic_Distillation_CVPR_2021_paper.html">Joint-DetNAS: Upgrade Your Detector With NAS, Pruning and Dynamic Distillation</a></th>
                    </tr>
                
                    <tr id="9808c882294fc3b6a1bfed85cc69d622d4ec7751">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9808c882294fc3b6a1bfed85cc69d622d4ec7751">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Generalizing_to_the_Open_World_Deep_Visual_Odometry_With_Online_CVPR_2021_paper.html">Generalizing to the Open World: Deep Visual Odometry With Online Adaptation</a></th>
                    </tr>
                
                    <tr id="5645e0afc9188d5e2bc119499b2695177b655d82">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5645e0afc9188d5e2bc119499b2695177b655d82">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Fine-Grained_Shape-Appearance_Mutual_Learning_for_Cloth-Changing_Person_Re-Identification_CVPR_2021_paper.html">Fine-Grained Shape-Appearance Mutual Learning for Cloth-Changing Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="88cd821c6f5a78a9a08bcd8291efd30c6f78b053">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/88cd821c6f5a78a9a08bcd8291efd30c6f78b053">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Relation-aware_Instance_Refinement_for_Weakly_Supervised_Visual_Grounding_CVPR_2021_paper.html">Relation-aware Instance Refinement for Weakly Supervised Visual Grounding</a></th>
                    </tr>
                
                    <tr id="44c1149ba836a479b389fba4412a29340208c7d0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/44c1149ba836a479b389fba4412a29340208c7d0">19</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wimbauer_MonoRec_Semi-Supervised_Dense_Reconstruction_in_Dynamic_Environments_From_a_Single_CVPR_2021_paper.html">MonoRec: Semi-Supervised Dense Reconstruction in Dynamic Environments from a Single Moving Camera</a></th>
                    </tr>
                
                    <tr id="1d9795902ff50ab515e31f2ef4b4975b83cafe24">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d9795902ff50ab515e31f2ef4b4975b83cafe24">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Son_NTIRE_2021_Challenge_on_Video_Super-Resolution_CVPRW_2021_paper.html">NTIRE 2021 Challenge on Video Super-Resolution</a></th>
                    </tr>
                
                    <tr id="363ec14754802c049986a6999c5aa4c6ae5d2bad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/363ec14754802c049986a6999c5aa4c6ae5d2bad">19</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Aboah_A_Vision-Based_System_for_Traffic_Anomaly_Detection_Using_Deep_Learning_CVPRW_2021_paper.html">A Vision-Based System for Traffic Anomaly Detection Using Deep Learning and Decision Trees</a></th>
                    </tr>
                
                    <tr id="765ad3844c7c8fe00fbd5475012e02b67627a11c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/765ad3844c7c8fe00fbd5475012e02b67627a11c">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_OpenRooms_An_Open_Framework_for_Photorealistic_Indoor_Scene_Datasets_CVPR_2021_paper.html">OpenRooms: An Open Framework for Photorealistic Indoor Scene Datasets</a></th>
                    </tr>
                
                    <tr id="56c6c01b9762e52340fd546ec183809eee8d2f72">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/56c6c01b9762e52340fd546ec183809eee8d2f72">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pizzati_CoMoGAN_Continuous_Model-Guided_Image-to-Image_Translation_CVPR_2021_paper.html">CoMoGAN: Continuous Model-Guided Image-to-Image Translation</a></th>
                    </tr>
                
                    <tr id="316c5d697f7caf92b419213e929a6063afaf253c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/316c5d697f7caf92b419213e929a6063afaf253c">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_ACRE_Abstract_Causal_REasoning_Beyond_Covariation_CVPR_2021_paper.html">ACRE: Abstract Causal REasoning Beyond Covariation</a></th>
                    </tr>
                
                    <tr id="cf8dd25f61803ff658d2572d2f5f9ba8c8d46fa1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cf8dd25f61803ff658d2572d2f5f9ba8c8d46fa1">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_Context-Aware_Layout_to_Image_Generation_With_Enhanced_Object_Appearance_CVPR_2021_paper.html">Context-Aware Layout to Image Generation With Enhanced Object Appearance</a></th>
                    </tr>
                
                    <tr id="8748cd83efcd578a35fd95bd0ba044ce8bb3eea3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8748cd83efcd578a35fd95bd0ba044ce8bb3eea3">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Conditional_Bures_Metric_for_Domain_Adaptation_CVPR_2021_paper.html">Conditional Bures Metric for Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="42d21108b026d814d8243242459ea8d283c4d70d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/42d21108b026d814d8243242459ea8d283c4d70d">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_SUTD-TrafficQA_A_Question_Answering_Benchmark_and_an_Efficient_Network_for_CVPR_2021_paper.html">SUTD-TrafficQA: A Question Answering Benchmark and an Efficient Network for Video Reasoning Over Traffic Events</a></th>
                    </tr>
                
                    <tr id="3f7da5dbf82abf95e00874322555a8003abcb24b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f7da5dbf82abf95e00874322555a8003abcb24b">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Embedding_Transfer_With_Label_Relaxation_for_Improved_Metric_Learning_CVPR_2021_paper.html">Embedding Transfer With Label Relaxation for Improved Metric Learning</a></th>
                    </tr>
                
                    <tr id="84149211ed84edb70170845494230c5e97b60c60">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/84149211ed84edb70170845494230c5e97b60c60">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jeong_Memory-Guided_Unsupervised_Image-to-Image_Translation_CVPR_2021_paper.html">Memory-Guided Unsupervised Image-to-Image Translation</a></th>
                    </tr>
                
                    <tr id="078e1cf673454fd08e1865fe8673a90dbfe2b9ea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/078e1cf673454fd08e1865fe8673a90dbfe2b9ea">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tachella_The_Neural_Tangent_Link_Between_CNN_Denoisers_and_Non-Local_Filters_CVPR_2021_paper.html">The Neural Tangent Link Between CNN Denoisers and Non-Local Filters</a></th>
                    </tr>
                
                    <tr id="a3afb7a254d13bfc43c533ef2aa37949c72b8820">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a3afb7a254d13bfc43c533ef2aa37949c72b8820">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Serrurier_Achieving_Robustness_in_Classification_Using_Optimal_Transport_With_Hinge_Regularization_CVPR_2021_paper.html">Achieving Robustness in Classification Using Optimal Transport With Hinge Regularization</a></th>
                    </tr>
                
                    <tr id="f43302cc6fb115c97add812082db8b77970b4ec6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f43302cc6fb115c97add812082db8b77970b4ec6">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_User-Guided_Line_Art_Flat_Filling_With_Split_Filling_Mechanism_CVPR_2021_paper.html">User-Guided Line Art Flat Filling With Split Filling Mechanism</a></th>
                    </tr>
                
                    <tr id="031375c3f31ba5e20324eec3eb8cf3139d68820b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/031375c3f31ba5e20324eec3eb8cf3139d68820b">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Privacy-Preserving_Collaborative_Learning_With_Automatic_Transformation_Search_CVPR_2021_paper.html">Privacy-Preserving Collaborative Learning With Automatic Transformation Search</a></th>
                    </tr>
                
                    <tr id="1e20a0aacbb920816aec458d87ec567edc375307">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1e20a0aacbb920816aec458d87ec567edc375307">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Exploiting_Edge-Oriented_Reasoning_for_3D_Point-Based_Scene_Graph_Analysis_CVPR_2021_paper.html">Exploiting Edge-Oriented Reasoning for 3D Point-Based Scene Graph Analysis</a></th>
                    </tr>
                
                    <tr id="a347928e9665ccd81404c8797eec851a32ad6a48">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a347928e9665ccd81404c8797eec851a32ad6a48">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tomani_Post-Hoc_Uncertainty_Calibration_for_Domain_Drift_Scenarios_CVPR_2021_paper.html">Post-Hoc Uncertainty Calibration for Domain Drift Scenarios</a></th>
                    </tr>
                
                    <tr id="1865cbc2036f3b0bd1101cc91179c99299f67aed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1865cbc2036f3b0bd1101cc91179c99299f67aed">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jeong_Few-Shot_Open-Set_Recognition_by_Transformation_Consistency_CVPR_2021_paper.html">Few-Shot Open-Set Recognition by Transformation Consistency</a></th>
                    </tr>
                
                    <tr id="6a8cbf57962931e3409e136ae491067dd6d4c537">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a8cbf57962931e3409e136ae491067dd6d4c537">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Target-Aware_Object_Discovery_and_Association_for_Unsupervised_Video_Multi-Object_Segmentation_CVPR_2021_paper.html">Target-Aware Object Discovery and Association for Unsupervised Video Multi-Object Segmentation</a></th>
                    </tr>
                
                    <tr id="2bae6de96fccfe7f5e66bf2ff91613334726c8af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2bae6de96fccfe7f5e66bf2ff91613334726c8af">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Towards_Extremely_Compact_RNNs_for_Video_Recognition_With_Fully_Decomposed_CVPR_2021_paper.html">Towards Extremely Compact RNNs for Video Recognition With Fully Decomposed Hierarchical Tucker Structure</a></th>
                    </tr>
                
                    <tr id="6d192900820e886138053e5a6e6dae19e3caa4e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6d192900820e886138053e5a6e6dae19e3caa4e6">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Roads_Enriching_ImageNet_With_Human_Similarity_Judgments_and_Psychological_Embeddings_CVPR_2021_paper.html">Enriching ImageNet With Human Similarity Judgments and Psychological Embeddings</a></th>
                    </tr>
                
                    <tr id="df9a4dee35f4d4536e312269a469421d929f3197">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/df9a4dee35f4d4536e312269a469421d929f3197">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/de_Geus_Part-Aware_Panoptic_Segmentation_CVPR_2021_paper.html">Part-Aware Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="40481ae44c9cf75aa504bc8df6ca219d8b6edbfd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/40481ae44c9cf75aa504bc8df6ca219d8b6edbfd">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_No_Frame_Left_Behind_Full_Video_Action_Recognition_CVPR_2021_paper.html">No Frame Left Behind: Full Video Action Recognition</a></th>
                    </tr>
                
                    <tr id="0179688ea73f133a6dd50bc7a7595dd1d6de9160">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0179688ea73f133a6dd50bc7a7595dd1d6de9160">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wiles_Co-Attention_for_Conditioned_Image_Matching_CVPR_2021_paper.html">Co-Attention for Conditioned Image Matching</a></th>
                    </tr>
                
                    <tr id="802d7cfbecd6b0176310f6791d9dbaffca7b4eca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/802d7cfbecd6b0176310f6791d9dbaffca7b4eca">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Layerwise_Optimization_by_Gradient_Decomposition_for_Continual_Learning_CVPR_2021_paper.html">Layerwise Optimization by Gradient Decomposition for Continual Learning</a></th>
                    </tr>
                
                    <tr id="fa5bc4cbc95872f2a3ee1fd15c8a308b01dc0c10">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fa5bc4cbc95872f2a3ee1fd15c8a308b01dc0c10">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Deep_Homography_for_Efficient_Stereo_Image_Compression_CVPR_2021_paper.html">Deep Homography for Efficient Stereo Image Compression</a></th>
                    </tr>
                
                    <tr id="301ca7cfed69c7747d2bf53bf9d17d08a200f0ed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/301ca7cfed69c7747d2bf53bf9d17d08a200f0ed">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Transferable_Query_Selection_for_Active_Domain_Adaptation_CVPR_2021_paper.html">Transferable Query Selection for Active Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="561459f996924d2bb96e33e40766694eef70f171">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/561459f996924d2bb96e33e40766694eef70f171">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_RSG_A_Simple_but_Effective_Module_for_Learning_Imbalanced_Datasets_CVPR_2021_paper.html">RSG: A Simple but Effective Module for Learning Imbalanced Datasets</a></th>
                    </tr>
                
                    <tr id="886e69f9d7c85a1c008ed4ff9cd0d884fd79f344">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/886e69f9d7c85a1c008ed4ff9cd0d884fd79f344">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_PWCLO-Net_Deep_LiDAR_Odometry_in_3D_Point_Clouds_Using_Hierarchical_CVPR_2021_paper.html">PWCLO-Net: Deep LiDAR Odometry in 3D Point Clouds Using Hierarchical Embedding Mask Optimization</a></th>
                    </tr>
                
                    <tr id="c7c75f590c831f810f35195d9a85c57fe8f344fd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c7c75f590c831f810f35195d9a85c57fe8f344fd">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jia_Scalability_vs._Utility_Do_We_Have_To_Sacrifice_One_for_CVPR_2021_paper.html">Scalability vs. Utility: Do We Have To Sacrifice One for the Other in Data Importance Quantification?</a></th>
                    </tr>
                
                    <tr id="e4aef4816ea7de92889dcd8e8af88c1d7058dfbe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e4aef4816ea7de92889dcd8e8af88c1d7058dfbe">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Long_Radar-Camera_Pixel_Depth_Association_for_Depth_Completion_CVPR_2021_paper.html">Radar-Camera Pixel Depth Association for Depth Completion</a></th>
                    </tr>
                
                    <tr id="a6fed6b0c9c18aa02e5063bf6767b4272e38bb7c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a6fed6b0c9c18aa02e5063bf6767b4272e38bb7c">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Recurrent_Multi-View_Alignment_Network_for_Unsupervised_Surface_Registration_CVPR_2021_paper.html">Recurrent Multi-View Alignment Network for Unsupervised Surface Registration</a></th>
                    </tr>
                
                    <tr id="15dde86d1b8cd7531e228684c33812451cf750e0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15dde86d1b8cd7531e228684c33812451cf750e0">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Park_Learning_Dynamic_Network_Using_a_Reuse_Gate_Function_in_Semi-Supervised_CVPR_2021_paper.html">Learning Dynamic Network Using a Reuse Gate Function in Semi-Supervised Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="0453b7935e9a712a1c407a97b725756ed357f8cf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0453b7935e9a712a1c407a97b725756ed357f8cf">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Adaptive_Image_Transformer_for_One-Shot_Object_Detection_CVPR_2021_paper.html">Adaptive Image Transformer for One-Shot Object Detection</a></th>
                    </tr>
                
                    <tr id="00de838de267293fb8caf72b107359ec1ba1782b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00de838de267293fb8caf72b107359ec1ba1782b">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Action_Unit_Memory_Network_for_Weakly_Supervised_Temporal_Action_Localization_CVPR_2021_paper.html">Action Unit Memory Network for Weakly Supervised Temporal Action Localization</a></th>
                    </tr>
                
                    <tr id="8175a50b22b05ded12fe916e2271ccfc22fde60d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8175a50b22b05ded12fe916e2271ccfc22fde60d">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Self-Supervised_Video_Representation_Learning_by_Context_and_Motion_Decoupling_CVPR_2021_paper.html">Self-supervised Video Representation Learning by Context and Motion Decoupling</a></th>
                    </tr>
                
                    <tr id="0dc21823b956251f746415eef82aa6a77d42045e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0dc21823b956251f746415eef82aa6a77d42045e">18</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Salvador_Revamping_Cross-Modal_Recipe_Retrieval_With_Hierarchical_Transformers_and_Self-Supervised_Learning_CVPR_2021_paper.html">Revamping Cross-Modal Recipe Retrieval with Hierarchical Transformers and Self-supervised Learning</a></th>
                    </tr>
                
                    <tr id="1c214c00c5733ab368712c9ac7ec9f103b304a40">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1c214c00c5733ab368712c9ac7ec9f103b304a40">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Ancuti_NTIRE_2021_NonHomogeneous_Dehazing_Challenge_Report_CVPRW_2021_paper.html">NTIRE 2021 NonHomogeneous Dehazing Challenge Report</a></th>
                    </tr>
                
                    <tr id="652679b652ef98779a62e17a95701ac9030184f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/652679b652ef98779a62e17a95701ac9030184f2">18</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Cozzolino_SpoC_Spoofing_Camera_Fingerprints_CVPRW_2021_paper.html">SpoC: Spoofing Camera Fingerprints</a></th>
                    </tr>
                
                    <tr id="72d154853ccec18f35dc85dff570154b816379ca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/72d154853ccec18f35dc85dff570154b816379ca">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_iVPF_Numerical_Invertible_Volume_Preserving_Flow_for_Efficient_Lossless_Compression_CVPR_2021_paper.html">iVPF: Numerical Invertible Volume Preserving Flow for Efficient Lossless Compression</a></th>
                    </tr>
                
                    <tr id="7547d9c18a98479788986c2cdd898dd2bc01e696">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7547d9c18a98479788986c2cdd898dd2bc01e696">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Aygun_4D_Panoptic_LiDAR_Segmentation_CVPR_2021_paper.html">4D Panoptic LiDAR Segmentation</a></th>
                    </tr>
                
                    <tr id="71b424f88ad7a8060d1bf5b12f9894e4e96c0a00">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/71b424f88ad7a8060d1bf5b12f9894e4e96c0a00">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zou_Progressive_Temporal_Feature_Alignment_Network_for_Video_Inpainting_CVPR_2021_paper.html">Progressive Temporal Feature Alignment Network for Video Inpainting</a></th>
                    </tr>
                
                    <tr id="3cee6368f8825138636232d0d00c4b03ef1ae42b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3cee6368f8825138636232d0d00c4b03ef1ae42b">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_ECKPN_Explicit_Class_Knowledge_Propagation_Network_for_Transductive_Few-Shot_Learning_CVPR_2021_paper.html">ECKPN: Explicit Class Knowledge Propagation Network for Transductive Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="640667e929b2ce4fe4cce4f060c4e710c817365e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/640667e929b2ce4fe4cce4f060c4e710c817365e">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Deep_Two-View_Structure-From-Motion_Revisited_CVPR_2021_paper.html">Deep Two-View Structure-From-Motion Revisited</a></th>
                    </tr>
                
                    <tr id="89f3284d542eebaa7a06a724b014f6d73d6238dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/89f3284d542eebaa7a06a724b014f6d73d6238dd">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ma_Weakly_Supervised_Action_Selection_Learning_in_Video_CVPR_2021_paper.html">Weakly Supervised Action Selection Learning in Video</a></th>
                    </tr>
                
                    <tr id="80446df79c7d5d5c76dea68b5f8873e24efdd40e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/80446df79c7d5d5c76dea68b5f8873e24efdd40e">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Scene-Aware_Generative_Network_for_Human_Motion_Synthesis_CVPR_2021_paper.html">Scene-Aware Generative Network for Human Motion Synthesis</a></th>
                    </tr>
                
                    <tr id="08bb38957983f98b1729a0a8742a62c14b6b09df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/08bb38957983f98b1729a0a8742a62c14b6b09df">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dorkenwald_Stochastic_Image-to-Video_Synthesis_Using_cINNs_CVPR_2021_paper.html">Stochastic Image-to-Video Synthesis Using cINNs</a></th>
                    </tr>
                
                    <tr id="f8e6c012c722b1a7cdb52d6a17596486beb53af5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f8e6c012c722b1a7cdb52d6a17596486beb53af5">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ong_Protecting_Intellectual_Property_of_Generative_Adversarial_Networks_From_Ambiguity_Attacks_CVPR_2021_paper.html">Protecting Intellectual Property of Generative Adversarial Networks From Ambiguity Attacks</a></th>
                    </tr>
                
                    <tr id="cf29f0e9f66174ad274c6f6ef587c2f24c162358">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cf29f0e9f66174ad274c6f6ef587c2f24c162358">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_To_Restore_Hazy_Video_A_New_Real-World_Dataset_and_CVPR_2021_paper.html">Learning To Restore Hazy Video: A New Real-World Dataset and a New Method</a></th>
                    </tr>
                
                    <tr id="721379fe5d859f13442102a5681cf58952b5af14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/721379fe5d859f13442102a5681cf58952b5af14">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Abstract_Spatial-Temporal_Reasoning_via_Probabilistic_Abduction_and_Execution_CVPR_2021_paper.html">Abstract Spatial-Temporal Reasoning via Probabilistic Abduction and Execution</a></th>
                    </tr>
                
                    <tr id="0543cf559ce2a0704be669700ffc870414b6c9d7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0543cf559ce2a0704be669700ffc870414b6c9d7">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fischer_StickyPillars_Robust_and_Efficient_Feature_Matching_on_Point_Clouds_Using_CVPR_2021_paper.html">StickyPillars: Robust and Efficient Feature Matching on Point Clouds Using Graph Neural Networks</a></th>
                    </tr>
                
                    <tr id="3163e81db60346a669368372659eb773f3c21a27">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3163e81db60346a669368372659eb773f3c21a27">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Smoothing_the_Disentangled_Latent_Style_Space_for_Unsupervised_Image-to-Image_Translation_CVPR_2021_paper.html">Smoothing the Disentangled Latent Style Space for Unsupervised Image-to-Image Translation</a></th>
                    </tr>
                
                    <tr id="a9eb5c59763b5da7a9a0e1c5ef543b2f02630feb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a9eb5c59763b5da7a9a0e1c5ef543b2f02630feb">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Holynski_Animating_Pictures_With_Eulerian_Motion_Fields_CVPR_2021_paper.html">Animating Pictures With Eulerian Motion Fields</a></th>
                    </tr>
                
                    <tr id="c8a7014ab5013fe697592f78d9701d271874ae99">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c8a7014ab5013fe697592f78d9701d271874ae99">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Learning_Scene_Structure_Guidance_via_Cross-Task_Knowledge_Transfer_for_Single_CVPR_2021_paper.html">Learning Scene Structure Guidance via Cross-Task Knowledge Transfer for Single Depth Super-Resolution</a></th>
                    </tr>
                
                    <tr id="879705177ae248c76f0896ed8dd10aea07d0bc77">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/879705177ae248c76f0896ed8dd10aea07d0bc77">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kappel_High-Fidelity_Neural_Human_Motion_Transfer_From_Monocular_Video_CVPR_2021_paper.html">High-Fidelity Neural Human Motion Transfer From Monocular Video</a></th>
                    </tr>
                
                    <tr id="671602b93b66ba974d7cc02b74c59f8da178ffb7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/671602b93b66ba974d7cc02b74c59f8da178ffb7">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Duan_EventZoom_Learning_To_Denoise_and_Super_Resolve_Neuromorphic_Events_CVPR_2021_paper.html">EventZoom: Learning To Denoise and Super Resolve Neuromorphic Events</a></th>
                    </tr>
                
                    <tr id="0c13154582fe70b6b46184033610528119a60a22">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c13154582fe70b6b46184033610528119a60a22">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Weng_Unsupervised_Discovery_of_the_Long-Tail_in_Instance_Segmentation_Using_Hierarchical_CVPR_2021_paper.html">Unsupervised Discovery of the Long-Tail in Instance Segmentation Using Hierarchical Self-Supervision</a></th>
                    </tr>
                
                    <tr id="0b1c076a9b14677e2e8ea542bbbd9a435aa534e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0b1c076a9b14677e2e8ea542bbbd9a435aa534e1">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_Towards_Rolling_Shutter_Correction_and_Deblurring_in_Dynamic_Scenes_CVPR_2021_paper.html">Towards Rolling Shutter Correction and Deblurring in Dynamic Scenes</a></th>
                    </tr>
                
                    <tr id="cf59641715ecc3f785608160146cbfc12c0fd088">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cf59641715ecc3f785608160146cbfc12c0fd088">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kothari_Weakly-Supervised_Physically_Unconstrained_Gaze_Estimation_CVPR_2021_paper.html">Weakly-Supervised Physically Unconstrained Gaze Estimation</a></th>
                    </tr>
                
                    <tr id="1704633966c5400edc3e085102538c01d2eff9d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1704633966c5400edc3e085102538c01d2eff9d2">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Towards_Bridging_Event_Captioner_and_Sentence_Localizer_for_Weakly_Supervised_CVPR_2021_paper.html">Towards Bridging Event Captioner and Sentence Localizer for Weakly Supervised Dense Event Captioning</a></th>
                    </tr>
                
                    <tr id="581ba7d93349ac0e1eec74385160205bc1accb8a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/581ba7d93349ac0e1eec74385160205bc1accb8a">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ye_DeepTag_An_Unsupervised_Deep_Learning_Method_for_Motion_Tracking_on_CVPR_2021_paper.html">DeepTag: An Unsupervised Deep Learning Method for Motion Tracking on Cardiac Tagging Magnetic Resonance Images</a></th>
                    </tr>
                
                    <tr id="a9471043cef09ad7dc5b6605d8ce1f4b8f40183c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a9471043cef09ad7dc5b6605d8ce1f4b8f40183c">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guan_Bilevel_Online_Adaptation_for_Out-of-Domain_Human_Mesh_Reconstruction_CVPR_2021_paper.html">Bilevel Online Adaptation for Out-of-Domain Human Mesh Reconstruction</a></th>
                    </tr>
                
                    <tr id="20c05a8e3648e148f6919918225c90297b227938">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/20c05a8e3648e148f6919918225c90297b227938">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Semantic_Scene_Completion_via_Integrating_Instances_and_Scene_In-the-Loop_CVPR_2021_paper.html">Semantic Scene Completion via Integrating Instances and Scene In-the-Loop</a></th>
                    </tr>
                
                    <tr id="1d6467a45f76e881531725fe1c9fc1b45ab5b90c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d6467a45f76e881531725fe1c9fc1b45ab5b90c">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Su_BCNet_Searching_for_Network_Width_With_Bilaterally_Coupled_Network_CVPR_2021_paper.html">BCNet: Searching for Network Width With Bilaterally Coupled Network</a></th>
                    </tr>
                
                    <tr id="401585e0c8d512cad4866cec60a4f9bc9b5cbfb8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/401585e0c8d512cad4866cec60a4f9bc9b5cbfb8">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Martinez_Permute_Quantize_and_Fine-Tune_Efficient_Compression_of_Neural_Networks_CVPR_2021_paper.html">Permute, Quantize, and Fine-Tune: Efficient Compression of Neural Networks</a></th>
                    </tr>
                
                    <tr id="f2b9fca4cab776dd36a696a78eb2e912cca15189">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f2b9fca4cab776dd36a696a78eb2e912cca15189">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sengupta_Probabilistic_3D_Human_Shape_and_Pose_Estimation_From_Multiple_Unconstrained_CVPR_2021_paper.html">Probabilistic 3D Human Shape and Pose Estimation From Multiple Unconstrained Images in the Wild</a></th>
                    </tr>
                
                    <tr id="95c466170f60cc5a652b51ec23814320666a4f73">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/95c466170f60cc5a652b51ec23814320666a4f73">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Varol_Read_and_Attend_Temporal_Localisation_in_Sign_Language_Videos_CVPR_2021_paper.html">Read and Attend: Temporal Localisation in Sign Language Videos</a></th>
                    </tr>
                
                    <tr id="047942e051747d02ffdc167de2d723ce3368e256">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/047942e051747d02ffdc167de2d723ce3368e256">17</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_MOST_A_Multi-Oriented_Scene_Text_Detector_With_Localization_Refinement_CVPR_2021_paper.html">MOST: A Multi-Oriented Scene Text Detector with Localization Refinement</a></th>
                    </tr>
                
                    <tr id="d81a08f4e71b191aff23255a50bd73c75c21a8fe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d81a08f4e71b191aff23255a50bd73c75c21a8fe">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Ignatov_Fast_Camera_Image_Denoising_on_Mobile_GPUs_With_Deep_Learning_CVPRW_2021_paper.html">Fast Camera Image Denoising on Mobile GPUs With Deep Learning, Mobile AI 2021 Challenge: Report</a></th>
                    </tr>
                
                    <tr id="97c4233abd176227c4886ea517d1ac0773528dfe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/97c4233abd176227c4886ea517d1ac0773528dfe">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Ghosh_Contrastive_Learning_Improves_Model_Robustness_Under_Label_Noise_CVPRW_2021_paper.html">Contrastive Learning Improves Model Robustness Under Label Noise</a></th>
                    </tr>
                
                    <tr id="96565aaa249ec032f63eb9a8a795a4e321764a9f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96565aaa249ec032f63eb9a8a795a4e321764a9f">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Nguyen_Graph-Based_Person_Signature_for_Person_Re-Identifications_CVPRW_2021_paper.html">Graph-Based Person Signature for Person Re-Identifications</a></th>
                    </tr>
                
                    <tr id="3dfd38e58ebe8a83a338347294bc13a89b6459fc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3dfd38e58ebe8a83a338347294bc13a89b6459fc">17</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Liu_City-Scale_Multi-Camera_Vehicle_Tracking_Guided_by_Crossroad_Zones_CVPRW_2021_paper.html">City-Scale Multi-Camera Vehicle Tracking Guided by Crossroad Zones</a></th>
                    </tr>
                
                    <tr id="11f70483453f49fc3812a55faa3c13e993c8170c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/11f70483453f49fc3812a55faa3c13e993c8170c">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Wide-Depth-Range_6D_Object_Pose_Estimation_in_Space_CVPR_2021_paper.html">Wide-Depth-Range 6D Object Pose Estimation in Space</a></th>
                    </tr>
                
                    <tr id="1a8649c950e8f2208ed1ad965fa8f9c918d41460">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a8649c950e8f2208ed1ad965fa8f9c918d41460">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Scene-Intuitive_Agent_for_Remote_Embodied_Visual_Grounding_CVPR_2021_paper.html">Scene-Intuitive Agent for Remote Embodied Visual Grounding</a></th>
                    </tr>
                
                    <tr id="8aec21de38661bc10764242c0772310ffaa9c6cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8aec21de38661bc10764242c0772310ffaa9c6cd">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Zero-Shot_Instance_Segmentation_CVPR_2021_paper.html">Zero-Shot Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="bf992dd669f29adbee9a3919e33db7f580cc3996">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bf992dd669f29adbee9a3919e33db7f580cc3996">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pandey_Generalization_on_Unseen_Domains_via_Inference-Time_Label-Preserving_Target_Projections_CVPR_2021_paper.html">Generalization on Unseen Domains via Inference-Time Label-Preserving Target Projections</a></th>
                    </tr>
                
                    <tr id="0b74fc8ad52dd440ace2f3142b922e54a3cf14f4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0b74fc8ad52dd440ace2f3142b922e54a3cf14f4">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Labbe_Single-View_Robot_Pose_and_Joint_Angle_Estimation_via_Render__CVPR_2021_paper.html">Single-View Robot Pose and Joint Angle Estimation via Render &amp; Compare</a></th>
                    </tr>
                
                    <tr id="12e3bebd96651299b14ec398142534f3cba6df61">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/12e3bebd96651299b14ec398142534f3cba6df61">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Self-Point-Flow_Self-Supervised_Scene_Flow_Estimation_From_Point_Clouds_With_Optimal_CVPR_2021_paper.html">Self-Point-Flow: Self-Supervised Scene Flow Estimation From Point Clouds With Optimal Transport and Random Walk</a></th>
                    </tr>
                
                    <tr id="5484a3810dce9d8fc9fba554812032a69acb9362">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5484a3810dce9d8fc9fba554812032a69acb9362">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Structure-Aware_Face_Clustering_on_a_Large-Scale_Graph_With_107_Nodes_CVPR_2021_paper.html">Structure-Aware Face Clustering on a Large-Scale Graph With 107 Nodes</a></th>
                    </tr>
                
                    <tr id="2aea4926a6feee05c79699256752d09d73aba759">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2aea4926a6feee05c79699256752d09d73aba759">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Suin_Gated_Spatio-Temporal_Attention-Guided_Video_Deblurring_CVPR_2021_paper.html">Gated Spatio-Temporal Attention-Guided Video Deblurring</a></th>
                    </tr>
                
                    <tr id="1af5001d6274fdc61e5fbd852312bd141dda7f3b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1af5001d6274fdc61e5fbd852312bd141dda7f3b">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Rethinking_Text_Segmentation_A_Novel_Dataset_and_a_Text-Specific_Refinement_CVPR_2021_paper.html">Rethinking Text Segmentation: A Novel Dataset and a Text-Specific Refinement Approach</a></th>
                    </tr>
                
                    <tr id="2abe258bd0f36d521139def37138f168b03dd8f3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2abe258bd0f36d521139def37138f168b03dd8f3">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Large-Scale_Localization_Datasets_in_Crowded_Indoor_Spaces_CVPR_2021_paper.html">Large-Scale Localization Datasets in Crowded Indoor Spaces</a></th>
                    </tr>
                
                    <tr id="e1615abe79b2c7974a60d92e906584745b4612f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e1615abe79b2c7974a60d92e906584745b4612f5">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Miao_PVGNet_A_Bottom-Up_One-Stage_3D_Object_Detector_With_Integrated_Multi-Level_CVPR_2021_paper.html">PVGNet: A Bottom-Up One-Stage 3D Object Detector With Integrated Multi-Level Features</a></th>
                    </tr>
                
                    <tr id="3932bae8c584f2a8489b5e835ceb4b6d1a63ba7e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3932bae8c584f2a8489b5e835ceb4b6d1a63ba7e">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_ChallenCap_Monocular_3D_Capture_of_Challenging_Human_Performances_Using_Multi-Modal_CVPR_2021_paper.html">ChallenCap: Monocular 3D Capture of Challenging Human Performances Using Multi-Modal References</a></th>
                    </tr>
                
                    <tr id="bb81df87d772289f9dac1d68efcdf33ce1ce73e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bb81df87d772289f9dac1d68efcdf33ce1ce73e1">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Graph-Based_High-Order_Relation_Modeling_for_Long-Term_Action_Recognition_CVPR_2021_paper.html">Graph-Based High-Order Relation Modeling for Long-Term Action Recognition</a></th>
                    </tr>
                
                    <tr id="4409e504d895e9ae1d2324cd133aa0763fdf520b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4409e504d895e9ae1d2324cd133aa0763fdf520b">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Savarese_Information-Theoretic_Segmentation_by_Inpainting_Error_Maximization_CVPR_2021_paper.html">Information-Theoretic Segmentation by Inpainting Error Maximization</a></th>
                    </tr>
                
                    <tr id="15afc9c15d91091fad1522265578b2cb92f51b6f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15afc9c15d91091fad1522265578b2cb92f51b6f">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_From_Semantic_Categories_to_Fixations_A_Novel_Weakly-Supervised_Visual-Auditory_Saliency_CVPR_2021_paper.html">From Semantic Categories to Fixations: A Novel Weakly-Supervised Visual-Auditory Saliency Detection Approach</a></th>
                    </tr>
                
                    <tr id="057acb03527b8cae1f5a7ccd200d09dd8bdc5a86">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/057acb03527b8cae1f5a7ccd200d09dd8bdc5a86">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Multi-View_Multi-Person_3D_Pose_Estimation_With_Plane_Sweep_Stereo_CVPR_2021_paper.html">Multi-View Multi-Person 3D Pose Estimation With Plane Sweep Stereo</a></th>
                    </tr>
                
                    <tr id="016596ac909d0230f78e9173d43ccc9937246b30">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/016596ac909d0230f78e9173d43ccc9937246b30">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_Robust_Instance_Segmentation_Through_Reasoning_About_Multi-Object_Occlusion_CVPR_2021_paper.html">Robust Instance Segmentation Through Reasoning About Multi-Object Occlusion</a></th>
                    </tr>
                
                    <tr id="2a30dba0f64a174771056da71c4c05bfa9bf722f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2a30dba0f64a174771056da71c4c05bfa9bf722f">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qi_Multi-Scale_Aligned_Distillation_for_Low-Resolution_Detection_CVPR_2021_paper.html">Multi-Scale Aligned Distillation for Low-Resolution Detection</a></th>
                    </tr>
                
                    <tr id="a7d6d38f7bfe847318af8e9b2e5e68f044671941">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a7d6d38f7bfe847318af8e9b2e5e68f044671941">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_SetVAE_Learning_Hierarchical_Composition_for_Generative_Modeling_of_Set-Structured_Data_CVPR_2021_paper.html">SetVAE: Learning Hierarchical Composition for Generative Modeling of Set-Structured Data</a></th>
                    </tr>
                
                    <tr id="c51f8aa953b541d2ee5049c2b673f498078d096a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c51f8aa953b541d2ee5049c2b673f498078d096a">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gong_AlphaMatch_Improving_Consistency_for_Semi-Supervised_Learning_With_Alpha-Divergence_CVPR_2021_paper.html">AlphaMatch: Improving Consistency for Semi-Supervised Learning With Alpha-Divergence</a></th>
                    </tr>
                
                    <tr id="a6614e76f9862950a7cf62eb1bc1d206a6a09742">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a6614e76f9862950a7cf62eb1bc1d206a6a09742">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ren_Flow_Guided_Transformable_Bottleneck_Networks_for_Motion_Retargeting_CVPR_2021_paper.html">Flow Guided Transformable Bottleneck Networks for Motion Retargeting</a></th>
                    </tr>
                
                    <tr id="3c812b969d0fef6bd265520a5266604eb7124227">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3c812b969d0fef6bd265520a5266604eb7124227">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nguyen_Clusformer_A_Transformer_Based_Clustering_Approach_to_Unsupervised_Large-Scale_Face_CVPR_2021_paper.html">Clusformer: A Transformer Based Clustering Approach to Unsupervised Large-Scale Face and Visual Landmark Recognition</a></th>
                    </tr>
                
                    <tr id="5eb7db5ed90fe01fa0d6b3ff76628e7ffd0a013d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5eb7db5ed90fe01fa0d6b3ff76628e7ffd0a013d">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_HourNAS_Extremely_Fast_Neural_Architecture_Search_Through_an_Hourglass_Lens_CVPR_2021_paper.html">HourNAS: Extremely Fast Neural Architecture Search Through an Hourglass Lens</a></th>
                    </tr>
                
                    <tr id="60fc2141c71f839d745ffdd0ae7305d3857602cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/60fc2141c71f839d745ffdd0ae7305d3857602cc">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Alliegro_Denoise_and_Contrast_for_Category_Agnostic_Shape_Completion_CVPR_2021_paper.html">Denoise and Contrast for Category Agnostic Shape Completion</a></th>
                    </tr>
                
                    <tr id="ae746050aa6c36eae7f26243c617d70bd4b45d93">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae746050aa6c36eae7f26243c617d70bd4b45d93">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Rakotosaona_Learning_Delaunay_Surface_Elements_for_Mesh_Reconstruction_CVPR_2021_paper.html">Learning Delaunay Surface Elements for Mesh Reconstruction</a></th>
                    </tr>
                
                    <tr id="6adb1518f0332e13caaffa5ac5c28dfdd56d4ac4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6adb1518f0332e13caaffa5ac5c28dfdd56d4ac4">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kervadec_How_Transferable_Are_Reasoning_Patterns_in_VQA_CVPR_2021_paper.html">How Transferable Are Reasoning Patterns in VQA?</a></th>
                    </tr>
                
                    <tr id="f7679b408a947132f8a00fb6fd6f667b1a18a4cf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7679b408a947132f8a00fb6fd6f667b1a18a4cf">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Light_Field_Super-Resolution_With_Zero-Shot_Learning_CVPR_2021_paper.html">Light Field Super-Resolution With Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="9731cdbefd4fceb9782e0d93970965964c1b498f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9731cdbefd4fceb9782e0d93970965964c1b498f">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_iMiGUE_An_Identity-Free_Video_Dataset_for_Micro-Gesture_Understanding_and_Emotion_CVPR_2021_paper.html">iMiGUE: An Identity-Free Video Dataset for Micro-Gesture Understanding and Emotion Analysis</a></th>
                    </tr>
                
                    <tr id="5b47307a071a3f7da2441edb50fec25c9dfba1bb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b47307a071a3f7da2441edb50fec25c9dfba1bb">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Monocular_3D_Multi-Person_Pose_Estimation_by_Integrating_Top-Down_and_Bottom-Up_CVPR_2021_paper.html">Monocular 3D Multi-Person Pose Estimation by Integrating Top-Down and Bottom-Up Networks</a></th>
                    </tr>
                
                    <tr id="7cce15b7ac80d5e3e574323367a5cf7bbafd2313">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7cce15b7ac80d5e3e574323367a5cf7bbafd2313">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jia_IoU_Attack_Towards_Temporally_Coherent_Black-Box_Adversarial_Attack_for_Visual_CVPR_2021_paper.html">IoU Attack: Towards Temporally Coherent Black-Box Adversarial Attack for Visual Object Tracking</a></th>
                    </tr>
                
                    <tr id="53ae88c63ec6581b49d9a358e612f70935b552cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/53ae88c63ec6581b49d9a358e612f70935b552cc">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pan_Dual_Pixel_Exploration_Simultaneous_Depth_Estimation_and_Image_Restoration_CVPR_2021_paper.html">Dual Pixel Exploration: Simultaneous Depth Estimation and Image Restoration</a></th>
                    </tr>
                
                    <tr id="fc10e220e7258e54147b08ee04511f61aeedcd1d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc10e220e7258e54147b08ee04511f61aeedcd1d">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nguyen_Dictionary-Guided_Scene_Text_Recognition_CVPR_2021_paper.html">Dictionary-Guided Scene Text Recognition</a></th>
                    </tr>
                
                    <tr id="9b326de7574be398cb7a7a73349af19df3f3f0ea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9b326de7574be398cb7a7a73349af19df3f3f0ea">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Benny_Scale-Localized_Abstract_Reasoning_CVPR_2021_paper.html">Scale-Localized Abstract Reasoning</a></th>
                    </tr>
                
                    <tr id="0d5343900e19e04f5ee6c49c83eafaaf623597b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0d5343900e19e04f5ee6c49c83eafaaf623597b5">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Inferring_CAD_Modeling_Sequences_Using_Zone_Graphs_CVPR_2021_paper.html">Inferring CAD Modeling Sequences Using Zone Graphs</a></th>
                    </tr>
                
                    <tr id="4e80ad837eea408817b64c81129935aec6300db7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4e80ad837eea408817b64c81129935aec6300db7">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Dynamic_Transfer_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.html">Dynamic Transfer for Multi-Source Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="3a34836518214894344ea78edb9c91b831854910">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3a34836518214894344ea78edb9c91b831854910">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_FaceInpainter_High_Fidelity_Face_Adaptation_to_Heterogeneous_Domains_CVPR_2021_paper.html">FaceInpainter: High Fidelity Face Adaptation to Heterogeneous Domains</a></th>
                    </tr>
                
                    <tr id="3e7da84d258bbc830626a436e8f5f42ee64238a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3e7da84d258bbc830626a436e8f5f42ee64238a5">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Camera_Pose_Matters_Improving_Depth_Prediction_by_Mitigating_Pose_Distribution_CVPR_2021_paper.html">Camera Pose Matters: Improving Depth Prediction by Mitigating Pose Distribution Bias</a></th>
                    </tr>
                
                    <tr id="b7a1be45de035a228e2967fde3b166e7a1cc2b68">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b7a1be45de035a228e2967fde3b166e7a1cc2b68">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/She_Hierarchical_Layout-Aware_Graph_Convolutional_Network_for_Unified_Aesthetics_Assessment_CVPR_2021_paper.html">Hierarchical Layout-Aware Graph Convolutional Network for Unified Aesthetics Assessment</a></th>
                    </tr>
                
                    <tr id="cbf0949cecc70170b217fb1c43d821d37ecffc1a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cbf0949cecc70170b217fb1c43d821d37ecffc1a">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zou_Learning_To_Reconstruct_High_Speed_and_High_Dynamic_Range_Videos_CVPR_2021_paper.html">Learning To Reconstruct High Speed and High Dynamic Range Videos From Events</a></th>
                    </tr>
                
                    <tr id="c2b9de7b90cf5c2cbf36fbc29566d0e7b94946ee">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c2b9de7b90cf5c2cbf36fbc29566d0e7b94946ee">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Towards_Unified_Surgical_Skill_Assessment_CVPR_2021_paper.html">Towards Unified Surgical Skill Assessment</a></th>
                    </tr>
                
                    <tr id="a90b7fb45d1155e25f9967540fe1bd9ec555faf3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a90b7fb45d1155e25f9967540fe1bd9ec555faf3">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Learning_Probabilistic_Ordinal_Embeddings_for_Uncertainty-Aware_Regression_CVPR_2021_paper.html">Learning Probabilistic Ordinal Embeddings for Uncertainty-Aware Regression</a></th>
                    </tr>
                
                    <tr id="41eada435ebd11f379f2a148c70a1e2ece6da739">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/41eada435ebd11f379f2a148c70a1e2ece6da739">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pautrat_SOLD2_Self-Supervised_Occlusion-Aware_Line_Description_and_Detection_CVPR_2021_paper.html">SOLD2: Self-Supervised Occlusion-Aware Line Description and Detection</a></th>
                    </tr>
                
                    <tr id="8814a6b2c5957f0fa3d2c061436488fd67907937">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8814a6b2c5957f0fa3d2c061436488fd67907937">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jiang_Robust_Reference-Based_Super-Resolution_via_C2-Matching_CVPR_2021_paper.html">Robust Reference-based Super-Resolution via C2-Matching</a></th>
                    </tr>
                
                    <tr id="0f2b71606b2eeab9e9b521abfce0e72f680c3861">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0f2b71606b2eeab9e9b521abfce0e72f680c3861">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dai_SPSG_Self-Supervised_Photometric_Scene_Generation_From_RGB-D_Scans_CVPR_2021_paper.html">SPSG: Self-Supervised Photometric Scene Generation from RGB-D Scans</a></th>
                    </tr>
                
                    <tr id="5427b5e3d2b8134b82f5ba51c275b35eba9bbcca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5427b5e3d2b8134b82f5ba51c275b35eba9bbcca">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wolf_DeFlow_Learning_Complex_Image_Degradations_From_Unpaired_Data_With_Conditional_CVPR_2021_paper.html">DeFlow: Learning Complex Image Degradations from Unpaired Data with Conditional Flows</a></th>
                    </tr>
                
                    <tr id="26ef01a65f45f3b3b53c286d482e487953174ea4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26ef01a65f45f3b3b53c286d482e487953174ea4">16</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Data-Free_Knowledge_Distillation_for_Image_Super-Resolution_CVPR_2021_paper.html">Data-Free Knowledge Distillation For Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="77743f8cf6d617dccd147962696d3ef109bd4965">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/77743f8cf6d617dccd147962696d3ef109bd4965">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Luo_EBSR_Feature_Enhanced_Burst_Super-Resolution_With_Deformable_Alignment_CVPRW_2021_paper.html">EBSR: Feature Enhanced Burst Super-Resolution With Deformable Alignment</a></th>
                    </tr>
                
                    <tr id="bbec899e42816ccde1ce506ab953b4eb7a236203">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bbec899e42816ccde1ce506ab953b4eb7a236203">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Fu_DW-GAN_A_Discrete_Wavelet_Transform_GAN_for_NonHomogeneous_Dehazing_CVPRW_2021_paper.html">DW-GAN: A Discrete Wavelet Transform GAN for NonHomogeneous Dehazing</a></th>
                    </tr>
                
                    <tr id="00259dc6de64be80b1daf0d209e1234812894987">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00259dc6de64be80b1daf0d209e1234812894987">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AUVi/html/Lei_Micro-Expression_Recognition_Based_on_Facial_Graph_Representation_Learning_and_Facial_CVPRW_2021_paper.html">Micro-Expression Recognition Based on Facial Graph Representation Learning and Facial Action Unit Fusion</a></th>
                    </tr>
                
                    <tr id="47f306b7c3d6d668c41f6f58f7c7f81e6e89ff2f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47f306b7c3d6d668c41f6f58f7c7f81e6e89ff2f">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Ayazoglu_Extremely_Lightweight_Quantization_Robust_Real-Time_Single-Image_Super_Resolution_for_Mobile_CVPRW_2021_paper.html">Extremely Lightweight Quantization Robust Real-Time Single-Image Super Resolution for Mobile Devices</a></th>
                    </tr>
                
                    <tr id="7c98f37e86d4c4a685bce5c932dbaee736edbb50">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c98f37e86d4c4a685bce5c932dbaee736edbb50">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Ben-Ari_TAEN_Temporal_Aware_Embedding_Network_for_Few-Shot_Action_Recognition_CVPRW_2021_paper.html">TAEN: Temporal Aware Embedding Network for Few-Shot Action Recognition</a></th>
                    </tr>
                
                    <tr id="e997555d7a3ab88b26b3cd452cc8b1ffa8fde9c9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e997555d7a3ab88b26b3cd452cc8b1ffa8fde9c9">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Hao_Towards_Fair_Federated_Learning_With_Zero-Shot_Data_Augmentation_CVPRW_2021_paper.html">Towards Fair Federated Learning With Zero-Shot Data Augmentation</a></th>
                    </tr>
                
                    <tr id="b2de5bd44ed8eb9cfd46d2e7e5a0fff61e68cfee">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b2de5bd44ed8eb9cfd46d2e7e5a0fff61e68cfee">16</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Bai_Connecting_Language_and_Vision_for_Natural_Language-Based_Vehicle_Retrieval_CVPRW_2021_paper.html">Connecting Language and Vision for Natural Language-Based Vehicle Retrieval</a></th>
                    </tr>
                
                    <tr id="c21aec35629da69e6576aabbf2b224400276887e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c21aec35629da69e6576aabbf2b224400276887e">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fang_Dual_Attention_Guided_Gaze_Target_Detection_in_the_Wild_CVPR_2021_paper.html">Dual Attention Guided Gaze Target Detection in the Wild</a></th>
                    </tr>
                
                    <tr id="2b3dca41ee292523fd8cc42a0a9ff067a203fbfa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b3dca41ee292523fd8cc42a0a9ff067a203fbfa">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hui_Learning_the_Non-Differentiable_Optimization_for_Blind_Super-Resolution_CVPR_2021_paper.html">Learning the Non-Differentiable Optimization for Blind Super-Resolution</a></th>
                    </tr>
                
                    <tr id="750039db28d96422f0f70d337d717318837a9639">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/750039db28d96422f0f70d337d717318837a9639">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/R_Monocular_Reconstruction_of_Neural_Face_Reflectance_Fields_CVPR_2021_paper.html">Monocular Reconstruction of Neural Face Reflectance Fields</a></th>
                    </tr>
                
                    <tr id="026063cca5997b86044df92e718ef634b512f22e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/026063cca5997b86044df92e718ef634b512f22e">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kahatapitiya_Coarse-Fine_Networks_for_Temporal_Activity_Detection_in_Videos_CVPR_2021_paper.html">Coarse-Fine Networks for Temporal Activity Detection in Videos</a></th>
                    </tr>
                
                    <tr id="3f4fcc0bdd2a978a45d97183c04c00429330a9c5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f4fcc0bdd2a978a45d97183c04c00429330a9c5">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mackowiak_Generative_Classifiers_as_a_Basis_for_Trustworthy_Image_Classification_CVPR_2021_paper.html">Generative Classifiers as a Basis for Trustworthy Image Classification</a></th>
                    </tr>
                
                    <tr id="f73f606fdcb52fab4c4c0316f5729cc240f89f95">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f73f606fdcb52fab4c4c0316f5729cc240f89f95">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gong_Cluster_Split_Fuse_and_Update_Meta-Learning_for_Open_Compound_Domain_CVPR_2021_paper.html">Cluster, Split, Fuse, and Update: Meta-Learning for Open Compound Domain Adaptive Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="8a8324928d849b4f5e2887eda75221258ad94a26">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8a8324928d849b4f5e2887eda75221258ad94a26">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_NPAS_A_Compiler-Aware_Framework_of_Unified_Network_Pruning_and_Architecture_CVPR_2021_paper.html">NPAS: A Compiler-Aware Framework of Unified Network Pruning and Architecture Search for Beyond Real-Time Mobile Acceleration</a></th>
                    </tr>
                
                    <tr id="e904dda4c50ce84c6311f722f96452ad8bd4c6e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e904dda4c50ce84c6311f722f96452ad8bd4c6e1">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Single_Image_Reflection_Removal_With_Absorption_Effect_CVPR_2021_paper.html">Single Image Reflection Removal With Absorption Effect</a></th>
                    </tr>
                
                    <tr id="31d737977efb98471dc2ff32a619b2b1b25b3d12">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/31d737977efb98471dc2ff32a619b2b1b25b3d12">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Ranking_Neural_Checkpoints_CVPR_2021_paper.html">Ranking Neural Checkpoints</a></th>
                    </tr>
                
                    <tr id="1838c5b86cf3881d9739b6d827a185b496ed5949">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1838c5b86cf3881d9739b6d827a185b496ed5949">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Marriott_A_3D_GAN_for_Improved_Large-Pose_Facial_Recognition_CVPR_2021_paper.html">A 3D GAN for Improved Large-Pose Facial Recognition</a></th>
                    </tr>
                
                    <tr id="38f51d123edcd8b48391ad3f961a22e464d83681">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38f51d123edcd8b48391ad3f961a22e464d83681">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ni_Controlling_the_Rain_From_Removal_to_Rendering_CVPR_2021_paper.html">Controlling the Rain: From Removal to Rendering</a></th>
                    </tr>
                
                    <tr id="1ecb9c2d3cb7d0061db290b9e89843c2ba0ae3b8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ecb9c2d3cb7d0061db290b9e89843c2ba0ae3b8">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Deep_Video_Matting_via_Spatio-Temporal_Alignment_and_Aggregation_CVPR_2021_paper.html">Deep Video Matting via Spatio-Temporal Alignment and Aggregation</a></th>
                    </tr>
                
                    <tr id="8ebbfb708ed3671b756d5b54993c2d1f566facd1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8ebbfb708ed3671b756d5b54993c2d1f566facd1">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shahbazi_Efficient_Conditional_GAN_Transfer_With_Knowledge_Propagation_Across_Classes_CVPR_2021_paper.html">Efficient Conditional GAN Transfer With Knowledge Propagation Across Classes</a></th>
                    </tr>
                
                    <tr id="8c38368db31310959e44a2cc8f5be20854538fd0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c38368db31310959e44a2cc8f5be20854538fd0">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Rampini_Universal_Spectral_Adversarial_Attacks_for_Deformable_Shapes_CVPR_2021_paper.html">Universal Spectral Adversarial Attacks for Deformable Shapes</a></th>
                    </tr>
                
                    <tr id="9c0b7bdb8d81c31063aa805556167a35767ec5d7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c0b7bdb8d81c31063aa805556167a35767ec5d7">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yuan_Perception_Matters_Detecting_Perception_Failures_of_VQA_Models_Using_Metamorphic_CVPR_2021_paper.html">Perception Matters: Detecting Perception Failures of VQA Models Using Metamorphic Testing</a></th>
                    </tr>
                
                    <tr id="7a94617dac91e51464ffa158e2f83c06b8b67eb0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a94617dac91e51464ffa158e2f83c06b8b67eb0">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Unsupervised_Part_Segmentation_Through_Disentangling_Appearance_and_Shape_CVPR_2021_paper.html">Unsupervised Part Segmentation Through Disentangling Appearance and Shape</a></th>
                    </tr>
                
                    <tr id="313d1b8328d215b103dba1052dd670c70e18c660">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/313d1b8328d215b103dba1052dd670c70e18c660">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Quach_DyGLIP_A_Dynamic_Graph_Model_With_Link_Prediction_for_Accurate_CVPR_2021_paper.html">DyGLIP: A Dynamic Graph Model With Link Prediction for Accurate Multi-Camera Multiple Object Tracking</a></th>
                    </tr>
                
                    <tr id="18690ff821f98d2e5890544adbb91d32683054ba">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/18690ff821f98d2e5890544adbb91d32683054ba">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_DeFLOCNet_Deep_Image_Editing_via_Flexible_Low-Level_Controls_CVPR_2021_paper.html">DeFLOCNet: Deep Image Editing via Flexible Low-Level Controls</a></th>
                    </tr>
                
                    <tr id="926793511fa1af1f3d42dc8a7c3d87df1acad474">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/926793511fa1af1f3d42dc8a7c3d87df1acad474">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Representing_Videos_As_Discriminative_Sub-Graphs_for_Action_Recognition_CVPR_2021_paper.html">Representing Videos As Discriminative Sub-Graphs for Action Recognition</a></th>
                    </tr>
                
                    <tr id="729bdc83d693a2db56af049d1f881e053cd27c9e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/729bdc83d693a2db56af049d1f881e053cd27c9e">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Layer-Wise_Searching_for_1-Bit_Detectors_CVPR_2021_paper.html">Layer-Wise Searching for 1-Bit Detectors</a></th>
                    </tr>
                
                    <tr id="c39b25dae7f55bde120560ce850d5d92d4eed0f4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c39b25dae7f55bde120560ce850d5d92d4eed0f4">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/He_Partial_Person_Re-Identification_With_Part-Part_Correspondence_Learning_CVPR_2021_paper.html">Partial Person Re-Identification With Part-Part Correspondence Learning</a></th>
                    </tr>
                
                    <tr id="2c0ccf919d5347b87677e7a16a3ba5e555f51710">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c0ccf919d5347b87677e7a16a3ba5e555f51710">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qiao_Uncertainty-Guided_Model_Generalization_to_Unseen_Domains_CVPR_2021_paper.html">Uncertainty-Guided Model Generalization to Unseen Domains</a></th>
                    </tr>
                
                    <tr id="8dbd1a0e1720beaee0091a8db78f998acca56140">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8dbd1a0e1720beaee0091a8db78f998acca56140">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Noise-Resistant_Deep_Metric_Learning_With_Ranking-Based_Instance_Selection_CVPR_2021_paper.html">Noise-Resistant Deep Metric Learning With Ranking-Based Instance Selection</a></th>
                    </tr>
                
                    <tr id="3f16e45cdf761273655d8698794422f50dcbd5a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f16e45cdf761273655d8698794422f50dcbd5a6">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Learning_To_Warp_for_Style_Transfer_CVPR_2021_paper.html">Learning To Warp for Style Transfer</a></th>
                    </tr>
                
                    <tr id="446030903e114f9578bbf069925ff3e4f6606424">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/446030903e114f9578bbf069925ff3e4f6606424">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_WOAD_Weakly_Supervised_Online_Action_Detection_in_Untrimmed_Videos_CVPR_2021_paper.html">WOAD: Weakly Supervised Online Action Detection in Untrimmed Videos</a></th>
                    </tr>
                
                    <tr id="0c078c661331b41a539a5dbdec653f6686963d74">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c078c661331b41a539a5dbdec653f6686963d74">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hui_Collaborative_Spatial-Temporal_Modeling_for_Language-Queried_Video_Actor_Segmentation_CVPR_2021_paper.html">Collaborative Spatial-Temporal Modeling for Language-Queried Video Actor Segmentation</a></th>
                    </tr>
                
                    <tr id="af66fd525fbad5d9024e9fe424f8e6e717c9f947">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/af66fd525fbad5d9024e9fe424f8e6e717c9f947">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Where_and_What_Examining_Interpretable_Disentangled_Representations_CVPR_2021_paper.html">Where and What? Examining Interpretable Disentangled Representations</a></th>
                    </tr>
                
                    <tr id="9c51638041fd715b0a0d8963404b2c20b94ed879">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c51638041fd715b0a0d8963404b2c20b94ed879">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_a_Self-Expressive_Network_for_Subspace_Clustering_CVPR_2021_paper.html">Learning a Self-Expressive Network for Subspace Clustering</a></th>
                    </tr>
                
                    <tr id="3f866fad2afa3fd304e9f101e5f38fbe386d36d1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f866fad2afa3fd304e9f101e5f38fbe386d36d1">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_DSC-PoseNet_Learning_6DoF_Object_Pose_Estimation_via_Dual-Scale_Consistency_CVPR_2021_paper.html">DSC-PoseNet: Learning 6DoF Object Pose Estimation via Dual-Scale Consistency</a></th>
                    </tr>
                
                    <tr id="17dfc825e69ca6dc6d5845b54070681981405c8a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/17dfc825e69ca6dc6d5845b54070681981405c8a">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Understanding_the_Robustness_of_Skeleton-Based_Action_Recognition_Under_Adversarial_Attack_CVPR_2021_paper.html">Understanding the Robustness of Skeleton-Based Action Recognition Under Adversarial Attack</a></th>
                    </tr>
                
                    <tr id="c157c4021af0025e5450350bb84901578d2f8ad7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c157c4021af0025e5450350bb84901578d2f8ad7">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Sketch2Model_View-Aware_3D_Modeling_From_Single_Free-Hand_Sketches_CVPR_2021_paper.html">Sketch2Model: View-Aware 3D Modeling From Single Free-Hand Sketches</a></th>
                    </tr>
                
                    <tr id="13177ad90ca882efbf0fe45a1a6f66ccdd3d61c3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/13177ad90ca882efbf0fe45a1a6f66ccdd3d61c3">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Weakly-Supervised_Instance_Segmentation_via_Class-Agnostic_Learning_With_Salient_Images_CVPR_2021_paper.html">Weakly-Supervised Instance Segmentation via Class-Agnostic Learning With Salient Images</a></th>
                    </tr>
                
                    <tr id="87d71570c4d93ac3b102365bdbbd4ac4384fea7b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/87d71570c4d93ac3b102365bdbbd4ac4384fea7b">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jo_Practical_Single-Image_Super-Resolution_Using_Look-Up_Table_CVPR_2021_paper.html">Practical Single-Image Super-Resolution Using Look-Up Table</a></th>
                    </tr>
                
                    <tr id="761a5e04002bd22acb4ace27f5a059f259b76777">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/761a5e04002bd22acb4ace27f5a059f259b76777">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Cross-View_Gait_Recognition_With_Deep_Universal_Linear_Embeddings_CVPR_2021_paper.html">Cross-View Gait Recognition with Deep Universal Linear Embeddings</a></th>
                    </tr>
                
                    <tr id="a94487efe33bc340cf40cf0e23d0f1da7dfa3ef1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a94487efe33bc340cf40cf0e23d0f1da7dfa3ef1">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shi_StablePose_Learning_6D_Object_Poses_From_Geometrically_Stable_Patches_CVPR_2021_paper.html">StablePose: Learning 6D Object Poses from Geometrically Stable Patches</a></th>
                    </tr>
                
                    <tr id="83ddb4092571ad3c07918a23655b213b05e4050b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/83ddb4092571ad3c07918a23655b213b05e4050b">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deng_Spatially-Invariant_Style-Codes_Controlled_Makeup_Transfer_CVPR_2021_paper.html">Spatially-invariant Style-codes Controlled Makeup Transfer</a></th>
                    </tr>
                
                    <tr id="0fb1e5d0fe19f74a5aa47f3186eb67e4fc575673">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0fb1e5d0fe19f74a5aa47f3186eb67e4fc575673">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tirupattur_Modeling_Multi-Label_Action_Dependencies_for_Temporal_Action_Localization_CVPR_2021_paper.html">Modeling Multi-Label Action Dependencies for Temporal Action Localization</a></th>
                    </tr>
                
                    <tr id="5f4528f2836e24895c6d7c0f079067bec34c1b94">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f4528f2836e24895c6d7c0f079067bec34c1b94">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Habibian_Skip-Convolutions_for_Efficient_Video_Processing_CVPR_2021_paper.html">Skip-Convolutions for Efficient Video Processing</a></th>
                    </tr>
                
                    <tr id="f61886d138497431cbeaa7bb73051bfb7a745026">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f61886d138497431cbeaa7bb73051bfb7a745026">15</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ye_Linguistic_Structures_As_Weak_Supervision_for_Visual_Scene_Graph_Generation_CVPR_2021_paper.html">Linguistic Structures as Weak Supervision for Visual Scene Graph Generation</a></th>
                    </tr>
                
                    <tr id="2dc8d430faf7d7e1157b3f0edce42f5c3c1949f0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2dc8d430faf7d7e1157b3f0edce42f5c3c1949f0">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Yu_A_Two-Branch_Neural_Network_for_Non-Homogeneous_Dehazing_via_Ensemble_Learning_CVPRW_2021_paper.html">A Two-Branch Neural Network for Non-Homogeneous Dehazing via Ensemble Learning</a></th>
                    </tr>
                
                    <tr id="5c02a64c4ad04790ab96b53fad22290e2bfb465e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c02a64c4ad04790ab96b53fad22290e2bfb465e">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Chen_Boosting_Co-Teaching_With_Compression_Regularization_for_Label_Noise_CVPRW_2021_paper.html">Boosting Co-Teaching With Compression Regularization for Label Noise</a></th>
                    </tr>
                
                    <tr id="def5ead7d96de126d2eeb7aef052fcf77ff96b1b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/def5ead7d96de126d2eeb7aef052fcf77ff96b1b">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/GAZE/html/D_Appearance-Based_Gaze_Estimation_Using_Attention_and_Difference_Mechanism_CVPRW_2021_paper.html">Appearance-Based Gaze Estimation Using Attention and Difference Mechanism</a></th>
                    </tr>
                
                    <tr id="6a295d77d5534c406ff3cfc061d90d75ef96f694">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a295d77d5534c406ff3cfc061d90d75ef96f694">15</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/Giancola_Temporally-Aware_Feature_Pooling_for_Action_Spotting_in_Soccer_Broadcasts_CVPRW_2021_paper.html">Temporally-Aware Feature Pooling for Action Spotting in Soccer Broadcasts</a></th>
                    </tr>
                
                    <tr id="08cfd4a23d3be9fb6ba0c35722e151429dbe5ede">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/08cfd4a23d3be9fb6ba0c35722e151429dbe5ede">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jiang_Learning_Optical_Flow_From_a_Few_Matches_CVPR_2021_paper.html">Learning Optical Flow From a Few Matches</a></th>
                    </tr>
                
                    <tr id="cdbbbeb1b4ff5bca7876de49232d8f784f7636de">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cdbbbeb1b4ff5bca7876de49232d8f784f7636de">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_SSAN_Separable_Self-Attention_Network_for_Video_Representation_Learning_CVPR_2021_paper.html">SSAN: Separable Self-Attention Network for Video Representation Learning</a></th>
                    </tr>
                
                    <tr id="091d46d8e8aad21a3c40775da9e163b9d63da909">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/091d46d8e8aad21a3c40775da9e163b9d63da909">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Multi-Decoding_Deraining_Network_and_Quasi-Sparsity_Based_Training_CVPR_2021_paper.html">Multi-Decoding Deraining Network and Quasi-Sparsity Based Training</a></th>
                    </tr>
                
                    <tr id="4eb8125691762e3f5b67bc16fd343ff758fc03e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4eb8125691762e3f5b67bc16fd343ff758fc03e6">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Patil_LayoutGMN_Neural_Graph_Matching_for_Structural_Layout_Similarity_CVPR_2021_paper.html">LayoutGMN: Neural Graph Matching for Structural Layout Similarity</a></th>
                    </tr>
                
                    <tr id="dadda013599aa46ff3c38007c8ae88da94762df7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dadda013599aa46ff3c38007c8ae88da94762df7">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Learning_To_Segment_Actions_From_Visual_and_Language_Instructions_via_CVPR_2021_paper.html">Learning To Segment Actions From Visual and Language Instructions via Differentiable Weak Sequence Alignment</a></th>
                    </tr>
                
                    <tr id="0fcb232d0b1b640535d948db6bbd309266ff4d76">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0fcb232d0b1b640535d948db6bbd309266ff4d76">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Inception_Convolution_With_Efficient_Dilation_Search_CVPR_2021_paper.html">Inception Convolution With Efficient Dilation Search</a></th>
                    </tr>
                
                    <tr id="396089ea05b7f80914876bda0a222672d7fcecdb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/396089ea05b7f80914876bda0a222672d7fcecdb">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Toward_Accurate_and_Realistic_Outfits_Visualization_With_Attention_to_Details_CVPR_2021_paper.html">Toward Accurate and Realistic Outfits Visualization With Attention to Details</a></th>
                    </tr>
                
                    <tr id="9baa20b5ac807aec45e1941693d956dcf70fd96e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9baa20b5ac807aec45e1941693d956dcf70fd96e">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Somanath_HDR_Environment_Map_Estimation_for_Real-Time_Augmented_Reality_CVPR_2021_paper.html">HDR Environment Map Estimation for Real-Time Augmented Reality</a></th>
                    </tr>
                
                    <tr id="66476e14f784c98ce7cf2c053d17f739bc85e23b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/66476e14f784c98ce7cf2c053d17f739bc85e23b">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Badki_Binary_TTC_A_Temporal_Geofence_for_Autonomous_Navigation_CVPR_2021_paper.html">Binary TTC: A Temporal Geofence for Autonomous Navigation</a></th>
                    </tr>
                
                    <tr id="ea28802c3d531ea1d585de232375267384319633">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ea28802c3d531ea1d585de232375267384319633">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Triple-Cooperative_Video_Shadow_Detection_CVPR_2021_paper.html">Triple-Cooperative Video Shadow Detection</a></th>
                    </tr>
                
                    <tr id="e17529c6ce6099f95358da16d92b109ca7490446">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e17529c6ce6099f95358da16d92b109ca7490446">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_PatchMatch-Based_Neighborhood_Consensus_for_Semantic_Correspondence_CVPR_2021_paper.html">PatchMatch-Based Neighborhood Consensus for Semantic Correspondence</a></th>
                    </tr>
                
                    <tr id="9d2ed54f88c1f1af6831964b0ad36c0c56cfa3cb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9d2ed54f88c1f1af6831964b0ad36c0c56cfa3cb">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wan_Self-Attention_Based_Text_Knowledge_Mining_for_Text_Detection_CVPR_2021_paper.html">Self-Attention Based Text Knowledge Mining for Text Detection</a></th>
                    </tr>
                
                    <tr id="d1a18a828a052c7d136800aa3e9233e4d61136dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d1a18a828a052c7d136800aa3e9233e4d61136dd">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Coarse-To-Fine_Person_Re-Identification_With_Auxiliary-Domain_Classification_and_Second-Order_Information_Bottleneck_CVPR_2021_paper.html">Coarse-To-Fine Person Re-Identification With Auxiliary-Domain Classification and Second-Order Information Bottleneck</a></th>
                    </tr>
                
                    <tr id="245bef79e41012b6856ef0ec4749e6bcd0e906d1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/245bef79e41012b6856ef0ec4749e6bcd0e906d1">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bu_GAIA_A_Transfer_Learning_System_of_Object_Detection_That_Fits_CVPR_2021_paper.html">GAIA: A Transfer Learning System of Object Detection That Fits Your Needs</a></th>
                    </tr>
                
                    <tr id="90d1b79984a79a88dbd931a829029b171e57ca9e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/90d1b79984a79a88dbd931a829029b171e57ca9e">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Woo_Learning_To_Associate_Every_Segment_for_Video_Panoptic_Segmentation_CVPR_2021_paper.html">Learning To Associate Every Segment for Video Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="2ac3e0e4653ba39393be3a2bb67dd52752d6801f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ac3e0e4653ba39393be3a2bb67dd52752d6801f">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ge_A_Peek_Into_the_Reasoning_of_Neural_Networks_Interpreting_With_CVPR_2021_paper.html">A Peek Into the Reasoning of Neural Networks: Interpreting With Structural Visual Concepts</a></th>
                    </tr>
                
                    <tr id="0d806dcbb1c14bea8139f21290358c483f208b18">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0d806dcbb1c14bea8139f21290358c483f208b18">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Improving_OCR-Based_Image_Captioning_by_Incorporating_Geometrical_Relationship_CVPR_2021_paper.html">Improving OCR-Based Image Captioning by Incorporating Geometrical Relationship</a></th>
                    </tr>
                
                    <tr id="6b8cc0e55e3c1b1811c85bf3509b054bb9aa2f9e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6b8cc0e55e3c1b1811c85bf3509b054bb9aa2f9e">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_De-Rendering_the_Worlds_Revolutionary_Artefacts_CVPR_2021_paper.html">De-Rendering the World&#39;s Revolutionary Artefacts</a></th>
                    </tr>
                
                    <tr id="f8886f780bec62831599f2ec49f871c3b1e1348b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f8886f780bec62831599f2ec49f871c3b1e1348b">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cazenavette_Architectural_Adversarial_Robustness_The_Case_for_Deep_Pursuit_CVPR_2021_paper.html">Architectural Adversarial Robustness: The Case for Deep Pursuit</a></th>
                    </tr>
                
                    <tr id="590bb218a5fef2636a49f43acfb81eff848bde72">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/590bb218a5fef2636a49f43acfb81eff848bde72">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cui_Towards_Accurate_3D_Human_Motion_Prediction_From_Incomplete_Observations_CVPR_2021_paper.html">Towards Accurate 3D Human Motion Prediction From Incomplete Observations</a></th>
                    </tr>
                
                    <tr id="afffb3018c81e645f0ca398460edafe1dfd853af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/afffb3018c81e645f0ca398460edafe1dfd853af">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Self-Supervised_Learning_of_Depth_Inference_for_Multi-View_Stereo_CVPR_2021_paper.html">Self-Supervised Learning of Depth Inference for Multi-View Stereo</a></th>
                    </tr>
                
                    <tr id="0eb5efbb1d95cf90ed353e1ad05f21d3796e5dff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0eb5efbb1d95cf90ed353e1ad05f21d3796e5dff">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Choi_VaB-AL_Incorporating_Class_Imbalance_and_Difficulty_With_Variational_Bayes_for_CVPR_2021_paper.html">VaB-AL: Incorporating Class Imbalance and Difficulty With Variational Bayes for Active Learning</a></th>
                    </tr>
                
                    <tr id="90360e8d76c76825c355685998c71f3a31aaddad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/90360e8d76c76825c355685998c71f3a31aaddad">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Piao_Inverting_Generative_Adversarial_Renderer_for_Face_Reconstruction_CVPR_2021_paper.html">Inverting Generative Adversarial Renderer for Face Reconstruction</a></th>
                    </tr>
                
                    <tr id="8d3421280594525dd9036d2ece740b24b4a1b53b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8d3421280594525dd9036d2ece740b24b4a1b53b">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Stojanov_Using_Shape_To_Categorize_Low-Shot_Learning_With_an_Explicit_Shape_CVPR_2021_paper.html">Using Shape To Categorize: Low-Shot Learning With an Explicit Shape Bias</a></th>
                    </tr>
                
                    <tr id="7e4822e93b68b3432a32f5eba95d02dd3027195f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e4822e93b68b3432a32f5eba95d02dd3027195f">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Singh_Rectification-Based_Knowledge_Retention_for_Continual_Learning_CVPR_2021_paper.html">Rectification-Based Knowledge Retention for Continual Learning</a></th>
                    </tr>
                
                    <tr id="3ee182c703188b77343bc06df7758ef7d23d214b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ee182c703188b77343bc06df7758ef7d23d214b">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Class-Aware_Robust_Adversarial_Training_for_Object_Detection_CVPR_2021_paper.html">Class-Aware Robust Adversarial Training for Object Detection</a></th>
                    </tr>
                
                    <tr id="d15265907487e970a368eed375b3b54f5f5aee1d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d15265907487e970a368eed375b3b54f5f5aee1d">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bohle_Convolutional_Dynamic_Alignment_Networks_for_Interpretable_Classifications_CVPR_2021_paper.html">Convolutional Dynamic Alignment Networks for Interpretable Classifications</a></th>
                    </tr>
                
                    <tr id="9c1dcf39cbcb2fada5ac7f70aaeb2503de810953">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c1dcf39cbcb2fada5ac7f70aaeb2503de810953">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Incremental_Learning_via_Rate_Reduction_CVPR_2021_paper.html">Incremental Learning via Rate Reduction</a></th>
                    </tr>
                
                    <tr id="60baaba6568989a60ad1b2796afa48114bef6d2c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/60baaba6568989a60ad1b2796afa48114bef6d2c">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sharma_Instance_Level_Affinity-Based_Transfer_for_Unsupervised_Domain_Adaptation_CVPR_2021_paper.html">Instance Level Affinity-Based Transfer for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="56cf31996ffe2e88ed043994c3c87d601f5a36c9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/56cf31996ffe2e88ed043994c3c87d601f5a36c9">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Self-Supervised_Motion_Learning_From_Static_Images_CVPR_2021_paper.html">Self-supervised Motion Learning from Static Images</a></th>
                    </tr>
                
                    <tr id="e40dba4056acea6917955a6a73dc772fd5712565">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e40dba4056acea6917955a6a73dc772fd5712565">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mao_FCPose_Fully_Convolutional_Multi-Person_Pose_Estimation_With_Dynamic_Instance-Aware_Convolutions_CVPR_2021_paper.html">FCPose: Fully Convolutional Multi-Person Pose Estimation with Dynamic Instance-Aware Convolutions</a></th>
                    </tr>
                
                    <tr id="50a9ff8b1a3f49220baa0950bc4645ad6f88f013">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50a9ff8b1a3f49220baa0950bc4645ad6f88f013">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_HCRF-Flow_Scene_Flow_From_Point_Clouds_With_Continuous_High-Order_CRFs_CVPR_2021_paper.html">HCRF-Flow: Scene Flow from Point Clouds with Continuous High-order CRFs and Position-aware Flow Embedding</a></th>
                    </tr>
                
                    <tr id="865ffe014782a565d70eeb1a362479d22eed6508">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/865ffe014782a565d70eeb1a362479d22eed6508">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dai_Learning_Affinity-Aware_Upsampling_for_Deep_Image_Matting_CVPR_2021_paper.html">Learning Affinity-Aware Upsampling for Deep Image Matting</a></th>
                    </tr>
                
                    <tr id="c49512baf1c5f6068d8f0e33461bad55082f5884">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c49512baf1c5f6068d8f0e33461bad55082f5884">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_View-Guided_Point_Cloud_Completion_CVPR_2021_paper.html">View-Guided Point Cloud Completion</a></th>
                    </tr>
                
                    <tr id="db6052c2f4de55b927a31ffd4babf60151d5f247">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db6052c2f4de55b927a31ffd4babf60151d5f247">14</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Looking_Into_Your_Speech_Learning_Cross-Modal_Affinity_for_Audio-Visual_Speech_CVPR_2021_paper.html">Looking into Your Speech: Learning Cross-modal Affinity for Audio-visual Speech Separation</a></th>
                    </tr>
                
                    <tr id="52daf327136f238ad3410fe3227a51820c146a3b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/52daf327136f238ad3410fe3227a51820c146a3b">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AMFG/html/Kumar_Micro-Expression_Classification_Based_on_Landmark_Relations_With_Graph_Attention_Convolutional_CVPRW_2021_paper.html">Micro-Expression Classification Based on Landmark Relations With Graph Attention Convolutional Network</a></th>
                    </tr>
                
                    <tr id="3578e297f24fcff76641973ed6d597e5bde4d0a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3578e297f24fcff76641973ed6d597e5bde4d0a2">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Jing_Self-Supervised_Feature_Learning_by_Cross-Modality_and_Cross-View_Correspondences_CVPRW_2021_paper.html">Self-Supervised Feature Learning by Cross-Modality and Cross-View Correspondences</a></th>
                    </tr>
                
                    <tr id="c76acce3f868cfd4ea57ff5597031afe4983fe7b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c76acce3f868cfd4ea57ff5597031afe4983fe7b">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Oquab_Low_Bandwidth_Video-Chat_Compression_Using_Deep_Generative_Models_CVPRW_2021_paper.html">Low Bandwidth Video-Chat Compression Using Deep Generative Models</a></th>
                    </tr>
                
                    <tr id="5a30dd283a279661e224c477ccbad7b1a8ae45e4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5a30dd283a279661e224c477ccbad7b1a8ae45e4">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Caldarola_Cluster-Driven_Graph_Federated_Learning_Over_Multiple_Domains_CVPRW_2021_paper.html">Cluster-Driven Graph Federated Learning Over Multiple Domains</a></th>
                    </tr>
                
                    <tr id="9720098966d8ad66cea24460990548ae755ded3a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9720098966d8ad66cea24460990548ae755ded3a">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Pastore_A_Closer_Look_at_Self-Training_for_Zero-Label_Semantic_Segmentation_CVPRW_2021_paper.html">A Closer Look at Self-Training for Zero-Label Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="fb8574b7dfa50e73c7ceac590009a1ba78fa7fc6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fb8574b7dfa50e73c7ceac590009a1ba78fa7fc6">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Cheng_Data-Efficient_Language-Supervised_Zero-Shot_Learning_With_Self-Distillation_CVPRW_2021_paper.html">Data-Efficient Language-Supervised Zero-Shot Learning With Self-Distillation</a></th>
                    </tr>
                
                    <tr id="70217f160329f2b93aaad100880c01ab9e419814">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70217f160329f2b93aaad100880c01ab9e419814">14</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/Kulkarni_Table_Tennis_Stroke_Recognition_Using_Two-Dimensional_Human_Pose_Estimation_CVPRW_2021_paper.html">Table Tennis Stroke Recognition Using Two-Dimensional Human Pose Estimation</a></th>
                    </tr>
                
                    <tr id="d4778e363811ceabc2183e044e83e6efe177418e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d4778e363811ceabc2183e044e83e6efe177418e">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_SRDAN_Scale-Aware_and_Range-Aware_Domain_Adaptation_Network_for_Cross-Dataset_3D_CVPR_2021_paper.html">SRDAN: Scale-Aware and Range-Aware Domain Adaptation Network for Cross-Dataset 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="c75398174a963ed58d2c4ce1c67abd1090af15b0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c75398174a963ed58d2c4ce1c67abd1090af15b0">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Prototype-Supervised_Adversarial_Network_for_Targeted_Attack_of_Deep_Hashing_CVPR_2021_paper.html">Prototype-Supervised Adversarial Network for Targeted Attack of Deep Hashing</a></th>
                    </tr>
                
                    <tr id="c9c92aa2dcab761b9b3361ba550d82e7850287a8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c9c92aa2dcab761b9b3361ba550d82e7850287a8">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Variational_Pedestrian_Detection_CVPR_2021_paper.html">Variational Pedestrian Detection</a></th>
                    </tr>
                
                    <tr id="9ad71bc0b115c797aeabca587ea5b1d0aeb2b6a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9ad71bc0b115c797aeabca587ea5b1d0aeb2b6a9">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Semantic-Aware_Video_Text_Detection_CVPR_2021_paper.html">Semantic-Aware Video Text Detection</a></th>
                    </tr>
                
                    <tr id="00b1ad4a029cd4a5f84f5ce7cd2c9308596fae54">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00b1ad4a029cd4a5f84f5ce7cd2c9308596fae54">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_NetAdaptV2_Efficient_Neural_Architecture_Search_With_Fast_Super-Network_Training_and_CVPR_2021_paper.html">NetAdaptV2: Efficient Neural Architecture Search With Fast Super-Network Training and Architecture Optimization</a></th>
                    </tr>
                
                    <tr id="8a3a366ec5ee526a1b79cb6b71489ac72259a96a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8a3a366ec5ee526a1b79cb6b71489ac72259a96a">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_PhD_Learning_Learning_With_Pompeiu-Hausdorff_Distances_for_Video-Based_Vehicle_Re-Identification_CVPR_2021_paper.html">PhD Learning: Learning With Pompeiu-Hausdorff Distances for Video-Based Vehicle Re-Identification</a></th>
                    </tr>
                
                    <tr id="0f6fcaedb5092f541b2e2801fb6fb4d07a4f0234">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0f6fcaedb5092f541b2e2801fb6fb4d07a4f0234">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jiang_Saliency-Guided_Image_Translation_CVPR_2021_paper.html">Saliency-Guided Image Translation</a></th>
                    </tr>
                
                    <tr id="1848e3afba3e7a3db6b23016905a6157baf6eff6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1848e3afba3e7a3db6b23016905a6157baf6eff6">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Exploring_Adversarial_Fake_Images_on_Face_Manifold_CVPR_2021_paper.html">Exploring Adversarial Fake Images on Face Manifold</a></th>
                    </tr>
                
                    <tr id="bc55f6b32fbd23acd6987d561d8ea4ffa47eb9cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bc55f6b32fbd23acd6987d561d8ea4ffa47eb9cc">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jayaraman_UV-Net_Learning_From_Boundary_Representations_CVPR_2021_paper.html">UV-Net: Learning From Boundary Representations</a></th>
                    </tr>
                
                    <tr id="14ce34c4ee3e7a17781e1a3f240346df22de71cb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/14ce34c4ee3e7a17781e1a3f240346df22de71cb">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhai_Hyper-LifelongGAN_Scalable_Lifelong_Learning_for_Image_Conditioned_Generation_CVPR_2021_paper.html">Hyper-LifelongGAN: Scalable Lifelong Learning for Image Conditioned Generation</a></th>
                    </tr>
                
                    <tr id="ff3dbf3a8bcb6a676995adcc7a0aea1c39b7bb1d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ff3dbf3a8bcb6a676995adcc7a0aea1c39b7bb1d">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Phan_Adversarial_Imaging_Pipelines_CVPR_2021_paper.html">Adversarial Imaging Pipelines</a></th>
                    </tr>
                
                    <tr id="967960ec13df326414b2971ff4c34511a42dedb6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/967960ec13df326414b2971ff4c34511a42dedb6">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_High-Speed_Image_Reconstruction_Through_Short-Term_Plasticity_for_Spiking_Cameras_CVPR_2021_paper.html">High-Speed Image Reconstruction Through Short-Term Plasticity for Spiking Cameras</a></th>
                    </tr>
                
                    <tr id="42effe8b3f3c39e83c84f06d2b0e6efb18d8d44f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/42effe8b3f3c39e83c84f06d2b0e6efb18d8d44f">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Unsupervised_Visual_Attention_and_Invariance_for_Reinforcement_Learning_CVPR_2021_paper.html">Unsupervised Visual Attention and Invariance for Reinforcement Learning</a></th>
                    </tr>
                
                    <tr id="7bb78ad8fc3f20e45ea47c462d7420191f6c79a1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7bb78ad8fc3f20e45ea47c462d7420191f6c79a1">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Faraki_Cross-Domain_Similarity_Learning_for_Face_Recognition_in_Unseen_Domains_CVPR_2021_paper.html">Cross-Domain Similarity Learning for Face Recognition in Unseen Domains</a></th>
                    </tr>
                
                    <tr id="5a20c113a8fec3a9cb4942ce76588c57ef359cca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5a20c113a8fec3a9cb4942ce76588c57ef359cca">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_3D_Shape_Feature_for_Texture-Insensitive_Person_Re-Identification_CVPR_2021_paper.html">Learning 3D Shape Feature for Texture-Insensitive Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="db08f45ce10a796e2e5bedcee18dc8c3668e4239">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db08f45ce10a796e2e5bedcee18dc8c3668e4239">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Spk2ImgNet_Learning_To_Reconstruct_Dynamic_Scene_From_Continuous_Spike_Stream_CVPR_2021_paper.html">Spk2ImgNet: Learning To Reconstruct Dynamic Scene From Continuous Spike Stream</a></th>
                    </tr>
                
                    <tr id="ab047178864dffd3924668f8cd3557be5299dc84">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ab047178864dffd3924668f8cd3557be5299dc84">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Progressively_Complementary_Network_for_Fisheye_Image_Rectification_Using_Appearance_Flow_CVPR_2021_paper.html">Progressively Complementary Network for Fisheye Image Rectification Using Appearance Flow</a></th>
                    </tr>
                
                    <tr id="ead86c36c6f6492aee65a00d86a6735c04ae6d99">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ead86c36c6f6492aee65a00d86a6735c04ae6d99">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ma_MUST-GAN_Multi-Level_Statistics_Transfer_for_Self-Driven_Person_Image_Generation_CVPR_2021_paper.html">MUST-GAN: Multi-Level Statistics Transfer for Self-Driven Person Image Generation</a></th>
                    </tr>
                
                    <tr id="51e2a8172e9ef71fdd40194085a6fb8034c74f4b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/51e2a8172e9ef71fdd40194085a6fb8034c74f4b">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mi_HDMapGen_A_Hierarchical_Graph_Generative_Model_of_High_Definition_Maps_CVPR_2021_paper.html">HDMapGen: A Hierarchical Graph Generative Model of High Definition Maps</a></th>
                    </tr>
                
                    <tr id="83edb72c3ebbda793eb844a26764d7e407ed2e6f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/83edb72c3ebbda793eb844a26764d7e407ed2e6f">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lei_Robust_Reflection_Removal_With_Reflection-Free_Flash-Only_Cues_CVPR_2021_paper.html">Robust Reflection Removal With Reflection-Free Flash-Only Cues</a></th>
                    </tr>
                
                    <tr id="809753afd1969e3b0cd27bc94acb5a4f86267a77">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/809753afd1969e3b0cd27bc94acb5a4f86267a77">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Rank-One_Prior_Toward_Real-Time_Scene_Recovery_CVPR_2021_paper.html">Rank-One Prior: Toward Real-Time Scene Recovery</a></th>
                    </tr>
                
                    <tr id="675ef23c1ab62de2134f477f22b30f7f95f0c7a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/675ef23c1ab62de2134f477f22b30f7f95f0c7a9">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Linear_Semantics_in_Generative_Adversarial_Networks_CVPR_2021_paper.html">Linear Semantics in Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="63abdeb29bc86810ae9f85728f7a5635c687cdc2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/63abdeb29bc86810ae9f85728f7a5635c687cdc2">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lal_CoCoNets_Continuous_Contrastive_3D_Scene_Representations_CVPR_2021_paper.html">CoCoNets: Continuous Contrastive 3D Scene Representations</a></th>
                    </tr>
                
                    <tr id="aa304858ce365a42d17e25b2525e48b8aebc997b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aa304858ce365a42d17e25b2525e48b8aebc997b">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mei_Depth-Aware_Mirror_Segmentation_CVPR_2021_paper.html">Depth-Aware Mirror Segmentation</a></th>
                    </tr>
                
                    <tr id="dbe75169ef82e450d16926d8b4538554a56a4ebf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dbe75169ef82e450d16926d8b4538554a56a4ebf">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Patchwise_Generative_ConvNet_Training_Energy-Based_Models_From_a_Single_Natural_CVPR_2021_paper.html">Patchwise Generative ConvNet: Training Energy-Based Models From a Single Natural Image for Internal Learning</a></th>
                    </tr>
                
                    <tr id="295c9f4511c8e0abf5718518910260467edecf46">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/295c9f4511c8e0abf5718518910260467edecf46">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Achille_LQF_Linear_Quadratic_Fine-Tuning_CVPR_2021_paper.html">LQF: Linear Quadratic Fine-Tuning</a></th>
                    </tr>
                
                    <tr id="070e51a0c33fc732273df67e8c49ee91561f794e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/070e51a0c33fc732273df67e8c49ee91561f794e">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_2D_or_not_2D_Adaptive_3D_Convolution_Selection_for_Efficient_CVPR_2021_paper.html">2D or not 2D? Adaptive 3D Convolution Selection for Efficient Video Recognition</a></th>
                    </tr>
                
                    <tr id="1429ecd688dfe9175f22302de727a9029d7f293a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1429ecd688dfe9175f22302de727a9029d7f293a">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Khandelwal_UniT_Unified_Knowledge_Transfer_for_Any-Shot_Object_Detection_and_Segmentation_CVPR_2021_paper.html">UniT: Unified Knowledge Transfer for Any-Shot Object Detection and Segmentation</a></th>
                    </tr>
                
                    <tr id="16cf8225d1b86c54a18b917a9475bfbd68b46306">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16cf8225d1b86c54a18b917a9475bfbd68b46306">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Distractor-Aware_Fast_Tracking_via_Dynamic_Convolutions_and_MOT_Philosophy_CVPR_2021_paper.html">Distractor-Aware Fast Tracking via Dynamic Convolutions and MOT Philosophy</a></th>
                    </tr>
                
                    <tr id="09d5f20ae19b7e349753edc6854a5417362acf04">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/09d5f20ae19b7e349753edc6854a5417362acf04">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Rozumnyi_DeFMO_Deblurring_and_Shape_Recovery_of_Fast_Moving_Objects_CVPR_2021_paper.html">DeFMO: Deblurring and Shape Recovery of Fast Moving Objects</a></th>
                    </tr>
                
                    <tr id="acc11d4651c892278f545356c78bcb65ffe776bb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/acc11d4651c892278f545356c78bcb65ffe776bb">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Point2Skeleton_Learning_Skeletal_Representations_from_Point_Clouds_CVPR_2021_paper.html">Point2Skeleton: Learning Skeletal Representations from Point Clouds</a></th>
                    </tr>
                
                    <tr id="d12b54dc7f0cf16791ee05a2ab77cfab38a9e0ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d12b54dc7f0cf16791ee05a2ab77cfab38a9e0ff">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chang_Learning_Discriminative_Prototypes_With_Dynamic_Time_Warping_CVPR_2021_paper.html">Learning Discriminative Prototypes With Dynamic Time Warping</a></th>
                    </tr>
                
                    <tr id="c459235244a532efda0be91a95da31d0298e0883">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c459235244a532efda0be91a95da31d0298e0883">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lo_CLCC_Contrastive_Learning_for_Color_Constancy_CVPR_2021_paper.html">CLCC: Contrastive Learning for Color Constancy</a></th>
                    </tr>
                
                    <tr id="16b673a3e38761be25b630c93ffde6dfcc8c6259">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16b673a3e38761be25b630c93ffde6dfcc8c6259">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yan_FP-NAS_Fast_Probabilistic_Neural_Architecture_Search_CVPR_2021_paper.html">FP-NAS: Fast Probabilistic Neural Architecture Search</a></th>
                    </tr>
                
                    <tr id="4ce8673aca36236db2e1234ff0a2963fbe6c211c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ce8673aca36236db2e1234ff0a2963fbe6c211c">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Autoregressive_Stylized_Motion_Synthesis_With_Generative_Flow_CVPR_2021_paper.html">Autoregressive Stylized Motion Synthesis With Generative Flow</a></th>
                    </tr>
                
                    <tr id="3838349e8b1c608aea95068f9b453d002863ae28">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3838349e8b1c608aea95068f9b453d002863ae28">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_LayoutTransformer_Scene_Layout_Generation_With_Conceptual_and_Spatial_Diversity_CVPR_2021_paper.html">LayoutTransformer: Scene Layout Generation With Conceptual and Spatial Diversity</a></th>
                    </tr>
                
                    <tr id="1caf796ff1e019429648e821cd01a15faaa364ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1caf796ff1e019429648e821cd01a15faaa364ac">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Urooj_Found_a_Reason_for_me_Weakly-supervised_Grounded_Visual_Question_Answering_CVPR_2021_paper.html">Found a Reason for me? Weakly-supervised Grounded Visual Question Answering using Capsules</a></th>
                    </tr>
                
                    <tr id="8162d90993c7081617877a4a0bc6305dfeab24d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8162d90993c7081617877a4a0bc6305dfeab24d2">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Haurum_Sewer-ML_A_Multi-Label_Sewer_Defect_Classification_Dataset_and_Benchmark_CVPR_2021_paper.html">Sewer-ML: A Multi-Label Sewer Defect Classification Dataset and Benchmark</a></th>
                    </tr>
                
                    <tr id="52f6d9cb1ed66d899cbc918e2228be6950e83739">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/52f6d9cb1ed66d899cbc918e2228be6950e83739">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gupta_Rotation_Equivariant_Siamese_Networks_for_Tracking_CVPR_2021_paper.html">Rotation Equivariant Siamese Networks for Tracking</a></th>
                    </tr>
                
                    <tr id="5352cb61d304f86ae90eea7cdcab676165940773">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5352cb61d304f86ae90eea7cdcab676165940773">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gonzalez_PLADE-Net_Towards_Pixel-Level_Accuracy_for_Self-Supervised_Single-View_Depth_Estimation_With_CVPR_2021_paper.html">PLADE-Net: Towards Pixel-Level Accuracy for Self-Supervised Single-View Depth Estimation With Neural Positional Encoding and Distilled Matting Loss</a></th>
                    </tr>
                
                    <tr id="e34608bd8565008c3b5692d2519f197eb15ab0db">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e34608bd8565008c3b5692d2519f197eb15ab0db">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Joint_Negative_and_Positive_Learning_for_Noisy_Labels_CVPR_2021_paper.html">Joint Negative and Positive Learning for Noisy Labels</a></th>
                    </tr>
                
                    <tr id="ec037c60723619b5e0c194fba6b5e91bd4f67917">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ec037c60723619b5e0c194fba6b5e91bd4f67917">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gong_Omni-Supervised_Point_Cloud_Segmentation_via_Gradual_Receptive_Field_Component_Reasoning_CVPR_2021_paper.html">Omni-supervised Point Cloud Segmentation via Gradual Receptive Field Component Reasoning</a></th>
                    </tr>
                
                    <tr id="8c4e0d0a98676615aeb4e56fa0ab90af618b1afd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c4e0d0a98676615aeb4e56fa0ab90af618b1afd">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Uy_Joint_Learning_of_3D_Shape_Retrieval_and_Deformation_CVPR_2021_paper.html">Joint Learning of 3D Shape Retrieval and Deformation</a></th>
                    </tr>
                
                    <tr id="0d2452be734198772cc5ece2a0ee8de21d7ae83f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0d2452be734198772cc5ece2a0ee8de21d7ae83f">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Spatial-Temporal_Correlation_and_Topology_Learning_for_Person_Re-Identification_in_Videos_CVPR_2021_paper.html">Spatial-Temporal Correlation and Topology Learning for Person Re-Identification in Videos</a></th>
                    </tr>
                
                    <tr id="0886ac1d8f63a073bd6cfdd63e62d2e7a41e54bf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0886ac1d8f63a073bd6cfdd63e62d2e7a41e54bf">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Poulenard_A_Functional_Approach_to_Rotation_Equivariant_Non-Linearities_for_Tensor_Field_CVPR_2021_paper.html">A functional approach to rotation equivariant non-linearities for Tensor Field Networks</a></th>
                    </tr>
                
                    <tr id="6d453f5df60963a232fdc62f5c5f70b4c55f5185">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6d453f5df60963a232fdc62f5c5f70b4c55f5185">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Aleotti_Learning_Optical_Flow_From_Still_Images_CVPR_2021_paper.html">Learning optical flow from still images</a></th>
                    </tr>
                
                    <tr id="3622d9b5f03e9d40967ee2748588f78f2df6d29a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3622d9b5f03e9d40967ee2748588f78f2df6d29a">13</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_From_Shadow_Generation_To_Shadow_Removal_CVPR_2021_paper.html">From Shadow Generation to Shadow Removal</a></th>
                    </tr>
                
                    <tr id="27de7c1e8da1ae4c7bc414579af553603a8da3ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/27de7c1e8da1ae4c7bc414579af553603a8da3ce">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Guo_IQMA_Network_Image_Quality_Multi-Scale_Assessment_Network_CVPRW_2021_paper.html">IQMA Network: Image Quality Multi-Scale Assessment Network</a></th>
                    </tr>
                
                    <tr id="0b48138a4bb0f61e8aeec3d909f3e9318ce07849">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0b48138a4bb0f61e8aeec3d909f3e9318ce07849">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LXCV/html/Lima_Generalizable_Multi-Camera_3D_Pedestrian_Detection_CVPRW_2021_paper.html">Generalizable Multi-Camera 3D Pedestrian Detection</a></th>
                    </tr>
                
                    <tr id="b6d60127144011a51780328e50266fce8fdcafb0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b6d60127144011a51780328e50266fce8fdcafb0">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ISIC/html/Bissoto_GAN-Based_Data_Augmentation_and_Anonymization_for_Skin-Lesion_Analysis_A_Critical_CVPRW_2021_paper.html">GAN-Based Data Augmentation and Anonymization for Skin-Lesion Analysis: A Critical Review</a></th>
                    </tr>
                
                    <tr id="298e17e162f2cd865d2339f5fb0751768adb7f03">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/298e17e162f2cd865d2339f5fb0751768adb7f03">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WiCV/html/Thota_Contrastive_Domain_Adaptation_CVPRW_2021_paper.html">Contrastive Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="7208c268c068b6139e12986da4c1171916524554">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7208c268c068b6139e12986da4c1171916524554">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ChaLearn/html/De_Coster_Isolated_Sign_Recognition_From_RGB_Video_Using_Pose_Flow_and_CVPRW_2021_paper.html">Isolated Sign Recognition From RGB Video Using Pose Flow and Self-Attention</a></th>
                    </tr>
                
                    <tr id="ee6a0de8e5716cb1d4116d707944e91277021ea6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ee6a0de8e5716cb1d4116d707944e91277021ea6">13</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ChaLearn/html/Rastgoo_Sign_Language_Production_A_Review_CVPRW_2021_paper.html">Sign Language Production: A Review</a></th>
                    </tr>
                
                    <tr id="e3ef9f82f783dfd151f7263dcf5d5a0bae3049fb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e3ef9f82f783dfd151f7263dcf5d5a0bae3049fb">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Learnable_Motion_Coherence_for_Correspondence_Pruning_CVPR_2021_paper.html">Learnable Motion Coherence for Correspondence Pruning</a></th>
                    </tr>
                
                    <tr id="198e3a4df3332e517f3b23995522155355ffeeaa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/198e3a4df3332e517f3b23995522155355ffeeaa">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Self-Supervised_Video_Hashing_via_Bidirectional_Transformers_CVPR_2021_paper.html">Self-Supervised Video Hashing via Bidirectional Transformers</a></th>
                    </tr>
                
                    <tr id="a1be3a80a767c3480c1dbee57bbe207f0e966203">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a1be3a80a767c3480c1dbee57bbe207f0e966203">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_SelfSAGCN_Self-Supervised_Semantic_Alignment_for_Graph_Convolution_Network_CVPR_2021_paper.html">SelfSAGCN: Self-Supervised Semantic Alignment for Graph Convolution Network</a></th>
                    </tr>
                
                    <tr id="e5481672b692c8a24c8853ece1629a6ef2238a64">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5481672b692c8a24c8853ece1629a6ef2238a64">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Unsupervised_Hyperbolic_Metric_Learning_CVPR_2021_paper.html">Unsupervised Hyperbolic Metric Learning</a></th>
                    </tr>
                
                    <tr id="4db555f3634743592713e071c6ec815f7ac08aa2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4db555f3634743592713e071c6ec815f7ac08aa2">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Griffin_Depth_From_Camera_Motion_and_Object_Detection_CVPR_2021_paper.html">Depth From Camera Motion and Object Detection</a></th>
                    </tr>
                
                    <tr id="7a8532fab4401250f53e8eac90d4404031710889">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a8532fab4401250f53e8eac90d4404031710889">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liang_PPR10K_A_Large-Scale_Portrait_Photo_Retouching_Dataset_With_Human-Region_Mask_CVPR_2021_paper.html">PPR10K: A Large-Scale Portrait Photo Retouching Dataset With Human-Region Mask and Group-Level Consistency</a></th>
                    </tr>
                
                    <tr id="f3998025773eb3d8cc577b30c89af840c86ff109">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f3998025773eb3d8cc577b30c89af840c86ff109">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ingle_Passive_Inter-Photon_Imaging_CVPR_2021_paper.html">Passive Inter-Photon Imaging</a></th>
                    </tr>
                
                    <tr id="2475e5be925867cab6c117ba3d8a1bf03ab446bf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2475e5be925867cab6c117ba3d8a1bf03ab446bf">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tian_Unsupervised_Object_Detection_With_LIDAR_Clues_CVPR_2021_paper.html">Unsupervised Object Detection With LIDAR Clues</a></th>
                    </tr>
                
                    <tr id="5473119bbc10c1f210bce526b51a63b3b1d93e07">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5473119bbc10c1f210bce526b51a63b3b1d93e07">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Park_Unsupervised_Hyperbolic_Representation_Learning_via_Message_Passing_Auto-Encoders_CVPR_2021_paper.html">Unsupervised Hyperbolic Representation Learning via Message Passing Auto-Encoders</a></th>
                    </tr>
                
                    <tr id="03fa40c0e49d0a21b0b7b555a8d3634e46dd8d29">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/03fa40c0e49d0a21b0b7b555a8d3634e46dd8d29">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Deep_Lucas-Kanade_Homography_for_Multimodal_Image_Alignment_CVPR_2021_paper.html">Deep Lucas-Kanade Homography for Multimodal Image Alignment</a></th>
                    </tr>
                
                    <tr id="cb2b6130aefb1f31c34b04b5a288fbbafeb9e056">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cb2b6130aefb1f31c34b04b5a288fbbafeb9e056">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Lighting_Reflectance_and_Geometry_Estimation_From_360deg_Panoramic_Stereo_CVPR_2021_paper.html">Lighting, Reflectance and Geometry Estimation From 360deg Panoramic Stereo</a></th>
                    </tr>
                
                    <tr id="f472dd701efb952f650d2c25383d7281d3d8566f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f472dd701efb952f650d2c25383d7281d3d8566f">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Self-Supervised_3D_Mesh_Reconstruction_From_Single_Images_CVPR_2021_paper.html">Self-Supervised 3D Mesh Reconstruction From Single Images</a></th>
                    </tr>
                
                    <tr id="d6737d83cec9b291554977d22517eebce475056b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d6737d83cec9b291554977d22517eebce475056b">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Rich_Context_Aggregation_With_Reflection_Prior_for_Glass_Surface_Detection_CVPR_2021_paper.html">Rich Context Aggregation With Reflection Prior for Glass Surface Detection</a></th>
                    </tr>
                
                    <tr id="d87ea36f4b0346e0e92c966cc0bb2b5c3f7337f6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d87ea36f4b0346e0e92c966cc0bb2b5c3f7337f6">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_NeRD_Neural_3D_Reflection_Symmetry_Detector_CVPR_2021_paper.html">NeRD: Neural 3D Reflection Symmetry Detector</a></th>
                    </tr>
                
                    <tr id="07c7d826d2b6ae675720d3d97f5e67d105ced423">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/07c7d826d2b6ae675720d3d97f5e67d105ced423">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Image_De-Raining_via_Continual_Learning_CVPR_2021_paper.html">Image De-Raining via Continual Learning</a></th>
                    </tr>
                
                    <tr id="8e75a37b9fbe99b3a19b4fd30329edb90941a6e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e75a37b9fbe99b3a19b4fd30329edb90941a6e6">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Learning_View-Disentangled_Human_Pose_Representation_by_Contrastive_Cross-View_Mutual_Information_CVPR_2021_paper.html">Learning View-Disentangled Human Pose Representation by Contrastive Cross-View Mutual Information Maximization</a></th>
                    </tr>
                
                    <tr id="b1d5e323d7303416dbb832ca70bc554d1a11f8c1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b1d5e323d7303416dbb832ca70bc554d1a11f8c1">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Landmark_Regularization_Ranking_Guided_Super-Net_Training_in_Neural_Architecture_Search_CVPR_2021_paper.html">Landmark Regularization: Ranking Guided Super-Net Training in Neural Architecture Search</a></th>
                    </tr>
                
                    <tr id="44cfb82fb3703f7ef2949f1cd38733643ce93328">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/44cfb82fb3703f7ef2949f1cd38733643ce93328">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Personalized_Outfit_Recommendation_With_Learnable_Anchors_CVPR_2021_paper.html">Personalized Outfit Recommendation With Learnable Anchors</a></th>
                    </tr>
                
                    <tr id="205e03f5cd9d970e389457f179b9efdd58c5757d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/205e03f5cd9d970e389457f179b9efdd58c5757d">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Singh_Combining_Semantic_Guidance_and_Deep_Reinforcement_Learning_for_Generating_Human_CVPR_2021_paper.html">Combining Semantic Guidance and Deep Reinforcement Learning for Generating Human Level Paintings</a></th>
                    </tr>
                
                    <tr id="50284f6a230a29d8420aeec274e22e2736c5946f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/50284f6a230a29d8420aeec274e22e2736c5946f">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Phillips_Deep_Multi-Task_Learning_for_Joint_Localization_Perception_and_Prediction_CVPR_2021_paper.html">Deep Multi-Task Learning for Joint Localization, Perception, and Prediction</a></th>
                    </tr>
                
                    <tr id="c14e9e74519a2a791f99e2dd8723b9b4f6bfef0e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c14e9e74519a2a791f99e2dd8723b9b4f6bfef0e">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ding_Deeply_Shape-Guided_Cascade_for_Instance_Segmentation_CVPR_2021_paper.html">Deeply Shape-Guided Cascade for Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="63a2ac160cbaf9da3b91f914badb60f81f56e238">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/63a2ac160cbaf9da3b91f914badb60f81f56e238">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bhattad_View_Generalization_for_Single_Image_Textured_3D_Models_CVPR_2021_paper.html">View Generalization for Single Image Textured 3D Models</a></th>
                    </tr>
                
                    <tr id="0e0d4d4f6bc9ef53f7167b596ac779b36604f7ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e0d4d4f6bc9ef53f7167b596ac779b36604f7ff">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Song_Tree-Like_Decision_Distillation_CVPR_2021_paper.html">Tree-Like Decision Distillation</a></th>
                    </tr>
                
                    <tr id="08bc2d373d930a30a0fc77a4854858d8f1981003">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/08bc2d373d930a30a0fc77a4854858d8f1981003">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Refer-It-in-RGBD_A_Bottom-Up_Approach_for_3D_Visual_Grounding_in_RGBD_CVPR_2021_paper.html">Refer-It-in-RGBD: A Bottom-Up Approach for 3D Visual Grounding in RGBD Images</a></th>
                    </tr>
                
                    <tr id="2ab2d8f7b35f20ed55a34088b2b67b3c7e60be3a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2ab2d8f7b35f20ed55a34088b2b67b3c7e60be3a">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Extreme_Rotation_Estimation_Using_Dense_Correlation_Volumes_CVPR_2021_paper.html">Extreme Rotation Estimation Using Dense Correlation Volumes</a></th>
                    </tr>
                
                    <tr id="02dc03dddbe81dfe84fb3097cf3742b21f6073d5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/02dc03dddbe81dfe84fb3097cf3742b21f6073d5">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Diao_BASARBlack-Box_Attack_on_Skeletal_Action_Recognition_CVPR_2021_paper.html">BASAR:Black-Box Attack on Skeletal Action Recognition</a></th>
                    </tr>
                
                    <tr id="4bee506b3340afc1e22dfcc3b4026d4b0757ea0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4bee506b3340afc1e22dfcc3b4026d4b0757ea0c">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Progressive_Unsupervised_Learning_for_Visual_Object_Tracking_CVPR_2021_paper.html">Progressive Unsupervised Learning for Visual Object Tracking</a></th>
                    </tr>
                
                    <tr id="4575ca5bcb688f3fd90f2464d082b9c22f965aba">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4575ca5bcb688f3fd90f2464d082b9c22f965aba">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Byun_FBI-Denoiser_Fast_Blind_Image_Denoiser_for_Poisson-Gaussian_Noise_CVPR_2021_paper.html">FBI-Denoiser: Fast Blind Image Denoiser for Poisson-Gaussian Noise</a></th>
                    </tr>
                
                    <tr id="96ab55d174d95c95a772a6e848be80daf3d78ec3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96ab55d174d95c95a772a6e848be80daf3d78ec3">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_Tensor_Low-Rank_Prior_for_Hyperspectral_Image_Reconstruction_CVPR_2021_paper.html">Learning Tensor Low-Rank Prior for Hyperspectral Image Reconstruction</a></th>
                    </tr>
                
                    <tr id="84d76a1111720aa617325ac0abed4c26325cc504">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/84d76a1111720aa617325ac0abed4c26325cc504">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Sign-Agnostic_Implicit_Learning_of_Surface_Self-Similarities_for_Shape_Modeling_and_CVPR_2021_paper.html">Sign-Agnostic Implicit Learning of Surface Self-Similarities for Shape Modeling and Reconstruction From Raw Point Clouds</a></th>
                    </tr>
                
                    <tr id="8d27e9566a73b25c8171aafb084a938b9db636b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8d27e9566a73b25c8171aafb084a938b9db636b5">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Iterative_Shrinking_for_Referring_Expression_Grounding_Using_Deep_Reinforcement_Learning_CVPR_2021_paper.html">Iterative Shrinking for Referring Expression Grounding Using Deep Reinforcement Learning</a></th>
                    </tr>
                
                    <tr id="a3ff5cb5d3e2a43e4dda4b9e26f385776a703a7a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a3ff5cb5d3e2a43e4dda4b9e26f385776a703a7a">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yao_A_Decomposition_Model_for_Stereo_Matching_CVPR_2021_paper.html">A Decomposition Model for Stereo Matching</a></th>
                    </tr>
                
                    <tr id="c24ad0eaf96c840ba1fa5a0222800224741e51df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c24ad0eaf96c840ba1fa5a0222800224741e51df">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_TSGCNet_Discriminative_Geometric_Feature_Learning_With_Two-Stream_Graph_Convolutional_Network_CVPR_2021_paper.html">TSGCNet: Discriminative Geometric Feature Learning With Two-Stream Graph Convolutional Network for 3D Dental Model Segmentation</a></th>
                    </tr>
                
                    <tr id="191a14be3c977d958da731c98383cc2c90d12da5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/191a14be3c977d958da731c98383cc2c90d12da5">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Morreale_Neural_Surface_Maps_CVPR_2021_paper.html">Neural Surface Maps</a></th>
                    </tr>
                
                    <tr id="1cb411046e9b1844ab006600ac698e5711f3fbae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1cb411046e9b1844ab006600ac698e5711f3fbae">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_PCLs_Geometry-Aware_Neural_Reconstruction_of_3D_Pose_With_Perspective_Crop_CVPR_2021_paper.html">PCLs: Geometry-Aware Neural Reconstruction of 3D Pose With Perspective Crop Layers</a></th>
                    </tr>
                
                    <tr id="2bd3395d16875fcf3b7e3bc22db4e9bf743171b0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2bd3395d16875fcf3b7e3bc22db4e9bf743171b0">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Prabhakar_Labeled_From_Unlabeled_Exploiting_Unlabeled_Data_for_Few-Shot_Deep_HDR_CVPR_2021_paper.html">Labeled From Unlabeled: Exploiting Unlabeled Data for Few-Shot Deep HDR Deghosting</a></th>
                    </tr>
                
                    <tr id="d87d800cdbd0ef8e4414cc03281fbe990cfd4fe5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d87d800cdbd0ef8e4414cc03281fbe990cfd4fe5">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Exploit_Visual_Dependency_Relations_for_Semantic_Segmentation_CVPR_2021_paper.html">Exploit Visual Dependency Relations for Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="39e70be1d3d9907271aeeb6733a98eb38fe27d26">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39e70be1d3d9907271aeeb6733a98eb38fe27d26">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lamba_Restoring_Extremely_Dark_Images_in_Real_Time_CVPR_2021_paper.html">Restoring Extremely Dark Images in Real Time</a></th>
                    </tr>
                
                    <tr id="23a84830d2500f3adc8c7556b49f30d45a24a897">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/23a84830d2500f3adc8c7556b49f30d45a24a897">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Exploring_intermediate_representation_for_monocular_vehicle_pose_estimation_CVPR_2021_paper.html">Exploring intermediate representation for monocular vehicle pose estimation</a></th>
                    </tr>
                
                    <tr id="baee6bd21ac34e4e96479b928917e0c4f78c9c14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/baee6bd21ac34e4e96479b928917e0c4f78c9c14">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lyu_Towards_Evaluating_and_Training_Verifiably_Robust_Neural_Networks_CVPR_2021_paper.html">Towards Evaluating and Training Verifiably Robust Neural Networks</a></th>
                    </tr>
                
                    <tr id="e9bf333219929128e3b96a280b55474b043d4f7b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e9bf333219929128e3b96a280b55474b043d4f7b">12</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mittal_Affect2MM_Affective_Analysis_of_Multimedia_Content_Using_Emotion_Causality_CVPR_2021_paper.html">Affect2MM: Affective Analysis of Multimedia Content Using Emotion Causality</a></th>
                    </tr>
                
                    <tr id="5491a4f2003efa5bb21396a1655a734ff2a9576a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5491a4f2003efa5bb21396a1655a734ff2a9576a">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Shi_Region-Adaptive_Deformable_Network_for_Image_Quality_Assessment_CVPRW_2021_paper.html">Region-Adaptive Deformable Network for Image Quality Assessment</a></th>
                    </tr>
                
                    <tr id="78bbdf7c04151ecaab04d5ddd21f3db597caf10c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/78bbdf7c04151ecaab04d5ddd21f3db597caf10c">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Agarwal_Detecting_Deep-Fake_Videos_From_Aural_and_Oral_Dynamics_CVPRW_2021_paper.html">Detecting Deep-Fake Videos From Aural and Oral Dynamics</a></th>
                    </tr>
                
                    <tr id="78e83294d2d21f47190b0b588d6ba849b066958e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/78e83294d2d21f47190b0b588d6ba849b066958e">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Wang_Machine-Learned_3D_Building_Vectorization_From_Satellite_Imagery_CVPRW_2021_paper.html">Machine-Learned 3D Building Vectorization From Satellite Imagery</a></th>
                    </tr>
                
                    <tr id="12a3ffe8622ffac9cdbc96c2ac68f2425f09150b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/12a3ffe8622ffac9cdbc96c2ac68f2425f09150b">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Dutta_Stacked_Deep_Multi-Scale_Hierarchical_Network_for_Fast_Bokeh_Effect_Rendering_CVPRW_2021_paper.html">Stacked Deep Multi-Scale Hierarchical Network for Fast Bokeh Effect Rendering From a Single Image</a></th>
                    </tr>
                
                    <tr id="c97765822a95af326c29993ac72a53a91511ee05">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c97765822a95af326c29993ac72a53a91511ee05">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WAD/html/Lv_LCCNet_LiDAR_and_Camera_Self-Calibration_Using_Cost_Volume_Network_CVPRW_2021_paper.html">LCCNet: LiDAR and Camera Self-Calibration Using Cost Volume Network</a></th>
                    </tr>
                
                    <tr id="82debd146c2351ec37ef2f6b51ca7fb04244d527">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/82debd146c2351ec37ef2f6b51ca7fb04244d527">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ChaLearn/html/Jiang_Skeletor_Skeletal_Transformers_for_Robust_Body-Pose_Estimation_CVPRW_2021_paper.html">Skeletor: Skeletal Transformers for Robust Body-Pose Estimation</a></th>
                    </tr>
                
                    <tr id="3ab4adaecdd4502b427f60887c6adc4e8ede4bae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ab4adaecdd4502b427f60887c6adc4e8ede4bae">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/van_de_Ven_Class-Incremental_Learning_With_Generative_Classifiers_CVPRW_2021_paper.html">Class-Incremental Learning With Generative Classifiers</a></th>
                    </tr>
                
                    <tr id="66c5d1e8708ec4cbfa62bc56239cc71ecce67d15">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/66c5d1e8708ec4cbfa62bc56239cc71ecce67d15">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/OmniCV/html/Albanis_Pano3D_A_Holistic_Benchmark_and_a_Solid_Baseline_for_360deg_CVPRW_2021_paper.html">Pano3D: A Holistic Benchmark and a Solid Baseline for 360deg Depth Estimation</a></th>
                    </tr>
                
                    <tr id="ba3b0561267ffe79ea66a178c746d3ca9dd6a34a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ba3b0561267ffe79ea66a178c746d3ca9dd6a34a">12</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Ye_A_Robust_MTMC_Tracking_System_for_AI-City_Challenge_2021_CVPRW_2021_paper.html">A Robust MTMC Tracking System for AI-City Challenge 2021</a></th>
                    </tr>
                
                    <tr id="61254c941106a4c837e34cbcf89e81d7f0eccda3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61254c941106a4c837e34cbcf89e81d7f0eccda3">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Removing_Diffraction_Image_Artifacts_in_Under-Display_Camera_via_Dynamic_Skip_CVPR_2021_paper.html">Removing Diffraction Image Artifacts in Under-Display Camera via Dynamic Skip Connection Network</a></th>
                    </tr>
                
                    <tr id="09abc59567e0b4cc210ad2f1b554643d6df41003">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/09abc59567e0b4cc210ad2f1b554643d6df41003">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sheng_SSN_Soft_Shadow_Network_for_Image_Compositing_CVPR_2021_paper.html">SSN: Soft Shadow Network for Image Compositing</a></th>
                    </tr>
                
                    <tr id="771ba492e3d93bfd422c05778346c88f35d6cd8a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/771ba492e3d93bfd422c05778346c88f35d6cd8a">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tian_Can_Audio-Visual_Integration_Strengthen_Robustness_Under_Multimodal_Attacks_CVPR_2021_paper.html">Can Audio-Visual Integration Strengthen Robustness Under Multimodal Attacks?</a></th>
                    </tr>
                
                    <tr id="e4ac49aa6f1d7ea8bfa3b09b4642bc2ec68ca5a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e4ac49aa6f1d7ea8bfa3b09b4642bc2ec68ca5a0">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jiao_EffiScene_Efficient_Per-Pixel_Rigidity_Inference_for_Unsupervised_Joint_Learning_of_CVPR_2021_paper.html">EffiScene: Efficient Per-Pixel Rigidity Inference for Unsupervised Joint Learning of Optical Flow, Depth, Camera Pose and Motion Segmentation</a></th>
                    </tr>
                
                    <tr id="b429c750d902852609087b86393aee2c0dde99e8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b429c750d902852609087b86393aee2c0dde99e8">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_One-Shot_Neural_Ensemble_Architecture_Search_by_Diversity-Guided_Search_Space_Shrinking_CVPR_2021_paper.html">One-Shot Neural Ensemble Architecture Search by Diversity-Guided Search Space Shrinking</a></th>
                    </tr>
                
                    <tr id="208d21f9a2f2875acc0a69148a330a578650de32">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/208d21f9a2f2875acc0a69148a330a578650de32">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Skeleton_Merger_An_Unsupervised_Aligned_Keypoint_Detector_CVPR_2021_paper.html">Skeleton Merger: An Unsupervised Aligned Keypoint Detector</a></th>
                    </tr>
                
                    <tr id="3015614ffb2d7e6968146a3693aedcbf00ed7959">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3015614ffb2d7e6968146a3693aedcbf00ed7959">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_SAIL-VOS_3D_A_Synthetic_Dataset_and_Baselines_for_Object_Detection_CVPR_2021_paper.html">SAIL-VOS 3D: A Synthetic Dataset and Baselines for Object Detection and 3D Mesh Reconstruction From Video Data</a></th>
                    </tr>
                
                    <tr id="8aa6a358daa5e89b00f051ecfbfe3c5342e31264">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8aa6a358daa5e89b00f051ecfbfe3c5342e31264">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Oh_Automated_Log-Scale_Quantization_for_Low-Cost_Deep_Neural_Networks_CVPR_2021_paper.html">Automated Log-Scale Quantization for Low-Cost Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="36804777a6a05c89437d16b04a60ffd0288b2fec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/36804777a6a05c89437d16b04a60ffd0288b2fec">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Daniel_Soft-IntroVAE_Analyzing_and_Improving_the_Introspective_Variational_Autoencoder_CVPR_2021_paper.html">Soft-IntroVAE: Analyzing and Improving the Introspective Variational Autoencoder</a></th>
                    </tr>
                
                    <tr id="b507cdbe56af0aca2a76275466fa5ec448da88c3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b507cdbe56af0aca2a76275466fa5ec448da88c3">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jo_Tackling_the_Ill-Posedness_of_Super-Resolution_Through_Adaptive_Target_Generation_CVPR_2021_paper.html">Tackling the Ill-Posedness of Super-Resolution Through Adaptive Target Generation</a></th>
                    </tr>
                
                    <tr id="501873671909a43c2cc4fa2ac0af724a2088840f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/501873671909a43c2cc4fa2ac0af724a2088840f">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sanchez_Affective_Processes_Stochastic_Modelling_of_Temporal_Context_for_Emotion_and_CVPR_2021_paper.html">Affective Processes: Stochastic Modelling of Temporal Context for Emotion and Facial Expression Recognition</a></th>
                    </tr>
                
                    <tr id="f7acf9355deb04f63d51aa0905418ee2ab092d0f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7acf9355deb04f63d51aa0905418ee2ab092d0f">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_3D_Graph_Anatomy_Geometry-Integrated_Network_for_Pancreatic_Mass_Segmentation_Diagnosis_CVPR_2021_paper.html">3D Graph Anatomy Geometry-Integrated Network for Pancreatic Mass Segmentation, Diagnosis, and Quantitative Patient Management</a></th>
                    </tr>
                
                    <tr id="41fc4acb579c347171f815c9ccea07bf88cd66f3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/41fc4acb579c347171f815c9ccea07bf88cd66f3">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Group_Whitening_Balancing_Learning_Efficiency_and_Representational_Capacity_CVPR_2021_paper.html">Group Whitening: Balancing Learning Efficiency and Representational Capacity</a></th>
                    </tr>
                
                    <tr id="c4dcaf4bfdb83da0c59e40ef97231fe2f0d85102">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c4dcaf4bfdb83da0c59e40ef97231fe2f0d85102">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nguyen_FAPIS_A_Few-Shot_Anchor-Free_Part-Based_Instance_Segmenter_CVPR_2021_paper.html">FAPIS: A Few-Shot Anchor-Free Part-Based Instance Segmenter</a></th>
                    </tr>
                
                    <tr id="c1d41e75bd795e21984452d276af4721fa2beb21">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c1d41e75bd795e21984452d276af4721fa2beb21">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_FAIEr_Fidelity_and_Adequacy_Ensured_Image_Caption_Evaluation_CVPR_2021_paper.html">FAIEr: Fidelity and Adequacy Ensured Image Caption Evaluation</a></th>
                    </tr>
                
                    <tr id="8f67627596e9fc66817a863e07d6607c817e73cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f67627596e9fc66817a863e07d6607c817e73cd">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ahmed_Object_Classification_From_Randomized_EEG_Trials_CVPR_2021_paper.html">Object Classification From Randomized EEG Trials</a></th>
                    </tr>
                
                    <tr id="cb4629db6ff0a53a570ad53b0687cb6650d50523">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cb4629db6ff0a53a570ad53b0687cb6650d50523">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Learning_Parallel_Dense_Correspondence_From_Spatio-Temporal_Descriptors_for_Efficient_and_CVPR_2021_paper.html">Learning Parallel Dense Correspondence From Spatio-Temporal Descriptors for Efficient and Robust 4D Reconstruction</a></th>
                    </tr>
                
                    <tr id="8e8036e24ef5c54740f37d1fd25eaec14d0fd194">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e8036e24ef5c54740f37d1fd25eaec14d0fd194">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Learning_Camera_Localization_via_Dense_Scene_Matching_CVPR_2021_paper.html">Learning Camera Localization via Dense Scene Matching</a></th>
                    </tr>
                
                    <tr id="4ae47e3cd171db9f31c485d2ec26d507206f1769">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ae47e3cd171db9f31c485d2ec26d507206f1769">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Discrete-Continuous_Action_Space_Policy_Gradient-Based_Attention_for_Image-Text_Matching_CVPR_2021_paper.html">Discrete-Continuous Action Space Policy Gradient-Based Attention for Image-Text Matching</a></th>
                    </tr>
                
                    <tr id="8e0303de82d05e2772bf2cae22d695a358fa243e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8e0303de82d05e2772bf2cae22d695a358fa243e">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Scene_Text_Retrieval_via_Joint_Text_Detection_and_Similarity_Learning_CVPR_2021_paper.html">Scene Text Retrieval via Joint Text Detection and Similarity Learning</a></th>
                    </tr>
                
                    <tr id="662ca58f63b58b2cf4c60013b9cc79c55ab63b86">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/662ca58f63b58b2cf4c60013b9cc79c55ab63b86">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fang_LiDAR-Aug_A_General_Rendering-Based_Augmentation_Framework_for_3D_Object_Detection_CVPR_2021_paper.html">LiDAR-Aug: A General Rendering-Based Augmentation Framework for 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="2f5d1c6de2cf91a0bc328b94f19b72de19c38714">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2f5d1c6de2cf91a0bc328b94f19b72de19c38714">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_AQD_Towards_Accurate_Quantized_Object_Detection_CVPR_2021_paper.html">AQD: Towards Accurate Quantized Object Detection</a></th>
                    </tr>
                
                    <tr id="5581bc4cdcce9b11be6223d91dceca2e03f71157">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5581bc4cdcce9b11be6223d91dceca2e03f71157">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gafni_Single-Shot_Freestyle_Dance_Reenactment_CVPR_2021_paper.html">Single-Shot Freestyle Dance Reenactment</a></th>
                    </tr>
                
                    <tr id="a4551eaa6d9989831b3923957238f60fa51463eb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a4551eaa6d9989831b3923957238f60fa51463eb">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Few-Shot_Human_Motion_Transfer_by_Personalized_Geometry_and_Texture_Modeling_CVPR_2021_paper.html">Few-Shot Human Motion Transfer by Personalized Geometry and Texture Modeling</a></th>
                    </tr>
                
                    <tr id="ce5d89920bf963f2c0a6106ce98d1b05185bca2e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ce5d89920bf963f2c0a6106ce98d1b05185bca2e">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Dynamic_Class_Queue_for_Large_Scale_Face_Recognition_in_the_CVPR_2021_paper.html">Dynamic Class Queue for Large Scale Face Recognition in the Wild</a></th>
                    </tr>
                
                    <tr id="7093f6ad13359bc16e136588190490149d6d8e41">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7093f6ad13359bc16e136588190490149d6d8e41">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jing_Cross-Modal_Center_Loss_for_3D_Cross-Modal_Retrieval_CVPR_2021_paper.html">Cross-Modal Center Loss for 3D Cross-Modal Retrieval</a></th>
                    </tr>
                
                    <tr id="44ed782fe08688e2e788223d134a23dc518b3b61">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/44ed782fe08688e2e788223d134a23dc518b3b61">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Deep_Texture_Recognition_via_Exploiting_Cross-Layer_Statistical_Self-Similarity_CVPR_2021_paper.html">Deep Texture Recognition via Exploiting Cross-Layer Statistical Self-Similarity</a></th>
                    </tr>
                
                    <tr id="565f23e8c0501252f9830f42b978735f6b4049f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/565f23e8c0501252f9830f42b978735f6b4049f1">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tan_HumanGPS_Geodesic_PreServing_Feature_for_Dense_Human_Correspondences_CVPR_2021_paper.html">HumanGPS: Geodesic PreServing Feature for Dense Human Correspondences</a></th>
                    </tr>
                
                    <tr id="3b62fbb4ddb020f6d843097a7edc42bb7fddbe75">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3b62fbb4ddb020f6d843097a7edc42bb7fddbe75">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lichy_Shape_and_Material_Capture_at_Home_CVPR_2021_paper.html">Shape and Material Capture at Home</a></th>
                    </tr>
                
                    <tr id="07cb8f743a6489dffae666d5bda3c90ae24a281b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/07cb8f743a6489dffae666d5bda3c90ae24a281b">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Unpaired_Image-to-Image_Translation_via_Latent_Energy_Transport_CVPR_2021_paper.html">Unpaired Image-to-Image Translation via Latent Energy Transport</a></th>
                    </tr>
                
                    <tr id="0a6935a89fc51bb0a9085a58de387226287bd8d3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a6935a89fc51bb0a9085a58de387226287bd8d3">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Singh_DISCO_Dynamic_and_Invariant_Sensitive_Channel_Obfuscation_for_Deep_Neural_CVPR_2021_paper.html">DISCO: Dynamic and Invariant Sensitive Channel Obfuscation for Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="a07f74389f3f300cd0a943c39faadeea3aabd1d6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a07f74389f3f300cd0a943c39faadeea3aabd1d6">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hyun_Self-Supervised_Video_GANs_Learning_for_Appearance_Consistency_and_Motion_Coherency_CVPR_2021_paper.html">Self-Supervised Video GANs: Learning for Appearance Consistency and Motion Coherency</a></th>
                    </tr>
                
                    <tr id="6c315ee8546702037bef3276529838858c7a00ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c315ee8546702037bef3276529838858c7a00ad">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Taha_Knowledge_Evolution_in_Neural_Networks_CVPR_2021_paper.html">Knowledge Evolution in Neural Networks</a></th>
                    </tr>
                
                    <tr id="b978aac95a122f6cb120b1949224f4bbdb62b483">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b978aac95a122f6cb120b1949224f4bbdb62b483">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Searching_by_Generating_Flexible_and_Efficient_One-Shot_NAS_With_Architecture_CVPR_2021_paper.html">Searching by Generating: Flexible and Efficient One-Shot NAS With Architecture Generator</a></th>
                    </tr>
                
                    <tr id="aaeeeecc0926a9d3f6f4784c7ad071300b90dec7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aaeeeecc0926a9d3f6f4784c7ad071300b90dec7">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Learning_by_Planning_Language-Guided_Global_Image_Editing_CVPR_2021_paper.html">Learning by Planning: Language-Guided Global Image Editing</a></th>
                    </tr>
                
                    <tr id="762d3dc3fe0e63e940f327db4ff6fdaa7684f8a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/762d3dc3fe0e63e940f327db4ff6fdaa7684f8a0">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Event-Based_Synthetic_Aperture_Imaging_With_a_Hybrid_Network_CVPR_2021_paper.html">Event-Based Synthetic Aperture Imaging With a Hybrid Network</a></th>
                    </tr>
                
                    <tr id="029c8ab45a63cab801f0b80d28ba23b6c4675cae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/029c8ab45a63cab801f0b80d28ba23b6c4675cae">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Muller_Seeing_Behind_Objects_for_3D_Multi-Object_Tracking_in_RGB-D_Sequences_CVPR_2021_paper.html">Seeing Behind Objects for 3D Multi-Object Tracking in RGB-D Sequences</a></th>
                    </tr>
                
                    <tr id="4bfa646c7145aa8b22f5741b81fb3d452da1a606">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4bfa646c7145aa8b22f5741b81fb3d452da1a606">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_The_Blessings_of_Unlabeled_Background_in_Untrimmed_Videos_CVPR_2021_paper.html">The Blessings of Unlabeled Background in Untrimmed Videos</a></th>
                    </tr>
                
                    <tr id="9b0297ad3e186c98b9813c4d799ffd0108a42b39">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9b0297ad3e186c98b9813c4d799ffd0108a42b39">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Boosting_Ensemble_Accuracy_by_Revisiting_Ensemble_Diversity_Metrics_CVPR_2021_paper.html">Boosting Ensemble Accuracy by Revisiting Ensemble Diversity Metrics</a></th>
                    </tr>
                
                    <tr id="1d1423e06246676391286a9b8599f30b6da19070">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1d1423e06246676391286a9b8599f30b6da19070">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Unsupervised_Visual_Representation_Learning_by_Tracking_Patches_in_Video_CVPR_2021_paper.html">Unsupervised Visual Representation Learning by Tracking Patches in Video</a></th>
                    </tr>
                
                    <tr id="04eae78cdde834722a3caa4b001bb838f906c65f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/04eae78cdde834722a3caa4b001bb838f906c65f">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Porzi_Improving_Panoptic_Segmentation_at_All_Scales_CVPR_2021_paper.html">Improving Panoptic Segmentation at All Scales</a></th>
                    </tr>
                
                    <tr id="05f9689124903a6c6537421a16b7a4c6b4b122d6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05f9689124903a6c6537421a16b7a4c6b4b122d6">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Combinatorial_Learning_of_Graph_Edit_Distance_via_Dynamic_Embedding_CVPR_2021_paper.html">Combinatorial Learning of Graph Edit Distance via Dynamic Embedding</a></th>
                    </tr>
                
                    <tr id="2c12b14ed6f3353d524009affdaaf673eb1a52ae">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c12b14ed6f3353d524009affdaaf673eb1a52ae">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bhunia_MetaHTR_Towards_Writer-Adaptive_Handwritten_Text_Recognition_CVPR_2021_paper.html">MetaHTR: Towards Writer-Adaptive Handwritten Text Recognition</a></th>
                    </tr>
                
                    <tr id="31370c0ad412e6d21a419a7acb58cd37eee7bd3f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/31370c0ad412e6d21a419a7acb58cd37eee7bd3f">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fayyaz_3D_CNNs_With_Adaptive_Temporal_Feature_Resolutions_CVPR_2021_paper.html">3D CNNs With Adaptive Temporal Feature Resolutions</a></th>
                    </tr>
                
                    <tr id="b584213297fb1e6df3804de8298c6e00479a12ea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b584213297fb1e6df3804de8298c6e00479a12ea">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lu_CGA-Net_Category_Guided_Aggregation_for_Point_Cloud_Semantic_Segmentation_CVPR_2021_paper.html">CGA-Net: Category Guided Aggregation for Point Cloud Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="2972bd6cb49883a5c75e26f8f7266dc91e1af25a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2972bd6cb49883a5c75e26f8f7266dc91e1af25a">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gamper_Multiple_Instance_Captioning_Learning_Representations_From_Histopathology_Textbooks_and_Articles_CVPR_2021_paper.html">Multiple Instance Captioning: Learning Representations From Histopathology Textbooks and Articles</a></th>
                    </tr>
                
                    <tr id="a828c8635c6afa57e5806ef8bf35865520827ff4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a828c8635c6afa57e5806ef8bf35865520827ff4">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fu_A_Multi-Task_Network_for_Joint_Specular_Highlight_Detection_and_Removal_CVPR_2021_paper.html">A Multi-Task Network for Joint Specular Highlight Detection and Removal</a></th>
                    </tr>
                
                    <tr id="d7a40ebebd8c00ff853b64ebecad366477bf0adb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d7a40ebebd8c00ff853b64ebecad366477bf0adb">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_IMAGINE_Image_Synthesis_by_Image-Guided_Model_Inversion_CVPR_2021_paper.html">IMAGINE: Image Synthesis by Image-Guided Model Inversion</a></th>
                    </tr>
                
                    <tr id="47312ef986c0b9574a4f60bef2d56cfdd09afa20">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47312ef986c0b9574a4f60bef2d56cfdd09afa20">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bauer_ReAgent_Point_Cloud_Registration_Using_Imitation_and_Reinforcement_Learning_CVPR_2021_paper.html">ReAgent: Point Cloud Registration using Imitation and Reinforcement Learning</a></th>
                    </tr>
                
                    <tr id="e02ca875cb8f23d5ebb7c9bb666634fbea6216a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e02ca875cb8f23d5ebb7c9bb666634fbea6216a2">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Onzon_Neural_Auto-Exposure_for_High-Dynamic_Range_Object_Detection_CVPR_2021_paper.html">Neural Auto-Exposure for High-Dynamic Range Object Detection</a></th>
                    </tr>
                
                    <tr id="3168089f726aa704c9deadac2070b829ad66367d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3168089f726aa704c9deadac2070b829ad66367d">11</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shen_S2-BNN_Bridging_the_Gap_Between_Self-Supervised_Real_and_1-Bit_Neural_CVPR_2021_paper.html">S2-BNN: Bridging the Gap Between Self-Supervised Real and 1-bit Neural Networks via Guided Distribution Calibration</a></th>
                    </tr>
                
                    <tr id="4fb2bf6df5e936b0b65a7d676fa0afaa4d87c501">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4fb2bf6df5e936b0b65a7d676fa0afaa4d87c501">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Yang_Multi-Modal_Bifurcated_Network_for_Depth_Guided_Image_Relighting_CVPRW_2021_paper.html">Multi-Modal Bifurcated Network for Depth Guided Image Relighting</a></th>
                    </tr>
                
                    <tr id="92ac9389fd065c535d666b30bd416ea7597d2acc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/92ac9389fd065c535d666b30bd416ea7597d2acc">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Hosler_Do_Deepfakes_Feel_Emotions_A_Semantic_Approach_to_Detecting_Deepfakes_CVPRW_2021_paper.html">Do Deepfakes Feel Emotions? A Semantic Approach to Detecting Deepfakes via Emotional Inconsistencies</a></th>
                    </tr>
                
                    <tr id="e132b0ae03abe3a6ed76e162eba2b97c373d108d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e132b0ae03abe3a6ed76e162eba2b97c373d108d">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Muglikar_How_To_Calibrate_Your_Event_Camera_CVPRW_2021_paper.html">How To Calibrate Your Event Camera</a></th>
                    </tr>
                
                    <tr id="c9db6a9b9428635117738303e65b6bf70148d793">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c9db6a9b9428635117738303e65b6bf70148d793">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AMFG/html/Chu_Part-Aware_Measurement_for_Robust_Multi-View_Multi-Human_3D_Pose_Estimation_and_CVPRW_2021_paper.html">Part-Aware Measurement for Robust Multi-View Multi-Human 3D Pose Estimation and Tracking</a></th>
                    </tr>
                
                    <tr id="64ae0581aa87edff1da62abce2e70114b9a1f617">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/64ae0581aa87edff1da62abce2e70114b9a1f617">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ISIC/html/Mirikharaji_D-LEMA_Deep_Learning_Ensembles_From_Multiple_Annotations_-_Application_to_CVPRW_2021_paper.html">D-LEMA: Deep Learning Ensembles From Multiple Annotations - Application to Skin Lesion Segmentation</a></th>
                    </tr>
                
                    <tr id="cb4921126d62dfd610237ec90d70ec99daf33ade">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cb4921126d62dfd610237ec90d70ec99daf33ade">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Du_Anchor-Based_Plain_Net_for_Mobile_Image_Super-Resolution_CVPRW_2021_paper.html">Anchor-Based Plain Net for Mobile Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="a47ef545d002c1daaf596ed048afbf152ba037f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a47ef545d002c1daaf596ed048afbf152ba037f2">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Ignatov_Fast_and_Accurate_Quantized_Camera_Scene_Detection_on_Smartphones_Mobile_CVPRW_2021_paper.html">Fast and Accurate Quantized Camera Scene Detection on Smartphones, Mobile AI 2021 Challenge: Report</a></th>
                    </tr>
                
                    <tr id="4c6207a203bcc7b725c41ed9c7451041530bf556">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c6207a203bcc7b725c41ed9c7451041530bf556">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Ragonesi_Learning_Unbiased_Representations_via_Mutual_Information_Backpropagation_CVPRW_2021_paper.html">Learning Unbiased Representations via Mutual Information Backpropagation</a></th>
                    </tr>
                
                    <tr id="a10bcfec38e04d0a2432827f1cee222a29135f72">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a10bcfec38e04d0a2432827f1cee222a29135f72">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Bhat_Distill_on_the_Go_Online_Knowledge_Distillation_in_Self-Supervised_Learning_CVPRW_2021_paper.html">Distill on the Go: Online Knowledge Distillation in Self-Supervised Learning</a></th>
                    </tr>
                
                    <tr id="8093040c477602ec7720ddf0421c84487a736ed0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8093040c477602ec7720ddf0421c84487a736ed0">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Sushko_One-Shot_GAN_Learning_To_Generate_Samples_From_Single_Images_and_CVPRW_2021_paper.html">One-Shot GAN: Learning To Generate Samples From Single Images and Videos</a></th>
                    </tr>
                
                    <tr id="3f430388245c8109beac68478f112aa30c54d776">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f430388245c8109beac68478f112aa30c54d776">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/HVU/html/Moon_IntegralAction_Pose-Driven_Feature_Integration_for_Robust_Human_Action_Recognition_in_CVPRW_2021_paper.html">IntegralAction: Pose-Driven Feature Integration for Robust Human Action Recognition in Videos</a></th>
                    </tr>
                
                    <tr id="1df56af79696fef734f26d495aaf888d4b2bff6f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1df56af79696fef734f26d495aaf888d4b2bff6f">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ChaLearn/html/Sincan_ChaLearn_LAP_Large_Scale_Signer_Independent_Isolated_Sign_Language_Recognition_CVPRW_2021_paper.html">ChaLearn LAP Large Scale Signer Independent Isolated Sign Language Recognition Challenge: Design, Results and Future Research</a></th>
                    </tr>
                
                    <tr id="1610d45240a0d7af41fa26c438bd4227a206b12d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1610d45240a0d7af41fa26c438bd4227a206b12d">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Masana_Ternary_Feature_Masks_Zero-Forgetting_for_Task-Incremental_Learning_CVPRW_2021_paper.html">Ternary Feature Masks: Zero-Forgetting for Task-Incremental Learning</a></th>
                    </tr>
                
                    <tr id="d197f6f0af202e0215ec09db1af814d0cd6c7231">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d197f6f0af202e0215ec09db1af814d0cd6c7231">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVPM/html/Schrumpf_Assessment_of_Deep_Learning_Based_Blood_Pressure_Prediction_From_PPG_CVPRW_2021_paper.html">Assessment of Deep Learning Based Blood Pressure Prediction From PPG and rPPG Signals</a></th>
                    </tr>
                
                    <tr id="3460f7e62682e1e4a5dd948a0051635048d35a8b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3460f7e62682e1e4a5dd948a0051635048d35a8b">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Specker_An_Occlusion-Aware_Multi-Target_Multi-Camera_Tracking_System_CVPRW_2021_paper.html">An Occlusion-Aware Multi-Target Multi-Camera Tracking System</a></th>
                    </tr>
                
                    <tr id="3943f1426b9991b5c39e04c9521fdf4fac20984c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3943f1426b9991b5c39e04c9521fdf4fac20984c">11</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/Koshkina_Contrastive_Learning_for_Sports_Video_Unsupervised_Player_Classification_CVPRW_2021_paper.html">Contrastive Learning for Sports Video: Unsupervised Player Classification</a></th>
                    </tr>
                
                    <tr id="e33d63405fec5d3cc8a9098ed99b922b0b812103">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e33d63405fec5d3cc8a9098ed99b922b0b812103">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Probabilistic_Model_Distillation_for_Semantic_Correspondence_CVPR_2021_paper.html">Probabilistic Model Distillation for Semantic Correspondence</a></th>
                    </tr>
                
                    <tr id="8ef5b7e1885f11759f607f323498fdce672e1ac1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8ef5b7e1885f11759f607f323498fdce672e1ac1">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cao_ReMix_Towards_Image-to-Image_Translation_With_Limited_Data_CVPR_2021_paper.html">ReMix: Towards Image-to-Image Translation With Limited Data</a></th>
                    </tr>
                
                    <tr id="5c266347cd384a44eb76c72f40a57b653ce9224b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c266347cd384a44eb76c72f40a57b653ce9224b">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Graber_Panoptic_Segmentation_Forecasting_CVPR_2021_paper.html">Panoptic Segmentation Forecasting</a></th>
                    </tr>
                
                    <tr id="2d7e4b2c3d69e9d3af12f4e1c90cab1dab4e1776">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d7e4b2c3d69e9d3af12f4e1c90cab1dab4e1776">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Meng_Connecting_What_To_Say_With_Where_To_Look_by_Modeling_CVPR_2021_paper.html">Connecting What To Say With Where To Look by Modeling Human Attention Traces</a></th>
                    </tr>
                
                    <tr id="62fb4a32549287b8850dcaee0b1dfa8e6566cd26">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/62fb4a32549287b8850dcaee0b1dfa8e6566cd26">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dusmanu_Privacy-Preserving_Image_Features_via_Adversarial_Affine_Subspace_Embeddings_CVPR_2021_paper.html">Privacy-Preserving Image Features via Adversarial Affine Subspace Embeddings</a></th>
                    </tr>
                
                    <tr id="b1db2077cecda0728733f6d293d1bcbc861e48d5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b1db2077cecda0728733f6d293d1bcbc861e48d5">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Charoenphakdee_On_Focal_Loss_for_Class-Posterior_Probability_Estimation_A_Theoretical_Perspective_CVPR_2021_paper.html">On Focal Loss for Class-Posterior Probability Estimation: A Theoretical Perspective</a></th>
                    </tr>
                
                    <tr id="321c41a1645b4a5e4791970d9ed135fe693df2f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/321c41a1645b4a5e4791970d9ed135fe693df2f1">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_SIPSA-Net_Shift-Invariant_Pan_Sharpening_With_Moving_Object_Alignment_for_Satellite_CVPR_2021_paper.html">SIPSA-Net: Shift-Invariant Pan Sharpening With Moving Object Alignment for Satellite Imagery</a></th>
                    </tr>
                
                    <tr id="ee21abe3f65b9830f3762e455507daa0b21691ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ee21abe3f65b9830f3762e455507daa0b21691ac">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jeon_Mining_Better_Samples_for_Contrastive_Learning_of_Temporal_Correspondence_CVPR_2021_paper.html">Mining Better Samples for Contrastive Learning of Temporal Correspondence</a></th>
                    </tr>
                
                    <tr id="8888c82729866b4fd9692461f86ddace104cebc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8888c82729866b4fd9692461f86ddace104cebc1">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hosseinzadeh_Image_Change_Captioning_by_Learning_From_an_Auxiliary_Task_CVPR_2021_paper.html">Image Change Captioning by Learning From an Auxiliary Task</a></th>
                    </tr>
                
                    <tr id="01b83275e3e71f8568271a14817f1dc40fe4b7fa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01b83275e3e71f8568271a14817f1dc40fe4b7fa">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jia_Intentonomy_A_Dataset_and_Study_Towards_Human_Intent_Understanding_CVPR_2021_paper.html">Intentonomy: A Dataset and Study Towards Human Intent Understanding</a></th>
                    </tr>
                
                    <tr id="3367da340ae2c66c1e872d875da6fab8acd9cf4d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3367da340ae2c66c1e872d875da6fab8acd9cf4d">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Demmel_Square_Root_Bundle_Adjustment_for_Large-Scale_Reconstruction_CVPR_2021_paper.html">Square Root Bundle Adjustment for Large-Scale Reconstruction</a></th>
                    </tr>
                
                    <tr id="f9afc31d79ccd5e50c5440f369f7ca7202db466b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f9afc31d79ccd5e50c5440f369f7ca7202db466b">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_High-Fidelity_Face_Tracking_for_ARVR_via_Deep_Lighting_Adaptation_CVPR_2021_paper.html">High-Fidelity Face Tracking for AR/VR via Deep Lighting Adaptation</a></th>
                    </tr>
                
                    <tr id="db387333076b3492d6dfc0bffbaa720c61640bea">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db387333076b3492d6dfc0bffbaa720c61640bea">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sharma_Nighttime_Visibility_Enhancement_by_Increasing_the_Dynamic_Range_and_Suppression_CVPR_2021_paper.html">Nighttime Visibility Enhancement by Increasing the Dynamic Range and Suppression of Light Effects</a></th>
                    </tr>
                
                    <tr id="3f762c399c6eeb184cfff9c8047c8e4fea626776">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3f762c399c6eeb184cfff9c8047c8e4fea626776">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Repetitive_Activity_Counting_by_Sight_and_Sound_CVPR_2021_paper.html">Repetitive Activity Counting by Sight and Sound</a></th>
                    </tr>
                
                    <tr id="e1b90ef6dee37340ac0ca175ca5aa5e2bda9294c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e1b90ef6dee37340ac0ca175ca5aa5e2bda9294c">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_a_Non-Blind_Deblurring_Network_for_Night_Blurry_Images_CVPR_2021_paper.html">Learning a Non-Blind Deblurring Network for Night Blurry Images</a></th>
                    </tr>
                
                    <tr id="4e91aa3a2847cf0aa7f06342b9e33611c2e7fc87">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4e91aa3a2847cf0aa7f06342b9e33611c2e7fc87">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fieraru_AIFit_Automatic_3D_Human-Interpretable_Feedback_Models_for_Fitness_Training_CVPR_2021_paper.html">AIFit: Automatic 3D Human-Interpretable Feedback Models for Fitness Training</a></th>
                    </tr>
                
                    <tr id="e37da64aaa1237e2833aefcca0d8cc96eeb588f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e37da64aaa1237e2833aefcca0d8cc96eeb588f5">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Virtual_Fully-Connected_Layer_Training_a_Large-Scale_Face_Recognition_Dataset_With_CVPR_2021_paper.html">Virtual Fully-Connected Layer: Training a Large-Scale Face Recognition Dataset With Limited Computational Resources</a></th>
                    </tr>
                
                    <tr id="a02d79cdcd85bb8d3272e44daca0df5303e485c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a02d79cdcd85bb8d3272e44daca0df5303e485c0">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hampali_Monte_Carlo_Scene_Search_for_3D_Scene_Understanding_CVPR_2021_paper.html">Monte Carlo Scene Search for 3D Scene Understanding</a></th>
                    </tr>
                
                    <tr id="0e3a7035672d19abd71f72c612be0d1caeecb63c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e3a7035672d19abd71f72c612be0d1caeecb63c">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bai_GMOT-40_A_Benchmark_for_Generic_Multiple_Object_Tracking_CVPR_2021_paper.html">GMOT-40: A Benchmark for Generic Multiple Object Tracking</a></th>
                    </tr>
                
                    <tr id="5688ada5bf8013a023de9330f04044fac87c9eb5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5688ada5bf8013a023de9330f04044fac87c9eb5">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Improving_Accuracy_of_Binary_Neural_Networks_Using_Unbalanced_Activation_Distribution_CVPR_2021_paper.html">Improving Accuracy of Binary Neural Networks Using Unbalanced Activation Distribution</a></th>
                    </tr>
                
                    <tr id="4ace41d069bc320719b543fb90b4ecf09c3bb29e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ace41d069bc320719b543fb90b4ecf09c3bb29e">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Germain_Neural_Reprojection_Error_Merging_Feature_Learning_and_Camera_Pose_Estimation_CVPR_2021_paper.html">Neural Reprojection Error: Merging Feature Learning and Camera Pose Estimation</a></th>
                    </tr>
                
                    <tr id="f7d1f69c1f599fb5a4840e3eb696a0645210d392">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7d1f69c1f599fb5a4840e3eb696a0645210d392">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kokkinos_Learning_Monocular_3D_Reconstruction_of_Articulated_Categories_From_Motion_CVPR_2021_paper.html">Learning Monocular 3D Reconstruction of Articulated Categories From Motion</a></th>
                    </tr>
                
                    <tr id="5f395f0820e0bf8d364a4ffeffa28bf7936e2d11">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f395f0820e0bf8d364a4ffeffa28bf7936e2d11">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Spatially-Varying_Outdoor_Lighting_Estimation_From_Intrinsics_CVPR_2021_paper.html">Spatially-Varying Outdoor Lighting Estimation From Intrinsics</a></th>
                    </tr>
                
                    <tr id="a06dbb8f663110065d88dc73e4b48a005ba734a0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a06dbb8f663110065d88dc73e4b48a005ba734a0">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Learning_to_Track_Instances_without_Video_Annotations_CVPR_2021_paper.html">Learning to Track Instances without Video Annotations</a></th>
                    </tr>
                
                    <tr id="38a31bdbdb45191fd0059960c0976b27a2e58384">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38a31bdbdb45191fd0059960c0976b27a2e58384">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Rotation-Only_Bundle_Adjustment_CVPR_2021_paper.html">Rotation-Only Bundle Adjustment</a></th>
                    </tr>
                
                    <tr id="8c131dfffd9c99ba208d5bf270ce0fbc4b6bbca5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c131dfffd9c99ba208d5bf270ce0fbc4b6bbca5">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Duggal_Compatibility-Aware_Heterogeneous_Visual_Search_CVPR_2021_paper.html">Compatibility-Aware Heterogeneous Visual Search</a></th>
                    </tr>
                
                    <tr id="3ab0ac6f43681e514194606ab3207fe39fddc084">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ab0ac6f43681e514194606ab3207fe39fddc084">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_A_Self-Boosting_Framework_for_Automated_Radiographic_Report_Generation_CVPR_2021_paper.html">A Self-Boosting Framework for Automated Radiographic Report Generation</a></th>
                    </tr>
                
                    <tr id="639f6a3c03aeb5bb7fa45790adb94cd2e1c8479d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/639f6a3c03aeb5bb7fa45790adb94cd2e1c8479d">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Son_SRWarp_Generalized_Image_Super-Resolution_under_Arbitrary_Transformation_CVPR_2021_paper.html">SRWarp: Generalized Image Super-Resolution under Arbitrary Transformation</a></th>
                    </tr>
                
                    <tr id="ba701f89513e3f11d77050d6004dccddd69655a7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ba701f89513e3f11d77050d6004dccddd69655a7">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chang_Towards_Robust_Classification_Model_by_Counterfactual_and_Invariant_Data_Generation_CVPR_2021_paper.html">Towards Robust Classification Model by Counterfactual and Invariant Data Generation</a></th>
                    </tr>
                
                    <tr id="a6940935385cd8feeadf979e36dde37af499ca0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a6940935385cd8feeadf979e36dde37af499ca0c">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Continual_Learning_via_Bit-Level_Information_Preserving_CVPR_2021_paper.html">Continual Learning via Bit-Level Information Preserving</a></th>
                    </tr>
                
                    <tr id="1a7586571ec088deea57bc43a96479f37e8d3130">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a7586571ec088deea57bc43a96479f37e8d3130">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Deep_Graph_Matching_Under_Quadratic_Constraint_CVPR_2021_paper.html">Deep Graph Matching Under Quadratic Constraint</a></th>
                    </tr>
                
                    <tr id="f0aec4c72f9fab03ed8fbdf60253593da3b6b5ba">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f0aec4c72f9fab03ed8fbdf60253593da3b6b5ba">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Spatiotemporal_Registration_for_Event-Based_Visual_Odometry_CVPR_2021_paper.html">Spatiotemporal Registration for Event-Based Visual Odometry</a></th>
                    </tr>
                
                    <tr id="e997292fc4b4af2fbc83e5970afb76d2f0f0633f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e997292fc4b4af2fbc83e5970afb76d2f0f0633f">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Learning_To_Aggregate_and_Personalize_3D_Face_From_In-the-Wild_Photo_CVPR_2021_paper.html">Learning To Aggregate and Personalize 3D Face From In-the-Wild Photo Collection</a></th>
                    </tr>
                
                    <tr id="1df3685d9dcdd218476a25c55d6ad5578a528878">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1df3685d9dcdd218476a25c55d6ad5578a528878">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jing_Turning_Frequency_to_Resolution_Video_Super-Resolution_via_Event_Cameras_CVPR_2021_paper.html">Turning Frequency to Resolution: Video Super-Resolution via Event Cameras</a></th>
                    </tr>
                
                    <tr id="837d57006a94a308bbceff0481917fdd41094be9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/837d57006a94a308bbceff0481917fdd41094be9">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bei_Learning_Semantic-Aware_Dynamics_for_Video_Prediction_CVPR_2021_paper.html">Learning Semantic-Aware Dynamics for Video Prediction</a></th>
                    </tr>
                
                    <tr id="7c16d2ebee10aa394cb49091c0dcaad42e8f49cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c16d2ebee10aa394cb49091c0dcaad42e8f49cd">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Automatic_Vertebra_Localization_and_Identification_in_CT_by_Spine_Rectification_CVPR_2021_paper.html">Automatic Vertebra Localization and Identification in CT by Spine Rectification and Anatomically-Constrained Optimization</a></th>
                    </tr>
                
                    <tr id="cff3dc39a7ae12d9df0a162b26eb8892815f7871">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cff3dc39a7ae12d9df0a162b26eb8892815f7871">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Revisiting_Knowledge_Distillation_An_Inheritance_and_Exploration_Framework_CVPR_2021_paper.html">Revisiting Knowledge Distillation: An Inheritance and Exploration Framework</a></th>
                    </tr>
                
                    <tr id="d99e0d98113083788121d93e9d15dc522af83ff6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d99e0d98113083788121d93e9d15dc522af83ff6">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Taherkhani_Self-Supervised_Wasserstein_Pseudo-Labeling_for_Semi-Supervised_Image_Classification_CVPR_2021_paper.html">Self-Supervised Wasserstein Pseudo-Labeling for Semi-Supervised Image Classification</a></th>
                    </tr>
                
                    <tr id="77bde604fba5d5052905d2dfe82b9f90cb0cf411">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/77bde604fba5d5052905d2dfe82b9f90cb0cf411">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fukao_Polarimetric_Normal_Stereo_CVPR_2021_paper.html">Polarimetric Normal Stereo</a></th>
                    </tr>
                
                    <tr id="802a609f1ffee95e57cea85fa62b4f6c2ad42d60">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/802a609f1ffee95e57cea85fa62b4f6c2ad42d60">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jiang_Learning_Compositional_Representation_for_4D_Captures_With_Neural_ODE_CVPR_2021_paper.html">Learning Compositional Representation for 4D Captures With Neural ODE</a></th>
                    </tr>
                
                    <tr id="aabe743b8b05f3d1a91d2421779d75f010649e72">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aabe743b8b05f3d1a91d2421779d75f010649e72">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xiao_You_See_What_I_Want_You_To_See_Exploring_Targeted_CVPR_2021_paper.html">You See What I Want You To See: Exploring Targeted Black-Box Transferability Attack for Hash-Based Image Retrieval Systems</a></th>
                    </tr>
                
                    <tr id="e4cebaa9c2a36bce80cce508c0c8d70b1816127c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e4cebaa9c2a36bce80cce508c0c8d70b1816127c">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gao_Isometric_Multi-Shape_Matching_CVPR_2021_paper.html">Isometric Multi-Shape Matching</a></th>
                    </tr>
                
                    <tr id="614a5afd870d734642df04fa758fca2e12958856">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/614a5afd870d734642df04fa758fca2e12958856">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Savarese_Domain-Independent_Dominance_of_Adaptive_Methods_CVPR_2021_paper.html">Domain-Independent Dominance of Adaptive Methods</a></th>
                    </tr>
                
                    <tr id="4438c6982ece53c8cb20eb7daf7a654b3b173c9c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4438c6982ece53c8cb20eb7daf7a654b3b173c9c">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Scene_Text_Telescope_Text-Focused_Scene_Image_Super-Resolution_CVPR_2021_paper.html">Scene Text Telescope: Text-Focused Scene Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="884b0fe671f2227d10bcb04ac61767a7371bd64e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/884b0fe671f2227d10bcb04ac61767a7371bd64e">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Taskology_Utilizing_Task_Relations_at_Scale_CVPR_2021_paper.html">Taskology: Utilizing Task Relations at Scale</a></th>
                    </tr>
                
                    <tr id="49621dd28e603232e5c1083e2038b606a9018028">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/49621dd28e603232e5c1083e2038b606a9018028">10</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chadha_Deep_Perceptual_Preprocessing_for_Video_Coding_CVPR_2021_paper.html">Deep Perceptual Preprocessing for Video Coding</a></th>
                    </tr>
                
                    <tr id="91425ace0d1cd3ff144184b85b7e55ba865ae82a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/91425ace0d1cd3ff144184b85b7e55ba865ae82a">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Horvath_Manipulation_Detection_in_Satellite_Images_Using_Vision_Transformer_CVPRW_2021_paper.html">Manipulation Detection in Satellite Images Using Vision Transformer</a></th>
                    </tr>
                
                    <tr id="30c03e22475e856add035182988dfc720e84a4b9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/30c03e22475e856add035182988dfc720e84a4b9">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Nguyen_Self-Supervised_Multi-Image_Super-Resolution_for_Push-Frame_Satellite_Images_CVPRW_2021_paper.html">Self-Supervised Multi-Image Super-Resolution for Push-Frame Satellite Images</a></th>
                    </tr>
                
                    <tr id="06ea6bffa1c1542a306254bd6bb3daa6d752594b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/06ea6bffa1c1542a306254bd6bb3daa6d752594b">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Delbruck_Feedback_Control_of_Event_Cameras_CVPRW_2021_paper.html">Feedback Control of Event Cameras</a></th>
                    </tr>
                
                    <tr id="1b69ecb91eb8007a6aa38608f35eaa3102c1c883">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1b69ecb91eb8007a6aa38608f35eaa3102c1c883">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AMFG/html/Fard_ASMNet_A_Lightweight_Deep_Neural_Network_for_Face_Alignment_and_CVPRW_2021_paper.html">ASMNet: A Lightweight Deep Neural Network for Face Alignment and Pose Estimation</a></th>
                    </tr>
                
                    <tr id="60dd8f53b98d875428d31fa89ac6db8b161ba5b0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/60dd8f53b98d875428d31fa89ac6db8b161ba5b0">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Rahman_An_Improved_Attention_for_Visual_Question_Answering_CVPRW_2021_paper.html">An Improved Attention for Visual Question Answering</a></th>
                    </tr>
                
                    <tr id="a97e8aa628ae2e3fbb03c25df2f2a3c1432a2f3b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a97e8aa628ae2e3fbb03c25df2f2a3c1432a2f3b">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Cho_Dealing_With_Missing_Modalities_in_the_Visual_Question_Answer-Difference_Prediction_CVPRW_2021_paper.html">Dealing With Missing Modalities in the Visual Question Answer-Difference Prediction Task Through Knowledge Distillation</a></th>
                    </tr>
                
                    <tr id="abc07a0f4841e465329b023ec162e645fe094f8e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/abc07a0f4841e465329b023ec162e645fe094f8e">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WAD/html/Laddha_MVFuseNet_Improving_End-to-End_Object_Detection_and_Motion_Forecasting_Through_Multi-View_CVPRW_2021_paper.html">MVFuseNet: Improving End-to-End Object Detection and Motion Forecasting Through Multi-View Fusion of LiDAR Data</a></th>
                    </tr>
                
                    <tr id="3015614ffb2d7e6968146a3693aedcbf00ed7959">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3015614ffb2d7e6968146a3693aedcbf00ed7959">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/HVU/html/Hu_SAIL-VOS_3D_A_Synthetic_Dataset_and_Baselines_for_Object_Detection_CVPRW_2021_paper.html">SAIL-VOS 3D: A Synthetic Dataset and Baselines for Object Detection and 3D Mesh Reconstruction From Video Data</a></th>
                    </tr>
                
                    <tr id="d54e747c3f1efabc578879094a0116b20ad90f03">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d54e747c3f1efabc578879094a0116b20ad90f03">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ChaLearn/html/Vazquez-Enriquez_Isolated_Sign_Language_Recognition_With_Multi-Scale_Spatial-Temporal_Graph_Convolutional_Networks_CVPRW_2021_paper.html">Isolated Sign Language Recognition With Multi-Scale Spatial-Temporal Graph Convolutional Networks</a></th>
                    </tr>
                
                    <tr id="616044560d05e316bcd331b0397fad2e4e71a62b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/616044560d05e316bcd331b0397fad2e4e71a62b">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Huynh_A_Strong_Baseline_for_Vehicle_Re-Identification_CVPRW_2021_paper.html">A Strong Baseline for Vehicle Re-Identification</a></th>
                    </tr>
                
                    <tr id="c5bd40295764aa4180c5100e09c1bbc2d8bf265b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c5bd40295764aa4180c5100e09c1bbc2d8bf265b">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/PBVS/html/Prajapati_Channel_Split_Convolutional_Neural_Network_ChaSNet_for_Thermal_Image_Super-Resolution_CVPRW_2021_paper.html">Channel Split Convolutional Neural Network (ChaSNet) for Thermal Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="1f8f6a63f8586cb491a1ba9955f94104e80f7efd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1f8f6a63f8586cb491a1ba9955f94104e80f7efd">10</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/BiVision/html/Chen_BNN_-_BN___Training_Binary_Neural_Networks_Without_CVPRW_2021_paper.html">&#34;BNN - BN = ?&#34;: Training Binary Neural Networks Without Batch Normalization</a></th>
                    </tr>
                
                    <tr id="3c80296126592b85257034a5427b1b3c62030268">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3c80296126592b85257034a5427b1b3c62030268">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_VirFace_Enhancing_Face_Recognition_via_Unlabeled_Shallow_Data_CVPR_2021_paper.html">VirFace: Enhancing Face Recognition via Unlabeled Shallow Data</a></th>
                    </tr>
                
                    <tr id="7fc3f7226e5f231a587e198d25b045396296ebcb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7fc3f7226e5f231a587e198d25b045396296ebcb">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_DualGraph_A_Graph-Based_Method_for_Reasoning_About_Label_Noise_CVPR_2021_paper.html">DualGraph: A Graph-Based Method for Reasoning About Label Noise</a></th>
                    </tr>
                
                    <tr id="2111081ea36376d5e3ec3cf9f50f3a626114ea52">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2111081ea36376d5e3ec3cf9f50f3a626114ea52">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_DeepACG_Co-Saliency_Detection_via_Semantic-Aware_Contrast_Gromov-Wasserstein_Distance_CVPR_2021_paper.html">DeepACG: Co-Saliency Detection via Semantic-Aware Contrast Gromov-Wasserstein Distance</a></th>
                    </tr>
                
                    <tr id="fcba11e0a4b4c1430c729f773fd0906e6df2d099">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fcba11e0a4b4c1430c729f773fd0906e6df2d099">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Toward_Joint_Thing-and-Stuff_Mining_for_Weakly_Supervised_Panoptic_Segmentation_CVPR_2021_paper.html">Toward Joint Thing-and-Stuff Mining for Weakly Supervised Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="309dfb0cb6b2730b97ba227df96c63a507118a0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/309dfb0cb6b2730b97ba227df96c63a507118a0c">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Intelligent_Carpet_Inferring_3D_Human_Pose_From_Tactile_Signals_CVPR_2021_paper.html">Intelligent Carpet: Inferring 3D Human Pose From Tactile Signals</a></th>
                    </tr>
                
                    <tr id="98dd2e74993bae0e6840d42c7ae19cba328b2ea9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/98dd2e74993bae0e6840d42c7ae19cba328b2ea9">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Attention-Guided_Image_Compression_by_Deep_Reconstruction_of_Compressive_Sensed_Saliency_CVPR_2021_paper.html">Attention-Guided Image Compression by Deep Reconstruction of Compressive Sensed Saliency Skeleton</a></th>
                    </tr>
                
                    <tr id="14c9fed3842b6116ab2d768e9356630ffa835d85">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/14c9fed3842b6116ab2d768e9356630ffa835d85">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_DeepMetaHandles_Learning_Deformation_Meta-Handles_of_3D_Meshes_With_Biharmonic_Coordinates_CVPR_2021_paper.html">DeepMetaHandles: Learning Deformation Meta-Handles of 3D Meshes With Biharmonic Coordinates</a></th>
                    </tr>
                
                    <tr id="6004f33a4e5098c4484c9f66145482c1e733a471">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6004f33a4e5098c4484c9f66145482c1e733a471">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_Student_Networks_in_the_Wild_CVPR_2021_paper.html">Learning Student Networks in the Wild</a></th>
                    </tr>
                
                    <tr id="ad778a8b70583f0f04e13d9034814b786f90de5b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ad778a8b70583f0f04e13d9034814b786f90de5b">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ashraf_Dogfight_Detecting_Drones_From_Drones_Videos_CVPR_2021_paper.html">Dogfight: Detecting Drones From Drones Videos</a></th>
                    </tr>
                
                    <tr id="6f4490cfc05763b420ee2eb961a64f041e2c53c2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6f4490cfc05763b420ee2eb961a64f041e2c53c2">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Das_Cloud2Curve_Generation_and_Vectorization_of_Parametric_Sketches_CVPR_2021_paper.html">Cloud2Curve: Generation and Vectorization of Parametric Sketches</a></th>
                    </tr>
                
                    <tr id="2e0bc6cc4153025cd37d957cb896abe237502cd5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e0bc6cc4153025cd37d957cb896abe237502cd5">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jaques_NewtonianVAE_Proportional_Control_and_Goal_Identification_From_Pixels_via_Physical_CVPR_2021_paper.html">NewtonianVAE: Proportional Control and Goal Identification From Pixels via Physical Latent Spaces</a></th>
                    </tr>
                
                    <tr id="1789ada5ec6d359d579366ebcd56d7eb97f9dc6e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1789ada5ec6d359d579366ebcd56d7eb97f9dc6e">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Fingerspelling_Detection_in_American_Sign_Language_CVPR_2021_paper.html">Fingerspelling Detection in American Sign Language</a></th>
                    </tr>
                
                    <tr id="68f21cbd2d5001528c07b16d27b8d4de5d6544e2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/68f21cbd2d5001528c07b16d27b8d4de5d6544e2">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kar_Zero-Shot_Single_Image_Restoration_Through_Controlled_Perturbation_of_Koschmieders_Model_CVPR_2021_paper.html">Zero-Shot Single Image Restoration Through Controlled Perturbation of Koschmieder&#39;s Model</a></th>
                    </tr>
                
                    <tr id="94c3167643d527e0a7b02a27b35a035f11c88d2b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/94c3167643d527e0a7b02a27b35a035f11c88d2b">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bechtold_Fostering_Generalization_in_Single-View_3D_Reconstruction_by_Learning_a_Hierarchy_CVPR_2021_paper.html">Fostering Generalization in Single-View 3D Reconstruction by Learning a Hierarchy of Local and Global Shape Priors</a></th>
                    </tr>
                
                    <tr id="f49db3dbfa02a88205e98e1504f3e52b66b0cb3e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f49db3dbfa02a88205e98e1504f3e52b66b0cb3e">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Seeking_the_Shape_of_Sound_An_Adaptive_Framework_for_Learning_CVPR_2021_paper.html">Seeking the Shape of Sound: An Adaptive Framework for Learning Voice-Face Association</a></th>
                    </tr>
                
                    <tr id="f513fd50710d762c0cbaf4f566ebb74defedb100">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f513fd50710d762c0cbaf4f566ebb74defedb100">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_KSM_Fast_Multiple_Task_Adaption_via_Kernel-Wise_Soft_Mask_Learning_CVPR_2021_paper.html">KSM: Fast Multiple Task Adaption via Kernel-Wise Soft Mask Learning</a></th>
                    </tr>
                
                    <tr id="36d57a83098d394538482aa8ffc85127ad45ef10">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/36d57a83098d394538482aa8ffc85127ad45ef10">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Burns_Limitations_of_Post-Hoc_Feature_Alignment_for_Robustness_CVPR_2021_paper.html">Limitations of Post-Hoc Feature Alignment for Robustness</a></th>
                    </tr>
                
                    <tr id="36e26a5fc994958573ab0275dd61083935f90865">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/36e26a5fc994958573ab0275dd61083935f90865">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Blattmann_Behavior-Driven_Synthesis_of_Human_Dynamics_CVPR_2021_paper.html">Behavior-Driven Synthesis of Human Dynamics</a></th>
                    </tr>
                
                    <tr id="d259b0e3741c135f4f295513e460cd78b51c8da9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d259b0e3741c135f4f295513e460cd78b51c8da9">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Anchor-Constrained_Viterbi_for_Set-Supervised_Action_Segmentation_CVPR_2021_paper.html">Anchor-Constrained Viterbi for Set-Supervised Action Segmentation</a></th>
                    </tr>
                
                    <tr id="fe5d894de5b90010391e70974798617e1f90b487">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fe5d894de5b90010391e70974798617e1f90b487">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Panoramic_Image_Reflection_Removal_CVPR_2021_paper.html">Panoramic Image Reflection Removal</a></th>
                    </tr>
                
                    <tr id="83928aa5322b5933348bc0513b7f1155080c3ee2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/83928aa5322b5933348bc0513b7f1155080c3ee2">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Keypoint-Graph-Driven_Learning_Framework_for_Object_Pose_Estimation_CVPR_2021_paper.html">Keypoint-Graph-Driven Learning Framework for Object Pose Estimation</a></th>
                    </tr>
                
                    <tr id="56d833d15705e2805eb66281700d80b65666a5d8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/56d833d15705e2805eb66281700d80b65666a5d8">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liao_Towards_Good_Practices_for_Efficiently_Annotating_Large-Scale_Image_Classification_Datasets_CVPR_2021_paper.html">Towards Good Practices for Efficiently Annotating Large-Scale Image Classification Datasets</a></th>
                    </tr>
                
                    <tr id="6c2eb7500929df41c462eb6b676a3c496cc496e2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c2eb7500929df41c462eb6b676a3c496cc496e2">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tong_FaceSec_A_Fine-Grained_Robustness_Evaluation_Framework_for_Face_Recognition_Systems_CVPR_2021_paper.html">FaceSec: A Fine-Grained Robustness Evaluation Framework for Face Recognition Systems</a></th>
                    </tr>
                
                    <tr id="639fbed94e8ff678d93a7b11d22f0df604c37504">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/639fbed94e8ff678d93a7b11d22f0df604c37504">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Optimal_Gradient_Checkpoint_Search_for_Arbitrary_Computation_Graphs_CVPR_2021_paper.html">Optimal Gradient Checkpoint Search for Arbitrary Computation Graphs</a></th>
                    </tr>
                
                    <tr id="144c60aa0faf4cc12d8f812e0afe50160a99342c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/144c60aa0faf4cc12d8f812e0afe50160a99342c">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gu_Capsule_Network_Is_Not_More_Robust_Than_Convolutional_Network_CVPR_2021_paper.html">Capsule Network Is Not More Robust Than Convolutional Network</a></th>
                    </tr>
                
                    <tr id="2d5bf52ef20881cd35468bdb481e91e0a97b7cc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d5bf52ef20881cd35468bdb481e91e0a97b7cc1">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Learning_Feature_Aggregation_for_Deep_3D_Morphable_Models_CVPR_2021_paper.html">Learning Feature Aggregation for Deep 3D Morphable Models</a></th>
                    </tr>
                
                    <tr id="494dbfeb6de7f040d32ee7fc0446eac83bdb003c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/494dbfeb6de7f040d32ee7fc0446eac83bdb003c">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wen_Learning_Progressive_Point_Embeddings_for_3D_Point_Cloud_Generation_CVPR_2021_paper.html">Learning Progressive Point Embeddings for 3D Point Cloud Generation</a></th>
                    </tr>
                
                    <tr id="307695c6a66c59ad4fee568f5e320bd785121e4b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/307695c6a66c59ad4fee568f5e320bd785121e4b">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Heo_Guided_Interactive_Video_Object_Segmentation_Using_Reliability-Based_Attention_Maps_CVPR_2021_paper.html">Guided Interactive Video Object Segmentation Using Reliability-Based Attention Maps</a></th>
                    </tr>
                
                    <tr id="b474efb0ec484a67c4ed3acc0c34a28996c4b689">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b474efb0ec484a67c4ed3acc0c34a28996c4b689">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bhattacharyya_Euro-PVI_Pedestrian_Vehicle_Interactions_in_Dense_Urban_Centers_CVPR_2021_paper.html">Euro-PVI: Pedestrian Vehicle Interactions in Dense Urban Centers</a></th>
                    </tr>
                
                    <tr id="6e71036fa5dd4b5ceaa3502f5dc3b3a280b41126">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6e71036fa5dd4b5ceaa3502f5dc3b3a280b41126">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_A_Circular-Structured_Representation_for_Visual_Emotion_Distribution_Learning_CVPR_2021_paper.html">A Circular-Structured Representation for Visual Emotion Distribution Learning</a></th>
                    </tr>
                
                    <tr id="d0b2cbe54f77ef34884b65dbfe8fce02d2b1e636">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d0b2cbe54f77ef34884b65dbfe8fce02d2b1e636">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Piergiovanni_Recognizing_Actions_in_Videos_From_Unseen_Viewpoints_CVPR_2021_paper.html">Recognizing Actions in Videos From Unseen Viewpoints</a></th>
                    </tr>
                
                    <tr id="7d55d9d6dedae90c26a12fd2aa462b73bb0a296a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7d55d9d6dedae90c26a12fd2aa462b73bb0a296a">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Perceptual_Indistinguishability-Net_PI-Net_Facial_Image_Obfuscation_With_Manipulable_Semantics_CVPR_2021_paper.html">Perceptual Indistinguishability-Net (PI-Net): Facial Image Obfuscation With Manipulable Semantics</a></th>
                    </tr>
                
                    <tr id="0833bed96c0a571782b4b31e90c730726b702595">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0833bed96c0a571782b4b31e90c730726b702595">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_MetaSets_Meta-Learning_on_Point_Sets_for_Generalizable_Representations_CVPR_2021_paper.html">MetaSets: Meta-Learning on Point Sets for Generalizable Representations</a></th>
                    </tr>
                
                    <tr id="3c44b04595d2098221d483767c1dc91bcd41c3bb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3c44b04595d2098221d483767c1dc91bcd41c3bb">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_CT-Net_Complementary_Transfering_Network_for_Garment_Transfer_With_Arbitrary_Geometric_CVPR_2021_paper.html">CT-Net: Complementary Transfering Network for Garment Transfer With Arbitrary Geometric Changes</a></th>
                    </tr>
                
                    <tr id="0ef3af6292cf5c4b94d6bc0b2cc9020457322dfe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ef3af6292cf5c4b94d6bc0b2cc9020457322dfe">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Hybrid_Rotation_Averaging_A_Fast_and_Robust_Rotation_Averaging_Approach_CVPR_2021_paper.html">Hybrid Rotation Averaging: A Fast and Robust Rotation Averaging Approach</a></th>
                    </tr>
                
                    <tr id="7e2c821943fedd29065801d26399492925a1fc56">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e2c821943fedd29065801d26399492925a1fc56">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Cross-MPI_Cross-Scale_Stereo_for_Image_Super-Resolution_Using_Multiplane_Images_CVPR_2021_paper.html">Cross-MPI: Cross-Scale Stereo for Image Super-Resolution Using Multiplane Images</a></th>
                    </tr>
                
                    <tr id="db373bb8b75d74baef533e58c3f3d08b0aa20b3f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db373bb8b75d74baef533e58c3f3d08b0aa20b3f">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_The_Heterogeneity_Hypothesis_Finding_Layer-Wise_Differentiated_Network_Architectures_CVPR_2021_paper.html">The Heterogeneity Hypothesis: Finding Layer-Wise Differentiated Network Architectures</a></th>
                    </tr>
                
                    <tr id="2b69c0960f169efeef98dce4173b93338f98e9b4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b69c0960f169efeef98dce4173b93338f98e9b4">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_A_Deep_Emulator_for_Secondary_Motion_of_3D_Characters_CVPR_2021_paper.html">A Deep Emulator for Secondary Motion of 3D Characters</a></th>
                    </tr>
                
                    <tr id="a2078de7a200dd73e867c4a0fef33bdbdb76df3d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a2078de7a200dd73e867c4a0fef33bdbdb76df3d">9</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Elliott_Explaining_Classifiers_Using_Adversarial_Perturbations_on_the_Perceptual_Ball_CVPR_2021_paper.html">Explaining Classifiers using Adversarial Perturbations on the Perceptual Ball</a></th>
                    </tr>
                
                    <tr id="08f61a32f617f63f44630b94fb29f391f6800883">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/08f61a32f617f63f44630b94fb29f391f6800883">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Ahn_Deep_Learning-Based_Distortion_Sensitivity_Prediction_for_Full-Reference_Image_Quality_Assessment_CVPRW_2021_paper.html">Deep Learning-Based Distortion Sensitivity Prediction for Full-Reference Image Quality Assessment</a></th>
                    </tr>
                
                    <tr id="5dd5fa4c2608471bde65bf87d8076ce5ff669592">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5dd5fa4c2608471bde65bf87d8076ce5ff669592">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Sharif_Beyond_Joint_Demosaicking_and_Denoising_An_Image_Processing_Pipeline_for_CVPRW_2021_paper.html">Beyond Joint Demosaicking and Denoising: An Image Processing Pipeline for a Pixel-Bin Image Sensor</a></th>
                    </tr>
                
                    <tr id="64236160dcc06a1370f2358c3e44b44d9054e796">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/64236160dcc06a1370f2358c3e44b44d9054e796">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Sharif_A_Two-Stage_Deep_Network_for_High_Dynamic_Range_Image_Reconstruction_CVPRW_2021_paper.html">A Two-Stage Deep Network for High Dynamic Range Image Reconstruction</a></th>
                    </tr>
                
                    <tr id="1b9e584f58389ea0299177b8338779503a484f45">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1b9e584f58389ea0299177b8338779503a484f45">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Hammou_EGB_Image_Quality_Assessment_Based_on_Ensemble_of_Gradient_Boosting_CVPRW_2021_paper.html">EGB: Image Quality Assessment Based on Ensemble of Gradient Boosting</a></th>
                    </tr>
                
                    <tr id="5d46dde2b4ca13968d3c0d5b4226856cafc083dc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5d46dde2b4ca13968d3c0d5b4226856cafc083dc">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Requena-Mesa_EarthNet2021_A_Large-Scale_Dataset_and_Challenge_for_Earth_Surface_Forecasting_CVPRW_2021_paper.html">EarthNet2021: A Large-Scale Dataset and Challenge for Earth Surface Forecasting as a Guided Video Prediction Task.</a></th>
                    </tr>
                
                    <tr id="c1fbcea73035a492b6ee3003a13479af9f1162f3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c1fbcea73035a492b6ee3003a13479af9f1162f3">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Tseng_Learning_To_Predict_Crop_Type_From_Heterogeneous_Sparse_Labels_Using_CVPRW_2021_paper.html">Learning To Predict Crop Type From Heterogeneous Sparse Labels Using Meta-Learning</a></th>
                    </tr>
                
                    <tr id="ae38e543fc93556e69c69794cc650bdd88093c50">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae38e543fc93556e69c69794cc650bdd88093c50">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LXCV/html/Pardo_BAOD_Budget-Aware_Object_Detection_CVPRW_2021_paper.html">BAOD: Budget-Aware Object Detection</a></th>
                    </tr>
                
                    <tr id="377549ac548d8bb458d4297325f983c85b6aec8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/377549ac548d8bb458d4297325f983c85b6aec8f">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Nehvi_Differentiable_Event_Stream_Simulator_for_Non-Rigid_3D_Tracking_CVPRW_2021_paper.html">Differentiable Event Stream Simulator for Non-Rigid 3D Tracking</a></th>
                    </tr>
                
                    <tr id="c75b2f8227a5dc3d3ce82edfc233f430ac6d46e8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c75b2f8227a5dc3d3ce82edfc233f430ac6d46e8">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Biometrics/html/Chaudhary_Differential_Morph_Face_Detection_Using_Discriminative_Wavelet_Sub-Bands_CVPRW_2021_paper.html">Differential Morph Face Detection Using Discriminative Wavelet Sub-Bands</a></th>
                    </tr>
                
                    <tr id="cd4d537976e1fcf8943ae6494eb26dc50ae0037f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cd4d537976e1fcf8943ae6494eb26dc50ae0037f">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Lee_Private-Shared_Disentangled_Multimodal_VAE_for_Learning_of_Latent_Representations_CVPRW_2021_paper.html">Private-Shared Disentangled Multimodal VAE for Learning of Latent Representations</a></th>
                    </tr>
                
                    <tr id="8093c81dcbc245706b77c5863007542f5da0322f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8093c81dcbc245706b77c5863007542f5da0322f">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Islam_Image_Compression_With_Recurrent_Neural_Network_and_Generalized_Divisive_Normalization_CVPRW_2021_paper.html">Image Compression With Recurrent Neural Network and Generalized Divisive Normalization</a></th>
                    </tr>
                
                    <tr id="0b261429ea89cd2c20efc2b77221f57147eb2ff8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0b261429ea89cd2c20efc2b77221f57147eb2ff8">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Swan_AI4MARS_A_Dataset_for_Terrain-Aware_Autonomous_Driving_on_Mars_CVPRW_2021_paper.html">AI4MARS: A Dataset for Terrain-Aware Autonomous Driving on Mars</a></th>
                    </tr>
                
                    <tr id="705d28ab55d65663ec5783302941e8eed2b99084">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/705d28ab55d65663ec5783302941e8eed2b99084">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WiCV/html/Dhingra_BGT-Net_Bidirectional_GRU_Transformer_Network_for_Scene_Graph_Generation_CVPRW_2021_paper.html">BGT-Net: Bidirectional GRU Transformer Network for Scene Graph Generation</a></th>
                    </tr>
                
                    <tr id="939cd1672701d22c57348aadf8d9942fe9954bc5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/939cd1672701d22c57348aadf8d9942fe9954bc5">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Hsyu_CSAnet_High_Speed_Channel_Spatial_Attention_Network_for_Mobile_ISP_CVPRW_2021_paper.html">CSAnet: High Speed Channel Spatial Attention Network for Mobile ISP</a></th>
                    </tr>
                
                    <tr id="cf58ef817c82cfaaa9693fc5900f6428ec5bc922">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cf58ef817c82cfaaa9693fc5900f6428ec5bc922">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Choi_MobileHumanPose_Toward_Real-Time_3D_Human_Pose_Estimation_in_Mobile_Devices_CVPRW_2021_paper.html">MobileHumanPose: Toward Real-Time 3D Human Pose Estimation in Mobile Devices</a></th>
                    </tr>
                
                    <tr id="e8493a900af742600c4f55530030f8d547eac78e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e8493a900af742600c4f55530030f8d547eac78e">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WAD/html/Ishihara_Multi-Task_Learning_With_Attention_for_End-to-End_Autonomous_Driving_CVPRW_2021_paper.html">Multi-Task Learning With Attention for End-to-End Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="d28e6325aed119d93fca0fad36035f3d1ba545ba">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d28e6325aed119d93fca0fad36035f3d1ba545ba">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/He_Generative_Zero-Shot_Network_Quantization_CVPRW_2021_paper.html">Generative Zero-Shot Network Quantization</a></th>
                    </tr>
                
                    <tr id="2777a33dec29cbefa0f84df8ec730a62ceea8e64">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2777a33dec29cbefa0f84df8ec730a62ceea8e64">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Chu_Discovering_Multi-Hardware_Mobile_Models_via_Architecture_Search_CVPRW_2021_paper.html">Discovering Multi-Hardware Mobile Models via Architecture Search</a></th>
                    </tr>
                
                    <tr id="b475d2e395f816889f2fa15fe450b457e2706f6f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b475d2e395f816889f2fa15fe450b457e2706f6f">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/VOCVALC/html/Raisi_Transformer-Based_Text_Detection_in_the_Wild_CVPRW_2021_paper.html">Transformer-Based Text Detection in the Wild</a></th>
                    </tr>
                
                    <tr id="5f9fd0df5b6e738b8111323ee6bb167de67d51c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f9fd0df5b6e738b8111323ee6bb167de67d51c0">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Choi_Dual-Teacher_Class-Incremental_Learning_With_Data-Free_Generative_Replay_CVPRW_2021_paper.html">Dual-Teacher Class-Incremental Learning With Data-Free Generative Replay</a></th>
                    </tr>
                
                    <tr id="252163327fe215b9c50a388a396d732a78210d34">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/252163327fe215b9c50a388a396d732a78210d34">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Luo_An_Empirical_Study_of_Vehicle_Re-Identification_on_the_AI_City_CVPRW_2021_paper.html">An Empirical Study of Vehicle Re-Identification on the AI City Challenge</a></th>
                    </tr>
                
                    <tr id="b1e516959cb23526b7db83dc2bc39123de9cca05">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b1e516959cb23526b7db83dc2bc39123de9cca05">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Zhao_Good_Practices_and_a_Strong_Baseline_for_Traffic_Anomaly_Detection_CVPRW_2021_paper.html">Good Practices and a Strong Baseline for Traffic Anomaly Detection</a></th>
                    </tr>
                
                    <tr id="f6410881eb68cb55d94c83b5698fc730d1528710">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f6410881eb68cb55d94c83b5698fc730d1528710">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/IMW/html/Efe_DFM_A_Performance_Baseline_for_Deep_Feature_Matching_CVPRW_2021_paper.html">DFM: A Performance Baseline for Deep Feature Matching</a></th>
                    </tr>
                
                    <tr id="de29859b266d5e8fe892e9f9dc2495e0d441172b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/de29859b266d5e8fe892e9f9dc2495e0d441172b">9</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/PBVS/html/Rivadeneira_Thermal_Image_Super-Resolution_Challenge_-_PBVS_2021_CVPRW_2021_paper.html">Thermal Image Super-Resolution Challenge - PBVS 2021</a></th>
                    </tr>
                
                    <tr id="81a4381176c4e01355bf03ca8147cd83ddae01d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/81a4381176c4e01355bf03ca8147cd83ddae01d4">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Baek_Polka_Lines_Learning_Structured_Illumination_and_Reconstruction_for_Active_Stereo_CVPR_2021_paper.html">Polka Lines: Learning Structured Illumination and Reconstruction for Active Stereo</a></th>
                    </tr>
                
                    <tr id="d518373bbe01c3898c702d7991257cdbb7479125">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d518373bbe01c3898c702d7991257cdbb7479125">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Fully_Understanding_Generic_Objects_Modeling_Segmentation_and_Reconstruction_CVPR_2021_paper.html">Fully Understanding Generic Objects: Modeling, Segmentation, and Reconstruction</a></th>
                    </tr>
                
                    <tr id="b91ffa452579b7dc8188154eafad809ab40c5781">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b91ffa452579b7dc8188154eafad809ab40c5781">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Safe_Local_Motion_Planning_With_Self-Supervised_Freespace_Forecasting_CVPR_2021_paper.html">Safe Local Motion Planning With Self-Supervised Freespace Forecasting</a></th>
                    </tr>
                
                    <tr id="b0e315be91555d78d995f91dacc5c125b91c793e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b0e315be91555d78d995f91dacc5c125b91c793e">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_DeepLM_Large-Scale_Nonlinear_Least_Squares_on_Deep_Learning_Frameworks_Using_CVPR_2021_paper.html">DeepLM: Large-Scale Nonlinear Least Squares on Deep Learning Frameworks Using Stochastic Domain Decomposition</a></th>
                    </tr>
                
                    <tr id="0c1cf8d40c82cedfa3f9ab399b3f8dbd7b49ea04">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c1cf8d40c82cedfa3f9ab399b3f8dbd7b49ea04">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cao_Normal_Integration_via_Inverse_Plane_Fitting_With_Minimum_Point-to-Plane_Distance_CVPR_2021_paper.html">Normal Integration via Inverse Plane Fitting With Minimum Point-to-Plane Distance</a></th>
                    </tr>
                
                    <tr id="9bbc7c272fed6609604ffed3754999d54f29e7ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9bbc7c272fed6609604ffed3754999d54f29e7ad">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Divergence_Optimization_for_Noisy_Universal_Domain_Adaptation_CVPR_2021_paper.html">Divergence Optimization for Noisy Universal Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="35ab453822e6e45ce58a8799aceb419d1f0631bd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/35ab453822e6e45ce58a8799aceb419d1f0631bd">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Layout-Guided_Novel_View_Synthesis_From_a_Single_Indoor_Panorama_CVPR_2021_paper.html">Layout-Guided Novel View Synthesis From a Single Indoor Panorama</a></th>
                    </tr>
                
                    <tr id="b36356f2cde9ba0c21b64684313c13bc41ed94a8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b36356f2cde9ba0c21b64684313c13bc41ed94a8">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Metadata_Normalization_CVPR_2021_paper.html">Metadata Normalization</a></th>
                    </tr>
                
                    <tr id="f725f078d030df9b93bb3590f13436261ccd7f93">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f725f078d030df9b93bb3590f13436261ccd7f93">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_End-to-End_Rotation_Averaging_With_Multi-Source_Propagation_CVPR_2021_paper.html">End-to-End Rotation Averaging With Multi-Source Propagation</a></th>
                    </tr>
                
                    <tr id="0f80014879c6bb8ff738e621283df0afb81ac86e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0f80014879c6bb8ff738e621283df0afb81ac86e">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qian_Roof-GAN_Learning_To_Generate_Roof_Geometry_and_Relations_for_Residential_CVPR_2021_paper.html">Roof-GAN: Learning To Generate Roof Geometry and Relations for Residential Houses</a></th>
                    </tr>
                
                    <tr id="4404cfa42c09c8072eb21a44fcb36b5e324627a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4404cfa42c09c8072eb21a44fcb36b5e324627a2">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chaudhuri_Semi-Supervised_Synthesis_of_High-Resolution_Editable_Textures_for_3D_Humans_CVPR_2021_paper.html">Semi-Supervised Synthesis of High-Resolution Editable Textures for 3D Humans</a></th>
                    </tr>
                
                    <tr id="b5f8fd5ecf9aa2b1d16fe172a319576ff5a62667">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b5f8fd5ecf9aa2b1d16fe172a319576ff5a62667">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Song_Towards_Diverse_Paragraph_Captioning_for_Untrimmed_Videos_CVPR_2021_paper.html">Towards Diverse Paragraph Captioning for Untrimmed Videos</a></th>
                    </tr>
                
                    <tr id="727e89a98628d0935a339e0c4d328c8c6307cdb5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/727e89a98628d0935a339e0c4d328c8c6307cdb5">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Awasthi_Adversarial_Robustness_Across_Representation_Spaces_CVPR_2021_paper.html">Adversarial Robustness Across Representation Spaces</a></th>
                    </tr>
                
                    <tr id="988959a957717cc7067341f8f1959c7368461952">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/988959a957717cc7067341f8f1959c7368461952">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_MagDR_Mask-Guided_Detection_and_Reconstruction_for_Defending_Deepfakes_CVPR_2021_paper.html">MagDR: Mask-Guided Detection and Reconstruction for Defending Deepfakes</a></th>
                    </tr>
                
                    <tr id="a826a3fdada1163b69b5e2041587abcebc7b9c1f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a826a3fdada1163b69b5e2041587abcebc7b9c1f">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qu_DAT_Training_Deep_Networks_Robust_To_Label-Noise_by_Matching_the_CVPR_2021_paper.html">DAT: Training Deep Networks Robust To Label-Noise by Matching the Feature Distributions</a></th>
                    </tr>
                
                    <tr id="ec85c1b5ce437069571eed550aaefbd4dafdb80a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ec85c1b5ce437069571eed550aaefbd4dafdb80a">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Single-Stage_Instance_Shadow_Detection_With_Bidirectional_Relation_Learning_CVPR_2021_paper.html">Single-Stage Instance Shadow Detection With Bidirectional Relation Learning</a></th>
                    </tr>
                
                    <tr id="c0092ed8ab5c3ab2a7e44a31061fb18db9d9ec4f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c0092ed8ab5c3ab2a7e44a31061fb18db9d9ec4f">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Deng_LAU-Net_Latitude_Adaptive_Upscaling_Network_for_Omnidirectional_Image_Super-Resolution_CVPR_2021_paper.html">LAU-Net: Latitude Adaptive Upscaling Network for Omnidirectional Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="3037ca6c9e0392ad7382c268caae8cab7ba90ea8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3037ca6c9e0392ad7382c268caae8cab7ba90ea8">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Barath_Efficient_Initial_Pose-Graph_Generation_for_Global_SfM_CVPR_2021_paper.html">Efficient Initial Pose-Graph Generation for Global SfM</a></th>
                    </tr>
                
                    <tr id="6b4cf0b58dd96836f8c2e4e357da93a9910f04ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6b4cf0b58dd96836f8c2e4e357da93a9910f04ab">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_3D_Video_Stabilization_With_Depth_Estimation_by_CNN-Based_Optimization_CVPR_2021_paper.html">3D Video Stabilization With Depth Estimation by CNN-Based Optimization</a></th>
                    </tr>
                
                    <tr id="6854b00854f2b31f7e273c5dc19540314640dcdc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6854b00854f2b31f7e273c5dc19540314640dcdc">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Predicting_Human_Scanpaths_in_Visual_Question_Answering_CVPR_2021_paper.html">Predicting Human Scanpaths in Visual Question Answering</a></th>
                    </tr>
                
                    <tr id="54faf0f3e4f101100ae29bc52197254b32914458">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/54faf0f3e4f101100ae29bc52197254b32914458">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lu_Bridging_the_Visual_Gap_Wide-Range_Image_Blending_CVPR_2021_paper.html">Bridging the Visual Gap: Wide-Range Image Blending</a></th>
                    </tr>
                
                    <tr id="cdaa2f41b6e010e55dae03c75dbd27c2c27e34e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cdaa2f41b6e010e55dae03c75dbd27c2c27e34e1">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lv_Residential_Floor_Plan_Recognition_and_Reconstruction_CVPR_2021_paper.html">Residential Floor Plan Recognition and Reconstruction</a></th>
                    </tr>
                
                    <tr id="7c810bc9c9353de4fd595330662a152b17193720">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c810bc9c9353de4fd595330662a152b17193720">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wickramasinghe_Deep_Active_Surface_Models_CVPR_2021_paper.html">Deep Active Surface Models</a></th>
                    </tr>
                
                    <tr id="27660c8e9627b204dc2ebc9a9431555cfafa8dcc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/27660c8e9627b204dc2ebc9a9431555cfafa8dcc">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cai_Deep_Lesion_Tracker_Monitoring_Lesions_in_4D_Longitudinal_Imaging_Studies_CVPR_2021_paper.html">Deep Lesion Tracker: Monitoring Lesions in 4D Longitudinal Imaging Studies</a></th>
                    </tr>
                
                    <tr id="c074594b6e9fd2070ed7840b6515f5c8565574b4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c074594b6e9fd2070ed7840b6515f5c8565574b4">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Raaj_Exploiting__Refining_Depth_Distributions_With_Triangulation_Light_Curtains_CVPR_2021_paper.html">Exploiting &amp; Refining Depth Distributions With Triangulation Light Curtains</a></th>
                    </tr>
                
                    <tr id="9be62daa9750c8c6c4cab407543ab6b984ea0b85">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9be62daa9750c8c6c4cab407543ab6b984ea0b85">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bai_Learning_Scalable_lY-Constrained_Near-Lossless_Image_Compression_via_Joint_Lossy_Image_CVPR_2021_paper.html">Learning Scalable lY=-Constrained Near-Lossless Image Compression via Joint Lossy Image and Residual Compression</a></th>
                    </tr>
                
                    <tr id="b5e7d893a551b8017071658dc7739d8095a8c057">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b5e7d893a551b8017071658dc7739d8095a8c057">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_FESTA_Flow_Estimation_via_Spatial-Temporal_Attention_for_Scene_Point_Clouds_CVPR_2021_paper.html">FESTA: Flow Estimation via Spatial-Temporal Attention for Scene Point Clouds</a></th>
                    </tr>
                
                    <tr id="9bb2003f59c1e2b542139e869cdc0ed4ebd13217">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9bb2003f59c1e2b542139e869cdc0ed4ebd13217">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shi_Self-Supervised_Visibility_Learning_for_Novel_View_Synthesis_CVPR_2021_paper.html">Self-Supervised Visibility Learning for Novel View Synthesis</a></th>
                    </tr>
                
                    <tr id="5080b26891a0957fcb9e2b5a67ef89ea075b14e9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5080b26891a0957fcb9e2b5a67ef89ea075b14e9">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Domain-Robust_VQA_With_Diverse_Datasets_and_Methods_but_No_Target_CVPR_2021_paper.html">Domain-Robust VQA With Diverse Datasets and Methods but No Target Labels</a></th>
                    </tr>
                
                    <tr id="26b9207002fe91fcbc906ae3e49e23296fd2491d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26b9207002fe91fcbc906ae3e49e23296fd2491d">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kag_Time_Adaptive_Recurrent_Neural_Network_CVPR_2021_paper.html">Time Adaptive Recurrent Neural Network</a></th>
                    </tr>
                
                    <tr id="e40d05c24647dec847459d57f231f27490a6bc8d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e40d05c24647dec847459d57f231f27490a6bc8d">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Enhance_Curvature_Information_by_Structured_Stochastic_Quasi-Newton_Methods_CVPR_2021_paper.html">Enhance Curvature Information by Structured Stochastic Quasi-Newton Methods</a></th>
                    </tr>
                
                    <tr id="bd4fd822b07bcae23f99b8c95d56066e9ecef65a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bd4fd822b07bcae23f99b8c95d56066e9ecef65a">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bowen_OCONet_Image_Extrapolation_by_Object_Completion_CVPR_2021_paper.html">OCONet: Image Extrapolation by Object Completion</a></th>
                    </tr>
                
                    <tr id="a7b177d4651473aacdc74895d798c9bd4a59ec14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a7b177d4651473aacdc74895d798c9bd4a59ec14">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Dynamic_Metric_Learning_Towards_a_Scalable_Metric_Space_To_Accommodate_CVPR_2021_paper.html">Dynamic Metric Learning: Towards a Scalable Metric Space To Accommodate Multiple Semantic Scales</a></th>
                    </tr>
                
                    <tr id="a65040d5b3fb1fbaafbbeaeb39643f958b7f3ea5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a65040d5b3fb1fbaafbbeaeb39643f958b7f3ea5">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shu_Learning_Spatial-Semantic_Relationship_for_Facial_Attribute_Recognition_With_Limited_Labeled_CVPR_2021_paper.html">Learning Spatial-Semantic Relationship for Facial Attribute Recognition With Limited Labeled Data</a></th>
                    </tr>
                
                    <tr id="41a32f77518efc95302d062739e927af9a071b1d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/41a32f77518efc95302d062739e927af9a071b1d">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Feng_Siamese_Natural_Language_Tracker_Tracking_by_Natural_Language_Descriptions_With_CVPR_2021_paper.html">Siamese Natural Language Tracker: Tracking by Natural Language Descriptions With Siamese Trackers</a></th>
                    </tr>
                
                    <tr id="0c24a4a0dab7c86f83ddfb9c4ffb348544594c3f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c24a4a0dab7c86f83ddfb9c4ffb348544594c3f">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Discrimination-Aware_Mechanism_for_Fine-Grained_Representation_Learning_CVPR_2021_paper.html">Discrimination-Aware Mechanism for Fine-Grained Representation Learning</a></th>
                    </tr>
                
                    <tr id="4e62c850e9554d34ccd8979fc1b67ed1448cd8fb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4e62c850e9554d34ccd8979fc1b67ed1448cd8fb">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jang_MeanShift_Extremely_Fast_Mode-Seeking_With_Applications_to_Segmentation_and_Object_CVPR_2021_paper.html">MeanShift++: Extremely Fast Mode-Seeking With Applications to Segmentation and Object Tracking</a></th>
                    </tr>
                
                    <tr id="1119cb7a2d9626796db19e13e829f0e5fc3cba26">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1119cb7a2d9626796db19e13e829f0e5fc3cba26">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Distribution-Aware_Adaptive_Multi-Bit_Quantization_CVPR_2021_paper.html">Distribution-Aware Adaptive Multi-Bit Quantization</a></th>
                    </tr>
                
                    <tr id="6e073dc0b1404f2c46f9512a4abba570a47a706b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6e073dc0b1404f2c46f9512a4abba570a47a706b">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_VS-Net_Voting_With_Segmentation_for_Visual_Localization_CVPR_2021_paper.html">VS-Net: Voting With Segmentation for Visual Localization</a></th>
                    </tr>
                
                    <tr id="28928541efe609213e745eed83d303d04870aeb9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/28928541efe609213e745eed83d303d04870aeb9">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Gudovskiy_AutoDO_Robust_AutoAugment_for_Biased_Data_With_Label_Noise_via_CVPR_2021_paper.html">AutoDO: Robust AutoAugment for Biased Data With Label Noise via Scalable Probabilistic Implicit Differentiation</a></th>
                    </tr>
                
                    <tr id="f2cd60845911395faed5f7da64765993028dfe81">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f2cd60845911395faed5f7da64765993028dfe81">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Rui_Learning_an_Explicit_Weighting_Scheme_for_Adapting_Complex_HSI_Noise_CVPR_2021_paper.html">Learning an Explicit Weighting Scheme for Adapting Complex HSI Noise</a></th>
                    </tr>
                
                    <tr id="07afd0417be76aca92d406cff1346608ad5391ca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/07afd0417be76aca92d406cff1346608ad5391ca">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tu_Learning_Better_Visual_Dialog_Agents_With_Pretrained_Visual-Linguistic_Representation_CVPR_2021_paper.html">Learning Better Visual Dialog Agents With Pretrained Visual-Linguistic Representation</a></th>
                    </tr>
                
                    <tr id="5249d188beda2ec2820834fc932e6da1f5902feb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5249d188beda2ec2820834fc932e6da1f5902feb">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dong_Robust_Neural_Routing_Through_Space_Partitions_for_Camera_Relocalization_in_CVPR_2021_paper.html">Robust Neural Routing Through Space Partitions for Camera Relocalization in Dynamic Indoor Environments</a></th>
                    </tr>
                
                    <tr id="a74b9dff054562bc398d65fdbcdf3f5ed62cdfdc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a74b9dff054562bc398d65fdbcdf3f5ed62cdfdc">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Bilateral_Grid_Learning_for_Stereo_Matching_Networks_CVPR_2021_paper.html">Bilateral Grid Learning for Stereo Matching Networks</a></th>
                    </tr>
                
                    <tr id="6da11b9ee9d0f0f509dc00f5a35b76fc8aaa578b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6da11b9ee9d0f0f509dc00f5a35b76fc8aaa578b">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dong_Learning_Spatially-Variant_MAP_Models_for_Non-Blind_Image_Deblurring_CVPR_2021_paper.html">Learning Spatially-Variant MAP Models for Non-blind Image Deblurring</a></th>
                    </tr>
                
                    <tr id="9ea72f717ee9cf009a4afdb404a0b9e996e424b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9ea72f717ee9cf009a4afdb404a0b9e996e424b5">8</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Pseudo_3D_Auto-Correlation_Network_for_Real_Image_Denoising_CVPR_2021_paper.html">Pseudo 3D Auto-Correlation Network for Real Image Denoising</a></th>
                    </tr>
                
                    <tr id="8b5300bea1e5ec06f14be1dc87ad2eb26951b517">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b5300bea1e5ec06f14be1dc87ad2eb26951b517">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Derksen_Shadow_Neural_Radiance_Fields_for_Multi-View_Satellite_Photogrammetry_CVPRW_2021_paper.html">Shadow Neural Radiance Fields for Multi-View Satellite Photogrammetry</a></th>
                    </tr>
                
                    <tr id="191e79851bbc3424ee81308419a2403b4649e5e3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/191e79851bbc3424ee81308419a2403b4649e5e3">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Jiao_Comparing_Representations_in_Tracking_for_Event_Camera-Based_SLAM_CVPRW_2021_paper.html">Comparing Representations in Tracking for Event Camera-Based SLAM</a></th>
                    </tr>
                
                    <tr id="4aa2b4a93165cba137554b4ba06992922c080fe4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4aa2b4a93165cba137554b4ba06992922c080fe4">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AMFG/html/Liu_EQFace_A_Simple_Explicit_Quality_Network_for_Face_Recognition_CVPRW_2021_paper.html">EQFace: A Simple Explicit Quality Network for Face Recognition</a></th>
                    </tr>
                
                    <tr id="5c266347cd384a44eb76c72f40a57b653ce9224b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c266347cd384a44eb76c72f40a57b653ce9224b">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Precognition/html/Graber_Panoptic_Segmentation_Forecasting_CVPRW_2021_paper.html">Panoptic Segmentation Forecasting</a></th>
                    </tr>
                
                    <tr id="9a2f9ac69ee769ec7ebece7fc98b49a915a2e903">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9a2f9ac69ee769ec7ebece7fc98b49a915a2e903">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Li_Pseudo-IoU_Improving_Label_Assignment_in_Anchor-Free_Object_Detection_CVPRW_2021_paper.html">Pseudo-IoU: Improving Label Assignment in Anchor-Free Object Detection</a></th>
                    </tr>
                
                    <tr id="04a499ae6d72f9c819326ff1c50901f5f1fe47a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/04a499ae6d72f9c819326ff1c50901f5f1fe47a2">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Wang_Knowledge_Distillation_for_Fast_and_Accurate_Monocular_Depth_Estimation_on_CVPRW_2021_paper.html">Knowledge Distillation for Fast and Accurate Monocular Depth Estimation on Mobile Devices</a></th>
                    </tr>
                
                    <tr id="022cbe514184c433a20007b991664a4858fa3348">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/022cbe514184c433a20007b991664a4858fa3348">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Singh_Improving_Semi-Supervised_Domain_Adaptation_Using_Effective_Target_Selection_and_Semantics_CVPRW_2021_paper.html">Improving Semi-Supervised Domain Adaptation Using Effective Target Selection and Semantics</a></th>
                    </tr>
                
                    <tr id="7f9b5a61b2de6d8b409e0b02a9bdb27b1fb2d169">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7f9b5a61b2de6d8b409e0b02a9bdb27b1fb2d169">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WAD/html/Barbato_Latent_Space_Regularization_for_Unsupervised_Domain_Adaptation_in_Semantic_Segmentation_CVPRW_2021_paper.html">Latent Space Regularization for Unsupervised Domain Adaptation in Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="f454d430ac51d3d627a17ec8de4467a678840db2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f454d430ac51d3d627a17ec8de4467a678840db2">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Abdolrashidi_Pareto-Optimal_Quantized_ResNet_Is_Mostly_4-Bit_CVPRW_2021_paper.html">Pareto-Optimal Quantized ResNet Is Mostly 4-Bit</a></th>
                    </tr>
                
                    <tr id="100f2e2a810394503472f50938522930bd07b834">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/100f2e2a810394503472f50938522930bd07b834">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Kim_Rethinking_the_Self-Attention_in_Vision_Transformers_CVPRW_2021_paper.html">Rethinking the Self-Attention in Vision Transformers</a></th>
                    </tr>
                
                    <tr id="508af828c5f5927f9d3ddaec836ab86b79038257">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/508af828c5f5927f9d3ddaec836ab86b79038257">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/GAZE/html/Tomas_GOO_A_Dataset_for_Gaze_Object_Prediction_in_Retail_Environments_CVPRW_2021_paper.html">GOO: A Dataset for Gaze Object Prediction in Retail Environments</a></th>
                    </tr>
                
                    <tr id="7f160841319fd790e01804eb2049bb0ea66d69c9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7f160841319fd790e01804eb2049bb0ea66d69c9">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Korycki_Class-Incremental_Experience_Replay_for_Continual_Learning_Under_Concept_Drift_CVPRW_2021_paper.html">Class-Incremental Experience Replay for Continual Learning Under Concept Drift</a></th>
                    </tr>
                
                    <tr id="72da5f278a52ecfb0a15e1810633e8d2caef325d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/72da5f278a52ecfb0a15e1810633e8d2caef325d">8</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Wu_A_Multi-Camera_Vehicle_Tracking_System_Based_on_City-Scale_Vehicle_Re-ID_CVPRW_2021_paper.html">A Multi-Camera Vehicle Tracking System Based on City-Scale Vehicle Re-ID and Spatial-Temporal Information</a></th>
                    </tr>
                
                    <tr id="852b5cfe8821441fc15d5911f93c3e9d2db57adb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/852b5cfe8821441fc15d5911f93c3e9d2db57adb">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kaneko_Blur_Noise_and_Compression_Robust_Generative_Adversarial_Networks_CVPR_2021_paper.html">Blur, Noise, and Compression Robust Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="483c8173701fa27f890066d29a3d909ead8c9463">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/483c8173701fa27f890066d29a3d909ead8c9463">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lienen_Monocular_Depth_Estimation_via_Listwise_Ranking_Using_the_Plackett-Luce_Model_CVPR_2021_paper.html">Monocular Depth Estimation via Listwise Ranking Using the Plackett-Luce Model</a></th>
                    </tr>
                
                    <tr id="2234716aa9afb57a1fcb60d1bd163b82bfafaf58">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2234716aa9afb57a1fcb60d1bd163b82bfafaf58">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Montesuma_Wasserstein_Barycenter_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.html">Wasserstein Barycenter for Multi-Source Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="d29bbde7fb7f367bc5b06c407f2cf0bfaad6146d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d29bbde7fb7f367bc5b06c407f2cf0bfaad6146d">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Morais_Learning_Asynchronous_and_Sparse_Human-Object_Interaction_in_Videos_CVPR_2021_paper.html">Learning Asynchronous and Sparse Human-Object Interaction in Videos</a></th>
                    </tr>
                
                    <tr id="82e619e74534893d0d6094e36c29924a05fcc319">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/82e619e74534893d0d6094e36c29924a05fcc319">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Neumann_Pedestrian_and_Ego-Vehicle_Trajectory_Prediction_From_Monocular_Camera_CVPR_2021_paper.html">Pedestrian and Ego-Vehicle Trajectory Prediction From Monocular Camera</a></th>
                    </tr>
                
                    <tr id="6cda0deac2ed54fe7605cf345c3cd362cc54f14d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6cda0deac2ed54fe7605cf345c3cd362cc54f14d">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_PAUL_Procrustean_Autoencoder_for_Unsupervised_Lifting_CVPR_2021_paper.html">PAUL: Procrustean Autoencoder for Unsupervised Lifting</a></th>
                    </tr>
                
                    <tr id="3afe57f19db1c0e9af382f72b564e228614592e4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3afe57f19db1c0e9af382f72b564e228614592e4">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Transformation_Driven_Visual_Reasoning_CVPR_2021_paper.html">Transformation Driven Visual Reasoning</a></th>
                    </tr>
                
                    <tr id="1ddef33ece4f6976f80d1ca586d63364379d6fe6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ddef33ece4f6976f80d1ca586d63364379d6fe6">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_A_Multiplexed_Network_for_End-to-End_Multilingual_OCR_CVPR_2021_paper.html">A Multiplexed Network for End-to-End, Multilingual OCR</a></th>
                    </tr>
                
                    <tr id="3b06f586c29628648a9712d519cb0505769b8b76">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3b06f586c29628648a9712d519cb0505769b8b76">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Causal_Hidden_Markov_Model_for_Time_Series_Disease_Forecasting_CVPR_2021_paper.html">Causal Hidden Markov Model for Time Series Disease Forecasting</a></th>
                    </tr>
                
                    <tr id="1ea4eb9ea36e7a5de968e6ce8367ae58ef82efdb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1ea4eb9ea36e7a5de968e6ce8367ae58ef82efdb">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tan_CodedStereo_Learned_Phase_Masks_for_Large_Depth-of-Field_Stereo_CVPR_2021_paper.html">CodedStereo: Learned Phase Masks for Large Depth-of-Field Stereo</a></th>
                    </tr>
                
                    <tr id="5d34fa9b5da1a0b1b457ac5a9c37c91a581f2d76">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5d34fa9b5da1a0b1b457ac5a9c37c91a581f2d76">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Human_De-Occlusion_Invisible_Perception_and_Recovery_for_Humans_CVPR_2021_paper.html">Human De-Occlusion: Invisible Perception and Recovery for Humans</a></th>
                    </tr>
                
                    <tr id="5f301194501ac11d0abb8ad513dbd3a9a2544ab7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f301194501ac11d0abb8ad513dbd3a9a2544ab7">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fan_Learning_Triadic_Belief_Dynamics_in_Nonverbal_Communication_From_Videos_CVPR_2021_paper.html">Learning Triadic Belief Dynamics in Nonverbal Communication From Videos</a></th>
                    </tr>
                
                    <tr id="5b51b2e23deb02dae7538a0bb51d5e692f011553">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b51b2e23deb02dae7538a0bb51d5e692f011553">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Blattmann_Understanding_Object_Dynamics_for_Interactive_Image-to-Video_Synthesis_CVPR_2021_paper.html">Understanding Object Dynamics for Interactive Image-to-Video Synthesis</a></th>
                    </tr>
                
                    <tr id="a461fbe220a95036ff60fb6057c248ec80c21e92">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a461fbe220a95036ff60fb6057c248ec80c21e92">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Vesdapunt_CRFace_Confidence_Ranker_for_Model-Agnostic_Face_Detection_Refinement_CVPR_2021_paper.html">CRFace: Confidence Ranker for Model-Agnostic Face Detection Refinement</a></th>
                    </tr>
                
                    <tr id="86dd3a213b43648c7a836444257d85f3242bc6b8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/86dd3a213b43648c7a836444257d85f3242bc6b8">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Neverova_Discovering_Relationships_Between_Object_Categories_via_Universal_Canonical_Maps_CVPR_2021_paper.html">Discovering Relationships Between Object Categories via Universal Canonical Maps</a></th>
                    </tr>
                
                    <tr id="906baee62963811f592aafac4ee81e72d0f482ef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/906baee62963811f592aafac4ee81e72d0f482ef">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Khakzar_Neural_Response_Interpretation_Through_the_Lens_of_Critical_Pathways_CVPR_2021_paper.html">Neural Response Interpretation Through the Lens of Critical Pathways</a></th>
                    </tr>
                
                    <tr id="2165ce015042eb0c6a4bf0edaf4d9656add556cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2165ce015042eb0c6a4bf0edaf4d9656add556cd">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xia_Deep_Denoising_of_Flash_and_No-Flash_Pairs_for_Photography_in_CVPR_2021_paper.html">Deep Denoising of Flash and No-Flash Pairs for Photography in Low-Light Environments</a></th>
                    </tr>
                
                    <tr id="4d8a81c78308f3b019ffb299f1881d1f33c3a755">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4d8a81c78308f3b019ffb299f1881d1f33c3a755">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Adaptive_Cross-Modal_Prototypes_for_Cross-Domain_Visual-Language_Retrieval_CVPR_2021_paper.html">Adaptive Cross-Modal Prototypes for Cross-Domain Visual-Language Retrieval</a></th>
                    </tr>
                
                    <tr id="b871dd49a0f5f1dffa1605627f850f5cd8c9440b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b871dd49a0f5f1dffa1605627f850f5cd8c9440b">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Self-Aligned_Video_Deraining_With_Transmission-Depth_Consistency_CVPR_2021_paper.html">Self-Aligned Video Deraining With Transmission-Depth Consistency</a></th>
                    </tr>
                
                    <tr id="c09572105e9bfabddc4585020cf2d17a64d9c0ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c09572105e9bfabddc4585020cf2d17a64d9c0ab">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Meta-Mining_Discriminative_Samples_for_Kinship_Verification_CVPR_2021_paper.html">Meta-Mining Discriminative Samples for Kinship Verification</a></th>
                    </tr>
                
                    <tr id="e1398f811e5e96887d80740f9c483274abc8ba24">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e1398f811e5e96887d80740f9c483274abc8ba24">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Self-Generated_Defocus_Blur_Detection_via_Dual_Adversarial_Discriminators_CVPR_2021_paper.html">Self-Generated Defocus Blur Detection via Dual Adversarial Discriminators</a></th>
                    </tr>
                
                    <tr id="5f95e905a73a0b0c1f08def6c6a10de42e9cef4f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f95e905a73a0b0c1f08def6c6a10de42e9cef4f">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Real-Time_Selfie_Video_Stabilization_CVPR_2021_paper.html">Real-Time Selfie Video Stabilization</a></th>
                    </tr>
                
                    <tr id="428d543e9df38b81cd4f21c4078ae6db075de89a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/428d543e9df38b81cd4f21c4078ae6db075de89a">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sepas-Moghaddam_Multi-Perspective_LSTM_for_Joint_Visual_Representation_Learning_CVPR_2021_paper.html">Multi-Perspective LSTM for Joint Visual Representation Learning</a></th>
                    </tr>
                
                    <tr id="0c781c6efa21ceb2c1a97b5cc55186e546518450">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c781c6efa21ceb2c1a97b5cc55186e546518450">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Learning_the_Superpixel_in_a_Non-Iterative_and_Lifelong_Manner_CVPR_2021_paper.html">Learning the Superpixel in a Non-Iterative and Lifelong Manner</a></th>
                    </tr>
                
                    <tr id="c5122aee0689f64c636f1e9f9297f90de6cfc16e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c5122aee0689f64c636f1e9f9297f90de6cfc16e">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ichikawa_Shape_From_Sky_Polarimetric_Normal_Recovery_Under_the_Sky_CVPR_2021_paper.html">Shape From Sky: Polarimetric Normal Recovery Under the Sky</a></th>
                    </tr>
                
                    <tr id="ed64296f3317089365626ae56dba51cc0f0e35fc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ed64296f3317089365626ae56dba51cc0f0e35fc">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Composing_Photos_Like_a_Photographer_CVPR_2021_paper.html">Composing Photos Like a Photographer</a></th>
                    </tr>
                
                    <tr id="f61b7fa7ed2d8dcc318d8d4330b8f097cd797673">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f61b7fa7ed2d8dcc318d8d4330b8f097cd797673">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Generic_Perceptual_Loss_for_Modeling_Structured_Output_Dependencies_CVPR_2021_paper.html">Generic Perceptual Loss for Modeling Structured Output Dependencies</a></th>
                    </tr>
                
                    <tr id="380ea82761465918c61365f0346019c5196e279a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/380ea82761465918c61365f0346019c5196e279a">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kobayashi_T-vMF_Similarity_for_Regularizing_Intra-Class_Feature_Distribution_CVPR_2021_paper.html">T-vMF Similarity for Regularizing Intra-Class Feature Distribution</a></th>
                    </tr>
                
                    <tr id="5f4c8a26d30b9a6a078c3f7433477f1c85cfb555">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f4c8a26d30b9a6a078c3f7433477f1c85cfb555">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Surrogate_Gradient_Field_for_Latent_Space_Manipulation_CVPR_2021_paper.html">Surrogate Gradient Field for Latent Space Manipulation</a></th>
                    </tr>
                
                    <tr id="cfab717022d3a55dca1c5745f6271b31cbf2992c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cfab717022d3a55dca1c5745f6271b31cbf2992c">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mitsuzumi_Generalized_Domain_Adaptation_CVPR_2021_paper.html">Generalized Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="7a5946a5c015241230ffa53add77a0bb773a7054">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a5946a5c015241230ffa53add77a0bb773a7054">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bhardwaj_How_Does_Topology_Influence_Gradient_Propagation_and_Model_Performance_of_CVPR_2021_paper.html">How Does Topology Influence Gradient Propagation and Model Performance of Deep Networks With DenseNet-Type Skip Connections?</a></th>
                    </tr>
                
                    <tr id="93a03bd4b184964483c2c68200357e6802d1b5c3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/93a03bd4b184964483c2c68200357e6802d1b5c3">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Explicit_Knowledge_Incorporation_for_Visual_Reasoning_CVPR_2021_paper.html">Explicit Knowledge Incorporation for Visual Reasoning</a></th>
                    </tr>
                
                    <tr id="635847ad3ebbbe421b328dcec3927badc671c03d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/635847ad3ebbbe421b328dcec3927badc671c03d">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Content-Aware_GAN_Compression_CVPR_2021_paper.html">Content-Aware GAN Compression</a></th>
                    </tr>
                
                    <tr id="1a642325b39f16ec603af90e2b519bb42e8d5dfc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a642325b39f16ec603af90e2b519bb42e8d5dfc">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ouyang_Neural_Camera_Simulators_CVPR_2021_paper.html">Neural Camera Simulators</a></th>
                    </tr>
                
                    <tr id="b8e4c9acbbf681503c577f7c9d58ada45a96e29f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b8e4c9acbbf681503c577f7c9d58ada45a96e29f">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tran_SSLayout360_Semi-Supervised_Indoor_Layout_Estimation_From_360deg_Panorama_CVPR_2021_paper.html">SSLayout360: Semi-Supervised Indoor Layout Estimation From 360deg Panorama</a></th>
                    </tr>
                
                    <tr id="808c908377b9acd49845ba898819db6121b35109">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/808c908377b9acd49845ba898819db6121b35109">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mezghanni_Physically-Aware_Generative_Network_for_3D_Shape_Modeling_CVPR_2021_paper.html">Physically-Aware Generative Network for 3D Shape Modeling</a></th>
                    </tr>
                
                    <tr id="460197e41dbc961582d70fc323cc9dbd760a04a2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/460197e41dbc961582d70fc323cc9dbd760a04a2">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Partial_Feature_Selection_and_Alignment_for_Multi-Source_Domain_Adaptation_CVPR_2021_paper.html">Partial Feature Selection and Alignment for Multi-Source Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="13803ee48893ba25f13f01cd15d1ddd2ed6ca274">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/13803ee48893ba25f13f01cd15d1ddd2ed6ca274">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qiu_Effective_Snapshot_Compressive-Spectral_Imaging_via_Deep_Denoising_and_Total_Variation_CVPR_2021_paper.html">Effective Snapshot Compressive-Spectral Imaging via Deep Denoising and Total Variation Priors</a></th>
                    </tr>
                
                    <tr id="5c52e6a85cb3f68804bf0c875e88fa2f44160220">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c52e6a85cb3f68804bf0c875e88fa2f44160220">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Transitional_Adaptation_of_Pretrained_Models_for_Visual_Storytelling_CVPR_2021_paper.html">Transitional Adaptation of Pretrained Models for Visual Storytelling</a></th>
                    </tr>
                
                    <tr id="6c954a5034b543a70e621c9f18997510b82f0a47">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c954a5034b543a70e621c9f18997510b82f0a47">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sayed_Improved_Handling_of_Motion_Blur_in_Online_Object_Detection_CVPR_2021_paper.html">Improved Handling of Motion Blur in Online Object Detection</a></th>
                    </tr>
                
                    <tr id="cf93c0a6db5e46c367af4d3ba8a78f30565e7d30">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cf93c0a6db5e46c367af4d3ba8a78f30565e7d30">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tan_Practical_Wide-Angle_Portraits_Correction_With_Deep_Structured_Models_CVPR_2021_paper.html">Practical Wide-Angle Portraits Correction With Deep Structured Models</a></th>
                    </tr>
                
                    <tr id="aee8a56202088c2a51dc6f858c1bdd07c405e000">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aee8a56202088c2a51dc6f858c1bdd07c405e000">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wei_Improved_Image_Matting_via_Real-Time_User_Clicks_and_Uncertainty_Estimation_CVPR_2021_paper.html">Improved Image Matting via Real-Time User Clicks and Uncertainty Estimation</a></th>
                    </tr>
                
                    <tr id="a526175364bd139a7d6a70406a799e2cdb7b19ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a526175364bd139a7d6a70406a799e2cdb7b19ce">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bo_Hardness_Sampling_for_Self-Training_Based_Transductive_Zero-Shot_Learning_CVPR_2021_paper.html">Hardness Sampling for Self-Training Based Transductive Zero-Shot Learning</a></th>
                    </tr>
                
                    <tr id="34504edc566825571eefaf070e598822d3600b8f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/34504edc566825571eefaf070e598822d3600b8f">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Birds_of_a_Feather_Capturing_Avian_Shape_Models_From_Images_CVPR_2021_paper.html">Birds of a Feather: Capturing Avian Shape Models From Images</a></th>
                    </tr>
                
                    <tr id="ccab0ab0b58c5621ef73d0bc5231ababdde62e2c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ccab0ab0b58c5621ef73d0bc5231ababdde62e2c">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Alaniz_Learning_Decision_Trees_Recurrently_Through_Communication_CVPR_2021_paper.html">Learning Decision Trees Recurrently Through Communication</a></th>
                    </tr>
                
                    <tr id="aa7ff7cf95a893436117a5bf737cc4d6c70d387d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aa7ff7cf95a893436117a5bf737cc4d6c70d387d">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chi_Feature-Level_Collaboration_Joint_Unsupervised_Learning_of_Optical_Flow_Stereo_Depth_CVPR_2021_paper.html">Feature-Level Collaboration: Joint Unsupervised Learning of Optical Flow, Stereo Depth and Camera Motion</a></th>
                    </tr>
                
                    <tr id="426f19b225ec6b0500f014456a0b0787e30b0513">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/426f19b225ec6b0500f014456a0b0787e30b0513">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mihajlovic_DeepSurfels_Learning_Online_Appearance_Fusion_CVPR_2021_paper.html">DeepSurfels: Learning Online Appearance Fusion</a></th>
                    </tr>
                
                    <tr id="c2ebb74d58db22b6738c1cb0455fff065e0da0d3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c2ebb74d58db22b6738c1cb0455fff065e0da0d3">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Gradient-Based_Algorithms_for_Machine_Teaching_CVPR_2021_paper.html">Gradient-based Algorithms for Machine Teaching</a></th>
                    </tr>
                
                    <tr id="f9cee194487d6cb578c90209b13e83f3806bf9d0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f9cee194487d6cb578c90209b13e83f3806bf9d0">7</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tang_SKFAC_Training_Neural_Networks_With_Faster_Kronecker-Factored_Approximate_Curvature_CVPR_2021_paper.html">SKFAC: Training Neural Networks with Faster Kronecker-Factored Approximate Curvature</a></th>
                    </tr>
                
                    <tr id="93f7b204bd99e02f63da16bd87fa3e965c7c568e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/93f7b204bd99e02f63da16bd87fa3e965c7c568e">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Ayyoubzadeh_ASNA_An_Attention-Based_Siamese-Difference_Neural_Network_With_Surrogate_Ranking_Loss_CVPRW_2021_paper.html">(ASNA) An Attention-Based Siamese-Difference Neural Network With Surrogate Ranking Loss Function for Perceptual Image Quality Assessment</a></th>
                    </tr>
                
                    <tr id="ab0047135836dc52277fdf2e77dcb3498197b412">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ab0047135836dc52277fdf2e77dcb3498197b412">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Dutta_Efficient_Space-Time_Video_Super_Resolution_Using_Low-Resolution_Flow_and_Mask_CVPRW_2021_paper.html">Efficient Space-Time Video Super Resolution Using Low-Resolution Flow and Mask Upsampling</a></th>
                    </tr>
                
                    <tr id="7d22857dc7f921c8b292ca9673231fe9bbdf0f08">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7d22857dc7f921c8b292ca9673231fe9bbdf0f08">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Xu_EDPN_Enhanced_Deep_Pyramid_Network_for_Blurry_Image_Restoration_CVPRW_2021_paper.html">EDPN: Enhanced Deep Pyramid Network for Blurry Image Restoration</a></th>
                    </tr>
                
                    <tr id="fba52cffcd2f190465308f82d1ae33a388649264">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fba52cffcd2f190465308f82d1ae33a388649264">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Treu_Fashion-Guided_Adversarial_Attack_on_Person_Segmentation_CVPRW_2021_paper.html">Fashion-Guided Adversarial Attack on Person Segmentation</a></th>
                    </tr>
                
                    <tr id="f6baff1c310e0b9f9a29688691d08953165869d9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f6baff1c310e0b9f9a29688691d08953165869d9">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Shinohara_Point2color_3D_Point_Cloud_Colorization_Using_a_Conditional_Generative_Network_CVPRW_2021_paper.html">Point2color: 3D Point Cloud Colorization Using a Conditional Generative Network and Differentiable Rendering for Airborne LiDAR</a></th>
                    </tr>
                
                    <tr id="2e89b9128fec87d8a25445c94910081284799d75">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e89b9128fec87d8a25445c94910081284799d75">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Dua_Beyond_VQA_Generating_Multi-Word_Answers_and_Rationales_to_Visual_Questions_CVPRW_2021_paper.html">Beyond VQA: Generating Multi-Word Answers and Rationales to Visual Questions</a></th>
                    </tr>
                
                    <tr id="9211d298f988c18fbcdb4435cb7476c7d3db0085">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9211d298f988c18fbcdb4435cb7476c7d3db0085">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Precognition/html/Zatsarynna_Multi-Modal_Temporal_Convolutional_Network_for_Anticipating_Actions_in_Egocentric_Videos_CVPRW_2021_paper.html">Multi-Modal Temporal Convolutional Network for Anticipating Actions in Egocentric Videos</a></th>
                    </tr>
                
                    <tr id="c90f8f7818ab2e1a19220ab2ce58768ecbe65ae2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c90f8f7818ab2e1a19220ab2ce58768ecbe65ae2">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/RCV/html/Korkmaz_Inaccuracy_of_State-Action_Value_Function_for_Non-Optimal_Actions_in_Adversarially_CVPRW_2021_paper.html">Inaccuracy of State-Action Value Function for Non-Optimal Actions in Adversarially Trained Deep Neural Policies</a></th>
                    </tr>
                
                    <tr id="b894f25d1887896ca31061f28de70b4d4020e00b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b894f25d1887896ca31061f28de70b4d4020e00b">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/RCV/html/Hazirbas_Casual_Conversations_A_Dataset_for_Measuring_Fairness_in_AI_CVPRW_2021_paper.html">Casual Conversations: A Dataset for Measuring Fairness in AI</a></th>
                    </tr>
                
                    <tr id="7d4e156afb4d38aab56e53e259bf40bae52b5b71">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7d4e156afb4d38aab56e53e259bf40bae52b5b71">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/RCV/html/Michieli_Are_All_Users_Treated_Fairly_in_Federated_Learning_Systems_CVPRW_2021_paper.html">Are All Users Treated Fairly in Federated Learning Systems?</a></th>
                    </tr>
                
                    <tr id="973ee6745dc8308171b690b73a26e31fef651c32">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/973ee6745dc8308171b690b73a26e31fef651c32">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Liu_EVSRNet_Efficient_Video_Super-Resolution_With_Neural_Architecture_Search_CVPRW_2021_paper.html">EVSRNet: Efficient Video Super-Resolution With Neural Architecture Search</a></th>
                    </tr>
                
                    <tr id="a778a898d70d84c6e4193217ad572f37d0a2f502">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a778a898d70d84c6e4193217ad572f37d0a2f502">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Mahendran_Computer_Vision-Based_Assistance_System_for_the_Visually_Impaired_Using_Mobile_CVPRW_2021_paper.html">Computer Vision-Based Assistance System for the Visually Impaired Using Mobile Edge Artificial Intelligence</a></th>
                    </tr>
                
                    <tr id="dd7ce3331a3035786f41836e15732889030efb81">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dd7ce3331a3035786f41836e15732889030efb81">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Yun_Do_All_MobileNets_Quantize_Poorly_Gaining_Insights_Into_the_Effect_CVPRW_2021_paper.html">Do All MobileNets Quantize Poorly? Gaining Insights Into the Effect of Quantization on Depthwise Separable Convolutional Networks Through the Eyes of Multi-Scale Distributional Dynamics</a></th>
                    </tr>
                
                    <tr id="afc8c5ef1875b9c27e18757345cd9f830ae80275">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/afc8c5ef1875b9c27e18757345cd9f830ae80275">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Yucel_Real-Time_Monocular_Depth_Estimation_With_Sparse_Supervision_on_Mobile_CVPRW_2021_paper.html">Real-Time Monocular Depth Estimation With Sparse Supervision on Mobile</a></th>
                    </tr>
                
                    <tr id="1cfe5cc309c060b6a73999c6cfd04db0f4604081">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1cfe5cc309c060b6a73999c6cfd04db0f4604081">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Chen_Shot_in_the_Dark_Few-Shot_Learning_With_No_Base-Class_Labels_CVPRW_2021_paper.html">Shot in the Dark: Few-Shot Learning With No Base-Class Labels</a></th>
                    </tr>
                
                    <tr id="0ff16f9c7d96e65366ff8b0258b0dbb2a13cb5c2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ff16f9c7d96e65366ff8b0258b0dbb2a13cb5c2">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WAD/html/Wang_Rethinking_of_Radars_Role_A_Camera-Radar_Dataset_and_Systematic_Annotator_CVPRW_2021_paper.html">Rethinking of Radar&#39;s Role: A Camera-Radar Dataset and Systematic Annotator via Coordinate Alignment</a></th>
                    </tr>
                
                    <tr id="5434bac714ef02516d35b3695869abae6110b5c5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5434bac714ef02516d35b3695869abae6110b5c5">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WAD/html/Ouyang_Occlusion_Guided_Scene_Flow_Estimation_on_3D_Point_Clouds_CVPRW_2021_paper.html">Occlusion Guided Scene Flow Estimation on 3D Point Clouds</a></th>
                    </tr>
                
                    <tr id="7be18348ccd4f58101cab0cf341c13603d2a3bc7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7be18348ccd4f58101cab0cf341c13603d2a3bc7">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Lou_Dynamic-OFA_Runtime_DNN_Architecture_Switching_for_Performance_Scaling_on_Heterogeneous_CVPRW_2021_paper.html">Dynamic-OFA: Runtime DNN Architecture Switching for Performance Scaling on Heterogeneous Embedded Platforms</a></th>
                    </tr>
                
                    <tr id="358b8a33e362cf2daec137566dc3b14dde9b68c1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/358b8a33e362cf2daec137566dc3b14dde9b68c1">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/HVU/html/Rai_CoCon_Cooperative-Contrastive_Learning_CVPRW_2021_paper.html">CoCon: Cooperative-Contrastive Learning</a></th>
                    </tr>
                
                    <tr id="878d3d5eda61730bcf2a84467188fa44dad67501">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/878d3d5eda61730bcf2a84467188fa44dad67501">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Douillard_Insights_From_the_Future_for_Continual_Learning_CVPRW_2021_paper.html">Insights From the Future for Continual Learning</a></th>
                    </tr>
                
                    <tr id="227999ebc1bee29ab8ddcfc1b764677dd06cec6f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/227999ebc1bee29ab8ddcfc1b764677dd06cec6f">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Hayes_Selective_Replay_Enhances_Learning_in_Online_Continual_Analogical_Reasoning_CVPRW_2021_paper.html">Selective Replay Enhances Learning in Online Continual Analogical Reasoning</a></th>
                    </tr>
                
                    <tr id="eeab253c49dda8c058e27f9a1727b9043dc83e10">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eeab253c49dda8c058e27f9a1727b9043dc83e10">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Ha_Tiny-PIRATE_A_Tiny_Model_With_Parallelized_Intelligence_for_Real-Time_Analysis_CVPRW_2021_paper.html">Tiny-PIRATE: A Tiny Model With Parallelized Intelligence for Real-Time Analysis as a Traffic countEr</a></th>
                    </tr>
                
                    <tr id="dfcc0a2a67ade73a7c58195f7811c721f89c5d1b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dfcc0a2a67ade73a7c58195f7811c721f89c5d1b">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Tran_Real-Time_and_Robust_System_for_Counting_Movement-Specific_Vehicle_at_Crowded_CVPRW_2021_paper.html">Real-Time and Robust System for Counting Movement-Specific Vehicle at Crowded Intersections</a></th>
                    </tr>
                
                    <tr id="510588ab0dbc68c70610579c2ef4e22f0b960f20">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/510588ab0dbc68c70610579c2ef4e22f0b960f20">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Shim_Multi-Target_Multi-Camera_Vehicle_Tracking_for_City-Scale_Traffic_Management_CVPRW_2021_paper.html">Multi-Target Multi-Camera Vehicle Tracking for City-Scale Traffic Management</a></th>
                    </tr>
                
                    <tr id="561efc4582c681036a1ae89d82f827e474617ab9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/561efc4582c681036a1ae89d82f827e474617ab9">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/PBVS/html/Akkaya_Self-Training_Guided_Adversarial_Domain_Adaptation_for_Thermal_Imagery_CVPRW_2021_paper.html">Self-Training Guided Adversarial Domain Adaptation for Thermal Imagery</a></th>
                    </tr>
                
                    <tr id="2993de49c3f33be881ad50dec14518223e102339">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2993de49c3f33be881ad50dec14518223e102339">7</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DiffCVML/html/Hartman_Supervised_Deep_Learning_of_Elastic_SRV_Distances_on_the_Shape_CVPRW_2021_paper.html">Supervised Deep Learning of Elastic SRV Distances on the Shape Space of Curves</a></th>
                    </tr>
                
                    <tr id="8f9e0f1201b3fc672a05148ef50ce0b2ec7cd72c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f9e0f1201b3fc672a05148ef50ce0b2ec7cd72c">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tousi_Automatic_Correction_of_Internal_Units_in_Generative_Neural_Networks_CVPR_2021_paper.html">Automatic Correction of Internal Units in Generative Neural Networks</a></th>
                    </tr>
                
                    <tr id="ccf91ea974423a326f35f552e5444138b60358a5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ccf91ea974423a326f35f552e5444138b60358a5">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Beyond_Short_Clips_End-to-End_Video-Level_Learning_With_Collaborative_Memories_CVPR_2021_paper.html">Beyond Short Clips: End-to-End Video-Level Learning With Collaborative Memories</a></th>
                    </tr>
                
                    <tr id="c1580a4d786285250614b07d1bfb73a372079760">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c1580a4d786285250614b07d1bfb73a372079760">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kluger_Cuboids_Revisited_Learning_Robust_3D_Shape_Fitting_to_Single_RGB_CVPR_2021_paper.html">Cuboids Revisited: Learning Robust 3D Shape Fitting to Single RGB Images</a></th>
                    </tr>
                
                    <tr id="bcc5e1744ef55160572651c01f3dd9bdeeed8caa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bcc5e1744ef55160572651c01f3dd9bdeeed8caa">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ding_Globally_Optimal_Relative_Pose_Estimation_With_Gravity_Prior_CVPR_2021_paper.html">Globally Optimal Relative Pose Estimation With Gravity Prior</a></th>
                    </tr>
                
                    <tr id="86722947bea174633ce7ff56301ca5e86ad48a32">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/86722947bea174633ce7ff56301ca5e86ad48a32">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Vidanapathirana_Plan2Scene_Converting_Floorplans_to_3D_Scenes_CVPR_2021_paper.html">Plan2Scene: Converting Floorplans to 3D Scenes</a></th>
                    </tr>
                
                    <tr id="df07ed4a5aa7561e447d2a706a2f48bd02d69518">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/df07ed4a5aa7561e447d2a706a2f48bd02d69518">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Khrulkov_Neural_Side-by-Side_Predicting_Human_Preferences_for_No-Reference_Super-Resolution_Evaluation_CVPR_2021_paper.html">Neural Side-by-Side: Predicting Human Preferences for No-Reference Super-Resolution Evaluation</a></th>
                    </tr>
                
                    <tr id="d1f570e6a824634e04377c01c82738864c98a958">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d1f570e6a824634e04377c01c82738864c98a958">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kwon_Controllable_Image_Restoration_for_Under-Display_Camera_in_Smartphones_CVPR_2021_paper.html">Controllable Image Restoration for Under-Display Camera in Smartphones</a></th>
                    </tr>
                
                    <tr id="f26b6211d46a22907b1f292535378d1769d52a0a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f26b6211d46a22907b1f292535378d1769d52a0a">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/dApolito_GANmut_Learning_Interpretable_Conditional_Space_for_Gamut_of_Emotions_CVPR_2021_paper.html">GANmut: Learning Interpretable Conditional Space for Gamut of Emotions</a></th>
                    </tr>
                
                    <tr id="52e6c8fe82eedae59b8bd8c42e27dfd76870cb36">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/52e6c8fe82eedae59b8bd8c42e27dfd76870cb36">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kryzhanovskiy_QPP_Real-Time_Quantization_Parameter_Prediction_for_Deep_Neural_Networks_CVPR_2021_paper.html">QPP: Real-Time Quantization Parameter Prediction for Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="dc4b09e959344caca0141d29cbe7d19e8e23118b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dc4b09e959344caca0141d29cbe7d19e8e23118b">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lim_Building_Reliable_Explanations_of_Unreliable_Neural_Networks_Locally_Smoothing_Perspective_CVPR_2021_paper.html">Building Reliable Explanations of Unreliable Neural Networks: Locally Smoothing Perspective of Model Interpretation</a></th>
                    </tr>
                
                    <tr id="15940f6379eea6b47d41aa6503c410f24a764611">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15940f6379eea6b47d41aa6503c410f24a764611">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qiu_Boosting_Video_Representation_Learning_With_Multi-Faceted_Integration_CVPR_2021_paper.html">Boosting Video Representation Learning With Multi-Faceted Integration</a></th>
                    </tr>
                
                    <tr id="8de8cf785ad93f2c5aa800aaa7b99109f214d6ac">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8de8cf785ad93f2c5aa800aaa7b99109f214d6ac">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Robidoux_End-to-End_High_Dynamic_Range_Camera_Pipeline_Optimization_CVPR_2021_paper.html">End-to-End High Dynamic Range Camera Pipeline Optimization</a></th>
                    </tr>
                
                    <tr id="8f299da1395c07aa6e07043e079b2384b9510e45">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f299da1395c07aa6e07043e079b2384b9510e45">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhao_Prior_Based_Human_Completion_CVPR_2021_paper.html">Prior Based Human Completion</a></th>
                    </tr>
                
                    <tr id="be76788da35f627efd1886cd6a3d015372328191">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/be76788da35f627efd1886cd6a3d015372328191">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mustafa_Multi-Person_Implicit_Reconstruction_From_a_Single_Image_CVPR_2021_paper.html">Multi-Person Implicit Reconstruction From a Single Image</a></th>
                    </tr>
                
                    <tr id="e272f2336103e455720ce9fffc600c838d60a3bc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e272f2336103e455720ce9fffc600c838d60a3bc">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kerola_Hierarchical_Lovasz_Embeddings_for_Proposal-Free_Panoptic_Segmentation_CVPR_2021_paper.html">Hierarchical Lovasz Embeddings for Proposal-Free Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="8bc362ce5da17fd34ce80c5fceb00dcfb6437906">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8bc362ce5da17fd34ce80c5fceb00dcfb6437906">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Three_Birds_with_One_Stone_Multi-Task_Temporal_Action_Detection_via_CVPR_2021_paper.html">Three Birds with One Stone: Multi-Task Temporal Action Detection via Recycling Temporal Annotations</a></th>
                    </tr>
                
                    <tr id="2fbe8e9280f6c0817ab77d1d2791ef835c65e56e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2fbe8e9280f6c0817ab77d1d2791ef835c65e56e">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xiang_A_Dual_Iterative_Refinement_Method_for_Non-Rigid_Shape_Matching_CVPR_2021_paper.html">A Dual Iterative Refinement Method for Non-Rigid Shape Matching</a></th>
                    </tr>
                
                    <tr id="0c5974284a724ba31938e569d812ca3c128352b3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0c5974284a724ba31938e569d812ca3c128352b3">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_RankDetNet_Delving_Into_Ranking_Constraints_for_Object_Detection_CVPR_2021_paper.html">RankDetNet: Delving Into Ranking Constraints for Object Detection</a></th>
                    </tr>
                
                    <tr id="390aa4fdc4072479ceaa638b1fe586d056feeb98">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/390aa4fdc4072479ceaa638b1fe586d056feeb98">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Vowels_VDSM_Unsupervised_Video_Disentanglement_With_State-Space_Modeling_and_Deep_Mixtures_CVPR_2021_paper.html">VDSM: Unsupervised Video Disentanglement With State-Space Modeling and Deep Mixtures of Experts</a></th>
                    </tr>
                
                    <tr id="b30f5a670c6b0416577d51a232826146bc2e2444">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b30f5a670c6b0416577d51a232826146bc2e2444">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhou_Mesoscopic_Photogrammetry_With_an_Unstabilized_Phone_Camera_CVPR_2021_paper.html">Mesoscopic Photogrammetry With an Unstabilized Phone Camera</a></th>
                    </tr>
                
                    <tr id="aa8441031608c8417260ce6d15900afa6e68089d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aa8441031608c8417260ce6d15900afa6e68089d">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ye_Hierarchical_and_Partially_Observable_Goal-Driven_Policy_Learning_With_Goals_Relational_CVPR_2021_paper.html">Hierarchical and Partially Observable Goal-Driven Policy Learning With Goals Relational Graph</a></th>
                    </tr>
                
                    <tr id="6f935dd73f866bc390752b84ce207cc6595c3f9e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6f935dd73f866bc390752b84ce207cc6595c3f9e">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Moseley_Extreme_Low-Light_Environment-Driven_Image_Denoising_Over_Permanently_Shadowed_Lunar_Regions_CVPR_2021_paper.html">Extreme Low-Light Environment-Driven Image Denoising Over Permanently Shadowed Lunar Regions With a Physical Noise Model</a></th>
                    </tr>
                
                    <tr id="38c7534f5d1b3156f78a98235aa43a10144b7fe3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38c7534f5d1b3156f78a98235aa43a10144b7fe3">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Multi-View_3D_Reconstruction_of_a_Texture-Less_Smooth_Surface_of_Unknown_CVPR_2021_paper.html">Multi-View 3D Reconstruction of a Texture-Less Smooth Surface of Unknown Generic Reflectance</a></th>
                    </tr>
                
                    <tr id="cbf62054f25002675284b643e7f17deab8853106">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cbf62054f25002675284b643e7f17deab8853106">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Defending_Multimodal_Fusion_Models_Against_Single-Source_Adversaries_CVPR_2021_paper.html">Defending Multimodal Fusion Models Against Single-Source Adversaries</a></th>
                    </tr>
                
                    <tr id="5c6106dd24c393eaf79e4dfd495b0e694bf2670e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c6106dd24c393eaf79e4dfd495b0e694bf2670e">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Stochastic_Whitening_Batch_Normalization_CVPR_2021_paper.html">Stochastic Whitening Batch Normalization</a></th>
                    </tr>
                
                    <tr id="7c2559d585272a732fefa395e7845b8267f50750">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c2559d585272a732fefa395e7845b8267f50750">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Blind_Deblurring_for_Saturated_Images_CVPR_2021_paper.html">Blind Deblurring for Saturated Images</a></th>
                    </tr>
                
                    <tr id="2c956d96d6e72a4f6d7ec6992411eaa58cd4c65f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2c956d96d6e72a4f6d7ec6992411eaa58cd4c65f">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Duan_SLADE_A_Self-Training_Framework_for_Distance_Metric_Learning_CVPR_2021_paper.html">SLADE: A Self-Training Framework for Distance Metric Learning</a></th>
                    </tr>
                
                    <tr id="2e6ce6dfdc0b5bcfab23c097a16f83410e301102">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e6ce6dfdc0b5bcfab23c097a16f83410e301102">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bokhovkin_Towards_Part-Based_Understanding_of_RGB-D_Scans_CVPR_2021_paper.html">Towards Part-Based Understanding of RGB-D Scans</a></th>
                    </tr>
                
                    <tr id="51e9bc9c92adade4716ee34b387eef250197bec3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/51e9bc9c92adade4716ee34b387eef250197bec3">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Quality-Agnostic_Image_Recognition_via_Invertible_Decoder_CVPR_2021_paper.html">Quality-Agnostic Image Recognition via Invertible Decoder</a></th>
                    </tr>
                
                    <tr id="b7386dbdf7dcf344124408693c0e2075143dd5dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b7386dbdf7dcf344124408693c0e2075143dd5dd">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zeng_Pushing_It_Out_of_the_Way_Interactive_Visual_Navigation_CVPR_2021_paper.html">Pushing It Out of the Way: Interactive Visual Navigation</a></th>
                    </tr>
                
                    <tr id="5b62f55ee46245b0c4e710efac9c7578666c68a3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b62f55ee46245b0c4e710efac9c7578666c68a3">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Weakly_Supervised_Instance_Segmentation_for_Videos_With_Temporal_Mask_Consistency_CVPR_2021_paper.html">Weakly Supervised Instance Segmentation for Videos With Temporal Mask Consistency</a></th>
                    </tr>
                
                    <tr id="97a469951d2b3b61e7f1dc50580e5253c22284d0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/97a469951d2b3b61e7f1dc50580e5253c22284d0">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Brain_Image_Synthesis_With_Unsupervised_Multivariate_Canonical_CSCl4Net_CVPR_2021_paper.html">Brain Image Synthesis With Unsupervised Multivariate Canonical CSCl4Net</a></th>
                    </tr>
                
                    <tr id="69170c54e16270fed37cf76f38d95f6e1dcd1736">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/69170c54e16270fed37cf76f38d95f6e1dcd1736">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Learning_Fine-Grained_Segmentation_of_3D_Shapes_Without_Part_Labels_CVPR_2021_paper.html">Learning Fine-Grained Segmentation of 3D Shapes without Part Labels</a></th>
                    </tr>
                
                    <tr id="7f6fe6a6c1765a85e6c8d393b60a5e50ebbd2a60">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7f6fe6a6c1765a85e6c8d393b60a5e50ebbd2a60">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Troubleshooting_Blind_Image_Quality_Models_in_the_Wild_CVPR_2021_paper.html">Troubleshooting Blind Image Quality Models in the Wild</a></th>
                    </tr>
                
                    <tr id="7af7213190d85a5f148383dce1e7b1f26dc41637">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7af7213190d85a5f148383dce1e7b1f26dc41637">6</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hsu_DARCNN_Domain_Adaptive_Region-Based_Convolutional_Neural_Network_for_Unsupervised_Instance_CVPR_2021_paper.html">DARCNN: Domain Adaptive Region-based Convolutional Neural Network for Unsupervised Instance Segmentation in Biomedical Images</a></th>
                    </tr>
                
                    <tr id="e7e8cd24b4a44dbe5262096895eb0e642218df30">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e7e8cd24b4a44dbe5262096895eb0e642218df30">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Rabe_Development_Methodologies_for_Safety_Critical_Machine_Learning_Applications_in_the_CVPRW_2021_paper.html">Development Methodologies for Safety Critical Machine Learning Applications in the Automotive Domain: A Survey</a></th>
                    </tr>
                
                    <tr id="7b4b31d4c8a46e93e1b27af3f512ae7cafa33dd1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b4b31d4c8a46e93e1b27af3f512ae7cafa33dd1">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Wang_Multi-Scale_Self-Calibrated_Network_for_Image_Light_Source_Transfer_CVPRW_2021_paper.html">Multi-Scale Self-Calibrated Network for Image Light Source Transfer</a></th>
                    </tr>
                
                    <tr id="5199367445df20975073f43ae1b94d8d92a8fc50">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5199367445df20975073f43ae1b94d8d92a8fc50">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Kim_Noise_Conditional_Flow_Model_for_Learning_the_Super-Resolution_Space_CVPRW_2021_paper.html">Noise Conditional Flow Model for Learning the Super-Resolution Space</a></th>
                    </tr>
                
                    <tr id="b2e1988b4d48058983f99d0f5020e73b1e2a7941">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b2e1988b4d48058983f99d0f5020e73b1e2a7941">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Yang_NTIRE_2021_Challenge_on_Quality_Enhancement_of_Compressed_Video_Dataset_CVPRW_2021_paper.html">NTIRE 2021 Challenge on Quality Enhancement of Compressed Video: Dataset and Study</a></th>
                    </tr>
                
                    <tr id="2166e6af2239c837aa26610dafcdb905b9145aa9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2166e6af2239c837aa26610dafcdb905b9145aa9">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Kinli_Instagram_Filter_Removal_on_Fashionable_Images_CVPRW_2021_paper.html">Instagram Filter Removal on Fashionable Images</a></th>
                    </tr>
                
                    <tr id="c87e81c5d988d276798720e2c91f26bef81aadd0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c87e81c5d988d276798720e2c91f26bef81aadd0">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Xu_Boosting_the_Performance_of_Video_Compression_Artifact_Reduction_With_Reference_CVPRW_2021_paper.html">Boosting the Performance of Video Compression Artifact Reduction With Reference Frame Proposals and Frequency Domain Information</a></th>
                    </tr>
                
                    <tr id="3d93fd5ead6644ea130052ba7c093375f24adbdf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3d93fd5ead6644ea130052ba7c093375f24adbdf">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Chen_Single-Image_HDR_Reconstruction_With_Task-Specific_Network_Based_on_Channel_Adaptive_CVPRW_2021_paper.html">Single-Image HDR Reconstruction With Task-Specific Network Based on Channel Adaptive RDN</a></th>
                    </tr>
                
                    <tr id="6749cb47d5294f3de07cef8b13073d81fbf74e74">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6749cb47d5294f3de07cef8b13073d81fbf74e74">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Jo_SRFlow-DA_Super-Resolution_Using_Normalizing_Flow_With_Deep_Convolutional_Block_CVPRW_2021_paper.html">SRFlow-DA: Super-Resolution Using Normalizing Flow With Deep Convolutional Block</a></th>
                    </tr>
                
                    <tr id="a6b05ddfee4190302bb7c6e2c040d17d3e15b356">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a6b05ddfee4190302bb7c6e2c040d17d3e15b356">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/UG2/html/Abello_Dissecting_the_High-Frequency_Bias_in_Convolutional_Neural_Networks_CVPRW_2021_paper.html">Dissecting the High-Frequency Bias in Convolutional Neural Networks</a></th>
                    </tr>
                
                    <tr id="195608bc28010cdaabc49b683c89c9aff34bff93">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/195608bc28010cdaabc49b683c89c9aff34bff93">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Xiang_Forensic_Analysis_of_Video_Files_Using_Metadata_CVPRW_2021_paper.html">Forensic Analysis of Video Files Using Metadata</a></th>
                    </tr>
                
                    <tr id="107eb32e949b2396a9750283eeeaf745123acc79">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/107eb32e949b2396a9750283eeeaf745123acc79">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LXCV/html/Valdenegro-Toro_I_Find_Your_Lack_of_Uncertainty_in_Computer_Vision_Disturbing_CVPRW_2021_paper.html">I Find Your Lack of Uncertainty in Computer Vision Disturbing</a></th>
                    </tr>
                
                    <tr id="55047f6d0cc19b3057961e3056818831db60502f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/55047f6d0cc19b3057961e3056818831db60502f">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Chiberre_Detecting_Stable_Keypoints_From_Events_Through_Image_Gradient_Prediction_CVPRW_2021_paper.html">Detecting Stable Keypoints From Events Through Image Gradient Prediction</a></th>
                    </tr>
                
                    <tr id="f9e8b8fb3d61d18313f8e48593d2807b9abaab0e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f9e8b8fb3d61d18313f8e48593d2807b9abaab0e">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Cannici_N-ROD_A_Neuromorphic_Dataset_for_Synthetic-to-Real_Domain_Adaptation_CVPRW_2021_paper.html">N-ROD: A Neuromorphic Dataset for Synthetic-to-Real Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="d30c8aa06a8c8234182f58f2a0c71e7beb4e3b73">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d30c8aa06a8c8234182f58f2a0c71e7beb4e3b73">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AUVi/html/Gomez_Improving_Parkinson_Detection_Using_Dynamic_Features_From_Evoked_Expressions_in_CVPRW_2021_paper.html">Improving Parkinson Detection Using Dynamic Features From Evoked Expressions in Video</a></th>
                    </tr>
                
                    <tr id="3be3b64b307f859e93479913fcb7ef0dc568843b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3be3b64b307f859e93479913fcb7ef0dc568843b">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Dong_Radar_Camera_Fusion_via_Representation_Learning_in_Autonomous_Driving_CVPRW_2021_paper.html">Radar Camera Fusion via Representation Learning in Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="7c44c0fa20e2a4b901286bfd83baf7a9dab95e44">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c44c0fa20e2a4b901286bfd83baf7a9dab95e44">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CiV/html/Zhang_Learning_Contextual_Causality_Between_Daily_Events_From_Time-Consecutive_Images_CVPRW_2021_paper.html">Learning Contextual Causality Between Daily Events From Time-Consecutive Images</a></th>
                    </tr>
                
                    <tr id="59feba414422264387df16afc60dc1857cd3cbda">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/59feba414422264387df16afc60dc1857cd3cbda">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Zhao_A_Universal_Encoder_Rate_Distortion_Optimization_Framework_for_Learned_Compression_CVPRW_2021_paper.html">A Universal Encoder Rate Distortion Optimization Framework for Learned Compression</a></th>
                    </tr>
                
                    <tr id="4ceb9f9534502dd926cbc1afcacd429fb8c89395">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4ceb9f9534502dd926cbc1afcacd429fb8c89395">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/RCV/html/Poppi_Revisiting_the_Evaluation_of_Class_Activation_Mapping_for_Explainability_A_CVPRW_2021_paper.html">Revisiting the Evaluation of Class Activation Mapping for Explainability: A Novel Metric and Experimental Analysis</a></th>
                    </tr>
                
                    <tr id="7252b5a3337cdab9dc9c33f8b00f5abde39a28ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7252b5a3337cdab9dc9c33f8b00f5abde39a28ab">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Sabater_One-Shot_Action_Recognition_in_Challenging_Therapy_Scenarios_CVPRW_2021_paper.html">One-Shot Action Recognition in Challenging Therapy Scenarios</a></th>
                    </tr>
                
                    <tr id="30101e7fb6310d0bfb2130ac627aeb090b0b50fc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/30101e7fb6310d0bfb2130ac627aeb090b0b50fc">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EVW/html/Aghli_Combining_Weight_Pruning_and_Knowledge_Distillation_for_CNN_Compression_CVPRW_2021_paper.html">Combining Weight Pruning and Knowledge Distillation for CNN Compression</a></th>
                    </tr>
                
                    <tr id="296a22664daf1a4a39a22697a6e379720646c283">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/296a22664daf1a4a39a22697a6e379720646c283">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Szymanowicz_X-MAN_Explaining_Multiple_Sources_of_Anomalies_in_Video_CVPRW_2021_paper.html">X-MAN: Explaining Multiple Sources of Anomalies in Video</a></th>
                    </tr>
                
                    <tr id="42451d1c180ffc87b4afd06f7e65782161b7d880">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/42451d1c180ffc87b4afd06f7e65782161b7d880">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Wang_InfoScrub_Towards_Attribute_Privacy_by_Targeted_Obfuscation_CVPRW_2021_paper.html">InfoScrub: Towards Attribute Privacy by Targeted Obfuscation</a></th>
                    </tr>
                
                    <tr id="7663a568ce56a0ce232a06d59b927b2e7010ab48">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7663a568ce56a0ce232a06d59b927b2e7010ab48">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ChaLearn/html/Moryossef_Evaluating_the_Immediate_Applicability_of_Pose_Estimation_for_Sign_Language_CVPRW_2021_paper.html">Evaluating the Immediate Applicability of Pose Estimation for Sign Language Recognition</a></th>
                    </tr>
                
                    <tr id="6e88a932058134bbdd37935862127133c6f67761">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6e88a932058134bbdd37935862127133c6f67761">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Wu_Box-Level_Tube_Tracking_and_Refinement_for_Vehicles_Anomaly_Detection_CVPRW_2021_paper.html">Box-Level Tube Tracking and Refinement for Vehicles Anomaly Detection</a></th>
                    </tr>
                
                    <tr id="2d6d84434fb1ceb95e877782a03baca3febed965">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d6d84434fb1ceb95e877782a03baca3febed965">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Nguyen_Traffic_Video_Event_Retrieval_via_Text_Query_Using_Vehicle_Appearance_CVPRW_2021_paper.html">Traffic Video Event Retrieval via Text Query Using Vehicle Appearance and Motion Attributes</a></th>
                    </tr>
                
                    <tr id="4296e2dd068b61e133b69cf5f48841054b86f1bb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4296e2dd068b61e133b69cf5f48841054b86f1bb">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Gloudemans_Fast_Vehicle_Turning-Movement_Counting_Using_Localization-Based_Tracking_CVPRW_2021_paper.html">Fast Vehicle Turning-Movement Counting Using Localization-Based Tracking</a></th>
                    </tr>
                
                    <tr id="8be19d9c441ebe6b0a6ce2f648dc7e4c4b742059">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8be19d9c441ebe6b0a6ce2f648dc7e4c4b742059">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Lu_Robust_and_Online_Vehicle_Counting_at_Crowded_Intersections_CVPRW_2021_paper.html">Robust and Online Vehicle Counting at Crowded Intersections</a></th>
                    </tr>
                
                    <tr id="46ecff6db6e08b7e610e392d7a07a0582d69e5bf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/46ecff6db6e08b7e610e392d7a07a0582d69e5bf">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Doshi_An_Efficient_Approach_for_Anomaly_Detection_in_Traffic_Videos_CVPRW_2021_paper.html">An Efficient Approach for Anomaly Detection in Traffic Videos</a></th>
                    </tr>
                
                    <tr id="15b2e1104e183822e2c1d5b42501a890d81df83b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15b2e1104e183822e2c1d5b42501a890d81df83b">6</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DiffCVML/html/Zhang_Deep_Spherical_Manifold_Gaussian_Kernel_for_Unsupervised_Domain_Adaptation_CVPRW_2021_paper.html">Deep Spherical Manifold Gaussian Kernel for Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="bd0cf7c85cdb91d52596d8b9cfd80ca34bdb19d9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bd0cf7c85cdb91d52596d8b9cfd80ca34bdb19d9">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Franz_Global_Transport_for_Fluid_Reconstruction_With_Learned_Self-Supervision_CVPR_2021_paper.html">Global Transport for Fluid Reconstruction With Learned Self-Supervision</a></th>
                    </tr>
                
                    <tr id="3ae27c83301cc75bcdc57b11cb8739bc580a7bda">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ae27c83301cc75bcdc57b11cb8739bc580a7bda">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tan_Mirror3D_Depth_Refinement_for_Mirror_Surfaces_CVPR_2021_paper.html">Mirror3D: Depth Refinement for Mirror Surfaces</a></th>
                    </tr>
                
                    <tr id="9c5599861fee2cd8b6b4c3747d9341b9c70a3baa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9c5599861fee2cd8b6b4c3747d9341b9c70a3baa">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hou_Informative_and_Consistent_Correspondence_Mining_for_Cross-Domain_Weakly_Supervised_Object_CVPR_2021_paper.html">Informative and Consistent Correspondence Mining for Cross-Domain Weakly Supervised Object Detection</a></th>
                    </tr>
                
                    <tr id="7100fa152f6ff7e6aab8f4d78dafe69ef7f04c78">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7100fa152f6ff7e6aab8f4d78dafe69ef7f04c78">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zadorozhnyy_Adaptive_Weighted_Discriminator_for_Training_Generative_Adversarial_Networks_CVPR_2021_paper.html">Adaptive Weighted Discriminator for Training Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="5b81580712f6e16abd05824c162537674e99b095">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5b81580712f6e16abd05824c162537674e99b095">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhu_Learning_Neural_Representation_of_Camera_Pose_with_Matrix_Representation_of_CVPR_2021_paper.html">Learning Neural Representation of Camera Pose with Matrix Representation of Pose Shift via View Synthesis</a></th>
                    </tr>
                
                    <tr id="8f7ed8686fc97c4e624c8ea4f52fc48d3b03d6b7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f7ed8686fc97c4e624c8ea4f52fc48d3b03d6b7">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cheng_Learning_Deep_Classifiers_Consistent_With_Fine-Grained_Novelty_Detection_CVPR_2021_paper.html">Learning Deep Classifiers Consistent With Fine-Grained Novelty Detection</a></th>
                    </tr>
                
                    <tr id="3eeae55a6016c09ced79fc9e1982400ed1bf8466">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3eeae55a6016c09ced79fc9e1982400ed1bf8466">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Restore_From_Restored_Video_Restoration_With_Pseudo_Clean_Video_CVPR_2021_paper.html">Restore From Restored: Video Restoration With Pseudo Clean Video</a></th>
                    </tr>
                
                    <tr id="e5cfe35c9516ae299a3adcc6da39e63e6bfdc3ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5cfe35c9516ae299a3adcc6da39e63e6bfdc3ff">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_Not_Just_Compete_but_Collaborate_Local_Image-to-Image_Translation_via_Cooperative_CVPR_2021_paper.html">Not Just Compete, but Collaborate: Local Image-to-Image Translation via Cooperative Mask Prediction</a></th>
                    </tr>
                
                    <tr id="302e4537b277384542d7f0b5cdc4db33abbaa1db">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/302e4537b277384542d7f0b5cdc4db33abbaa1db">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bodla_Hierarchical_Video_Prediction_Using_Relational_Layouts_for_Human-Object_Interactions_CVPR_2021_paper.html">Hierarchical Video Prediction Using Relational Layouts for Human-Object Interactions</a></th>
                    </tr>
                
                    <tr id="645bb80a11cf1cbbba014227033b492f0f0e027b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/645bb80a11cf1cbbba014227033b492f0f0e027b">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shacht_Single_Pair_Cross-Modality_Super_Resolution_CVPR_2021_paper.html">Single Pair Cross-Modality Super Resolution</a></th>
                    </tr>
                
                    <tr id="20456388aedbdaaf9ddfc0e7d96bf90fc03af15b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/20456388aedbdaaf9ddfc0e7d96bf90fc03af15b">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tennakoon_Consensus_Maximisation_Using_Influences_of_Monotone_Boolean_Functions_CVPR_2021_paper.html">Consensus Maximisation Using Influences of Monotone Boolean Functions</a></th>
                    </tr>
                
                    <tr id="037440ca869cde871cf311374f4d792bffc63d7d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/037440ca869cde871cf311374f4d792bffc63d7d">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_S3_Learnable_Sparse_Signal_Superdensity_for_Guided_Depth_Estimation_CVPR_2021_paper.html">S3: Learnable Sparse Signal Superdensity for Guided Depth Estimation</a></th>
                    </tr>
                
                    <tr id="4de17fe5c301e90062c8edad26c91ab7867913df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4de17fe5c301e90062c8edad26c91ab7867913df">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chelani_How_Privacy-Preserving_Are_Line_Clouds_Recovering_Scene_Details_From_3D_CVPR_2021_paper.html">How Privacy-Preserving Are Line Clouds? Recovering Scene Details From 3D Lines</a></th>
                    </tr>
                
                    <tr id="ef53a10ad78bb4590c984245f6eb103575add267">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ef53a10ad78bb4590c984245f6eb103575add267">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ma_CapsuleRRT_Relationships-Aware_Regression_Tracking_via_Capsules_CVPR_2021_paper.html">CapsuleRRT: Relationships-Aware Regression Tracking via Capsules</a></th>
                    </tr>
                
                    <tr id="a687a2efa9b215a8d0710b96b24f63ad9b53a804">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a687a2efa9b215a8d0710b96b24f63ad9b53a804">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Multi-Label_Activity_Recognition_Using_Activity-Specific_Features_and_Activity_Correlations_CVPR_2021_paper.html">Multi-Label Activity Recognition Using Activity-Specific Features and Activity Correlations</a></th>
                    </tr>
                
                    <tr id="27ce83180648b63f045d531036055cd6608eebe5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/27ce83180648b63f045d531036055cd6608eebe5">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Training_Generative_Adversarial_Networks_in_One_Stage_CVPR_2021_paper.html">Training Generative Adversarial Networks in One Stage</a></th>
                    </tr>
                
                    <tr id="8b09d1377d312def10c9335ab486f605002d7bc1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8b09d1377d312def10c9335ab486f605002d7bc1">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Amir_Understanding_and_Simplifying_Perceptual_Distances_CVPR_2021_paper.html">Understanding and Simplifying Perceptual Distances</a></th>
                    </tr>
                
                    <tr id="7c8b60cfffb711abefe090c39316b5d5aab268d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c8b60cfffb711abefe090c39316b5d5aab268d2">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Su_The_Affective_Growth_of_Computer_Vision_CVPR_2021_paper.html">The Affective Growth of Computer Vision</a></th>
                    </tr>
                
                    <tr id="cde7688f482dd6172419c324816b519a654a304a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cde7688f482dd6172419c324816b519a654a304a">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_LPSNet_A_Lightweight_Solution_for_Fast_Panoptic_Segmentation_CVPR_2021_paper.html">LPSNet: A Lightweight Solution for Fast Panoptic Segmentation</a></th>
                    </tr>
                
                    <tr id="e19c76aa52268ef19024cdff987878b840fb3260">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e19c76aa52268ef19024cdff987878b840fb3260">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Mol2Image_Improved_Conditional_Flow_Models_for_Molecule_to_Image_Synthesis_CVPR_2021_paper.html">Mol2Image: Improved Conditional Flow Models for Molecule to Image Synthesis</a></th>
                    </tr>
                
                    <tr id="b5126ed0d46ef7af3663f60fcaacf1c503e4065d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b5126ed0d46ef7af3663f60fcaacf1c503e4065d">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Harley_Track_Check_Repeat_An_EM_Approach_to_Unsupervised_Tracking_CVPR_2021_paper.html">Track, Check, Repeat: An EM Approach to Unsupervised Tracking</a></th>
                    </tr>
                
                    <tr id="c96c9bb08aa08b157ea01a77087849ebecd2238c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c96c9bb08aa08b157ea01a77087849ebecd2238c">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Robust_Bayesian_Neural_Networks_by_Spectral_Expectation_Bound_Regularization_CVPR_2021_paper.html">Robust Bayesian Neural Networks by Spectral Expectation Bound Regularization</a></th>
                    </tr>
                
                    <tr id="54324947ec5fc5bcc5454cbfa1bac26019eb2c7e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/54324947ec5fc5bcc5454cbfa1bac26019eb2c7e">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Song_Co-Grounding_Networks_With_Semantic_Attention_for_Referring_Expression_Comprehension_in_CVPR_2021_paper.html">Co-Grounding Networks With Semantic Attention for Referring Expression Comprehension in Videos</a></th>
                    </tr>
                
                    <tr id="67a532b116febf6629cad1e2c71b7f13b4c8e6b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/67a532b116febf6629cad1e2c71b7f13b4c8e6b1">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Inverse_Simulation_Reconstructing_Dynamic_Geometry_of_Clothed_Humans_via_Optimal_CVPR_2021_paper.html">Inverse Simulation: Reconstructing Dynamic Geometry of Clothed Humans via Optimal Control</a></th>
                    </tr>
                
                    <tr id="c22060424a75f0e8888fbe2af80f3740b61d286a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c22060424a75f0e8888fbe2af80f3740b61d286a">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Song_Dynamic_Probabilistic_Graph_Convolution_for_Facial_Action_Unit_Intensity_Estimation_CVPR_2021_paper.html">Dynamic Probabilistic Graph Convolution for Facial Action Unit Intensity Estimation</a></th>
                    </tr>
                
                    <tr id="3c6321c030b656f6735c0b0239a18b7f8d30f438">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3c6321c030b656f6735c0b0239a18b7f8d30f438">5</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhong_DAP_Detection-Aware_Pre-Training_With_Weak_Supervision_CVPR_2021_paper.html">DAP: Detection-Aware Pre-training with Weak Supervision</a></th>
                    </tr>
                
                    <tr id="70bb50d4a63042341bc5c3a7d08740f2520834c7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70bb50d4a63042341bc5c3a7d08740f2520834c7">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Singh_Simulation_Driven_Design_and_Test_for_Safety_of_AI_Based_CVPRW_2021_paper.html">Simulation Driven Design and Test for Safety of AI Based Autonomous Vehicles</a></th>
                    </tr>
                
                    <tr id="9afd4501100f3abbad90f570331ebe09d3e375c4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9afd4501100f3abbad90f570331ebe09d3e375c4">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Addepalli_Boosting_Adversarial_Robustness_Using_Feature_Level_Stochastic_Smoothing_CVPRW_2021_paper.html">Boosting Adversarial Robustness Using Feature Level Stochastic Smoothing</a></th>
                    </tr>
                
                    <tr id="81077eda904a87aa1238a60bdd10118979293e36">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/81077eda904a87aa1238a60bdd10118979293e36">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Fontanel_Detecting_Anomalies_in_Semantic_Segmentation_With_Prototypes_CVPRW_2021_paper.html">Detecting Anomalies in Semantic Segmentation With Prototypes</a></th>
                    </tr>
                
                    <tr id="e9eb8a29074ff425da91dc7f0a1ac38a527ef9ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e9eb8a29074ff425da91dc7f0a1ac38a527ef9ab">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Lyssenko_From_Evaluation_to_Verification_Towards_Task-Oriented_Relevance_Metrics_for_Pedestrian_CVPRW_2021_paper.html">From Evaluation to Verification: Towards Task-Oriented Relevance Metrics for Pedestrian Detection in Safety-Critical Domains</a></th>
                    </tr>
                
                    <tr id="d97e585758e419b9be61bbb5a6760574dd6825f5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d97e585758e419b9be61bbb5a6760574dd6825f5">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Lin_Edge_Guided_Progressively_Generative_Image_Outpainting_CVPRW_2021_paper.html">Edge Guided Progressively Generative Image Outpainting</a></th>
                    </tr>
                
                    <tr id="812e2288d89427a83b7fb0d6ed52d9cad3b76689">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/812e2288d89427a83b7fb0d6ed52d9cad3b76689">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Yang_S3Net_A_Single_Stream_Structure_for_Depth_Guided_Image_Relighting_CVPRW_2021_paper.html">S3Net: A Single Stream Structure for Depth Guided Image Relighting</a></th>
                    </tr>
                
                    <tr id="a8265e320bb8aac2b603d7a20fe3bfbc7d1e2ea6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a8265e320bb8aac2b603d7a20fe3bfbc7d1e2ea6">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Liu_Variational_AutoEncoder_for_Reference_Based_Image_Super-Resolution_CVPRW_2021_paper.html">Variational AutoEncoder for Reference Based Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="5ae9da1c15725878549f0661028cb52923d3f70b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5ae9da1c15725878549f0661028cb52923d3f70b">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Jo_Multi-Scale_Selective_Residual_Learning_for_Non-Homogeneous_Dehazing_CVPRW_2021_paper.html">Multi-Scale Selective Residual Learning for Non-Homogeneous Dehazing</a></th>
                    </tr>
                
                    <tr id="2b8940e5b3de02c6db110b4bbe7fd1febc32ee76">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b8940e5b3de02c6db110b4bbe7fd1febc32ee76">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Verma_QFabric_Multi-Task_Change_Detection_Dataset_CVPRW_2021_paper.html">QFabric: Multi-Task Change Detection Dataset</a></th>
                    </tr>
                
                    <tr id="51090c92c542c4b27be3168d4b0a29b774874123">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/51090c92c542c4b27be3168d4b0a29b774874123">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Xu_Dot_Distance_for_Tiny_Object_Detection_in_Aerial_Images_CVPRW_2021_paper.html">Dot Distance for Tiny Object Detection in Aerial Images</a></th>
                    </tr>
                
                    <tr id="bc388f97401b249cdcd7bb2389263fc1fc3f6728">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bc388f97401b249cdcd7bb2389263fc1fc3f6728">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AMFG/html/Xin_EVA-GCN_Head_Pose_Estimation_Based_on_Graph_Convolutional_Networks_CVPRW_2021_paper.html">EVA-GCN: Head Pose Estimation Based on Graph Convolutional Networks</a></th>
                    </tr>
                
                    <tr id="ede07c5c45b1c1d6bba585e87008932537dcc595">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ede07c5c45b1c1d6bba585e87008932537dcc595">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Alcazar_APES_Audiovisual_Person_Search_in_Untrimmed_Video_CVPRW_2021_paper.html">APES: Audiovisual Person Search in Untrimmed Video</a></th>
                    </tr>
                
                    <tr id="98ae5913e9b5de1225076bbdf27bb7173cd3a07e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/98ae5913e9b5de1225076bbdf27bb7173cd3a07e">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Nawaz_Cross-Modal_Speaker_Verification_and_Recognition_A_Multilingual_Perspective_CVPRW_2021_paper.html">Cross-Modal Speaker Verification and Recognition: A Multilingual Perspective</a></th>
                    </tr>
                
                    <tr id="128f8e6b915458ff946fb316c65c4d45184381af">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/128f8e6b915458ff946fb316c65c4d45184381af">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CiV/html/Vowels_Shadow-Mapping_for_Unsupervised_Neural_Causal_Discovery_CVPRW_2021_paper.html">Shadow-Mapping for Unsupervised Neural Causal Discovery</a></th>
                    </tr>
                
                    <tr id="9a44aebcfc91c7db51769fe51216ecd0acadedf6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9a44aebcfc91c7db51769fe51216ecd0acadedf6">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Dung_A_Spacecraft_Dataset_for_Detection_Segmentation_and_Parts_Recognition_CVPRW_2021_paper.html">A Spacecraft Dataset for Detection, Segmentation and Parts Recognition</a></th>
                    </tr>
                
                    <tr id="a16a4b2b1b241ec9a5dde1645406069c8a5e7a2c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a16a4b2b1b241ec9a5dde1645406069c8a5e7a2c">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Kucik_Investigating_Spiking_Neural_Networks_for_Energy-Efficient_On-Board_AI_Applications._A_CVPRW_2021_paper.html">Investigating Spiking Neural Networks for Energy-Efficient On-Board AI Applications. A Case Study in Land Cover and Land Use Classification</a></th>
                    </tr>
                
                    <tr id="c791b3b549ca62702ebd76230329a6bee3e90828">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c791b3b549ca62702ebd76230329a6bee3e90828">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WiCV/html/Goel_On_the_Robustness_of_Monte_Carlo_Dropout_Trained_With_Noisy_CVPRW_2021_paper.html">On the Robustness of Monte Carlo Dropout Trained With Noisy Labels</a></th>
                    </tr>
                
                    <tr id="63efaad771a5677707b185c3d7c3e015941bed6b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/63efaad771a5677707b185c3d7c3e015941bed6b">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Precognition/html/Wang_End-to-End_Interactive_Prediction_and_Planning_With_Optical_Flow_Distillation_for_CVPRW_2021_paper.html">End-to-End Interactive Prediction and Planning With Optical Flow Distillation for Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="919cb84e6d19505625d2df763ae267c4a0cb6334">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/919cb84e6d19505625d2df763ae267c4a0cb6334">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/RCV/html/Wang_MTUNet_Few-Shot_Image_Classification_With_Visual_Explanations_CVPRW_2021_paper.html">MTUNet: Few-Shot Image Classification With Visual Explanations</a></th>
                    </tr>
                
                    <tr id="cbebf6a6ad306fc5f5a040dfbd956292f9904d55">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cbebf6a6ad306fc5f5a040dfbd956292f9904d55">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WAD/html/He_Semi-Synthesis_A_Fast_Way_To_Produce_Effective_Datasets_for_Stereo_CVPRW_2021_paper.html">Semi-Synthesis: A Fast Way To Produce Effective Datasets for Stereo Matching</a></th>
                    </tr>
                
                    <tr id="f104854bc499561f9d1eca3a489724e5e75b76cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f104854bc499561f9d1eca3a489724e5e75b76cc">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AgriVision/html/Wang_Phenology_Alignment_Network_A_Novel_Framework_for_Cross-Regional_Time_Series_CVPRW_2021_paper.html">Phenology Alignment Network: A Novel Framework for Cross-Regional Time Series Crop Classification</a></th>
                    </tr>
                
                    <tr id="f6f3266e92f508b84bd0e81585215c95bc4c3da9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f6f3266e92f508b84bd0e81585215c95bc4c3da9">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ChaLearn/html/Renz_Sign_Segmentation_With_Changepoint-Modulated_Pseudo-Labelling_CVPRW_2021_paper.html">Sign Segmentation With Changepoint-Modulated Pseudo-Labelling</a></th>
                    </tr>
                
                    <tr id="3e8a178e08617cbf2f71f87eabd6a8afacce0248">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3e8a178e08617cbf2f71f87eabd6a8afacce0248">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/OmniCV/html/Plaut_3D_Object_Detection_From_a_Single_Fisheye_Image_Without_a_CVPRW_2021_paper.html">3D Object Detection From a Single Fisheye Image Without a Single Fisheye Training Image</a></th>
                    </tr>
                
                    <tr id="a6be6f3905b32d4e7a4b9157ff4da8dd0156019c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a6be6f3905b32d4e7a4b9157ff4da8dd0156019c">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/OmniCV/html/Seidel_OmniFlow_Human_Omnidirectional_Optical_Flow_CVPRW_2021_paper.html">OmniFlow: Human Omnidirectional Optical Flow</a></th>
                    </tr>
                
                    <tr id="99f3d0831e13040e99f67620bdac56bdcf50f49f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/99f3d0831e13040e99f67620bdac56bdcf50f49f">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVMI/html/Wu_RCNN-SliceNet_A_Slice_and_Cluster_Approach_for_Nuclei_Centroid_Detection_CVPRW_2021_paper.html">RCNN-SliceNet: A Slice and Cluster Approach for Nuclei Centroid Detection in Three-Dimensional Fluorescence Microscopy Images</a></th>
                    </tr>
                
                    <tr id="2d97b455e25de9fbe4b4986de7e8cffc42eb6f47">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d97b455e25de9fbe4b4986de7e8cffc42eb6f47">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVMI/html/Stepec_Unsupervised_Detection_of_Cancerous_Regions_in_Histology_Imagery_Using_Image-to-Image_CVPRW_2021_paper.html">Unsupervised Detection of Cancerous Regions in Histology Imagery Using Image-to-Image Translation</a></th>
                    </tr>
                
                    <tr id="1449ac79c31428175d7496e41485126455353d8c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1449ac79c31428175d7496e41485126455353d8c">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/DInnocente_Localized_Triplet_Loss_for_Fine-Grained_Fashion_Image_Retrieval_CVPRW_2021_paper.html">Localized Triplet Loss for Fine-Grained Fashion Image Retrieval</a></th>
                    </tr>
                
                    <tr id="345d8f6301f3ce296ab08fde344917b1237361a1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/345d8f6301f3ce296ab08fde344917b1237361a1">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Deldjoo_A_Study_on_the_Relative_Importance_of_Convolutional_Neural_Networks_CVPRW_2021_paper.html">A Study on the Relative Importance of Convolutional Neural Networks in Visually-Aware Recommender Systems</a></th>
                    </tr>
                
                    <tr id="2cadf52b820d31debe565c15317d86c3fcd3a91e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2cadf52b820d31debe565c15317d86c3fcd3a91e">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Yuan_Line_Art_Colorization_With_Concatenated_Spatial_Attention_CVPRW_2021_paper.html">Line Art Colorization With Concatenated Spatial Attention</a></th>
                    </tr>
                
                    <tr id="d412a13e853933fed545aa1c4e7392bce79f497a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d412a13e853933fed545aa1c4e7392bce79f497a">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Parekh_Fine-Grained_Visual_Attribute_Extraction_From_Fashion_Wear_CVPRW_2021_paper.html">Fine-Grained Visual Attribute Extraction From Fashion Wear</a></th>
                    </tr>
                
                    <tr id="3918ca2dbc773e044a259df7cc15c8907fbc048c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3918ca2dbc773e044a259df7cc15c8907fbc048c">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Chen_Dual-Modality_Vehicle_Anomaly_Detection_via_Bilateral_Trajectory_Tracing_CVPRW_2021_paper.html">Dual-Modality Vehicle Anomaly Detection via Bilateral Trajectory Tracing</a></th>
                    </tr>
                
                    <tr id="4f6ea8c1c5a069c2d7c038a2235f92ca87318beb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f6ea8c1c5a069c2d7c038a2235f92ca87318beb">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Sun_DUN_Dual-Path_Temporal_Matching_Network_for_Natural_Language-Based_Vehicle_Retrieval_CVPRW_2021_paper.html">DUN: Dual-Path Temporal Matching Network for Natural Language-Based Vehicle Retrieval</a></th>
                    </tr>
                
                    <tr id="0025963ee4b1c61c59a2dd783d3338384b72e102">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0025963ee4b1c61c59a2dd783d3338384b72e102">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Jiang_Robust_Vehicle_Re-Identification_via_Rigid_Structure_Prior_CVPRW_2021_paper.html">Robust Vehicle Re-Identification via Rigid Structure Prior</a></th>
                    </tr>
                
                    <tr id="8be99c2d0802d6222e233dd67d2927c75a0bed24">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8be99c2d0802d6222e233dd67d2927c75a0bed24">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Khorramshahi_Towards_Accurate_Visual_and_Natural_Language-Based_Vehicle_Retrieval_Systems_CVPRW_2021_paper.html">Towards Accurate Visual and Natural Language-Based Vehicle Retrieval Systems</a></th>
                    </tr>
                
                    <tr id="35e841a8f0c2a2e5780303080578962b390e3408">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/35e841a8f0c2a2e5780303080578962b390e3408">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Tran_A_Region-and-Trajectory_Movement_Matching_for_Multiple_Turn-Counts_at_Road_Intersection_CVPRW_2021_paper.html">A Region-and-Trajectory Movement Matching for Multiple Turn-Counts at Road Intersection on Edge Device</a></th>
                    </tr>
                
                    <tr id="8902e85a57b8714e02395ee7832cf6c70094beab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8902e85a57b8714e02395ee7832cf6c70094beab">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/PBVS/html/Ellenfeld_Deep_Fusion_of_Appearance_and_Frame_Differencing_for_Motion_Segmentation_CVPRW_2021_paper.html">Deep Fusion of Appearance and Frame Differencing for Motion Segmentation</a></th>
                    </tr>
                
                    <tr id="5456822fd85f77b8ef2f33e3f0bce65cbcc30726">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5456822fd85f77b8ef2f33e3f0bce65cbcc30726">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DiffCVML/html/Miller_Multi_Scale_Diffeomorphic_Metric_Mapping_of_Spatial_Transcriptomics_Datasets_CVPRW_2021_paper.html">Multi Scale Diffeomorphic Metric Mapping of Spatial Transcriptomics Datasets</a></th>
                    </tr>
                
                    <tr id="f40749601f3e0e9a92b7c9556901849499645733">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f40749601f3e0e9a92b7c9556901849499645733">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/Tanaka_LoL-V2T_Large-Scale_Esports_Video_Description_Dataset_CVPRW_2021_paper.html">LoL-V2T: Large-Scale Esports Video Description Dataset</a></th>
                    </tr>
                
                    <tr id="a77a67609656199890c39430d6bd5553b164fed9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a77a67609656199890c39430d6bd5553b164fed9">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/Martin_Automated_Tackle_Injury_Risk_Assessment_in_Contact-Based_Sports_-_A_CVPRW_2021_paper.html">Automated Tackle Injury Risk Assessment in Contact-Based Sports - A Rugby Union Example</a></th>
                    </tr>
                
                    <tr id="c7bdbc37877e690844d887982fddcb3f09d3f21c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c7bdbc37877e690844d887982fddcb3f09d3f21c">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/Vats_Puck_Localization_and_Multi-Task_Event_Recognition_in_Broadcast_Hockey_Videos_CVPRW_2021_paper.html">Puck Localization and Multi-Task Event Recognition in Broadcast Hockey Videos</a></th>
                    </tr>
                
                    <tr id="0b77c60826c080841d2fc163e93b459eb20a1d34">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0b77c60826c080841d2fc163e93b459eb20a1d34">5</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/BiVision/html/Laydevant_Training_Dynamical_Binary_Neural_Networks_With_Equilibrium_Propagation_CVPRW_2021_paper.html">Training Dynamical Binary Neural Networks With Equilibrium Propagation</a></th>
                    </tr>
                
                    <tr id="4a88e707ab68b4ed3f49fac34a999b2575254b03">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4a88e707ab68b4ed3f49fac34a999b2575254b03">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Geppert_Privacy_Preserving_Localization_and_Mapping_From_Uncalibrated_Cameras_CVPR_2021_paper.html">Privacy Preserving Localization and Mapping From Uncalibrated Cameras</a></th>
                    </tr>
                
                    <tr id="7de5f1aa200affde036a1bb041be026d1eb92577">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7de5f1aa200affde036a1bb041be026d1eb92577">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Generating_Manga_From_Illustrations_via_Mimicking_Manga_Creation_Workflow_CVPR_2021_paper.html">Generating Manga From Illustrations via Mimicking Manga Creation Workflow</a></th>
                    </tr>
                
                    <tr id="c226e57f7bc35427310e1b4c559a94579ef45e69">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c226e57f7bc35427310e1b4c559a94579ef45e69">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Mullapudi_Background_Splitting_Finding_Rare_Classes_in_a_Sea_of_Background_CVPR_2021_paper.html">Background Splitting: Finding Rare Classes in a Sea of Background</a></th>
                    </tr>
                
                    <tr id="26d26a2a38908c9ee5acb3d3fc4f4e6db133b19c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/26d26a2a38908c9ee5acb3d3fc4f4e6db133b19c">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Delving_Deep_Into_Many-to-Many_Attention_for_Few-Shot_Video_Object_Segmentation_CVPR_2021_paper.html">Delving Deep Into Many-to-Many Attention for Few-Shot Video Object Segmentation</a></th>
                    </tr>
                
                    <tr id="7d5b513aad54fb6a2bc63c6703d49c316a98aeda">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7d5b513aad54fb6a2bc63c6703d49c316a98aeda">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Implicit_Feature_Alignment_Learn_To_Convert_Text_Recognizer_to_Text_CVPR_2021_paper.html">Implicit Feature Alignment: Learn To Convert Text Recognizer to Text Spotter</a></th>
                    </tr>
                
                    <tr id="8ddbdfb9d587202970a8f4e5d5f3367dad94aab7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8ddbdfb9d587202970a8f4e5d5f3367dad94aab7">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Repopulating_Street_Scenes_CVPR_2021_paper.html">Repopulating Street Scenes</a></th>
                    </tr>
                
                    <tr id="0e64bbaba70918d3b0f72f014e23eca37e658eb4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e64bbaba70918d3b0f72f014e23eca37e658eb4">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Continuous_Face_Aging_via_Self-Estimated_Residual_Age_Embedding_CVPR_2021_paper.html">Continuous Face Aging via Self-Estimated Residual Age Embedding</a></th>
                    </tr>
                
                    <tr id="647c87250a6c68c5a63d9da166d1f520c55db02e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/647c87250a6c68c5a63d9da166d1f520c55db02e">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chugunov_Mask-ToF_Learning_Microlens_Masks_for_Flying_Pixel_Correction_in_Time-of-Flight_CVPR_2021_paper.html">Mask-ToF: Learning Microlens Masks for Flying Pixel Correction in Time-of-Flight Imaging</a></th>
                    </tr>
                
                    <tr id="782557405250b04bb7287f50c3f52046dab7f81a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/782557405250b04bb7287f50c3f52046dab7f81a">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Fu_Double_Low-Rank_Representation_With_Projection_Distance_Penalty_for_Clustering_CVPR_2021_paper.html">Double Low-Rank Representation With Projection Distance Penalty for Clustering</a></th>
                    </tr>
                
                    <tr id="4210ca43b545bca3aa19a72a7741304aecab409b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4210ca43b545bca3aa19a72a7741304aecab409b">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhuang_Fusing_the_Old_with_the_New_Learning_Relative_Camera_Pose_CVPR_2021_paper.html">Fusing the Old with the New: Learning Relative Camera Pose with Geometry-Guided Uncertainty</a></th>
                    </tr>
                
                    <tr id="6bccfc8e175f3cb9cc1bfd56cff77142acd35fd5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6bccfc8e175f3cb9cc1bfd56cff77142acd35fd5">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Armandpour_Partition-Guided_GANs_CVPR_2021_paper.html">Partition-Guided GANs</a></th>
                    </tr>
                
                    <tr id="65350c1bc1f295bb76ac43cbecd1a5d20ccd0140">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/65350c1bc1f295bb76ac43cbecd1a5d20ccd0140">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Min_GATSBI_Generative_Agent-Centric_Spatio-Temporal_Object_Interaction_CVPR_2021_paper.html">GATSBI: Generative Agent-Centric Spatio-Temporal Object Interaction</a></th>
                    </tr>
                
                    <tr id="8766d273dd20f82f75b0376e75e10f35a851cce6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8766d273dd20f82f75b0376e75e10f35a851cce6">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_IronMask_Modular_Architecture_for_Protecting_Deep_Face_Template_CVPR_2021_paper.html">IronMask: Modular Architecture for Protecting Deep Face Template</a></th>
                    </tr>
                
                    <tr id="12da7d6c08438ab1e832870d1192ddbe35eaf58b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/12da7d6c08438ab1e832870d1192ddbe35eaf58b">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yin_Learning_To_Recommend_Frame_for_Interactive_Video_Object_Segmentation_in_CVPR_2021_paper.html">Learning To Recommend Frame for Interactive Video Object Segmentation in the Wild</a></th>
                    </tr>
                
                    <tr id="db2ff14da0b74916a1a59269871c7013627fa15d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db2ff14da0b74916a1a59269871c7013627fa15d">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Dynamic_Domain_Adaptation_for_Efficient_Inference_CVPR_2021_paper.html">Dynamic Domain Adaptation for Efficient Inference</a></th>
                    </tr>
                
                    <tr id="4205578153715bfd7ebd51bbf5c845f38135252f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4205578153715bfd7ebd51bbf5c845f38135252f">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zheng_Unsupervised_Disentanglement_of_Linear-Encoded_Facial_Semantics_CVPR_2021_paper.html">Unsupervised Disentanglement of Linear-Encoded Facial Semantics</a></th>
                    </tr>
                
                    <tr id="3b0576d5a54cf4bdd1ec6aa3f495f5492f3a6b56">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3b0576d5a54cf4bdd1ec6aa3f495f5492f3a6b56">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Truong_Unsupervised_Learning_for_Robust_Fitting_A_Reinforcement_Learning_Approach_CVPR_2021_paper.html">Unsupervised Learning for Robust Fitting: A Reinforcement Learning Approach</a></th>
                    </tr>
                
                    <tr id="b5dfdbc5c61747ef112de79144bae53d1981a5ba">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b5dfdbc5c61747ef112de79144bae53d1981a5ba">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Abdelhamed_Leveraging_the_Availability_of_Two_Cameras_for_Illuminant_Estimation_CVPR_2021_paper.html">Leveraging the Availability of Two Cameras for Illuminant Estimation</a></th>
                    </tr>
                
                    <tr id="3e9fa14b16c3092718f3f9468553e106aa4ac818">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3e9fa14b16c3092718f3f9468553e106aa4ac818">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_MetricOpt_Learning_To_Optimize_Black-Box_Evaluation_Metrics_CVPR_2021_paper.html">MetricOpt: Learning To Optimize Black-Box Evaluation Metrics</a></th>
                    </tr>
                
                    <tr id="c27cf485fa3d056d2b6f7560779b2c2b5978d50d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c27cf485fa3d056d2b6f7560779b2c2b5978d50d">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Multispectral_Photometric_Stereo_for_Spatially-Varying_Spectral_Reflectances_A_Well_Posed_CVPR_2021_paper.html">Multispectral Photometric Stereo for Spatially-Varying Spectral Reflectances: A Well Posed Problem?</a></th>
                    </tr>
                
                    <tr id="1193fc121f9be24a5da562745dd3a07a1e1a7269">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1193fc121f9be24a5da562745dd3a07a1e1a7269">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Epstein_Learning_Goals_From_Failure_CVPR_2021_paper.html">Learning Goals From Failure</a></th>
                    </tr>
                
                    <tr id="7c49e6cd95e96934ed80ff7ce59c02fef51b2baf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c49e6cd95e96934ed80ff7ce59c02fef51b2baf">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Wide-Baseline_Multi-Camera_Calibration_Using_Person_Re-Identification_CVPR_2021_paper.html">Wide-Baseline Multi-Camera Calibration Using Person Re-Identification</a></th>
                    </tr>
                
                    <tr id="492276505cf4a5c6c5c421bbdd9d01557438578d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/492276505cf4a5c6c5c421bbdd9d01557438578d">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ruan_Gaussian_Context_Transformer_CVPR_2021_paper.html">Gaussian Context Transformer</a></th>
                    </tr>
                
                    <tr id="1c1fe6175e9af1365c10a177ec9f789f977b7345">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1c1fe6175e9af1365c10a177ec9f789f977b7345">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tuan_ColorRL_Reinforced_Coloring_for_End-to-End_Instance_Segmentation_CVPR_2021_paper.html">ColorRL: Reinforced Coloring for End-to-End Instance Segmentation</a></th>
                    </tr>
                
                    <tr id="31f9c1159c60cf9ac617ce4e99eab13e4311378b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/31f9c1159c60cf9ac617ce4e99eab13e4311378b">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Indoor_Panorama_Planar_3D_Reconstruction_via_Divide_and_Conquer_CVPR_2021_paper.html">Indoor Panorama Planar 3D Reconstruction via Divide and Conquer</a></th>
                    </tr>
                
                    <tr id="7cc1957396ea32aec93434f4d27019b7fc757450">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7cc1957396ea32aec93434f4d27019b7fc757450">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Angles_MIST_Multiple_Instance_Spatial_Transformer_CVPR_2021_paper.html">MIST: Multiple Instance Spatial Transformer</a></th>
                    </tr>
                
                    <tr id="4f2649b5b0452fd982699562027b4c9cbd7194ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f2649b5b0452fd982699562027b4c9cbd7194ad">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pang_PGT_A_Progressive_Method_for_Training_Models_on_Long_Videos_CVPR_2021_paper.html">PGT: A Progressive Method for Training Models on Long Videos</a></th>
                    </tr>
                
                    <tr id="9ccfd31f1ee5d72270af674eeb92087748f607d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9ccfd31f1ee5d72270af674eeb92087748f607d4">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shi_ZeroScatter_Domain_Transfer_for_Long_Distance_Imaging_and_Vision_Through_CVPR_2021_paper.html">ZeroScatter: Domain Transfer for Long Distance Imaging and Vision Through Scattering Media</a></th>
                    </tr>
                
                    <tr id="7a63466568e4ab23db5a18b48be0a6a19d9d069d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7a63466568e4ab23db5a18b48be0a6a19d9d069d">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_StruMonoNet_Structure-Aware_Monocular_3D_Prediction_CVPR_2021_paper.html">StruMonoNet: Structure-Aware Monocular 3D Prediction</a></th>
                    </tr>
                
                    <tr id="30def7c9292b0941fc98eaea95b4733189adc7b2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/30def7c9292b0941fc98eaea95b4733189adc7b2">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Song_Pareidolia_Face_Reenactment_CVPR_2021_paper.html">Pareidolia Face Reenactment</a></th>
                    </tr>
                
                    <tr id="518e72e1f8843f176197acf8b3596b6c7a9b4597">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/518e72e1f8843f176197acf8b3596b6c7a9b4597">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kar_Fast_Bayesian_Uncertainty_Estimation_and_Reduction_of_Batch_Normalized_Single_CVPR_2021_paper.html">Fast Bayesian Uncertainty Estimation and Reduction of Batch Normalized Single Image Super-Resolution Network</a></th>
                    </tr>
                
                    <tr id="761361d613a605bcc56197c1406384d929d5000c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/761361d613a605bcc56197c1406384d929d5000c">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Meshry_StEP_Style-Based_Encoder_Pre-Training_for_Multi-Modal_Image_Synthesis_CVPR_2021_paper.html">StEP: Style-Based Encoder Pre-Training for Multi-Modal Image Synthesis</a></th>
                    </tr>
                
                    <tr id="15816dee35e891b00e1d4da8624490234a3e616b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15816dee35e891b00e1d4da8624490234a3e616b">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Efficient_Deformable_Shape_Correspondence_via_Multiscale_Spectral_Manifold_Wavelets_Preservation_CVPR_2021_paper.html">Efficient Deformable Shape Correspondence via Multiscale Spectral Manifold Wavelets Preservation</a></th>
                    </tr>
                
                    <tr id="bdec22a60804b84a4240af3e4e56d61e636eec2a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bdec22a60804b84a4240af3e4e56d61e636eec2a">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_EDNet_Efficient_Disparity_Estimation_With_Cost_Volume_Combination_and_Attention-Based_CVPR_2021_paper.html">EDNet: Efficient Disparity Estimation With Cost Volume Combination and Attention-Based Spatial Residual</a></th>
                    </tr>
                
                    <tr id="f7c949c4043fd9a10f6967ef7033a656ca280280">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7c949c4043fd9a10f6967ef7033a656ca280280">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hernandez_Neural_Cellular_Automata_Manifold_CVPR_2021_paper.html">Neural Cellular Automata Manifold</a></th>
                    </tr>
                
                    <tr id="6b1a587bc891b0d6ef5dceccc14aa6ca5d56bcaf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6b1a587bc891b0d6ef5dceccc14aa6ca5d56bcaf">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Indoor_Lighting_Estimation_Using_an_Event_Camera_CVPR_2021_paper.html">Indoor Lighting Estimation Using an Event Camera</a></th>
                    </tr>
                
                    <tr id="0783a1b4cb2da919c5d281ebefffa2cc4b8dea74">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0783a1b4cb2da919c5d281ebefffa2cc4b8dea74">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Hilbert_Sinkhorn_Divergence_for_Optimal_Transport_CVPR_2021_paper.html">Hilbert Sinkhorn Divergence for Optimal Transport</a></th>
                    </tr>
                
                    <tr id="67e7d10585ddb00795120f19a8db14893791db59">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/67e7d10585ddb00795120f19a8db14893791db59">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qi_PQA_Perceptual_Question_Answering_CVPR_2021_paper.html">PQA: Perceptual Question Answering</a></th>
                    </tr>
                
                    <tr id="c908fee6106ce3cddf47fc5df2eac072071b8540">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c908fee6106ce3cddf47fc5df2eac072071b8540">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yoo_RaScaNet_Learning_Tiny_Models_by_Raster-Scanning_Images_CVPR_2021_paper.html">RaScaNet: Learning Tiny Models by Raster-Scanning Images</a></th>
                    </tr>
                
                    <tr id="09617d7dbc845c9d8a76c24a43033b1fce2e750d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/09617d7dbc845c9d8a76c24a43033b1fce2e750d">4</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lei_Picasso_A_CUDA-Based_Library_for_Deep_Learning_Over_3D_Meshes_CVPR_2021_paper.html">Picasso: A CUDA-based Library for Deep Learning over 3D Meshes</a></th>
                    </tr>
                
                    <tr id="bc4c65be9564abb0c40f5e754398bba450889568">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bc4c65be9564abb0c40f5e754398bba450889568">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Vemparala_Adversarial_Robust_Model_Compression_Using_In-Train_Pruning_CVPRW_2021_paper.html">Adversarial Robust Model Compression Using In-Train Pruning</a></th>
                    </tr>
                
                    <tr id="6bbbfa3610d8374a111d813b889bce5cd68906a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6bbbfa3610d8374a111d813b889bce5cd68906a6">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Yamac_KernelNet_A_Blind_Super-Resolution_Kernel_Estimation_Network_CVPRW_2021_paper.html">KernelNet: A Blind Super-Resolution Kernel Estimation Network</a></th>
                    </tr>
                
                    <tr id="5f0d9bd91296abc152c7247bc2a3b22896cfd656">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f0d9bd91296abc152c7247bc2a3b22896cfd656">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Chen_SRKTDN_Applying_Super_Resolution_Method_to_Dehazing_Task_CVPRW_2021_paper.html">SRKTDN: Applying Super Resolution Method to Dehazing Task</a></th>
                    </tr>
                
                    <tr id="d127378c2bd7c0ac4d17732e46606adf39582f0d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d127378c2bd7c0ac4d17732e46606adf39582f0d">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Cai_Toward_Interactive_Modulation_for_Photo-Realistic_Image_Restoration_CVPRW_2021_paper.html">Toward Interactive Modulation for Photo-Realistic Image Restoration</a></th>
                    </tr>
                
                    <tr id="9a563f7ee29010be33499f7f715fb5d1ebb6ddf8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9a563f7ee29010be33499f7f715fb5d1ebb6ddf8">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/A._Single_Image_HDR_Synthesis_Using_a_Densely_Connected_Dilated_ConvNet_CVPRW_2021_paper.html">Single Image HDR Synthesis Using a Densely Connected Dilated ConvNet</a></th>
                    </tr>
                
                    <tr id="16cfab3cb081265c79918c91542421afba8d897f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16cfab3cb081265c79918c91542421afba8d897f">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Vo_Attention_Stay_Focus_CVPRW_2021_paper.html">Attention! Stay Focus!</a></th>
                    </tr>
                
                    <tr id="117fb16ba027c302f0f53240c534765d42a1a885">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/117fb16ba027c302f0f53240c534765d42a1a885">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/UG2/html/Chen_DarkLight_Networks_for_Action_Recognition_in_the_Dark_CVPRW_2021_paper.html">DarkLight Networks for Action Recognition in the Dark</a></th>
                    </tr>
                
                    <tr id="b2fb20db5fa6fc862c42b9d9fbc388d8bec1bd85">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b2fb20db5fa6fc862c42b9d9fbc388d8bec1bd85">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Thakkar_On_the_Feasibility_of_3D_Model-Based_Forensic_Height_and_Weight_CVPRW_2021_paper.html">On the Feasibility of 3D Model-Based Forensic Height and Weight Estimation</a></th>
                    </tr>
                
                    <tr id="9eb7509bbdb33052b7a6c22a70699752ab09eecc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9eb7509bbdb33052b7a6c22a70699752ab09eecc">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Black_Deep_Image_Comparator_Learning_To_Visualize_Editorial_Change_CVPRW_2021_paper.html">Deep Image Comparator: Learning To Visualize Editorial Change</a></th>
                    </tr>
                
                    <tr id="248d10e3264185e84032e3b74f6690721cee5c60">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/248d10e3264185e84032e3b74f6690721cee5c60">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Christie_Single_View_Geocentric_Pose_in_the_Wild_CVPRW_2021_paper.html">Single View Geocentric Pose in the Wild</a></th>
                    </tr>
                
                    <tr id="be78d52609a1e695bd2293a79dc15160aa99329c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/be78d52609a1e695bd2293a79dc15160aa99329c">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Duwek_Image_Reconstruction_From_Neuromorphic_Event_Cameras_Using_Laplacian-Prediction_and_Poisson_CVPRW_2021_paper.html">Image Reconstruction From Neuromorphic Event Cameras Using Laplacian-Prediction and Poisson Integration With Spiking and Artificial Neural Networks</a></th>
                    </tr>
                
                    <tr id="2467f6f18c5d5c30210e26b9e0d03df6e6b28325">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2467f6f18c5d5c30210e26b9e0d03df6e6b28325">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Paikin_EFI-Net_Video_Frame_Interpolation_From_Fusion_of_Events_and_Frames_CVPRW_2021_paper.html">EFI-Net: Video Frame Interpolation From Fusion of Events and Frames</a></th>
                    </tr>
                
                    <tr id="087946dc0a2583b7831cf3a9d5962f5c91e38e01">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/087946dc0a2583b7831cf3a9d5962f5c91e38e01">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Ciabatti_Autonomous_Planetary_Landing_via_Deep_Reinforcement_Learning_and_Transfer_Learning_CVPRW_2021_paper.html">Autonomous Planetary Landing via Deep Reinforcement Learning and Transfer Learning</a></th>
                    </tr>
                
                    <tr id="bc098bdbc4928fd0f9578957474b3661e16425e2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bc098bdbc4928fd0f9578957474b3661e16425e2">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Garcia_LSPnet_A_2D_Localization-Oriented_Spacecraft_Pose_Estimation_Neural_Network_CVPRW_2021_paper.html">LSPnet: A 2D Localization-Oriented Spacecraft Pose Estimation Neural Network</a></th>
                    </tr>
                
                    <tr id="8f4829ee339ced9a1fa2896f72d82f452472c7c0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f4829ee339ced9a1fa2896f72d82f452472c7c0">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SketchDL/html/Torres_Compact_and_Effective_Representations_for_Sketch-Based_Image_Retrieval_CVPRW_2021_paper.html">Compact and Effective Representations for Sketch-Based Image Retrieval</a></th>
                    </tr>
                
                    <tr id="92cb6e04e28f2099dae2e5a311505e78ec23bda9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/92cb6e04e28f2099dae2e5a311505e78ec23bda9">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SketchDL/html/Fuentes_Sketch-QNet_A_Quadruplet_ConvNet_for_Color_Sketch-Based_Image_Retrieval_CVPRW_2021_paper.html">Sketch-QNet: A Quadruplet ConvNet for Color Sketch-Based Image Retrieval</a></th>
                    </tr>
                
                    <tr id="947bd01e92d28ffd860a0fc8a539defe4becd2c7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/947bd01e92d28ffd860a0fc8a539defe4becd2c7">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WiCV/html/Desai_RUIG_Realistic_Underwater_Image_Generation_Towards_Restoration_CVPRW_2021_paper.html">RUIG: Realistic Underwater Image Generation Towards Restoration</a></th>
                    </tr>
                
                    <tr id="5bf94bc0fc5a2db303ce73bb6ba72054dd90e89e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5bf94bc0fc5a2db303ce73bb6ba72054dd90e89e">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/RCV/html/Fu_Reconsidering_CO2_Emissions_From_Computer_Vision_CVPRW_2021_paper.html">Reconsidering CO2 Emissions From Computer Vision</a></th>
                    </tr>
                
                    <tr id="bd6af9a5010a521b6dd11b7d8e956b5beeb1636f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bd6af9a5010a521b6dd11b7d8e956b5beeb1636f">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Howells_Real-Time_Analogue_Gauge_Transcription_on_Mobile_Phone_CVPRW_2021_paper.html">Real-Time Analogue Gauge Transcription on Mobile Phone</a></th>
                    </tr>
                
                    <tr id="a82ac23ae7db7ad88e9d4ecd526cb15fb5d68b99">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a82ac23ae7db7ad88e9d4ecd526cb15fb5d68b99">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Liu_Layer_Importance_Estimation_With_Imprinting_for_Neural_Network_Quantization_CVPRW_2021_paper.html">Layer Importance Estimation With Imprinting for Neural Network Quantization</a></th>
                    </tr>
                
                    <tr id="70b3d8e445d4047c7138785ce720fc76a63e4a98">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70b3d8e445d4047c7138785ce720fc76a63e4a98">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Yang_AsymmNet_Towards_Ultralight_Convolution_Neural_Networks_Using_Asymmetrical_Bottlenecks_CVPRW_2021_paper.html">AsymmNet: Towards Ultralight Convolution Neural Networks Using Asymmetrical Bottlenecks</a></th>
                    </tr>
                
                    <tr id="78ad509b45714fb34b8d256db96a277ed4dd3fc3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/78ad509b45714fb34b8d256db96a277ed4dd3fc3">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Cunha_Filtering_Empty_Camera_Trap_Images_in_Embedded_Systems_CVPRW_2021_paper.html">Filtering Empty Camera Trap Images in Embedded Systems</a></th>
                    </tr>
                
                    <tr id="13f2a76f9ab1997608c7552fd4265ba1b762667c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/13f2a76f9ab1997608c7552fd4265ba1b762667c">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Zhao_ReMP_Rectified_Metric_Propagation_for_Few-Shot_Learning_CVPRW_2021_paper.html">ReMP: Rectified Metric Propagation for Few-Shot Learning</a></th>
                    </tr>
                
                    <tr id="c9b6b26adcef3dca5c9de061acb7e50bcb6c8068">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c9b6b26adcef3dca5c9de061acb7e50bcb6c8068">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Shi_Boosting_Unconstrained_Face_Recognition_With_Auxiliary_Unlabeled_Data_CVPRW_2021_paper.html">Boosting Unconstrained Face Recognition With Auxiliary Unlabeled Data</a></th>
                    </tr>
                
                    <tr id="4da45c899e39d646c175d6195c4661ccf7e7818d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4da45c899e39d646c175d6195c4661ccf7e7818d">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Patashnik_BalaGAN_Cross-Modal_Image_Translation_Between_Imbalanced_Domains_CVPRW_2021_paper.html">BalaGAN: Cross-Modal Image Translation Between Imbalanced Domains</a></th>
                    </tr>
                
                    <tr id="669bcea0c13a65a42f8d284314b5a2dc2a0c1caa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/669bcea0c13a65a42f8d284314b5a2dc2a0c1caa">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WAD/html/Gustafsson_Accurate_3D_Object_Detection_Using_Energy-Based_Models_CVPRW_2021_paper.html">Accurate 3D Object Detection Using Energy-Based Models</a></th>
                    </tr>
                
                    <tr id="57cedeb66471da66a9d0c88155260e6db794567d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/57cedeb66471da66a9d0c88155260e6db794567d">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AgriVision/html/Ren_Multi-Resolution_Outlier_Pooling_for_Sorghum_Classification_CVPRW_2021_paper.html">Multi-Resolution Outlier Pooling for Sorghum Classification</a></th>
                    </tr>
                
                    <tr id="c931e8c73a9cf5aa4fc020e43cd4dcdb9e3c3fdd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c931e8c73a9cf5aa4fc020e43cd4dcdb9e3c3fdd">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/GAZE/html/Poulopoulos_PupilTAN_A_Few-Shot_Adversarial_Pupil_Localizer_CVPRW_2021_paper.html">PupilTAN: A Few-Shot Adversarial Pupil Localizer</a></th>
                    </tr>
                
                    <tr id="dd9f23fd7e3a0bbbfdb20f236b8cb841c76bef2f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dd9f23fd7e3a0bbbfdb20f236b8cb841c76bef2f">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/HVU/html/Gkalelis_ObjectGraphs_Using_Objects_and_a_Graph_Convolutional_Network_for_the_CVPRW_2021_paper.html">ObjectGraphs: Using Objects and a Graph Convolutional Network for the Bottom-Up Recognition and Explanation of Events in Video</a></th>
                    </tr>
                
                    <tr id="47569cf3ac6ff779f22556f863ccb6cf751597ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/47569cf3ac6ff779f22556f863ccb6cf751597ab">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ChaLearn/html/Gruber_Mutual_Support_of_Data_Modalities_in_the_Task_of_Sign_CVPRW_2021_paper.html">Mutual Support of Data Modalities in the Task of Sign Language Recognition</a></th>
                    </tr>
                
                    <tr id="ec1521d259d3046341da89b10b1cdbee9b87f16a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ec1521d259d3046341da89b10b1cdbee9b87f16a">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/He_A_Tale_of_Two_CILs_The_Connections_Between_Class_Incremental_CVPRW_2021_paper.html">A Tale of Two CILs: The Connections Between Class Incremental Learning and Class Imbalanced Learning, and Beyond</a></th>
                    </tr>
                
                    <tr id="464112a6a8b0a242b49211b86c8060e978ba4d00">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/464112a6a8b0a242b49211b86c8060e978ba4d00">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/OmniCV/html/Rao_OmniLayout_Room_Layout_Reconstruction_From_Indoor_Spherical_Panoramas_CVPRW_2021_paper.html">OmniLayout: Room Layout Reconstruction From Indoor Spherical Panoramas</a></th>
                    </tr>
                
                    <tr id="096081359b6251db87ee8083db30262e211ac986">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/096081359b6251db87ee8083db30262e211ac986">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVPM/html/Chin_An_Infrared_Thermography_Model_Enabling_Remote_Body_Temperature_Screening_Up_CVPRW_2021_paper.html">An Infrared Thermography Model Enabling Remote Body Temperature Screening Up to 10 Meters</a></th>
                    </tr>
                
                    <tr id="554863b9c2a7b285da7b3971b3aa80b12d4f0d21">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/554863b9c2a7b285da7b3971b3aa80b12d4f0d21">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVPM/html/Huang_Nose_Breathing_or_Mouth_Breathing_A_Thermography-Based_New_Measurement_for_CVPRW_2021_paper.html">Nose Breathing or Mouth Breathing? A Thermography-Based New Measurement for Sleep Monitoring</a></th>
                    </tr>
                
                    <tr id="255f90cd765d90e602cd35ab7e22c3a8db1acefa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/255f90cd765d90e602cd35ab7e22c3a8db1acefa">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Lorbert_Scalable_and_Explainable_Outfit_Generation_CVPRW_2021_paper.html">Scalable and Explainable Outfit Generation</a></th>
                    </tr>
                
                    <tr id="3ab49c726bfc12d9b1d71d99dd0d953e8df50ffc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ab49c726bfc12d9b1d71d99dd0d953e8df50ffc">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Park_Keyword-Based_Vehicle_Retrieval_CVPRW_2021_paper.html">Keyword-Based Vehicle Retrieval</a></th>
                    </tr>
                
                    <tr id="0ee07ec12ff4f08db39caf96923d1a175c98efeb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ee07ec12ff4f08db39caf96923d1a175c98efeb">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Ren_Multi-Camera_Vehicle_Tracking_System_Based_on_Spatial-Temporal_Filtering_CVPRW_2021_paper.html">Multi-Camera Vehicle Tracking System Based on Spatial-Temporal Filtering</a></th>
                    </tr>
                
                    <tr id="23636ac70a3c59241dc8efc6b63cb01c0ff85ab7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/23636ac70a3c59241dc8efc6b63cb01c0ff85ab7">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Fernandez_Vehicle_Re-Identification_Based_on_Ensembling_Deep_Learning_Features_Including_a_CVPRW_2021_paper.html">Vehicle Re-Identification Based on Ensembling Deep Learning Features Including a Synthetic Training Dataset, Orientation and Background Features, and Camera Verification.</a></th>
                    </tr>
                
                    <tr id="8f06a56a1314cc2e234a043eed1e354f92c4b753">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8f06a56a1314cc2e234a043eed1e354f92c4b753">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Sebastian_TIED_A_Cycle_Consistent_Encoder-Decoder_Model_for_Text-to-Image_Retrieval_CVPRW_2021_paper.html">TIED: A Cycle Consistent Encoder-Decoder Model for Text-to-Image Retrieval</a></th>
                    </tr>
                
                    <tr id="0a6635b5e713936710a90e6f542ecf1ef4effc75">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a6635b5e713936710a90e6f542ecf1ef4effc75">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Nguyen_Contrastive_Learning_for_Natural_Language-Based_Vehicle_Retrieval_CVPRW_2021_paper.html">Contrastive Learning for Natural Language-Based Vehicle Retrieval</a></th>
                    </tr>
                
                    <tr id="c982fccd87a432710b9844d02704c89d67c63123">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c982fccd87a432710b9844d02704c89d67c63123">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/IMW/html/Koguciuk_Perceptual_Loss_for_Robust_Unsupervised_Homography_Estimation_CVPRW_2021_paper.html">Perceptual Loss for Robust Unsupervised Homography Estimation</a></th>
                    </tr>
                
                    <tr id="1c421007b21a145c53600ca0241783945580bf84">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1c421007b21a145c53600ca0241783945580bf84">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/PBVS/html/Zheng_Learning_From_the_Web_Webly_Supervised_Meta-Learning_for_Masked_Face_CVPRW_2021_paper.html">Learning From the Web: Webly Supervised Meta-Learning for Masked Face Recognition</a></th>
                    </tr>
                
                    <tr id="196fb6953eab55463660cb605200d5202cd46116">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/196fb6953eab55463660cb605200d5202cd46116">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/BiVision/html/Pan_Fast_Walsh-Hadamard_Transform_and_Smooth-Thresholding_Based_Binary_Layers_in_Deep_CVPRW_2021_paper.html">Fast Walsh-Hadamard Transform and Smooth-Thresholding Based Binary Layers in Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="6dda4e444e2905c00df913980937d97da3a43b96">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6dda4e444e2905c00df913980937d97da3a43b96">4</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/BiVision/html/Livochka_Initialization_and_Transfer_Learning_of_Stochastic_Binary_Networks_From_Real-Valued_CVPRW_2021_paper.html">Initialization and Transfer Learning of Stochastic Binary Networks From Real-Valued Ones</a></th>
                    </tr>
                
                    <tr id="8c9e6e5ad185a99e4beec3a9cd66f86b6d428dfb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8c9e6e5ad185a99e4beec3a9cd66f86b6d428dfb">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Klopp_How_To_Exploit_the_Transferability_of_Learned_Image_Compression_to_CVPR_2021_paper.html">How To Exploit the Transferability of Learned Image Compression to Conventional Codecs</a></th>
                    </tr>
                
                    <tr id="43b21c5681a08a441d3ac1e676ed2cb74064ea79">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/43b21c5681a08a441d3ac1e676ed2cb74064ea79">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Jin_Harmonious_Semantic_Line_Detection_via_Maximal_Weight_Clique_Selection_CVPR_2021_paper.html">Harmonious Semantic Line Detection via Maximal Weight Clique Selection</a></th>
                    </tr>
                
                    <tr id="68a1f82996592834e318a056c39154f32d913ecc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/68a1f82996592834e318a056c39154f32d913ecc">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Su_ArtCoder_An_End-to-End_Method_for_Generating_Scanning-Robust_Stylized_QR_Codes_CVPR_2021_paper.html">ArtCoder: An End-to-End Method for Generating Scanning-Robust Stylized QR Codes</a></th>
                    </tr>
                
                    <tr id="60bdcfe2577338ae8698b9b8eadb7bec89a68447">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/60bdcfe2577338ae8698b9b8eadb7bec89a68447">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Mask-Embedded_Discriminator_With_Region-Based_Semantic_Regularization_for_Semi-Supervised_Class-Conditional_Image_CVPR_2021_paper.html">Mask-Embedded Discriminator With Region-Based Semantic Regularization for Semi-Supervised Class-Conditional Image Synthesis</a></th>
                    </tr>
                
                    <tr id="61c113ec0959f7b1a40118a33c644ad821ba68f2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61c113ec0959f7b1a40118a33c644ad821ba68f2">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Cluster-Wise_Hierarchical_Generative_Model_for_Deep_Amortized_Clustering_CVPR_2021_paper.html">Cluster-Wise Hierarchical Generative Model for Deep Amortized Clustering</a></th>
                    </tr>
                
                    <tr id="a86ca55d6b7c6d1c01d3c595c4285b12aac5dec7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a86ca55d6b7c6d1c01d3c595c4285b12aac5dec7">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Song_Mesh_Saliency_An_Independent_Perceptual_Measure_or_a_Derivative_of_CVPR_2021_paper.html">Mesh Saliency: An Independent Perceptual Measure or a Derivative of Image Saliency?</a></th>
                    </tr>
                
                    <tr id="6521bd8cbd2b8ba9a6203eb6a50f20d66753ae89">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6521bd8cbd2b8ba9a6203eb6a50f20d66753ae89">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/An_Learning_Deep_Latent_Variable_Models_by_Short-Run_MCMC_Inference_With_CVPR_2021_paper.html">Learning Deep Latent Variable Models by Short-Run MCMC Inference With Optimal Transport Correction</a></th>
                    </tr>
                
                    <tr id="40561a613e26d436d6a24e078f7db361133984c2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/40561a613e26d436d6a24e078f7db361133984c2">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Amirloo_Self-Supervised_Simultaneous_Multi-Step_Prediction_of_Road_Dynamics_and_Cost_Map_CVPR_2021_paper.html">Self-Supervised Simultaneous Multi-Step Prediction of Road Dynamics and Cost Map</a></th>
                    </tr>
                
                    <tr id="de4b744a19da77b16b3416cffdee7e7d37674555">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/de4b744a19da77b16b3416cffdee7e7d37674555">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Idelbayev_Optimal_Quantization_Using_Scaled_Codebook_CVPR_2021_paper.html">Optimal Quantization Using Scaled Codebook</a></th>
                    </tr>
                
                    <tr id="c6d477e223b44f4b0b7c44f973294aa00907cf58">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c6d477e223b44f4b0b7c44f973294aa00907cf58">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kulal_Hierarchical_Motion_Understanding_via_Motion_Programs_CVPR_2021_paper.html">Hierarchical Motion Understanding via Motion Programs</a></th>
                    </tr>
                
                    <tr id="b9b284e26e1a3e8cf181ff0272740022a693dc0d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b9b284e26e1a3e8cf181ff0272740022a693dc0d">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_No_Shadow_Left_Behind_Removing_Objects_and_Their_Shadows_Using_CVPR_2021_paper.html">No Shadow Left Behind: Removing Objects and Their Shadows Using Approximate Lighting and Geometry</a></th>
                    </tr>
                
                    <tr id="6dc1df43ac2573a6a8311445be791515b3258774">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6dc1df43ac2573a6a8311445be791515b3258774">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Vakhitov_Uncertainty-Aware_Camera_Pose_Estimation_From_Points_and_Lines_CVPR_2021_paper.html">Uncertainty-Aware Camera Pose Estimation From Points and Lines</a></th>
                    </tr>
                
                    <tr id="e90ea1b6eef711b9212fa4fec09db336236819da">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e90ea1b6eef711b9212fa4fec09db336236819da">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xing_Invertible_Image_Signal_Processing_CVPR_2021_paper.html">Invertible Image Signal Processing</a></th>
                    </tr>
                
                    <tr id="b423b8d374c32d7809120bbf6c0df5a660b3734d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b423b8d374c32d7809120bbf6c0df5a660b3734d">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Malinowski_Gradient_Forward-Propagation_for_Large-Scale_Temporal_Video_Modelling_CVPR_2021_paper.html">Gradient Forward-Propagation for Large-Scale Temporal Video Modelling</a></th>
                    </tr>
                
                    <tr id="fc3246c125f0124eb2aa139e670e41c4d558e04b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc3246c125f0124eb2aa139e670e41c4d558e04b">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cao_Debiased_Subjective_Assessment_of_Real-World_Image_Enhancement_CVPR_2021_paper.html">Debiased Subjective Assessment of Real-World Image Enhancement</a></th>
                    </tr>
                
                    <tr id="d6a88c7c8ea4bcd23ae84f4327051dcce90a21b0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d6a88c7c8ea4bcd23ae84f4327051dcce90a21b0">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hu_Model-Aware_Gesture-to-Gesture_Translation_CVPR_2021_paper.html">Model-Aware Gesture-to-Gesture Translation</a></th>
                    </tr>
                
                    <tr id="2e066e63d88963f1de90f16c083b51ce79727d0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e066e63d88963f1de90f16c083b51ce79727d0c">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wallace_Can_We_Characterize_Tasks_Without_Labels_or_Features_CVPR_2021_paper.html">Can We Characterize Tasks Without Labels or Features?</a></th>
                    </tr>
                
                    <tr id="bd03d8cf406d5c7557c3628bc8019ddcf6587fd0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bd03d8cf406d5c7557c3628bc8019ddcf6587fd0">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qiu_Scene_Essence_CVPR_2021_paper.html">Scene Essence</a></th>
                    </tr>
                
                    <tr id="7cb3a41fac20faed9d8f995bb7189b121d1c2788">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7cb3a41fac20faed9d8f995bb7189b121d1c2788">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Takatani_Event-Based_Bispectral_Photometry_Using_Temporally_Modulated_Illumination_CVPR_2021_paper.html">Event-Based Bispectral Photometry Using Temporally Modulated Illumination</a></th>
                    </tr>
                
                    <tr id="f75c2bb595c06756e905168feaa55300c4a95158">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f75c2bb595c06756e905168feaa55300c4a95158">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wang_Pseudo_Facial_Generation_With_Extreme_Poses_for_Face_Recognition_CVPR_2021_paper.html">Pseudo Facial Generation With Extreme Poses for Face Recognition</a></th>
                    </tr>
                
                    <tr id="aa796828aa643c070d10222a5f51f516f3ab2ce9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aa796828aa643c070d10222a5f51f516f3ab2ce9">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Chen_Efficient_Object_Embedding_for_Spliced_Image_Retrieval_CVPR_2021_paper.html">Efficient Object Embedding for Spliced Image Retrieval</a></th>
                    </tr>
                
                    <tr id="e0f1a85c0d908f09a5acf7728436cbd4bf64c650">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e0f1a85c0d908f09a5acf7728436cbd4bf64c650">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Learning_View_Selection_for_3D_Scenes_CVPR_2021_paper.html">Learning View Selection for 3D Scenes</a></th>
                    </tr>
                
                    <tr id="1013d5a6638c5d1e37f939676df937ce5aaeedd4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1013d5a6638c5d1e37f939676df937ce5aaeedd4">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Parra_Rotation_Coordinate_Descent_for_Fast_Globally_Optimal_Rotation_Averaging_CVPR_2021_paper.html">Rotation Coordinate Descent for Fast Globally Optimal Rotation Averaging</a></th>
                    </tr>
                
                    <tr id="4bed6356a43627e71a5bb67726f20c1610ae84bf">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4bed6356a43627e71a5bb67726f20c1610ae84bf">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Video_Rescaling_Networks_With_Joint_Optimization_Strategies_for_Downscaling_and_CVPR_2021_paper.html">Video Rescaling Networks With Joint Optimization Strategies for Downscaling and Upscaling</a></th>
                    </tr>
                
                    <tr id="9213a79454fcc5a8c73cb0fe9c6e3e0602d4153d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9213a79454fcc5a8c73cb0fe9c6e3e0602d4153d">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ha_NormalFusion_Real-Time_Acquisition_of_Surface_Normals_for_High-Resolution_RGB-D_Scanning_CVPR_2021_paper.html">NormalFusion: Real-Time Acquisition of Surface Normals for High-Resolution RGB-D Scanning</a></th>
                    </tr>
                
                    <tr id="1cccbd656dd00ab988e82138df5c18a9954954d4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1cccbd656dd00ab988e82138df5c18a9954954d4">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Qiu_3DCaricShop_A_Dataset_and_a_Baseline_Method_for_Single-View_3D_CVPR_2021_paper.html">3DCaricShop: A Dataset and a Baseline Method for Single-View 3D Caricature Face Reconstruction</a></th>
                    </tr>
                
                    <tr id="0ecf0ab58d8e653eb07662a1d31c665ec7ea3bbd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0ecf0ab58d8e653eb07662a1d31c665ec7ea3bbd">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ali_RPSRNet_End-to-End_Trainable_Rigid_Point_Set_Registration_Network_Using_Barnes-Hut_CVPR_2021_paper.html">RPSRNet: End-to-End Trainable Rigid Point Set Registration Network Using Barnes-Hut 2D-Tree Representation</a></th>
                    </tr>
                
                    <tr id="0a7ec86fcfc93eb0075048a8ca7f3fe11c78fedd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0a7ec86fcfc93eb0075048a8ca7f3fe11c78fedd">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Popovic_CompositeTasking_Understanding_Images_by_Spatial_Composition_of_Tasks_CVPR_2021_paper.html">CompositeTasking: Understanding Images by Spatial Composition of Tasks</a></th>
                    </tr>
                
                    <tr id="2e2cfdc65ec2cb91b67e3d5e07e374efae14446f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2e2cfdc65ec2cb91b67e3d5e07e374efae14446f">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Cui_Bayesian_Nested_Neural_Networks_for_Uncertainty_Calibration_and_Adaptive_Compression_CVPR_2021_paper.html">Bayesian Nested Neural Networks for Uncertainty Calibration and Adaptive Compression</a></th>
                    </tr>
                
                    <tr id="e2d9dc4197e8ec5c802aa589a7da1c4a92031e01">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e2d9dc4197e8ec5c802aa589a7da1c4a92031e01">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lee_Blocks-World_Cameras_CVPR_2021_paper.html">Blocks-World Cameras</a></th>
                    </tr>
                
                    <tr id="2f760d26b1172f9983292ae5c9151e164f45ea4b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2f760d26b1172f9983292ae5c9151e164f45ea4b">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_What_Can_Style_Transfer_and_Paintings_Do_for_Model_Robustness_CVPR_2021_paper.html">What Can Style Transfer and Paintings Do for Model Robustness?</a></th>
                    </tr>
                
                    <tr id="378f5305d7250e7290dd1cde87b319617d285d39">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/378f5305d7250e7290dd1cde87b319617d285d39">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xie_Exploiting_Aliasing_for_Manga_Restoration_CVPR_2021_paper.html">Exploiting Aliasing for Manga Restoration</a></th>
                    </tr>
                
                    <tr id="633b9d9f2aad906efbf6b4f92e08749a97b77f14">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/633b9d9f2aad906efbf6b4f92e08749a97b77f14">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kan_Relative_Order_Analysis_and_Optimization_for_Unsupervised_Deep_Metric_Learning_CVPR_2021_paper.html">Relative Order Analysis and Optimization for Unsupervised Deep Metric Learning</a></th>
                    </tr>
                
                    <tr id="10ab15c5fd4e2d16df23cbb94567ab60b911c956">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/10ab15c5fd4e2d16df23cbb94567ab60b911c956">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xiong_Seeing_in_Extra_Darkness_Using_a_Deep-Red_Flash_CVPR_2021_paper.html">Seeing in Extra Darkness Using a Deep-Red Flash</a></th>
                    </tr>
                
                    <tr id="dabcd6d6dc535dbfd3b3d9299975c17011bbae65">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dabcd6d6dc535dbfd3b3d9299975c17011bbae65">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Le_Moing_Semantic_Palette_Guiding_Scene_Generation_With_Class_Proportions_CVPR_2021_paper.html">Semantic Palette: Guiding Scene Generation with Class Proportions</a></th>
                    </tr>
                
                    <tr id="7bbdef19b560755d612750af687ca500ba6b55a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7bbdef19b560755d612750af687ca500ba6b55a9">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tang_Leveraging_Large-Scale_Weakly_Labeled_Data_for_Semi-Supervised_Mass_Detection_in_CVPR_2021_paper.html">Leveraging Large-Scale Weakly Labeled Data for Semi-Supervised Mass Detection in Mammograms</a></th>
                    </tr>
                
                    <tr id="11128cea0ae59ae8c96efda8e57b2203b4fbed93">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/11128cea0ae59ae8c96efda8e57b2203b4fbed93">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hong_Student-Teacher_Learning_From_Clean_Inputs_to_Noisy_Inputs_CVPR_2021_paper.html">Student-Teacher Learning from Clean Inputs to Noisy Inputs</a></th>
                    </tr>
                
                    <tr id="d6ef9ed905a3a6688aed5219268a3637b050cc0c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d6ef9ed905a3a6688aed5219268a3637b050cc0c">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ye_Adversarial_Invariant_Learning_CVPR_2021_paper.html">Adversarial Invariant Learning</a></th>
                    </tr>
                
                    <tr id="aa2c98b2f9796f768e0a56662e6445eac44474a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aa2c98b2f9796f768e0a56662e6445eac44474a6">3</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_PluckerNet_Learn_To_Register_3D_Line_Reconstructions_CVPR_2021_paper.html">PlckerNet: Learn to Register 3D Line Reconstructions</a></th>
                    </tr>
                
                    <tr id="1a1dde3ca79be436f83a023701a003ed6b0c6e5a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a1dde3ca79be436f83a023701a003ed6b0c6e5a">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Moller_Out-of-Distribution_Detection_and_Generation_Using_Soft_Brownian_Offset_Sampling_and_CVPRW_2021_paper.html">Out-of-Distribution Detection and Generation Using Soft Brownian Offset Sampling and Autoencoders</a></th>
                    </tr>
                
                    <tr id="c1ddc2ff8e4ef1a85a5f9bc035d7cfad0c0291ce">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c1ddc2ff8e4ef1a85a5f9bc035d7cfad0c0291ce">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Varghese_An_Unsupervised_Temporal_Consistency_TC_Loss_To_Improve_the_Performance_CVPRW_2021_paper.html">An Unsupervised Temporal Consistency (TC) Loss To Improve the Performance of Semantic Segmentation Networks</a></th>
                    </tr>
                
                    <tr id="75ffd15fe0325ff98e9e6326eb66aae694953624">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/75ffd15fe0325ff98e9e6326eb66aae694953624">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Yazdani_Physically_Inspired_Dense_Fusion_Networks_for_Relighting_CVPRW_2021_paper.html">Physically Inspired Dense Fusion Networks for Relighting</a></th>
                    </tr>
                
                    <tr id="bbec512d1f6faa10a9c9c00cc468cbdbb1b4e7fa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bbec512d1f6faa10a9c9c00cc468cbdbb1b4e7fa">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Bai_Learning_a_Cascaded_Non-Local_Residual_Network_for_Super-Resolving_Blurry_Images_CVPRW_2021_paper.html">Learning a Cascaded Non-Local Residual Network for Super-Resolving Blurry Images</a></th>
                    </tr>
                
                    <tr id="fc9a8673798295654e20fc2f489e7d91071d980f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc9a8673798295654e20fc2f489e7d91071d980f">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Vasluianu_Shadow_Removal_With_Paired_and_Unpaired_Learning_CVPRW_2021_paper.html">Shadow Removal With Paired and Unpaired Learning</a></th>
                    </tr>
                
                    <tr id="4b2e85ad840949335c432f65635740631c9b1209">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4b2e85ad840949335c432f65635740631c9b1209">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Liang_Guidance_Network_With_Staged_Learning_for_Image_Enhancement_CVPRW_2021_paper.html">Guidance Network With Staged Learning for Image Enhancement</a></th>
                    </tr>
                
                    <tr id="fd616af72c1695622de86113b29d70d194f558fb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fd616af72c1695622de86113b29d70d194f558fb">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Helminger_Generic_Image_Restoration_With_Flow_Based_Priors_CVPRW_2021_paper.html">Generic Image Restoration With Flow Based Priors</a></th>
                    </tr>
                
                    <tr id="2f83dd0897b66c2c01f2fdeec3b8605fafd32e99">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2f83dd0897b66c2c01f2fdeec3b8605fafd32e99">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Zheng_Adaptive_Spatial-Temporal_Fusion_of_Multi-Objective_Networks_for_Compressed_Video_Perceptual_CVPRW_2021_paper.html">Adaptive Spatial-Temporal Fusion of Multi-Objective Networks for Compressed Video Perceptual Enhancement</a></th>
                    </tr>
                
                    <tr id="77a3dace0ede3f17eacd422c0b7501a85d0a9e16">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/77a3dace0ede3f17eacd422c0b7501a85d0a9e16">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Yang_Cross_Modality_Knowledge_Distillation_for_Multi-Modal_Aerial_View_Object_Classification_CVPRW_2021_paper.html">Cross Modality Knowledge Distillation for Multi-Modal Aerial View Object Classification</a></th>
                    </tr>
                
                    <tr id="02849192d2d456b6e63e80634dc6c348a8b44c44">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/02849192d2d456b6e63e80634dc6c348a8b44c44">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/UG2/html/Chen_Multi-Scale_Hourglass_Hierarchical_Fusion_Network_for_Single_Image_Deraining_CVPRW_2021_paper.html">Multi-Scale Hourglass Hierarchical Fusion Network for Single Image Deraining</a></th>
                    </tr>
                
                    <tr id="eb752fd572ca2c984b56a06c9974fdfdf951acb6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eb752fd572ca2c984b56a06c9974fdfdf951acb6">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Schwarcz_Finding_Facial_Forgery_Artifacts_With_Parts-Based_Detectors_CVPRW_2021_paper.html">Finding Facial Forgery Artifacts With Parts-Based Detectors</a></th>
                    </tr>
                
                    <tr id="cff54affdbc75f72e72acaec1245f03ea8544fa5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cff54affdbc75f72e72acaec1245f03ea8544fa5">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Qin_OpenGF_An_Ultra-Large-Scale_Ground_Filtering_Dataset_Built_Upon_Open_ALS_CVPRW_2021_paper.html">OpenGF: An Ultra-Large-Scale Ground Filtering Dataset Built Upon Open ALS Point Clouds Around the World</a></th>
                    </tr>
                
                    <tr id="2b7dc09637c58fc46753ae36cf6652e259cc02a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2b7dc09637c58fc46753ae36cf6652e259cc02a6">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LXCV/html/Barros_I_Only_Have_Eyes_for_You_The_Impact_of_Masks_CVPRW_2021_paper.html">I Only Have Eyes for You: The Impact of Masks on Convolutional-Based Facial Expression Recognition</a></th>
                    </tr>
                
                    <tr id="118c81057cdecce85514c9543e01ae88ffe56448">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/118c81057cdecce85514c9543e01ae88ffe56448">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LXCV/html/Pestana_Assistive_Signals_for_Deep_Neural_Network_Classifiers_CVPRW_2021_paper.html">Assistive Signals for Deep Neural Network Classifiers</a></th>
                    </tr>
                
                    <tr id="4f865096d10c1538e620421dbb13c77314a0e685">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f865096d10c1538e620421dbb13c77314a0e685">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LXCV/html/Meza_MarkerPose_Robust_Real-Time_Planar_Target_Tracking_for_Accurate_Stereo_Pose_CVPRW_2021_paper.html">MarkerPose: Robust Real-Time Planar Target Tracking for Accurate Stereo Pose Estimation</a></th>
                    </tr>
                
                    <tr id="922cdba0e49cf2517294698248e33326b76a52a9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/922cdba0e49cf2517294698248e33326b76a52a9">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Barbier_Spike_Timing-Based_Unsupervised_Learning_of_Orientation_Disparity_and_Motion_Representations_CVPRW_2021_paper.html">Spike Timing-Based Unsupervised Learning of Orientation, Disparity, and Motion Representations in a Spiking Neural Network</a></th>
                    </tr>
                
                    <tr id="a758b3d479b19a9f24e192225a8ce053663999e6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a758b3d479b19a9f24e192225a8ce053663999e6">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Biometrics/html/Ayotte_Group_Leakage_Overestimates_Performance_A_Case_Study_in_Keystroke_Dynamics_CVPRW_2021_paper.html">Group Leakage Overestimates Performance: A Case Study in Keystroke Dynamics</a></th>
                    </tr>
                
                    <tr id="0f0087bb5a29f8a42bf27931c5d697298c2e6a80">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0f0087bb5a29f8a42bf27931c5d697298c2e6a80">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Liao_Target-Tailored_Source-Transformation_for_Scene_Graph_Generation_CVPRW_2021_paper.html">Target-Tailored Source-Transformation for Scene Graph Generation</a></th>
                    </tr>
                
                    <tr id="9702dc2031f1ae817d6fb4b7b855387d945a9f57">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9702dc2031f1ae817d6fb4b7b855387d945a9f57">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Stergioulas_3D_Hand_Pose_Estimation_via_Aligned_Latent_Space_Injection_and_CVPRW_2021_paper.html">3D Hand Pose Estimation via Aligned Latent Space Injection and Kinematic Losses</a></th>
                    </tr>
                
                    <tr id="f462b16213e59c270abd0bbca03ef88a1ab1c076">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f462b16213e59c270abd0bbca03ef88a1ab1c076">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CiV/html/Panda_Instance-Wise_Causal_Feature_Selection_for_Model_Interpretation_CVPRW_2021_paper.html">Instance-Wise Causal Feature Selection for Model Interpretation</a></th>
                    </tr>
                
                    <tr id="9b6382cab074c8fd16008fd510750f610ad743ad">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9b6382cab074c8fd16008fd510750f610ad743ad">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CiV/html/Zhang_DeVLBert_Out-of-Distribution_Visio-Linguistic_Pretraining_With_Causality_CVPRW_2021_paper.html">DeVLBert: Out-of-Distribution Visio-Linguistic Pretraining With Causality</a></th>
                    </tr>
                
                    <tr id="ea3df0ce79af82094b0d490dd0eed2861625f442">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ea3df0ce79af82094b0d490dd0eed2861625f442">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Brand_Rate-Distortion_Optimized_Learning-Based_Image_Compression_Using_an_Adaptive_Hierachical_Autoencoder_CVPRW_2021_paper.html">Rate-Distortion Optimized Learning-Based Image Compression Using an Adaptive Hierachical Autoencoder With Conditional Hyperprior</a></th>
                    </tr>
                
                    <tr id="b0b8046daabb7b0f92636e23b537a2dbdd7a6564">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b0b8046daabb7b0f92636e23b537a2dbdd7a6564">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Ma_Variable_Rate_ROI_Image_Compression_Optimized_for_Visual_Quality_CVPRW_2021_paper.html">Variable Rate ROI Image Compression Optimized for Visual Quality</a></th>
                    </tr>
                
                    <tr id="f523a9ae9c84fa986c2a4e7acba7d7fe5ad595b4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f523a9ae9c84fa986c2a4e7acba7d7fe5ad595b4">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Mergy_Vision-Based_Neural_Scene_Representations_for_Spacecraft_CVPRW_2021_paper.html">Vision-Based Neural Scene Representations for Spacecraft</a></th>
                    </tr>
                
                    <tr id="ca72ecf7f827ef39eb04aa37530d92054f165385">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ca72ecf7f827ef39eb04aa37530d92054f165385">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Sikorski_Event-Based_Spacecraft_Landing_Using_Time-To-Contact_CVPRW_2021_paper.html">Event-Based Spacecraft Landing Using Time-To-Contact</a></th>
                    </tr>
                
                    <tr id="e54708257fcdc679587fb33e8f613d754371cfb8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e54708257fcdc679587fb33e8f613d754371cfb8">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Chakravarthy_MRSCAtt_A_Spatio-Channel_Attention-Guided_Network_for_Mars_Rover_Image_Classification_CVPRW_2021_paper.html">MRSCAtt: A Spatio-Channel Attention-Guided Network for Mars Rover Image Classification</a></th>
                    </tr>
                
                    <tr id="c65fd2b88ca86c5364f7858f0dd3ac7bda12668d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c65fd2b88ca86c5364f7858f0dd3ac7bda12668d">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WiCV/html/Pucci_Collaborative_Image_and_Object_Level_Features_for_Image_Colourisation_CVPRW_2021_paper.html">Collaborative Image and Object Level Features for Image Colourisation</a></th>
                    </tr>
                
                    <tr id="655bee7ed91885fef3ad09e5acffed24cb12d590">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/655bee7ed91885fef3ad09e5acffed24cb12d590">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/RCV/html/Szabo_Tilted_Cross-Entropy_TCE_Promoting_Fairness_in_Semantic_Segmentation_CVPRW_2021_paper.html">Tilted Cross-Entropy (TCE): Promoting Fairness in Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="e6fec7958d1b49e1bdc408a4c6130f28ee132263">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e6fec7958d1b49e1bdc408a4c6130f28ee132263">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Li_RSCA_Real-Time_Segmentation-Based_Context-Aware_Scene_Text_Detection_CVPRW_2021_paper.html">RSCA: Real-Time Segmentation-Based Context-Aware Scene Text Detection</a></th>
                    </tr>
                
                    <tr id="44ff60c14b55dda44fa5ac51d86b452386052898">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/44ff60c14b55dda44fa5ac51d86b452386052898">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Zhang_Efficient_Pre-Trained_Features_and_Recurrent_Pseudo-Labeling_in_Unsupervised_Domain_Adaptation_CVPRW_2021_paper.html">Efficient Pre-Trained Features and Recurrent Pseudo-Labeling in Unsupervised Domain Adaptation</a></th>
                    </tr>
                
                    <tr id="4c8eab1174434bdf45d6e7dc2c6261468cd423e1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c8eab1174434bdf45d6e7dc2c6261468cd423e1">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Cai_DAMSL_Domain_Agnostic_Meta_Score-Based_Learning_CVPRW_2021_paper.html">DAMSL: Domain Agnostic Meta Score-Based Learning</a></th>
                    </tr>
                
                    <tr id="abf94b6d6e2166f29c1a08316709890f0fff9bb0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/abf94b6d6e2166f29c1a08316709890f0fff9bb0">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Duarte_PLM_Partial_Label_Masking_for_Imbalanced_Multi-Label_Classification_CVPRW_2021_paper.html">PLM: Partial Label Masking for Imbalanced Multi-Label Classification</a></th>
                    </tr>
                
                    <tr id="cc02a26214343b4d540354b9fd3b2b85f64ccc66">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cc02a26214343b4d540354b9fd3b2b85f64ccc66">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Chao_Rethinking_Ensemble-Distillation_for_Semantic_Segmentation_Based_Unsupervised_Domain_Adaption_CVPRW_2021_paper.html">Rethinking Ensemble-Distillation for Semantic Segmentation Based Unsupervised Domain Adaption</a></th>
                    </tr>
                
                    <tr id="1c0254123c271a62458ad854edb31b5fc8751e17">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1c0254123c271a62458ad854edb31b5fc8751e17">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WAD/html/Siam_Video_Class_Agnostic_Segmentation_Benchmark_for_Autonomous_Driving_CVPRW_2021_paper.html">Video Class Agnostic Segmentation Benchmark for Autonomous Driving</a></th>
                    </tr>
                
                    <tr id="f7e9e1afb0d17b3d314fa5c1d2cd00cad5619fcc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7e9e1afb0d17b3d314fa5c1d2cd00cad5619fcc">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WAD/html/Aghdam_RAD_Realtime_and_Accurate_3D_Object_Detection_on_Embedded_Systems_CVPRW_2021_paper.html">RAD: Realtime and Accurate 3D Object Detection on Embedded Systems</a></th>
                    </tr>
                
                    <tr id="15b737f3cd3f641685b23fb9f8867dfe33371a74">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15b737f3cd3f641685b23fb9f8867dfe33371a74">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Langroudi_ALPS_Adaptive_Quantization_of_Deep_Neural_Networks_With_GeneraLized_PositS_CVPRW_2021_paper.html">ALPS: Adaptive Quantization of Deep Neural Networks With GeneraLized PositS</a></th>
                    </tr>
                
                    <tr id="ca97230115c6f1cedba4c8699962f2b2c2e8e9bb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ca97230115c6f1cedba4c8699962f2b2c2e8e9bb">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Fournarakis_In-Hindsight_Quantization_Range_Estimation_for_Quantized_Training_CVPRW_2021_paper.html">In-Hindsight Quantization Range Estimation for Quantized Training</a></th>
                    </tr>
                
                    <tr id="76766e08874a75ec16ce6bf7fb116bf15a99205c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/76766e08874a75ec16ce6bf7fb116bf15a99205c">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Bisla_A_Theoretical-Empirical_Approach_to_Estimating_Sample_Complexity_of_DNNs_CVPRW_2021_paper.html">A Theoretical-Empirical Approach to Estimating Sample Complexity of DNNs</a></th>
                    </tr>
                
                    <tr id="592c6dde00693fb3f38847370f9398554727eb10">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/592c6dde00693fb3f38847370f9398554727eb10">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Shukla_A_Mathematical_Analysis_of_Learning_Loss_for_Active_Learning_in_CVPRW_2021_paper.html">A Mathematical Analysis of Learning Loss for Active Learning in Regression</a></th>
                    </tr>
                
                    <tr id="d1de5118ae839f47ab5ec5ad382284b29e2123ec">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d1de5118ae839f47ab5ec5ad382284b29e2123ec">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Khattar_Cross-Domain_Multi-Task_Learning_for_Object_Detection_and_Saliency_Estimation_CVPRW_2021_paper.html">Cross-Domain Multi-Task Learning for Object Detection and Saliency Estimation</a></th>
                    </tr>
                
                    <tr id="966a76953c0d61b90811838fb137957b6c9f302b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/966a76953c0d61b90811838fb137957b6c9f302b">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Mirzadeh_CL-Gym_Full-Featured_PyTorch_Library_for_Continual_Learning_CVPRW_2021_paper.html">CL-Gym: Full-Featured PyTorch Library for Continual Learning</a></th>
                    </tr>
                
                    <tr id="f1e8104a2ef43344333aa41d7996dd3643dfece1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f1e8104a2ef43344333aa41d7996dd3643dfece1">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Sun_ILCOC_An_Incremental_Learning_Framework_Based_on_Contrastive_One-Class_Classifiers_CVPRW_2021_paper.html">ILCOC: An Incremental Learning Framework Based on Contrastive One-Class Classifiers</a></th>
                    </tr>
                
                    <tr id="cba5aeebe6848e23af17f1ca599fd4610d312b2b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cba5aeebe6848e23af17f1ca599fd4610d312b2b">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/OmniCV/html/Gkitsas_PanoDR_Spherical_Panorama_Diminished_Reality_for_Indoor_Scenes_CVPRW_2021_paper.html">PanoDR: Spherical Panorama Diminished Reality for Indoor Scenes</a></th>
                    </tr>
                
                    <tr id="d9bc14825bc8134c8cdb39486642709032de8d8b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d9bc14825bc8134c8cdb39486642709032de8d8b">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVMI/html/Fujii_X-Net_With_Different_Loss_Functions_for_Cell_Image_Segmentation_CVPRW_2021_paper.html">X-Net With Different Loss Functions for Cell Image Segmentation</a></th>
                    </tr>
                
                    <tr id="c519b0e27df831472d24558bfb819459061ef78a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c519b0e27df831472d24558bfb819459061ef78a">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVMI/html/Zhang_A_Joint_Spatial_and_Magnification_Based_Attention_Framework_for_Large_CVPRW_2021_paper.html">A Joint Spatial and Magnification Based Attention Framework for Large Scale Histopathology Classification</a></th>
                    </tr>
                
                    <tr id="5356410a66e58f438e3845b489a2333a308bcce5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5356410a66e58f438e3845b489a2333a308bcce5">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVPM/html/Nowara_Combining_Magnification_and_Measurement_for_Non-Contact_Cardiac_Monitoring_CVPRW_2021_paper.html">Combining Magnification and Measurement for Non-Contact Cardiac Monitoring</a></th>
                    </tr>
                
                    <tr id="22041b9ecce1ca72d03c32257819093a614452d8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/22041b9ecce1ca72d03c32257819093a614452d8">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVPM/html/Mehta_Towards_Automated_and_Marker-Less_Parkinson_Disease_Assessment_Predicting_UPDRS_Scores_CVPRW_2021_paper.html">Towards Automated and Marker-Less Parkinson Disease Assessment: Predicting UPDRS Scores Using Sit-Stand Videos</a></th>
                    </tr>
                
                    <tr id="191a77f7381289af81e0124f1acbd5744bef07c7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/191a77f7381289af81e0124f1acbd5744bef07c7">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVPM/html/Kwasniewska_Improving_Accuracy_of_Respiratory_Rate_Estimation_by_Restoring_High_Resolution_CVPRW_2021_paper.html">Improving Accuracy of Respiratory Rate Estimation by Restoring High Resolution Features With Transformers and Recursive Convolutional Models</a></th>
                    </tr>
                
                    <tr id="fc3e2cc8b737d23dc2500c77908793a2eb498615">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc3e2cc8b737d23dc2500c77908793a2eb498615">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Mishra_Effectively_Leveraging_Attributes_for_Visual_Similarity_CVPRW_2021_paper.html">Effectively Leveraging Attributes for Visual Similarity</a></th>
                    </tr>
                
                    <tr id="3aa7021410baa6ff2d4462a8db7220152e776d32">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3aa7021410baa6ff2d4462a8db7220152e776d32">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Chawla_Leveraging_Style_and_Content_Features_for_Text_Conditioned_Image_Retrieval_CVPRW_2021_paper.html">Leveraging Style and Content Features for Text Conditioned Image Retrieval</a></th>
                    </tr>
                
                    <tr id="c76210eccbbca222259c3d6876ac867a7a864762">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c76210eccbbca222259c3d6876ac867a7a864762">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Kocur_Multi-Class_Multi-Movement_Vehicle_Counting_Based_on_CenterTrack_CVPRW_2021_paper.html">Multi-Class Multi-Movement Vehicle Counting Based on CenterTrack</a></th>
                    </tr>
                
                    <tr id="38dc340bca0c82e2784d5b58334c3581e7af19df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/38dc340bca0c82e2784d5b58334c3581e7af19df">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DiffCVML/html/Chen_SrvfRegNet_Elastic_Function_Registration_Using_Deep_Neural_Networks_CVPRW_2021_paper.html">SrvfRegNet: Elastic Function Registration Using Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="6e16a4e3ae175a3bbdfde43fd7e16a389fffd4dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6e16a4e3ae175a3bbdfde43fd7e16a389fffd4dd">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/Liu_Detecting_and_Matching_Related_Objects_With_One_Proposal_Multiple_Predictions_CVPRW_2021_paper.html">Detecting and Matching Related Objects With One Proposal Multiple Predictions</a></th>
                    </tr>
                
                    <tr id="b32f0a26ae2cbfc5428f578d3b5cbb00f6c7066a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b32f0a26ae2cbfc5428f578d3b5cbb00f6c7066a">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/BiVision/html/Razani_Adaptive_Binary-Ternary_Quantization_CVPRW_2021_paper.html">Adaptive Binary-Ternary Quantization</a></th>
                    </tr>
                
                    <tr id="28bfd247aa7950dcf58ec60a41c317e4cd04f5e7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/28bfd247aa7950dcf58ec60a41c317e4cd04f5e7">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/BiVision/html/Samragh_On_the_Application_of_Binary_Neural_Networks_in_Oblivious_Inference_CVPRW_2021_paper.html">On the Application of Binary Neural Networks in Oblivious Inference</a></th>
                    </tr>
                
                    <tr id="34bb0993f6487ba733e976917f7848c5343dc226">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/34bb0993f6487ba733e976917f7848c5343dc226">3</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/BiVision/html/Redfern_BCNN_A_Binary_CNN_With_All_Matrix_Ops_Quantized_to_CVPRW_2021_paper.html">BCNN: A Binary CNN With All Matrix Ops Quantized to 1 Bit Precision</a></th>
                    </tr>
                
                    <tr id="af733ab05a6e6b3b90ba58d4d4490f65ecea3cf6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/af733ab05a6e6b3b90ba58d4d4490f65ecea3cf6">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ghosh_Learning_Graphs_for_Knowledge_Transfer_With_Limited_Labels_CVPR_2021_paper.html">Learning Graphs for Knowledge Transfer With Limited Labels</a></th>
                    </tr>
                
                    <tr id="4f83d9948cabb9cccc241d152a6dbeacca33be9a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f83d9948cabb9cccc241d152a6dbeacca33be9a">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Tian_Probabilistic_Selective_Encryption_of_Convolutional_Neural_Networks_for_Hierarchical_Services_CVPR_2021_paper.html">Probabilistic Selective Encryption of Convolutional Neural Networks for Hierarchical Services</a></th>
                    </tr>
                
                    <tr id="39a3db7c5eb38aa3e435134b592d156d07db36b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/39a3db7c5eb38aa3e435134b592d156d07db36b1">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Dahary_Digital_Gimbal_End-to-End_Deep_Image_Stabilization_With_Learnable_Exposure_Times_CVPR_2021_paper.html">Digital Gimbal: End-to-End Deep Image Stabilization With Learnable Exposure Times</a></th>
                    </tr>
                
                    <tr id="00c802fcab95c2edbb48523a8b4ea1b26e6969c6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/00c802fcab95c2edbb48523a8b4ea1b26e6969c6">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Luo_Stay_Positive_Non-Negative_Image_Synthesis_for_Augmented_Reality_CVPR_2021_paper.html">Stay Positive: Non-Negative Image Synthesis for Augmented Reality</a></th>
                    </tr>
                
                    <tr id="69ce667351b1bc0336add76079fd83f4d7841b96">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/69ce667351b1bc0336add76079fd83f4d7841b96">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shi_GLAVNet_Global-Local_Audio-Visual_Cues_for_Fine-Grained_Material_Recognition_CVPR_2021_paper.html">GLAVNet: Global-Local Audio-Visual Cues for Fine-Grained Material Recognition</a></th>
                    </tr>
                
                    <tr id="f7fcd5e177190ceea5531613fcd041981631e067">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f7fcd5e177190ceea5531613fcd041981631e067">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhen_Simpler_Certified_Radius_Maximization_by_Propagating_Covariances_CVPR_2021_paper.html">Simpler Certified Radius Maximization by Propagating Covariances</a></th>
                    </tr>
                
                    <tr id="dfd72a7f0d662590bec4f1b0b98ceed36ca56ef4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dfd72a7f0d662590bec4f1b0b98ceed36ca56ef4">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Sparse_Multi-Path_Corrections_in_Fringe_Projection_Profilometry_CVPR_2021_paper.html">Sparse Multi-Path Corrections in Fringe Projection Profilometry</a></th>
                    </tr>
                
                    <tr id="15057a67ce856d9405240bc1edd88e29d6ceb4d3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15057a67ce856d9405240bc1edd88e29d6ceb4d3">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yin_ID-Unet_Iterative_Soft_and_Hard_Deformation_for_View_Synthesis_CVPR_2021_paper.html">ID-Unet: Iterative Soft and Hard Deformation for View Synthesis</a></th>
                    </tr>
                
                    <tr id="43faa30a076c723c566228b73a6ed81a8039b806">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/43faa30a076c723c566228b73a6ed81a8039b806">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Progressive_Stage-Wise_Learning_for_Unsupervised_Feature_Representation_Enhancement_CVPR_2021_paper.html">Progressive Stage-Wise Learning for Unsupervised Feature Representation Enhancement</a></th>
                    </tr>
                
                    <tr id="81061d95fdac9d9287ab5dac4b6eabd1f51e0013">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/81061d95fdac9d9287ab5dac4b6eabd1f51e0013">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Shen_Verifiability_and_Predictability_Interpreting_Utilities_of_Network_Architectures_for_Point_CVPR_2021_paper.html">Verifiability and Predictability: Interpreting Utilities of Network Architectures for Point Cloud Processing</a></th>
                    </tr>
                
                    <tr id="ae86d095fb319d22fc53ea58f253930bcbe6701b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ae86d095fb319d22fc53ea58f253930bcbe6701b">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Bahat_Whats_in_the_Image_Explorable_Decoding_of_Compressed_Images_CVPR_2021_paper.html">What&#39;s in the Image? Explorable Decoding of Compressed Images</a></th>
                    </tr>
                
                    <tr id="bf9e215b79f1f8796b70e3c38486b2727b3b5594">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/bf9e215b79f1f8796b70e3c38486b2727b3b5594">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kaneko_Unsupervised_Learning_of_Depth_and_Depth-of-Field_Effect_From_Natural_Images_CVPR_2021_paper.html">Unsupervised Learning of Depth and Depth-of-Field Effect From Natural Images With Aperture Rendering Generative Adversarial Networks</a></th>
                    </tr>
                
                    <tr id="4d780a8eb22dcabda118be42d426bbcc2be53c47">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4d780a8eb22dcabda118be42d426bbcc2be53c47">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Safadi_Learning-Based_Image_Registration_With_Meta-Regularization_CVPR_2021_paper.html">Learning-Based Image Registration With Meta-Regularization</a></th>
                    </tr>
                
                    <tr id="fe6ce90e0978b1b23a0b739c3a803dd49f61505d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fe6ce90e0978b1b23a0b739c3a803dd49f61505d">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Learning_To_Identify_Correct_2D-2D_Line_Correspondences_on_Sphere_CVPR_2021_paper.html">Learning To Identify Correct 2D-2D Line Correspondences on Sphere</a></th>
                    </tr>
                
                    <tr id="f24cbc1f451a3de124d95bacd5985b1489f83ed8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f24cbc1f451a3de124d95bacd5985b1489f83ed8">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yang_Few-Shot_Transformation_of_Common_Actions_Into_Time_and_Space_CVPR_2021_paper.html">Few-Shot Transformation of Common Actions Into Time and Space</a></th>
                    </tr>
                
                    <tr id="c0a7c93139910914f01f19a4eef1c2aebf99c50e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c0a7c93139910914f01f19a4eef1c2aebf99c50e">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Magri_MultiLink_Multi-Class_Structure_Recovery_via_Agglomerative_Clustering_and_Model_Selection_CVPR_2021_paper.html">MultiLink: Multi-Class Structure Recovery via Agglomerative Clustering and Model Selection</a></th>
                    </tr>
                
                    <tr id="76cf7136a722a3f54155e76d043af7896f34e317">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/76cf7136a722a3f54155e76d043af7896f34e317">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Discovering_Hidden_Physics_Behind_Transport_Dynamics_CVPR_2021_paper.html">Discovering Hidden Physics Behind Transport Dynamics</a></th>
                    </tr>
                
                    <tr id="1492b01afa2e75d58534d04b61281d7468cc0114">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1492b01afa2e75d58534d04b61281d7468cc0114">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Sun_Tuning_IR-Cut_Filter_for_Illumination-Aware_Spectral_Reconstruction_From_RGB_CVPR_2021_paper.html">Tuning IR-cut Filter for Illumination-aware Spectral Reconstruction from RGB</a></th>
                    </tr>
                
                    <tr id="6a049b867dea5b529b0689c1e1e28443c0a973ff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6a049b867dea5b529b0689c1e1e28443c0a973ff">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Physics-Based_Iterative_Projection_Complex_Neural_Network_for_Phase_Retrieval_in_CVPR_2021_paper.html">Physics-based Iterative Projection Complex Neural Network for Phase Retrieval in Lensless Microscopy Imaging</a></th>
                    </tr>
                
                    <tr id="db4ff352fd93d628d0b92294af2ec2be316d78b9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/db4ff352fd93d628d0b92294af2ec2be316d78b9">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Meuleman_Real-Time_Sphere_Sweeping_Stereo_From_Multiview_Fisheye_Images_CVPR_2021_paper.html">Real-Time Sphere Sweeping Stereo from Multiview Fisheye Images</a></th>
                    </tr>
                
                    <tr id="7b92e3ec611494300112cf4348abca13c305344a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7b92e3ec611494300112cf4348abca13c305344a">2</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Li_Spatial_Assembly_Networks_for_Image_Representation_Learning_CVPR_2021_paper.html">Spatial Assembly Networks for Image Representation Learning</a></th>
                    </tr>
                
                    <tr id="65aee337c7201415e25191432f254416d2d120b3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/65aee337c7201415e25191432f254416d2d120b3">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Feifel_Reevaluating_the_Safety_Impact_of_Inherent_Interpretability_on_Deep_Neural_CVPRW_2021_paper.html">Reevaluating the Safety Impact of Inherent Interpretability on Deep Neural Networks for Pedestrian Detection</a></th>
                    </tr>
                
                    <tr id="5f7757c5b2ab57f9c953c3754bdc9712370cc193">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5f7757c5b2ab57f9c953c3754bdc9712370cc193">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Klingner_Improving_Online_Performance_Prediction_for_Semantic_Segmentation_CVPRW_2021_paper.html">Improving Online Performance Prediction for Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="6dfb274f27518ea4dace609d028c08a00b3e7ec0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6dfb274f27518ea4dace609d028c08a00b3e7ec0">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Haselhoff_Towards_Black-Box_Explainability_With_Gaussian_Discriminant_Knowledge_Distillation_CVPRW_2021_paper.html">Towards Black-Box Explainability With Gaussian Discriminant Knowledge Distillation</a></th>
                    </tr>
                
                    <tr id="ed3b1108e5768aff62f546f68b03606b4322955d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ed3b1108e5768aff62f546f68b03606b4322955d">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Yang_Long-Tailed_Recognition_of_SAR_Aerial_View_Objects_by_Cascading_and_CVPRW_2021_paper.html">Long-Tailed Recognition of SAR Aerial View Objects by Cascading and Paralleling Experts</a></th>
                    </tr>
                
                    <tr id="53c8bc7cf08bed28493237e5004dd202077fc59f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/53c8bc7cf08bed28493237e5004dd202077fc59f">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Oskarsson_Robust_Image-to-Image_Color_Transfer_Using_Optimal_Inlier_Maximization_CVPRW_2021_paper.html">Robust Image-to-Image Color Transfer Using Optimal Inlier Maximization</a></th>
                    </tr>
                
                    <tr id="962b1a18d36e3147075d11b0b72062c491a6c194">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/962b1a18d36e3147075d11b0b72062c491a6c194">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Zhao_Single_Image_Dehazing_Using_Bounded_Channel_Difference_Prior_CVPRW_2021_paper.html">Single Image Dehazing Using Bounded Channel Difference Prior</a></th>
                    </tr>
                
                    <tr id="1e1ad57e691a6f79daaf477a12b30b277acc63a7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1e1ad57e691a6f79daaf477a12b30b277acc63a7">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Mastan_DeepObjStyle_Deep_Object-Based_Photo_Style_Transfer_CVPRW_2021_paper.html">DeepObjStyle: Deep Object-Based Photo Style Transfer</a></th>
                    </tr>
                
                    <tr id="990900955cec02f055f3e2beeebcd4972b854ff7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/990900955cec02f055f3e2beeebcd4972b854ff7">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Argaw_Restoration_of_Video_Frames_From_a_Single_Blurred_Image_With_CVPRW_2021_paper.html">Restoration of Video Frames From a Single Blurred Image With Motion Understanding</a></th>
                    </tr>
                
                    <tr id="b5656b77f7a806626a7c2e359c6e79d765bb2f39">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b5656b77f7a806626a7c2e359c6e79d765bb2f39">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Rafique_Unifying_Guided_and_Unguided_Outdoor_Image_Synthesis_CVPRW_2021_paper.html">Unifying Guided and Unguided Outdoor Image Synthesis</a></th>
                    </tr>
                
                    <tr id="e7c1c001bb5fd70d1a6eddcc30fe5f15e75f9eed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e7c1c001bb5fd70d1a6eddcc30fe5f15e75f9eed">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Calvarons_Improved_Noise2Noise_Denoising_With_Limited_Data_CVPRW_2021_paper.html">Improved Noise2Noise Denoising With Limited Data</a></th>
                    </tr>
                
                    <tr id="e9f52050e8420cb3e1d215dcdf64d165c7508c12">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e9f52050e8420cb3e1d215dcdf64d165c7508c12">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Pfister_Self-Supervised_Multi-Task_Pretraining_Improves_Image_Aesthetic_Assessment_CVPRW_2021_paper.html">Self-Supervised Multi-Task Pretraining Improves Image Aesthetic Assessment</a></th>
                    </tr>
                
                    <tr id="211e69d61dc827b6142b3147c227179e6dcf1735">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/211e69d61dc827b6142b3147c227179e6dcf1735">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Muller_Overparametrization_of_HyperNetworks_at_Fixed_FLOP-Count_Enables_Fast_Neural_Image_CVPRW_2021_paper.html">Overparametrization of HyperNetworks at Fixed FLOP-Count Enables Fast Neural Image Enhancement</a></th>
                    </tr>
                
                    <tr id="e828be5c5bd81d7a0a9ce34b0e69e912ee39aba2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e828be5c5bd81d7a0a9ce34b0e69e912ee39aba2">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Jiang_PNG_Micro-Structured_Prune-and-Grow_Networks_for_Flexible_Image_Restoration_CVPRW_2021_paper.html">PNG: Micro-Structured Prune-and-Grow Networks for Flexible Image Restoration</a></th>
                    </tr>
                
                    <tr id="e92a134e86f64150b1d064201fb456381bc0de48">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e92a134e86f64150b1d064201fb456381bc0de48">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Zhou_VSpSR_Explorable_Super-Resolution_via_Variational_Sparse_Representation_CVPRW_2021_paper.html">VSpSR: Explorable Super-Resolution via Variational Sparse Representation</a></th>
                    </tr>
                
                    <tr id="e5ddad38c35f35eec0dd885e5b0c69a45f0e57bd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e5ddad38c35f35eec0dd885e5b0c69a45f0e57bd">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Miron_Efficient_CNN_Architecture_for_Multi-Modal_Aerial_View_Object_Classification_CVPRW_2021_paper.html">Efficient CNN Architecture for Multi-Modal Aerial View Object Classification</a></th>
                    </tr>
                
                    <tr id="9208dc0128f2938303ad13e9530afec846a65dbb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9208dc0128f2938303ad13e9530afec846a65dbb">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Lee_Wide_Receptive_Field_and_Channel_Attention_Network_for_JPEG_Compressed_CVPRW_2021_paper.html">Wide Receptive Field and Channel Attention Network for JPEG Compressed Image Deblurring</a></th>
                    </tr>
                
                    <tr id="91eef8af845e4fcb99536256c067a60933680d20">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/91eef8af845e4fcb99536256c067a60933680d20">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/UG2/html/Hira_Delta_Sampling_R-BERT_for_Limited_Data_and_Low-Light_Action_Recognition_CVPRW_2021_paper.html">Delta Sampling R-BERT for Limited Data and Low-Light Action Recognition</a></th>
                    </tr>
                
                    <tr id="0caeaf7474255a15d0e2b821b5ddd9b7ba8a9321">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0caeaf7474255a15d0e2b821b5ddd9b7ba8a9321">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/UG2/html/Du_Expectation-Maximization_Attention_Cross_Residual_Network_for_Single_Image_Super-Resolution_CVPRW_2021_paper.html">Expectation-Maximization Attention Cross Residual Network for Single Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="118638c768e7116f58a48545d514c4e3640ec2a3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/118638c768e7116f58a48545d514c4e3640ec2a3">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LXCV/html/Suarez-Ramirez_A_Bop_and_Beyond_A_Second_Order_Optimizer_for_Binarized_CVPRW_2021_paper.html">A Bop and Beyond: A Second Order Optimizer for Binarized Neural Networks</a></th>
                    </tr>
                
                    <tr id="a1428054c3d082bb892069ce422884abb9e198a6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a1428054c3d082bb892069ce422884abb9e198a6">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Bolten_DVS-OUTLAB_A_Neuromorphic_Event-Based_Long_Time_Monitoring_Dataset_for_Real-World_CVPRW_2021_paper.html">DVS-OUTLAB: A Neuromorphic Event-Based Long Time Monitoring Dataset for Real-World Outdoor Scenarios</a></th>
                    </tr>
                
                    <tr id="7e68c026b901cd7670785df9ad7fb9d4644495e0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e68c026b901cd7670785df9ad7fb9d4644495e0">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Scarpellini_Lifting_Monocular_Events_to_3D_Human_Poses_CVPRW_2021_paper.html">Lifting Monocular Events to 3D Human Poses</a></th>
                    </tr>
                
                    <tr id="9dfb82f038b18a55618fa4797157d318468d665d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9dfb82f038b18a55618fa4797157d318468d665d">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Biometrics/html/Mallat_Indirect_Synthetic_Attack_on_Thermal_Face_Biometric_Systems_via_Visible-to-Thermal_CVPRW_2021_paper.html">Indirect Synthetic Attack on Thermal Face Biometric Systems via Visible-to-Thermal Spectrum Conversion</a></th>
                    </tr>
                
                    <tr id="eae7a98d6c15bd6af847bb60a176c29a7d9e8fc3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eae7a98d6c15bd6af847bb60a176c29a7d9e8fc3">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Biometrics/html/Brito_A_Deep_Adversarial_Framework_for_Visually_Explainable_Periocular_Recognition_CVPRW_2021_paper.html">A Deep Adversarial Framework for Visually Explainable Periocular Recognition</a></th>
                    </tr>
                
                    <tr id="eb169a1b1c3e10afd039bedf8ad266f31fe486cb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/eb169a1b1c3e10afd039bedf8ad266f31fe486cb">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AMFG/html/Vyas_An_Efficient_3D_Synthetic_Model_Generation_Pipeline_for_Human_Pose_CVPRW_2021_paper.html">An Efficient 3D Synthetic Model Generation Pipeline for Human Pose Data Augmentation</a></th>
                    </tr>
                
                    <tr id="c158916e4c3184836b4221607df29eea308b3a4d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c158916e4c3184836b4221607df29eea308b3a4d">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AMFG/html/Liu_Video-Based_Person_Re-Identification_Without_Bells_and_Whistles_CVPRW_2021_paper.html">Video-Based Person Re-Identification Without Bells and Whistles</a></th>
                    </tr>
                
                    <tr id="43e434618fbca87648856e67874dfec4b6e8611c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/43e434618fbca87648856e67874dfec4b6e8611c">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AUVi/html/Olague_Less_Is_More_Pursuing_the_Visual_Turing_Test_With_the_CVPRW_2021_paper.html">Less Is More: Pursuing the Visual Turing Test With the Kuleshov Effect</a></th>
                    </tr>
                
                    <tr id="b13e729cf7fa9d0e79d2f27fc77373fcbb127b64">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b13e729cf7fa9d0e79d2f27fc77373fcbb127b64">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Nguyen_Practical_Cross-Modal_Manifold_Alignment_for_Robotic_Grounded_Language_Learning_CVPRW_2021_paper.html">Practical Cross-Modal Manifold Alignment for Robotic Grounded Language Learning</a></th>
                    </tr>
                
                    <tr id="7e9cae8849a5454254d748e912644e5d1cfca4d2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e9cae8849a5454254d748e912644e5d1cfca4d2">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Koorathota_Editing_Like_Humans_A_Contextual_Multimodal_Framework_for_Automated_Video_CVPRW_2021_paper.html">Editing Like Humans: A Contextual, Multimodal Framework for Automated Video Editing</a></th>
                    </tr>
                
                    <tr id="18839a9a29722918e91dcb8ac676240ca770021b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/18839a9a29722918e91dcb8ac676240ca770021b">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ISIC/html/Mohseni_Can_Self-Training_Identify_Suspicious_Ugly_Duckling_Lesions_CVPRW_2021_paper.html">Can Self-Training Identify Suspicious Ugly Duckling Lesions?</a></th>
                    </tr>
                
                    <tr id="009e844a5213ec4fa5732dc6eae3803f928f0b5a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/009e844a5213ec4fa5732dc6eae3803f928f0b5a">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ISIC/html/Reimers_Conditional_Dependence_Tests_Reveal_the_Usage_of_ABCD_Rule_Features_CVPRW_2021_paper.html">Conditional Dependence Tests Reveal the Usage of ABCD Rule Features and Bias Variables in Automatic Skin Lesion Classification</a></th>
                    </tr>
                
                    <tr id="c0ef405ce72522044c26f193da01b1dfc244ba32">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c0ef405ce72522044c26f193da01b1dfc244ba32">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ISIC/html/Stieler_Towards_Domain-Specific_Explainable_AI_Model_Interpretation_of_a_Skin_Image_CVPRW_2021_paper.html">Towards Domain-Specific Explainable AI: Model Interpretation of a Skin Image Classifier Using a Human Approach</a></th>
                    </tr>
                
                    <tr id="9d55aa12328025cb423769407dc81e1683903747">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9d55aa12328025cb423769407dc81e1683903747">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Iwai_Self_Texture_Transfer_Networks_for_Low_Bitrate_Image_Compression_CVPRW_2021_paper.html">Self Texture Transfer Networks for Low Bitrate Image Compression</a></th>
                    </tr>
                
                    <tr id="7519bfa33dde6a64685088e79b6c61170e40ca26">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7519bfa33dde6a64685088e79b6c61170e40ca26">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Peng_Multi-Metric_Fusion_Network_for_Image_Quality_Assessment_CVPRW_2021_paper.html">Multi-Metric Fusion Network for Image Quality Assessment</a></th>
                    </tr>
                
                    <tr id="fd1aa928a65b731c045dae85ed0af25417a320f0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fd1aa928a65b731c045dae85ed0af25417a320f0">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Baireddy_Spacecraft_Time-Series_Anomaly_Detection_Using_Transfer_Learning_CVPRW_2021_paper.html">Spacecraft Time-Series Anomaly Detection Using Transfer Learning</a></th>
                    </tr>
                
                    <tr id="aeda0f87c60c25b8231d513d1038ab24a5237918">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aeda0f87c60c25b8231d513d1038ab24a5237918">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WiCV/html/Hegde_DeepDNet_Deep_Dense_Network_for_Depth_Completion_Task_CVPRW_2021_paper.html">DeepDNet: Deep Dense Network for Depth Completion Task</a></th>
                    </tr>
                
                    <tr id="63607db8c11f5d88619bd3c4756992bd9b5a952f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/63607db8c11f5d88619bd3c4756992bd9b5a952f">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WiCV/html/Katageri_PointDCCNet_3D_Object_Categorization_Network_Using_Point_Cloud_Decomposition_CVPRW_2021_paper.html">PointDCCNet: 3D Object Categorization Network Using Point Cloud Decomposition</a></th>
                    </tr>
                
                    <tr id="292d4fb83bc386b4b3bb308abebd96f176f2cb4f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/292d4fb83bc386b4b3bb308abebd96f176f2cb4f">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Precognition/html/Aoyagi_Spatio-Temporal_Predictive_Network_for_Videos_With_Physical_Properties_CVPRW_2021_paper.html">Spatio-Temporal Predictive Network for Videos With Physical Properties</a></th>
                    </tr>
                
                    <tr id="fe90737e2c5537f7cc9ee650bd1dcae149e7d5a4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fe90737e2c5537f7cc9ee650bd1dcae149e7d5a4">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Pouget_Fast_and_Accurate_Camera_Scene_Detection_on_Smartphones_CVPRW_2021_paper.html">Fast and Accurate Camera Scene Detection on Smartphones</a></th>
                    </tr>
                
                    <tr id="b1cd99762bf07a682c5337ad178e336e852a0f11">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b1cd99762bf07a682c5337ad178e336e852a0f11">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MAI/html/Zhang_A_Simple_Baseline_for_Fast_and_Accurate_Depth_Estimation_on_CVPRW_2021_paper.html">A Simple Baseline for Fast and Accurate Depth Estimation on Mobile Devices</a></th>
                    </tr>
                
                    <tr id="fc1c12e994496f5937aaeae72cb616baf4b2dd08">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fc1c12e994496f5937aaeae72cb616baf4b2dd08">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Martinson_Training_Rare_Object_Detection_in_Satellite_Imagery_With_Synthetic_GAN_CVPRW_2021_paper.html">Training Rare Object Detection in Satellite Imagery With Synthetic GAN Images</a></th>
                    </tr>
                
                    <tr id="ffda5796ec9a5690e7ee67d534a1c12bdb2218f6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ffda5796ec9a5690e7ee67d534a1c12bdb2218f6">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WAD/html/Nuanes_Soft_Cross_Entropy_Loss_and_Bottleneck_Tri-Cost_Volume_for_Efficient_CVPRW_2021_paper.html">Soft Cross Entropy Loss and Bottleneck Tri-Cost Volume for Efficient Stereo Depth Prediction</a></th>
                    </tr>
                
                    <tr id="09013a6545a01813bb7cd6e2d70aa4fdc72e7fff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/09013a6545a01813bb7cd6e2d70aa4fdc72e7fff">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AgriVision/html/Dadsetan_Superpixels_and_Graph_Convolutional_Neural_Networks_for_Efficient_Detection_of_CVPRW_2021_paper.html">Superpixels and Graph Convolutional Neural Networks for Efficient Detection of Nutrient Deficiency Stress From Aerial Imagery</a></th>
                    </tr>
                
                    <tr id="74b7d2a922fd7cc82307bf6d8a8cd35d8910863d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/74b7d2a922fd7cc82307bf6d8a8cd35d8910863d">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AgriVision/html/Ratnayake_Towards_Computer_Vision_and_Deep_Learning_Facilitated_Pollination_Monitoring_for_CVPRW_2021_paper.html">Towards Computer Vision and Deep Learning Facilitated Pollination Monitoring for Agriculture</a></th>
                    </tr>
                
                    <tr id="dfc2d585d72eff8d8fb3c7d17d5d06f56d888ef9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dfc2d585d72eff8d8fb3c7d17d5d06f56d888ef9">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AgriVision/html/Innani_Fuse-PN_A_Novel_Architecture_for_Anomaly_Pattern_Segmentation_in_Aerial_CVPRW_2021_paper.html">Fuse-PN: A Novel Architecture for Anomaly Pattern Segmentation in Aerial Agricultural Images</a></th>
                    </tr>
                
                    <tr id="5c09bf369751eab038e2715f62e62090c8fe6aca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c09bf369751eab038e2715f62e62090c8fe6aca">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/JRDB/html/He_Know_Your_Surroundings_Panoramic_Multi-Object_Tracking_by_Multimodality_Collaboration_CVPRW_2021_paper.html">Know Your Surroundings: Panoramic Multi-Object Tracking by Multimodality Collaboration</a></th>
                    </tr>
                
                    <tr id="823a912f6aa09d191508e9dc53cc26392e2718ef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/823a912f6aa09d191508e9dc53cc26392e2718ef">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Yu_Is_In-Domain_Data_Really_Needed_A_Pilot_Study_on_Cross-Domain_CVPRW_2021_paper.html">Is In-Domain Data Really Needed? A Pilot Study on Cross-Domain Calibration for Network Quantization</a></th>
                    </tr>
                
                    <tr id="007c24576b4a2f58d50c79047008283252cc27d7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/007c24576b4a2f58d50c79047008283252cc27d7">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Pouransari_Extracurricular_Learning_Knowledge_Transfer_Beyond_Empirical_Distribution_CVPRW_2021_paper.html">Extracurricular Learning: Knowledge Transfer Beyond Empirical Distribution</a></th>
                    </tr>
                
                    <tr id="0637d23766191a2f1c0e75fba23370d0e5211d58">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0637d23766191a2f1c0e75fba23370d0e5211d58">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Chin_Width_Transfer_On_the_Invariance_of_Width_Optimization_CVPRW_2021_paper.html">Width Transfer: On the (In)variance of Width Optimization</a></th>
                    </tr>
                
                    <tr id="807faf818aa92dcb543d25a39c6c397e5fceed5d">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/807faf818aa92dcb543d25a39c6c397e5fceed5d">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Zhang_BasisNet_Two-Stage_Model_Synthesis_for_Efficient_Inference_CVPRW_2021_paper.html">BasisNet: Two-Stage Model Synthesis for Efficient Inference</a></th>
                    </tr>
                
                    <tr id="6c07e145295b1925445096ff253529a62b411584">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c07e145295b1925445096ff253529a62b411584">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/GAZE/html/Siegfried_Visual_Focus_of_Attention_Estimation_in_3D_Scene_With_an_CVPRW_2021_paper.html">Visual Focus of Attention Estimation in 3D Scene With an Arbitrary Number of Targets</a></th>
                    </tr>
                
                    <tr id="0313cfd4e709a3164845f248a6c760b688c54ee2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0313cfd4e709a3164845f248a6c760b688c54ee2">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/VOCVALC/html/Zhang_HSiPu2_-_A_New_Human_Physical_Fitness_Action_Dataset_for_CVPRW_2021_paper.html">HSiPu2 - A New Human Physical Fitness Action Dataset for Recognition and 3D Reconstruction Evaluation</a></th>
                    </tr>
                
                    <tr id="3eb656e584d00c2ac31c59d3c290b09abb627fb1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3eb656e584d00c2ac31c59d3c290b09abb627fb1">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EVW/html/Ristea_Automotive_Radar_Interference_Mitigation_With_Unfolded_Robust_PCA_Based_on_CVPRW_2021_paper.html">Automotive Radar Interference Mitigation With Unfolded Robust PCA Based on Residual Overcomplete Auto-Encoder Blocks</a></th>
                    </tr>
                
                    <tr id="390ec1f13ac58429a092fb01678d4c3105482aaa">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/390ec1f13ac58429a092fb01678d4c3105482aaa">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EVW/html/Pirvu_Depth_Distillation_Unsupervised_Metric_Depth_Estimation_for_UAVs_by_Finding_CVPRW_2021_paper.html">Depth Distillation: Unsupervised Metric Depth Estimation for UAVs by Finding Consensus Between Kinematics, Optical Flow and Deep Learning</a></th>
                    </tr>
                
                    <tr id="48abcea1c9a1e0c980115521160027d1004973df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/48abcea1c9a1e0c980115521160027d1004973df">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Sun_A_Watermarking-Based_Framework_for_Protecting_Deep_Image_Classifiers_Against_Adversarial_CVPRW_2021_paper.html">A Watermarking-Based Framework for Protecting Deep Image Classifiers Against Adversarial Attacks</a></th>
                    </tr>
                
                    <tr id="4f0a83108fbcf8a7b53b13ad15755d66ad02e577">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f0a83108fbcf8a7b53b13ad15755d66ad02e577">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Rahnama_An_Adversarial_Approach_for_Explaining_the_Predictions_of_Deep_Neural_CVPRW_2021_paper.html">An Adversarial Approach for Explaining the Predictions of Deep Neural Networks</a></th>
                    </tr>
                
                    <tr id="e380528fd189cf34ea86e557151fa050ae954be2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e380528fd189cf34ea86e557151fa050ae954be2">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Chin_Renofeation_A_Simple_Transfer_Learning_Method_for_Improved_Adversarial_Robustness_CVPRW_2021_paper.html">Renofeation: A Simple Transfer Learning Method for Improved Adversarial Robustness</a></th>
                    </tr>
                
                    <tr id="d35fce16b4a8f101d3d9f65bfd50f57afb6436e5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d35fce16b4a8f101d3d9f65bfd50f57afb6436e5">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/HVU/html/Hara_Rethinking_Training_Data_for_Mitigating_Representation_Biases_in_Action_Recognition_CVPRW_2021_paper.html">Rethinking Training Data for Mitigating Representation Biases in Action Recognition</a></th>
                    </tr>
                
                    <tr id="b01bf3e8fb6446c3219a2ca5ceb49032e99afae9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b01bf3e8fb6446c3219a2ca5ceb49032e99afae9">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Jiang_IB-DRR_-_Incremental_Learning_With_Information-Back_Discrete_Representation_Replay_CVPRW_2021_paper.html">IB-DRR - Incremental Learning With Information-Back Discrete Representation Replay</a></th>
                    </tr>
                
                    <tr id="0e4838f28d4f059cfb02e2dbb7ea6087b4475abe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0e4838f28d4f059cfb02e2dbb7ea6087b4475abe">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Mundt_Neural_Architecture_Search_of_Deep_Priors_Towards_Continual_Learning_Without_CVPRW_2021_paper.html">Neural Architecture Search of Deep Priors: Towards Continual Learning Without Catastrophic Interference</a></th>
                    </tr>
                
                    <tr id="7c85e6492852d3b763d33e32483c74734cb017ed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c85e6492852d3b763d33e32483c74734cb017ed">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/OmniCV/html/Berenguel-Baeta_Scaled_360_Layouts_Revisiting_Non-Central_Panoramas_CVPRW_2021_paper.html">Scaled 360 Layouts: Revisiting Non-Central Panoramas</a></th>
                    </tr>
                
                    <tr id="35b0bdaaf1592c7fec88139b039dc2993f453d87">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/35b0bdaaf1592c7fec88139b039dc2993f453d87">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/OmniCV/html/Oskarsson_Fast_Solvers_for_Minimal_Radial_Distortion_Relative_Pose_Problems_CVPRW_2021_paper.html">Fast Solvers for Minimal Radial Distortion Relative Pose Problems</a></th>
                    </tr>
                
                    <tr id="c4694dc4b2035535b151a63695d94cf31d59d0fe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c4694dc4b2035535b151a63695d94cf31d59d0fe">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVMI/html/Aguilar_3D_Fiber_Segmentation_With_Deep_Center_Regression_and_Geometric_Clustering_CVPRW_2021_paper.html">3D Fiber Segmentation With Deep Center Regression and Geometric Clustering</a></th>
                    </tr>
                
                    <tr id="46caa2beb0219e041682da87d3f995e59995a1c9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/46caa2beb0219e041682da87d3f995e59995a1c9">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVMI/html/Liu_Learning_Melanocytic_Proliferation_Segmentation_in_Histopathology_Images_From_Imperfect_Annotations_CVPRW_2021_paper.html">Learning Melanocytic Proliferation Segmentation in Histopathology Images From Imperfect Annotations</a></th>
                    </tr>
                
                    <tr id="8cb3fab33879829bacd5e169d9b5be818f3f608c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8cb3fab33879829bacd5e169d9b5be818f3f608c">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVPM/html/Gao_A_LSTM-Based_Realtime_Signal_Quality_Assessment_for_Photoplethysmogram_and_Remote_CVPRW_2021_paper.html">A LSTM-Based Realtime Signal Quality Assessment for Photoplethysmogram and Remote Photoplethysmogram</a></th>
                    </tr>
                
                    <tr id="3a7046b7e9eb4c0448d4a8dc32a2f89873de1d08">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3a7046b7e9eb4c0448d4a8dc32a2f89873de1d08">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Kaicheng_Modeling_Fashion_Compatibility_With_Explanation_by_Using_Bidirectional_LSTM_CVPRW_2021_paper.html">Modeling Fashion Compatibility With Explanation by Using Bidirectional LSTM</a></th>
                    </tr>
                
                    <tr id="c106d22a70c180a9eaa8f4dc2fe71d9c470bc6b4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c106d22a70c180a9eaa8f4dc2fe71d9c470bc6b4">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Sbai_Surprising_Image_Compositions_CVPRW_2021_paper.html">Surprising Image Compositions</a></th>
                    </tr>
                
                    <tr id="e4d01f76b69ec64976d5a2f0dd7a9622ebbebd65">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e4d01f76b69ec64976d5a2f0dd7a9622ebbebd65">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Ferreira_Explainable_Noisy_Label_Flipping_for_Multi-Label_Fashion_Image_Classification_CVPRW_2021_paper.html">Explainable Noisy Label Flipping for Multi-Label Fashion Image Classification</a></th>
                    </tr>
                
                    <tr id="2f84a4d3edfddfc7a477f712d2b8848fe6275160">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2f84a4d3edfddfc7a477f712d2b8848fe6275160">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Kips_Deep_Graphics_Encoder_for_Real-Time_Video_Makeup_Synthesis_From_Example_CVPRW_2021_paper.html">Deep Graphics Encoder for Real-Time Video Makeup Synthesis From Example</a></th>
                    </tr>
                
                    <tr id="909aa6a33830c3280118eb822ee852edf047fde3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/909aa6a33830c3280118eb822ee852edf047fde3">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Sun_Progressive_Data_Mining_and_Adaptive_Weighted_Multi-Model_Ensemble_for_Vehicle_CVPRW_2021_paper.html">Progressive Data Mining and Adaptive Weighted Multi-Model Ensemble for Vehicle Re-Identification</a></th>
                    </tr>
                
                    <tr id="64e8cab1d0a4022cde1caee7c3579ceb0afeeed1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/64e8cab1d0a4022cde1caee7c3579ceb0afeeed1">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Lee_SBNet_Segmentation-Based_Network_for_Natural_Language-Based_Vehicle_Search_CVPRW_2021_paper.html">SBNet: Segmentation-Based Network for Natural Language-Based Vehicle Search</a></th>
                    </tr>
                
                    <tr id="83fecdd53ce9ca68136529322d78cb1982dc1bf9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/83fecdd53ce9ca68136529322d78cb1982dc1bf9">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/PBVS/html/Marques_Instance_Segmentation-Based_Identification_of_Pelagic_Species_in_Acoustic_Backscatter_Data_CVPRW_2021_paper.html">Instance Segmentation-Based Identification of Pelagic Species in Acoustic Backscatter Data</a></th>
                    </tr>
                
                    <tr id="1f4e6fe93f65921ef43068d901216c2a061fab06">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1f4e6fe93f65921ef43068d901216c2a061fab06">2</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DiffCVML/html/Nunez_SrvfNet_A_Generative_Network_for_Unsupervised_Multiple_Diffeomorphic_Functional_Alignment_CVPRW_2021_paper.html">SrvfNet: A Generative Network for Unsupervised Multiple Diffeomorphic Functional Alignment</a></th>
                    </tr>
                
                    <tr id="6e9d76cc8f018abd8d23fd235a83a97502f9c9ca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6e9d76cc8f018abd8d23fd235a83a97502f9c9ca">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Song_Communication_Efficient_SGD_via_Gradient_Sampling_With_Bayes_Prior_CVPR_2021_paper.html">Communication Efficient SGD via Gradient Sampling With Bayes Prior</a></th>
                    </tr>
                
                    <tr id="cc0e41db9f3ac982623ecca66a4756130d97dc1c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cc0e41db9f3ac982623ecca66a4756130d97dc1c">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Xu_Adaptive_Rank_Estimate_in_Robust_Principal_Component_Analysis_CVPR_2021_paper.html">Adaptive Rank Estimate in Robust Principal Component Analysis</a></th>
                    </tr>
                
                    <tr id="989fcc975e59904499f794114f248b8b780a81f6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/989fcc975e59904499f794114f248b8b780a81f6">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Pal_Synthesize-It-Classifier_Learning_a_Generative_Classifier_Through_Recurrent_Self-Analysis_CVPR_2021_paper.html">Synthesize-It-Classifier: Learning a Generative Classifier Through Recurrent Self-Analysis</a></th>
                    </tr>
                
                    <tr id="2600e63ab4272bd2451fbc135cf8ae1abb2a179c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2600e63ab4272bd2451fbc135cf8ae1abb2a179c">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Posterior_Promoted_GAN_With_Distribution_Discriminator_for_Unsupervised_Image_Synthesis_CVPR_2021_paper.html">Posterior Promoted GAN With Distribution Discriminator for Unsupervised Image Synthesis</a></th>
                    </tr>
                
                    <tr id="75fbe705b772c538a8cb4a7cfba171dd2ad27cff">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/75fbe705b772c538a8cb4a7cfba171dd2ad27cff">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Guo_Positive-Unlabeled_Data_Purification_in_the_Wild_for_Object_Detection_CVPR_2021_paper.html">Positive-Unlabeled Data Purification in the Wild for Object Detection</a></th>
                    </tr>
                
                    <tr id="df1a4b5cb1cec9a321f8c2accf72c4dd7ef866f9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/df1a4b5cb1cec9a321f8c2accf72c4dd7ef866f9">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Khan_Differentiable_Diffusion_for_Dense_Depth_Estimation_From_Multi-View_Images_CVPR_2021_paper.html">Differentiable Diffusion for Dense Depth Estimation From Multi-View Images</a></th>
                    </tr>
                
                    <tr id="56619f60bb8bd17aa1bcd9250f235814857cb6dc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/56619f60bb8bd17aa1bcd9250f235814857cb6dc">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yan_Online_Learning_of_a_Probabilistic_and_Adaptive_Scene_Representation_CVPR_2021_paper.html">Online Learning of a Probabilistic and Adaptive Scene Representation</a></th>
                    </tr>
                
                    <tr id="7ed667577ace680693a2a2aa47fa44ab7e2235cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7ed667577ace680693a2a2aa47fa44ab7e2235cc">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liu_Neighborhood_Normalization_for_Robust_Geometric_Feature_Learning_CVPR_2021_paper.html">Neighborhood Normalization for Robust Geometric Feature Learning</a></th>
                    </tr>
                
                    <tr id="760911867f853b355e4409587562c46e5854d913">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/760911867f853b355e4409587562c46e5854d913">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Ornhag_Bilinear_Parameterization_for_Non-Separable_Singular_Value_Penalties_CVPR_2021_paper.html">Bilinear Parameterization for Non-Separable Singular Value Penalties</a></th>
                    </tr>
                
                    <tr id="67d9a209930e673a715a25d89a07eb3335317372">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/67d9a209930e673a715a25d89a07eb3335317372">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Kim_High-Quality_Stereo_Image_Restoration_From_Double_Refraction_CVPR_2021_paper.html">High-Quality Stereo Image Restoration From Double Refraction</a></th>
                    </tr>
                
                    <tr id="087321c15eaa0f5f67765ebdbaa41e10376ca182">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/087321c15eaa0f5f67765ebdbaa41e10376ca182">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lacroix_IMODAL_Creating_Learnable_User-Defined_Deformation_Models_CVPR_2021_paper.html">IMODAL: Creating Learnable User-Defined Deformation Models</a></th>
                    </tr>
                
                    <tr id="af87d1186726b484acff295b46244bc4067a1f25">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/af87d1186726b484acff295b46244bc4067a1f25">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_PSRR-MaxpoolNMS_Pyramid_Shifted_MaxpoolNMS_With_Relationship_Recovery_CVPR_2021_paper.html">PSRR-MaxpoolNMS: Pyramid Shifted MaxpoolNMS With Relationship Recovery</a></th>
                    </tr>
                
                    <tr id="7795056120c29a15dfed9ebc5bf2339481cf34d9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7795056120c29a15dfed9ebc5bf2339481cf34d9">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Hamaguchi_Heterogeneous_Grid_Convolution_for_Adaptive_Efficient_and_Controllable_Computation_CVPR_2021_paper.html">Heterogeneous Grid Convolution for Adaptive, Efficient, and Controllable Computation</a></th>
                    </tr>
                
                    <tr id="3b12cd8ac9699e8763cf4e0039427b0105bee091">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3b12cd8ac9699e8763cf4e0039427b0105bee091">1</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lin_Reciprocal_Landmark_Detection_and_Tracking_With_Extremely_Few_Annotations_CVPR_2021_paper.html">Reciprocal Landmark Detection and Tracking With Extremely Few Annotations</a></th>
                    </tr>
                
                    <tr id="d3722874fc24d1662dea5037142594e673dff5df">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d3722874fc24d1662dea5037142594e673dff5df">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Jaworek-Korjakowska_SafeSO_Interpretable_and_Explainable_Deep_Learning_Approach_for_Seat_Occupancy_CVPRW_2021_paper.html">SafeSO: Interpretable and Explainable Deep Learning Approach for Seat Occupancy Classification in Vehicle Interior</a></th>
                    </tr>
                
                    <tr id="5658b38e26680acd6fea64d4443eb058a8ea8918">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5658b38e26680acd6fea64d4443eb058a8ea8918">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Zhu_LTNet_Light_Transfer_Network_for_Depth_Guided_Image_Relighting_CVPRW_2021_paper.html">LTNet: Light Transfer Network for Depth Guided Image Relighting</a></th>
                    </tr>
                
                    <tr id="8a157e49ab3a9989d2c2ffd65153110aa36e3352">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8a157e49ab3a9989d2c2ffd65153110aa36e3352">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Cho_Weighted_Multi-Kernel_Prediction_Network_for_Burst_Image_Super-Resolution_CVPRW_2021_paper.html">Weighted Multi-Kernel Prediction Network for Burst Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="16fb6d56a037406396f274bea2bda878c0556a7e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/16fb6d56a037406396f274bea2bda878c0556a7e">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Pan_Three_Gaps_for_Quantisation_in_Learned_Image_Compression_CVPRW_2021_paper.html">Three Gaps for Quantisation in Learned Image Compression</a></th>
                    </tr>
                
                    <tr id="6c01fce58a18003b08a722ec5565e7b10991bf50">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c01fce58a18003b08a722ec5565e7b10991bf50">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/UG2/html/Hu_E2VTS_Energy-Efficient_Video_Text_Spotting_From_Unmanned_Aerial_Vehicles_CVPRW_2021_paper.html">E2VTS: Energy-Efficient Video Text Spotting From Unmanned Aerial Vehicles</a></th>
                    </tr>
                
                    <tr id="32913fefc14b8ad080ba5eb0e6c619cd3c9566b7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/32913fefc14b8ad080ba5eb0e6c619cd3c9566b7">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Sabel_On_the_Robustness_and_Generalizability_of_Face_Synthesis_Detection_Methods_CVPRW_2021_paper.html">On the Robustness and Generalizability of Face Synthesis Detection Methods</a></th>
                    </tr>
                
                    <tr id="e0d287d0d03b8e896c2ad74fc34f6fa09476de27">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e0d287d0d03b8e896c2ad74fc34f6fa09476de27">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LXCV/html/Rodriguez_On_Disentanglement_and_Mutual_Information_in_Semi-Supervised_Variational_Auto-Encoders_CVPRW_2021_paper.html">On Disentanglement and Mutual Information in Semi-Supervised Variational Auto-Encoders</a></th>
                    </tr>
                
                    <tr id="fd8c7b778c7a3d4f550d9f9cf6cd0df718ad7b7e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fd8c7b778c7a3d4f550d9f9cf6cd0df718ad7b7e">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Peveri_A_Cortically-Inspired_Architecture_for_Event-Based_Visual_Motion_Processing_From_Design_CVPRW_2021_paper.html">A Cortically-Inspired Architecture for Event-Based Visual Motion Processing: From Design Principles to Real-World Applications</a></th>
                    </tr>
                
                    <tr id="353d0646e4f91399012927e3ac1b859c746d4cab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/353d0646e4f91399012927e3ac1b859c746d4cab">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Biometrics/html/Ali_Toe_Prints_An_Application_Study_for_Biometric_Verification_in_Adults_CVPRW_2021_paper.html">Toe Prints: An Application Study for Biometric Verification in Adults</a></th>
                    </tr>
                
                    <tr id="260a676c2879672acea312adf99c2f114f701d96">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/260a676c2879672acea312adf99c2f114f701d96">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Biometrics/html/Tulyakov_Multistage_Fusion_of_Face_Matchers_CVPRW_2021_paper.html">Multistage Fusion of Face Matchers</a></th>
                    </tr>
                
                    <tr id="0cf76c6113d4976af2235092e79c89908eb0b239">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0cf76c6113d4976af2235092e79c89908eb0b239">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AMFG/html/Lee_Face_Parsing_From_RGB_and_Depth_Using_Cross-Domain_Mutual_Learning_CVPRW_2021_paper.html">Face Parsing From RGB and Depth Using Cross-Domain Mutual Learning</a></th>
                    </tr>
                
                    <tr id="007a96a507fb0fcf7db7428d967901017ecd476e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/007a96a507fb0fcf7db7428d967901017ecd476e">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AMFG/html/Banerjee_LEGAN_Disentangled_Manipulation_of_Directional_Lighting_and_Facial_Expressions_Whilst_CVPRW_2021_paper.html">LEGAN: Disentangled Manipulation of Directional Lighting and Facial Expressions Whilst Leveraging Human Perceptual Judgements</a></th>
                    </tr>
                
                    <tr id="5e9954c6e2b30696253bb4215aff0e55101a745f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5e9954c6e2b30696253bb4215aff0e55101a745f">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Kangaspunta_Adaptive_Intermediate_Representations_for_Video_Understanding_CVPRW_2021_paper.html">Adaptive Intermediate Representations for Video Understanding</a></th>
                    </tr>
                
                    <tr id="080a5965358bd0559ba38f22091326d1e328f8c8">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/080a5965358bd0559ba38f22091326d1e328f8c8">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Zheng_Progressive_Knowledge-Embedded_Unified_Perceptual_Parsing_for_Scene_Understanding_CVPRW_2021_paper.html">Progressive Knowledge-Embedded Unified Perceptual Parsing for Scene Understanding</a></th>
                    </tr>
                
                    <tr id="88b5d42753d2f3a2194c886169038fd9ae7ade22">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/88b5d42753d2f3a2194c886169038fd9ae7ade22">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Dong_Using_Text_To_Teach_Image_Retrieval_CVPRW_2021_paper.html">Using Text To Teach Image Retrieval</a></th>
                    </tr>
                
                    <tr id="c6732c1583766ed49df35505eb50c9232d29d57c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c6732c1583766ed49df35505eb50c9232d29d57c">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DynaVis/html/Pesavento_Super-Resolution_Appearance_Transfer_for_4D_Human_Performances_CVPRW_2021_paper.html">Super-Resolution Appearance Transfer for 4D Human Performances</a></th>
                    </tr>
                
                    <tr id="a783e1837d674d98bcc43bac71b2d5ad8dc9c335">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a783e1837d674d98bcc43bac71b2d5ad8dc9c335">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DynaVis/html/Caliskan_Temporal_Consistency_Loss_for_High_Resolution_Textured_and_Clothed_3D_CVPRW_2021_paper.html">Temporal Consistency Loss for High Resolution Textured and Clothed 3D Human Reconstruction From Monocular Video</a></th>
                    </tr>
                
                    <tr id="2d4b11483a23e1c2ea1513b4b039ed911fc92984">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/2d4b11483a23e1c2ea1513b4b039ed911fc92984">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Gao_Perceptual_Friendly_Variable_Rate_Image_Compression_CVPRW_2021_paper.html">Perceptual Friendly Variable Rate Image Compression</a></th>
                    </tr>
                
                    <tr id="b3c86c3e5361412e53ab4524e7773b548f76ae10">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b3c86c3e5361412e53ab4524e7773b548f76ae10">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Ho_End-to-End_Learned_Image_Compression_With_Augmented_Normalizing_Flows_CVPRW_2021_paper.html">End-to-End Learned Image Compression With Augmented Normalizing Flows</a></th>
                    </tr>
                
                    <tr id="ef94064402792ec16927916085b27ca495459878">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ef94064402792ec16927916085b27ca495459878">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Wang_Subjective_Quality_Optimized_Efficient_Image_Compression_CVPRW_2021_paper.html">Subjective Quality Optimized Efficient Image Compression</a></th>
                    </tr>
                
                    <tr id="91c031f0fb499b0b9f9197c43ea035bebad3ffc0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/91c031f0fb499b0b9f9197c43ea035bebad3ffc0">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Wu_Deep_Image_Compression_With_Latent_Optimization_and_Piece-Wise_Quantization_Approximation_CVPRW_2021_paper.html">Deep Image Compression With Latent Optimization and Piece-Wise Quantization Approximation</a></th>
                    </tr>
                
                    <tr id="7c23782ab5b813d79312c06eb9abef8b2cdb33cd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7c23782ab5b813d79312c06eb9abef8b2cdb33cd">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Brummer_End-to-End_Optimized_Image_Compression_With_Competition_of_Prior_Distributions_CVPRW_2021_paper.html">End-to-End Optimized Image Compression With Competition of Prior Distributions</a></th>
                    </tr>
                
                    <tr id="b160be552299ecaa3035b57a8edb18b669660e7f">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b160be552299ecaa3035b57a8edb18b669660e7f">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Huang_Beyond_VVC_Towards_Perceptual_Quality_Optimized_Video_Compression_Using_Multi-Scale_CVPRW_2021_paper.html">Beyond VVC: Towards Perceptual Quality Optimized Video Compression Using Multi-Scale Hybrid Approaches</a></th>
                    </tr>
                
                    <tr id="521b0c08cf099bc04c50e05369eee9a1804a32bc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/521b0c08cf099bc04c50e05369eee9a1804a32bc">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Moya_AI_for_Dating_Stars_A_Benchmarking_Study_for_Gyrochronology_CVPRW_2021_paper.html">AI for Dating Stars: A Benchmarking Study for Gyrochronology</a></th>
                    </tr>
                
                    <tr id="b00296c12a876d69fd823a8371ef09e6b637b1d0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b00296c12a876d69fd823a8371ef09e6b637b1d0">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Menezes_From_Rocks_to_Walls_A_Model-Free_Reinforcement_Learning_Approach_To_CVPRW_2021_paper.html">From Rocks to Walls: A Model-Free Reinforcement Learning Approach To Dry Stacking With Irregular Rocks</a></th>
                    </tr>
                
                    <tr id="4fe09e32933f687bdc61a5787b2cccf0877a6d93">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4fe09e32933f687bdc61a5787b2cccf0877a6d93">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SketchDL/html/Yesilbek_On_Training_Sketch_Recognizers_for_New_Domains_CVPRW_2021_paper.html">On Training Sketch Recognizers for New Domains</a></th>
                    </tr>
                
                    <tr id="d354905b51ef13955e6cb3975d49750360bdc84b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d354905b51ef13955e6cb3975d49750360bdc84b">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WiCV/html/Madmad_CNN-Based_Morphological_Decomposition_of_X-Ray_Images_for_Details_and_Defects_CVPRW_2021_paper.html">CNN-Based Morphological Decomposition of X-Ray Images for Details and Defects Contrast Enhancement</a></th>
                    </tr>
                
                    <tr id="d48fa8359c27eb52a741778137c5938080f7756c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d48fa8359c27eb52a741778137c5938080f7756c">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Precognition/html/Gupta_Glaucoma_Precognition_Based_on_Confocal_Scanning_Laser_Ophthalmoscopy_Images_of_CVPRW_2021_paper.html">Glaucoma Precognition Based on Confocal Scanning Laser Ophthalmoscopy Images of the Optic Disc Using Convolutional Neural Network</a></th>
                    </tr>
                
                    <tr id="94ee2e6a6d40dcee04855e1d0210f46574f953c2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/94ee2e6a6d40dcee04855e1d0210f46574f953c2">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/Precognition/html/Mo_Long-Term_Head_Pose_Forecasting_Conditioned_on_the_Gaze-Guiding_Prior_CVPRW_2021_paper.html">Long-Term Head Pose Forecasting Conditioned on the Gaze-Guiding Prior</a></th>
                    </tr>
                
                    <tr id="790b17be19daf6e997d6e32aa16e819361598a7e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/790b17be19daf6e997d6e32aa16e819361598a7e">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Caiafa_Learning_From_Incomplete_Features_by_Simultaneous_Training_of_Neural_Networks_CVPRW_2021_paper.html">Learning From Incomplete Features by Simultaneous Training of Neural Networks and Sparse Coding</a></th>
                    </tr>
                
                    <tr id="3ebf6514489d52b08e2ad5d717d36c76f4f1a3e5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ebf6514489d52b08e2ad5d717d36c76f4f1a3e5">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Luddecke_The_Role_of_Data_for_One-Shot_Semantic_Segmentation_CVPRW_2021_paper.html">The Role of Data for One-Shot Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="263d7e9815af8b0385a677aeadc511c3f62cbc68">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/263d7e9815af8b0385a677aeadc511c3f62cbc68">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/JRDB/html/Hatay_Learning_To_Detect_Phone-Related_Pedestrian_Distracted_Behaviors_With_Synthetic_Data_CVPRW_2021_paper.html">Learning To Detect Phone-Related Pedestrian Distracted Behaviors With Synthetic Data</a></th>
                    </tr>
                
                    <tr id="d8c2e613b3ea37d079d5c2ad0e0443b0ca5b33ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d8c2e613b3ea37d079d5c2ad0e0443b0ca5b33ab">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Zhang_CompConv_A_Compact_Convolution_Module_for_Efficient_Feature_Learning_CVPRW_2021_paper.html">CompConv: A Compact Convolution Module for Efficient Feature Learning</a></th>
                    </tr>
                
                    <tr id="d65712a7162694a21d241584e3e921c86f17d3f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/d65712a7162694a21d241584e3e921c86f17d3f1">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EVW/html/Chen_CASSOD-Net_Cascaded_and_Separable_Structures_of_Dilated_Convolution_for_Embedded_CVPRW_2021_paper.html">CASSOD-Net: Cascaded and Separable Structures of Dilated Convolution for Embedded Vision Systems and Applications</a></th>
                    </tr>
                
                    <tr id="0f791ff138eb9025d7fa5bceeb429516cda22544">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0f791ff138eb9025d7fa5bceeb429516cda22544">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Begon_Sample-Free_White-Box_Out-of-Distribution_Detection_for_Deep_Learning_CVPRW_2021_paper.html">Sample-Free White-Box Out-of-Distribution Detection for Deep Learning</a></th>
                    </tr>
                
                    <tr id="c1d9bcbd271dc42fc4dea07e116e1fb7b15838c9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/c1d9bcbd271dc42fc4dea07e116e1fb7b15838c9">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/TCV/html/Tomei_Estimating_and_Fixing_the_Effect_of_Face_Obfuscation_in_Video_CVPRW_2021_paper.html">Estimating (and Fixing) the Effect of Face Obfuscation in Video Recognition</a></th>
                    </tr>
                
                    <tr id="01b6bf20e38818df0b1c9f5a55a5f013aadcef09">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/01b6bf20e38818df0b1c9f5a55a5f013aadcef09">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Wang_Continual_Learning_in_Cross-Modal_Retrieval_CVPRW_2021_paper.html">Continual Learning in Cross-Modal Retrieval</a></th>
                    </tr>
                
                    <tr id="28bd939da40d262c82a4f2fd6baf837f9f55e0b7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/28bd939da40d262c82a4f2fd6baf837f9f55e0b7">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/OmniCV/html/Buquet_Evaluating_the_Impact_of_Wide-Angle_Lens_Distortion_on_Learning-Based_Depth_CVPRW_2021_paper.html">Evaluating the Impact of Wide-Angle Lens Distortion on Learning-Based Depth Estimation</a></th>
                    </tr>
                
                    <tr id="29058deefa791428249c26e590200b4531415717">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/29058deefa791428249c26e590200b4531415717">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVMI/html/Meng_Hierarchical_Spatial_Pyramid_Network_for_Cervical_Precancerous_Segmentation_by_Reconstructing_CVPRW_2021_paper.html">Hierarchical Spatial Pyramid Network for Cervical Precancerous Segmentation by Reconstructing Deep Segmentation Networks</a></th>
                    </tr>
                
                    <tr id="e89415bac94a9e99a8a6908e5348165617c097c2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e89415bac94a9e99a8a6908e5348165617c097c2">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVPM/html/Webering_Markerless_Camera-Based_Vertical_Jump_Height_Measurement_Using_OpenPose_CVPRW_2021_paper.html">Markerless Camera-Based Vertical Jump Height Measurement Using OpenPose</a></th>
                    </tr>
                
                    <tr id="6741b3fd9d36a802aca9770e65d86fe6e385eb08">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6741b3fd9d36a802aca9770e65d86fe6e385eb08">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Rajput_IndoFashion_Apparel_Classification_for_Indian_Ethnic_Clothes_CVPRW_2021_paper.html">IndoFashion: Apparel Classification for Indian Ethnic Clothes</a></th>
                    </tr>
                
                    <tr id="811842c7e2aa6c9ee7469afb0ba442113d2bbffe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/811842c7e2aa6c9ee7469afb0ba442113d2bbffe">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Jouanneau_Where_Are_My_Clothes_A_Multi-Level_Approach_for_Evaluating_Deep_CVPRW_2021_paper.html">Where Are My Clothes? A Multi-Level Approach for Evaluating Deep Instance Segmentation Architectures on Fashion Images</a></th>
                    </tr>
                
                    <tr id="4cc28c8a7dd581aad4e6b8b084619a7b3d8a38b5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4cc28c8a7dd581aad4e6b8b084619a7b3d8a38b5">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Oyewusi_AFRIFASHION1600_A_Contemporary_African_Fashion_Dataset_for_Computer_Vision_CVPRW_2021_paper.html">AFRIFASHION1600: A Contemporary African Fashion Dataset for Computer Vision</a></th>
                    </tr>
                
                    <tr id="f189327b851bb833d42fdd3433c3a6ce821f2f71">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f189327b851bb833d42fdd3433c3a6ce821f2f71">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Yang_Tracklet-Refined_Multi-Camera_Tracking_Based_on_Balanced_Cross-Domain_Re-Identification_for_Vehicles_CVPRW_2021_paper.html">Tracklet-Refined Multi-Camera Tracking Based on Balanced Cross-Domain Re-Identification for Vehicles</a></th>
                    </tr>
                
                    <tr id="e28a7acab7892189f21e5de6ce21c500b30e881c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e28a7acab7892189f21e5de6ce21c500b30e881c">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/PBVS/html/Nathan_Leveraging_Multi_Scale_Backbone_With_Multilevel_Supervision_for_Thermal_Image_CVPRW_2021_paper.html">Leveraging Multi Scale Backbone With Multilevel Supervision for Thermal Image Super Resolution</a></th>
                    </tr>
                
                    <tr id="da3e4ad3aabc997c863c5735d4ccd209363696d9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/da3e4ad3aabc997c863c5735d4ccd209363696d9">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/PBVS/html/Brorsson_Reconstruction_of_CASSI-Raman_Images_With_Machine-Learning_CVPRW_2021_paper.html">Reconstruction of CASSI-Raman Images With Machine-Learning</a></th>
                    </tr>
                
                    <tr id="15709a6b23937e84b1e0b00bc7e03b7cbc59015a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/15709a6b23937e84b1e0b00bc7e03b7cbc59015a">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/PBVS/html/Axelsson_Semantic_Labeling_of_Lidar_Point_Clouds_for_UAV_Applications_CVPRW_2021_paper.html">Semantic Labeling of Lidar Point Clouds for UAV Applications</a></th>
                    </tr>
                
                    <tr id="7e2bcbbef521ed7ba090a6739ba56284747c4aef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7e2bcbbef521ed7ba090a6739ba56284747c4aef">1</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/McNally_DeepDarts_Modeling_Keypoints_as_Objects_for_Automatic_Scorekeeping_in_Darts_CVPRW_2021_paper.html">DeepDarts: Modeling Keypoints as Objects for Automatic Scorekeeping in Darts Using a Single Camera</a></th>
                    </tr>
                
                    <tr id="24b456e2bdad13c7e5e75ab205df31c21235a870">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/24b456e2bdad13c7e5e75ab205df31c21235a870">0</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Lebrat_MongeNet_Efficient_Sampler_for_Geometric_Deep_Learning_CVPR_2021_paper.html">MongeNet: Efficient Sampler for Geometric Deep Learning</a></th>
                    </tr>
                
                    <tr id="f1005edfa1fbc4ea0d9a90345388bda8a01e69ed">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f1005edfa1fbc4ea0d9a90345388bda8a01e69ed">0</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Zhang_Confluent_Vessel_Trees_With_Accurate_Bifurcations_CVPR_2021_paper.html">Confluent Vessel Trees With Accurate Bifurcations</a></th>
                    </tr>
                
                    <tr id="be4b20bad7cac81225d926014657b698e51c1cd5">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/be4b20bad7cac81225d926014657b698e51c1cd5">0</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Harel_Crossing_Cuts_Polygonal_Puzzles_Models_and_Solvers_CVPR_2021_paper.html">Crossing Cuts Polygonal Puzzles: Models and Solvers</a></th>
                    </tr>
                
                    <tr id="ded141ceebf3b8ceb315806b66d6330cd9c8ea31">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/ded141ceebf3b8ceb315806b66d6330cd9c8ea31">0</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Nam_Polygonal_Point_Set_Tracking_CVPR_2021_paper.html">Polygonal Point Set Tracking</a></th>
                    </tr>
                
                    <tr id="817ae17576204a0fb88b73d3888c7c5216c0cbfb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/817ae17576204a0fb88b73d3888c7c5216c0cbfb">0</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Olsson_A_Quasiconvex_Formulation_for_Radial_Cameras_CVPR_2021_paper.html">A Quasiconvex Formulation for Radial Cameras</a></th>
                    </tr>
                
                    <tr id="05d453f611a8c63a74a4fb6a52d4c943c1a7d540">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/05d453f611a8c63a74a4fb6a52d4c943c1a7d540">0</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Yu_Minimally_Invasive_Surgery_for_Sparse_Neural_Networks_in_Contrastive_Manner_CVPR_2021_paper.html">Minimally Invasive Surgery for Sparse Neural Networks in Contrastive Manner</a></th>
                    </tr>
                
                    <tr id="3c670f30034ee44a784305a821c9fe0c4f247c2c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3c670f30034ee44a784305a821c9fe0c4f247c2c">0</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Liao_4D_Hyperspectral_Photoacoustic_Data_Restoration_With_Reliability_Analysis_CVPR_2021_paper.html">4D Hyperspectral Photoacoustic Data Restoration With Reliability Analysis</a></th>
                    </tr>
                
                    <tr id="8d6ed48a3085c507605afcb7a42ad46d01566e9b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8d6ed48a3085c507605afcb7a42ad46d01566e9b">0</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Wu_Forecasting_Irreversible_Disease_via_Progression_Learning_CVPR_2021_paper.html">Forecasting Irreversible Disease via Progression Learning</a></th>
                    </tr>
                
                    <tr id="7d0f6e87484881f65c78bd30300f1b85d6ec2bfe">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7d0f6e87484881f65c78bd30300f1b85d6ec2bfe">0</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Manandhar_Magic_Layouts_Structural_Prior_for_Component_Detection_in_User_Interface_CVPR_2021_paper.html">Magic Layouts: Structural Prior for Component Detection in User Interface Designs</a></th>
                    </tr>
                
                    <tr id="8eccc344dfa05cce03cb2a97244d00c49f82d6dd">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8eccc344dfa05cce03cb2a97244d00c49f82d6dd">0</a>
                        </td>
                        <td class="align-middle text-center">MAIN</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021/html/Huang_Geo-FARM_Geodesic_Factor_Regression_Model_for_Misaligned_Pre-Shape_Responses_in_CVPR_2021_paper.html">Geo-FARM: Geodesic Factor Regression Model for Misaligned Pre-shape Responses in Statistical Shape Analysis</a></th>
                    </tr>
                
                    <tr id="64d6c08420ee56b38950e71417dcd5a1ec15ec82">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/64d6c08420ee56b38950e71417dcd5a1ec15ec82">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Adilova_Plants_Dont_Walk_on_the_Street_Common-Sense_Reasoning_for_Reliable_CVPRW_2021_paper.html">Plants Don&#39;t Walk on the Street: Common-Sense Reasoning for Reliable Semantic Segmentation</a></th>
                    </tr>
                
                    <tr id="934bd0cdc709a35ecd898ae4a87ea0e2b8e955cb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/934bd0cdc709a35ecd898ae4a87ea0e2b8e955cb">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Rosenzweig_Patch_Shortcuts_Interpretable_Proxy_Models_Efficiently_Find_Black-Box_Vulnerabilities_CVPRW_2021_paper.html">Patch Shortcuts: Interpretable Proxy Models Efficiently Find Black-Box Vulnerabilities</a></th>
                    </tr>
                
                    <tr id="b950bda920743e863d8524743bf1800504202ca0">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b950bda920743e863d8524743bf1800504202ca0">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/SAIAD/html/Chen_Sparse_Activation_Maps_for_Interpreting_3D_Object_Detection_CVPRW_2021_paper.html">Sparse Activation Maps for Interpreting 3D Object Detection</a></th>
                    </tr>
                
                    <tr id="e55fb832754718a4a2a41428ba12b75e4154cf23">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e55fb832754718a4a2a41428ba12b75e4154cf23">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/NTIRE/html/Xi_Pixel-Guided_Dual-Branch_Attention_Network_for_Joint_Image_Deblurring_and_Super-Resolution_CVPRW_2021_paper.html">Pixel-Guided Dual-Branch Attention Network for Joint Image Deblurring and Super-Resolution</a></th>
                    </tr>
                
                    <tr id="73db0a7f957fb2cd6ecf8d4144edf2541ade8c23">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/73db0a7f957fb2cd6ecf8d4144edf2541ade8c23">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/UG2/html/Ju_VRHI_Visibility_Restoration_for_Hazy_Images_Using_a_Haze_Density_CVPRW_2021_paper.html">VRHI: Visibility Restoration for Hazy Images Using a Haze Density Model</a></th>
                    </tr>
                
                    <tr id="df0e99ab0136975a56ef23f22b622676f42f1ea1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/df0e99ab0136975a56ef23f22b622676f42f1ea1">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/UG2/html/Han_Two-Stage_Network_for_Single_Image_Super-Resolution_CVPRW_2021_paper.html">Two-Stage Network for Single Image Super-Resolution</a></th>
                    </tr>
                
                    <tr id="4f2fa16c4e18bb8e946424ee6595a8bd46038ae6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4f2fa16c4e18bb8e946424ee6595a8bd46038ae6">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/UG2/html/Jiang_CE-PeopleSeg_Real-Time_People_Segmentation_With_10_CPU_Usage_for_Video_CVPRW_2021_paper.html">CE-PeopleSeg: Real-Time People Segmentation With 10% CPU Usage for Video Conference</a></th>
                    </tr>
                
                    <tr id="353c1a733e80c37235ee0c2402c70d3e47c7aaa9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/353c1a733e80c37235ee0c2402c70d3e47c7aaa9">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/WMF/html/Valenzuela_Expression_Transfer_Using_Flow-Based_Generative_Models_CVPRW_2021_paper.html">Expression Transfer Using Flow-Based Generative Models</a></th>
                    </tr>
                
                    <tr id="96df4c3c08f99ade1160df8b4fd5cd86904fdb0b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/96df4c3c08f99ade1160df8b4fd5cd86904fdb0b">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Mukherjee_Towards_Indirect_Top-Down_Road_Transport_Emissions_Estimation_CVPRW_2021_paper.html">Towards Indirect Top-Down Road Transport Emissions Estimation</a></th>
                    </tr>
                
                    <tr id="4c5464e3a340da2dd8300fb1f3e5b36f7068487c">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/4c5464e3a340da2dd8300fb1f3e5b36f7068487c">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Lee_Training_Domain-Invariant_Object_Detector_Faster_With_Feature_Replay_and_Slow_CVPRW_2021_paper.html">Training Domain-Invariant Object Detector Faster With Feature Replay and Slow Learner</a></th>
                    </tr>
                
                    <tr id="b2dd7a4e2ba1599b38d9093a8e58912c6b0bcbca">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b2dd7a4e2ba1599b38d9093a8e58912c6b0bcbca">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Drenkow_Addressing_Visual_Search_in_Open_and_Closed_Set_Settings_CVPRW_2021_paper.html">Addressing Visual Search in Open and Closed Set Settings</a></th>
                    </tr>
                
                    <tr id="a443900c3ddd149edf0953998a0468d9c1221221">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a443900c3ddd149edf0953998a0468d9c1221221">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EarthVision/html/Jain_Combining_Remotely_Sensed_Imagery_With_Survival_Models_for_Outage_Risk_CVPRW_2021_paper.html">Combining Remotely Sensed Imagery With Survival Models for Outage Risk Estimation of the Power Grid</a></th>
                    </tr>
                
                    <tr id="7fe10785dc4adb10c4c7a030758cf9fbb7d5df71">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7fe10785dc4adb10c4c7a030758cf9fbb7d5df71">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LXCV/html/Pereyra_Talking_With_Signs_A_Simple_Method_To_Detect_Nouns_and_CVPRW_2021_paper.html">Talking With Signs: A Simple Method To Detect Nouns and Numbers in a Non-Annotated Signs Language Corpus</a></th>
                    </tr>
                
                    <tr id="9d4f68845cddbfcfd15c1a1e6f08db3d8ad1985e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9d4f68845cddbfcfd15c1a1e6f08db3d8ad1985e">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LXCV/html/Izquierdo-Cordova_Filter_Distribution_Templates_in_Convolutional_Networks_for_Image_Classification_Tasks_CVPRW_2021_paper.html">Filter Distribution Templates in Convolutional Networks for Image Classification Tasks</a></th>
                    </tr>
                
                    <tr id="9ed5ab64449b3b45a5d295bd14db5a22636fe5f4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9ed5ab64449b3b45a5d295bd14db5a22636fe5f4">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EventVision/html/Nunes_Live_Demonstration_Incremental_Motion_Estimation_for_Event-Based_Cameras_by_Dispersion_CVPRW_2021_paper.html">Live Demonstration: Incremental Motion Estimation for Event-Based Cameras by Dispersion Minimisation</a></th>
                    </tr>
                
                    <tr id="8452a9272316efaa58c4660c73ce28c97af1706a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/8452a9272316efaa58c4660c73ce28c97af1706a">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/MULA/html/Dandu_Exploring_the_Limits_of_Zero-Shot_Learning_-_How_Low_Can_CVPRW_2021_paper.html">Exploring the Limits of Zero-Shot Learning - How Low Can You Go?</a></th>
                    </tr>
                
                    <tr id="7628db71c960eca70c571a69edfb795c35b15527">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7628db71c960eca70c571a69edfb795c35b15527">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CiV/html/Zhang_Grounded_Controllable_and_Debiased_Image_Completion_With_Lexical_Semantics_CVPRW_2021_paper.html">Grounded, Controllable and Debiased Image Completion With Lexical Semantics</a></th>
                    </tr>
                
                    <tr id="7edebfb711887f4cf74b17b1f5af6fd468cbf057">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7edebfb711887f4cf74b17b1f5af6fd468cbf057">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DynaVis/html/Bridgeman_Dynamic_Appearance_Modelling_From_Minimal_Cameras_CVPRW_2021_paper.html">Dynamic Appearance Modelling From Minimal Cameras</a></th>
                    </tr>
                
                    <tr id="20a0d6d32433eecb99f83873e0a1d97411510fe4">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/20a0d6d32433eecb99f83873e0a1d97411510fe4">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DynaVis/html/Shibata_Consistent_3D_Human_Shape_From_Repeatable_Action_CVPRW_2021_paper.html">Consistent 3D Human Shape From Repeatable Action</a></th>
                    </tr>
                
                    <tr id="61e6683fd380f7a278d5808b02b2de5f56ae95ab">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/61e6683fd380f7a278d5808b02b2de5f56ae95ab">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Cheng_Perceptual_Image_Compression_Using_Relativistic_Average_Least_Squares_GANs_CVPRW_2021_paper.html">Perceptual Image Compression Using Relativistic Average Least Squares GANs</a></th>
                    </tr>
                
                    <tr id="381534f0772964e7949d0917310a8c52813dcf26">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/381534f0772964e7949d0917310a8c52813dcf26">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Pham_Deep_Learning_Based_Spatial-Temporal_In-Loop_Filtering_for_Versatile_Video_Coding_CVPRW_2021_paper.html">Deep Learning Based Spatial-Temporal In-Loop Filtering for Versatile Video Coding</a></th>
                    </tr>
                
                    <tr id="3fade88cee031ef9d02e735aeb85d7c4b43e3c96">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3fade88cee031ef9d02e735aeb85d7c4b43e3c96">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Suzuki_Learned_Image_Compression_With_Super-Resolution_Residual_Modules_and_DISTS_Optimization_CVPRW_2021_paper.html">Learned Image Compression With Super-Resolution Residual Modules and DISTS Optimization</a></th>
                    </tr>
                
                    <tr id="9f90c8d80bd462e49286c9454fe346b858406ded">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/9f90c8d80bd462e49286c9454fe346b858406ded">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Katakol_DANICE_Domain_Adaptation_Without_Forgetting_in_Neural_Image_Compression_CVPRW_2021_paper.html">DANICE: Domain Adaptation Without Forgetting in Neural Image Compression</a></th>
                    </tr>
                
                    <tr id="83841fae325e8fa0f211c4057329ef0bc13257cc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/83841fae325e8fa0f211c4057329ef0bc13257cc">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLIC/html/Zou_Learned_Video_Compression_With_Intra-Guided_Enhancement_and_Implicit_Motion_Information_CVPRW_2021_paper.html">Learned Video Compression With Intra-Guided Enhancement and Implicit Motion Information</a></th>
                    </tr>
                
                    <tr id="66946e12a37191307291548c18eda21938205dfb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/66946e12a37191307291548c18eda21938205dfb">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Chen_Spot_the_GEO_Satellites_From_Dataset_to_Kelvins_SpotGEO_Challenge_CVPRW_2021_paper.html">Spot the GEO Satellites: From Dataset to Kelvins SpotGEO Challenge</a></th>
                    </tr>
                
                    <tr id="68367f5f770de6ec5962bd3013012d9ce0cad3b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/68367f5f770de6ec5962bd3013012d9ce0cad3b1">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Jonnalagedda_SPACESeg_Automated_Detection_of_Bed_Junction_Morphologies_Indicating_Signs_of_CVPRW_2021_paper.html">SPACESeg: Automated Detection of Bed Junction Morphologies Indicating Signs of Life in Ediacaran Period</a></th>
                    </tr>
                
                    <tr id="dd70aecdec059edf77e93e70722863cb7fc86687">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dd70aecdec059edf77e93e70722863cb7fc86687">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Oestreich_On-Orbit_Inspection_of_an_Unknown_Tumbling_Target_Using_NASAs_Astrobee_CVPRW_2021_paper.html">On-Orbit Inspection of an Unknown, Tumbling Target Using NASA&#39;s Astrobee Robotic Free-Flyers</a></th>
                    </tr>
                
                    <tr id="742cf6bf84e7c761b9b60f700020491d61406069">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/742cf6bf84e7c761b9b60f700020491d61406069">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Thomas_Improving_Astronomy_Image_Quality_Through_Real-Time_Wavefront_Estimation_CVPRW_2021_paper.html">Improving Astronomy Image Quality Through Real-Time Wavefront Estimation</a></th>
                    </tr>
                
                    <tr id="469fa014809ddceb25427aab7b11cfac3add19f7">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/469fa014809ddceb25427aab7b11cfac3add19f7">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Price_A_Monocular_Pose_Estimation_Case_Study_The_Hayabusa2_Minerva-II2_Deployment_CVPRW_2021_paper.html">A Monocular Pose Estimation Case Study: The Hayabusa2 Minerva-II2 Deployment</a></th>
                    </tr>
                
                    <tr id="7613fea67564c13c57d89de106f8cfe3f481c3b1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/7613fea67564c13c57d89de106f8cfe3f481c3b1">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AI4Space/html/Dor_Visual_SLAM_for_Asteroid_Relative_Navigation_CVPRW_2021_paper.html">Visual SLAM for Asteroid Relative Navigation</a></th>
                    </tr>
                
                    <tr id="b875ff12bb8ca9a680a5d122d10e89175117ada1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/b875ff12bb8ca9a680a5d122d10e89175117ada1">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Rai_Weak_Multi-View_Supervision_for_Surface_Mapping_Estimation_CVPRW_2021_paper.html">Weak Multi-View Supervision for Surface Mapping Estimation</a></th>
                    </tr>
                
                    <tr id="74784d758960f07bd6ef9131585f262970450f34">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/74784d758960f07bd6ef9131585f262970450f34">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Rakesh_Efficacy_of_Bayesian_Neural_Networks_in_Active_Learning_CVPRW_2021_paper.html">Efficacy of Bayesian Neural Networks in Active Learning</a></th>
                    </tr>
                
                    <tr id="6c8a4f2baa5dece4448ce1ecea8e98b582f497b3">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/6c8a4f2baa5dece4448ce1ecea8e98b582f497b3">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Bernal_Training_Deep_Generative_Models_in_Highly_Incomplete_Data_Scenarios_With_CVPRW_2021_paper.html">Training Deep Generative Models in Highly Incomplete Data Scenarios With Prior Regularization</a></th>
                    </tr>
                
                    <tr id="f23274d20128b7713473e391e801a8587cfdcbef">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f23274d20128b7713473e391e801a8587cfdcbef">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/LLID/html/Pang_Unlocking_the_Full_Potential_of_Small_Data_With_Diverse_Supervision_CVPRW_2021_paper.html">Unlocking the Full Potential of Small Data With Diverse Supervision</a></th>
                    </tr>
                
                    <tr id="e9c50ef681d30a465103fd194274a61a60c85c85">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/e9c50ef681d30a465103fd194274a61a60c85c85">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AgriVision/html/Jensen_Determining_Dendrometry_Using_Drone_Scouting_Convolutional_Neural_Networks_and_Point_CVPRW_2021_paper.html">Determining Dendrometry Using Drone Scouting, Convolutional Neural Networks and Point Clouds</a></th>
                    </tr>
                
                    <tr id="3d362efcea2d6fbf9cea6b8e301bc68a739433e9">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3d362efcea2d6fbf9cea6b8e301bc68a739433e9">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Hong_Network_Space_Search_for_Pareto-Efficient_Spaces_CVPRW_2021_paper.html">Network Space Search for Pareto-Efficient Spaces</a></th>
                    </tr>
                
                    <tr id="3ef43365fa71574604bf3872a53505e3bbdcb391">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/3ef43365fa71574604bf3872a53505e3bbdcb391">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/ECV/html/Lin_Efficient_Two-Stream_Action_Recognition_on_FPGA_CVPRW_2021_paper.html">Efficient Two-Stream Action Recognition on FPGA</a></th>
                    </tr>
                
                    <tr id="f857e5e4312587a7cef23adc4b67bb0bf0ba0103">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f857e5e4312587a7cef23adc4b67bb0bf0ba0103">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/EVW/html/Lin_Phase_Selective_Convolution_CVPRW_2021_paper.html">Phase Selective Convolution</a></th>
                    </tr>
                
                    <tr id="aec6666166dd24992bfa27ee13450ddd52bb4b41">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/aec6666166dd24992bfa27ee13450ddd52bb4b41">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CLVision/html/Kuo_Plastic_and_Stable_Gated_Classifiers_for_Continual_Learning_CVPRW_2021_paper.html">Plastic and Stable Gated Classifiers for Continual Learning</a></th>
                    </tr>
                
                    <tr id="534d13141dac4ff43bb8f2d0018d57fac76449c2">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/534d13141dac4ff43bb8f2d0018d57fac76449c2">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/OmniCV/html/Kato_Detecting_Low-Rank_Regions_in_Omnidirectional_Images_CVPRW_2021_paper.html">Detecting Low-Rank Regions in Omnidirectional Images</a></th>
                    </tr>
                
                    <tr id="dd26d2464df7274728ab0cf5217b11f390c0803b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/dd26d2464df7274728ab0cf5217b11f390c0803b">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVMI/html/Simon_Quantifying_Variability_in_Microscopy_Image_Analyses_for_COVID-19_Drug_Discovery_CVPRW_2021_paper.html">Quantifying Variability in Microscopy Image Analyses for COVID-19 Drug Discovery</a></th>
                    </tr>
                
                    <tr id="afcfe1f786039bb78997ab33c51dbabb3a6fb1c6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/afcfe1f786039bb78997ab33c51dbabb3a6fb1c6">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVPM/html/Takahashi_Oxygen_Saturation_Estimation_Based_on_Optimal_Band_Selection_From_Multi-Band_CVPRW_2021_paper.html">Oxygen Saturation Estimation Based on Optimal Band Selection From Multi-Band Video</a></th>
                    </tr>
                
                    <tr id="5c36ecc9b63f04a172775e67513731e3f72ddf0e">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/5c36ecc9b63f04a172775e67513731e3f72ddf0e">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Horiuchi_Differentiable_Rendering-Based_Pose-Conditioned_Human_Image_Generation_CVPRW_2021_paper.html">Differentiable Rendering-Based Pose-Conditioned Human Image Generation</a></th>
                    </tr>
                
                    <tr id="fdc03eab22a8d974b37480516817e864f1078f8b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/fdc03eab22a8d974b37480516817e864f1078f8b">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVFAD/html/Agrawal_Color_Me_Good_Branding_in_the_Coloring_Style_of_Movie_CVPRW_2021_paper.html">Color Me Good: Branding in the Coloring Style of Movie Posters</a></th>
                    </tr>
                
                    <tr id="70465543573b18cd61ad9ccc063d55a02c503175">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/70465543573b18cd61ad9ccc063d55a02c503175">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Scribano_All_You_Can_Embed_Natural_Language_Based_Vehicle_Retrieval_With_CVPRW_2021_paper.html">All You Can Embed: Natural Language Based Vehicle Retrieval With Spatio-Temporal Transformers</a></th>
                    </tr>
                
                    <tr id="cc6ef7204904adfc6964f46c4fddbb816dbd60f6">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/cc6ef7204904adfc6964f46c4fddbb816dbd60f6">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/AICity/html/Li_Multi-Camera_Tracking_by_Candidate_Intersection_Ratio_Tracklet_Matching_CVPRW_2021_paper.html">Multi-Camera Tracking by Candidate Intersection Ratio Tracklet Matching</a></th>
                    </tr>
                
                    <tr id="62ada0a8d16c6c989f9de8fafece3ba36978eb8a">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/62ada0a8d16c6c989f9de8fafece3ba36978eb8a">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/PBVS/html/Hu_Quad-DIP_for_X-Ray_Cargo_Image_Decomposition_CVPRW_2021_paper.html">Quad-DIP for X-Ray Cargo Image Decomposition</a></th>
                    </tr>
                
                    <tr id="0cd2889f6830202f8d61236ed020187ae553d458">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/0cd2889f6830202f8d61236ed020187ae553d458">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/PBVS/html/Gao_Generalized_Unsupervised_Clustering_of_Hyperspectral_Images_of_Geological_Targets_in_CVPRW_2021_paper.html">Generalized Unsupervised Clustering of Hyperspectral Images of Geological Targets in the Near Infrared</a></th>
                    </tr>
                
                    <tr id="a78014498ff39a36cc1abaf7358eb0212d7e50cb">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a78014498ff39a36cc1abaf7358eb0212d7e50cb">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DiffCVML/html/Friedlander_Uniting_Stereo_and_Depth-From-Defocus_A_Thin_Lens-Based_Variational_Framework_for_CVPRW_2021_paper.html">Uniting Stereo and Depth-From-Defocus: A Thin Lens-Based Variational Framework for Multiview Reconstruction</a></th>
                    </tr>
                
                    <tr id="1bd3eeab5103cd22bfe9f11c8952c5ef1f0bc8be">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1bd3eeab5103cd22bfe9f11c8952c5ef1f0bc8be">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DiffCVML/html/Matuk_Geometric_Empirical_Bayesian_Model_for_Classification_of_Functional_Data_Under_CVPRW_2021_paper.html">Geometric Empirical Bayesian Model for Classification of Functional Data Under Diverse Sampling Regimes</a></th>
                    </tr>
                
                    <tr id="91c2c0c26f2ebd115e2ac0df67b64c1a6acfddcc">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/91c2c0c26f2ebd115e2ac0df67b64c1a6acfddcc">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DiffCVML/html/Nagananda_GILDA_Grassmann_Incremental_Linear_Discriminant_Analysis_CVPRW_2021_paper.html">GILDA++: Grassmann Incremental Linear Discriminant Analysis</a></th>
                    </tr>
                
                    <tr id="a34315a8367693528ece708ef85f608ff850bbf1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/a34315a8367693528ece708ef85f608ff850bbf1">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DiffCVML/html/Braunsmann_Learning_Low_Bending_and_Low_Distortion_Manifold_Embeddings_CVPRW_2021_paper.html">Learning Low Bending and Low Distortion Manifold Embeddings</a></th>
                    </tr>
                
                    <tr id="f3435d0c0470ba3aa8e96c7fc143511121e92897">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/f3435d0c0470ba3aa8e96c7fc143511121e92897">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/DiffCVML/html/Hu_A_Sheaf_and_Topology_Approach_to_Detecting_Local_Merging_Relations_CVPRW_2021_paper.html">A Sheaf and Topology Approach to Detecting Local Merging Relations in Digital Images</a></th>
                    </tr>
                
                    <tr id="1a43c7717848791d17af7d88b6e2fb8b90c52c4b">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/1a43c7717848791d17af7d88b6e2fb8b90c52c4b">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/Rahimi_Toward_Improving_the_Visual_Characterization_of_Sport_Activities_With_Abstracted_CVPRW_2021_paper.html">Toward Improving the Visual Characterization of Sport Activities With Abstracted Scene Graphs</a></th>
                    </tr>
                
                    <tr id="69cfd5fad62bf4af13e11a5d1cdb8e199330f3f1">
                        <td class="align-middle text-right"><a
                                href="https://semanticscholar.org/paper/69cfd5fad62bf4af13e11a5d1cdb8e199330f3f1">0</a>
                        </td>
                        <td class="align-middle text-center">WORKSHOP</td>
                        <th scope="row" class="align-middle text-left font-weight-normal"><a
                                href="https://openaccess.thecvf.com/content/CVPR2021W/CVSports/html/Pidaparthy_Automatic_Play_Segmentation_of_Hockey_Videos_CVPRW_2021_paper.html">Automatic Play Segmentation of Hockey Videos</a></th>
                    </tr>
                

                </tbody>
            </table>
        </div>
    </section>

</main>

<script src="https://cdn.jsdelivr.net/npm/jquery@3.5.1/dist/jquery.slim.min.js"
        integrity="sha384-DfXdz2htPH0lsSSs5nCTpuj/zy4C+OGpamoFVy38MVBnE+IbbVYUew+OrCXaRkfj"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/popper.js@1.16.1/dist/umd/popper.min.js"
        integrity="sha384-9/reFTGAW83EW2RDu2S0VKaIzap3H66lZH81PoYlFhbGU+6BZp6G7niu735Sk7lN"
        crossorigin="anonymous"></script>
<script src="https://cdn.jsdelivr.net/npm/bootstrap@4.6.2/dist/js/bootstrap.min.js"
        integrity="sha384-+sLIOodYLS7CIrQpBjl+C7nPvqq+FbNUBDunl/OZv93DB7Ln/533i8e/mZXLi/P+"
        crossorigin="anonymous"></script>

</body>
</html>
