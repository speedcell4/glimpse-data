{
  "https://jmlr.org/papers/v21/16-494.html": {
    "title": "A Low Complexity Algorithm with O(âT) Regret and O(1) Constraint Violations for Online Convex Optimization with Long Term Constraints",
    "abstract": "This paper considers online convex optimization over a complicated constraint set, which typically consists of multiple functional constraints and a set constraint.  The conventional online projection algorithm (Zinkevich, 2003) can be difficult to implement due to the potentially high computation complexity of the projection operation. In this paper, we relax the functional constraints by allowing them to be violated at each round but still requiring them to be satisfied in the long term. This type of relaxed online convex optimization (with long term constraints) was first considered in Mahdavi et al. (2012). That prior work proposes an algorithm to achieve $O(\\sqrt{T})$ regret and $O(T^{3/4})$ constraint violations for general problems and another algorithm to achieve an $O(T^{2/3})$ bound for both regret and constraint violations when the constraint set can be described by a finite number of linear constraints.  A recent extension in Jenatton et al. (2016) can achieve $O(T^{\\max\\{\\theta,1-\\theta\\}})$ regret and $O(T^{1-\\theta/2})$ constraint violations where $\\theta\\in (0,1)$. The current paper proposes a new simple algorithm that yields improved performance in comparison to prior works. The new algorithm achieves an $O(\\sqrt{T})$ regret bound with $O(1)$ constraint violations",
    "volume": "main",
    "checked": false,
    "id": "0b47bd8468a12bb491a399abbbac1a0d8d4eec19",
    "citation_count": 50
  },
  "https://jmlr.org/papers/v21/17-068.html": {
    "title": "A Statistical Learning Approach to Modal Regression",
    "abstract": "This paper studies the nonparametric modal regression problem systematically from a statistical learning viewpoint.  Originally motivated by pursuing a theoretical understanding of the maximum correntropy criterion based regression (MCCR), our study reveals that MCCR with a tending-to-zero scale parameter is essentially modal regression. We show that the nonparametric modal regression problem can be approached via the classical empirical risk minimization. Some efforts are then made to develop a framework for analyzing and implementing modal regression. For instance, the modal regression function is described, the modal regression risk is defined explicitly and its Bayes rule is characterized; for the sake of computational tractability, the surrogate modal regression risk, which is termed as the generalization risk in our study, is introduced. On the theoretical side, the excess modal regression risk, the excess generalization risk, the function estimation error, and the relations among the above three quantities are studied rigorously. It turns out that under mild conditions, function estimation consistency and convergence may be pursued in modal regression as in vanilla regression protocols such as mean regression, median regression, and quantile regression. On the practical side, the implementation issues of modal regression including the computational algorithm and the selection of the tuning parameters are discussed. Numerical validations on modal regression are also conducted to verify our findings",
    "volume": "main",
    "checked": true,
    "id": "d67c4f835778c6be1a344dd77faff3713ff33529",
    "citation_count": 54
  },
  "https://jmlr.org/papers/v21/17-360.html": {
    "title": "A Model of Fake Data in Data-driven Analysis",
    "abstract": "Data-driven analysis has been increasingly used in various decision making processes. With more sources, including reviews, news, and pictures, can now be used for data analysis, the authenticity of data sources is in doubt. While previous literature attempted to detect fake data piece by piece, in the current work, we try to capture the fake data sender's strategic behavior to detect the fake data source. Specifically, we model the tension between a data receiver who makes data-driven decisions and a fake data sender who benefits from misleading the receiver. We propose a potentially infinite horizon continuous time game-theoretic model with asymmetric information to capture the fact that the receiver does not initially know the existence of fake data and learns about it during the course of the game. We use point processes to model the data traffic, where each piece of data can occur at any discrete moment in a continuous time flow. We fully solve the model and employ numerical examples to illustrate the players' strategies and payoffs for insights. Specifically, our results show that maintaining some suspicion about the data sources and understanding that the sender can be strategic are very helpful to the data receiver. In addition, based on our model, we propose a methodology of detecting fake data that is complementary to the previous studies on this topic, which suggested various approaches on analyzing the data piece by piece. We show that after analyzing each piece of data, understanding a source by looking at the its whole history of pushing data can be helpful",
    "volume": "main",
    "checked": true,
    "id": "7e062e6f99a4086f8e4eb4ce4c2358138743eb8f",
    "citation_count": 1
  },
  "https://jmlr.org/papers/v21/17-470.html": {
    "title": "Universal Latent Space Model Fitting for Large Networks with Edge Covariates",
    "abstract": "Latent space models are effective tools for statistical modeling and visualization of network data. Due to their close connection to generalized linear models, it is also natural to incorporate covariate information in them. The current paper presents two universal fitting algorithms for networks with edge covariates: one based on nuclear norm penalization and the other based on projected gradient descent. Both algorithms are motivated by maximizing the likelihood function for an existing class of inner-product models, and we establish their statistical rates of convergence for these models. In addition, the theory informs us that both methods work simultaneously for a wide range of different latent space models that allow latent positions to affect edge formation in flexible ways, such as distance models. Furthermore, the effectiveness of the methods is demonstrated on a number of real world network data sets for different statistical tasks, including community detection with and without edge covariates, and network assisted learning",
    "volume": "main",
    "checked": true,
    "id": "b1876e54a975657db97155e0599e152e4290aad5",
    "citation_count": 44
  },
  "https://jmlr.org/papers/v21/19-771.html": {
    "title": "Lower Bounds for Parallel and Randomized Convex Optimization",
    "abstract": "We study the question of whether parallelization in the exploration of the feasible set can be used to speed up convex optimization, in the local oracle model of computation and in the high-dimensional regime. We show that the answer is negative for both deterministic and randomized algorithms applied to essentially any of the interesting geometries and nonsmooth, weakly-smooth, or smooth objective functions. In particular, we show that it is not possible to obtain a polylogarithmic (in the sequential complexity of the problem) number of parallel rounds  with a polynomial (in the dimension) number of queries per round. In the majority of these settings and when the dimension of the space is polynomial in the inverse target accuracy, our lower bounds match the oracle complexity of sequential convex optimization, up to at most a logarithmic factor in the dimension, which makes them (nearly) tight. Another conceptual contribution of our work is in providing a general and streamlined framework for proving lower bounds in the setting of parallel convex optimization. Prior to our work, lower bounds for parallel convex optimization algorithms were only known in a small fraction of the settings considered in this paper, mainly applying to Euclidean ($\\ell_2$) and $\\ell_\\infty$ spaces",
    "volume": "main",
    "checked": true,
    "id": "dbcec08a76c017a9b55e3a8324595129cc7e7015",
    "citation_count": 36
  },
  "https://jmlr.org/papers/v21/18-085.html": {
    "title": "Path-Based Spectral Clustering: Guarantees, Robustness to Outliers, and Fast Algorithms",
    "abstract": "We consider the problem of clustering with the longest-leg path distance (LLPD) metric, which is informative for elongated and irregularly shaped clusters. We prove finite-sample guarantees on the performance of clustering with respect to this metric when random samples are drawn from multiple intrinsically low-dimensional clusters in high-dimensional space, in the presence of a large number of high-dimensional outliers.  By combining these results with spectral clustering with respect to LLPD, we provide conditions under which the Laplacian eigengap statistic correctly determines the number of clusters for a large class of data sets,  and prove guarantees on the labeling accuracy of the proposed algorithm.  Our methods are quite general and provide performance guarantees for spectral clustering with any ultrametric.  We also introduce an efficient, easy to implement approximation algorithm for the LLPD based on a multiscale analysis of adjacency graphs, which allows for the runtime of LLPD spectral clustering to be quasilinear in the number of data points",
    "volume": "main",
    "checked": true,
    "id": "f0fd5f56b19f3aeef0599b2b8b1a2ad8c5d67092",
    "citation_count": 33
  },
  "https://jmlr.org/papers/v21/18-141.html": {
    "title": "Target Propagation in Recurrent Neural Networks",
    "abstract": "Recurrent Neural Networks have been widely used to process sequence data, but have long been criticized for their biological implausibility and training difficulties related to vanishing and exploding gradients. This paper presents a novel algorithm for training recurrent networks, target propagation through time (TPTT), that outperforms standard backpropagation through time (BPTT) on four out of the five problems used for testing. The proposed algorithm is initially tested and compared to BPTT on four synthetic time lag tasks, and its performance is also measured using the sequential MNIST data set. In addition, as TPTT uses target propagation, it allows for discrete nonlinearities and could potentially mitigate the credit assignment problem in more complex recurrent architectures",
    "volume": "main",
    "checked": true,
    "id": "f09a0b37d1b3ee75791b38d38e1d94496d22415e",
    "citation_count": 29
  },
  "https://jmlr.org/papers/v21/18-144.html": {
    "title": "DESlib: A Dynamic ensemble selection library in Python",
    "abstract": "DESlib is an open-source python library providing the implementation of several dynamic selection techniques. The library is divided into three modules: (i) dcs, containing the implementation of dynamic classifier selection methods (DCS); (ii) des, containing the implementation of dynamic ensemble selection methods (DES); (iii) static, with the implementation of static ensemble techniques. The library is fully documented (documentation available online on Read the Docs), has a high test coverage (codecov.io) and is part of the scikit-learn-contrib supported projects. Documentation, code and examples can be found on its GitHub page: https://github.com/scikit-learn-contrib/DESlib",
    "volume": "main",
    "checked": true,
    "id": "16e66b38d8089739d3383feaee0619975759c1b5",
    "citation_count": 57
  },
  "https://jmlr.org/papers/v21/18-156.html": {
    "title": "On Mahalanobis Distance in Functional Settings",
    "abstract": "Mahalanobis distance is a classical tool in multivariate analysis. We suggest here an extension of this concept to the case of functional data. More precisely, the proposed definition concerns those statistical problems where the sample data are real functions defined on a compact interval of the real line. The obvious difficulty for such a functional extension is the non-invertibility of the covariance operator in infinite-dimensional cases. Unlike other recent proposals, our definition is suggested and motivated in terms of the Reproducing Kernel Hilbert Space (RKHS) associated with the stochastic process that generates the data. The proposed distance is a true metric; it depends on a unique real smoothing parameter which is fully motivated in RKHS terms. Moreover, it shares some properties of its finite dimensional counterpart: it is invariant under isometries, it can be consistently estimated from the data and its sampling distribution is known under Gaussian models. An empirical study for two statistical applications, outliers detection and binary classification, is included. The results are quite competitive when compared to other recent proposals in the literature",
    "volume": "main",
    "checked": true,
    "id": "37430ac3a2d3c0f6d15a0017cd6cace25ab9948e",
    "citation_count": 14
  },
  "https://jmlr.org/papers/v21/18-567.html": {
    "title": "Online Sufficient Dimension Reduction Through Sliced Inverse Regression",
    "abstract": "Sliced inverse regression is an effective paradigm that achieves the goal of dimension reduction through replacing  high dimensional covariates with a small number of linear combinations. It does not impose  parametric assumptions on the dependence structure. More importantly, such a reduction of dimension  is sufficient in that it  does  not cause  loss of  information. In this paper, we adapt the stationary sliced inverse regression to cope with the rapidly  changing environments. We propose to implement sliced inverse regression in an online fashion. This online  learner consists of two steps. In the first step we construct an online estimate for the  kernel matrix; in the second step we propose two online algorithms, one is motivated by the perturbation method and the other is originated from the gradient descent optimization, to perform   online singular value decomposition. The  theoretical properties of this   online learner are established. We demonstrate the numerical performance of  this  online learner  through simulations and  real world applications. All numerical studies confirm that this  online learner  performs as well as the batch learner",
    "volume": "main",
    "checked": true,
    "id": "d0cf6aebb741dd59bb17b51b632c41d63b1f5fea",
    "citation_count": 22
  },
  "https://jmlr.org/papers/v21/18-573.html": {
    "title": "Weighted Message Passing and Minimum Energy Flow for Heterogeneous Stochastic Block Models with Side Information",
    "abstract": "We study the misclassification error for community detection in general heterogeneous stochastic block models (SBM) with noisy or partial label information. We establish a connection between the misclassification rate and the notion of minimum energy on the local neighborhood of the SBM. We develop an optimally weighted message passing algorithm to reconstruct labels for SBM based on the minimum energy flow and the eigenvectors of a certain Markov transition matrix. The general SBM considered in this paper allows for unequal-size communities, degree heterogeneity, and different connection probabilities among blocks. We focus on how to optimally weigh the message passing to improve misclassification",
    "volume": "main",
    "checked": true,
    "id": "bd5afbfcdea88ecaa4c06567b19803f3493c310e",
    "citation_count": 8
  },
  "https://jmlr.org/papers/v21/18-577.html": {
    "title": "Neyman-Pearson classification: parametrics and sample size requirement",
    "abstract": "The Neyman-Pearson (NP) paradigm in binary classification seeks classifiers that achieve a minimal type II error while enforcing the prioritized type I error controlled under some user-specified level $\\alpha$. This paradigm serves naturally in applications such as severe disease diagnosis and spam detection, where people have clear priorities among the two error types. Recently, Tong, Feng, and Li (2018) proposed a nonparametric umbrella algorithm that adapts all scoring-type classification methods (e.g., logistic regression, support vector machines, random forest) to respect the given type I error (i.e., conditional probability of classifying a class $0$ observation as class $1$ under the 0-1 coding) upper bound $\\alpha$ with high probability, without specific  distributional assumptions on the features and the responses. Universal the umbrella algorithm is, it demands an explicit minimum sample size requirement on class $0$, which is often the more scarce class, such as in rare disease diagnosis applications. In this work, we employ the parametric linear discriminant analysis (LDA) model and propose a new parametric thresholding algorithm, which does not need the minimum sample size requirements on class $0$ observations and thus is suitable for small sample applications such as rare disease diagnosis. Leveraging both the existing nonparametric and the newly proposed parametric thresholding rules, we propose four LDA-based NP classifiers, for both low- and high-dimensional settings. On the theoretical front, we prove NP oracle inequalities for one proposed classifier, where the rate for excess type II error benefits from the explicit parametric model assumption. Furthermore, as NP classifiers involve a sample splitting step of class $0$ observations,  we construct a new adaptive sample splitting scheme that can be applied universally to NP classifiers, and this adaptive strategy reduces the type II error of these classifiers. The proposed NP classifiers are implemented in the R package nproc",
    "volume": "main",
    "checked": true,
    "id": "88573a83f13c832c0c77205b5e7302f9cdc57d80",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v21/18-595.html": {
    "title": "Generalized probabilistic principal component analysis of correlated data",
    "abstract": "Principal component analysis (PCA) is a well-established tool in machine learning and data processing. The principal axes in PCA were shown to be equivalent to the maximum marginal likelihood estimator of the factor loading matrix in a latent factor model for the observed data, assuming that the latent factors are independently distributed as standard normal distributions. However, the independence assumption may be unrealistic for many scenarios such as modeling multiple time series, spatial processes, and functional data, where the outcomes are correlated.  In this paper, we introduce the generalized probabilistic principal component analysis (GPPCA) to study the latent factor model for multiple correlated outcomes, where each factor is modeled by a Gaussian process. Our method generalizes the previous probabilistic formulation of PCA (PPCA)  by providing the closed-form maximum marginal likelihood estimator of the factor loadings and other parameters.  Based on the explicit expression of the precision matrix in the marginal likelihood that we derived, the number of the computational operations is linear to the number of output variables. Furthermore, we also provide the closed-form expression of the marginal likelihood when   other covariates are included in the mean structure. We highlight the advantage of GPPCA in terms of the practical relevance, estimation accuracy and computational convenience.  Numerical studies of simulated and real data confirm the excellent finite-sample performance of the proposed approach",
    "volume": "main",
    "checked": true,
    "id": "cb724ed0bf1b07b8de004e3772dc6051de0bb24f",
    "citation_count": 17
  },
  "https://jmlr.org/papers/v21/18-601.html": {
    "title": "On lp-Support Vector Machines and Multidimensional Kernels",
    "abstract": "In this paper, we extend the  methodology developed for Support Vector Machines (SVM) using the $\\ell_2$-norm  ($\\ell_2$-SVM)  to the more general case of  $\\ell_p$-norms with $p>1$ ($\\ell_p$-SVM).  We derive second order cone formulations for the resulting dual and primal problems.  The concept of kernel function, widely applied in $\\ell_2$-SVM,  is extended to the more general case of $\\ell_p$-norms with $p>1$ by defining a new operator called multidimensional kernel. This object gives rise to reformulations of dual problems, in a transformed space of the original data, where the dependence on the original data always appear as homogeneous polynomials. We adapt known solution algorithms to efficiently solve the primal and dual resulting problems and some computational experiments on real-world datasets are presented showing rather good behavior in terms of the accuracy of $\\ell_p$-SVM with $p>1$",
    "volume": "main",
    "checked": true,
    "id": "0ab5cd765f0ad37508c8f76ac048b7c3dba6a84f",
    "citation_count": 21
  },
  "https://jmlr.org/papers/v21/18-720.html": {
    "title": "Perturbation Bounds for Procrustes, Classical Scaling, and Trilateration, with Applications to Manifold Learning",
    "abstract": "One of the common tasks in unsupervised learning is dimensionality reduction, where the goal is to find meaningful low-dimensional structures hidden in high-dimensional data.  Sometimes referred to as manifold learning, this problem is closely related to the problem of localization, which aims at embedding a weighted graph into a low-dimensional Euclidean space.  Several methods have been proposed for localization, and also manifold learning. Nonetheless, the robustness property of most of them is little understood. In this paper, we obtain perturbation bounds for classical scaling and trilateration, which are then applied to derive performance bounds for Isomap, Landmark Isomap, and Maximum Variance Unfolding.  A new perturbation bound for procrustes analysis plays a key role",
    "volume": "main",
    "checked": true,
    "id": "bfcfeb8cd20bb8f16348c02c67f03be5d4bb125c",
    "citation_count": 14
  },
  "https://jmlr.org/papers/v21/18-786.html": {
    "title": "Practical Locally Private Heavy Hitters",
    "abstract": "We present new practical local differentially private heavy hitters algorithms achieving optimal or near-optimal worst-case error and running time -- TreeHist and Bitstogram. In both algorithms, server running time is $\\tilde O(n)$ and user running time is $\\tilde O(1)$, hence improving on the prior state-of-the-art result of Bassily and Smith [STOC 2015] requiring $O(n^{5/2})$ server time and $O(n^{3/2})$ user time. With a typically large number of participants in local algorithms (in the millions), this reduction in time complexity, in particular at the user side, is crucial for making locally private heavy hitters algorithms usable in practice. We implemented Algorithm TreeHist to verify our theoretical analysis and compared its performance with the performance of Google's RAPPOR code",
    "volume": "main",
    "checked": true,
    "id": "f7d1647c6097a9dd00a6ca9d02c9c38121771133",
    "citation_count": 228
  },
  "https://jmlr.org/papers/v21/18-817.html": {
    "title": "Expectation Propagation as a Way of Life: A Framework for Bayesian Inference on Partitioned Data",
    "abstract": "A common divide-and-conquer approach for Bayesian computation with big data is to partition the data, perform local inference for each piece separately, and combine the results to obtain a global posterior approximation. While being conceptually and computationally appealing, this method involves the problematic need to also split the prior for the local inferences; these weakened priors may not provide enough regularization for each separate computation, thus eliminating one of the key advantages of Bayesian methods. To resolve this dilemma while still retaining the generalizability of the underlying local inference method, we apply the idea of expectation propagation (EP) as a framework for distributed Bayesian inference. The central idea is to iteratively update approximations to the local likelihoods given the state of the other approximations and the prior. The present paper has two roles: we review the steps that are needed to keep EP algorithms numerically stable, and we suggest a general approach, inspired by EP, for approaching data partitioning problems in a way that achieves the computational benefits of parallelism while allowing each local update to make use of relevant information from the other sites. In addition, we demonstrate how the method can be applied in a hierarchical context to make use of partitioning of both data and parameters. The paper describes a general algorithmic framework, rather than a specific algorithm, and presents an example implementation for it",
    "volume": "main",
    "checked": true,
    "id": "d5194566644c0ee6b09225caa409b1f73109029a",
    "citation_count": 72
  },
  "https://jmlr.org/papers/v21/18-850.html": {
    "title": "Connecting Spectral Clustering to Maximum Margins and Level Sets",
    "abstract": "We study the connections between spectral clustering and the problems of maximum margin clustering, and estimation of the components of level sets of a density function. Specifically, we obtain bounds on the eigenvectors of graph Laplacian matrices in terms of the between cluster separation, and within cluster connectivity. These bounds ensure that the spectral clustering solution converges to the maximum margin clustering solution as the scaling parameter is reduced towards zero. The sensitivity of maximum margin clustering solutions to outlying points is well known, but can be mitigated by first removing such outliers, and applying maximum margin clustering to the remaining points. If outliers are identified using an estimate of the underlying probability density, then the remaining points may be seen as an estimate of a level set of this density function. We show that such an approach can be used to consistently estimate the components of the level sets of a density function under very mild assumptions",
    "volume": "main",
    "checked": true,
    "id": "3a176fdd847164c2ae1460195b7a7aeb57647064",
    "citation_count": 0
  },
  "https://jmlr.org/papers/v21/19-071.html": {
    "title": "High-Dimensional Interactions Detection with Sparse Principal Hessian Matrix",
    "abstract": "In statistical learning framework with regressions, interactions are the contributions to the response variable from the products of the explanatory variables. In high-dimensional problems, detecting interactions is challenging due to  combinatorial complexity and limited data information. We consider detecting interactions by exploring their connections with the principal Hessian matrix. Specifically, we propose a one-step synthetic approach for estimating the principal Hessian matrix by a penalized M-estimator. An alternating direction method of multipliers (ADMM) is proposed to efficiently solve the encountered regularized optimization problem. Based on the sparse estimator, we  detect the interactions by identifying its nonzero components. Our method directly targets at the interactions, and it requires no structural assumption on the hierarchy of the interactions effects.  We show that our estimator is theoretically valid, computationally efficient, and practically useful for detecting the interactions in a broad spectrum of scenarios",
    "volume": "main",
    "checked": true,
    "id": "5de4f0c9ec7916367db94953c4da08209e67a2db",
    "citation_count": 8
  },
  "https://jmlr.org/papers/v21/19-083.html": {
    "title": "Convergences of Regularized Algorithms and Stochastic Gradient Methods with Random Projections",
    "abstract": "We study the least-squares regression problem over a Hilbert space, covering nonparametric regression over a reproducing kernel Hilbert space as a special case.  We first investigate regularized algorithms adapted to a projection operator on a closed subspace of the Hilbert space. We prove convergence results with respect to variants of norms, under a capacity assumption on the hypothesis space and a regularity condition on the target function.  As a result, we obtain optimal rates for regularized algorithms with randomized sketches, provided that the sketch dimension is proportional to the effective dimension up to a logarithmic factor. As a byproduct, we obtain similar results for Nystr\\\"{o}m regularized algorithms.  Our results provide optimal, distribution-dependent rates that do not have any saturation effect for sketched/Nystr\\\"{o}m regularized algorithms, considering both the attainable and non-attainable cases, in the well-conditioned regimes. We then study stochastic gradient methods with projection over the subspace, allowing multi-pass over the data and minibatches, and we derive similar optimal statistical convergence results",
    "volume": "main",
    "checked": true,
    "id": "cc487263bda8d13e75219c3b3df6a65ed2a83f1b",
    "citation_count": 6
  },
  "https://jmlr.org/papers/v21/19-198.html": {
    "title": "Derivative-Free Methods for Policy Optimization: Guarantees for Linear Quadratic Systems",
    "abstract": "We study derivative-free methods for policy optimization over the class of linear policies. We focus on characterizing the convergence rate of these methods when applied to linear-quadratic systems, and study various settings of driving noise and reward feedback.  Our main theoretical result provides an explicit bound on the sample or evaluation complexity: we show that these methods are guaranteed to converge to within any pre-specified tolerance of the optimal policy with a number of zero-order evaluations that is an explicit polynomial of the error tolerance, dimension, and curvature properties of the problem.  Our analysis reveals some interesting differences between the settings of additive driving noise and random initialization, as well as the settings of one-point and two-point reward feedback. Our theory is corroborated by simulations of derivative-free methods in application to these systems. Along the way, we derive convergence rates for stochastic zero-order optimization algorithms when applied to a certain class of non-convex problems",
    "volume": "main",
    "checked": true,
    "id": "df5e2f089288934b51d72d2308d0a83444e46f16",
    "citation_count": 148
  },
  "https://jmlr.org/papers/v21/19-276.html": {
    "title": "A Unified Framework for Structured Graph Learning via Spectral Constraints",
    "abstract": "Graph learning from data is a canonical problem that has received substantial attention in the literature. Learning a structured graph is essential for interpretability and identification of the relationships among data. In general, learning a graph with a specific structure is an NP-hard combinatorial problem and thus designing a general tractable algorithm is challenging. Some useful structured graphs include connected, sparse, multi-component, bipartite, and regular graphs. In this paper, we introduce a unified framework for structured graph learning that combines Gaussian graphical model and spectral graph theory. We propose to convert combinatorial structural constraints into spectral constraints on graph matrices and develop an optimization framework based on block majorization-minimization to solve structured graph learning problem. The proposed algorithms are provably convergent and practically amenable for a number of graph based applications such as data clustering. Extensive numerical experiments with both synthetic and real data sets illustrate the effectiveness of the proposed algorithms. An open source R package containing the code for all the experiments is available at https://CRAN.R-project.org/package=spectralGraphTopology",
    "volume": "main",
    "checked": true,
    "id": "634c0c19690e136a727fb5bb820912ac6e5e37c0",
    "citation_count": 70
  },
  "https://jmlr.org/papers/v21/19-429.html": {
    "title": "GluonCV and GluonNLP: Deep Learning in Computer Vision and Natural Language Processing",
    "abstract": "We present GluonCV and GluonNLP, the deep learning toolkits for computer vision and natural language processing based on Apache MXNet (incubating). These toolkits provide state-of-the-art pre-trained models, training scripts, and training logs, to facilitate rapid prototyping and promote reproducible research. We also provide modular APIs with flexible building blocks to enable efficient customization. Leveraging the MXNet ecosystem, the deep learning models in GluonCV and GluonNLP can be deployed onto a variety of platforms with different programming languages. The Apache 2.0 license has been adopted by GluonCV and GluonNLP to allow for software distribution, modification, and usage",
    "volume": "main",
    "checked": true,
    "id": "2733574d40ce8e861d7d658bfc33ab36f529864d",
    "citation_count": 148
  },
  "https://jmlr.org/papers/v21/19-537.html": {
    "title": "Distributed Feature Screening via Componentwise Debiasing",
    "abstract": "Feature screening is a powerful tool in processing high-dimensional data. When the sample size N and the number of features p are both large, the implementation of classic screening methods can be numerically challenging. In this paper, we propose a distributed screening framework for big data setup. In the spirit of 'divide-and-conquer', the proposed framework expresses a correlation measure as a function of several component parameters, each of which can be distributively estimated using a natural U-statistic from data segments. With the component estimates aggregated, we obtain a final correlation estimate that can be readily used for screening features. This framework enables distributed storage and parallel computing and thus is computationally attractive. Due to the unbiased distributive estimation of the component parameters, the final aggregated estimate achieves a high accuracy that  is insensitive to the number of data segments m. Under mild conditions, we show that the aggregated correlation estimator is as efficient as the centralized estimator in terms of the probability convergence bound and the mean squared error rate; the corresponding screening procedure enjoys sure screening property for a wide range of correlation measures. The promising performances of the new method are supported by extensive numerical examples",
    "volume": "main",
    "checked": true,
    "id": "a46ef1a09c51a918472a0e54252cc911fcabd14c",
    "citation_count": 22
  },
  "https://jmlr.org/papers/v21/19-580.html": {
    "title": "Lower Bounds for Testing Graphical Models: Colorings and Antiferromagnetic Ising Models",
    "abstract": "We study the identity testing problem in the context of spin systems or undirected graphical models, where it takes the following form: given the parameter specification of the model $M$ and a sampling oracle for the distribution $\\mu_{M^*}$ of an unknown model $M^*$, can we efficiently determine if the two models $M$ and $M^*$ are the same? We consider identity testing for both soft-constraint and hard-constraint systems. In particular, we prove hardness results in two prototypical cases, the Ising model and proper colorings, and explore whether identity testing is any easier than structure learning. For the ferromagnetic (attractive) Ising model, Daskalakis et al. (2018) presented a polynomial-time algorithm for identity testing. We prove hardness results in the antiferromagnetic (repulsive) setting in the same regime of parameters where structure learning is known to require a super-polynomial number of samples. Specifically, for $n$-vertex graphs of maximum degree $d$, we prove that if $|\\beta| d = \\omega(\\log{n})$ (where $\\beta$ is the inverse temperature parameter), then there is no polynomial running time identity testing algorithm unless $RP=NP$. In the hard-constraint setting, we present hardness results for identity testing for proper colorings. Our results are based on the presumed hardness of #BIS, the problem of (approximately) counting independent sets in bipartite graphs",
    "volume": "main",
    "checked": true,
    "id": "af5ffe46844a3916ae94a7c428e5e7210b36b9c6",
    "citation_count": 17
  },
  "https://jmlr.org/papers/v21/15-509.html": {
    "title": "Targeted Fused Ridge Estimation of Inverse Covariance Matrices from Multiple High-Dimensional Data Classes",
    "abstract": "We consider the problem of jointly estimating multiple inverse covariance matrices from high-dimensional data consisting of distinct classes. An $\\ell_2$-penalized maximum likelihood approach is employed. The suggested approach is flexible and generic, incorporating several other $\\ell_2$-penalized estimators as special cases. In addition, the approach allows specification of target matrices through which prior knowledge may be incorporated and which can stabilize the estimation procedure in high-dimensional settings. The result is a targeted fused ridge estimator that is of use when the precision matrices of the constituent classes are believed to chiefly share the same structure while potentially differing in a number of locations of interest. It has many applications in (multi)factorial study designs. We focus on the graphical interpretation of precision matrices with the proposed estimator then serving as a basis for integrative or meta-analytic Gaussian graphical modeling. Situations are considered in which the classes are defined by data sets and subtypes of diseases. The performance of the proposed estimator in the graphical modeling setting is assessed through extensive simulation experiments. Its practical usability is illustrated by the differential network modeling of 12 large-scale gene expression data sets of diffuse large B-cell lymphoma subtypes. The estimator and its related procedures are incorporated into the R-package rags2ridges",
    "volume": "main",
    "checked": true,
    "id": "67c1df30be545ba76f62d0f98ab0fe815bfea1f6",
    "citation_count": 23
  },
  "https://jmlr.org/papers/v21/16-639.html": {
    "title": "A New Class of Time Dependent Latent Factor Models with Applications",
    "abstract": "In many applications, observed data are influenced by some combination of latent causes. For example, suppose sensors are placed inside a building to record responses such as temperature, humidity, power consumption and noise levels. These random, observed responses are typically affected by many unobserved, latent factors (or features) within the building such as the number of individuals, the turning on and off of electrical devices, power surges, etc. These latent factors are usually present for a contiguous period of time before disappearing; further, multiple factors could be present at a time. \r\n\r\nThis paper develops new probabilistic methodology and inference methods for random object generation influenced by latent features exhibiting temporal persistence. Every datum is associated with subsets of a potentially infinite number of hidden, persistent features that account for temporal dynamics in an observation. The ensuing class of dynamic models constructed by adapting the Indian Buffet Process â a probability measure on the space of random, unbounded binary matrices â finds use in a variety of applications arising in operations, signal processing, biomedicine, marketing, image analysis, etc. Illustrations using synthetic and real data are provided",
    "volume": "main",
    "checked": true,
    "id": "430981aa3198badab1776df55dd072939713f9a7",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v21/17-698.html": {
    "title": "On the consistency of graph-based Bayesian semi-supervised learning and the scalability of sampling algorithms",
    "abstract": "This paper considers a Bayesian approach to graph-based semi-supervised learning. We show that if the graph parameters are suitably scaled, the graph-posteriors converge to a continuum limit as the size of the unlabeled data set grows. This consistency result has profound algorithmic implications: we prove that when consistency holds, carefully designed Markov chain Monte Carlo algorithms have a uniform spectral gap, independent of the number of unlabeled inputs. Numerical experiments illustrate and complement the theory",
    "volume": "main",
    "checked": true,
    "id": "874ae8b6c7df63b52491888c8454d0511a72ab3f",
    "citation_count": 16
  },
  "https://jmlr.org/papers/v21/17-788.html": {
    "title": "The Maximum Separation Subspace in Sufficient Dimension Reduction with Categorical Response",
    "abstract": "Sufficient dimension reduction (SDR) is a very useful concept for exploratory analysis and data visualization in regression, especially when the number of covariates is large. Many SDR methods have been proposed for regression with a continuous response, where the central subspace (CS) is the target of estimation. Various conditions, such as the linearity condition and the constant covariance condition, are imposed so that these methods can estimate at least a portion of the CS. In this paper we study SDR for regression and discriminant analysis with categorical response. Motivated by the exploratory analysis and data visualization aspects of SDR,  we propose a new geometric framework to reformulate the SDR problem in terms of manifold optimization and introduce a new concept called Maximum Separation Subspace (MASES). The MASES naturally preserves the âsufficiencyâ in SDR without imposing additional conditions on the predictor distribution, and directly inspires a semi-parametric estimator. Numerical studies show MASES exhibits superior performance as compared with competing SDR methods in specific settings",
    "volume": "main",
    "checked": true,
    "id": "48c06fc5080b4572d47715da775220986c342021",
    "citation_count": 5
  },
  "https://jmlr.org/papers/v21/18-008.html": {
    "title": "Tensor Train Decomposition on TensorFlow (T3F)",
    "abstract": "Tensor Train decomposition is used across many branches of machine learning. We present T3Fâa library for Tensor Train decomposition based on TensorFlow. T3F supports GPU execution, batch processing, automatic differentiation, and versatile functionality for the Riemannian optimization framework, which takes into account the underlying manifold structure to construct efficient optimization methods. The library makes it easier to implement machine learning papers that rely on the Tensor Train decomposition. T3F includes documentation, examples and 94% test coverage",
    "volume": "main",
    "checked": true,
    "id": "b88aff3b7bb19035ed3e420ff3cbc50bf9fe2df5",
    "citation_count": 54
  },
  "https://jmlr.org/papers/v21/18-112.html": {
    "title": "Generalized Nonbacktracking Bounds on the Influence",
    "abstract": "This paper develops deterministic upper and lower bounds on the influence measure in a network, more precisely, the expected number of nodes that a seed set can influence in the independent cascade model. In particular, our bounds exploit r-nonbacktracking walks and Fortuin-Kasteleyn-Ginibre (FKG) type inequalities, and are computed by message passing algorithms. Further, we provide parameterized versions of the bounds that control the trade-off between efficiency and accuracy. Finally, the tightness of the bounds is illustrated on various network models",
    "volume": "main",
    "checked": true,
    "id": "f388bc784379672cb30dd9f6dfffc0c322e357de",
    "citation_count": 0
  },
  "https://jmlr.org/papers/v21/18-143.html": {
    "title": "Provably robust estimation of modulo 1 samples of a smooth function with applications to phase unwrapping",
    "abstract": "Consider an unknown smooth function  $f: [0,1]^d \\rightarrow \\mathbb{R}$, and assume we are given $n$ noisy mod 1 samples of $f$, i.e., $y_i = (f(x_i) + \\eta_i)  \\bmod 1$, for  $x_i \\in [0,1]^d$, where $\\eta_i$ denotes the noise. Given the samples $(x_i,y_i)_{i=1}^{n}$, our goal is to recover smooth, robust estimates of the clean  samples $f(x_i) \\bmod  1$. We formulate a natural approach for solving this problem, which works with angular embeddings of  the noisy mod 1 samples over the unit circle, inspired by the angular synchronization framework. This amounts to solving a smoothness regularized least-squares problem -- a quadratically constrained quadratic program (QCQP) -- where the variables are constrained to lie on the unit circle. Our proposed approach is based on solving its relaxation, which is a trust-region sub-problem and hence solvable efficiently. We provide theoretical guarantees demonstrating its robustness to noise for adversarial, as well as random Gaussian and Bernoulli noise models. To the best of our knowledge, these are the first such theoretical results for this problem. We demonstrate the robustness and efficiency of our proposed approach via extensive numerical simulations on synthetic data, along with a simple least-squares based solution for the unwrapping stage, that recovers the original samples of $f$ (up to a global shift). It is shown to perform well at high levels of noise, when taking as input the denoised modulo $1$ samples. Finally, we also consider two other approaches for denoising the modulo 1 samples that leverage tools from Riemannian optimization on manifolds, including a Burer-Monteiro approach for a semidefinite programming relaxation of our formulation. For the two-dimensional version of the problem, which has applications in synthetic aperture radar interferometry (InSAR), we are able to solve instances of real-world data with a million sample points in under 10 seconds, on a personal laptop",
    "volume": "main",
    "checked": true,
    "id": "2ba7fe7a8a18c0acd8ccbdf776993ed5d6ea8647",
    "citation_count": 8
  },
  "https://jmlr.org/papers/v21/18-425.html": {
    "title": "On the Complexity Analysis of the Primal Solutions for the Accelerated Randomized Dual Coordinate Ascent",
    "abstract": "Dual first-order methods are essential techniques for large-scale constrained convex optimization. However, when recovering the primal solutions, we need $T(\\epsilon^{-2})$ iterations to achieve an $\\epsilon$-optimal primal solution when we apply an algorithm to the non-strongly convex dual problem with $T(\\epsilon^{-1})$ iterations to achieve an $\\epsilon$-optimal dual solution, where $T(x)$ can be $x$ or $\\sqrt{x}$. In this paper, we prove that the iteration complexity of the primal solutions and dual solutions have the same $O\\left(\\frac{1}{\\sqrt{\\epsilon}}\\right)$ order of magnitude for the accelerated randomized dual coordinate ascent. When the dual function further satisfies the quadratic functional growth condition, by restarting the algorithm at any period, we establish the linear iteration complexity for both the primal solutions and dual solutions even if the condition number is unknown. When applied to the regularized empirical risk minimization problem, we prove the iteration complexity of $O\\left(n\\log n+\\sqrt{\\frac{n}{\\epsilon}}\\right)$ in both primal space and dual space, where $n$ is the number of samples. Our result takes out the $\\left(\\log \\frac{1}{\\epsilon}\\right)$ factor compared with the methods based on smoothing/regularization or Catalyst reduction. As far as we know, this is the first time that the optimal $O\\left(\\sqrt{\\frac{n}{\\epsilon}}\\right)$ iteration complexity in the primal space is established for the dual coordinate ascent based stochastic algorithms. We also establish the accelerated linear complexity for some problems with nonsmooth loss, e.g., the least absolute deviation and SVM",
    "volume": "main",
    "checked": true,
    "id": "bed4f0680623f2c62927a6b88ac5e46f8381c479",
    "citation_count": 8
  },
  "https://jmlr.org/papers/v21/18-638.html": {
    "title": "Graph-Dependent Implicit Regularisation for Distributed Stochastic Subgradient Descent",
    "abstract": "We propose graph-dependent implicit regularisation strategies for synchronised distributed stochastic subgradient descent (Distributed SGD) for convex problems in multi-agent learning. Under the standard assumptions of convexity, Lipschitz continuity, and smoothness, we establish statistical learning rates that retain, up to logarithmic terms, single-machine serial statistical guarantees through implicit regularisation (step size tuning and early stopping) with appropriate dependence on the graph topology. Our approach avoids the need for explicit regularisation in  decentralised learning problems, such as adding constraints to the empirical risk minimisation rule. Particularly for distributed methods, the use of implicit regularisation allows the algorithm to remain simple, without projections or dual methods. To prove our results, we establish graph-independent generalisation bounds for Distributed SGD that match the single-machine serial SGD setting (using algorithmic stability), and we establish graph-dependent optimisation bounds that are of independent interest. We present numerical experiments to show that the qualitative nature of the upper bounds we derive can be representative of real behaviours",
    "volume": "main",
    "checked": true,
    "id": "c611db853e3b84840dcf0e3d9a69cb90310a2796",
    "citation_count": 14
  },
  "https://jmlr.org/papers/v21/19-021.html": {
    "title": "Learning with Fenchel-Young losses",
    "abstract": "Over the past decades, numerous loss functions have been been proposed for a variety of supervised learning tasks, including regression, classification, ranking, and more generally structured prediction. Understanding the core principles and theoretical properties underpinning these losses is key to choose the right loss for the right problem, as well as to create new losses which combine their strengths. In this paper, we introduce Fenchel-Young losses, a generic way to construct a convex loss function for a regularized prediction function. We provide an in-depth study of their properties in a very broad setting, covering all the aforementioned supervised learning tasks, and revealing new connections between sparsity, generalized entropies, and separation margins. We show that Fenchel-Young losses unify many well-known loss functions and allow to create useful new ones easily. Finally, we derive efficient predictive and training algorithms, making Fenchel-Young losses appealing both in theory and practice",
    "volume": "main",
    "checked": true,
    "id": "3ca8a63b74859c8e74ec905f6f655470b8e47b17",
    "citation_count": 80
  },
  "https://jmlr.org/papers/v21/19-117.html": {
    "title": "Noise Accumulation in High Dimensional Classification and Total Signal Index",
    "abstract": "Great attention has been paid to Big Data in recent years. Such data hold promise for scientific discoveries but also pose challenges to analyses. One potential challenge is noise accumulation. In this paper, we explore noise accumulation in high dimensional two-group classification. First, we revisit a previous assessment of noise accumulation with principal component analyses, which yields a different threshold for discriminative ability than originally identified. Then we extend our scope to its impact on classifiers developed with three common machine learning approaches---random forest, support vector machine, and boosted classification trees. We simulate four scenarios with differing amounts of signal strength to evaluate each method. After determining noise accumulation may affect the performance of these classifiers, we assess factors that impact it. We conduct simulations by varying sample size, signal strength, signal strength proportional to the number predictors, and signal magnitude with random forest classifiers. These simulations suggest that noise accumulation affects the discriminative ability of high-dimensional classifiers developed using common machine learning methods, which can be modified by sample size, signal strength, and signal magnitude. We developed the measure total signal index (TSI) to track the trends of total signal and noise accumulation",
    "volume": "main",
    "checked": true,
    "id": "608319426fed9a09a63f3fe8c7c4d47c47c8bc71",
    "citation_count": 1
  },
  "https://jmlr.org/papers/v21/19-187.html": {
    "title": "Causal Discovery Toolbox: Uncovering causal relationships in Python",
    "abstract": "This paper presents a new open source Python framework for causal discovery from observational data and domain background knowledge, aimed at causal graph and causal mechanism modeling. The cdt package implements an end-to-end approach, recovering the direct dependencies (the skeleton of the causal graph) and the causal relationships between variables. It includes algorithms from the `Bnlearn' and `Pcalg' packages, together with algorithms for pairwise causal discovery such as ANM",
    "volume": "main",
    "checked": true,
    "id": "75197f0cfd291e2d63aeb80f58a76e1cdcfb6c9e",
    "citation_count": 83
  },
  "https://jmlr.org/papers/v21/19-239.html": {
    "title": "Latent Simplex Position Model: High Dimensional Multi-view Clustering with Uncertainty Quantification",
    "abstract": "High dimensional data often contain multiple facets, and several clustering patterns can co-exist under different variable subspaces, also known as the views. While multi-view clustering algorithms were proposed, the uncertainty quantification remains difficult --- a particular challenge is in the high complexity of estimating the cluster assignment probability under each view, and sharing information among views. In this article, we propose an approximate Bayes approach --- treating the similarity matrices generated over the views as rough first-stage estimates for the co-assignment probabilities; in its Kullback-Leibler neighborhood, we obtain a refined low-rank matrix, formed by the pairwise product of simplex coordinates. Interestingly, each simplex coordinate directly encodes the cluster assignment uncertainty. For multi-view clustering, we let each view draw a  parameterization from a few candidates, leading to dimension reduction. With high model flexibility, the estimation can be efficiently carried out as a continuous optimization problem, hence enjoys gradient-based computation. The theory establishes the connection of this model to a random partition distribution under multiple views. Compared to single-view clustering approaches, substantially more interpretable results are obtained when clustering brains from a human traumatic brain injury study, using high-dimensional gene expression data",
    "volume": "main",
    "checked": true,
    "id": "2bad7aa9294d7a0fd429003a4c61e58088263575",
    "citation_count": 4
  },
  "https://jmlr.org/papers/v21/19-260.html": {
    "title": "Learning Linear Non-Gaussian Causal Models in the Presence of Latent Variables",
    "abstract": "We consider the problem of learning causal models from observational data generated by linear non-Gaussian acyclic causal models with latent variables. Without considering the effect of latent variables, the inferred causal relationships among the observed variables are often wrong. Under faithfulness assumption, we propose a method to check whether there exists a causal path between any two observed variables. From this information, we can obtain the causal order among the observed variables. The next question is whether the causal effects can be uniquely identified as well. We show that causal effects among observed variables cannot be identified uniquely under mere assumptions of faithfulness and non-Gaussianity of exogenous noises. However, we are able to propose an efficient method that identifies the set of all possible causal effects that are compatible with the observational data. We present additional structural conditions on the causal graph under which causal effects among observed variables can be determined uniquely.  Furthermore, we provide necessary and sufficient graphical conditions for unique identification of the number of variables in the system. Experiments on synthetic data and real-world data show the effectiveness of our proposed algorithm for learning causal models",
    "volume": "main",
    "checked": true,
    "id": "9f622f97483f379b023055f3719001fc9b44f2fc",
    "citation_count": 19
  },
  "https://jmlr.org/papers/v21/19-299.html": {
    "title": "Optimal Bipartite Network Clustering",
    "abstract": "We study bipartite community detection in networks, or more generally the network  biclustering problem. We present a fast two-stage procedure based on spectral initialization followed by the application of a pseudo-likelihood  classifier twice. Under mild regularity conditions, we establish the weak consistency of the procedure (i.e., the convergence of the misclassification rate to zero) under a general bipartite stochastic block model. We show that the procedure is optimal in the sense that it achieves the optimal convergence rate that is achievable by a biclustering oracle, adaptively over the whole class, up to constants. This is further formalized by deriving a minimax lower bound over a class of biclustering problems.  The optimal rate we obtain sharpens some of the existing results and generalizes others to a wide regime of  average degree growth, from sparse networks with average degrees growing arbitrarily slowly  to fairly dense networks with average degrees of order $\\sqrt{n}$. As a special case, we recover the known exact recovery threshold in the $\\log n$ regime of sparsity. To obtain the consistency result, as part of the provable version of the algorithm, we introduce a sub-block partitioning scheme that is also computationally attractive, allowing for distributed implementation of the algorithm without sacrificing optimality. The provable  algorithm is derived from a general class of pseudo-likelihood biclustering algorithms that employ simple EM type updates. We show the effectiveness of this general class  by numerical simulations",
    "volume": "main",
    "checked": true,
    "id": "de149d4190359a6cde8b83d04e7a6a8d355bf7ab",
    "citation_count": 26
  },
  "https://jmlr.org/papers/v21/19-407.html": {
    "title": "Switching Regression Models and Causal Inference in the Presence of Discrete Latent Variables",
    "abstract": "Given a response $Y$ and a vector $X = (X^1, \\dots, X^d)$ of $d$ predictors, we investigate the problem of inferring direct causes of $Y$ among the vector $X$. Models for $Y$ that use all of its causal covariates as predictors enjoy the property of being invariant across different environments or interventional settings. Given data from such environments, this property has been exploited for causal discovery. Here, we extend this inference principle to situations in which some (discrete-valued) direct causes of $ Y $ are unobserved. Such cases naturally give rise to switching regression models. We provide sufficient conditions for the existence, consistency and asymptotic normality of the MLE in linear switching regression models with Gaussian noise, and construct a test for the equality of such models. These results allow us to prove that the proposed causal discovery method obtains asymptotic false discovery control under mild conditions. We provide an algorithm, make available code, and test our method on simulated data. It is robust against model violations and outperforms state-of-the-art approaches. We further apply our method to a real data set, where we show that it does not only output causal predictors, but also a process-based clustering of data points, which could be of additional interest to practitioners",
    "volume": "main",
    "checked": true,
    "id": "afb1685ee5678e4ba42e073f27ccabf65a4011ee",
    "citation_count": 11
  },
  "https://jmlr.org/papers/v21/19-468.html": {
    "title": "Branch and Bound for Piecewise Linear Neural Network Verification",
    "abstract": "The success of Deep Learning and its potential use in many safety-critical applicationshas motivated research on formal verification of Neural Network (NN) models. In thiscontext, verification involves proving or disproving that an NN model satisfies certaininput-output properties. Despite the reputation of learned NN models as black boxes,and the theoretical hardness of proving useful properties about them, researchers havebeen successful in verifying some classes of models by exploiting their piecewise linearstructure and taking insights from formal methods such as Satisifiability Modulo Theory.However, these methods are still far from scaling to realistic neural networks. To facilitateprogress on this crucial area, we exploit the Mixed Integer Linear Programming (MIP) formulation of verification to propose a family of algorithms based on Branch-and-Bound (BaB). We show that our family contains previous verification methods as special cases.With the help of the BaB framework, we make three key contributions. Firstly, we identifynew methods that combine the strengths of multiple existing approaches, accomplishingsignificant performance improvements over previous state of the art. Secondly, we introducean effective branching strategy on ReLU non-linearities. This branching strategy allows usto efficiently and successfully deal with high input dimensional problems with convolutionalnetwork architecture, on which previous methods fail frequently.  Finally, we proposecomprehensive test data sets and benchmarks which includes a collection of previouslyreleased testcases. We use the data sets to conduct a thorough experimental comparison ofexisting and new algorithms and to provide an inclusive analysis of the factors impactingthe hardness of verification problems",
    "volume": "main",
    "checked": true,
    "id": "1314d8f118c66e52e6da5e928b4b37452e90edfe",
    "citation_count": 114
  },
  "https://jmlr.org/papers/v21/19-569.html": {
    "title": "Greedy Attack and Gumbel Attack: Generating Adversarial Examples for Discrete Data",
    "abstract": "We present a probabilistic framework for studying adversarial attacks on discrete data. Based on this framework, we derive a perturbation-based method, Greedy Attack, and a scalable learning-based method, Gumbel Attack, that illustrate various tradeoffs in the design of attacks. We demonstrate the effectiveness of these methods using both quantitative metrics and human evaluation on various state-of-the-art models for text classification, including a word-based CNN, a character-based CNN and an LSTM. As an example of our results, we show that the accuracy of character-based convolutional networks drops to the level of random selection by modifying only five characters through Greedy Attack",
    "volume": "main",
    "checked": true,
    "id": "a1da7529400aa6701be5ae4dd410db9ea22eb36a",
    "citation_count": 79
  },
  "https://jmlr.org/papers/v21/19-589.html": {
    "title": "Dynamical Systems as Temporal Feature Spaces",
    "abstract": "Parametrised state space models in the form of recurrent networks are often used in machine learning to learn from data streams exhibiting temporal dependencies. To break the black box nature of such models it is important to understand the dynamical features of the input-driving time series that are formed in the state space. We propose a framework for rigorous analysis of such state representations in vanishing memory state space models such as echo state networks (ESN). In particular, we consider the state space a temporal feature space and the readout mapping from the state space a kernel machine operating in that feature space. We show that: (1) The usual ESN strategy of randomly generating input-to-state, as well as state coupling leads to shallow memory time series representations, corresponding to cross-correlation operator with fast exponentially decaying coefficients; (2) Imposing symmetry on dynamic coupling yields a constrained dynamic kernel matching the input time series with straightforward exponentially decaying motifs or exponentially decaying motifs of the highest frequency; (3) Simple ring (cycle) high-dimensional reservoir topology specified only through two free parameters can implement deep memory dynamic kernels with a rich variety of matching motifs. We quantify richness of feature representations imposed by dynamic kernels and demonstrate that for dynamic kernel associated with cycle reservoir topology, the kernel richness undergoes a phase transition close to the edge of stability",
    "volume": "main",
    "checked": true,
    "id": "527957291652368118aacc1bc3ba3675e6f7e007",
    "citation_count": 17
  },
  "https://jmlr.org/papers/v21/19-594.html": {
    "title": "A Convex Parametrization of a New Class of Universal Kernel Functions",
    "abstract": "The accuracy and complexity of kernel learning algorithms is determined by the set of kernels over which it is able to optimize. An ideal set of kernels should: admit a linear parameterization (tractability); be dense in the set of all kernels (accuracy); and every member should be universal so that the hypothesis space is infinite-dimensional (scalability). Currently, there is no class of kernel that meets all three criteria - e.g. Gaussians are not tractable or accurate; polynomials are not scalable. We propose a new class that meet all three criteria - the Tessellated Kernel (TK) class. Specifically, the TK class: admits a linear parameterization using positive matrices; is dense in all kernels; and every element in the class is universal. This implies that the use of TK kernels for learning the kernel can obviate the need for selecting candidate kernels in algorithms such as SimpleMKL and parameters such as the bandwidth.  Numerical testing on soft margin Support Vector Machine (SVM) problems show that algorithms using TK kernels outperform other kernel learning algorithms and neural networks. Furthermore, our results show that when the ratio of the number of training data to features is high, the improvement of TK over MKL increases significantly",
    "volume": "main",
    "checked": false,
    "id": "d9ec5364076631fa229064d0e92dfd5581559cfa",
    "citation_count": 5
  },
  "https://jmlr.org/papers/v21/19-763.html": {
    "title": "pyts: A Python Package for Time Series Classification",
    "abstract": "pyts is an open-source Python package for time series classification. This versatile toolbox provides implementations of many algorithms published in the literature, preprocessing functionalities, and data set loading utilities. pyts relies on the standard scientific Python packages numpy, scipy, scikit-learn, joblib, and numba, and is distributed under the BSD-3-Clause license. Documentation contains installation instructions, a detailed user guide, a full API description, and concrete self-contained examples",
    "volume": "main",
    "checked": true,
    "id": "acd8ae94f9102fdfc809a9eeaaeb999cdb892c49",
    "citation_count": 69
  },
  "https://jmlr.org/papers/v21/19-985.html": {
    "title": "Ancestral Gumbel-Top-k Sampling for Sampling Without Replacement",
    "abstract": "We develop ancestral Gumbel-Top-$k$ sampling: a generic and efficient method for sampling without replacement from discrete-valued Bayesian networks, which includes multivariate discrete distributions, Markov chains and sequence models. The method uses an extension of the Gumbel-Max trick to sample without replacement by finding the top $k$ of perturbed log-probabilities among all possible configurations of a Bayesian network. Despite the exponentially large domain, the algorithm has a complexity linear in the number of variables and sample size $k$. Our algorithm allows to set the number of parallel processors $m$, to trade off the number of iterations versus the total cost (iterations times $m$) of running the algorithm. For $m = 1$ the algorithm has minimum total cost, whereas for $m = k$ the number of iterations is minimized, and the resulting algorithm is known as Stochastic Beam Search. We provide extensions of the algorithm and discuss a number of related algorithms. We analyze the properties of ancestral Gumbel-Top-$k$ sampling and compare against alternatives on randomly generated Bayesian networks with different levels of connectivity. In the context of (deep) sequence models, we show its use as a method to generate diverse but high-quality translations and statistical estimates of translation quality and entropy",
    "volume": "main",
    "checked": true,
    "id": "73e536de8a93f5941a967e8996ff4b9d70cc30a5",
    "citation_count": 17
  },
  "https://jmlr.org/papers/v21/13-561.html": {
    "title": "Skill Rating for Multiplayer Games. Introducing Hypernode Graphs and their Spectral Theory",
    "abstract": "We consider the skill rating problem for multiplayer games, that is how to infer player skills from game outcomes in multiplayer games. We formulate the problem as a minimization problem $\\arg \\min_{s} s^T \\Delta s$ where $\\Delta$ is a positive semidefinite matrix and $s$ a real-valued function, of which some entries are the skill values to be inferred and other entries are constrained by the game outcomes. We leverage graph-based semi-supervised learning (SSL) algorithms for this problem. We apply our algorithms on several data sets of multiplayer games and obtain very promising results compared to Elo Duelling (see Elo, 1978) and TrueSkill (see Herbrich et al., 2006).. As we leverage graph-based SSL algorithms and because games can be seen as relations between sets of players, we then generalize the approach. For this aim, we introduce a new finite model, called hypernode graph, defined to be a set of weighted binary relations between sets of nodes. We define Laplacians of hypernode graphs. Then, we show that the skill rating problem for multiplayer games can be formulated as $\\arg \\min_{s} s^T \\Delta s$ where $\\Delta$ is the Laplacian of a hypernode graph constructed from a set of games.  From a fundamental perspective, we show that hypernode graph Laplacians are symmetric positive semidefinite matrices with constant functions in their null space. We show that problems on hypernode graphs can not be solved with graph constructions and graph kernels. We relate hypernode graphs to signed graphs showing that positive relations between groups can lead to negative relations between individuals",
    "volume": "main",
    "checked": true,
    "id": "e9ca8923abf66839bbf212262ab371f34b809380",
    "citation_count": 1
  },
  "https://jmlr.org/papers/v21/14-368.html": {
    "title": "Ensemble Learning for Relational Data",
    "abstract": "We present a theoretical analysis framework for relational ensemble models. We show that ensembles of collective classifiers can improve predictions for graph data by reducing errors due to variance in both learning and inference. In addition, we propose a relational ensemble framework that combines a relational ensemble learning approach with a relational ensemble inference approach for collective classification. The proposed ensemble techniques are applicable for both single and multiple graph settings. Experiments on both synthetic and real-world data demonstrate the effectiveness of the proposed framework. Finally, our experimental results support the theoretical analysis and confirm that ensemble algorithms that explicitly focus on both learning and inference processes and aim at reducing errors associated with both, are the best performers",
    "volume": "main",
    "checked": true,
    "id": "71d00cce5a2c0e92ca5ce53cca9cb107445c5d5a",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v21/15-114.html": {
    "title": "Sparse and low-rank multivariate Hawkes processes",
    "abstract": "We consider the problem of unveiling the implicit network structure of node interactions (such as user interactions in a social network), based only on high-frequency timestamps. Our inference is based on the minimization of the least-squares loss associated with a multivariate Hawkes model, penalized by $\\ell_1$ and trace norm of the interaction tensor. We provide a first theoretical analysis for this problem, that includes sparsity and low-rank inducing penalizations. This result involves a new data-driven concentration inequality for matrix martingales in continuous time with observable variance, which is a result of independent interest and a broad range of possible applications since it extends to matrix martingales former results restricted to the scalar case. A consequence of our analysis is the construction of sharply tuned $\\ell_1$ and trace-norm penalizations, that leads to a data-driven scaling of the variability of information available for each users. Numerical experiments illustrate the significant improvements achieved by the use of such data-driven penalizations",
    "volume": "main",
    "checked": true,
    "id": "3a3eae8b9642299c99a0ff41871dcb30f00d3890",
    "citation_count": 30
  },
  "https://jmlr.org/papers/v21/16-252.html": {
    "title": "Learning Causal Networks via Additive Faithfulness",
    "abstract": "In this paper we introduce a statistical model, called additively faithful directed acyclic graph (AFDAG), for causal learning from observational data. Our approach is based on additive conditional independence (ACI), a recently proposed three-way statistical relation that shares many similarities with conditional independence but without resorting to multi-dimensional kernels. This distinct feature strikes a balance between a parametric model and a fully nonparametric model, which makes the proposed model attractive for handling large networks. We develop an estimator for AFDAG based on a linear operator that characterizes ACI, and establish the consistency and convergence rates of this estimator, as well as the uniform consistency of the estimated DAG. Moreover, we introduce a modified PC-algorithm to implement the estimating procedure efficiently, so that its complexity is determined by the level of sparseness rather than the dimension of the network. Through simulation studies we show that our method outperforms existing methods when commonly assumed conditions such as Gaussian or Gaussian copula distributions do not hold. Finally, the usefulness of AFDAG formulation is demonstrated through an application to a proteomics data set",
    "volume": "main",
    "checked": true,
    "id": "36246632fae4c68785def23cddef66369504062f",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v21/18-012.html": {
    "title": "Expected Policy Gradients for Reinforcement Learning",
    "abstract": "We propose expected policy gradients (EPG), which unify stochastic policy gradients (SPG) and deterministic policy gradients (DPG) for reinforcement learning. Inspired by expected sarsa, EPG integrates (or sums) across actions when estimating the gradient, instead of relying only on the action in the sampled trajectory. For continuous action spaces, we first derive a practical result for Gaussian policies and quadratic critics and then extend it to a universal analytical method, covering a broad class of actors and critics, including Gaussian, exponential families, and policies with bounded support. For Gaussian policies, we introduce an exploration method that uses covariance proportional to the matrix exponential of the scaled Hessian of the critic with respect to the actions. For discrete action spaces, we derive a variant of EPG based on softmax policies. We also establish a new general policy gradient theorem, of which the stochastic and deterministic policy gradient theorems are special cases. Furthermore, we prove that EPG reduces the variance of the gradient estimates without requiring deterministic policies and with little computational overhead. Finally, we provide an extensive experimental evaluation of EPG and show that it outperforms existing approaches on multiple challenging control domains",
    "volume": "main",
    "checked": true,
    "id": "cf9d6a148462a66964d891c5d32f92d38a75d1db",
    "citation_count": 35
  },
  "https://jmlr.org/papers/v21/18-357.html": {
    "title": "High-Dimensional Inference for Cluster-Based Graphical Models",
    "abstract": "Motivated by modern applications in which one constructs graphical models based on a very large number of features, this paper introduces a new class of cluster-based graphical models, in which variable clustering is applied as an initial step for reducing the dimension of the feature space. We employ model assisted clustering, in which the clusters contain features that are similar to the same unobserved latent variable. Two different cluster-based Gaussian graphical models are considered: the latent variable graph, corresponding to the graphical model associated with the unobserved latent variables, and the cluster-average graph, corresponding to the vector of features averaged over clusters. Our study reveals that likelihood based inference for the latent graph, not analyzed previously,  is analytically intractable. Our main contribution is the development and analysis of  alternative estimation and inference strategies, for  the precision matrix of an unobservable latent vector Z. We replace the likelihood of the data by an appropriate class of empirical risk functions, that can be specialized  to the latent graphical model and to the simpler, but under-analyzed, cluster-average graphical model. The estimators thus derived can be used  for inference on the graph structure, for instance  on edge strength or pattern recovery. Inference is based on the asymptotic limits of the entry-wise estimates of the precision matrices associated with the conditional independence  graphs under consideration. While taking the uncertainty induced by the clustering step into account, we establish  Berry-Esseen central limit theorems for the proposed estimators. It is noteworthy that, although the clusters are estimated adaptively from the data, the central limit theorems regarding the entries of the estimated graphs  are proved under the same conditions one would use if the clusters were known in advance.  As an illustration  of the usage of  these newly developed inferential tools, we show that they can be reliably used for recovery of the sparsity pattern of the graphs we study, under FDR control, which is verified via simulation studies and an fMRI data analysis. These experimental results confirm the theoretically established difference between the two graph structures. Furthermore, the data analysis suggests that the  latent variable graph, corresponding to  the unobserved cluster centers, can help provide more insight into the understanding of the brain connectivity networks relative to the simpler, average-based, graph",
    "volume": "main",
    "checked": true,
    "id": "163b04e1d06105f4a660f723915c959c9b0040dd",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v21/18-370.html": {
    "title": "GraKeL: A Graph Kernel Library in Python",
    "abstract": "The problem of accurately measuring the similarity between graphs is at the core of many applications in a variety of disciplines. Graph kernels have recently emerged as a promising approach to this problem. There are now many kernels, each focusing on different structural aspects of graphs. Here, we present GraKeL, a library that unifies several graph kernels into a common framework. The library is written in Python and adheres to the scikit-learn interface. It is simple to use and can be naturally combined with scikit-learn's modules to build a complete machine learning pipeline for tasks such as graph classification and clustering. The code is BSD licensed and is available at: https://github.com/ysig/GraKeL",
    "volume": "main",
    "checked": true,
    "id": "a4856d82ef6c9748e45e1709c664990eea28ca73",
    "citation_count": 107
  },
  "https://jmlr.org/papers/v21/18-473.html": {
    "title": "Conjugate Gradients for Kernel Machines",
    "abstract": "Regularized least-squares (kernel-ridge / Gaussian process) regression is a fundamental algorithm of statistics and machine learning. Because generic algorithms for the exact solution have cubic complexity in the number of datapoints, large datasets require to resort to approximations. In this work, the computation of the least-squares prediction is itself treated as a probabilistic inference problem. We propose a structured Gaussian regression model on the kernel function that uses projections of the kernel matrix to obtain a low-rank approximation of the kernel and the matrix. A central result is an enhanced way to use the method of conjugate gradients for the specific setting of least-squares regression as encountered in machine learning",
    "volume": "main",
    "checked": true,
    "id": "7602e23d4ca4bce7fac80a2d8deb91dc67e4d813",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v21/18-488.html": {
    "title": "Fast Rates for General Unbounded Loss Functions: From ERM to Generalized Bayes",
    "abstract": "We present new excess risk bounds for general unbounded loss functions including log loss and squared loss, where the distribution of the losses may be heavy-tailed. The bounds hold for general estimators, but they are optimized when applied to $\\eta$-generalized Bayesian, MDL, and empirical risk minimization estimators. In the case of log loss, the bounds imply convergence rates for generalized Bayesian inference under misspecification in terms of a generalization of the Hellinger metric as long as the learning rate $\\eta$ is set correctly. For general loss functions, our bounds rely on two separate conditions: the $v$-GRIP (generalized reversed information projection) conditions, which control the lower tail of the excess loss; and the newly introduced witness condition, which controls the upper tail. The parameter $v$ in the $v$-GRIP conditions determines the achievable rate and is akin to the exponent in the Tsybakov margin condition and the Bernstein condition for bounded losses, which the $v$-GRIP conditions generalize; favorable $v$ in combination with small model complexity leads to $\\tilde{O}(1/n)$ rates. The witness condition allows us to connect the excess risk to an 'annealed' version thereof, by which we generalize several previous results connecting Hellinger and RÃ©nyi divergence to KL divergence",
    "volume": "main",
    "checked": true,
    "id": "a5735d720ac89b54f286ffef7c57e10cf5ebfff9",
    "citation_count": 61
  },
  "https://jmlr.org/papers/v21/18-794.html": {
    "title": "Self-paced Multi-view Co-training",
    "abstract": "Co-training is a well-known semi-supervised learning approach which trains classifiers on two or more different views and exchanges pseudo labels of unlabeled instances in an iterative way. During the co-training process, pseudo labels of unlabeled instances are very likely to be false especially in the initial training, while the standard co-training algorithm adopts a 'draw without replacement' strategy and does not remove these wrongly labeled instances from training stages. Besides, most of the traditional co-training approaches are implemented for two-view cases, and their extensions in multi-view scenarios are not intuitive. These issues not only degenerate their performance as well as available application range but also hamper their fundamental theory. Moreover, there is no optimization model to explain the objective a co-training process manages to optimize. To address these issues, in this study we design a unified self-paced multi-view co-training (SPamCo) framework which draws unlabeled instances with replacement. Two specified co-regularization terms are formulated to develop different strategies for selecting pseudo-labeled instances during training. Both forms share the same optimization strategy which is consistent with the iteration process in co-training and can be naturally extended to multi-view scenarios. A distributed optimization strategy is also introduced to train the classifier of each view in parallel to further improve the efficiency of the algorithm. Furthermore, the SPamCo algorithm is proved to be PAC learnable, supporting its theoretical soundness. Experiments conducted on synthetic, text categorization, person re-identification, image recognition and object detection data sets substantiate the superiority of the proposed method",
    "volume": "main",
    "checked": true,
    "id": "9a7793c9e9b2198b07851ad20d53e883ee188a01",
    "citation_count": 32
  },
  "https://jmlr.org/papers/v21/18-813.html": {
    "title": "Robust Asynchronous Stochastic Gradient-Push: Asymptotically Optimal and Network-Independent Performance for Strongly Convex Functions",
    "abstract": "We consider the standard model of distributed optimization of a  sum of functions $F(\\mathbf z) = \\sum_{i=1}^n f_i(\\mathbf z)$, where node $i$ in a network holds the function $f_i(\\mathbf z)$. We allow for a harsh network model characterized by asynchronous updates, message delays, unpredictable message losses, and directed communication among nodes.  In this setting, we analyze a modification of the Gradient-Push method for distributed optimization, assuming that (i) node $i$ is capable of generating gradients of its function $f_i(\\mathbf z)$ corrupted by zero-mean bounded-support additive noise at each step, (ii) $F(\\mathbf z)$ is strongly convex, and (iii) each $f_i(\\mathbf z)$ has Lipschitz gradients. We show that our proposed  method asymptotically performs  as well as the best bounds on centralized  gradient descent that takes steps in the direction of the  sum of the noisy gradients of all the functions $f_1(\\mathbf z), \\ldots, f_n(\\mathbf z)$ at each step",
    "volume": "main",
    "checked": true,
    "id": "deb0432c2af09ddedef412260b5c2daddc92cde2",
    "citation_count": 43
  },
  "https://jmlr.org/papers/v21/18-884.html": {
    "title": "Exact Guarantees on the Absence of Spurious Local Minima for Non-negative Rank-1 Robust Principal Component Analysis",
    "abstract": "This work is concerned with the non-negative rank-1 robust principal component analysis (RPCA), where the goal is to recover the dominant non-negative principal components of a data matrix precisely, where a number of measurements could be grossly corrupted with sparse and arbitrary large noise. Most of the known techniques for solving the RPCA rely on convex relaxation methods by lifting the problem to a higher dimension, which significantly increase the number of variables. As an alternative, the well-known Burer-Monteiro approach can be used to cast the RPCA as a non-convex and non-smooth $\\ell_1$ optimization problem with a significantly smaller number of variables. In this work, we show that the low-dimensional formulation of the symmetric and asymmetric positive rank-1 RPCA based on the Burer-Monteiro approach has benign landscape, i.e., 1) it does not have any spurious local solution, 2) has a unique global solution, and 3) its unique global solution coincides with the true components. An implication of this result is that simple local search algorithms are guaranteed to achieve a zero global optimality gap when directly applied to the low-dimensional formulation. Furthermore, we provide strong deterministic and probabilistic guarantees for the exact recovery of the true principal components. In particular, it is shown that a constant fraction of the measurements could be grossly corrupted and yet they would not create any spurious local solution",
    "volume": "main",
    "checked": true,
    "id": "3dfce82c8d81d26c5a6c5898bb080f56a19f1e9f",
    "citation_count": 29
  },
  "https://jmlr.org/papers/v21/19-047.html": {
    "title": "Kymatio: Scattering Transforms in Python",
    "abstract": "The wavelet scattering transform is an invariant and stable signal representation suitable for many signal processing and machine learning applications. We present the Kymatio software package, an easy-to-use, high-performance Python implementation of the scattering transform in 1D, 2D, and 3D that is compatible with modern deep learning frameworks, including PyTorch and TensorFlow/Keras. The transforms are implemented on both CPUs and GPUs, the latter offering a significant speedup over the former. The package also has a small memory footprint. Source code, documentation, and examples are available under a BSD license at https://www.kymat.io",
    "volume": "main",
    "checked": true,
    "id": "7e3224180c274ce8bb64a998ba2aafa6427dfbb0",
    "citation_count": 91
  },
  "https://jmlr.org/papers/v21/19-054.html": {
    "title": "Multiparameter Persistence Landscapes",
    "abstract": "An important problem in the field of Topological Data Analysis is defining topological summaries which can be combined with traditional data analytic tools. In recent work Bubenik introduced the persistence landscape, a stable representation of persistence diagrams amenable to statistical analysis and machine learning tools. In this paper we generalise the persistence landscape to multiparameter persistence modules providing a stable representation of the rank invariant. We show that multiparameter landscapes are stable with respect to the interleaving distance and persistence weighted Wasserstein distance, and that the collection of multiparameter landscapes faithfully represents the rank invariant. Finally we provide example calculations and statistical tests to demonstrate a range of potential applications and how one can interpret the landscapes associated to a multiparameter module",
    "volume": "main",
    "checked": true,
    "id": "23dab559c7e0dd54d4af4fb2d632299615d5c0c1",
    "citation_count": 46
  },
  "https://jmlr.org/papers/v21/19-120.html": {
    "title": "Generalized Optimal Matching Methods for Causal Inference",
    "abstract": "We develop an encompassing framework for matching, covariate balancing, and doubly-robust methods for causal inference from observational data called generalized optimal matching (GOM). The framework is given by generalizing a new functional-analytical formulation of optimal matching, giving rise to the class of GOM methods, for which we provide a single unified theory to analyze tractability and consistency. Many commonly used existing methods are included in GOM and, using their GOM interpretation, can be extended to optimally and automatically trade off balance for variance and outperform their standard counterparts. As a subclass, GOM gives rise to kernel optimal matching (KOM), which, as supported by new theoretical and empirical results, is notable for combining many of the positive properties of other methods in one. KOM, which is solved as a linearly-constrained convex-quadratic optimization problem, inherits both the interpretability and model-free consistency of matching but can also achieve the $\\sqrt{n}$-consistency of well-specified regression and the bias reduction and robustness of doubly robust methods. In settings of limited overlap, KOM enables a very transparent method for interval estimation for partial identification and robust coverage. We demonstrate this in examples with both synthetic and real data",
    "volume": "main",
    "checked": true,
    "id": "09b4a22b518eaf5bcfeae6af9851e153b6c61add",
    "citation_count": 87
  },
  "https://jmlr.org/papers/v21/19-169.html": {
    "title": "Unique Sharp Local Minimum in L1-minimization Complete Dictionary Learning",
    "abstract": "We study the problem of globally recovering a dictionary from a set of signals via $\\ell_1$-minimization. We assume that the signals are generated as i.i.d. random linear combinations of the $K$ atoms from a complete reference dictionary $D^*\\in \\mathbb R^{K\\times K}$, where the linear combination coefficients are from either a Bernoulli type model or exact sparse model. First, we obtain a necessary and sufficient norm condition for the reference dictionary $D^*$ to be a sharp local minimum of the expected $\\ell_1$ objective function. Our result substantially extends that of Wu and Yu (2015) and allows the combination coefficient to be non-negative. Secondly, we obtain an explicit bound on the region within which the objective value of the reference dictionary is minimal. Thirdly, we show that the reference dictionary is the unique sharp local minimum, thus establishing the first known global property of $\\ell_1$-minimization dictionary learning. Motivated by the theoretical results, we introduce a perturbation based test to determine whether a dictionary is a sharp local minimum of the objective function. In addition, we also propose a new dictionary learning algorithm based on Block Coordinate Descent, called DL-BCD, which is guaranteed to decrease the obective function monotonically. Simulation studies show that DL-BCD has competitive performance in terms of recovery rate compared to other state-of-the-art dictionary learning algorithms when the reference dictionary is generated from random Gaussian matrices",
    "volume": "main",
    "checked": false,
    "id": "fa51336946d5b12a870949f0f7ecc360762209c0",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v21/19-181.html": {
    "title": "Community-Based Group Graphical Lasso",
    "abstract": "A new strategy for probabilistic graphical modeling is developed that draws parallels to community detection analysis. The method jointly estimates an undirected graph and homogeneous communities of nodes. The structure of the communities is taken into account when estimating the graph and at the same time, the structure of the graph is accounted for when estimating communities of nodes. The procedure uses a joint group graphical lasso approach with community detection-based grouping, such that some groups of edges co-occur in the estimated graph. The grouping structure is unknown and is estimated based on community detection algorithms. Theoretical derivations regarding graph convergence and sparsistency, as well as accuracy of community recovery are included, while the method's empirical performance is illustrated in an fMRI context, as well as with simulated examples",
    "volume": "main",
    "checked": true,
    "id": "abfe4f2509e058baad033b254ca2440fd1ca0ed0",
    "citation_count": 5
  },
  "https://jmlr.org/papers/v21/19-246.html": {
    "title": "Smoothed Nonparametric Derivative Estimation using Weighted Difference Quotients",
    "abstract": "Derivatives play an important role in bandwidth selection methods (e.g., plug-ins), data analysis and bias-corrected confidence intervals. Therefore, obtaining accurate derivative information is crucial. Although many derivative estimation methods exist, the majority require a fixed design assumption. In this paper, we propose an effective and fully data-driven framework to estimate the first and second order derivative in random design. We establish the asymptotic properties of the proposed derivative estimator, and also propose a fast selection method for the tuning parameters. The performance and flexibility of the method is illustrated via an extensive simulation study",
    "volume": "main",
    "checked": true,
    "id": "3b98a7c395fb19b409d4b093f3d50d37092f1511",
    "citation_count": 3
  },
  "https://jmlr.org/papers/v21/19-277.html": {
    "title": "WONDER: Weighted One-shot Distributed Ridge Regression in High Dimensions",
    "abstract": "In many areas, practitioners need to analyze large data sets that challenge conventional single-machine computing. To scale up data analysis, distributed and parallel computing approaches are increasingly needed. Here we study a fundamental and highly important problem in this area: How to do ridge regression in a distributed computing environment? Ridge regression is an extremely popular method for supervised learning, and has several optimality properties, thus it is important to study. We study one-shot methods that construct weighted combinations of ridge regression estimators computed on each machine. By analyzing the mean squared error in a high-dimensional random-effects model where each predictor has a small effect, we discover several new phenomena. Infinite-worker limit: The distributed estimator works well for very large numbers of machines, a phenomenon we call 'infinite-worker limit'. Optimal weights: The optimal weights for combining local estimators sum to more than unity, due to the downward bias of ridge. Thus, all averaging methods are suboptimal. We also propose a new Weighted ONe-shot DistributEd Ridge regression algorithm (WONDER). We test WONDER in simulation studies and using the Million Song Dataset as an example. There it can save at least 100x in computation time, while nearly preserving test accuracy",
    "volume": "main",
    "checked": false,
    "id": "126d841fe41e07e5a42210a40ba571ab354bc935",
    "citation_count": 40
  },
  "https://jmlr.org/papers/v21/19-290.html": {
    "title": "The weight function in the subtree kernel is decisive",
    "abstract": "Tree data are ubiquitous because they model a large variety of situations, e.g., the architecture of plants, the secondary structure of RNA, or the hierarchy of XML files. Nevertheless, the analysis of these non-Euclidean data is difficult per se. In this paper, we focus on the subtree kernel that is a convolution kernel for tree data introduced by Vishwanathan and Smola in the early 2000's. More precisely, we investigate the influence of the weight function from a theoretical perspective and in real data applications. We establish on a 2-classes stochastic model that the performance of the subtree kernel is improved when the weight of leaves vanishes, which motivates the definition of a new weight function, learned from the data and not fixed by the user as usually done. To this end, we define a unified framework for computing the subtree kernel from ordered or unordered trees, that is particularly suitable for tuning parameters. We show through eight real data classification problems the great efficiency of our approach, in particular for small data sets, which also states the high importance of the weight function. Finally, a visualization tool of the significant features is derived",
    "volume": "main",
    "checked": true,
    "id": "0ed1f34e5fd1a39c08a1ef478ddc774c1f4bdd8d",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v21/19-327.html": {
    "title": "On Stationary-Point Hitting Time and Ergodicity of Stochastic Gradient Langevin Dynamics",
    "abstract": "Stochastic gradient Langevin dynamics (SGLD) is a fundamental algorithm in stochastic optimization. Recent work by Zhang et al. (2017) presents an analysis for the hitting time of SGLD for the first and second order stationary points. The proof in  Zhang et al. (2017) is a two-stage procedure through bounding the Cheeger's constant, which is rather complicated and leads to loose bounds.  In this paper,  using intuitions from stochastic differential equations,  we provide a direct analysis for the hitting times of SGLD to the first and second order stationary points. Our analysis is straightforward. It only relies on basic linear algebra and probability theory tools. Our direct analysis also leads to tighter bounds comparing to Zhang et al. (2017) and shows the explicit dependence of the hitting time on different factors, including dimensionality, smoothness, noise strength, and step size effects.  Under suitable conditions,  we show that the hitting time of SGLD to first-order stationary points can be dimension-independent. Moreover, we apply our analysis to study several important online estimation problems in machine learning, including linear regression, matrix factorization, and online PCA",
    "volume": "main",
    "checked": true,
    "id": "0d47a23973a9af21b8a1714f11484e61b4b065b4",
    "citation_count": 25
  },
  "https://jmlr.org/papers/v21/19-347.html": {
    "title": "Union of Low-Rank Tensor Spaces: Clustering and Completion",
    "abstract": "We consider the problem of clustering and completing a set of tensors with missing data that are drawn from a union of low-rank tensor spaces. In the clustering problem, given a partially sampled tensor data that is composed of a number of subtensors, each chosen from one of a certain number of unknown tensor spaces, we need to group the subtensors that belong to the same tensor space. We provide a geometrical analysis on the sampling pattern and subsequently derive the sampling rate that guarantees the correct clustering under some assumptions with high probability. Moreover, we investigate the fundamental conditions for finite/unique completability for the union of tensor spaces completion problem. Both deterministic and probabilistic conditions on the sampling pattern to ensure finite/unique completability are obtained. For both the clustering and completion problems, our tensor analysis provides significantly better bound than the bound given by the matrix analysis applied to any unfolding of the tensor data",
    "volume": "main",
    "checked": true,
    "id": "15f95782778250b1453a0de35c8013aebbe10827",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v21/19-447.html": {
    "title": "Representation Learning for Dynamic Graphs: A Survey",
    "abstract": "Graphs arise naturally in many real-world applications including social networks, recommender systems, ontologies, biology, and computational finance. Traditionally, machine learning models for graphs have been mostly designed for static graphs. However, many applications involve evolving graphs. This introduces important challenges for learning and inference since nodes, attributes, and edges change over time. In this survey, we review the recent advances in representation learning for dynamic graphs, including dynamic knowledge graphs. We describe existing models from an encoder-decoder perspective, categorize these encoders and decoders based on the techniques they employ, and analyze the approaches in each category. We also review several prominent applications and widely used datasets and highlight directions for future research",
    "volume": "main",
    "checked": true,
    "id": "8a8e4fa580a81ba2fcb86965f323709cafcab275",
    "citation_count": 225
  },
  "https://jmlr.org/papers/v21/19-496.html": {
    "title": "Estimation of a Low-rank Topic-Based Model for Information Cascades",
    "abstract": "We consider the problem of estimating the latent structure of a social network based on the observed information diffusion events, or cascades, where the observations for a given cascade consist of only the timestamps of infection for infected nodes but not the source of the infection. Most of the existing work on this problem has focused on estimating a diffusion matrix without any structural assumptions on it.  In this paper, we propose a novel model based on the intuition that an information is more likely to propagate among two nodes if they are interested in similar topics which are also prominent in the information content. In particular, our model endows each node with an influence vector (which measures how authoritative the node is on each topic) and a receptivity vector (which measures how susceptible the node is for each topic). We show how this node-topic structure can be estimated from the observed cascades, and prove the consistency of the estimator.  Experiments on synthetic and real data demonstrate the improved performance and better interpretability of our model compared to existing state-of-the-art methods",
    "volume": "main",
    "checked": true,
    "id": "651817a38c67c0a936605a4b25dbccef715862b9",
    "citation_count": 3
  },
  "https://jmlr.org/papers/v21/19-514.html": {
    "title": "(1 + epsilon)-class Classification: an Anomaly Detection Method for Highly Imbalanced or Incomplete Data Sets",
    "abstract": "Anomaly detection is not an easy problem since distribution of anomalous samples is unknown a priori. We explore a novel method that gives a trade-off possibility between one-class and two-class approaches, and leads to a better performance on anomaly detection problems with small or non-representative anomalous samples. The method is evaluated using several data sets and compared to a set of conventional one-class and two-class approaches",
    "volume": "main",
    "checked": false,
    "id": "67daa87008c2aa9e1d14ef26b3c464f4e7344d1a",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v21/19-536.html": {
    "title": "Scalable Approximate MCMC Algorithms for the Horseshoe Prior",
    "abstract": "The horseshoe prior is frequently employed in Bayesian analysis of high-dimensional models, and has been shown to achieve minimax optimal risk properties when the truth is sparse. While optimization-based algorithms for the extremely popular Lasso and elastic net procedures can scale to dimension in the hundreds of thousands, algorithms for the horseshoe that use Markov chain Monte Carlo (MCMC) for computation are limited to problems an order of magnitude smaller. This is due to high computational cost per step and growth of the variance of time-averaging estimators as a function of dimension. We propose two new MCMC algorithms for computation in these models that have significantly improved performance compared to existing alternatives. One of the algorithms also approximates an expensive matrix product to give orders of magnitude speedup in high-dimensional applications. We prove guarantees for the accuracy of the approximate algorithm, and show that gradually decreasing the approximation error as the chain extends results in an exact algorithm. The scalability of the algorithm is illustrated in simulations with problem size as large as $N=5,000$ observations and $p=50,000$ predictors, and an application to a genome-wide association study with $N=2,267$ and $p=98,385$. The empirical results also show that the new algorithm yields estimates with lower mean squared error, intervals with better coverage, and elucidates features of the posterior that were often missed by previous algorithms in high dimensions, including bimodality of posterior marginals indicating uncertainty about which covariates belong in the model",
    "volume": "main",
    "checked": true,
    "id": "dfb5c2c3de4f46c258190ff60360bbedc6ca30f9",
    "citation_count": 41
  },
  "https://jmlr.org/papers/v21/19-563.html": {
    "title": "High-dimensional Gaussian graphical models on network-linked data",
    "abstract": "Graphical models are commonly used to represent conditional dependence relationships between variables. There are multiple methods available for exploring them from high-dimensional data, but almost all of them rely on the assumption that the observations are independent and identically distributed.  At the same time, observations connected by a network are becoming increasingly common, and tend to violate these assumptions.  Here we develop a Gaussian graphical model for observations connected by a network with potentially different mean vectors, varying smoothly over the network. We propose an efficient estimation algorithm and demonstrate its effectiveness on both simulated and real data, obtaining meaningful and interpretable results on a statistics coauthorship network. We also prove that our method estimates both the inverse covariance matrix and the corresponding graph structure correctly under the assumption of network âcohesionâ, which refers to the empirically observed phenomenon of network neighbors sharing similar traits",
    "volume": "main",
    "checked": false,
    "id": "3a60c4404b114a1de740dea728dee202849def02",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v21/19-664.html": {
    "title": "Identifiability of Additive Noise Models Using Conditional Variances",
    "abstract": "This paper considers a new identifiability condition for additive noise models (ANMs) in which each variable is determined by an arbitrary Borel measurable function of its parents plus an independent error. It has been shown that ANMs are fully recoverable under some identifiability conditions, such as when all error variances are equal. However, this identifiable condition could be restrictive, and hence, this paper focuses on a relaxed identifiability condition that involves not only error variances, but also the influence of parents. This new class of identifiable ANMs does not put any constraints on the form of dependencies, or distributions of errors, and allows different error variances. It further provides a statistically consistent and computationally feasible structure learning algorithm for the identifiable ANMs based on the new identifiability condition. The proposed algorithm assumes that all relevant variables are observed, while it does not assume faithfulness or a sparse graph. Demonstrated through extensive simulated and real multivariate data is that the proposed algorithm successfully recovers directed acyclic graphs",
    "volume": "main",
    "checked": true,
    "id": "f44e7ff2c7f2fd40bdcd59037509aaf731845bfa",
    "citation_count": 20
  },
  "https://jmlr.org/papers/v21/19-718.html": {
    "title": "GADMM: Fast and Communication Efficient Framework for Distributed Machine Learning",
    "abstract": "When the data is distributed across multiple servers, lowering the communication cost between the servers (or workers) while solving the distributed learning problem is an important problem and is the focus of this paper. In particular, we propose a fast, and communication-efficient decentralized framework to solve the distributed machine learning (DML) problem. The proposed algorithm, Group Alternating Direction Method of Multipliers (GADMM) is based on the Alternating Direction Method of Multipliers (ADMM) framework. The key novelty in GADMM is that it solves the problem in a decentralized topology where at most half of the workers are competing for the limited communication resources at any given time. Moreover, each worker exchanges the locally trained model only with two neighboring workers, thereby training a global model with a lower amount of communication overhead in each exchange. We prove that GADMM converges to the optimal solution for convex loss functions, and numerically show that it converges faster and more communication-efficient than the state-of-the-art communication-efficient algorithms such as the Lazily Aggregated Gradient (LAG) and dual averaging, in linear and logistic regression tasks on synthetic and real datasets. Furthermore, we propose Dynamic GADMM (D-GADMM), a variant of GADMM, and prove its convergence under the time-varying network topology of the workers",
    "volume": "main",
    "checked": true,
    "id": "718692d0030f207fe7f3988496bd02e889e758aa",
    "citation_count": 59
  },
  "https://jmlr.org/papers/v21/19-912.html": {
    "title": "Multi-Player Bandits: The Adversarial Case",
    "abstract": "We consider a setting where multiple players sequentially choose among a common set of actions (arms). Motivated by an application to cognitive radio networks, we assume that players incur a loss upon colliding, and that communication between players is not possible. Existing approaches assume that the system is stationary. Yet this assumption is often violated in practice, e.g., due to signal strength fluctuations. In this work, we design the first multi-player Bandit algorithm that provably works in arbitrarily changing environments, where the losses of the arms may even be chosen by an adversary. This resolves an open problem posed by Rosenski et al. (2016)",
    "volume": "main",
    "checked": true,
    "id": "dc028e88c39a1a1214306d3f81f3a193f30f1d0b",
    "citation_count": 30
  },
  "https://jmlr.org/papers/v21/16-543.html": {
    "title": "Harmless Overfitting: Using Denoising Autoencoders in Estimation of Distribution Algorithms",
    "abstract": "Estimation of Distribution Algorithms (EDAs) are metaheuristics where learning a model and sampling new solutions replaces the variation operators recombination and mutation used in standard Genetic Algorithms. The choice of these models as well as the corresponding training processes are subject to the bias/variance tradeoff, also known as under- and overfitting: simple models cannot capture complex interactions between problem variables, whereas complex models are susceptible to modeling random noise. This paper suggests using Denoising Autoencoders (DAEs) as generative models within EDAs (DAE-EDA). The resulting DAE-EDA is able to model complex probability distributions. Furthermore, overfitting is less harmful, since DAEs overfit by learning the identity function. This overfitting behavior introduces unbiased random noise into the samples, which is no major problem for the EDA but just leads to higher population diversity. As a result, DAE-EDA runs for more generations before convergence and searches promising parts of the solution space more thoroughly. We study the performance of DAE-EDA on several combinatorial single-objective optimization problems. In comparison to the Bayesian Optimization Algorithm, DAE-EDA requires a similar number of evaluations of the objective function but is much faster and can be parallelized efficiently, making it the preferred choice especially for large and difficult optimization problems",
    "volume": "main",
    "checked": true,
    "id": "2e3d9d87a95da56a1176fa6e05d27bd1f7b86eba",
    "citation_count": 5
  },
  "https://jmlr.org/papers/v21/17-231.html": {
    "title": "Quantile Graphical Models: a Bayesian Approach",
    "abstract": "Graphical models are ubiquitous tools to describe the interdependence between variables measured simultaneously such as large-scale gene or protein expression data. Gaussian graphical models (GGMs) are well-established tools for probabilistic exploration of dependence structures using precision matrices and they are generated under a multivariate normal joint distribution. However, they suffer from several shortcomings since they are based on Gaussian distribution assumptions. In this article, we propose a Bayesian quantile based approach for sparse estimation of graphs. We demonstrate that the resulting graph estimation is robust to outliers and applicable under general distributional assumptions. Furthermore, we develop efficient variational Bayes approximations to scale the methods for large data sets. Our methods are applied to a novel cancer proteomics data dataset where-in multiple proteomic antibodies are simultaneously assessed on tumor samples using reverse-phase protein arrays (RPPA) technology",
    "volume": "main",
    "checked": true,
    "id": "e90eb7259568cbbaf2457fea021c3f210aced4be",
    "citation_count": 4
  },
  "https://jmlr.org/papers/v21/18-042.html": {
    "title": "Memoryless Sequences for General Losses",
    "abstract": "One way to define the randomness of a fixed individual sequence is to ask how hard it is to predict relative to a given loss function.  A sequence is memoryless if, with respect to average loss, no continuous function can predict the next entry of the sequence from a finite window of previous entries better than a constant prediction.  For squared loss, memoryless sequences are known to have stochastic attributes analogous to those of truly random sequences.  In this paper, we address the question of how changing the loss function changes the set of memoryless sequences, and in particular, the stochastic attributes they possess.  For convex differentiable losses we establish that the statistic or property elicited by the loss determines the identity and stochastic attributes of the corresponding memoryless sequences.  We generalize these results to convex non-differentiable losses, under additional assumptions, and to non-convex Bregman divergences.  In particular, our results show that any Bregman divergence has the same set of memoryless sequences as squared loss.  We apply our results to price calibration in prediction markets",
    "volume": "main",
    "checked": true,
    "id": "8509962e44f5fc054b3db7ba20e1aa3f3a9f4805",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v21/18-223.html": {
    "title": "Tuning Hyperparameters without Grad Students: Scalable and Robust Bayesian Optimisation with Dragonfly",
    "abstract": "Bayesian Optimisation (BO) refers to a suite of techniques for global optimisation of expensive black box functions, which use introspective Bayesian models of the function to efficiently search for the optimum. While BO has been applied successfully in many applications, modern optimisation tasks usher in new challenges where conventional methods fail spectacularly. In this work, we present Dragonfly, an open source Python library for scalable and robust BO. Dragonfly incorporates multiple recently developed methods that allow BO to be applied in challenging real world settings; these include better methods for handling higher dimensional domains, methods for handling multi-fidelity evaluations when cheap approximations of an expensive function are available, methods for optimising over structured combinatorial spaces, such as the space of neural network architectures, and methods for handling parallel evaluations. Additionally, we develop new methodological improvements in BO for selecting the Bayesian model, selecting the acquisition function, and optimising over complex domains with different variable types and additional constraints. We compare Dragonfly to a suite of other packages and algorithms for global optimisation and demonstrate that when the above methods are integrated, they enable significant improvements in the performance of BO. The Dragonfly library is available at dragonfly.github.io",
    "volume": "main",
    "checked": true,
    "id": "f02d80cc16630cd5ebfe69bd313bcefdf70af2d6",
    "citation_count": 134
  },
  "https://jmlr.org/papers/v21/18-410.html": {
    "title": "Sequential change-point detection in high-dimensional Gaussian graphical models",
    "abstract": "High dimensional piecewise stationary graphical models represent a versatile class for modelling time varying networks arising in diverse application areas, including biology, economics, and social sciences. There has been recent work in offline detection and estimation of regime changes in the topology of sparse graphical models. However, the online setting remains largely unexplored, despite its high relevance to applications in sensor networks and other engineering monitoring systems, as well as financial markets. To that end, this work introduces a novel scalable online algorithm for detecting an unknown number of abrupt changes in the inverse covariance matrix of sparse Gaussian graphical models with small delay. The proposed algorithm is based upon monitoring the conditional log-likelihood of all nodes in the network and can be extended to a large class of continuous and discrete graphical models. We also investigate asymptotic properties of our procedure under certain mild regularity conditions on the graph size, sparsity level, number of samples, and pre- and post-changes in the topology of the network. Numerical works on both synthetic and real data illustrate the good performance of the proposed methodology both in terms of computational and statistical efficiency across numerous experimental settings",
    "volume": "main",
    "checked": true,
    "id": "962068125177667813de7ffe1af0f67818c73f2d",
    "citation_count": 19
  },
  "https://jmlr.org/papers/v21/18-562.html": {
    "title": "Discerning the Linear Convergence of ADMM for Structured Convex Optimization through the Lens of Variational Analysis",
    "abstract": "Despite the rich literature, the linear convergence of alternating direction method of multipliers (ADMM) has not been fully understood even for the convex case. For example, the linear convergence of ADMM can be empirically observed in a wide range of applications arising in statistics, machine learning, and related areas, while existing theoretical results seem to be too stringent to be satisfied or too ambiguous to be checked and thus why the ADMM performs linear convergence for these applications still seems to be unclear. In this paper, we systematically study the local linear convergence of ADMM in the context of convex optimization through the lens of variational analysis. We show that the local  linear convergence of ADMM can be guaranteed without the strong convexity of objective functions together with the full rank assumption of the coefficient matrices, or the full polyhedricity assumption of their subdifferential; and it is possible to discern the local linear convergence for various concrete applications, especially for some representative models arising in statistical learning. We use some variational analysis techniques sophisticatedly; and our analysis is conducted in the most general proximal version of ADMM with Fortin and Glowinski's larger step size so that all major variants of the ADMM known in the literature are covered",
    "volume": "main",
    "checked": true,
    "id": "fa898af42c9856fb7272c925398bdec03e8ee4ae",
    "citation_count": 30
  },
  "https://jmlr.org/papers/v21/18-668.html": {
    "title": "Model-Preserving Sensitivity Analysis for Families of Gaussian Distributions",
    "abstract": "The accuracy of probability distributions inferred using machine-learning algorithms heavily depends on data availability and quality. In practical applications it is therefore fundamental to investigate the robustness of a statistical model to misspecification of some of its underlying probabilities. In the context of graphical models, investigations of robustness fall under the notion of sensitivity analyses. These analyses consist in varying some of the model's probabilities or parameters and then assessing how far apart the original and the varied distributions are.  However, for Gaussian graphical models, such variations usually make the original graph an incoherent  representation of the model's conditional independence structure. Here we develop an approach to sensitivity analysis which guarantees the original graph remains valid after any probability variation and we quantify the effect of such variations using different measures. To achieve this we take advantage of algebraic techniques to both concisely represent conditional independence and to provide a straightforward way of checking the validity of such relationships. Our methods are demonstrated to be robust and comparable to standard ones, which can break the conditional independence structure of the model, using an artificial example and a medical real-world application",
    "volume": "main",
    "checked": true,
    "id": "ee80d0f2858c5d74520d083b39abf731022edaff",
    "citation_count": 4
  },
  "https://jmlr.org/papers/v21/18-772.html": {
    "title": "Effective Ways to Build and Evaluate Individual Survival Distributions",
    "abstract": "An accurate model of a patientâs individual survival distribution can help determine the appropriate treatment for terminal patients. Unfortunately, risk scores (for example from Cox Proportional Hazard models) do not provide survival probabilities, single-time probability models (for instance the Gail model, predicting 5 year probability) only provide for a single time point, and standard Kaplan-Meier survival curves provide only population averages for a large class of patients, meaning they are not specific to individual patients. This motivates an alternative class of tools that can learn a model that provides an individual survival distribution for each subject, which gives survival probabilities across all times, such as extensions to the Cox model, Accelerated Failure Time, an extension to Random Survival Forests, and Multi-Task Logistic Regression. This paper first motivates such 'individual survival distribution' (ISD) models, and explains how they differ from standard models. It then discusses ways to evaluate such models â namely Concordance, 1-Calibration, Integrated Brier score, and versions of L1-loss â then motivates and defines a novel approach, 'D-Calibration', which determines whether a model's probability estimates are meaningful. We also discuss how these measures differ, and use them to evaluate several ISD prediction tools over a range of survival data sets. We also provide a code base for all of these survival models and evaluation measures, at https://github.com/haiderstats/ISDEvaluation",
    "volume": "main",
    "checked": true,
    "id": "2489f90b55e5785b06d5eef3c4b6d5aef1cf1863",
    "citation_count": 57
  },
  "https://jmlr.org/papers/v21/18-804.html": {
    "title": "Convergence Rate of Optimal Quantization and Application to the Clustering Performance of the Empirical Measure",
    "abstract": "We study the convergence rate of the optimal quantization for a probability measure sequence $(\\mu_{n})_{n\\in\\mathbb{N}^{*}}$ on $\\mathbb{R}^{d}$ converging in the Wasserstein distance in two aspects: the first one is the convergence rate of optimal quantizer $x^{(n)}\\in(\\mathbb{R}^{d})^{K}$ of $\\mu_{n}$ at level $K$; the other one is the convergence rate of the distortion function valued at $x^{(n)}$, called the âperformanceâ of $x^{(n)}$. Moreover, we also study the mean performance of the optimal quantization for the empirical measure of a distribution $\\mu$ with finite second moment but possibly unbounded support. As an application, we show an upper bound with a convergence rate  $\\mathcal{O}(\\frac{\\log n}{\\sqrt{n}})$ of the mean performance for the empirical measure of the multidimensional normal distribution $\\mathcal{N}(m, \\Sigma)$ and of distributions with hyper-exponential tails.  This extends the results from Biau et al. (2008) obtained for compactly supported distribution. We also derive an upper bound which is sharper in the quantization level $K$ but suboptimal in $n$ by applying results in Fournier and Guillin (2015)",
    "volume": "main",
    "checked": true,
    "id": "2e6b10ce34d53fe3dea0827e9a32972d8c9d3f4d",
    "citation_count": 6
  },
  "https://jmlr.org/papers/v21/18-843.html": {
    "title": "Constrained Dynamic Programming and Supervised Penalty Learning Algorithms for Peak Detection in Genomic Data",
    "abstract": "Peak detection in genomic data involves segmenting counts of DNA sequence reads aligned to different locations of a chromosome. The goal is to detect peaks with higher counts, and filter out background noise with lower counts. Most existing algorithms for this problem are unsupervised heuristics tailored to patterns in specific data types. We propose a supervised framework for this problem, using optimal changepoint detection models with learned penalty functions. We propose the first dynamic programming algorithm that is guaranteed to compute the optimal solution to changepoint detection problems with constraints between adjacent segment mean parameters. Implementing this algorithm requires the choice of penalty parameter that determines the number of segments that are estimated. We show how the supervised learning ideas of Rigaill et al. (2013) can be used to choose this penalty. We compare the resulting implementation of our algorithm to several baselines in a benchmark of labeled ChIP-seq data sets with two different patterns (broad H3K36me3 data and sharp H3K4me3 data). Whereas baseline unsupervised methods only provide accurate peak detection for a single pattern, our supervised method achieves state-of-the-art accuracy in all data sets. The log-linear timings of our proposed dynamic programming algorithm make it scalable to the large genomic data sets that are now common. Our implementation is available in the PeakSegOptimal R package on CRAN",
    "volume": "main",
    "checked": true,
    "id": "05a206502f031c776fcd56a7093fbd9dc1fcc227",
    "citation_count": 17
  },
  "https://jmlr.org/papers/v21/19-102.html": {
    "title": "TargetâAware Bayesian Inference: How to Beat Optimal Conventional Estimators",
    "abstract": "Standard approaches for Bayesian inference focus solely on approximating the posterior distribution. Typically, this approximation is, in turn, used to calculate expectations for one or more target functionsâa computational pipeline that is inefficient when the target function(s) are known upfront. We address this inefficiency by introducing a framework for targetâaware Bayesian inference (TABI) that estimates these expectations directly. While conventional Monte Carlo estimators have a fundamental limit on the error they can achieve for a given sample size, our TABI framework is able to breach this limit; it can theoretically produce arbitrarily accurate estimators using only three samples, while we show empirically that it can also breach this limit in practice. We utilize our TABI framework by combining it with adaptive importance sampling approaches and show both theoretically and empirically that the resulting estimators are capable of converging faster than the standard $\\mathcal{O}(1/N)$ Monte Carlo rate, potentially producing rates as fast as $\\mathcal{O}(1/N^2)$. We further combine our TABI framework with amortized inference methods, to produce a method for amortizing the cost of calculating expectations. Finally, we show how TABI can be used to convert any marginal likelihood estimator into a target aware inference scheme and demonstrate the substantial benefits this can yield",
    "volume": "main",
    "checked": false,
    "id": "afce485a84e27cc7483ce10e435732596a820866",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v21/19-232.html": {
    "title": "Causal Discovery from Heterogeneous/Nonstationary Data",
    "abstract": "It is commonplace to encounter heterogeneous or nonstationary data, of which the underlying generating process changes across domains or over time. Such a distribution shift feature presents both challenges and opportunities for causal discovery. In this paper, we develop a framework for causal discovery from such data, called Constraint-based causal Discovery from heterogeneous/NOnstationary Data (CD-NOD), to find causal skeleton and directions and estimate the properties of mechanism changes. First, we propose an enhanced constraint-based procedure to detect variables whose local mechanisms change and recover the skeleton of the causal structure over observed variables. Second, we present a method to determine causal orientations by making use of independent changes in the data distribution implied by the underlying causal model, benefiting from information carried by changing distributions. After learning the causal structure, next, we investigate how to efficiently estimate the âdriving forceâ of the nonstationarity of a causal mechanism. That is, we aim to extract from data a low-dimensional representation of changes. The proposed methods are nonparametric, with no hard restrictions on data distributions and causal mechanisms, and do not rely on window segmentation. Furthermore, we find that data heterogeneity benefits causal structure identification even with particular types of confounders. Finally, we show the connection between heterogeneity/nonstationarity and soft intervention in causal discovery. Experimental results on various synthetic and real-world data sets (task-fMRI and stock market data) are presented to demonstrate the efficacy of the proposed methods",
    "volume": "main",
    "checked": true,
    "id": "cdc04b748e440f43547c0516f77480ffb8bf5cda",
    "citation_count": 113
  },
  "https://jmlr.org/papers/v21/19-322.html": {
    "title": "Probabilistic Symmetries and Invariant Neural Networks",
    "abstract": "Treating neural network inputs and outputs as random variables, we characterize the structure of neural networks that can be used to model data that are invariant or equivariant under the action of a compact group. Much recent research has been devoted to encoding invariance under symmetry transformations into neural network architectures, in an effort to improve the performance of deep neural networks in data-scarce, non-i.i.d., or unsupervised settings. By considering group invariance from the perspective of probabilistic symmetry, we establish a link between functional and probabilistic symmetry, and obtain generative functional representations of probability distributions that are invariant or equivariant under the action of a compact group. Our representations completely characterize the structure of neural networks that can be used to model such distributions and yield a general program for constructing invariant stochastic or deterministic neural networks. We demonstrate that examples from the recent literature are special cases, and develop the details of the general program for exchangeable sequences and arrays",
    "volume": "main",
    "checked": false,
    "id": "6147befcb33e513fc6f20e23bc88542d26cc5c83",
    "citation_count": 26
  },
  "https://jmlr.org/papers/v21/19-383.html": {
    "title": "Simultaneous Inference for Pairwise Graphical Models with Generalized Score Matching",
    "abstract": "Probabilistic graphical models provide a flexible yet parsimonious framework for modeling dependencies among nodes in networks.  There is a vast literature on parameter estimation and consistent model selection for graphical models.  However, in many of the applications, scientists are also interested in quantifying the uncertainty associated with the estimated parameters and selected models, which current literature has not addressed thoroughly.  In this paper, we propose a novel estimator for statistical inference on edge parameters in pairwise graphical models based on generalized Hyvarinen scoring rule.  Hyvarinen scoring rule is especially useful in cases where the normalizing constant cannot be obtained efficiently in a closed form, which is a common problem for graphical models, including Ising models and truncated Gaussian graphical models.  Our estimator allows us to perform statistical inference for general graphical models whereas the existing works mostly focus on statistical inference for Gaussian graphical models where finding normalizing constant is computationally tractable.  Under mild conditions that are typically assumed in the literature for consistent estimation, we prove that our proposed estimator is $\\sqrt{n}$-consistent and asymptotically normal, which allows us to construct confidence intervals and build hypothesis tests for edge parameters. Moreover, we show how our proposed method can be applied to test hypotheses that involve a large number of model parameters simultaneously.  We illustrate validity of our estimator through extensive simulation studies on a diverse collection of data-generating processes",
    "volume": "main",
    "checked": true,
    "id": "20a8f0417c346b7e04aaf2d6fd239f8c10c97805",
    "citation_count": 24
  },
  "https://jmlr.org/papers/v21/19-441.html": {
    "title": "Fast mixing of Metropolized Hamiltonian Monte Carlo: Benefits of multi-step gradients",
    "abstract": "Hamiltonian Monte Carlo (HMC) is a state-of-the-art Markov chain Monte Carlo sampling algorithm for drawing samples from smooth probability densities over continuous spaces. We study the variant most widely used in practice, Metropolized HMC with the Stormer-Verlet or leapfrog integrator, and make two primary contributions. First, we provide a non-asymptotic upper bound on the mixing time of the Metropolized HMC with explicit choices of step-size and number of leapfrog steps. This bound gives a precise quantification of the faster convergence of Metropolized HMC relative to simpler MCMC algorithms such as the Metropolized random walk, or Metropolized Langevin algorithm. Second, we provide a general framework for sharpening mixing time bounds of Markov chains initialized at a substantial distance from the target distribution over continuous spaces. We apply this sharpening device to the Metropolized random walk and Langevin algorithms, thereby obtaining improved mixing time bounds from a non-warm initial distribution",
    "volume": "main",
    "checked": true,
    "id": "fc626b13271e5187dcb66201b6f078cfa9517f46",
    "citation_count": 82
  },
  "https://jmlr.org/papers/v21/19-592.html": {
    "title": "Distributed Kernel Ridge Regression with Communications",
    "abstract": "This paper focuses on generalization performance analysis for distributed algorithms in the framework of learning theory. Taking distributed kernel ridge regression (DKRR) for example, we succeed in deriving its optimal learning rates in expectation and providing theoretically optimal ranges of the number of local processors. Due to the gap between theory and experiments, we also deduce optimal learning rates for DKRR in probability to essentially reflect the generalization performance and limitations of DKRR. Furthermore, we propose a communication strategy to improve the learning performance of DKRR and demonstrate the power of communications in DKRR via both theoretical assessments and numerical experiments",
    "volume": "main",
    "checked": true,
    "id": "1610181708211140db33241ea35f3efa5415fd99",
    "citation_count": 21
  },
  "https://jmlr.org/papers/v21/19-800.html": {
    "title": "Minimax Nonparametric Parallelism Test",
    "abstract": "Testing the hypothesis of parallelism is a fundamental statistical problem arising from many applied sciences.  In this paper, we develop a nonparametric parallelism test for inferring whether the trends are parallel in treatment and control groups.  In particular, the proposed nonparametric parallelism test is a Wald type test based on a smoothing spline ANOVA (SSANOVA) model which can characterize the complex patterns of the data. We derive that the asymptotic null distribution of the test statistic is a Chi-square distribution, unveiling a new version of Wilks phenomenon. Notably, we establish the minimax sharp lower bound of the distinguishable rate for the nonparametric parallelism test by using the information theory, and further prove that the proposed test is minimax optimal. Simulation studies are conducted to investigate the empirical performance of the proposed test. DNA methylation and neuroimaging studies are presented to illustrate potential applications of the test. The software is available at https://github.com/BioAlgs/Parallelism",
    "volume": "main",
    "checked": true,
    "id": "290d6b7182ac4cc71d90bfc35daaf3c03776fdfa",
    "citation_count": 6
  },
  "https://jmlr.org/papers/v21/19-805.html": {
    "title": "Cornac: A Comparative Framework for Multimodal Recommender Systems",
    "abstract": "Cornac is an open-source Python framework for multimodal recommender systems. In addition to core utilities for accessing, building, evaluating, and comparing recommender models, Cornac is distinctive in putting emphasis on recommendation models that leverage auxiliary information in the form of a social network, item textual descriptions, product images, etc. Such multimodal auxiliary data supplement user-item interactions (e.g., ratings, clicks), which tend to be sparse in practice. To facilitate broad adoption and community contribution, Cornac is publicly available at https://github.com/PreferredAI/cornac, and it can be installed via Anaconda or the Python Package Index (pip). Not only is it well-covered by unit tests to ensure code quality, but it is also accompanied with a detailed documentation, tutorials, examples, and several built-in benchmarking data sets",
    "volume": "main",
    "checked": true,
    "id": "ff4d7042e159833edcd99ea43e1648eb3ac490a8",
    "citation_count": 42
  },
  "https://jmlr.org/papers/v21/19-864.html": {
    "title": "pyDML: A Python Library for Distance Metric Learning",
    "abstract": "pyDML is an open-source python library that provides a wide range of distance metric learning algorithms. Distance metric learning can be useful to improve similarity learning algorithms, such as the nearest neighbors classifier, and also has other applications, like dimensionality reduction. The pyDML package currently provides more than 20 algorithms, which can be categorized, according to their purpose, in: dimensionality reduction algorithms, algorithms to improve nearest neighbors or nearest centroids classifiers, information theory based algorithms or kernel based algorithms, among others. In addition, the library also provides some utilities for the visualization of classifier regions, parameter tuning and a stats website with the performance of the implemented algorithms. The package relies on the scipy ecosystem, it is fully compatible with scikit-learn, and is distributed under GPLv3 license. Source code and documentation can be found at https://github.com/jlsuarezdiaz/pyDML",
    "volume": "main",
    "checked": true,
    "id": "d0026b4dad1f4ac9b422e1fffb8bb6747968f6d0",
    "citation_count": 11
  },
  "https://jmlr.org/papers/v21/19-959.html": {
    "title": "Loss Control with Rank-one Covariance Estimate for Short-term Portfolio Optimization",
    "abstract": "In short-term portfolio optimization (SPO), some financial characteristics like the expected return and the true covariance might be dynamic. Then there are only a small window size $w$ of observations that are sufficiently close to the current moment and reliable to make estimations. $w$ is usually much smaller than the number of assets $d$, which leads to a typical undersampled problem. Worse still, the asset price relatives are not likely subject to any proper distributions. These facts violate the statistical assumptions of the traditional covariance estimates and invalidate their statistical efficiency and consistency in risk measurement. In this paper, we propose to reconsider the function of covariance estimates in the perspective of operators, and establish a rank-one covariance estimate in the principal rank-one tangent space at the observation matrix. Moreover, we propose a loss control scheme with this estimate, which effectively catches the instantaneous risk structure and avoids extreme losses. We conduct extensive experiments on $7$ real-world benchmark daily or monthly data sets with stocks, funds and portfolios from diverse regional markets to show that the proposed method achieves state-of-the-art performance in comprehensive downside risk metrics and gains good investing incomes as well. It offers a novel perspective of rank-related approaches for undersampled estimations in SPO",
    "volume": "main",
    "checked": true,
    "id": "4e80c2a168847aa745c443a8eea3e508f2d54d5d",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v21/20-097.html": {
    "title": "A General Framework for Consistent Structured Prediction with Implicit Loss Embeddings",
    "abstract": "We propose and analyze a novel theoretical and algorithmic framework for structured prediction. While so far the term has referred to discrete output spaces, here we consider more general settings, such as manifolds or spaces of probability measures. We define structured prediction as a problem where the output space lacks a vectorial structure. We identify and study a large class of loss functions that implicitly defines a suitable geometry on the problem. The latter is the key to develop an algorithmic framework amenable to a sharp statistical analysis and yielding efficient computations. When dealing with output spaces with infinite cardinality, a suitable implicit formulation of the estimator is shown to be crucial",
    "volume": "main",
    "checked": true,
    "id": "aa1247cebf4dc9f583b5a7a7c1e4def2d6609ca3",
    "citation_count": 26
  },
  "https://jmlr.org/papers/v21/17-123.html": {
    "title": "Joint Causal Inference from Multiple Contexts",
    "abstract": "The gold standard for discovering causal relations is by means of experimentation. Over the last decades, alternative methods have been proposed that can infer causal relations between variables from certain statistical patterns in purely observational data. We introduce Joint Causal Inference (JCI), a novel approach to causal discovery from multiple data sets from different contexts that elegantly unifies both approaches. JCI is a causal modeling framework rather than a specific algorithm, and it can be implemented using any causal discovery algorithm that can take into account certain background knowledge. JCI can deal with different types of interventions (e.g., perfect, imperfect, stochastic, etc.) in a unified fashion, and does not require knowledge of intervention targets or types in case of interventional data. We explain how several well-known causal discovery algorithms can be seen as addressing special cases of the JCI framework, and we also propose novel implementations that extend existing causal discovery methods for purely observational data to the JCI setting. We evaluate different JCI implementations on synthetic data and on flow cytometry protein expression data and conclude that JCI implementations can considerably outperform state-of-the-art causal discovery algorithms",
    "volume": "main",
    "checked": true,
    "id": "a538e92e2804d39af36e37647af76eff6a1ce5a4",
    "citation_count": 145
  },
  "https://jmlr.org/papers/v21/17-328.html": {
    "title": "General Latent Feature Models for Heterogeneous Datasets",
    "abstract": "Latent variable models allow capturing the hidden structure underlying the data. In particular, feature allocation models represent each observation by a linear combination of latent variables. These models are often used to make predictions either for new observations or for missing information in the original data, as well as to perform exploratory data analysis. Although there is an extensive literature on latent feature allocation models for homogeneous datasets, where all the attributes that describe each object are of the same (continuous or discrete) type, there is no general framework for practical latent feature modeling for heterogeneous datasets. In this paper, we introduce a general Bayesian nonparametric latent feature allocation model suitable for heterogeneous datasets, where the attributes describing each object can be arbitrary combinations of real-valued, positive real-valued, categorical, ordinal and count variables. The proposed model presents several important properties. First, it is suitable for heterogeneous data while keeping the properties of conjugate models, which enables us to develop an inference algorithm that presents linear complexity with respect to the number of objects and attributes per MCMC iteration. Second, the Bayesian nonparametric component allows us to place a prior distribution on the number of features required to capture the latent structure in the data. Third, the latent features in the model are binary-valued, which facilitates the interpretability of the obtained latent features in exploratory data analysis. Finally, a software package, called GLFM toolbox, is made publicly available for other researchers to use and extend. It is available at https://ivaleram.github.io/GLFM/. We show the flexibility of the proposed model by solving both prediction and data analysis tasks on several real-world datasets",
    "volume": "main",
    "checked": true,
    "id": "3c3c359eae5e9ba298f18a6929ff30697f300a22",
    "citation_count": 15
  },
  "https://jmlr.org/papers/v21/18-101.html": {
    "title": "Regularized Gaussian Belief Propagation with Nodes of Arbitrary Size",
    "abstract": "Gaussian belief propagation (GaBP) is a message-passing algorithm that can be used to perform approximate inference on a pairwise Markov graph (MG) constructed from a multivariate Gaussian distribution in canonical parameterization. The output of GaBP is a set of approximate univariate marginals for each variable in the pairwise MG. An extension of GaBP (labeled GaBP-m), allowing for the approximation of higher-dimensional marginal distributions, was explored by Kamper et al. (2019). The idea is to create an MG in which each node is allowed to receive more than one variable. As in the univariate case, the multivariate extension does not necessarily converge in loopy graphs and, even if convergence occurs, is not guaranteed to provide exact inference. To address the problem of convergence, we consider a multivariate extension of the principle of node regularization proposed by Kamper et al. (2018). We label this algorithm slow GaBP-m (sGaBP-m), where the term 'slow' relates to the damping effect of the regularization on the message passing. We prove that, given sufficient regularization, this algorithm will converge and provide the exact marginal means at convergence, regardless of the way variables are assigned to nodes. The selection of the degree of regularization is addressed through the use of a heuristic, which is based on a tree representation of sGaBP-m. As a further contribution, we extend other GaBP variants in the literature to allow for higher-dimensional marginalization. We show that our algorithm compares favorably with these variants, both in terms of convergence speed and inference quality",
    "volume": "main",
    "checked": true,
    "id": "25a2a588715dc3a9995a376728885c9fedc6d10d",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v21/18-402.html": {
    "title": "AI-Toolbox: A C++ library for Reinforcement Learning and Planning (with Python Bindings)",
    "abstract": "This paper describes AI-Toolbox, a C++ software library that contains reinforcement learning and planning algorithms, and supports both single and multi agent problems, as well as partial observability. It is designed for simplicity and clarity, and contains extensive documentation of its API and code. It supports Python to enable users not comfortable with C++ to take advantage of the library's speed and functionality. AI-Toolbox is free software, and is hosted online at https://github.com/Svalorzen/AI-Toolbox",
    "volume": "main",
    "checked": true,
    "id": "0decc164f10ff95596d47a97cd1fc2a5738f7d8f",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v21/18-447.html": {
    "title": "Stochastic Nested Variance Reduction for Nonconvex Optimization",
    "abstract": "We study nonconvex optimization problems, where the objective function is either an average of $n$ nonconvex functions or the expectation of some stochastic function. We propose a new stochastic gradient descent algorithm based on nested variance reduction, namely, Stochastic Nested Variance-Reduced Gradient descent ($\\text{SNVRG}$). Compared with conventional stochastic variance reduced gradient ($\\text{SVRG}$) algorithm that uses two reference points to construct a semi-stochastic gradient with diminishing variance in each iteration, our algorithm uses $K+1$ nested reference points to build a semi-stochastic gradient to further reduce its variance in each iteration. For smooth nonconvex functions, $\\text{SNVRG}$ converges to an $\\epsilon$-approximate first-order stationary point within $\\tilde O(n\\land\\epsilon^{-2}+\\epsilon^{-3}\\land n^{1/2}\\epsilon^{-2})$ number of stochastic gradient evaluations. This improves the best known gradient complexity of $\\text{SVRG}$ $O(n+n^{2/3}\\epsilon^{-2})$ and that of $\\text{SCSG}$ $O(n\\land \\epsilon^{-2}+\\epsilon^{-10/3}\\land n^{2/3}\\epsilon^{-2})$. For gradient dominated functions, $\\text{SNVRG}$ also achieves better gradient complexity than the state-of-the-art algorithms.  \r\n \r\n\r\nBased on $\\text{SNVRG}$, we further propose two algorithms that can find local minima faster than state-of-the-art algorithms in both finite-sum and general stochastic (online) nonconvex optimization. In particular, for finite-sum optimization problems, the proposed $\\text{SNVRG}+\\text{Neon2}^{\\text{finite}}$ algorithm achieves $\\tilde{O}(n^{1/2}\\epsilon^{-2}+n\\epsilon_H^{-3}+n^{3/4}\\epsilon_H^{-7/2})$ gradient complexity to converge to an $(\\epsilon, \\epsilon_H)$-second-order stationary point, which outperforms $\\text{SVRG}+\\text{Neon2}^{\\text{finite}}$ (Allen-Zhu and Li, 2018), the best existing algorithm, in a wide regime. For general stochastic optimization problems, the proposed $\\text{SNVRG}+\\text{Neon2}^{\\text{online}}$ achieves $\\tilde{O}(\\epsilon^{-3}+\\epsilon_H^{-5}+\\epsilon^{-2}\\epsilon_H^{-3})$ gradient complexity, which is better than both $\\text{SVRG}+\\text{Neon2}^{\\text{online}}$ (Allen-Zhu and Li, 2018) and $\\text{Natasha2}$ (Allen-Zhu, 2018a) in certain regimes. Thorough experimental results on different nonconvex optimization problems back up our theory",
    "volume": "main",
    "checked": true,
    "id": "2abacaad34a880919ca6144cf77e962edb7625a6",
    "citation_count": 117
  },
  "https://jmlr.org/papers/v21/18-664.html": {
    "title": "Sparse Projection Oblique Randomer Forests",
    "abstract": "Decision forests, including Random Forests and Gradient Boosting Trees, have recently demonstrated state-of-the-art performance in a variety of machine learning settings. Decision forests are typically ensembles of axis-aligned decision trees; that is, trees that split only along feature dimensions. In contrast, many recent extensions to decision forests  are based on axis-oblique splits. Unfortunately, these extensions forfeit one or more of the favorable properties of decision forests based on axis-aligned splits, such as robustness to many noise dimensions, interpretability, or computational efficiency. We introduce yet another decision forest, called âSparse Projection Oblique Randomer Forestsâ (SPORF). SPORF trees recursively split along very sparse random projections. Our method significantly improves accuracy over existing state-of-the-art algorithms on a standard benchmark suite for classification with $>100$ problems of varying dimension, sample size, and number of classes. To illustrate how SPORF addresses the limitations of both axis-aligned and existing oblique decision forest methods, we conduct extensive simulated experiments. SPORF typically yields improved performance over existing decision forest methods, while mitigating  computational efficiency and scalability and maintaining interpretability. Very sparse random projections can be incorporated into gradient boosted trees to obtain potentially similar gains",
    "volume": "main",
    "checked": true,
    "id": "f0b08c71cc1bce696d9ed3dcfcbef78038afd716",
    "citation_count": 32
  },
  "https://jmlr.org/papers/v21/18-764.html": {
    "title": "Stochastic Conditional Gradient Methods: From Convex Minimization to Submodular Maximization",
    "abstract": "This paper considers stochastic optimization problems for a large class of objective functions, including convex and continuous submodular. Stochastic proximal gradient methods have been widely used to solve such problems; however, their applicability remains limited when the problem dimension is large and the projection onto a convex set is computationally costly. Instead, stochastic conditional gradient algorithms are proposed as an alternative solution which rely on (i) Approximating gradients via a simple averaging technique requiring a single stochastic gradient evaluation per iteration; (ii) Solving a linear program to compute the descent/ascent direction. The gradient averaging technique reduces the noise of gradient approximations as time progresses, and replacing projection step in proximal methods by a linear program lowers the computational complexity of each iteration. We show that under convexity and smoothness assumptions, our proposed stochastic conditional gradient method converges to the optimal objective function value at a sublinear rate of $\\mathcal{O}(1/t^{1/3})$. Further, for a monotone and continuous DR-submodular function and subject to a general convex body constraint, we prove that our proposed method achieves a $((1-1/e)\\text{OPT} -\\epsilon)$ guarantee (in expectation) with   $\\mathcal{O}{(1/\\epsilon^3)}$ stochastic gradient computations. This guarantee matches the known hardness results and closes the gap between deterministic and stochastic continuous submodular maximization. Additionally, we achieve $((1/e)\\text{OPT} -\\epsilon)$ guarantee after operating on $\\mathcal{O}{(1/\\epsilon^3)}$ stochastic gradients for the case that the objective function is continuous DR-submodular but non-monotone and the constraint set is a down-closed convex body. By using stochastic continuous optimization as an interface, we also provide the first $(1-1/e)$ tight approximation guarantee for maximizing  a monotone but stochastic submodular set function subject to a general matroid constraint and $(1/e)$ approximation guarantee for the non-monotone case",
    "volume": "main",
    "checked": true,
    "id": "fd90bb8f78b5b7ab3e13dce8a5212df10ce7932d",
    "citation_count": 97
  },
  "https://jmlr.org/papers/v21/18-790.html": {
    "title": "Quadratic Decomposable Submodular Function Minimization: Theory and Practice",
    "abstract": "We introduce a new convex optimization problem, termed quadratic decomposable submodular function minimization (QDSFM), which allows to model a number of learning tasks on graphs and hypergraphs. The problem exhibits close ties to decomposable submodular function minimization (DSFM) yet is much more challenging to solve. We approach the problem via a new dual strategy and formulate an objective that can be optimized through a number of double-loop algorithms. The outer-loop uses either random coordinate descent (RCD) or alternative projection (AP) methods, for both of which we prove linear convergence rates. The inner-loop computes projections onto cones generated by base polytopes of the submodular functions via the modified min-norm-point or Frank-Wolfe algorithms. We also describe two new applications of QDSFM: hypergraph-adapted PageRank and semi-supervised learning. The proposed hypergraph-based PageRank algorithm can be used for local hypergraph partitioning and comes with provable performance guarantees. For hypergraph-adapted semi-supervised learning, we provide numerical experiments demonstrating the efficiency of our QDSFM solvers and their significant improvements on prediction accuracy when compared to state-of-the-art methods",
    "volume": "main",
    "checked": true,
    "id": "30245218e7e3f22d32c73ee23e31bb3047ff8bba",
    "citation_count": 24
  },
  "https://jmlr.org/papers/v21/18-814.html": {
    "title": "Change Point Estimation in a Dynamic Stochastic Block Model",
    "abstract": "We consider the problem of estimating the location of a single change point in a network generated by a dynamic stochastic block model mechanism. This model produces community structure in the network that exhibits change at a single time epoch. We propose two methods of estimating the change point, together with the model parameters,  before and after its occurrence. The first employs a least-squares criterion function and takes into consideration the full structure of the stochastic block model and is evaluated at each point in time. Hence, as an intermediate step, it requires estimating the community structure based on a clustering algorithm at every time point. The second method comprises the following two steps: in the first one, a least-squares function is used and evaluated at each time point, but ignoring the community structure and only considering a random graph generating mechanism exhibiting a change point. Once the change point is identified, in the second step, all network data before and after it are used together with a clustering algorithm to obtain the corresponding community structures and subsequently estimate the generating stochastic block model parameters. The first method, since it requires knowledge of the community structure and hence clustering at every point in time,  is significantly more computationally expensive than the second one. On the other hand, it requires a significantly less stringent identifiability condition for consistent estimation of the change point and the model parameters than the second method; however, it also requires a condition on the misclassification rate of misallocating network nodes to their respective communities that may fail to hold in many realistic settings. Despite the apparent stringency of the identifiability condition for the second method, we show that networks generated by a stochastic block mechanism exhibiting a change in their structure can easily satisfy this condition under a multitude of scenarios, including merging/splitting communities, nodes joining another community, etc. Further, for both methods under their respective identifiability and certain additional regularity conditions,  we establish rates of convergence and derive the asymptotic distributions of the change point estimators. The results are illustrated on synthetic data. In summary, this work provides an in-depth investigation of the novel problem of change point analysis for networks generated by stochastic block models, identifies key conditions for the consistent estimation of the change point, and proposes a computationally fast algorithm that solves the problem in many settings that occur in applications. Finally, it discusses challenges posed by employing clustering algorithms in this problem, that require additional investigation for their full resolution",
    "volume": "main",
    "checked": true,
    "id": "b2c14aaa0a6dc41e6be1324721893ee5e443e923",
    "citation_count": 32
  },
  "https://jmlr.org/papers/v21/19-095.html": {
    "title": "ThunderGBM: Fast GBDTs and Random Forests on GPUs",
    "abstract": "Gradient Boosting Decision Trees (GBDTs) and Random Forests (RFs) have been used in many real-world applications. They are often a standard recipe for building state-of-the-art solutions to machine learning and data mining problems. However, training and prediction are very expensive computationally for large and high dimensional problems. This article presents an efficient and open source software toolkit called ThunderGBM which exploits the high-performance Graphics Processing Units (GPUs) for GBDTs and RFs. ThunderGBM supports classification, regression and ranking, and can run on single or multiple GPUs of a machine. Our experimental results show that ThunderGBM outperforms the existing libraries while producing similar models, and can handle high dimensional problems where existing GPU-based libraries fail. Documentation, examples, and more details about ThunderGBM are available at https://github.com/xtra-computing/thundergbm",
    "volume": "main",
    "checked": true,
    "id": "d8d3f5e3f41e63b04223b83f3834a3ee3363e9ad",
    "citation_count": 15
  },
  "https://jmlr.org/papers/v21/19-123.html": {
    "title": "Bayesian Model Selection with Graph Structured Sparsity",
    "abstract": "We propose a general algorithmic framework for Bayesian model selection. A spike-and-slab Laplacian prior is introduced to model the underlying structural assumption. Using the notion of effective resistance, we derive an EM-type algorithm with closed-form iterations to efficiently explore possible candidates for Bayesian model selection. The deterministic nature of the proposed algorithm makes it more scalable to large-scale and high-dimensional data sets compared with existing stochastic search algorithms. When applied to sparse linear regression, our framework recovers the EMVS algorithm by RoÄkovÃ¡ and George (2014) as a special case. We also discuss extensions of our framework using tools from graph algebra to incorporate complex Bayesian models such as biclustering and submatrix localization. Extensive simulation studies and real data applications are conducted to demonstrate the superior performance of our methods over its frequentist competitors such as $\\ell_0$ or $\\ell_1$ penalization",
    "volume": "main",
    "checked": true,
    "id": "f272a10238eeb7ef42e521ad0566b51451dd6008",
    "citation_count": 5
  },
  "https://jmlr.org/papers/v21/19-248.html": {
    "title": "ProxSARAH: An Efficient Algorithmic Framework for Stochastic Composite Nonconvex Optimization",
    "abstract": "We propose a new stochastic first-order algorithmic framework to solve stochastic  composite nonconvex optimization problems that covers both finite-sum and expectation settings. Our algorithms rely on the SARAH estimator and consist of two steps: a proximal gradient and an averaging step making them different from existing nonconvex proximal-type algorithms. The algorithms only require an average smoothness assumption of the nonconvex objective term and additional bounded variance assumption if applied to expectation problems. They work with both constant and dynamic step-sizes, while allowing single sample and mini-batches. In all these cases, we prove that our algorithms can achieve the best-known complexity bounds in terms of stochastic first-order oracle. One key step of our methods is the new constant and dynamic step-sizes resulting in the desired complexity bounds while improving practical performance. Our constant step-size is much larger than existing methods including proximal SVRG scheme in the single sample case. We also specify our framework to the non-composite case that covers existing state-of-the-arts in terms of oracle complexity bounds. Our update also allows one to trade-off between step-sizes and mini-batch sizes to improve performance. We test the proposed algorithms on two composite nonconvex problems and neural networks using several well-known data sets",
    "volume": "main",
    "checked": true,
    "id": "0750b8ebd42c79684d859339ba7eeb8b8b4b0dbe",
    "citation_count": 103
  },
  "https://jmlr.org/papers/v21/19-348.html": {
    "title": "MFE: Towards reproducible meta-feature extraction",
    "abstract": "Automated recommendation of machine learning algorithms is receiving a large deal of attention, not only because they can recommend the most suitable algorithms for a new task, but also because they can support efficient hyper-parameter tuning, leading to better machine learning solutions. The automated recommendation can be implemented using meta-learning, learning from previous learning experiences, to create a meta-model able to associate a data set to the predictive performance of machine learning algorithms. Although a large number of publications report the use of meta-learning, reproduction and comparison of meta-learning experiments is a difficult task.  The literature lacks extensive and comprehensive public tools that enable the reproducible investigation of the different meta-learning approaches. An alternative to deal with this difficulty is to develop a meta-feature extractor package with the main characterization measures, following uniform guidelines that facilitate the use and inclusion of new meta-features.  In this paper, we propose two Meta-Feature Extractor (MFE) packages, written in both Python and R, to fill this lack. The packages follow recent frameworks for meta-feature extraction, aiming to facilitate the reproducibility of meta-learning experiments",
    "volume": "main",
    "checked": true,
    "id": "101182ab858ca0c16808cc27622df7db253a3135",
    "citation_count": 46
  },
  "https://jmlr.org/papers/v21/19-428.html": {
    "title": "High-dimensional Linear Discriminant Analysis Classifier for Spiked Covariance Model",
    "abstract": "Linear discriminant analysis (LDA) is a popular classifier that is built on the assumption of common population covariance matrix across classes. The performance of LDA depends heavily on the quality of estimating the mean vectors and the population covariance matrix. This issue becomes more challenging in high-dimensional settings where the number of features is of the same order as the number of training samples. Several techniques for estimating the covariance matrix can be found in the literature. One of the most popular approaches are estimators based on using a regularized sample covariance matrix, giving the name regularized LDA (R-LDA) to the corresponding classifier. These estimators are known to be more resilient to the sample noise than the traditional sample covariance matrix estimator. However, the main challenge of the regularization approach is the choice of the optimal regularization parameter, as an arbitrary choice could lead to severe degradation of the classifier performance. In this work, we propose an improved LDA classifier based on the assumption that the covariance matrix follows a spiked covariance model. The main principle of our proposed technique is the design of a parametrized inverse covariance matrix estimator, the parameters of which are shown to be easily optimized. Numerical simulations, using both real and synthetic data, show that the proposed classifier yields better classification performance than the classical R-LDA while requiring lower computational complexity",
    "volume": "main",
    "checked": true,
    "id": "0a8233c9e52a61b8544c35dbc6a779f08c569924",
    "citation_count": 25
  },
  "https://jmlr.org/papers/v21/19-535.html": {
    "title": "Prediction regions through Inverse Regression",
    "abstract": "Predicting a new response from a covariate is a challenging task in regression, which raises new question since the era of high-dimensional data. In this paper, we are interested in the inverse regression method from a theoretical viewpoint. Theoretical results  for the well-known Gaussian linear model are well-known, but the curse of dimensionality has increased the interest of practitioners and theoreticians into generalization of those results for various estimators, calibrated for the high-dimension context. We propose to focus on  inverse regression. It is known to be  a reliable and efficient approach  when the number of features exceeds the number of observations. Indeed, under some conditions, dealing with the inverse regression problem associated to a forward regression problem drastically reduces the number of parameters to estimate, makes the problem tractable and allows to consider more general distributions, as elliptical distributions.   When both the responses and the covariates are multivariate, estimators constructed by the inverse regression are studied in this paper, the main result being explicit asymptotic prediction regions for the response. The performances of the proposed estimators and prediction regions are also analyzed through a simulation study and compared with usual estimators",
    "volume": "main",
    "checked": true,
    "id": "ec462ee0bb3e7faffcbb85dfd7ca5c32578b6bf5",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v21/19-671.html": {
    "title": "NEVAE: A Deep Generative Model for Molecular Graphs",
    "abstract": "Deep generative models have been praised for their ability to learn smooth latent representations of images, text, and audio, which can then be used to generate new, plausible data. Motivated by these success stories, there has been a surge of interest in developing deep generative models for automated molecule design. However, these models face several difficulties due to the unique characteristics of molecular graphsâtheir underlying structure is not Euclidean or grid-like, they remain isomorphic under permutation of the nodesâ labels, and they come with a different number of nodes and edges. In this paper, we first propose a novel variational autoencoder for molecular graphs, whose encoder and decoder are specially designed to account for the above properties by means of several technical innovations. Moreover, in contrast with the state of the art, our decoder is able to provide the spatial coordinates of the atoms of the molecules it generates. Then, we develop a gradient-based algorithm to optimize the decoder of our model so that it learns to generate molecules that maximize the value of certain property of interest and, given any arbitrary molecule, it is able to optimize the spatial configuration of its atoms for greater stability. Experiments reveal that our variational autoencoder can discover plausible, diverse and novel molecules more effectively than several state of the art models. Moreover, for several properties of interest, our optimized decoder is able to identify molecules with property values 121% higher than those identified by several state of the art methods based on Bayesian optimization and reinforcement learning",
    "volume": "main",
    "checked": true,
    "id": "0c9fc038583b7a6b27772e808c798fcdc10778bc",
    "citation_count": 163
  },
  "https://jmlr.org/papers/v21/19-802.html": {
    "title": "Identifiability and Consistent Estimation of Nonparametric Translation Hidden Markov Models with General State Space",
    "abstract": "This paper considers hidden Markov models where the observations are given as the sum of a latent state which lies in a general state space and some independent noise with unknown distribution. It is shown that these fully nonparametric translation models are identifiable with respect to both the distribution of the latent variables and the distribution of the noise, under mostly a light tail assumption on the latent variables. Two nonparametric estimation methods are proposed and we prove that the corresponding estimators are consistent for the weak convergence topology. These results are illustrated with numerical experiments",
    "volume": "main",
    "checked": true,
    "id": "e757a2f3d19d5542162d3454528625d0206bf4aa",
    "citation_count": 5
  },
  "https://jmlr.org/papers/v21/19-820.html": {
    "title": "GluonTS: Probabilistic and Neural Time Series Modeling in Python",
    "abstract": "We introduce the Gluon Time Series Toolkit (GluonTS), a Python library for deep learning based time series modeling for ubiquitous tasks, such as forecasting and anomaly detection. GluonTS simplifies the time series modeling pipeline by providing the necessary components and tools for quick model development, efficient experimentation and evaluation. In addition, it contains reference implementations of state-of-the-art time series models that enable simple benchmarking of new algorithms",
    "volume": "main",
    "checked": true,
    "id": "16c5cd802cdb64e484fa4c3f6df0b0afd57492d3",
    "citation_count": 97
  },
  "https://jmlr.org/papers/v21/19-874.html": {
    "title": "Regularized Estimation of High-dimensional Factor-Augmented Vector Autoregressive (FAVAR) Models",
    "abstract": "A factor-augmented vector autoregressive (FAVAR) model is defined by a VAR equation that captures lead-lag correlations amongst a set of observed variables $X$ and latent factors $F$, and a calibration equation that relates another set of observed variables $Y$ with $F$ and $X$. The latter equation is used to estimate the factors that are subsequently used in estimating the parameters of the VAR system. The FAVAR model has become popular in applied economic research, since it can summarize a large number of variables of interest as a few factors through the calibration equation and subsequently examine their influence on core variables of primary interest through the VAR equation. However, there is increasing need for examining lead-lag relationships between a large number of time series, while incorporating information from another high-dimensional set of variables. Hence, in this paper we investigate the FAVAR model under high-dimensional scaling. We introduce an  appropriate identification constraint for the model parameters, which when incorporated into the formulated optimization problem yields estimates with good statistical properties. Further, we address a number of technical challenges introduced by the fact that estimates of the VAR system model parameters are based on estimated rather than directly observed quantities. The performance of the proposed estimators is evaluated on synthetic data. Further, the model is applied to commodity prices and reveals interesting and interpretable relationships between the prices and the factors extracted from a set of global macroeconomic indicators",
    "volume": "main",
    "checked": true,
    "id": "cca9a0d674e5484259c8592d1f30e852f3a06095",
    "citation_count": 12
  },
  "https://jmlr.org/papers/v21/20-091.html": {
    "title": "Tslearn, A Machine Learning Toolkit for Time Series Data",
    "abstract": "tslearn is a general-purpose Python machine learning library for time series that offers tools for pre-processing and feature extraction as well as dedicated models for clustering, classification and regression. It follows scikit-learn's Application Programming Interface for transformers and estimators, allowing the use of standard pipelines and model selection tools on top of tslearn objects. It is distributed under the BSD-2-Clause license, and its source code is available at https://github.com/tslearn-team/tslearn",
    "volume": "main",
    "checked": true,
    "id": "80c3c1cb86eeb9f2ab0934d6f914918889d34db7",
    "citation_count": 196
  },
  "https://jmlr.org/papers/v21/13-233.html": {
    "title": "Bayesian Closed Surface Fitting Through Tensor Products",
    "abstract": "Closed surfaces provide a useful model for $3$-d shapes, with the data typically consisting of a cloud of points in $\\mathbb{R}^3$. The existing literature on closed surface modeling focuses on frequentist point estimation methods that join surface patches along the edges, with surface patches created via BÃ©zier surfaces or tensor products of B-splines. However, the resulting surfaces are not smooth along the edges and the geometric constraints required to join the surface patches lead to computational drawbacks. In this article, we develop a Bayesian model for closed surfaces based on tensor products of a cyclic basis resulting in infinitely smooth surface realizations. We impose sparsity on the control points through a double-shrinkage prior. Theoretical properties of the support of our proposed prior are studied and it is shown that the posterior achieves the optimal rate of convergence under reasonable assumptions on the prior. The proposed approach is illustrated with some examples",
    "volume": "main",
    "checked": true,
    "id": "40dd9f2a2274829eb111d2eef80029f13b1772f5",
    "citation_count": 1
  },
  "https://jmlr.org/papers/v21/16-311.html": {
    "title": "A Class of Parallel Doubly Stochastic Algorithms for Large-Scale Learning",
    "abstract": "We consider learning problems over training sets in which both, the number of training examples and the dimension of the feature vectors, are large. To solve these problems we propose the random parallel stochastic algorithm (RAPSA). We call the algorithm random parallel because it utilizes multiple parallel processors to operate on a randomly chosen subset of blocks of the feature vector. RAPSA is doubly stochastic since each processor utilizes a random set of functions to compute the stochastic gradient associated with a randomly chosen sets of variable coordinates. Algorithms that are parallel in either of these dimensions exist, but RAPSA is the first attempt at a methodology that is parallel in both the selection of blocks and the selection of elements of the training set. In RAPSA, processors utilize the randomly chosen functions to compute the stochastic gradient component associated with a randomly chosen block. The technical contribution of this paper is to show that this minimally coordinated algorithm converges to the optimal classifier when the training objective is strongly convex. Moreover, we present an accelerated version of RAPSA (ARAPSA) that incorporates the objective function curvature information by premultiplying the descent direction by a Hessian approximation matrix. We further extend the results for asynchronous settings and show that if the processors perform their updates without any coordination the algorithms are still convergent to the optimal argument. RAPSA and its extensions are then numerically evaluated on a linear estimation problem and a binary image classification task using the MNIST handwritten digit dataset",
    "volume": "main",
    "checked": true,
    "id": "7e21556941de87a50bd89a3f29840e6659f561cb",
    "citation_count": 13
  },
  "https://jmlr.org/papers/v21/18-259.html": {
    "title": "Agnostic Estimation for Phase Retrieval",
    "abstract": "The goal of noisy high-dimensional phase retrieval is to estimate an $s$-sparse parameter $\\boldsymbol{\\beta}^*\\in \\mathbb{R}^d$ from $n$ realizations of the model $Y = (\\mathbf{X}^T \\boldsymbol{\\beta}^*)^2 + \\varepsilon$. Based on this model, we propose a significant semi-parametric generalization called  misspecified phase retrieval (MPR), in which $Y = f(\\mathbf{X}^T \\boldsymbol{\\beta}^*, \\varepsilon)$ with unknown $f$ and $\\operatorname{Cov}(Y, (\\mathbf{X}^T \\boldsymbol{\\beta}^*)^2) > 0$. For example, MPR encompasses $Y = h(|\\mathbf{X}^T \\boldsymbol{\\beta}^*|) + \\varepsilon$ with increasing $h$ as a special case. Despite the generality of the MPR model, it eludes the reach of most existing semi-parametric estimators. In this paper, we propose an estimation procedure, which consists of solving a cascade of two convex programs and provably recovers the direction of $\\boldsymbol{\\beta}^*$. Furthermore, we prove that our procedure is minimax optimal over the class of MPR models. Interestingly, our minimax analysis characterizes the statistical price of misspecifying the link function in phase retrieval models. Our theory is backed up by thorough numerical results",
    "volume": "main",
    "checked": true,
    "id": "ad44bc1277912950eafc611e87c5be3f098c18af",
    "citation_count": 0
  },
  "https://jmlr.org/papers/v21/18-435.html": {
    "title": "Kernel-estimated Nonparametric Overlap-Based Syncytial Clustering",
    "abstract": "Commonly-used clustering algorithms usually find ellipsoidal, spherical or other regular-structured clusters, but are more challenged  when the underlying groups lack formal structure or definition. Syncytial clustering is the name that we introduce for methods that merge groups obtained from standard clustering algorithms in order to reveal complex group structure in the data. Here, we develop a distribution-free fully-automated syncytial clustering algorithm that can be used with $k$-means and other algorithms. Our approach estimates the cumulative distribution function of the normed residuals from an appropriately fit $k$-groups model and calculates  the estimated nonparametric overlap between each pair of clusters. Groups with high pairwise overlap are merged  as long as the estimated generalized overlap decreases. Our methodology is always a top performer in identifying groups with regular and irregular structures in several datasets and can be applied to datasets with scatter or incomplete records. The approach is also used to identify the distinct kinds of gamma ray bursts in the Burst and Transient Source Experiment 4Br catalog and the distinct kinds of activation in a functional Magnetic Resonance Imaging study",
    "volume": "main",
    "checked": true,
    "id": "02988732ac9006eb877b24d7a7f03c6e3dbb07fc",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v21/18-503.html": {
    "title": "Tensor Regression Networks",
    "abstract": "Convolutional neural networks typically consist of many convolutional layers followed by one or more fully connected layers. While convolutional layers map between high-order activation tensors, the fully connected layers operate on flattened activation vectors. Despite empirical success, this approach has notable drawbacks. Flattening followed by fully connected layers discards multilinear structure in the activations and requires many parameters. We address these problems by incorporating tensor algebraic operations that preserve multilinear structure at every layer. First, we introduce Tensor Contraction Layers (TCLs) that reduce the dimensionality of their input while preserving their multilinear structure using tensor contraction. Next, we introduce Tensor Regression Layers (TRLs), which express outputs through a low-rank multilinear mapping from a high-order activation tensor to an output tensor of arbitrary order. We learn the contraction and regression factors end-to-end, and produce accurate nets with fewer parameters. Additionally, our layers regularize networks by imposing low-rank constraints on the activations (TCL) and regression weights (TRL). Experiments on ImageNet show that, applied to VGG and ResNet architectures, TCLs and TRLs reduce the number of parameters compared to fully connected layers by more than 65% while maintaining or increasing accuracy. In addition to the space savings, our approach's ability to leverage topological structure can be crucial for structured data such as MRI. In particular, we demonstrate significant performance improvements over comparable architectures on three tasks associated with the UK Biobank dataset",
    "volume": "main",
    "checked": true,
    "id": "27f9b91bd7c70a99f578c8a5cb52d37e4123da47",
    "citation_count": 106
  },
  "https://jmlr.org/papers/v21/18-514.html": {
    "title": "Fast Bayesian Inference of Sparse Networks with Automatic Sparsity Determination",
    "abstract": "Structure learning of Gaussian graphical models typically involves careful tuning of penalty parameters, which balance the tradeoff between data fidelity and graph sparsity. Unfortunately, this tuning is often a âblack artâ requiring expert experience or brute-force search. It is therefore tempting to develop tuning-free algorithms that can determine the sparsity of the graph adaptively from the observed data in an automatic fashion. In this paper, we propose a novel approach, named BISN (Bayesian inference of Sparse Networks), for automatic Gaussian graphical model selection. Specifically, we regard the off-diagonal entries in the precision matrix as random variables and impose sparse-promoting horseshoe priors on them, resulting in automatic sparsity determination. With the help of stochastic gradients, an efficient variational Bayes algorithm is derived to learn the model. We further propose a decaying recursive stochastic gradient (DRSG) method to reduce the variance of the stochastic gradients and to accelerate the convergence. Our theoretical analysis shows that the time complexity of BISN scales only quadratically with the dimension, whereas the theoretical time complexity of the state-of-the-art methods for automatic graphical model selection is typically a third-order function of the dimension. Furthermore, numerical results show that BISN can achieve comparable or better performance than the state-of-the-art methods in terms of structure recovery, and yet its computational time is several orders of magnitude shorter, especially for large dimensions",
    "volume": "main",
    "checked": true,
    "id": "f9c182bb0c8a4bf1002be1a0f6e1948092b67cf7",
    "citation_count": 4
  },
  "https://jmlr.org/papers/v21/18-527.html": {
    "title": "Optimal Algorithms for Continuous Non-monotone Submodular and DR-Submodular Maximization",
    "abstract": "In this paper we study the fundamental problems of maximizing a continuous non-monotone submodular function over the hypercube, both with and without coordinate-wise concavity. This family of optimization problems has several applications in machine learning, economics, and communication systems. Our main result is the first $\\frac{1}{2}$-approximation algorithm for continuous submodular function maximization; this approximation factor of $\\frac{1}{2}$ is the best possible for algorithms that only query the objective function at polynomially many points.  For the special case of DR-submodular maximization, i.e. when the submodular function is also coordinate-wise concave along all coordinates, we provide a different $\\frac{1}{2}$-approximation algorithm that runs in quasi-linear time. Both these results improve upon prior work (Bian et al. 2017; Soma and Yoshida, 2017). Our first algorithm uses novel ideas such as reducing the guaranteed approximation problem to analyzing a zero-sum game for each coordinate, and incorporates the geometry of this zero-sum game to fix the value at this coordinate. Our second algorithm exploits coordinate-wise concavity to identify a monotone equilibrium condition sufficient for getting the required approximation guarantee, and hunts for the equilibrium point using binary search. We further run experiments to verify the performance of our proposed algorithms in related machine learning applications",
    "volume": "main",
    "checked": true,
    "id": "5cdb1198efc37d4669fc7d26b8e7303a335a05dd",
    "citation_count": 44
  },
  "https://jmlr.org/papers/v21/18-696.html": {
    "title": "Distributed Minimum Error Entropy Algorithms",
    "abstract": "Minimum Error Entropy (MEE) principle is an important approach in Information Theoretical Learning (ITL). It is widely applied and studied in various fields for its robustness to noise. In this paper, we study a reproducing kernel-based distributed MEE algorithm, DMEE, which is designed to work with both fully supervised data and semi-supervised data. The divide-and-conquer approach is employed, so there is no inter-node communication overhead. Similar as other distributed algorithms, DMEE significantly reduces the computational complexity and memory requirement on single computing nodes. With fully supervised data, our proved learning rates equal the minimax optimal learning rates of the classical pointwise kernel-based regressions. Under the semi-supervised learning scenarios, we show that DMEE exploits unlabeled data effectively, in the sense that first, under the settings with weak regularity assumptions, additional unlabeled data significantly improves the learning rates of DMEE. Second, with sufficient unlabeled data, labeled data can be distributed to many more computing nodes, that each node takes only O(1) labels, without spoiling the learning rates in terms of the number of labels. This conclusion overcomes the saturation phenomenon in unlabeled data size. It parallels a recent results for regularized least squares (Lin and Zhou, 2018), and suggests that an inflation of unlabeled data is a solution to the MEE learning problems with decentralized data source for the concerns of privacy protection. Our work refers to pairwise learning and non-convex loss. The theoretical analysis is achieved by distributed U-statistics and error decomposition techniques in integral operators",
    "volume": "main",
    "checked": true,
    "id": "ee65ab0f5b6271ee903780a902971563384da32a",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v21/18-800.html": {
    "title": "Apache Mahout: Machine Learning on Distributed Dataflow Systems",
    "abstract": "Apache Mahout is a library for scalable machine learning (ML) on distributed dataflow systems, offering various implementations of classification, clustering, dimensionality reduction and recommendation algorithms. Mahout was a pioneer in large-scale machine learning in 2008, when it started  and targeted MapReduce, which was the predominant abstraction for scalable computing in industry at that time. Mahout has been widely used by leading web companies and is part of several commercial cloud offerings. In recent years, Mahout migrated to a general framework enabling a mix of dataflow programming and linear algebraic computations on backends such as Apache Spark and Apache Flink. This design allows users to execute data preprocessing and model training in a single, unified dataflow system, instead of requiring a complex integration of several specialized systems. Mahout is maintained as a community-driven open source project at the Apache Software Foundation, and is available under https://mahout.apache.org",
    "volume": "main",
    "checked": true,
    "id": "12ab3f2e959715401410fb45f1af6b878a17702f",
    "citation_count": 11
  },
  "https://jmlr.org/papers/v21/18-807.html": {
    "title": "A Regularization-Based Adaptive Test for High-Dimensional GLMs",
    "abstract": "In spite of its urgent importance in the era of big data, testing high-dimensional parameters in generalized linear models (GLMs) in the presence of high-dimensional nuisance parameters has been largely under-studied, especially with regard to constructing powerful tests for general (and unknown) alternatives. Most existing tests are powerful only against certain alternatives and may yield incorrect Type 1 error rates under high-dimensional nuisance parameter situations. In this paper, we propose the adaptive interaction sum of powered score (aiSPU) test in the framework of penalized regression with a non-convex penalty, called truncated Lasso penalty (TLP), which can maintain correct Type 1 error rates while yielding high statistical power across a wide range of alternatives. To calculate its p-values analytically, we derive its asymptotic null distribution. Via simulations, its superior finite-sample performance is demonstrated over several representative existing methods. In addition, we apply it and other representative tests to an Alzheimer's Disease Neuroimaging Initiative (ADNI) data set, detecting possible gene-gender interactions for Alzheimer's disease. We also put R package âaispuâ implementing the proposed test on GitHub",
    "volume": "main",
    "checked": true,
    "id": "77358f0a89bb3f9b082ebff725ae8ec51a5138d3",
    "citation_count": 1
  },
  "https://jmlr.org/papers/v21/18-808.html": {
    "title": "A General System of Differential Equations to Model First-Order Adaptive Algorithms",
    "abstract": "First-order optimization algorithms play a major role in large scale machine learning. A new class of methods, called adaptive algorithms, was recently introduced to adjust iteratively the learning rate for each coordinate. Despite great practical success in deep learning, their behavior and performance on more general loss functions are not well understood. In this paper, we derive a non-autonomous system of differential equations, which is the continuous-time limit of adaptive optimization methods. We study the convergence of its trajectories and give conditions under which the differential system, underlying all adaptive algorithms, is suitable for optimization. We discuss convergence to a critical point in the non-convex case and give conditions for the dynamics to avoid saddle points and local maxima. For convex loss function, we introduce a suitable Lyapunov functional which allows us to study its rate of convergence. Several other properties of both the continuous and discrete systems are briefly discussed. The differential system studied in the paper is general enough to encompass many other classical algorithms (such as Heavy Ball and Nesterov's accelerated method) and allow us to recover several known results for these algorithms",
    "volume": "main",
    "checked": false,
    "id": "7281b9295da6258faadc990ff4042e51709e9dc1",
    "citation_count": 20
  },
  "https://jmlr.org/papers/v21/19-1035.html": {
    "title": "AI Explainability 360: An Extensible Toolkit for Understanding Data and Machine Learning Models",
    "abstract": "As artificial intelligence algorithms make further inroads in high-stakes societal applications, there are increasing calls from multiple stakeholders for these algorithms to explain their outputs.  To make matters more challenging, different personas of consumers of explanations have different requirements for explanations. Toward addressing these needs, we introduce AI Explainability 360, an open-source Python toolkit featuring ten diverse and state-of-the-art explainability methods and two evaluation metrics. Equally important, we provide a taxonomy to help entities requiring explanations to navigate the space of interpretation and explanation methods, not only those in the toolkit but also in the broader literature on explainability. For data scientists and other users of the toolkit, we have implemented an extensible software architecture that organizes methods according to their place in the AI modeling pipeline.  The toolkit is not only the software, but also guidance material, tutorials, and an interactive web demo to introduce AI explainability to different audiences. Together, our toolkit and taxonomy can help identify gaps where more explainability methods are needed and provide a platform to incorporate them as they are developed",
    "volume": "main",
    "checked": true,
    "id": "037408721e7a79a8ba2c26f82446847d03bd70b9",
    "citation_count": 43
  },
  "https://jmlr.org/papers/v21/19-1015.html": {
    "title": "Convergence of Sparse Variational Inference in Gaussian Processes Regression",
    "abstract": "Gaussian processes are distributions over functions that are versatile and mathematically convenient priors in Bayesian modelling. However, their use is often impeded for data with large numbers of observations, $N$, due to the cubic (in $N$) cost of matrix operations used in exact inference. Many solutions have been proposed that rely on $M \\ll N$ inducing variables to form an approximation at a cost of $\\mathcal{O}\\left(NM^2\\right)$. While the computational cost appears linear in $N$, the true complexity depends on how $M$ must scale with $N$ to ensure a certain quality of the approximation. In this work, we investigate upper and lower bounds on how $M$ needs to grow with $N$ to ensure high quality approximations. We show that we can make the KL-divergence between the approximate model and the exact posterior arbitrarily small for a Gaussian-noise regression model with $M \\ll N$. Specifically, for the popular squared exponential kernel and $D$-dimensional Gaussian distributed covariates, $M = \\mathcal{O}((\\log N)^D)$ suffice and a method with an overall computational cost of $\\mathcal{O}\\left(N(\\log N)^{2D}(\\log \\log N)^2\\right)$ can be used to perform inference",
    "volume": "main",
    "checked": true,
    "id": "d0948ba18d0a24a6fea06f7ee1da0cbc4a5c72b3",
    "citation_count": 37
  },
  "https://jmlr.org/papers/v21/19-346.html": {
    "title": "Monte Carlo Gradient Estimation in Machine Learning",
    "abstract": "This paper is a broad and accessible survey of the methods we have at our disposal for Monte Carlo gradient estimation in machine learning and across the statistical sciences: the problem of computing the gradient of an expectation of a function with respect to parameters defining the distribution that is integrated; the problem of sensitivity analysis. In machine learning research, this gradient problem lies at the core of many learning problems, in supervised, unsupervised and reinforcement learning. We will generally seek to rewrite such gradients in a form that allows for Monte Carlo estimation, allowing them to be easily and efficiently used and analysed. We explore three strategies---the pathwise, score function, and measure-valued gradient estimators---exploring their historical development, derivation, and underlying assumptions. We describe their use in other fields, show how they are related and can be combined, and expand on their possible generalisations. Wherever Monte Carlo gradient estimators have been derived and deployed in the past, important advances have followed. A deeper and more widely-held understanding of this problem will lead to further advances, and it is these advances that we wish to support",
    "volume": "main",
    "checked": true,
    "id": "c7b08c2e69a338e8d0c8444ce081b51caa50b273",
    "citation_count": 251
  },
  "https://jmlr.org/papers/v21/19-359.html": {
    "title": "Gradient Descent for Sparse Rank-One Matrix Completion for Crowd-Sourced Aggregation of Sparsely Interacting Workers",
    "abstract": "We consider worker skill estimation for the single-coin Dawid-Skene crowdsourcing model. In practice, skill-estimation is challenging because worker assignments are sparse and irregular due to the arbitrary and uncontrolled availability of workers. We formulate skill estimation as a rank-one correlation-matrix completion problem, where the observed components correspond to observed label correlation between workers. We show that the correlation matrix can be successfully recovered and skills are identifiable if and only if the sampling matrix (observed components) does not have a bipartite connected component. We then propose a projected gradient descent scheme and show that skill estimates converge to the desired global optima for such sampling matrices. Our proof is original and the results are surprising in light of the fact that even the weighted rank-one matrix factorization problem is NP-hard in general. Next, we derive sample complexity bounds in terms of spectral properties of the  signless Laplacian of the sampling matrix. Our proposed scheme achieves state-of-art performance on a number of real-world datasets",
    "volume": "main",
    "checked": true,
    "id": "a35385317de8580b6e12e51ab53b1e79aa2ec504",
    "citation_count": 22
  },
  "https://jmlr.org/papers/v21/19-470.html": {
    "title": "Probabilistic Learning on Graphs via Contextual Architectures",
    "abstract": "We propose a novel methodology for representation learning on graph-structured data, in which a stack of Bayesian Networks learns different distributions of a vertex's neighbourhood. Through an incremental construction policy and layer-wise training, we can build deeper architectures with respect to typical graph convolutional neural networks, with benefits in terms of context spreading between vertices. First, the model learns from graphs via maximum likelihood estimation without using target labels. Then, a supervised readout is applied to the learned graph embeddings to deal with graph classification and vertex classification tasks, showing competitive results against neural models for graphs. The computational complexity is linear in the number of edges, facilitating learning on large scale data sets. By studying how depth affects the performances of our model, we discover that a broader context generally improves performances. In turn, this leads to a critical analysis of some benchmarks used in literature",
    "volume": "main",
    "checked": true,
    "id": "d2eef675f761fba10f6d820a9310db3d32812954",
    "citation_count": 9
  },
  "https://jmlr.org/papers/v21/19-562.html": {
    "title": "A Unified Framework of Online Learning Algorithms for Training Recurrent Neural Networks",
    "abstract": "We present a framework for compactly summarizing many recent results in efficient and/or biologically plausible online training of recurrent neural networks (RNN). The framework organizes algorithms according to several criteria: (a) past vs. future facing, (b) tensor structure, (c) stochastic vs. deterministic, and (d) closed form vs. numerical. These axes reveal latent conceptual connections among several recent advances in online learning. Furthermore, we provide novel mathematical intuitions for their degree of success. Testing these algorithms on two parametric task families shows that performances cluster according to our criteria. Although a similar clustering is also observed for pairwise gradient alignment, alignment with exact methods does not explain ultimate performance. This suggests the need for better comparison metrics",
    "volume": "main",
    "checked": true,
    "id": "4451d1adf09454c721541d7174535b90ee19c907",
    "citation_count": 45
  },
  "https://jmlr.org/papers/v21/19-636.html": {
    "title": "Convergence Rates for the Stochastic Gradient Descent Method for Non-Convex Objective Functions",
    "abstract": "We prove the convergence to minima and estimates on the rate of convergence for the stochastic gradient descent method in the case of not necessarily locally convex nor contracting objective functions.  In particular, the analysis relies on a quantitative use of mini-batches to control the loss of iterates to non-attracted regions.  The applicability of the results to simple objective functions arising in machine learning is shown",
    "volume": "main",
    "checked": true,
    "id": "e7f728bb85def743320f20df1aa366cb657d803a",
    "citation_count": 61
  },
  "https://jmlr.org/papers/v21/19-650.html": {
    "title": "Contextual Bandits with Continuous Actions: Smoothing, Zooming, and Adapting",
    "abstract": "We study contextual bandit learning with an abstract policy class and continuous action space. We obtain two qualitatively different regret bounds: one competes with a smoothed version of the policy class under no continuity assumptions, while the other requires standard Lipschitz assumptions. Both bounds exhibit data-dependent âzoomingâ behavior and, with no tuning, yield improved guarantees for benign problems. We also study adapting to unknown smoothness parameters, establishing a price-of-adaptivity and deriving optimal adaptive algorithms that require no additional information",
    "volume": "main",
    "checked": true,
    "id": "95c126448c7218adface63db44a63260fb4030aa",
    "citation_count": 51
  },
  "https://jmlr.org/papers/v21/19-678.html": {
    "title": "metric-learn: Metric Learning Algorithms in Python",
    "abstract": "metric-learn is an open source Python package implementing supervised and weakly-supervised distance metric learning algorithms. As part of scikit-learn-contrib, it provides a unified interface compatible with scikit-learn which allows to easily perform cross-validation, model selection, and pipelining with other machine learning estimators. metric-learn is thoroughly tested and available on PyPi under the MIT license",
    "volume": "main",
    "checked": true,
    "id": "104d21985a693332c9bf6d590e5bba7146c0c521",
    "citation_count": 40
  },
  "https://jmlr.org/papers/v21/19-794.html": {
    "title": "Chaining Meets Chain Rule: Multilevel Entropic Regularization and Training of Neural Networks",
    "abstract": "We derive generalization and excess risk bounds for neural networks using a family of complexity measures based on a multilevel relative entropy. The bounds are obtained by introducing the notion of generated hierarchical coverings of neural networks and by using the technique of chaining mutual information introduced by Asadi et al. '18. The resulting bounds are algorithm-dependent and multiscale: they exploit the multilevel structure of neural networks. This, in turn, leads to an empirical risk minimization problem with a multilevel entropic regularization. The minimization problem is resolved by introducing a multiscale extension of the celebrated Gibbs posterior distribution, proving that the derived distribution achieves the unique minimum. This leads to a new training procedure for neural networks with performance guarantees, which exploits the chain rule of relative entropy rather than the chain rule of derivatives (as in backpropagation), and which takes into account the interactions between different scales of the hypothesis sets of neural networks corresponding to different depths of the hidden layers. To obtain an efficient implementation of the latter, we further develop a multilevel Metropolis algorithm simulating the multiscale Gibbs distribution, with an experiment for a two-layer neural network on the MNIST data set",
    "volume": "main",
    "checked": false,
    "id": "8ff0836d79e9a63d5fdfa4c57da67ec98c04edc8",
    "citation_count": 25
  },
  "https://jmlr.org/papers/v21/20-074.html": {
    "title": "Exploring the Limits of Transfer Learning with a Unified Text-to-Text Transformer",
    "abstract": "Transfer learning, where a model is first pre-trained on a data-rich task before being fine-tuned on a downstream task, has emerged as a powerful technique in natural language processing (NLP). The effectiveness of transfer learning has given rise to a diversity of approaches, methodology, and practice. In this paper, we explore the landscape of transfer learning techniques for NLP by introducing a unified framework that converts all text-based language problems into a text-to-text format. Our systematic study compares pre-training objectives, architectures, unlabeled data sets, transfer approaches, and other factors on dozens of language understanding tasks. By combining the insights from our exploration with scale and our new âColossal Clean Crawled Corpusâ, we achieve state-of-the-art results on many benchmarks covering summarization, question answering, text classification, and more. To facilitate future work on transfer learning for NLP, we release our data set, pre-trained models, and code",
    "volume": "main",
    "checked": true,
    "id": "3cfb319689f06bf04c2e28399361f414ca32c4b3",
    "citation_count": 8733
  },
  "https://jmlr.org/papers/v21/20-124.html": {
    "title": "Importance Sampling Techniques for Policy Optimization",
    "abstract": "How can we effectively exploit the collected samples when solving a continuous control task with Reinforcement Learning? Recent results have empirically demonstrated that multiple policy optimization steps can be performed with the same batch by using off-distribution techniques based on importance sampling. However, when dealing with off-distribution optimization, it is essential to take into account the uncertainty introduced by the importance sampling process. In this paper, we propose and analyze a class of model-free, policy search algorithms that extend the recent Policy Optimization via Importance Sampling (Metelli et al., 2018) by incorporating two advanced variance reduction techniques: per-decision and multiple importance sampling. For both of them, we derive a high-probability bound, of independent interest, and then we show how to employ it to define a suitable surrogate objective function that can be used for both action-based and parameter-based settings. The resulting algorithms are finally evaluated on a set of continuous control tasks, using both linear and deep policies, and compared with modern policy optimization methods",
    "volume": "main",
    "checked": true,
    "id": "a4ee74a7e57bfad8199e1794c934c6b263321fde",
    "citation_count": 31
  },
  "https://jmlr.org/papers/v21/19-265.html": {
    "title": "Nesterov's Acceleration for Approximate Newton",
    "abstract": "Optimization plays a key role in machine learning. Recently, stochastic second-order methods have attracted considerable attention because of their low computational cost in each iteration. However, these methods might suffer from poor performance when the Hessian is hard to be approximate well in a computation-efficient way. To overcome this dilemma, we resort to Nesterov's acceleration to improve the convergence performance of these second-order methods and propose accelerated approximate Newton. We give the theoretical convergence analysis of accelerated approximate Newton and show that Nesterov's acceleration can improve the convergence rate. Accordingly, we propose an accelerated regularized sub-sampled Newton (ARSSN) which performs much better than the conventional regularized sub-sampled Newton  empirically and theoretically. Moreover, we show that ARSSN has better performance  than classical first-order methods empirically",
    "volume": "main",
    "checked": true,
    "id": "0ac967deda4739f663707d007b4697794d38eacb",
    "citation_count": 8
  },
  "https://jmlr.org/papers/v21/19-1022.html": {
    "title": "A Data Efficient and Feasible Level Set Method for Stochastic Convex Optimization with Expectation Constraints",
    "abstract": "Stochastic convex optimization problems with expectation constraints (SOECs) are encountered in statistics and machine learning, business, and engineering. The SOEC objective and constraints contain expectations defined with respect to complex distributions or large data sets, leading to high computational complexity when solved by the algorithms that use exact functions and their gradients. Recent stochastic first order methods exhibit low computational complexity when handling SOECs but guarantee near-feasibility and near-optimality only at convergence. These methods may thus return highly infeasible solutions when heuristically terminated, as is often the case, due to theoretical convergence criteria being highly conservative. This issue limits the use of first order methods in several applications where the SOEC constraints encode implementation requirements. We design a stochastic feasible level set method (SFLS) for SOECs that has low complexity and emphasizes feasibility before convergence. Specifically, our level-set method solves a root-finding problem by calling a novel first order oracle that computes a stochastic upper bound on the level-set function by extending mirror descent and online validation techniques. We establish that SFLS maintains a high-probability feasible solution at each root-finding iteration and exhibits favorable complexity compared to state-of-the-art deterministic feasible level set and stochastic subgradient methods. Numerical experiments on three diverse applications highlight how SFLS finds feasible solutions with small optimality gaps with lower complexity than the former approaches",
    "volume": "main",
    "checked": true,
    "id": "43464f03331641ff8c8a54e4cac5fce5d82e8eb5",
    "citation_count": 11
  },
  "https://jmlr.org/papers/v21/19-152.html": {
    "title": "Empirical Priors for Prediction in Sparse High-dimensional Linear Regression",
    "abstract": "In this paper we adopt the familiar sparse, high-dimensional linear regression model and focus on the important but often overlooked task of prediction.  In particular, we consider a new empirical Bayes framework that incorporates data in the prior in two ways: one is to center the prior for the non-zero regression coefficients and the other is to provide some additional regularization.  We show that, in certain settings, the asymptotic concentration of the proposed empirical Bayes posterior predictive distribution is very fast, and we establish a Bernstein--von Mises theorem which ensures that the derived empirical Bayes prediction intervals achieve the targeted frequentist coverage probability.  The empirical prior has a convenient conjugate form, so posterior computations are relatively simple and fast.  Finally, our numerical results demonstrate the proposed method's strong finite-sample performance in terms of prediction accuracy, uncertainty quantification, and computation time compared to existing Bayesian methods",
    "volume": "main",
    "checked": true,
    "id": "c10691d7afebca0576cc06a3611b81b883648c89",
    "citation_count": 15
  },
  "https://jmlr.org/papers/v21/19-1031.html": {
    "title": "Orlicz Random Fourier Features",
    "abstract": "Kernel techniques are among the most widely-applied and influential tools in machine learning with applications at virtually all areas of the field. To combine this expressive power with computational efficiency numerous randomized schemes have been proposed in the literature, among which probably random Fourier features (RFF) are the simplest and most popular. While RFFs were originally designed for the approximation of kernel values, recently they have been adapted to kernel derivatives, and hence to the solution of large-scale tasks involving function derivatives. Unfortunately, the understanding of the RFF scheme for the approximation of higher-order kernel derivatives is quite limited due to the challenging polynomial growing nature of the underlying function class in the empirical process. To tackle this difficulty, we establish a finite-sample deviation bound for a general class of polynomial-growth functions under $\\alpha$-exponential Orlicz condition on the distribution of the sample. Instantiating this result for RFFs, our finite-sample uniform guarantee implies a.s. convergence with tight rate for arbitrary kernel with $\\alpha$-exponential Orlicz spectrum and any order of derivative",
    "volume": "main",
    "checked": true,
    "id": "19aea056bdbe655dff286d328c242784ab0d2870",
    "citation_count": 4
  },
  "https://jmlr.org/papers/v21/17-678.html": {
    "title": "New Insights and Perspectives on the Natural Gradient Method",
    "abstract": "Natural gradient descent is an optimization method traditionally motivated from the perspective of information geometry, and works well for many applications as an alternative to stochastic gradient descent. In this paper we critically analyze this method and its properties, and show how it can be viewed as a type of 2nd-order optimization method, with the Fisher information matrix acting as a substitute for the Hessian. In many important cases, the Fisher information matrix is shown to be equivalent to the Generalized Gauss-Newton matrix, which both approximates the Hessian, but also has certain properties that favor its use over the Hessian. This perspective turns out to have significant implications for the design of a practical and robust natural gradient optimizer, as it motivates the use of techniques like trust regions and Tikhonov regularization. Additionally, we make a series of contributions to the understanding of natural gradient and 2nd-order methods, including: a thorough analysis of the convergence speed of stochastic natural gradient descent (and more general stochastic 2nd-order methods) as applied to convex quadratics, a critical examination of the oft-used 'empirical' approximation of the Fisher matrix, and an analysis of the (approximate) parameterization invariance property possessed by natural gradient methods (which we show also holds for certain other curvature matrices, but notably not the Hessian)",
    "volume": "main",
    "checked": true,
    "id": "189ef6bea81fe8ee3ed3214b9394f7e2027eff98",
    "citation_count": 399
  },
  "https://jmlr.org/papers/v21/18-041.html": {
    "title": "Optimal Convergence for Distributed Learning with Stochastic Gradient Methods and Spectral Algorithms",
    "abstract": "We study generalization properties of distributed algorithms in the setting of nonparametric regression over a reproducing kernel Hilbert space (RKHS). We first investigate distributed stochastic gradient methods (SGM), with mini-batches and multi-passes over the data. We show that optimal generalization error bounds (up to logarithmic factor) can be retained for distributed SGM  provided that the partition level is not too large.  We then extend our results to spectral algorithms (SA), including kernel ridge regression (KRR), kernel principal component regression, and gradient methods.  Our results show that distributed SGM has a smaller theoretical computational complexity, compared with distributed KRR and classic SGM. Moreover, even for a general non-distributed SA, they provide optimal, capacity-dependent convergence rates, for the case that the regression function may not be in the RKHS in the well-conditioned regimes",
    "volume": "main",
    "checked": true,
    "id": "091a0796b1fd2d896295e7bedb7f8c05c2dba9df",
    "citation_count": 18
  },
  "https://jmlr.org/papers/v21/18-083.html": {
    "title": "Local Causal Network Learning for Finding Pairs of Total and Direct Effects",
    "abstract": "In observational studies, it is important to evaluate not only the total effect but also the direct and indirect effects of a treatment variable on a response variable. In terms of local structural learning of causal networks, we try to find all possible pairs of total and direct causal effects, which can further be used to calculate indirect causal effects. An intuitive global learning approach is first to find an essential graph over all variables representing all Markov equivalent causal networks, and then enumerate all equivalent networks and estimate a pair of the total and direct effects for each of them. However, it could be inefficient to learn an essential graph and enumerate equivalent networks when the true causal graph is large. In this paper, we propose a local learning approach instead. In the local learning approach, we first learn locally a chain component containing the treatment. Then, if necessary, we learn locally a chain component containing the response. Next, we locally enumerate all possible pairs of the treatment's parents and the response's parents. Finally based on these pairs, we find all possible pairs of total and direct effects of the treatment on the response",
    "volume": "main",
    "checked": true,
    "id": "55a1c4710cc6257e5d14bd7657027bcad69024ee",
    "citation_count": 4
  },
  "https://jmlr.org/papers/v21/18-211.html": {
    "title": "Distributionally Ambiguous Optimization for Batch Bayesian Optimization",
    "abstract": "We propose a novel, theoretically-grounded, acquisition function for Batch Bayesian Optimization informed by insights from distributionally ambiguous optimization. Our acquisition function is a lower bound on the well-known Expected Improvement function, which requires evaluation of a Gaussian expectation over a multivariate piecewise affine function. Our bound is computed instead by evaluating the best-case expectation over all probability distributions consistent with the same mean and variance as the original Gaussian distribution. Unlike alternative approaches, including Expected Improvement, our proposed acquisition function avoids multi-dimensional integrations entirely, and can be computed exactly - even on large batch sizes - as the solution of a tractable convex optimization problem. Our suggested acquisition function can also be optimized efficiently, since first and second derivative information can be calculated inexpensively as by-products of the acquisition function calculation itself. We derive various novel theorems that ground our work theoretically and we demonstrate superior performance via simple motivating examples, benchmark functions and real-world problems",
    "volume": "main",
    "checked": true,
    "id": "0a26126c99deb8e8405e6dc87fcbb6b30c77d5ad",
    "citation_count": 3
  },
  "https://jmlr.org/papers/v21/18-212.html": {
    "title": "The Kalai-Smorodinsky solution for many-objective Bayesian optimization",
    "abstract": "An ongoing aim of research in multiobjective Bayesian optimization is to extend its applicability to a large number of objectives.  While coping with a limited budget of evaluations, recovering the set of optimal compromise solutions generally requires numerous observations and is less interpretable since this set tends to grow larger with the number of objectives. We thus propose to focus on a specific solution originating from game theory, the Kalai-Smorodinsky solution, which possesses attractive properties. In particular, it ensures equal marginal gains over all objectives. We further make it insensitive to a monotonic transformation of the objectives by considering the objectives in the copula space.  A novel tailored algorithm is proposed to search for the solution, in the form of a Bayesian optimization algorithm: sequential sampling decisions are made based on acquisition functions that derive from an instrumental Gaussian process prior. Our approach is tested on four problems with respectively four, six, eight, and nine objectives. The method is available in the R package GPGame",
    "volume": "main",
    "checked": true,
    "id": "0adf6a03226fcb688e5e31c15f058005632cb8e2",
    "citation_count": 12
  },
  "https://jmlr.org/papers/v21/18-216.html": {
    "title": "Robust Reinforcement Learning with Bayesian Optimisation and Quadrature",
    "abstract": "Bayesian optimisation has been successfully applied to a variety of reinforcement learning problems. However, the traditional approach for learning optimal policies in simulators does not utilise the opportunity to improve learning by adjusting certain environment variables: state features that are unobservable and randomly determined by the environment in a physical setting but are controllable in a simulator. This article considers the problem of finding a robust policy while taking into account the impact of environment variables. We present Alternating Optimisation and Quadrature (ALOQ), which uses Bayesian optimisation and Bayesian quadrature to address such settings. We also present Transferable ALOQ (TALOQ), for settings where simulator inaccuracies lead to difficulty in transferring the learnt policy to the physical system. We show that our algorithms are robust to the presence of significant rare events, which may not be observable under random sampling but play a substantial role in determining the optimal policy. Experimental results across different domains show that our algorithms learn robust policies efficiently",
    "volume": "main",
    "checked": true,
    "id": "0f30e4d903de4a0d3f892c0862b396e2c81fa3a7",
    "citation_count": 0
  },
  "https://jmlr.org/papers/v21/18-487.html": {
    "title": "Dual Iterative Hard Thresholding",
    "abstract": "Iterative Hard Thresholding (IHT) is a popular class of first-order greedy selection methods for loss minimization under cardinality constraint. The existing IHT-style algorithms, however, are proposed for minimizing the primal formulation. It is still an open issue to explore duality theory and algorithms for such a non-convex and NP-hard combinatorial optimization problem. To address this issue, we develop in this article a novel duality theory for $\\ell_2$-regularized empirical risk minimization under cardinality constraint, along with an IHT-style algorithm for dual optimization. Our sparse duality theory establishes a set of sufficient and/or necessary conditions under which the original non-convex problem can be equivalently or approximately solved in a concave dual formulation. In view of this theory, we propose the Dual IHT (DIHT) algorithm  as a super-gradient ascent method to solve the non-smooth dual problem with provable guarantees on primal-dual gap convergence and sparsity recovery. Numerical results confirm our theoretical predictions and demonstrate the superiority of DIHT to the state-of-the-art primal IHT-style algorithms in model estimation accuracy and computational efficiency",
    "volume": "main",
    "checked": true,
    "id": "7ae99efa18f329d121755fd56e956068df4bf9a6",
    "citation_count": 6
  },
  "https://jmlr.org/papers/v21/18-581.html": {
    "title": "Spectral Algorithms for Community Detection in Directed Networks",
    "abstract": "Community detection in large social networks is affected by degree heterogeneity of nodes. The D-SCORE algorithm for directed networks was introduced to reduce this effect by taking the element-wise ratios of the singular vectors of the adjacency matrix before clustering. Meaningful results were obtained for the statistician citation network, but rigorous analysis on its performance was missing. First, this paper  establishes theoretical guarantee for this algorithm and its variants for the directed degree-corrected block model (Directed-DCBM). Second, this paper provides significant improvements for the original D-SCORE algorithms  by attaching the nodes outside of the community cores using the information of the original network instead of the singular vectors",
    "volume": "main",
    "checked": true,
    "id": "0388cb5498241192cc5c0777104a7fc14a7ba108",
    "citation_count": 22
  },
  "https://jmlr.org/papers/v21/18-766.html": {
    "title": "Learning from Binary Multiway Data: Probabilistic Tensor Decomposition and its Statistical Optimality",
    "abstract": "We consider the problem of decomposing a higher-order tensor with binary entries. Such data problems arise frequently in applications such as neuroimaging, recommendation system, topic modeling, and sensor network localization. We propose a multilinear Bernoulli model, develop a rank-constrained likelihood-based estimation method, and obtain the theoretical accuracy guarantees. In contrast to continuous-valued problems, the binary tensor problem exhibits an interesting phase transition phenomenon according to the signal-to-noise ratio. The error bound for the parameter tensor estimation is established, and we show that the obtained rate is minimax optimal under the considered model. Furthermore, we develop an alternating optimization algorithm with convergence guarantees. The efficacy of our approach is demonstrated through both simulations and analyses of multiple data sets on the tasks of tensor completion and clustering",
    "volume": "main",
    "checked": true,
    "id": "acb27d98fb6242ec45a3fdbe864fd71d81c01678",
    "citation_count": 27
  },
  "https://jmlr.org/papers/v21/19-073.html": {
    "title": "Estimate Sequences for Stochastic Composite Optimization: Variance Reduction, Acceleration, and Robustness to Noise",
    "abstract": "In this paper, we propose a unified view of gradient-based algorithms for stochastic convex composite optimization by extending the concept of estimate sequence introduced by Nesterov. More precisely, we interpret a large class of stochastic optimization methods as procedures that iteratively minimize a surrogate of the objective, which covers the stochastic gradient descent method and variants of the incremental approaches SAGA, SVRG, and MISO/Finito/SDCA. This point of view has several advantages: (i) we provide a simple generic proof of convergence for all of the aforementioned methods; (ii) we naturally obtain new algorithms with the same guarantees; (iii) we derive generic strategies to make these algorithms robust to stochastic noise, which is useful when data is corrupted by small random perturbations. Finally, we propose a new accelerated stochastic gradient descent algorithm and a new accelerated SVRG algorithm that is robust to stochastic noise",
    "volume": "main",
    "checked": true,
    "id": "8fdba3debf237d6ba1292176ef0361b5c73b0b50",
    "citation_count": 44
  },
  "https://jmlr.org/papers/v21/19-161.html": {
    "title": "Asymptotic Consistency of $\\alpha$-{R}\\'enyi-Approximate Posteriors",
    "abstract": "We study the asymptotic consistency properties of $\\alpha$-{R}\\'enyi approximate posteriors, a class of variational Bayesian methods that approximate an intractable Bayesian posterior with a member of a tractable family of distributions, the member chosen to minimize the $\\alpha$-{R}\\'enyi divergence from the true posterior. Unique to our work is that we consider settings with $\\alpha > 1$, resulting in approximations that upperbound the log-likelihood, and consequently have wider spread than traditional variational approaches that minimize the Kullback-Liebler (KL) divergence from the posterior. Our primary result identifies sufficient conditions under which consistency holds, centering around the existence of a `good' sequence of distributions in the approximating family that possesses, among other properties, the right rate of convergence to a limit distribution. We further characterize the good sequence by demonstrating that a sequence of distributions that converges too quickly cannot be a good sequence. We also extend our analysis to the setting where $\\alpha$ equals one, corresponding to the minimizer of the reverse KL divergence, and to models with local latent variables. We also illustrate the existence of a good sequence with a number of examples. Our results complement a growing body of work focused on the frequentist properties of variational Bayesian methods",
    "volume": "main",
    "checked": false,
    "id": "c6c665aadf46ddc667d4775bde9e9f24c21b3f90",
    "citation_count": 6
  },
  "https://jmlr.org/papers/v21/19-222.html": {
    "title": "Streamlined Variational Inference with Higher Level Random Effects",
    "abstract": "We derive and present explicit algorithms to facilitate streamlined computing for variational inference for models containing higher level random effects. Existing literature is such that streamlined variational inference is restricted to mean field variational Bayes algorithms for two-level random effects models. Here we provide the following extensions: (1) explicit Gaussian response mean field variational Bayes algorithms for three-level models, (2) explicit algorithms for the alternative variational message passing approach in the case of two-level and three-level models, and (3) an explanation of how arbitrarily high levels of nesting can be handled based on the recently published matrix algebraic results of the authors. A pay-off from (2) is simple extension to non-Gaussian response models. In summary, we remove barriers for streamlining variational inference algorithms based on either the mean field variational Bayes approach or the variational message passing approach when higher level random effects are present",
    "volume": "main",
    "checked": true,
    "id": "de2d3023bf7a6c3997977bc47a639c8b71c0cede",
    "citation_count": 2
  },
  "https://jmlr.org/papers/v21/19-318.html": {
    "title": "Learning Big Gaussian Bayesian Networks: Partition, Estimation and Fusion",
    "abstract": "Structure learning of Bayesian networks has always been a challenging problem. Nowadays, massive-size networks with thousands or more of nodes but fewer samples frequently appear in many areas. We develop a divide-and-conquer framework, called partition-estimation-fusion (PEF), for structure learning of such big networks. The proposed method first partitions nodes into clusters, then learns a subgraph on each cluster of nodes, and finally fuses all learned subgraphs into one Bayesian network. The PEF method is designed in a flexible way so that any structure learning method may be used in the second step to learn a subgraph structure as either a DAG or a CPDAG. In the clustering step, we adapt hierarchical clustering to automatically choose a proper number of clusters. In the fusion step, we propose a novel hybrid method that sequentially adds edges between subgraphs. Extensive numerical experiments demonstrate the competitive performance of our PEF method, in terms of both speed and accuracy compared to existing methods. Our method can improve the accuracy of structure learning by 20% or more, while reducing running time up to two orders-of-magnitude",
    "volume": "main",
    "checked": false,
    "id": "5dbfbfc000a513ebb0ac3ee486238e406fff9126",
    "citation_count": 7
  },
  "https://jmlr.org/papers/v21/19-368.html": {
    "title": "Generating Weighted MAX-2-SAT Instances with Frustrated Loops: an RBM Case Study",
    "abstract": "Many optimization problems can be cast into the maximum satisfiability (MAX-SAT) form, and many solvers have been developed for tackling such problems. To evaluate a MAXSAT solver, it is convenient to generate hard MAX-SAT instances with known solutions. Here, we propose a method of generating weighted MAX-2-SAT instances inspired by the frustrated-loop algorithm used by the quantum annealing community. We extend the algorithm for instances of general bipartite couplings, with the associated optimization problem being the minimization of the restricted Boltzmann machine (RBM) energy over the nodal values, which is useful for effectively pre-training the RBM. The hardness of the generated instances can be tuned through a central parameter known as the frustration index. Two versions of the algorithm are presented: the random- and structured-loop algorithms. For the random-loop algorithm, we provide a thorough theoretical and empirical analysis on its mathematical properties from the perspective of frustration, and observe empirically a double phase transition behavior in the hardness scaling behavior driven by the frustration index. For the structured-loop algorithm, we show that it offers an improvement in hardness over the random-loop algorithm in the regime of high loop density, with the variation of hardness tunable through the concentration of frustrated weights",
    "volume": "main",
    "checked": true,
    "id": "566063223c2d75c09327770d8f532244f74dbe57",
    "citation_count": 1
  },
  "https://jmlr.org/papers/v21/19-462.html": {
    "title": "Generative Adversarial Nets for Robust Scatter Estimation: A Proper Scoring Rule Perspective",
    "abstract": "Robust covariance matrix estimation is a fundamental task in statistics. The recent discovery on the connection between robust estimation and generative adversarial nets (GANs) suggests that it is possible to compute depth-like robust estimators using similar techniques that optimize GANs. In this paper, we introduce a general learning via classification framework based on the notion of proper scoring rules. This framework allows us to understand both matrix depth function, a technique of rate-optimal robust estimation, and various  GANs through the lens of variational approximations of $f$-divergences induced by proper scoring rules. We then propose a new class of robust covariance matrix estimators in this framework by carefully constructing discriminators with appropriate neural network structures. These estimators are proved to achieve the minimax rate of covariance matrix estimation under Huber's contamination model. The results are also extended to robust scatter estimation for elliptical distributions. Our numerical results demonstrate the good performance of the proposed procedures under various settings against competitors in the literature",
    "volume": "main",
    "checked": true,
    "id": "e8b5fba4bde532e468a4ba21ffdca4288d676ce6",
    "citation_count": 19
  },
  "https://jmlr.org/papers/v21/19-467.html": {
    "title": "apricot: Submodular selection for data summarization in Python",
    "abstract": "We present apricot, an open source Python package for selecting representative subsets from large data sets using submodular optimization. The package implements several efficient greedy selection algorithms that offer strong theoretical guarantees on the quality of the selected set. Additionally, several submodular set functions are implemented, including facility location, which is broadly applicable but requires memory quadratic in the number of examples in the data set, and a feature-based function that is less broadly applicable but can scale to millions of examples. Apricot is extremely efficient, using both algorithmic speedups such as the lazy greedy algorithm and memoization as well as code optimization using numba. We demonstrate the use of subset selection by training machine learning models to comparable accuracy using either the full data set or a representative subset thereof. This paper presents an explanation of submodular selection, an overview of the features in apricot, and applications to two data sets",
    "volume": "main",
    "checked": true,
    "id": "729d7b69c8fbe40f585fa9b617f00d2960430681",
    "citation_count": 24
  },
  "https://jmlr.org/papers/v21/19-505.html": {
    "title": "Regression with Comparisons: Escaping the Curse of Dimensionality with Ordinal Information",
    "abstract": "In supervised learning, we typically leverage a fully labeled dataset to design methods for function estimation or prediction. In many practical situations, we are able to obtain alternative feedback, possibly at a low cost. A broad goal is to understand the usefulness of, and to design algorithms to exploit, this alternative feedback. In this paper, we consider a semi-supervised regression setting, where we obtain additional ordinal (or comparison) information for the unlabeled samples. We consider ordinal feedback of varying qualities where we have either a perfect ordering of the samples, a noisy ordering of the samples or noisy pairwise comparisons between the samples. We provide a precise quantification of the usefulness of these types of ordinal feedback in both nonparametric and linear regression, showing that in many cases it is possible to accurately estimate an underlying function with a very small labeled set, effectively escaping the curse of dimensionality. We also present lower bounds, that establish fundamental limits for the task and show that our algorithms are optimal in a variety of settings. Finally, we present extensive experiments on new datasets that demonstrate the efficacy and practicality of our algorithms and investigate their robustness to various sources of noise and model misspecification",
    "volume": "main",
    "checked": false,
    "id": "588222a89edaa3bfda4fd2f9012d09adf0bc14f9",
    "citation_count": 11
  },
  "https://jmlr.org/papers/v21/19-524.html": {
    "title": "Trust-Region Variational Inference with Gaussian Mixture Models",
    "abstract": "Many methods for machine learning rely on approximate inference from intractable probability distributions. Variational inference approximates such distributions by tractable models that can be subsequently used for approximate inference. Learning sufficiently accurate approximations requires a rich model family and careful exploration of the relevant modes of the target distribution. We propose a method for learning accurate GMM approximations of intractable probability distributions based on insights from policy search by using information-geometric trust regions for principled exploration. For efficient improvement of the GMM approximation, we derive a lower bound on the corresponding optimization objective enabling us to update the components independently. Our use of the lower bound ensures convergence to a stationary point of the original objective. The number of components is adapted online by adding new components in promising regions and by deleting components with negligible weight. We demonstrate on several domains that we can learn approximations of complex, multimodal distributions with a quality that is unmet by previous variational inference methods, and that the GMM approximation can be used for drawing samples that are on par with samples created by state-of-the-art MCMC samplers while requiring up to three orders of magnitude less computational resources",
    "volume": "main",
    "checked": true,
    "id": "f935dc8e4303d1f4f761349d97ab0f95321a8568",
    "citation_count": 15
  },
  "https://jmlr.org/papers/v21/19-560.html": {
    "title": "Cramer-Wold Auto-Encoder",
    "abstract": "The computation of the distance to the true distribution is a key component of most state-of-the-art generative models. Inspired by prior works on the Sliced-Wasserstein Auto-Encoders (SWAE) and the Wasserstein Auto-Encoders with MMD-based penalty (WAE-MMD), we propose a new generative model - a Cramer-Wold Auto-Encoder (CWAE). A fundamental component of CWAE is the characteristic kernel, the construction of which is one of the goals of this paper, from here on referred to as the Cramer-Wold kernel. Its main distinguishing feature is that it has a closed-form of the kernel product of radial Gaussians. Consequently, CWAE model has a~closed-form for the distance between the posterior and the normal prior, which simplifies the optimization procedure by removing the need to sample in order to compute the loss function. At the same time, CWAE performance often improves upon WAE-MMD and SWAE on standard benchmarks",
    "volume": "main",
    "checked": true,
    "id": "cb256eeb2d2d2134003fae62d0c9150d962ef808",
    "citation_count": 14
  },
  "https://jmlr.org/papers/v21/19-755.html": {
    "title": "Complete Dictionary Learning via L4-Norm Maximization over the Orthogonal Group",
    "abstract": "This paper considers the fundamental problem of learning a complete (orthogonal) dictionary from samples of sparsely generated signals. Most existing methods solve the dictionary (and sparse representations) based on heuristic algorithms, usually without theoretical guarantees for either optimality or complexity. The recent $\\ell^1$-minimization based methods do provide such guarantees but the associated algorithms recover the dictionary one column at a time. In this work, we propose a new formulation that maximizes the $\\ell^4$-norm over the orthogonal group, to learn the entire dictionary. We prove that under a random data model, with nearly minimum sample complexity, the global optima of the $\\ell^4$-norm are very close to signed permutations of the ground truth. Inspired by this observation, we give a conceptually simple and yet effective algorithm based on matching, stretching, and projection (MSP). The algorithm provably converges locally and cost per iteration is merely an SVD. In addition to strong theoretical guarantees, experiments show that the new algorithm is significantly more efficient and effective than existing methods, including KSVD and $\\ell^1$-based methods. Preliminary experimental results on mixed real imagery data clearly demonstrate advantages of so learned dictionary over classic PCA bases",
    "volume": "main",
    "checked": false,
    "id": "f9d7dbb8372d563b29065cb30cb624a366f0e461",
    "citation_count": 50
  },
  "https://jmlr.org/papers/v21/19-777.html": {
    "title": "High Dimensional Forecasting via Interpretable Vector Autoregression",
    "abstract": "Vector autoregression (VAR) is a fundamental tool for modeling multivariate time series.  However, as the number of component series is increased, the VAR model becomes overparameterized.  Several authors have addressed this issue by incorporating regularized approaches, such as the lasso in VAR estimation. Traditional approaches address overparameterization by selecting a low lag order, based on the assumption of short range dependence, assuming that a universal lag order applies to all components.  Such an approach constrains the relationship between the components and impedes forecast performance.  The lasso-based approaches perform much better in high-dimensional situations but do not incorporate the notion of lag order selection. We propose a new class of hierarchical lag structures (HLag) that embed the notion of lag selection into a convex regularizer. The key modeling tool is a group lasso with nested groups which guarantees that the sparsity pattern of lag coefficients honors the VAR's ordered structure.  The proposed HLag framework offers three basic structures, which allow for varying levels of flexibility, with many possible generalizations.  A simulation study demonstrates improved performance in forecasting and lag order selection over previous approaches, and macroeconomic, financial, and energy applications further highlight forecasting improvements as well as HLag's convenient, interpretable output",
    "volume": "main",
    "checked": true,
    "id": "3bbebd253bdba7ee961a249529dd0ed4f2abbb9f",
    "citation_count": 72
  },
  "https://jmlr.org/papers/v21/19-827.html": {
    "title": "Double Reinforcement Learning for Efficient Off-Policy Evaluation in Markov Decision Processes",
    "abstract": "Off-policy evaluation (OPE) in reinforcement learning allows one to evaluate novel decision policies without needing to conduct exploration, which is often costly or otherwise infeasible. We consider for the first time the semiparametric efficiency limits of OPE in Markov decision processes (MDPs), where actions, rewards, and states are memoryless. We show existing OPE estimators may fail to be efficient in this setting. We develop a new estimator based on cross-fold estimation of $q$-functions and marginalized density ratios, which we term double reinforcement learning (DRL). We show that DRL is efficient when both components are estimated at fourth-root rates and is also doubly robust when only one component is consistent. We investigate these properties empirically and demonstrate the performance benefits due to harnessing memorylessness",
    "volume": "main",
    "checked": true,
    "id": "25a7b8c2e110a1bcd5c42ab5de55a0c08b0b8846",
    "citation_count": 122
  },
  "https://jmlr.org/papers/v21/19-833.html": {
    "title": "Convex and Non-Convex Approaches for Statistical Inference with Class-Conditional Noisy Labels",
    "abstract": "We study the problem of estimation and testing in logistic regression with class-conditional noise in the observed labels, which has an important implication in the Positive-Unlabeled (PU) learning setting. With the key observation that the label noise problem belongs to a special sub-class of generalized linear models (GLM), we discuss convex and non-convex approaches that address this problem. A non-convex approach based on the maximum likelihood estimation produces an estimator with several optimal properties, but a convex approach has an obvious advantage in optimization. We demonstrate that in the low-dimensional setting, both estimators are consistent and asymptotically normal, where the asymptotic variance of the non-convex estimator is smaller than the convex counterpart. We also quantify the efficiency gap which provides insight into when the two methods are comparable. In the high-dimensional setting, we show that both estimation procedures achieve $\\ell_2$-consistency at the minimax optimal $\\sqrt{s\\log p/n}$ rates under mild conditions. Finally, we propose an inference procedure using a de-biasing approach. We validate our theoretical findings through simulations and a real-data example",
    "volume": "main",
    "checked": true,
    "id": "4c90a6776ca69f001c671fe5ecc4e88000c65234",
    "citation_count": 3
  },
  "https://jmlr.org/papers/v21/19-844.html": {
    "title": "The Optimal Ridge Penalty for Real-world High-dimensional Data Can Be Zero or Negative due to the Implicit Ridge Regularization",
    "abstract": "A conventional wisdom in statistical learning is that large models require strong regularization to prevent overfitting. Here we show that this rule can be violated by  linear regression in the underdetermined $n\\ll p$ situation under realistic conditions. Using simulations and real-life high-dimensional datasets, we demonstrate that an explicit positive ridge penalty can fail to provide any improvement over the minimum-norm least squares estimator. Moreover, the optimal value of ridge penalty in this situation can be negative. This happens when the high-variance directions in the predictor space can predict the response variable, which is often the case in the real-world high-dimensional data. In this regime, low-variance directions provide an implicit ridge regularization and can make any further positive ridge penalty detrimental. We prove that augmenting any linear model with random covariates and using minimum-norm estimator is asymptotically equivalent to adding the ridge penalty. We use a spiked covariance model as an analytically tractable example and prove that the optimal ridge penalty in this case is negative when $n\\ll p$",
    "volume": "main",
    "checked": true,
    "id": "2e70943d1bca4b53445c7e1146413bd711000320",
    "citation_count": 57
  },
  "https://jmlr.org/papers/v21/19-872.html": {
    "title": "Rationally Inattentive Inverse Reinforcement Learning Explains YouTube Commenting Behavior",
    "abstract": "We consider a novel application of inverse reinforcement learning with behavioral economics constraints to model, learn and predict the commenting behavior of YouTube viewers. Each group of users is modeled as a rationally inattentive Bayesian agent which solves a contextual bandit problem. Our methodology integrates three key components. First, to identify distinct commenting patterns, we use deep embedded clustering to estimate framing information (essential extrinsic  features) that clusters users into distinct groups. Second, we present an inverse reinforcement learning algorithm that uses Bayesian revealed preferences to test for rationality: does there exist a utility function that rationalizes the given data, and if yes, can it be used to predict commenting behavior? Finally, we impose behavioral economics constraints stemming from rational inattention to characterize the attention span of groups of users. The test imposes a Renyi mutual information cost constraint which impacts how the agent can select attention strategies to maximize their expected utility. After a careful analysis of a massive YouTube dataset, our surprising result is that in most YouTube user groups, the commenting behavior is consistent with optimizing a Bayesian utility with rationally inattentive constraints. The paper also highlights how the rational inattention model can accurately predict commenting behavior. The massive YouTube dataset and analysis used in this paper are available on GitHub and completely reproducible",
    "volume": "main",
    "checked": true,
    "id": "bec74d59a376f609402a69be6af43de8c0c4563a",
    "citation_count": 20
  },
  "https://jmlr.org/papers/v21/19-905.html": {
    "title": "Randomization as Regularization: A Degrees of Freedom Explanation for Random Forest Success",
    "abstract": "Random forests remain among the most popular off-the-shelf supervised machine learning tools with a well-established track record of predictive accuracy in both regression and classification settings.  Despite their empirical success as well as a bevy of recent work investigating their statistical properties, a full and satisfying explanation for their success has yet to be put forth. Here we aim to take a step forward in this direction by demonstrating that the additional randomness injected into individual trees serves as a form of implicit regularization, making random forests an ideal model in low signal-to-noise ratio (SNR) settings. Specifically, from a model-complexity perspective, we show that the mtry parameter in random forests serves much the same purpose as the shrinkage penalty in explicitly regularized regression procedures like lasso and ridge regression.  To highlight this point, we design a randomized linear-model-based forward selection procedure intended as an analogue to tree-based random forests and demonstrate its surprisingly strong empirical performance.  Numerous demonstrations on both real and synthetic data are provided",
    "volume": "main",
    "checked": true,
    "id": "0386d90efab8654a58cd168bc73d86d0a3ee7ac7",
    "citation_count": 34
  },
  "https://jmlr.org/papers/v21/19-993.html": {
    "title": "Krylov Subspace Method for Nonlinear Dynamical Systems with Random Noise",
    "abstract": "Operator-theoretic analysis of nonlinear dynamical systems has attracted much attention in a variety of engineering and scientific fields, endowed with practical estimation methods using data such as dynamic mode decomposition. In this paper, we address a lifted representation of nonlinear dynamical systems with random noise based on transfer operators, and develop a novel Krylov subspace method for estimating the operators using finite data, with consideration of the unboundedness of operators. For this purpose, we first consider Perron-Frobenius operators with kernel-mean embeddings for such systems. We then extend the Arnoldi method, which is the most classical type of Kryov subspace methods, so that it can be applied to the current case. Meanwhile, the Arnoldi method requires the assumption that the operator is bounded, which is not necessarily satisfied for transfer operators on nonlinear systems. We accordingly develop the shift-invert Arnoldi method for Perron-Frobenius operators to avoid this problem. Also, we describe an approach of evaluating predictive accuracy by estimated operators on the basis of the maximum mean discrepancy, which is applicable, for example, to anomaly detection in complex systems. The empirical performance of our methods is investigated using synthetic and real-world healthcare data",
    "volume": "main",
    "checked": true,
    "id": "83cc7061241f7aab12ba3e3a10e0b4759e2ac270",
    "citation_count": 15
  }
}