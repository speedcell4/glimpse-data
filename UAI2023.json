{
  "https://proceedings.mlr.press/v216/abu-el-haija23a.html": {
    "title": "SubMix: Learning to Mix Graph Sampling Heuristics",
    "abstract": "Sampling subgraphs for training Graph Neural Networks (GNNs) is receiving much attention from the GNN community. While a variety of methods have been proposed, each method samples the graph according to its own heuristic. However, there has been little work in mixing these heuristics in an end-to-end trainable manner. In this work, we design a generative framework for graph sampling. Our method, SubMix, parameterizes subgraph sampling as a convex combination of heuristics. We show that a continuous relaxation of the discrete sampling process allows us to efficiently obtain analytical gradients for training the sampling parameters. Our experimental results illustrate the usefulness of learning graph sampling in three scenarios: (1) robust training of GNNs by automatically learning to discard noisy edge sources; (2) improving model performance by trainable and online edge subset selection; and (3) by integrating our framework into decoupled GNN models improves their performance on standard benchmarks",
    "volume": "main",
    "checked": false,
    "id": "61cd4c25ba17132a61a0a757b0b3bcef2bd27a7c",
    "citation_count": 11
  },
  "https://proceedings.mlr.press/v216/achituve23a.html": {
    "title": "Guided Deep Kernel Learning",
    "abstract": "Combining Gaussian processes with the expressive power of deep neural networks is commonly done nowadays through deep kernel learning (DKL). Unfortunately, due to the kernel optimization process, this often results in losing their Bayesian benefits. In this study, we present a novel approach for learning deep kernels by utilizing infinite-width neural networks. We propose to use the Neural Network Gaussian Process (NNGP) model as a guide to the DKL model in the optimization process. Our approach harnesses the reliable uncertainty estimation of the NNGPs to adapt the DKL target confidence when it encounters novel data points. As a result, we get the best of both worlds, we leverage the Bayesian behavior of the NNGP, namely its robustness to overfitting, and accurate uncertainty estimation, while maintaining the generalization abilities, scalability, and flexibility of deep kernels. Empirically, we show on multiple benchmark datasets of varying sizes and dimensionality, that our method is robust to overfitting, has good predictive performance, and provides reliable uncertainty estimations",
    "volume": "main",
    "checked": true,
    "id": "0862d142b965ac42780dbec3f9f75819db78ebe4",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/adamczyk23a.html": {
    "title": "Bounding the optimal value function in compositional reinforcement learning",
    "abstract": "In the field of reinforcement learning (RL), agents are often tasked with solving a variety of problems differing only in their reward functions. In order to quickly obtain solutions to unseen problems with new reward functions, a popular approach involves functional composition of previously solved tasks. However, previous work using such functional composition has primarily focused on specific instances of composition functions, whose limiting assumptions allow for exact zero-shot composition. Our work unifies these examples and provides a more general framework for compositionality in both standard and entropy-regularized RL. We find that, for a broad class of functions, the optimal solution for the composite task of interest can be related to the known primitive task solutions. Specifically, we present double-sided inequalities relating the optimal composite value function to the value functions for the primitive tasks. We also show that the regret of using a zero-shot policy can be bounded for this class of functions. The derived bounds can be used to develop clipping approaches for reducing uncertainty during training, allowing agents to quickly adapt to new tasks",
    "volume": "main",
    "checked": true,
    "id": "0ea833864776f5e10b449770c87f33147a9331c3",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/agarwal23a.html": {
    "title": "A decoder suffices for query-adaptive variational inference",
    "abstract": "Deep generative models like variational autoencoders (VAEs) are widely used for density estimation and dimensionality reduction, but infer latent representations via amortized inference algorithms, which require that all data dimensions are observed. VAEs thus lack a key strength of probabilistic graphical models: the ability to infer posteriors for test queries with arbitrary structure. We demonstrate that many prior methods for imputation with VAEs are costly and ineffective, and achieve superior performance via query-adaptive variational inference (QAVI) algorithms based directly on the generative decoder.  By analytically marginalizing arbitrary sets of missing features, and optimizing expressive posteriors including mixtures and density flows, our non-amortized QAVI algorithms achieve excellent performance while avoiding expensive model retraining. On standard image and tabular datasets, our approach substantially outperforms prior methods in the plausibility and diversity of imputations.  We also show that QAVI effectively generalizes to recent hierarchical VAE models for high-dimensional images",
    "volume": "main",
    "checked": true,
    "id": "3d3359ed373ec13aed37784bca7990e06009ff89",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/alam23a.html": {
    "title": "FLASH: Automating federated learning using CASH",
    "abstract": "In this paper, we present FLASH, a framework which addresses for the first time the central AutoML problem of Combined Algorithm Selection and HyperParameter (HP) Optimization (CASH) in the context of Federated Learning (FL). To limit training cost, FLASH incrementally adapts the set of algorithms to train based on their projected loss rates, while supporting decentralized (federated) implementation of the embedded hyper-parameter optimization (HPO), model selection and loss calculation problems. We provide a theoretical analysis of the training and validation loss under FLASH, and their tradeoff with the training cost measured as the data wasted in training sub-optimal algorithms. The bounds depend on the degree of dissimilarity between the datasets of the clients, a result of FL restriction that client datasets remain private. Through extensive experimental investigation on several datasets, we evaluate three variants of FLASH, and show that FLASH performs close to centralized CASH methods",
    "volume": "main",
    "checked": false,
    "id": "f0a8bbae81554f8ccec0108eaef1641f960113fc",
    "citation_count": 10
  },
  "https://proceedings.mlr.press/v216/aloui23a.html": {
    "title": "Transfer learning for individual treatment effect estimation",
    "abstract": "This work considers the problem of transferring causal knowledge between tasks for Individual Treatment Effect (ITE) estimation. To this end, we theoretically assess the feasibility of transferring ITE knowledge and present a practical framework for efficient transfer. A lower bound is introduced on the ITE error of the target task to demonstrate that ITE knowledge transfer is challenging due to the absence of counterfactual information. Nevertheless, we establish generalization upper bounds on the counterfactual loss and ITE error of the target task, demonstrating the feasibility of ITE knowledge transfer. Subsequently, we introduce a framework with a new Causal Inference Task Affinity (CITA) measure for ITE knowledge transfer. Specifically, we use CITA to find the closest source task to the target task and utilize it for ITE knowledge transfer. Empirical studies are provided, demonstrating the efficacy of the proposed method. We observe that ITE knowledge transfer can significantly (up to 95%) reduce the amount of data required for ITE estimation",
    "volume": "main",
    "checked": true,
    "id": "ad12fd26aeb35f4e8feb218739218e04f14c0bbc",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/andrade23a.html": {
    "title": "Robust Gaussian process regression with the trimmed marginal likelihood",
    "abstract": "Accurate outlier detection is not only a necessary preprocessing step, but can itself give important insights into the data. However, especially, for non-linear regression the detection of outliers is non-trivial, and actually ambiguous. We propose a new method that identifies outliers by finding a subset of data points T such that the marginal likelihood of all remaining data points S is maximized. Though the idea is more general, it is particular appealing for Gaussian processes regression, where the marginal likelihood has an analytic solution. While maximizing the marginal likelihood for hyper-parameter optimization is a well established non-convex optimization problem, optimizing the set of data points S is not. Indeed, even a greedy approximation is computationally challenging due to the high cost of evaluating the marginal likelihood. As a remedy, we propose an efficient projected gradient descent method with provable convergence guarantees. Moreover, we also establish the breakdown point when jointly optimizing hyper-parameters and S. For various datasets and types of outliers, our experiments demonstrate that the proposed method can improve outlier detection and robustness when compared with several popular alternatives like the student-t likelihood",
    "volume": "main",
    "checked": true,
    "id": "d9ee245507c5c9948b27297eacd42c20e1e8ef16",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/ao23a.html": {
    "title": "Two Sides of Miscalibration: Identifying Over and Under-Confidence Prediction for Network Calibration",
    "abstract": "Proper confidence calibration of deep neural networks is essential for reliable predictions in safety-critical tasks. Miscalibration can lead to model over-confidence and/or under-confidence; i.e., the model’s confidence in its prediction can be greater or less than the model’s accuracy. Recent studies have highlighted the over-confidence issue by introducing calibration techniques and demonstrated success on various tasks. However, miscalibration through under-confidence has not yet to receive much attention. In this paper, we address the necessity of paying attention to the under-confidence issue. We first introduce a novel metric, a miscalibration score, to identify the overall and class-wise calibration status, including being over or under-confident. Our proposed metric reveals the pitfalls of existing calibration techniques, where they often overly calibrate the model and worsen under-confident predictions. Then we utilize the class-wise miscalibration score as a proxy to design a calibration technique that can tackle both over and under-confidence. We report extensive experiments that show our proposed methods substantially outperforming existing calibration techniques. We also validate our proposed calibration technique on an automatic failure detection task with a risk-coverage curve, reporting that our methods improve failure detection as well as trustworthiness of the model. The code are available at \\url{https://github.com/AoShuang92/miscalibration_TS}",
    "volume": "main",
    "checked": true,
    "id": "4876be99d6d1ba6b4f71449e978a33b693b95fa2",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/arora23a.html": {
    "title": "Quantifying lottery tickets under label noise: accuracy, calibration, and complexity",
    "abstract": "Pruning deep neural networks is a widely used strategy to alleviate the computational burden in machine learning. Overwhelming empirical evidence suggests that pruned models retain very high accuracy even with a tiny fraction of parameters. However, relatively little work has gone into characterising the small pruned networks obtained, beyond a measure of their accuracy. In this paper, we use the sparse double descent approach to identify univocally and characterise pruned models associated with classification tasks. We observe empirically that, for a given task, iterative magnitude pruning (IMP) tends to converge to networks of comparable sizes even when starting from full networks with sizes ranging over orders of magnitude. We analyse the best pruned models in a controlled experimental setup and show that their number of parameters reflects task difficulty and that they are much better than full networks at capturing the true conditional probability distribution of the labels. On real data, we similarly observe that pruned models are less prone to overconfident predictions. Our results suggest that pruned models obtained via IMP not only have advantageous computational properties but also provide a better representation of uncertainty in learning",
    "volume": "main",
    "checked": true,
    "id": "27ceb7eb6090d4087a35d36325adf3b4cdb4ec5d",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/arriojas23a.html": {
    "title": "Bayesian inference approach for entropy regularized reinforcement learning with stochastic dynamics",
    "abstract": "We develop a novel approach to determine the optimal policy in entropy-regularized reinforcement learning (RL) with stochastic dynamics. For deterministic dynamics, the optimal policy can be derived using Bayesian inference in the control-as-inference framework; however, for stochastic dynamics, the direct use of this approach leads to risk-taking optimistic policies. To address this issue, current approaches in entropy-regularized RL involve a constrained optimization procedure which fixes system dynamics to the original dynamics, however this approach is not consistent with the unconstrained Bayesian inference framework. In this work we resolve this inconsistency by developing an exact mapping from the constrained optimization problem in entropy-regularized RL to a different optimization problem which can be solved using the unconstrained Bayesian inference approach. We show that the optimal policies are the same for both problems, thus our results lead to the exact solution for the optimal policy in entropy-regularized RL with stochastic dynamics through Bayesian inference",
    "volume": "main",
    "checked": false,
    "id": "7c5f440862998c125628e17591f5a5bb9302cc7c",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/banerjee23a.html": {
    "title": "Neural tangent kernel at initialization: linear width suffices",
    "abstract": "In this paper we study the problem of lower bounding the minimum eigenvalue of the neural tangent kernel (NTK) at initialization, an important quantity for the theoretical analysis of training in neural networks. We consider feedforward neural networks with smooth activation functions. Without any distributional assumptions on the input, we present a novel result: we show that for suitable initialization variance, $\\widetilde{\\Omega}(n)$ width, where $n$ is the number of training samples, suffices to ensure that the NTK at initialization is positive definite, improving prior results for smooth activations under our setting. Prior to our work, the sufficiency of linear width has only been shown either for networks with ReLU activation functions, and sublinear width has been shown for smooth networks but with additional conditions on the distribution of the data. The technical challenge in the analysis stems from the layerwise inhomogeneity of smooth activation functions and we handle the challenge using {\\em generalized} Hermite series expansion of such activations",
    "volume": "main",
    "checked": false,
    "id": "808569a99df02227240a78d388f2b7557a409ad4",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/bang23a.html": {
    "title": "Do we become wiser with time? On causal equivalence with tiered background knowledge",
    "abstract": "Equivalence classes of DAGs (represented by CPDAGs) may be too large to provide useful causal information. Here, we address incorporating tiered background knowledge yielding restricted equivalence classes represented by ‘tiered MPDAGs’. Tiered knowledge leads to considerable gains in informativeness and computational efficiency: We show that construction of tiered MPDAGs only requires application of Meeks 1st rule, and that tiered MPDAGs (unlike general MPDAGs) are chain graphs with chordal components. This entails simplifications e.g. of determining valid adjustment sets for causal effect estimation. Further, we characterise when one tiered ordering is more informative than another, providing insights into useful aspects of background knowledge",
    "volume": "main",
    "checked": true,
    "id": "89d76e1496965a705cfd7e2f21ce3a134974c268",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/bauvin23a.html": {
    "title": "Sample Boosting Algorithm (SamBA) - An interpretable greedy ensemble classifier based on local expertise for fat data",
    "abstract": "Ensemble methods are a very diverse family of algorithms with a wide range of applications. One of the most commonly used is boosting, with the prominent Adaboost. Adaboost relies on greedily learning base classifiers that rectify the error from previous iterations. Then, it combines them through a weighted majority vote, based on their quality on the entire learning set. In this paper, we propose a supervised binary classification framework that propagates the local knowledge acquired during the boosting iterations to the prediction function. Based on this general framework, we introduce SamBA, an interpretable greedy ensemble method designed for fat datasets, with a large number of dimensions and a small number of samples. SamBA learns local classifiers and combines them, using a similarity function, to optimize its efficiency in data extraction. We provide a theoretical analysis of SamBA, yielding convergence and generalization guarantees. In addition, we highlight SamBA’s empirical behavior in an extensive experimental analysis on both real biological and generated datasets, comparing it to state-of-the-art ensemble methods and similarity-based approaches",
    "volume": "main",
    "checked": false,
    "id": "2c16cbf14b0e123b4c234bbd102f1e4b60b9c907",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/benavoli23a.html": {
    "title": "Learning Choice Functions with Gaussian Processes",
    "abstract": "In consumer theory, ranking available objects by means of preference relations yields the most common description of individual choices. However, preference-based models assume that individuals: (1) give their preferences only between pairs of objects; (2) are always able to pick the best preferred object. In many situations, they may be instead choosing out of a set with more than two elements and, because of lack of information and/or incomparability (objects with contradictory characteristics), they may not be able to select a single most preferred object. To address these situations, we need a choice model which allows an individual to express a set-valued choice. Choice functions provide such a mathematical framework. We propose a Gaussian Process model to learn choice functions from choice data. The model assumes a multiple utility representation of a choice function based on the concept of Pareto rationalization, and derives a strategy to learn both the number and the values of these latent multiple utilities. Simulation experiments demonstrate that the proposed model outperforms the state-of-the-art methods",
    "volume": "main",
    "checked": true,
    "id": "23b9082ec3c522b3c4f8bfe7a8d2ee2d320ba99a",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v216/berenbrink23a.html": {
    "title": "Inference of a rumor's source in the independent cascade model",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/bhattacharjee23a.html": {
    "title": "Best arm identification in rare events",
    "abstract": "We consider the Best Arm Identification (BAI) problem in the stochastic multi-armed bandit framework, where each arm has a small probability of realizing large rewards, while with overwhelming probability, the reward is zero. A key application of this framework is in online advertising, where click rates of advertisements could be a fraction of a single percent and final conversion to sales, while highly profitable, may again be a small fraction of the click rates. Lately, algorithms for BAI problems have been developed that minimise sample complexity while providing statistical guarantees on the correct arm selection. As we observe, these algorithms can be computationally prohibitive. We exploit the fact that the reward process for each arm is well approximated by a Compound Poisson process and arrive at algorithms that are faster, with a small increase in sample complexity. We analyze the problem in an asymptotic regime as rarity of reward occurrence reduces to zero, and reward amounts increase to infinity. This helps illustrate the benefits of the proposed algorithm. It also sheds light on the underlying structure of the optimal BAI algorithms in the rare event setting",
    "volume": "main",
    "checked": true,
    "id": "e9505a1ed3998f2e56760532aba269ae900392d4",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/bieri23a.html": {
    "title": "BeliefPPG: Uncertainty-aware heart rate estimation from PPG signals via belief propagation",
    "abstract": "We present a novel learning-based method that achieves state-of-the-art performance on several heart rate estimation benchmarks extracted from photoplethysmography signals (PPG). We consider the evolution of the heart rate in the context of a discrete-time stochastic process that we represent as a hidden Markov model. We derive a distribution over possible heart rate values for a given PPG signal window through a trained neural network. Using belief propagation, we incorporate the statistical distribution of heart rate changes to refine these estimates in a temporal context. From this, we obtain a quantized probability distribution over the range of possible heart rate values that captures a meaningful and well-calibrated estimate of the inherent predictive uncertainty. We show the robustness of our method on eight public datasets with three different cross-validation experiments",
    "volume": "main",
    "checked": true,
    "id": "425a11ec975ebec9bc1e5138d084a52557757136",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/bitzer23a.html": {
    "title": "Amortized Inference for Gaussian Process Hyperparameters of Structured Kernels",
    "abstract": "Learning the kernel parameters for Gaussian processes is often the computational bottleneck in applications such as online learning, Bayesian optimization, or active learning. Amortizing parameter inference over different datasets is a promising approach to dramatically speed up training time. However, existing methods restrict the amortized inference procedure to a fixed kernel structure. The amortization network must be redesigned manually and trained again in case a different kernel is employed, which leads to a large overhead in design time and training time. We propose amortizing kernel parameter inference over a complete kernel-structure-family rather than a fixed kernel structure. We do that via defining an amortization network over pairs of datasets and kernel structures. This enables fast kernel inference for each element in the kernel family without retraining the amortization network. As a by-product, our amortization network is able to do fast ensembling over kernel structures. In our experiments, we show drastically reduced inference time combined with competitive test performance for a large set of kernels and datasets",
    "volume": "main",
    "checked": true,
    "id": "b3780f92c35a46999818c3a0a4ea3218ca870058",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/boeken23a.html": {
    "title": "Correcting for selection bias and missing response in regression using privileged information",
    "abstract": "When estimating a regression model, we might have data where some labels are missing, or our data might be biased by a selection mechanism. When the response or selection mechanism is ignorable (i.e., independent of the response variable given the features) one can use off-the-shelf regression methods; in the nonignorable case one typically has to adjust for bias. We observe that privileged information (i.e. information that is only available during training) might render a nonignorable selection mechanism ignorable, and we refer to this scenario as Privilegedly Missing at Random (PMAR). We propose a novel imputation-based regression method, named repeated regression, that is suitable for PMAR. We also consider an importance weighted regression method, and a doubly robust combination of the two. The proposed methods are easy to implement with most popular out-of-the-box regression algorithms. We empirically assess the performance of the proposed methods with extensive simulated experiments and on a synthetically augmented real-world dataset. We conclude that repeated regression can appropriately correct for bias, and can have considerable advantage over weighted regression, especially when extrapolating to regions of the feature space where response is never observed",
    "volume": "main",
    "checked": true,
    "id": "d8090fb60cd66557b9417b2c4ffceeea7b6b70c7",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/bondugula23a.html": {
    "title": "Efficient Learning of Minimax Risk Classifiers in High Dimensions",
    "abstract": "High-dimensional data is common in multiple areas, such as health care and genomics, where the number of features can be tens of thousands. In such scenarios, the large number of features often leads to inefficient learning. Constraint generation methods have recently enabled efficient learning of L1-regularized support vector machines (SVMs). In this paper, we leverage such methods to obtain an efficient learning algorithm for the recently proposed minimax risk classifiers (MRCs). The proposed iterative algorithm also provides a sequence of worst-case error probabilities and performs feature selection. Experiments on multiple high-dimensional datasets show that the proposed algorithm is efficient in high-dimensional scenarios. In addition, the worst-case error probability provides useful information about the classifier performance, and the features selected by the algorithm are competitive with the state-of-the-art",
    "volume": "main",
    "checked": true,
    "id": "2a28ab7097be8c0290e661cbfae18ce74330811a",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/bounia23a.html": {
    "title": "Approximating probabilistic explanations via supermodular minimization",
    "abstract": "Explaining in accurate and intelligible terms the predictions made by classifiers is a key challenge of eXplainable Artificial Intelligence (XAI). To this end, an abductive explanation for the predicted label of some data instance is a subset-minimal collection of features such that the restriction of the instance to these features is sufficient to determine the prediction. However, due to cognitive limitations, abductive explanations are often too large to be interpretable. In those cases, we need to reduce the size of abductive explanations, while still determining the predicted label with high probability. In this paper, we show that finding such probabilistic explanations is NP-hard, even for decision trees. In order to circumvent this issue, we investigate the approximability of probabilistic explanations through the lens of supermodularity. We examine both greedy descent and greedy ascent approaches for supermodular minimization, whose approximation guarantees depend on the curvature of the “unnormalized” error function that evaluates the precision of the explanation. Based on various experiments for explaining decision tree predictions, we show that our greedy algorithms provide an efficient alternative to the state-of-the-art constraint optimization method",
    "volume": "main",
    "checked": false,
    "id": "0beec2b42500fed0ca9ecab17b2fc10c07c8a211",
    "citation_count": 11
  },
  "https://proceedings.mlr.press/v216/boyd23a.html": {
    "title": "Inference for mark-censored temporal point processes",
    "abstract": "Marked temporal point processes (MTPPs) are a general class of stochastic models for modeling the evolution of events of different types (“marks”) in continuous time. These models have broad applications in areas such as medical data monitoring, financial prediction, user modeling, and communication networks. Of significant practical interest in such problems is the issue of missing or censored data over time. In this paper, we focus on the specific problem of inference for a trained MTPP model when events of certain types are not observed over a period of time during prediction. We introduce the concept of mark-censored sub-processes and use this framework to develop a novel marginalization technique for inference in the presence of censored marks. The approach is model-agnostic and applicable to any MTPP model with a well-defined intensity function. We illustrate the flexibility and utility of the method in the context of both parametric and neural MTPP models, with results across a range of datasets including data from simulated Hawkes processes, self-correcting processes, and multiple real-world event datasets",
    "volume": "main",
    "checked": true,
    "id": "60fc5e7ce1919d5261f0222f2a2c6ffc746a2619",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/burrell23a.html": {
    "title": "Testing conventional wisdom (of the crowd)",
    "abstract": "Do common assumptions about the way that crowd workers make mistakes in microtask (labeling) applications manifest in real crowdsourcing data? Prior work only addresses this question indirectly. Instead, it primarily focuses on designing new label aggregation algorithms, seeming to imply that better performance justifies any additional assumptions. However, empirical evidence in past instances has raised significant challenges to common assumptions. We continue this line of work, using crowdsourcing data itself as directly as possible to interrogate several basic assumptions about workers and tasks. We find strong evidence that the assumption that workers respond correctly to each task with a constant probability, which is common in theoretical work, is implausible in real data. We also illustrate how heterogeneity among tasks and workers can take different forms, which have different implications for the design and evaluation of label aggregation algorithms",
    "volume": "main",
    "checked": true,
    "id": "680d3b52a4b2b28ce61fa0fec629c5ff5eb67682",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/cao23a.html": {
    "title": "Overcoming Language Priors for Visual Question Answering via Loss Rebalancing Label and Global Context",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/cao23b.html": {
    "title": "Scaling integer arithmetic in probabilistic programs",
    "abstract": "Distributions on integers are ubiquitous in probabilistic modeling but remain challenging for many of today’s probabilistic programming languages (PPLs). The core challenge comes from discrete structure: many of today’s PPL inference strategies rely on enumeration, sampling, or differentiation in order to scale, which fail for high-dimensional complex discrete distributions involving integers. Our insight is that there is structure in arithmetic that these approaches are not using. We present a binary encoding strategy for discrete distributions that exploits the rich logical structure of integer operations like summation and comparison. We leverage this structured encoding with knowledge compilation to perform exact probabilistic inference, and show that this approach scales to much larger integer distributions with arithmetic",
    "volume": "main",
    "checked": true,
    "id": "e5ccfc2779f7fd0352cfe8babd0773e2b8e56eb1",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/carey23a.html": {
    "title": "Human Control: Definitions and Algorithms",
    "abstract": "How can humans stay in control of advanced artificial intelligence systems? One proposal is corrigibility, which requires the agent to follow the instructions of a human overseer, without inappropriately influencing them. In this paper, we formally define a variant of corrigibility called shutdown instructability, and show that it implies appropriate shutdown behavior, retention of human autonomy, and avoidance of user harm. We also analyse the related concepts of non-obstruction and shutdown alignment, three previously proposed algorithms for human control, and one new algorithm",
    "volume": "main",
    "checked": true,
    "id": "c458cec389a2ed3bbe5e35bc9a5b0a85ca073d15",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/chakraborty23a.html": {
    "title": "Scalable nonparametric Bayesian learning for dynamic velocity fields",
    "abstract": "Learning and understanding heterogeneous patterns in complex spatio-temporal data is an important and challenging task across domains in science and engineering. In this work, we develop a model for learning heterogeneous and dynamic patterns of velocity field data, motivated by applications in the transportation domain. We draw from basic nonparametric Bayesian modeling elements such as the infinite hidden Markov model and Gaussian process and focus on making the learning of such a stochastic model scalable for voluminous and streaming data. This is achieved by employing sequential MAP estimates from the infinite HMM model, an efficient sequential sparse GP posterior computation, and refinement of the estimates using the Viterbi algorithm, which is shown to work effectively on a careful simulation study. We demonstrate the efficacy of our techniques to the NGSIM dataset of complex multi-vehicle interactions",
    "volume": "main",
    "checked": false,
    "id": "1b81606fbe6b7e7a8d77c51643348b8333513923",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/chandrasekaran23a.html": {
    "title": "Learning in online MDPs: is there a price for handling the communicating case?",
    "abstract": "It is a remarkable fact that the same $O(\\sqrt{T})$ regret rate can be achieved in both the Experts Problem and the Adversarial Multi-Armed Bandit problem albeit with a worse dependence on number of actions in the latter case. In contrast, it has been shown that handling online MDPs with communicating structure and bandit information incurs $\\Omega(T^{2/3})$ regret even in the case of deterministic transitions. Is this the price we pay for handling communicating structure or is it because we also have bandit feedback? In this paper we show that with full information, online MDPs can still be learned at an $O(\\sqrt{T})$ rate even in the presence of communicating structure. We first show this by proposing an efficient follow the perturbed leader (FPL) algorithm for the deterministic transition case. We then extend our scope to consider stochastic transitions where we first give an inefficient $O(\\sqrt{T})$-regret algorithm (with a mild additional condition on the dynamics). Then we show how to achieve $O\\left(\\sqrt{\\frac{T}{\\alpha}}\\right)$ regret rate using an oracle-efficient algorithm but with the additional restriction that the starting state distribution has mass at least $\\alpha$ on each state",
    "volume": "main",
    "checked": true,
    "id": "47fee34c6f58df480d0b882e7a24a4a67c55cf36",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v216/chen23a.html": {
    "title": "Modified Retrace for Off-Policy Temporal Difference Learning",
    "abstract": "Off-policy learning is a key to extend reinforcement learning as it allows to learn  a target policy from a different behavior policy that generates the data. However, it is well known as “the deadly triad” when combined with bootstrapping and function approximation. Retrace is an efficient and  convergent off-policy algorithm with tabular value functions which employs  truncated importance sampling ratios. Unfortunately, Retrace is known to be unstable with linear function approximation. In this paper, we propose modified Retrace  to correct the  off-policy return, derive a new off-policy temporal difference learning algorithm (TD-MRetrace) with linear function approximation, and obtain a convergence guarantee under standard assumptions. Experimental results on counterexamples and control tasks validate the effectiveness of the proposed algorithm compared with traditional algorithms",
    "volume": "main",
    "checked": false,
    "id": "2e564eed641d8f15b6707672cde031d9a108c8c9",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v216/chen23b.html": {
    "title": "Benign Overfitting in Adversarially Robust Linear Classification",
    "abstract": "Benign overfitting, where classifiers memorize noisy training data yet still achieve a good generalization performance, has drawn great attention in the machine learning community. To explain this surprising phenomenon, a series of works have provided theoretical justification for over-parameterized linear regression, classification, and kernel methods. However, it is not clear if benign overfitting can occur in the presence of adversarial examples, i.e., examples with tiny and intentional perturbations to fool the classifiers. In this paper, we show that benign overfitting indeed occurs in adversarial training, a principled approach to defend against adversarial examples, on subGaussian mixture data. In detail, we prove the risk bounds of the adversarially trained linear classifier on the mixture of sub-Gaussian data under Lp adversarial perturbations. Our result suggests that under moderate perturbations, adversarially trained linear classifiers can achieve the near-optimal standard and adversarial risks, despite overfitting the noisy training data. Numerical experiments validate our theoretical findings",
    "volume": "main",
    "checked": true,
    "id": "40bd323201c9ab8294fac973ca0e5d6417b7221c",
    "citation_count": 4
  },
  "https://proceedings.mlr.press/v216/chen23c.html": {
    "title": "An effective negotiating agent framework based on deep offline reinforcement learning",
    "abstract": "Learning is crucial for automated negotiation, and recent years have witnessed a remarkable achievement in application of reinforcement learning (RL) for various negotiation tasks. Conventional RL methods focus generally on learning from active interactions with opposing negotiators. However, collecting online data is expensive in many realistic negotiation scenarios. While previous studies partially mitigate this problem through the use of opponent simulators (i.e., agents following known strategies), in reality it is usually hard to fully capture an opponent’s negotiation strategy. Moreover, a further challenge lies in an agent’s capability of adapting to dynamic variations of an opponent’s preferences or strategies, which may happen from time to time for different reasons in subsequent negotiations. In response to these challenges, this article proposes a novel Deep Offline Reinforcement learning Negotiating Agent framework that allows to learn an effective strategy using previously collected negotiation datasets without requiring interaction with an opponent. This is in contrast to existing RL-based negotiation approaches that all rely on active interaction with opponents. Furthermore, the strategy fine-tuning mechanism is included to adjust the learned strategy in response to the preferences or strategy changes of the opponent. The performance of the proposed framework is evaluated based on a diverse set of state-of-the-art baselines under different settings. Experimental results show that the framework allows to learn effective strategies exclusively with offline datasets, and is also capable of effectively adapting to changes of an opponent’s preferences or strategy",
    "volume": "main",
    "checked": false,
    "id": "004b3ce1d65b0641991257ff2ef3035a5278dbbe",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/chen23d.html": {
    "title": "MFA: Multi-layer Feature-aware Attack for Object Detection",
    "abstract": "Physical adversarial attacks can mislead detectors in real-world scenarios and have attracted increasing attention. However, most existing works manipulate the detector’s final outputs as attack targets while ignoring the inherent characteristics of objects. This can result in attacks being trapped in model-specific local optima and reduced transferability. To address this issue, we propose a Multi-layer Feature-aware Attack (MFA) that considers the importance of multi-layer features and disrupts critical object-aware features that dominate decision-making across different models. Specifically, we leverage the location and category information of detector outputs to assign attribution scores to different feature layers. Then, we weight each feature according to their attribution results and design a pixel-level loss function in the opposite optimized direction of object detection to generate adversarial camouflages. We conduct extensive experiments in both digital and physical worlds on ten outstanding detection models and demonstrate the superior performance of MFA in terms of attacking capability and transferability. Our code is available at: \\url{https://github.com/ChenWen1997/MFA}",
    "volume": "main",
    "checked": false,
    "id": "b6d07d7b643f6da63f1eaca7d3ca25d5ed8d14f8",
    "citation_count": 53
  },
  "https://proceedings.mlr.press/v216/chen23e.html": {
    "title": "Differential Privacy in Cooperative Multiagent Planning",
    "abstract": "Privacy-aware multiagent systems must protect agents’ sensitive data while simultaneously ensuring that agents accomplish their shared objectives. Towards this goal, we propose a framework to privatize inter-agent communications in cooperative multiagent decision-making problems. We study sequential decision-making problems formulated as cooperative Markov games with reach-avoid objectives. We apply a differential privacy mechanism to privatize agents’ communicated symbolic state trajectories, and analyze tradeoffs between the strength of privacy and the team’s performance. For a given level of privacy, this tradeoff is shown to depend critically upon the total correlation among agents’ state-action processes. We synthesize policies that are robust to privacy by reducing the value of the total correlation. Numerical experiments demonstrate that the team’s performance under these policies decreases by only 6 percent when comparing private versus non-private implementations of communication. By contrast, the team’s performance decreases by 88 percent when using baseline policies that ignore total correlation and only optimize team performance",
    "volume": "main",
    "checked": true,
    "id": "638edc83cc7aced4d1918a0424194f4f220e26be",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/chen23f.html": {
    "title": "Causal inference with outcome-dependent missingness and self-censoring",
    "abstract": "We consider missingness in the context of causal inference when the outcome of interest may be missing. If the outcome directly affects its own missingness status, i.e., it is “self-censoring”, this may lead to severely biased causal effect estimates. Miao et al. (2015) proposed the shadow variable method to correct for bias due to self-censoring; however, verifying the required model assumptions can be difficult. Here, we propose a test based on a randomized incentive variable offered to encourage reporting of the outcome that can be used to verify identification assumptions that are sufficient to correct for both self-censoring and confounding bias. Concretely, the test confirms whether a given set of pre-treatment covariates is sufficient to block all backdoor paths between the treatment and outcome as well as all paths between the treatment and missingness indicator after conditioning on the outcome. We show that under these conditions, the causal effect is identified by using the treatment as a shadow variable, and it leads to an intuitive inverse probability weighting estimator that uses a product of the treatment and response weights. We evaluate the efficacy of our test and downstream estimator via simulations",
    "volume": "main",
    "checked": true,
    "id": "d27bab1dea7777b49d7bd60b3442e88a583973df",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/chen23g.html": {
    "title": "Detection of Short-Term Temporal Dependencies in Hawkes Processes with Heterogeneous Background Dynamics",
    "abstract": "Many kinds of simultaneously-observed event sequences exhibit mutually exciting or inhibiting patterns. Reliable detection of such temporal dependencies is crucial for scientific investigation. A common model is the Multivariate Hawkes Process (MHP), whose impact function naturally encodes a causal structure in Granger causality. However, the vast majority of existing methods use a transformed  standard MHP intensity with a constant baseline, which may be inconsistent with real-world data. On the other hand, modeling irregular and unknown background dynamics directly is a challenge, as one struggles to distinguish the effect of mutual interaction from that of fluctuations in background dynamics. In this paper, we address the short-term temporal dependency detection issue. We show that maximum likelihood estimation (MLE) for cross-impact from MHP has an error that can not be eliminated, but may be reduced by an order of magnitude using a heterogeneous intensity not for the target HP but for the interacting HP. Then we propose a robust and computationally-efficient modification of MLE that does not rely on the prior estimation of the heterogeneous intensity and is thus applicable in a data-limited regime (e.g., few-shot, unrepeated observations). Extensive experiments on various datasets show that our method outperforms existing ones by notable margins, with highlighted novel applications in neuroscience",
    "volume": "main",
    "checked": true,
    "id": "aaab810b20e00d79b7a4e1ca0b636fa8d24433c7",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/cheng23a.html": {
    "title": "Enhancing Treatment Effect Estimation: A Model Robust Approach Integrating Randomized Experiments and External Controls using the Double Penalty Integration Estimator",
    "abstract": "Randomized experiments (REs) are the cornerstone for treatment effect evaluation. However, due to practical considerations, REs may encounter difficulty recruiting sufficient patients. External controls (ECs) can supplement REs to boost estimation efficiency. Yet, there may be incomparability between ECs and concurrent controls (CCs), resulting in misleading treatment effect evaluation. We introduce a novel bias function to measure the difference in the outcome mean functions between ECs and CCs. We show that the ANCOVA model augmented by the bias function for ECs renders a consistent estimator of the average treatment effect, regardless of whether or not the ANCOVA model is correct.  To accommodate possibly different structures of the ANCOVA model and the bias function, we propose a double penalty integration estimator (DPIE) with different penalization terms for the two functions. With an appropriate choice of penalty parameters, our DPIE ensures consistency, oracle property, and asymptotic normality even in the presence of model misspecification. DPIE is at least as efficient as the estimator derived from REs alone, validated through theoretical and experimental results",
    "volume": "main",
    "checked": true,
    "id": "8bae36c2c21988d7da8038e73e9debcd45744442",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/choo23a.html": {
    "title": "Adaptivity Complexity for Causal Graph Discovery",
    "abstract": "Causal discovery from interventional data is an important problem, where the task is to design an interventional strategy that learns the hidden ground truth causal graph $G(V,E)$ on $|V| = n$ nodes while minimizing the number of performed interventions. Most prior interventional strategies broadly fall into two categories: non-adaptive and adaptive. Non-adaptive strategies decide on a single fixed set of interventions to be performed while adaptive strategies can decide on which nodes to intervene on sequentially based on past interventions. While adaptive algorithms may use exponentially fewer interventions than their non-adaptive counterparts, there are practical concerns that constrain the amount of adaptivity allowed. Motivated by this trade-off, we study the problem of $r$-adaptivity, where the algorithm designer recovers the causal graph under a total of $r$ sequential rounds whilst trying to minimize the total number of interventions. For this problem, we provide a $r$-adaptive algorithm that achieves $O(\\min\\{r,\\log n\\} \\cdot n^{1/\\min\\{r,\\log n\\}})$ approximation with respect to the verification number, a well-known lower bound for adaptive algorithms. Furthermore, for every $r$, we show that our approximation is tight. Our definition of $r$-adaptivity interpolates nicely between the non-adaptive ($r=1$) and fully adaptive ($r=n$) settings where our approximation simplifies to $O(n)$ and $O(\\log n)$ respectively, matching the best-known approximation guarantees for both extremes. Our results also extend naturally to the bounded size interventions",
    "volume": "main",
    "checked": true,
    "id": "85e40295559811a19d96db9982ff2e4fd75f6697",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/chowdhury23a.html": {
    "title": "Combinatorial categorized bandits with expert rankings",
    "abstract": "Many real-world systems such as e-commerce websites and content-serving platforms employ two-stage recommendation — in the first stage, multiple nominators (experts) provide ranked lists of items (one nominator per category, e.g., sports and political news articles), and in the second stage, an aggregator filters across the lists and outputs a single (short) list of K items to the users. The aggregation stage can be posed as a combinatorial multi-armed bandit problem, with the additional structure that the arms are grouped into categories (disjoint sets of items) and the ranking of arms within each category is known. We propose algorithms for selecting top K items in this setting under two learning objectives, namely minimizing regret over rounds and identifying the top K items within a fixed number of rounds. For each of the objectives, we provide sharp regret/error analysis using carefully defined notion of “gap” that exploits our problem structure. The resulting regret/error bounds strictly improve over prior work in combinatorial bandits literature. We also provide supporting evidence from simulations on synthetic and semi-synthetic problems",
    "volume": "main",
    "checked": false,
    "id": "7e3c6a595f10f876c88af934481f505421988fa2",
    "citation_count": 10
  },
  "https://proceedings.mlr.press/v216/chung23a.html": {
    "title": "Parity calibration",
    "abstract": "In a sequential regression setting, a decision-maker may be primarily concerned with whether the future observation will increase or decrease compared to the current one, rather than the actual value of the future observation. In this context, we introduce the notion of parity calibration, which captures the goal of calibrated forecasting for the increase-decrease (or “parity\") event in a timeseries. Parity probabilities can be extracted from a forecasted distribution for the output, but we show that such a strategy leads to theoretical unpredictability and poor practical performance. We then observe that although the original task was regression, parity calibration can be expressed as binary calibration. Drawing on this connection, we use an online binary calibration method to achieve parity calibration. We demonstrate the effectiveness of our approach on real-world case studies in epidemiology, weather forecasting, and model-based control in nuclear fusion",
    "volume": "main",
    "checked": true,
    "id": "0d7c02544daa37cf940fc48b462fe83a281e43a8",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/cisneros-velarde23a.html": {
    "title": "Finite-sample guarantees for Nash Q-learning with linear function approximation",
    "abstract": "Nash Q-learning may be considered one of the first and most known algorithms in multi-agent reinforcement learning (MARL) for learning policies that constitute a Nash equilibrium of an underlying general-sum Markov game. Its original proof provided asymptotic guarantees and was for the tabular case. Recently, finite-sample guarantees have been provided using more modern RL techniques for the tabular case. Our work analyzes Nash Q-learning using linear function approximation – a representation regime introduced when the state space is large or continuous – and provides finite-sample guarantees that indicate its sample efficiency. We find that the obtained performance nearly matches an existing efficient result for single-agent RL under the same representation and has a polynomial gap when compared to the best-known result for the tabular case",
    "volume": "main",
    "checked": true,
    "id": "b5151d86c9f1015843d0cd906f5611adc527d0f6",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/claassen23a.html": {
    "title": "Establishing Markov equivalence in cyclic directed graphs",
    "abstract": "We present a new, efficient procedure to establish Markov equivalence between directed graphs that may or may not contain cycles. It is based on the Cyclic Equivalence Theorem (CET) in the seminal works on cyclic models by Thomas Richardson in the mid ’90s, but now rephrased from an ancestral perspective. The resulting characterization leads to a procedure for establishing Markov equivalence between graphs that no longer requires explicit tests for $d$-separation, leading to a significantly reduced algorithmic complexity. The conceptually simplified characterization may help to reinvigorate theoretical research towards sound and complete cyclic discovery in the presence of latent confounders",
    "volume": "main",
    "checked": false,
    "id": "443418f652945dc72315f7ad34331d2257ce612a",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/clarte23a.html": {
    "title": "Expectation consistency for calibration of neural networks",
    "abstract": "Despite their incredible performance, it is well reported that deep neural networks tend to be overoptimistic about their prediction confidence. Finding effective and efficient calibration methods for neural networks is therefore an important endeavour towards better uncertainty quantification in deep learning. In this manuscript, we introduce a novel calibration technique named expectation consistency (EC), consisting of a post-training rescaling of the last layer weights by enforcing that the average validation confidence coincides with the average proportion of correct labels. First, we show that the EC method achieves similar calibration performance to temperature scaling (TS) across different neural network architectures and data sets, all while requiring similar validation samples and computational resources. However, we argue that EC provides a principled method grounded on a Bayesian optimality principle known as the Nishimori identity. Next, we provide an asymptotic characterization of both TS and EC in a synthetic setting and show that their performance crucially depends on the target function. In particular, we discuss examples where EC significantly outperforms TS",
    "volume": "main",
    "checked": true,
    "id": "768465efbbf532a066c87ca603a43f2b4fc9b3de",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v216/collins23a.html": {
    "title": "Human-in-the-Loop Mixup",
    "abstract": "Aligning model representations to humans has been found to improve robustness and generalization. However, such methods often focus on standard observational data. Synthetic data is proliferating and powering many advances in machine learning; yet, it is not always clear whether synthetic labels are perceptually aligned to humans – rendering it likely model representations are not human aligned. We focus on the synthetic data used in mixup: a powerful regularizer shown to improve model robustness, generalization, and calibration. We design a comprehensive series of elicitation interfaces, which we release as HILL MixE Suite, and recruit 159 participants to provide perceptual judgments along with their uncertainties, over mixup examples. We find that human perceptions do not consistently align with the labels traditionally used for synthetic points, and begin to demonstrate the applicability of these findings to potentially increase the reliability of downstream models, particularly when incorporating human uncertainty. We release all elicited judgments in a new data hub we call H-Mix",
    "volume": "main",
    "checked": true,
    "id": "99d54bb1bf115eb8e57d8efb9e1dc84f3fa9d80c",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v216/cui23a.html": {
    "title": "Learning to reason about contextual knowledge for planning under uncertainty",
    "abstract": "Sequential decision-making (SDM) methods enable AI agents to compute an action policy toward achieving long-term goals under uncertainty. Existing research has shown that contextual knowledge in declarative forms can be used for improving the performance of SDM methods. However, the contextual knowledge from people tends to be incomplete and sometimes inaccurate, which greatly limits the applicability of knowledge-based SDM methods. In this paper, we develop a novel algorithm for knowledge-based SDM, called PERIL, that learns from interaction experience to reason about contextual knowledge, as applied to urban driving scenarios. Experiments have been conducted using CARLA, a widely used autonomous driving simulator. Results demonstrate PERIL’s superiority in comparison to existing knowledge-based SDM baselines",
    "volume": "main",
    "checked": true,
    "id": "6d0edad1885df9e2ab1bfee6e047f252f696d662",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/cutkosky23a.html": {
    "title": "Blackbox optimization of unimodal functions",
    "abstract": "We provide an intuitive new algorithm for blackbox stochastic optimization of unimodal functions, a function class that we observe empirically can capture hyperparameter-tuning loss surfaces. Our method’s convergence guarantee automatically adapts to Lipschitz constants and other problem difficulty parameters, recovering and extending prior results. We complement our theoretical development with experimental validation on hyperparameter tuning tasks",
    "volume": "main",
    "checked": true,
    "id": "82db20f72ab93ec71c5d1010e00ca8f52c649ada",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/dadvar23a.html": {
    "title": "Conditional abstraction trees for sample-efficient reinforcement learning",
    "abstract": "In many real-world problems, the learning agent needs to learn a problem’s abstractions and solution simultaneously. However, most such abstractions need to be designed and refined by hand for different problems and domains of application. This paper presents a novel top-down approach for constructing state abstractions while carrying out reinforcement learning (RL). Starting with state variables and a simulator, it presents a novel domain-independent approach for dynamically computing an abstraction based on the dispersion of temporal difference errors in abstract states as the agent continues acting and learning. Extensive empirical evaluation on multiple domains and problems shows that this approach automatically learns semantically rich abstractions that are finely-tuned to the problem, yield strong sample efficiency, and result in the RL agent significantly outperforming existing approaches",
    "volume": "main",
    "checked": true,
    "id": "5d895e7e96ca4bea83cea0eebc2dd78761e6eb24",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/dai23a.html": {
    "title": "Improvable Gap Balancing for Multi-Task Learning",
    "abstract": "In multi-task learning (MTL), gradient balancing has recently attracted more research interest than loss balancing since it often leads to better performance. However, loss balancing is much more efficient than gradient balancing, and thus it is still worth further exploration in MTL. Note that prior studies typically ignore that there exist varying improvable gaps across multiple tasks, where the improvable gap per task is defined as the distance between the current training progress and desired final training progress. Therefore, after loss balancing, the performance imbalance still arises in many cases. In this paper, following the loss balancing framework, we propose two novel improvable gap balancing (IGB) algorithms for MTL: one takes a simple heuristic, and the other (for the first time) deploys deep reinforcement learning for MTL. Particularly, instead of directly balancing the losses in MTL, both algorithms choose to dynamically assign task weights for improvable gap balancing. Moreover, we combine IGB and gradient balancing to show the complementarity between the two types of algorithms. Extensive experiments on two benchmark datasets demonstrate that our IGB algorithms lead to the best results in MTL via loss balancing and achieve further improvements when combined with gradient balancing. Code is available at https://github.com/YanqiDai/IGB4MTL",
    "volume": "main",
    "checked": true,
    "id": "5a948c68a634c92a29b67ee9f6a861e2fd31970b",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/das23a.html": {
    "title": "CrysMMNet: Multimodal Representation for Crystal Property Prediction",
    "abstract": "Machine Learning models have emerged as a powerful tool for fast and accurate prediction of different crystalline properties. Exiting state-of-the-art models rely on a single modality of crystal data i.e crystal graph structure, where they construct multi-graph by establishing edges between nearby atoms in 3D space and apply GNN to learn materials representation. Thereby, they encode local chemical semantics around the atoms successfully but fail to capture important global periodic structural information like space group number, crystal symmetry, rotational information etc, which influence different crystal properties.  In this work, we leverage textual descriptions of materials to model global structural information into graph structure and learn a more robust and enriched representation of crystalline materials. To this effect, we first curate a textual dataset for crystalline material databases containing descriptions of each material. Further, we propose CrysMMNet, a simple multi-modal framework, which fuses both structural and textual representation together to generate a joint multimodal representation of crystalline materials. We conduct extensive experiments on two benchmark datasets across ten different properties to show that CrysMMNet outperforms existing state-of-the-art baseline methods with a good margin. We also observe that fusing the textual representation with crystal graph structure provides consistent improvement for all the SOTA GNN models compared to their own vanilla versions. We have shared the textual dataset, that we have curated for both the benchmark material databases, with the community for future use",
    "volume": "main",
    "checked": true,
    "id": "1b17d27c9a057b807cac5930c1f4712dd6fe2380",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/das23b.html": {
    "title": "Dirichlet Proportions Model for Hierarchically Coherent Probabilistic Forecasting",
    "abstract": "Probabilistic, hierarchically coherent forecasting is a key problem in many practical forecasting applications – the goal is to obtain coherent probabilistic predictions for a large number of  time series  arranged in a pre-specified tree hierarchy.  In this paper, we present an end-to-end deep  probabilistic model for hierarchical forecasting that is motivated by a classical top-down strategy. It jointly learns the distribution of the root time series, and the (dirichlet) proportions according to which each parent time-series is split among its children at any point in time. The resulting forecasts are naturally coherent, and provide probabilistic predictions over all time series in the hierarchy. We experiment on several public datasets and demonstrate significant improvements of up to 26% on most datasets compared to state-of-the-art baselines. Finally, we also provide theoretical justification for the superiority of our top-down approach compared to the more traditional bottom-up modeling",
    "volume": "main",
    "checked": true,
    "id": "fdb2f705ccbdff1c2703336474debb0c55628a60",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/de-smet23a.html": {
    "title": "Neural probabilistic logic programming in discrete-continuous domains",
    "abstract": "Neural-symbolic AI (NeSy) allows neural networks to exploit symbolic background knowledge in the form of logic. It has been shown to aid learning in the limited data regime and to facilitate inference on out-of-distribution data. Probabilistic NeSy focuses on integrating neural networks with both logic and probability theory, which additionally allows learning under uncertainty. A major limitation of current probabilistic NeSy systems, such as DeepProbLog, is their restriction to finite probability distributions, i.e., discrete random variables. In contrast, deep probabilistic programming (DPP) excels in modelling and optimising continuous probability distributions. Hence, we introduce DeepSeaProbLog, a neural probabilistic logic programming language that incorporates DPP techniques into NeSy. Doing so results in the support of inference and learning of both discrete and continuous probability distributions under logical constraints. Our main contributions are 1) the semantics of DeepSeaProbLog and its corresponding inference algorithm, 2) a proven asymptotically unbiased learning algorithm, and 3) a series of experiments that illustrate the versatility of our approach",
    "volume": "main",
    "checked": true,
    "id": "ef77d8bba77371953051f40bc7c04cc591d9aad3",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/donnat23a.html": {
    "title": "Studying the Effect of GNN Spatial Convolutions On The Embedding Space's Geometry",
    "abstract": "By recursively summing node features over entire neighborhoods, spatial graph convolution operators have been heralded as key to the success of Graph Neural Networks (GNNs). Yet, despite the multiplication of GNN methods across tasks and applications, the effect of this aggregation operation has yet to be analyzed. In fact, while most recent efforts in the GNN community have focused on optimizing the architecture of the neural network, fewer works have attempted to characterize  (a)  the different classes of spatial convolution operators, (b) their impact on the geometry of the embedding space, and (c) how the choice of a particular convolution should relate to properties of the data. In this paper, we propose to answer all three questions by dividing existing operators into two main classes (symmetrized vs. row-normalized spatial convolutions), and show how these correspond to different implicit biases on the data. Finally, we show that this convolution operator is in fact tunable, and explicit regimes in which certain choices of convolutions — and therefore, embedding geometries — might be more appropriate",
    "volume": "main",
    "checked": true,
    "id": "6259eaf5ca1be6d6cc910415ed4675b441ae6483",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/el-laham23a.html": {
    "title": "Deep Gaussian mixture ensembles",
    "abstract": "This work introduces a novel probabilistic deep learning technique called deep Gaussian mixture ensembles (DGMEs), which enables accurate quantification of both epistemic and aleatoric uncertainty. By assuming the data generating process follows that of a Gaussian mixture, DGMEs are capable of approximating complex probability distributions, such as heavy-tailed or multimodal distributions. Our contributions include the derivation of an expectation-maximization (EM) algorithm used for learning the model parameters, which results in an upper-bound on the log-likelihood of training data over that of standard deep ensembles.  Additionally, the proposed EM training procedure allows for learning of mixture weights, which is not commonly done in ensembles. Our experimental results demonstrate that DGMEs outperform state-of-the-art uncertainty quantifying deep learning models in handling complex predictive densities",
    "volume": "main",
    "checked": true,
    "id": "8244264e1a581cb1e0b740db56ffa4179ea2d241",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/fan23a.html": {
    "title": "Personalized federated domain adaptation for item-to-item recommendation",
    "abstract": "Item-to-Item (I2I) recommendation is an important function that suggests replacement or complement options for an item based on their functional similarities or synergies. To capture such item relationships effectively, the recommenders need to understand why subsets of items are co-viewed or co-purchased by the customers. Graph-based models, such as graph neural networks (GNNs), provide a natural framework to combine, ingest and extract valuable insights from such high-order item relationships. However, learning GNNs effectively for I2I requires ingesting a large amount of relational data, which might not always be available, especially in new, emerging market segments. To mitigate this data bottleneck, we postulate that recommendation patterns learned from existing market segments (with private data) could be adapted to build effective warm-start models for emerging ones. To achieve this, we introduce a personalized graph adaptation model based on GNNs to summarize, assemble and adapt recommendation patterns across market segments with heterogeneous customer behaviors into effective local models",
    "volume": "main",
    "checked": true,
    "id": "1e0c7e421d81c58bccea799535664c010874f68e",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/fan23b.html": {
    "title": "Generating Synthetic Datasets by Interpolating along Generalized Geodesics",
    "abstract": "Data for pretraining machine learning models often consists of collections of heterogeneous datasets. Although training on their union is reasonable in agnostic settings, it might be suboptimal when the target domain —where the model will ultimately be used— is known in advance. In that case, one would ideally pretrain only on the dataset(s) most similar to the target one. Instead of limiting this choice to those datasets already present in the pretraining collection, here we explore extending this search to all datasets that can be synthesized as ‘combinations’ of them. We define such combinations as multi-dataset interpolations, formalized through the notion of generalized geodesics from optimal transport (OT) theory. We compute these geodesics using a recent notion of distance between labeled datasets, and derive alternative interpolation schemes based on it: using either barycentric projections or optimal transport maps, the latter computed using recent neural OT methods. These methods are scalable, efficient, and —notably— can be used to interpolate even between datasets with distinct and unrelated label sets. Through various experiments in transfer learning in computer vision, we demonstrate this is a promising new approach for targeted on-demand dataset synthesis",
    "volume": "main",
    "checked": true,
    "id": "096ea80e2893b7ad4267c173963c2ada9bc01b9d",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v216/fathullah23a.html": {
    "title": "Logit-based ensemble distribution distillation for robust autoregressive sequence uncertainties",
    "abstract": "Efficiently and reliably estimating uncertainty is an important objective in deep learning. It is especially pertinent to autoregressive sequence tasks, where training and inference costs are typically very high. However, existing research has predominantly focused on tasks with static data such as image classification. In this work, we investigate Ensemble Distribution Distillation (EDD) applied to large-scale natural language sequence-to-sequence data. EDD aims to compress the superior uncertainty performance of an expensive (teacher) ensemble into a cheaper (student) single model. Importantly, the ability to separate knowledge (epistemic) and data (aleatoric) uncertainty is retained. Existing probability-space approaches to EDD, however, are difficult to scale to large vocabularies. We show, for modern transformer architectures on large-scale translation tasks, that modelling the ensemble logits, instead of softmax probabilities, leads to significantly better students. Moreover, the students surprisingly even outperform Deep Ensembles by up to $\\sim$10% AUROC on out-of-distribution detection, whilst matching them at in-distribution translation",
    "volume": "main",
    "checked": true,
    "id": "febf10dc1bff691005e837383c33be78530783f5",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/foldager23a.html": {
    "title": "On the role of model uncertainties in Bayesian optimisation",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/ganesh23a.html": {
    "title": "Does Momentum Help in Stochastic Optimization? A Sample Complexity Analysis",
    "abstract": "Stochastic Heavy Ball (SHB) and Nesterov’s Accelerated Stochastic Gradient (ASG) are popular momentum methods in optimization. While the benefits of these acceleration ideas in deterministic settings are well understood, their advantages in stochastic optimization are unclear. Several works have recently claimed that SHB and ASG always help in stochastic optimization. Our work shows that i.) these claims are either flawed or one-sided (e.g., consider only the bias term but not the variance), and ii.) when both these terms are accounted for, SHB and ASG do not always help. Specifically, for any quadratic optimization, we obtain a lower bound on the sample complexity of SHB and ASG, accounting for both bias and variance, and show that the vanilla SGD can achieve the same bound",
    "volume": "main",
    "checked": true,
    "id": "bcfd01032dc2448085645b70e6ff9039d3c9d23e",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v216/gao23a.html": {
    "title": "Time-Conditioned Generative Modeling of Object-Centric Representations for Video Decomposition and Prediction",
    "abstract": "When perceiving the world from multiple viewpoints, humans have the ability to reason about the complete objects in a compositional manner even when an object is completely occluded from certain viewpoints. Meanwhile, humans are able to imagine novel views after observing multiple viewpoints. Recent remarkable advances in multi-view object-centric learning still leaves some unresolved problems: 1) The shapes of partially or completely occluded objects can not be well reconstructed. 2) The novel viewpoint prediction depends on expensive viewpoint annotations rather than implicit rules in view representations. In this paper, we introduce a time-conditioned generative model for videos. To reconstruct the complete shape of an object accurately, we enhance the disentanglement between the latent representations of objects and views, where the latent representations of time-conditioned views are jointly inferred with a Transformer and then are input to a sequential extension of Slot Attention to learn object-centric representations. In addition, Gaussian processes are employed as priors of view latent variables for video generation and novel-view prediction without viewpoint annotations. Experiments on multiple datasets demonstrate that the proposed model can make object-centric video decomposition, reconstruct the complete shapes of occluded objects, and make novel-view predictions",
    "volume": "main",
    "checked": true,
    "id": "a783974416c8c96c809b7c595f0fc40d07fb0861",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v216/garg23a.html": {
    "title": "Information theoretic clustering via divergence maximization among clusters",
    "abstract": "Information-theoretic clustering is one of the most promising and principled approaches to finding clusters with minimal apriori assumptions. The key criterion therein is to maximize the mutual information between the data points and their cluster labels. Such an approach, however, does not explicitly promote any type of inter-cluster behavior. We instead propose to maximize the Kullback-Leibler divergence between the underlying data distributions associated to clusters (referred to as cluster distributions). We show it to entail the mutual information criterion along with maximizing cross entropy between the cluster distributions. For practical efficiency, we propose to empirically estimate the objective of KL-D between clusters in its dual form leveraging deep neural nets as a dual function approximator. Remarkably, our theoretical analysis establishes that estimating the divergence measure in its dual form simplifies the problem of clustering to one of optimally finding k-1 cut points for k clusters in the 1-D dual functional space. Overall, our approach enables linear-time clustering algorithms with theoretical guarantees of near-optimality, owing to the submodularity of the objective. We show the empirical superiority of our approach w.r.t. current state-of-the-art methods on the challenging task of clustering noisy timeseries as observed in domains such as neuroscience, healthcare, financial markets, spatio-temporal environmental dynamics, etc",
    "volume": "main",
    "checked": true,
    "id": "94a3b40064886282ade152240c4370ebc603870f",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/garg23b.html": {
    "title": "In- or out-of-distribution detection via dual divergence estimation",
    "abstract": "Detecting out-of-distribution (OOD) samples is a problem of practical importance for a reliable use of deep neural networks (DNNs) in production settings. The corollary to this problem is the detection in-distribution (ID) samples, which is applicable to domain adaptation scenarios for augmenting a train set with ID samples from other data sets, or to continual learning for replay from the past. For both ID or OOD detection, we propose a principled yet simple approach of (empirically) estimating KL-Divergence, in its dual form, for a given test set w.r.t. a known set of ID samples in order to quantify the contribution of each test sample individually towards the divergence measure and accordingly detect it as OOD or ID. Our approach is compute-efficient and enjoys strong theoretical guarantees. For WideResnet101 and ViT-L-16, by considering ImageNet-1k dataset as the ID benchmark, we evaluate the proposed OOD detector on 51 test (OOD) datasets, and observe drastically and consistently lower false positive rates w.r.t. all the competitive methods. Moreover, the proposed ID detector is evaluated, using ECG and stock price datasets, for the task of data augmentation in domain adaptation and continual learning settings, and we observe higher efficacy compared to relevant baselines",
    "volume": "main",
    "checked": false,
    "id": "135e3fe23727a7d7d2be27761554e387ac000d02",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/geng23a.html": {
    "title": "A Data-Driven State Aggregation Approach for Dynamic Discrete Choice Models",
    "abstract": "In dynamic discrete choice models, a commonly studied problem is estimating parameters of agent reward functions (also known as ’structural’ parameters) using agent behavioral data. This task is also known as inverse reinforcement learning. Maximum likelihood estimation for such models requires dynamic programming, which is limited by the curse of dimensionality [Bellman, 1957]. In this work, we present a novel algorithm that provides a data-driven method for selecting and aggregating states, which lowers the computational and sample complexity of estimation. Our method works in two stages. First, we estimate agent Qfunctions, and leverage them alongside a clustering algorithm to select a subset of states that are most pivotal for driving changes in Q-functions. Second, with these selected \"aggregated\" states, we conduct maximum likelihood estimation using a popular nested fixed-point algorithm [Rust, 1987]. The proposed two-stage approach mitigates the curse of dimensionality by reducing the problem dimension. Theoretically, we derive finite-sample bounds on the associated estimation error, which also characterize the trade-off of computational complexity, estimation error, and sample complexity. We demonstrate the empirical performance of the algorithm in two classic dynamic discrete choice estimation applications",
    "volume": "main",
    "checked": true,
    "id": "b01784b1a5d792fd1154fac08e87de601eb23ccf",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v216/ghalebikesabi23a.html": {
    "title": "Quasi-Bayesian nonparametric density estimation via autoregressive predictive updates",
    "abstract": "Bayesian methods are a popular choice for statistical inference in small-data regimes due to the regularization effect induced by the prior. %, which serves to counteract overfitting. In the context of density estimation, the standard nonparametric Bayesian approach is to target the posterior predictive of the Dirichlet process mixture model. In general, direct estimation of the posterior predictive is intractable and so methods typically resort to approximating the posterior distribution as an intermediate step. The recent development of quasi-Bayesian predictive copula updates, however, has made it possible to perform tractable predictive density estimation without the need for posterior approximation. Although these estimators are computationally appealing, they struggle on non-smooth data distributions. This is due to the comparatively restrictive form of the likelihood models from which the proposed copula updates were derived. To address this shortcoming, we consider a Bayesian nonparametric model with an autoregressive likelihood decomposition and a Gaussian process prior. While the predictive update of such a model is typically intractable, we derive a quasi-Bayesian update that achieves state-of-the-art results in small-data regimes",
    "volume": "main",
    "checked": true,
    "id": "88b36c675ec87711113ece8de556c3e31ef3ec08",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/gharari23a.html": {
    "title": "Copula-based deep survival models for dependent censoring",
    "abstract": "A survival dataset describes a set of instances (e.g. patients) and provides, for each, either the time until an event (e.g. death), or the censoring time (e.g. when lost to follow-up - which is a lower bound on the time until the event). We consider the challenge of survival prediction: learning, from such data, a predictive model that can produce an individual survival distribution for a novel instance. Many contemporary methods of survival prediction implicitly assume that the event and censoring distributions are independent conditional on the instance’s covariates - a strong assumption that is difficult to verify (as we observe only one outcome for each instance) and which can induce significant bias when it does not hold. This paper presents a parametric model of survival that extends modern non-linear survival analysis by relaxing the assumption of conditional independence. On synthetic and semi-synthetic data, our approach significantly improves estimates of survival distributions compared to the standard that assumes conditional independence in the data",
    "volume": "main",
    "checked": true,
    "id": "f99eda552c295353451b0c455014b316ea2224ee",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/ghosh23a.html": {
    "title": "Probabilistically robust conformal prediction",
    "abstract": "Conformal prediction (CP) is a framework to quantify uncertainty of machine learning classifiers including deep neural networks. Given a testing example and a trained classifier, CP produces a prediction set of candidate labels with a user-specified  coverage (i.e., true class label is contained with high probability). Almost all the existing work on CP assumes clean testing data and there is not much known about the robustness of CP algorithms w.r.t natural/adversarial perturbations to testing examples. This paper studies the problem of probabilistically robust conformal prediction (PRCP) which ensures robustness to most perturbations around clean input examples. PRCP generalizes the standard CP (cannot handle perturbations) and adversarially robust CP (ensures robustness w.r.t worst-case perturbations) to achieve better trade-offs between nominal performance and robustness.  We propose a novel adaptive PRCP (aPRCP) algorithm to achieve probabilistically robust coverage. The key idea behind aPRCP is to determine two parallel thresholds, one for data samples and another one for the perturbations on data (aka \"quantile-of-quantile” design). We provide theoretical analysis to show that aPRCP algorithm achieves robust coverage. Our experiments on CIFAR-10, CIFAR-100, and ImageNet datasets using deep neural networks demonstrate that aPRCP achieves better trade-offs than state-of-the-art CP and adversarially robust CP algorithms",
    "volume": "main",
    "checked": true,
    "id": "199f67917bc2f4abf067df9301bc0bcb5657f203",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/glaser23a.html": {
    "title": "Fast and scalable score-based kernel calibration tests",
    "abstract": "We introduce the Kernel Calibration Conditional Stein Discrepancy test (KCCSD test), a nonparametric, kernel-based test for assessing the calibration of probabilistic models with well-defined scores. In contrast to previous methods, our test avoids the need for possibly expensive expectation approximations while providing control over its type-I error. We achieve these improvements by using a new family of kernels for score-based probabilities that can be estimated without probability density samples, and by using a Conditional Goodness of Fit criterion for the KCCSD test’s U-statistic. We demonstrate the properties of our test on various synthetic settings",
    "volume": "main",
    "checked": false,
    "id": "02e3e85035a39f13f0979828502d7cd00e5f2000",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v216/glazunov23a.html": {
    "title": "Vacant holes for unsupervised detection of the outliers in compact latent representation",
    "abstract": "Detection of the outliers is pivotal for any machine learning model deployed and operated in real-world. It is essential for the Deep Neural Networks that were shown to be overconfident with such inputs. Moreover, even deep generative models that allow estimation of the probability density of the input fail in achieving this task. In this work, we concentrate on the specific type of these models: Variational Autoencoders (VAEs). First, we unveil a significant theoretical flaw in the assumption of the classical VAE model. Second, we enforce an accommodating topological property to the image of the deep neural mapping to the latent space: compactness to alleviate the flaw and obtain the means to provably bound the image within the determined limits by squeezing both inliers and outliers together. We enforce compactness using two approaches: $(i)$ Alexandroff extension and  $(ii)$ fixed Lipschitz continuity constant on the mapping of the encoder of the VAEs. Finally and most importantly, we discover that the anomalous inputs predominantly tend to land on the vacant latent holes within the compact space, enabling their successful identification. For that reason, we introduce a specifically devised score for hole detection and evaluate the solution against several baseline benchmarks achieving promising results",
    "volume": "main",
    "checked": true,
    "id": "6d8e9305c2991c689a130a5f564a8fafa5682fd7",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/goan23a.html": {
    "title": "Piecewise Deterministic Markov Processes for Bayesian Neural Networks",
    "abstract": "Inference on modern Bayesian Neural Networks (BNNs) often relies on a variational inference treatment, imposing violated assumptions of independence and the form of the posterior. Traditional MCMC approaches avoid these assumptions at the cost of increased computation due to its incompatibility to subsampling of the likelihood. New Piecewise Deterministic Markov Process (PDMP) samplers permit subsampling, though introduce a model-specific inhomogenous Poisson Process (IPPs) which is difficult to sample from. This work introduces a new generic and adaptive thinning scheme for sampling from these IPPs, and demonstrates how this approach can accelerate the application of PDMPs for inference in BNNs. Experimentation illustrates how inference with these methods is computationally feasible, can improve predictive accuracy, MCMC mixing performance, and provide informative uncertainty measurements when compared against other approximate inference schemes",
    "volume": "main",
    "checked": true,
    "id": "04b611800a40dcd91f3f6d36b36f57c93cd14fdd",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/gorji23a.html": {
    "title": "A scalable Walsh-Hadamard regularizer to overcome the low-degree spectral bias of neural networks",
    "abstract": "Despite the capacity of neural nets to learn arbitrary functions, models trained through gradient descent often exhibit a bias towards “simpler” functions. Various notions of simplicity have been introduced to characterize this behavior. Here, we focus on the case of neural networks with discrete (zero-one) inputs through the lens of their Fourier (Walsh-Hadamard) transforms, where the notion of simplicity can be captured through the degree of the Fourier coefficients. We empirically show that neural networks have a tendency to learn lower-degree frequencies. We show how this spectral bias towards simpler features can in fact hurt the neural network’s generalization on real-world datasets. To remedy this we propose a new scalable functional regularization scheme that aids the neural network to learn higher degree frequencies. Our regularizer also helps avoid erroneous identification of low-degree frequencies, which further improves generalization. We extensively evaluate our regularizer on synthetic datasets to gain insights into its behavior. Finally, we show significantly improved generalization on four different datasets compared to standard neural networks and other relevant baselines",
    "volume": "main",
    "checked": true,
    "id": "6f91a3f7967c921c435bbd5cff5659c0face74a7",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/gou23a.html": {
    "title": "Stochastic Graphical Bandits with Heavy-Tailed Rewards",
    "abstract": "We consider stochastic graphical bandits, where after pulling an arm, the decision maker observes rewards of not only the chosen arm but also its neighbors in a feedback graph. Most of existing work assumes that the rewards are drawn from bounded or at least sub-Gaussian distributions, which however may be violated in many practical scenarios such as social advertising and financial markets. To settle this issue, we investigate stochastic graphical bandits with heavy-tailed rewards, where the distributions have finite moments of order $1+\\epsilon$, for some $\\epsilon\\in(0, 1]$. Firstly, we develop one UCB-type algorithm, whose expected regret is upper bounded by a sum of gap-based quantities over the clique covering of the feedback graph. The key idea is to estimate the reward means of the selected arm’s neighbors by more refined robust estimators, and to construct a graph-based upper confidence bound for selecting candidates. Secondly, we design another elimination-based strategy and improve the regret bound to a gap-based sum with size controlled by the independence number of the feedback graph. For benign graphs, the independence number could be smaller than the size of the clique covering, resulting in tighter regret bounds. Finally, we conduct experiments on synthetic data to demonstrate the effectiveness of our methods",
    "volume": "main",
    "checked": true,
    "id": "0accb465a2a533c14ba4a2a826fe7310ee42686c",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/gudovskiy23a.html": {
    "title": "Concurrent Misclassification and Out-of-Distribution Detection for Semantic Segmentation via Energy-Based Normalizing Flow",
    "abstract": "Recent semantic segmentation models accurately classify test-time examples that are similar to a training dataset distribution. However, their discriminative closed-set approach is not robust in practical data setups with distributional shifts and out-of-distribution (OOD) classes. As a result, the predicted probabilities can be very imprecise when used as confidence scores at test time. To address this, we propose a generative model for concurrent in-distribution misclassification (IDM) and OOD detection that relies on a normalizing flow framework. The proposed flow-based detector with an energy-based inputs (FlowEneDet) can extend previously deployed segmentation models without their time-consuming retraining. Our FlowEneDet results in a low-complexity architecture with marginal increase in the memory footprint. FlowEneDet achieves promising results on Cityscapes, Cityscapes-C, FishyScapes and SegmentMeIfYouCan benchmarks in IDM/OOD detection when applied to pretrained DeepLabV3+ and SegFormer semantic segmentation models",
    "volume": "main",
    "checked": true,
    "id": "d660a837306bd81c2f6b0a2429bb43399c9fe98b",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/gultchin23a.html": {
    "title": "Functional causal Bayesian optimization",
    "abstract": "We propose functional causal Bayesian optimization (fCBO), a method for finding interventions that optimize a target variable in a known causal graph. fCBO extends the CBO family of methods to enable functional interventions, which set a variable to be a deterministic function of other variables in the graph. fCBO models the unknown objectives with Gaussian processes whose inputs are defined in a reproducing kernel Hilbert space, thus allowing to compute distances among vector-valued functions. In turn, this enables to sequentially select functions to explore by maximizing an expected improvement acquisition functional while keeping the typical computational tractability of standard BO settings. We introduce graphical criteria that establish when considering functional interventions allows attaining better target effects, and conditions under which selected interventions are also optimal for conditional target effects. We demonstrate the benefits of the method in a synthetic and in a real-world causal graph",
    "volume": "main",
    "checked": true,
    "id": "f9f422cdd999c9ea85a30a037445fb7bc93b0809",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/gunther23a.html": {
    "title": "Causal Discovery for time series from multiple datasets with latent contexts",
    "abstract": "Causal discovery from time series data is a typical problem setting across the sciences. Often, multiple datasets of the same system variables are available, for instance, time series of river runoff from different catchments. The local catchment systems then share certain causal parents, such as time-dependent large-scale weather over all catchments, but differ in other catchment-specific drivers, such as the altitude of the catchment. These drivers can be called temporal and spatial contexts, respectively, and are often partially unobserved. Pooling the datasets and considering the joint causal graph among system, context, and certain auxiliary variables enables us to overcome such latent confounding of system variables. In this work, we present a non-parametric time series causal discovery method, J(oint)-PCMCI$^+$, that efficiently learns such joint causal time series graphs when both observed and latent contexts are present, including time lags. We present asymptotic consistency results and numerical experiments demonstrating the utility and limitations of the method",
    "volume": "main",
    "checked": true,
    "id": "a36cefa2643a9bfa3a40c4543a2ffee3cbfc117e",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/guo23a.html": {
    "title": "Sufficient identification conditions and semiparametric estimation under missing not at random mechanisms",
    "abstract": "Conducting valid statistical analyses is challenging in the presence of missing-not-at-random (MNAR) data, where the missingness mechanism is dependent on the missing values themselves even conditioned on the observed data. Here, we consider a MNAR model that generalizes several prior popular MNAR models in two ways: first, it is less restrictive in terms of statistical independence assumptions imposed on the underlying joint data distribution, and second, it allows for all variables in the observed sample to have missing values. This MNAR model corresponds to a so-called criss-cross structure considered in the literature on graphical models of missing data that prevents nonparametric identification of the entire missing data model. Nonetheless, part of the complete-data distribution remains nonparametrically identifiable. By exploiting this fact and considering a rich class of exponential family distributions, we establish sufficient conditions for identification of the complete-data distribution as well as the entire missingness mechanism. We then propose methods for testing the independence restrictions encoded in such models using odds ratio as our parameter of interest. We adopt two semiparametric approaches for estimating the odds ratio parameter and establish the corresponding asymptotic theories: one involves maximizing a conditional likelihood with order statistics and the other uses estimating equations. The utility of our methods is illustrated via simulation studies",
    "volume": "main",
    "checked": true,
    "id": "340cc33b915d5a1f4780ee3fc3e6b1e5d9d6571d",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/haldar23a.html": {
    "title": "Interpretable differencing of machine learning models",
    "abstract": "Understanding the differences between machine learning (ML) models is of interest in scenarios ranging from choosing amongst a set of competing models, to updating a deployed model with new training data. In these cases, we wish to go beyond differences in overall metrics such as accuracy to identify where in the feature space do the differences occur. We formalize this problem of model differencing as one of predicting a dissimilarity function of two ML models’ outputs, subject to the representation of the differences being human-interpretable. Our solution is to learn a Joint Surrogate Tree (JST), which is composed of two conjoined decision tree surrogates for the two models. A JST provides an intuitive representation of differences and places the changes in the context of the models’ decision logic. Context is important as it helps users to map differences to an underlying mental model of an AI system. We also propose a refinement procedure to increase the precision of a JST. We demonstrate, through an empirical evaluation, that such contextual differencing is concise and can be achieved with no loss in fidelity over naive approaches",
    "volume": "main",
    "checked": true,
    "id": "3f646154c94d6e3ee401843ce83e1044c7389401",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/hamalainen23a.html": {
    "title": "Differentiable user models",
    "abstract": "Probabilistic user modeling is essential for building machine learning systems in the ubiquitous cases with humans in the loop. However, modern advanced user models, often designed as cognitive behavior simulators, are incompatible with modern machine learning pipelines and computationally prohibitive for most practical applications. We address this problem by introducing widely-applicable differentiable surrogates for bypassing this computational bottleneck; the surrogates enable computationally efficient inference with modern cognitive models. We show experimentally that modeling capabilities comparable to the only available solution, existing likelihood-free inference methods, are achievable with a computational cost suitable for online applications. Finally, we demonstrate how AI-assistants can now use cognitive models for online interaction in a menu-search task, which has so far required hours of computation during interaction",
    "volume": "main",
    "checked": true,
    "id": "141db563d308b9e3866c6ab6405f814bdfe673a6",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/han23a.html": {
    "title": "On the Convergence of Continual Learning with Adaptive Methods",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/harviainen23a.html": {
    "title": "Revisiting Bayesian network learning with small vertex cover",
    "abstract": "The problem of structure learning in Bayesian networks asks for a directed acyclic graph (DAG) that maximizes a given scoring function. Since the problem is NP-hard, research effort has been put into discovering restricted classes of DAGs for which the search problem can be solved in polynomial time. Here, we initiate investigation of questions that have received less attention thus far: Are the known polynomial algorithms close to the best possible, or is there room for significant improvements? If the interest is in Bayesian learning, that is, in sampling or weighted counting of DAGs, can we obtain similar complexity results? Focusing on DAGs with bounded vertex cover number—a class studied in Korhonen and Parviainen’s seminal work (NIPS 2015)—we answer the questions in the affirmative. We also give, apparently the first, proof that the counting problem is $#$P-hard in general. In addition, we show that under the vertex-cover constraint counting is $#$W[1]-hard",
    "volume": "main",
    "checked": false,
    "id": "470bad55c673e9d09db7a4d3717f866359b0b12f",
    "citation_count": 6
  },
  "https://proceedings.mlr.press/v216/harviainen23b.html": {
    "title": "On inference and learning with probabilistic generating circuits",
    "abstract": "Probabilistic generating circuits (PGCs) are economical representations of multivariate probability generating polynomials (PGPs). They unify and extend decomposable probabilistic circuits and determinantal point processes, admitting tractable computation of marginal probabilities. However, the need for addition and multiplication of high-degree polynomials incurs a significant additional factor in the complexity of inference. Here, we give a new inference algorithm that eliminates this extra factor. Specifically, we show that it suffices to keep track of the highest degree coefficients of the computed polynomials, rendering the algorithm linear in the circuit size. In addition, we show that determinant-based circuits need not be expanded to division-free circuits, but can be handled by division-based fast algorithms. While these advances enhance the appeal of PGCs, we also discover an obstacle to learning them from data: it is NP-hard to recognize whether a given PGC encodes a PGP. We discuss the implications of our ambivalent findings and sketch a method, in which learning is restricted to PGCs that are composed of moderate-size subcircuits",
    "volume": "main",
    "checked": true,
    "id": "2e4235999e433a1556aeac2719273b714f66a911",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/hasan23a.html": {
    "title": "Inference and sampling of point processes from diffusion excursions",
    "abstract": "Point processes often have a natural interpretation with respect to a continuous process. We propose a point process construction that describes arrival time observations in terms of the state of a latent diffusion process. In this framework, we relate the return times of a diffusion in a continuous path space to new arrivals of the point process. This leads to a continuous sample path that is used to describe the underlying mechanism generating the arrival distribution. These models arise in many disciplines, such as financial settings where actions in a market are determined by a hidden continuous price or in neuroscience where a latent stimulus generates spike trains. Based on the developments in Itô’s excursion theory, we propose methods for inferring and sampling from the point process derived from the latent diffusion process. We illustrate the approach with numerical examples using both simulated and real data. The proposed methods and framework provide a basis for interpreting point processes through the lens of diffusions",
    "volume": "main",
    "checked": true,
    "id": "33ed7f9bd63ad3c01c5c4e5bdd0f01081ec95e80",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/he23a.html": {
    "title": "Loosely consistent emphatic temporal-difference learning",
    "abstract": "There has been significant interest in searching for off-policy Temporal-Difference (TD) algorithms that find the same solution that would have been obtained in the on-policy regime. An important property of such algorithms is that their expected update has the same fixed point as that of On-policy TD($\\lambda$), which we call loose consistency. Notably, Full-IS-TD($\\lambda$) is the only existing loosely consistent method under general linear function approximation but, unfortunately, has a high variance and is scarcely practical. This notorious high variance issue motivates the introduction of ETD($\\lambda$), which tames down the variance but has a biased fixed point. Inspired by these two methods, we propose a new loosely consistent algorithm called Average Emphatic TD (AETD($\\lambda$)) with a transient bias, which strikes a balance between bias and variance. Further, we unify AETD($\\lambda$) with existing methods and obtain a new family of loosely consistent algorithms called Loosely Consistent Emphatic TD (LC-ETD($\\lambda$, $\\beta$, $\\nu$)), which can control a smooth bias-variance trade-off by varying the speed at which the transient bias fades. Through experiments on illustrative examples, we show the effectiveness and practicality of LC-ETD($\\lambda$, $\\beta$, $\\nu$)",
    "volume": "main",
    "checked": true,
    "id": "dabb6412b7db8ff2f899a8745f7b60d28a36da85",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/he23b.html": {
    "title": "Scalable and robust tensor ring decomposition for large-scale data",
    "abstract": "Tensor ring (TR) decomposition has recently received increased attention due to its superior expressive performance for high-order tensors. However, the applicability of traditional TR decomposition algorithms to real-world applications is hindered by prevalent large data sizes, missing entries, and corruption with outliers. In this work, we propose a scalable and robust TR decomposition algorithm capable of handling large-scale tensor data with missing entries and gross corruptions. We first develop a novel auto-weighted steepest descent method that can adaptively fill the missing entries and identify the outliers during the decomposition process. Further, taking advantage of the tensor ring model, we develop a novel fast Gram matrix computation (FGMC) approach and a randomized subtensor sketching (RStS) strategy which yield significant reduction in storage and computational complexity. Experimental results demonstrate that the proposed method outperforms existing TR decomposition methods in the presence of outliers, and runs significantly faster than existing robust tensor completion algorithms",
    "volume": "main",
    "checked": true,
    "id": "0e60cf2135bedcdcad8626f974f2fee6cd32efc2",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/heap23a.html": {
    "title": "Massively parallel reweighted wake-sleep",
    "abstract": "Reweighted wake-sleep (RWS) is a machine learning method for performing Bayesian inference in a very general class of models. RWS draws $K$ samples from an underlying approximate posterior, then uses importance weighting to provide a better estimate of the true posterior. RWS then updates its approximate posterior towards the importance-weighted estimate of the true posterior. However, recent work [Chattergee and Diaconis, 2018] indicates that the number of samples required for effective importance weighting is exponential in the number of latent variables. Attaining such a large number of importance samples is intractable in all but the smallest models. Here, we develop massively parallel RWS, which circumvents this issue by drawing $K$ samples of all $n$ latent variables, and individually reasoning about all $K^n$ possible combinations of samples. While reasoning about $K^n$ combinations might seem intractable, the required computations can be performed in polynomial time by exploiting conditional independencies in the generative model. We show considerable improvements over standard “global” RWS, which draws $K$ samples from the full joint",
    "volume": "main",
    "checked": true,
    "id": "d5833955c719e2c85daa224ccb34eeb99aea430f",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/hochsprung23a.html": {
    "title": "Increasing effect sizes of pairwise conditional independence tests between random vectors",
    "abstract": "A simple approach to test for conditional independence of two random vectors given a third random vector is to simultaneously test for conditional independence of every pair of components of the two random vectors given the third random vector. In this work, we show that conditioning on additional components of the two random vectors that are independent given the third one increases the tests’ effect sizes while leaving the validity of the overall approach unchanged. We leverage this result to derive a practical pairwise testing algorithm that first chooses tests with a relatively large effect size and then does the actual testing. We show both numerically and theoretically that our algorithm outperforms standard pairwise independence testing and other existing methods if the dependence within the two random vectors is sufficiently high",
    "volume": "main",
    "checked": true,
    "id": "444999e0f8ed72ab19792a97fa5831e07b304ffd",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v216/hu23a.html": {
    "title": "Optimistic Thompson Sampling-based algorithms for episodic reinforcement learning",
    "abstract": "We propose two  Thompson Sampling-like, model-based learning algorithms  for episodic Markov decision processes (MDPs) with a finite time horizon. Our proposed algorithms are inspired by Optimistic Thompson Sampling (O-TS), empirically studied in Chapelle and Li [2011], May et al. [2012] for stochastic multi-armed bandits. The key idea for the original O-TS is to clip the posterior distribution in an optimistic way  to ensure that the sampled models are always better than the empirical models. Both of our proposed algorithms are easy to implement and only need one posterior sample to construct an episode-dependent model. Our first  algorithm, Optimistic Thompson Sampling for MDPs (O-TS-MDP), achieves a $\\widetilde{O} \\left(\\sqrt{AS^2H^4T} \\right)$ regret bound, where $S$ is the size of the state space, $A$ is the size of the action space, $H$ is the number of time-steps per episode and $T$ is the number of episodes. Our second algorithm, Optimistic Thompson Sampling plus for MDPs (O-TS-MDP$^+$),  achieves the (near)-optimal $\\widetilde{O} \\left(\\sqrt{ASH^3T} \\right)$ regret bound by taking a more aggressive clipping strategy.  Since O-TS was only empirically studied previously, we derive regret bounds of O-TS for stochastic bandits. In addition, we propose,  O-TS-Bandit$^+$, a randomized version of UCB1 [Auer et al., 2002], for stochastic bandits. Both O-TS and O-TS-Bandit$^+$ achieve the optimal $O\\left(\\frac{A\\ln(T)}{\\Delta} \\right)$ problem-dependent regret bound, where $\\Delta$ denotes the sub-optimality gap",
    "volume": "main",
    "checked": false,
    "id": "a7ce7811585fd97ed4b282a76ff6a9f751aded4c",
    "citation_count": 14
  },
  "https://proceedings.mlr.press/v216/huang23a.html": {
    "title": "ASTRA: Understanding the practical impact of robustness for probabilistic programs",
    "abstract": "We present the first systematic study of effectiveness of robustness transformations on a diverse set of 24 probabilistic programs representing generalized linear models, mixture models, and time-series models. We evaluate five robustness transformations from literature on each model. We quantify and present insights on (1) the improvement of the posterior prediction accuracy and (2) the execution time overhead of the robustified programs, in the presence of three input noise models.  To automate the evaluation of various robustness transformations, we developed ASTRA - a novel framework for quantifying the robustness of probabilistic programs and exploring the trade-offs between robustness and execution time. Our experimental results indicate that the existing transformations are often suitable only for specific noise models, can significantly increase execution time, and have non-trivial interaction with the inference algorithms",
    "volume": "main",
    "checked": false,
    "id": "517bd6be96d017fd66dfbbba234ba45d79360254",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/huang23b.html": {
    "title": "A near-optimal high-probability swap-Regret upper bound for multi-agent bandits in unknown general-sum games",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/jafarnia-jahromi23a.html": {
    "title": "Posterior sampling-based online learning for the stochastic shortest path model",
    "abstract": "We consider the problem of online reinforcement learning for the Stochastic Shortest Path (SSP) problem modeled as an unknown MDP with an absorbing state. We propose PSRL-SSP, a simple posterior sampling-based reinforcement learning algorithm for the SSP problem. The algorithm operates in epochs. At the beginning of each epoch, a sample is drawn from the posterior distribution on the unknown model dynamics, and the optimal policy with respect to the drawn sample is followed during that epoch. An epoch completes if either the  number of visits to the goal state in the current epoch exceeds that of the previous epoch, or the number of visits to any of the state-action pairs is doubled. We establish a Bayesian regret bound of $\\tilde{\\mathcal{O}}(B_{\\ast} S\\sqrt{AK})$, where $B_{\\ast}$ is an upper bound on the expected cost of the optimal policy, $S$ is the size of the state space, $A$ is the size of the action space, and $K$ is the number of episodes. The algorithm only requires the knowledge of the prior distribution, and has no hyper-parameters to tune. It is the first such posterior sampling algorithm and outperforms numerically previously proposed optimism-based algorithms",
    "volume": "main",
    "checked": false,
    "id": "d390c365bfc801bee09e588ac6b3ef6ed668ffab",
    "citation_count": 14
  },
  "https://proceedings.mlr.press/v216/jahn23a.html": {
    "title": "Investigating a Generalization of Probabilistic Material Implication and Bayesian Conditionals",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/jansen23a.html": {
    "title": "Robust statistical comparison of random variables with locally varying scale of measurement",
    "abstract": "Spaces with locally varying scale of measurement, like multidimensional structures with differently scaled dimensions, are pretty common in statistics and machine learning. Nevertheless, it is still understood as an open question how to exploit the entire information encoded in them properly. We address this problem by considering an order based on (sets of) expectations of random variables mapping into such non-standard spaces. This order contains stochastic dominance and expectation order as extreme cases when no, or respectively perfect, cardinal structure is given.  We derive a (regularized) statistical test for our proposed generalized stochastic dominance (GSD) order, operationalize it by linear optimization, and robustify it by imprecise probability models. Our findings are illustrated with data from multidimensional poverty measurement, finance, and medicine",
    "volume": "main",
    "checked": true,
    "id": "3e92e4b35b2c5dfeba2a910b1e229c1507abaf4d",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v216/jeong23a.html": {
    "title": "Noisy adversarial representation learning for effective and efficient image obfuscation",
    "abstract": "Recent real-world applications of deep learning have led to the development of machine learning as a service (MLaaS). However, the scenario of client-server inference presents privacy concerns, where the server processes raw data sent from the user’s client device. One solution to this issue is to provide an obfuscator function to the client device using Adversarial Representation Learning (ARL). Prior works have primarily focused on the privacy-utility trade-off while overlooking the computational cost and memory burden on the client side. In this paper, we propose an effective and efficient ARL method that incorporates feature noise into the ARL pipeline. We evaluated our approach on various datasets, comparing it with state-of-the-art ARL techniques. Our experimental results indicate that our method achieves better accuracy, lower computation and memory overheads, and improved resistance to information leakage and reconstruction attacks",
    "volume": "main",
    "checked": false,
    "id": "e0136615f33cb89103f3622acf78e5fef51897f0",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/jia23a.html": {
    "title": "Incentivising Diffusion while Preserving Differential Privacy",
    "abstract": "Diffusion auction refers to an emerging paradigm of online marketplace where an auctioneer utilises a social network to attract potential buyers.  Diffusion auction poses significant privacy risks. From the auction outcome, it is possible to infer hidden, and potentially sensitive, preferences of buyers. To mitigate such risks, we initiate the study of differential privacy (DP) in diffusion auction mechanisms. DP is a well-established notion of privacy that protects a system against inference attacks. Achieving DP in diffusion auctions is non-trivial as the well-designed auction rules are required to incentivise the buyers to truthfully report their neighbourhood. We study the single-unit case and design two differentially private diffusion mechanisms (DPDMs): recursive DPDM and layered DPDM. We prove that these mechanisms guarantee differential privacy, incentive compatibility and individual rationality for both valuations and neighbourhood. We then empirically compare their performance on real and synthetic datasets",
    "volume": "main",
    "checked": false,
    "id": "cefa712327e39f9ba98dadcd127df6f202fa5f55",
    "citation_count": 15
  },
  "https://proceedings.mlr.press/v216/jia23b.html": {
    "title": "Content Sharing Design for Social Welfare in Networked Disclosure Game",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/jiang23a.html": {
    "title": "Multi-view graph contrastive learning for solving vehicle routing problems",
    "abstract": "Recently, neural heuristics based on deep learning have reported encouraging results for solving vehicle routing problems (VRPs), especially on independent and identically distributed (i.i.d.) instances, e.g. uniform. However, in the presence of a distribution shift for the testing instances, their performance becomes considerably inferior. In this paper, we propose a multi-view graph contrastive learning (MVGCL) approach to enhance the generalization across different distributions, which exploits a graph pattern learner in a self-supervised fashion to facilitate a neural heuristic equipped with an active search scheme. Specifically, our MVGCL first leverages graph contrastive learning to extract transferable patterns from VRP graphs to attain the generalizable multi-view (i.e. node and graph) representation. Then it adopts the learnt node embedding and graph embedding to assist the neural heuristic and the active search (during inference) for route construction, respectively. Extensive experiments on randomly generated VRP instances of various distributions, and the ones from TSPLib and CVRPLib show that our MVGCL is superior to the baselines in boosting the cross-distribution generalization performance",
    "volume": "main",
    "checked": false,
    "id": "c0d008636619cbae81d09aba48ae7ee15ae0a9a8",
    "citation_count": 9
  },
  "https://proceedings.mlr.press/v216/jiang23b.html": {
    "title": "Bayesian inference for vertex-series-parallel partial orders",
    "abstract": "Partial orders are a natural model for the social hierarchies that may constrain “queue-like” rank-order data. However, the computational cost of counting the linear extensions of a general partial order on a ground set with more than a few tens of elements is prohibitive. Vertex-series-parallel partial orders (VSPs) are a subclass of partial orders which admit rapid counting and represent the sorts of relations we expect to see in a social hierarchy. However, no Bayesian analysis of VSPs has been given to date. We construct a marginally consistent family of priors over VSPs with a parameter controlling the prior distribution over  VSP depth. The prior for VSPs is given in closed form. We extend an existing observation model for queue-like rank-order data to represent noise in our data and carry out Bayesian inference on “Royal Acta” data and Formula 1 race data. Model comparison shows our model is a better fit to the data than Plackett-Luce mixtures, Mallows mixtures, and “bucket order” models and competitive with more complex models fitting general partial orders",
    "volume": "main",
    "checked": true,
    "id": "d098f0f3bd41d676b2cfa030e57ed4d8c7857a8d",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/kalinke23a.html": {
    "title": "Nyström $M$-Hilbert-Schmidt independence criterion",
    "abstract": "Kernel techniques are among the most popular and powerful approaches of data science. Among the key features that make kernels ubiquitous are (i) the number of domains they have been designed for, (ii) the Hilbert structure of the function class associated to kernels facilitating their statistical analysis, and (iii) their ability to represent probability distributions without loss of information. These properties give rise to the immense success of Hilbert-Schmidt independence criterion (HSIC) which is able to capture joint independence of random variables under mild conditions, and permits closed-form estimators with quadratic computational complexity (w.r.t. the sample size). In order to alleviate the quadratic computational bottleneck in large-scale applications, multiple HSIC approximations have been proposed, however these estimators are restricted to $M=2$ random variables, do not extend naturally to the $M\\ge 2$ case, and lack theoretical guarantees. In this work, we propose an alternative Nyström-based HSIC estimator which handles the $M\\ge 2$ case, prove its consistency, and  demonstrate its applicability in multiple contexts, including synthetic examples, dependency testing of media annotations, and causal discovery",
    "volume": "main",
    "checked": false,
    "id": "909d96becd1ca2072096e5c18cc5330b171f9b99",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/kaltenpoth23a.html": {
    "title": "Causal Discovery with Hidden Confounders using the Algorithmic Markov Condition",
    "abstract": "Causal sufficiency is a cornerstone assumption in causal discovery. It is, however, both unlikely to hold in practice as well as unverifiable. When it does not hold, existing methods struggle to return meaningful results. In this paper, we show how to discover the causal network over both observed and unobserved variables. Moreover, we show that the causal model is identifiable in the sparse linear Gaussian case. More generally, we extend the algorithmic Markov condition to include latent confounders. We propose a consistent score based on the Minimum Description Length principle to discover the full causal network, including latent confounders. Based on this score, we develop an effective algorithm that finds those sets of nodes for which the addition of a confounding factor $Z$ is most beneficial, then fits a new causal network over both observed as well as inferred latent variables",
    "volume": "main",
    "checked": true,
    "id": "112526436b2cc5d9022b445ab58b1c58062ceab4",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/kang23a.html": {
    "title": "Heavy-tailed linear bandit with Huber regression",
    "abstract": "Linear bandit algorithms have been extensively studied and have shown successful in sequential decision tasks despite their simplicity. Many algorithms however work under the assumption that the reward is the sum of linear function of observed contexts and a sub-Gaussian error. In practical applications, errors can be heavy-tailed, especially in financial data. In such reward environments, algorithms designed for sub-Gaussian error may underexplore, resulting in suboptimal regret. In this paper, we relax the reward assumption and propose a novel linear bandit algorithm which works well under heavy-tailed errors as well. The proposed algorithm utilizes Huber regression. When contexts are stochastic with positive definite covariance matrix and the $(1+\\delta)$-th moment of the error is bounded by a constant, we show that the high-probability upper bound of the regret is $O(\\sqrt{d}T^{\\frac{1}{1+\\delta}}(\\log dT)^{\\frac{\\delta}{1+\\delta}})$, where $d$ is the dimension of context variables, $T$ is the time horizon, and $\\delta\\in (0,1]$. This bound improves on the state-of-the-art regret bound of the Median of Means and Truncation algorithm by a factor of $\\sqrt{\\log T}$ and $\\sqrt{d}$ for the case where the time horizon $T$ is unknown. We also remark that when $\\delta=1$, the order is the same as the regret bound of linear bandit algorithms designed for sub-Gaussian errors. We support our theoretical findings with synthetic experiments",
    "volume": "main",
    "checked": true,
    "id": "5060593b29982b1917e96d38a73a49a47a59f4df",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/karimi23a.html": {
    "title": "Fed-LAMB: Layer-wise and Dimension-wise Locally Adaptive Federated Learning",
    "abstract": "In the emerging paradigm of Federated Learning (FL), large amount of clients such as mobile devices are used to train possibly high-dimensional models on their respective data. Combining (dimension-wise) adaptive gradient methods (e.g., Adam, AMSGrad) with FL has been an active direction, which is shown to outperform traditional SGD based FL in many cases. In this paper, we focus on the problem of training federated deep neural networks, and propose a novel FL framework which further introduces layer-wise adaptivity to the local model updates to accelerate the convergence of adaptive FL methods. Our framework includes two variants based on two recent locally adaptive federated learning algorithms. Theoretically, we provide a convergence analysis of our layer-wise FL methods, coined Fed-LAMB and Mime-LAMB, which match the convergence rate of state-of-the-art results in adaptive FL and exhibits linear speedup in terms of the number of workers. Experimental results on various datasets and models, under both IID and non-IID local data settings, show that both Fed-LAMB and Mime-LAMB achieve faster convergence speed and better generalization performance, compared to various recent adaptive FL methods",
    "volume": "main",
    "checked": false,
    "id": "6c54fa8e68ad2581d48c326c552d866d376c93ba",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v216/karine23a.html": {
    "title": "Assessing the Impact of Context Inference Error and Partial Observability on RL Methods for Just-In-Time Adaptive Interventions",
    "abstract": "Just-in-Time Adaptive Interventions (JITAIs) are a class of personalized health interventions developed within the behavioral science community. JITAIs aim to provide the right type and amount of support by iteratively selecting a sequence of intervention options from a pre-defined set of components in response to each individual’s time varying state. In this work, we explore the application of reinforcement learning methods to the problem of learning intervention option selection policies. We study the effect of context inference error and partial observability on the ability to learn effective policies. Our results show that the propagation of uncertainty from context inferences is critical to improving intervention efficacy as context uncertainty increases, while policy gradient algorithms can provide remarkable robustness to partially observed behavioral state information",
    "volume": "main",
    "checked": true,
    "id": "7d388f8cca7b27eafcbebd80802220d4d66b139f",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/kim23a.html": {
    "title": "How to use dropout correctly on residual networks with batch normalization",
    "abstract": "For the stable optimization of deep neural networks, regularization methods such as dropout and batch normalization have been used in various tasks. Nevertheless, the correct position to apply dropout has rarely been discussed, and different positions have been employed depending on the practitioners. In this study, we investigate the correct position to apply dropout. We demonstrate that for a residual network with batch normalization, applying dropout at certain positions increases the performance, whereas applying dropout at other positions decreases the performance. Based on theoretical analysis, we provide the following guideline for the correct position to apply dropout: apply one dropout after the last batch normalization but before the last weight layer in the residual branch. We provide detailed theoretical explanations to support this claim and demonstrate them through module tests. In addition, we investigate the correct position of dropout in the head that produces the final prediction. Although the current consensus is to apply dropout after global average pooling, we prove that applying dropout before global average pooling leads to a more stable output. The proposed guidelines are validated through experiments using different datasets and models",
    "volume": "main",
    "checked": true,
    "id": "043073988aa9a023ed9c2620784e3e1d036beed3",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/kim23b.html": {
    "title": "Phase-shifted adversarial training",
    "abstract": "Adversarial training (AT) has been considered an imperative component for safely deploying neural network-based applications. However, it typically comes with slow convergence and worse performance on clean samples (i.e., non-adversarial samples). In this work, we analyze the behavior of neural networks during learning with adversarial samples through the lens of response frequency. Interestingly, we observe that AT causes neural networks to converge slowly to high-frequency information, resulting in highly oscillatory predictions near each data point. To learn high-frequency content efficiently, we first prove that a universal phenomenon, the frequency principle (i.e., lower frequencies are learned first), still holds in AT. Building upon this theoretical foundation, we present a novel approach to AT, which we call phase-shifted adversarial training (PhaseAT). In PhaseAT, the high-frequency components, which are a contributing factor to slow convergence, are adaptively shifted into the low-frequency range where faster convergence occurs. For evaluation, we conduct extensive experiments on CIFAR-10 and ImageNet, using an adaptive attack that is carefully designed for reliable evaluation. Comprehensive results show that PhaseAT substantially improves convergence for high-frequency information, thereby leading to improved adversarial robustness",
    "volume": "main",
    "checked": true,
    "id": "01b5904abf8349e20c9b59e210335844ea36f612",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/kivva23a.html": {
    "title": "On Identifiability of Conditional Causal Effects",
    "abstract": "We address the problem of identifiability of an arbitrary conditional causal effect given both the causal graph and a set of any observational and/or interventional distributions of the form $Q[S]:=P(S|do(V\\setminus S))$, where $V$ denotes the set of all observed variables and $S\\subseteq V$. We call this problem conditional generalized identifiability (c-gID in short) and prove the completeness of Pearl’s $do$-calculus for the c-gID problem by providing sound and complete algorithm for the c-gID problem.  This work revisited the c-gID problem in  Lee et al. [2020], Correa et al. [2021] by adding explicitly the positivity assumption which is crucial for identifiability. It extends the results of [Lee et al., 2019, Kivva et al., 2022] on general identifiability (gID) which studied the problem for  unconditional causal effects and  Shpitser and Pearl [2006b] on identifiability of conditional causal effects given merely the observational distribution $P(\\mathbf{V})$ as our algorithm generalizes the algorithms proposed in  [Kivva et al., 2022] and [Shpitser and Pearl, 2006b]",
    "volume": "main",
    "checked": true,
    "id": "f745237b3395a19ff4d66ee6f15d2deaa9845bad",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/kladny23a.html": {
    "title": "Causal effect estimation from observational and interventional data through matrix weighted linear estimators",
    "abstract": "We study causal effect estimation from a mixture of observational and interventional data in a confounded linear regression model with multivariate treatments. We show that the statistical efficiency in terms of expected squared error can be improved by combining estimators arising from both the observational and interventional setting. To this end, we derive methods based on matrix weighted linear estimators and prove that our methods are asymptotically unbiased in the infinite sample limit. This is an important improvement compared to the pooled estimator using the union of interventional and observational data, for which the bias only vanishes if the ratio of observational to interventional data tends to zero. Studies on synthetic data confirm our theoretical findings. In settings where confounding is substantial and the ratio of observational to interventional data is large, our estimators outperform a Stein-type estimator and various other baselines",
    "volume": "main",
    "checked": true,
    "id": "7f37ee626e6250ccd565707b6f30fc2c7e5ad8bc",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/ko23a.html": {
    "title": "Universal Graph Contrastive Learning with a Novel Laplacian Perturbation",
    "abstract": "Graph Contrastive Learning (GCL) is an effective method for discovering meaningful patterns in graph data. By evaluating diverse augmentations of the graph, GCL learns discriminative representations and provides a flexible and scalable mechanism for various graph mining tasks. This paper proposes a novel contrastive learning framework by introducing Laplacian perturbation. The proposed framework offers a distinct advantage by employing an indirect perturbation method, which provides a more stable approach while maintaining the perturbation effects. Moreover, it exhibits a wide range of applicability by not being restricted to specific graph types. We demonstrate that a spectral graph convolution based on the Laplacian successfully extracts representations from diverse graph types. Our extensive experiments on a variety of real-world datasets, covering multiple graph types, show that the proposed model outperforms state-of-the-art baselines in both node classification and link sign prediction tasks",
    "volume": "main",
    "checked": true,
    "id": "26538c789a73a48fd453e0adc29b8adf921e58cf",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/kong23a.html": {
    "title": "Molecule Design by Latent Space Energy-Based Modeling and Gradual Distribution Shifting",
    "abstract": "Generation of molecules with desired chemical and biological properties such as high drug-likeness, high binding affinity to target proteins, is critical for drug discovery. In this paper, we propose a probabilistic generative model to capture the joint distribution of molecules and their properties. Our model assumes an energy-based model (EBM) in the latent space. Conditional on the latent vector, the molecule and its properties are modeled by a molecule generation model and a property regression model respectively.  To search for molecules with desired properties,  we propose a sampling with gradual distribution shifting (SGDS) algorithm, so that after learning the model initially on the training data of existing molecules and their properties, the proposed algorithm gradually shifts the model distribution towards the region supported by molecules with desired values of properties. Our experiments show that our method achieves very strong performances on various molecule design tasks",
    "volume": "main",
    "checked": true,
    "id": "5604e0f650c6b9939e9e03333206e751675509ca",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/koprulu23a.html": {
    "title": "Reward-machine-guided, self-paced reinforcement learning",
    "abstract": "Self-paced reinforcement learning (RL) aims to improve the data efficiency of learning by automatically creating sequences, namely curricula, of probability distributions over contexts. However, existing techniques for self-paced RL fail in long-horizon planning tasks that involve temporally extended behaviors. We hypothesize that taking advantage of prior knowledge about the underlying task structure can improve the effectiveness of self-paced RL. We develop a self-paced RL algorithm guided by reward machines, i.e., a type of finite-state machine that encodes the underlying task structure. The algorithm integrates reward machines in 1) the update of the policy and value functions obtained by any RL algorithm of choice, and 2) the update of the automated curriculum that generates context distributions. Our empirical results evidence that the proposed algorithm achieves optimal behavior reliably even in cases in which existing baselines cannot make any meaningful progress. It also decreases the curriculum length and reduces the variance in the curriculum generation process by up to one-fourth and four orders of magnitude, respectively",
    "volume": "main",
    "checked": true,
    "id": "639f0f58645cde55171066ea478fd53b8f56b387",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v216/koprulu23b.html": {
    "title": "Risk-aware curriculum generation for heavy-tailed task distributions",
    "abstract": "Automated curriculum generation for reinforcement learning (RL) aims to speed up learning by designing a sequence of tasks of increasing difficulty. Such tasks are usually drawn from probability distributions with exponentially bounded tails, such as uniform or Gaussian distributions. However, existing approaches overlook heavy-tailed distributions. Under such distributions, current methods may fail to learn optimal policies in rare and risky tasks, which fall under the tails and yield the lowest returns, respectively. We address this challenge by proposing a risk-aware curriculum generation algorithm that simultaneously creates two curricula: 1) a primary curriculum that aims to maximize the expected discounted return with respect to a distribution over target tasks, and an auxiliary curriculum that identifies and over-samples rare and risky tasks observed in the primary curriculum. Our empirical results evidence that the proposed algorithm achieves significantly higher returns in frequent as well as rare tasks compared to the state-of-the-art methods",
    "volume": "main",
    "checked": true,
    "id": "75da06848cd0edf01e881d4d80274b9a8623a8cc",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/kreacic23a.html": {
    "title": "Differentially private synthetic data using KD-trees",
    "abstract": "Creation of a synthetic dataset that faithfully represents the data distribution and simultaneously preserves privacy is a major research challenge. Many space partitioning based approaches have emerged in recent years for answering statistical queries in a differentially private manner. However, for synthetic data generation problem, recent research has been mainly focused on deep generative models. In contrast, we exploit space partitioning techniques together with noise perturbation and thus achieve intuitive and transparent algorithms. We propose both data independent and data dependent algorithms for $\\epsilon$-differentially private synthetic data generation whose kernel density resembles that of the real dataset. Additionally, we provide theoretical results on the utility-privacy trade-offs and show how our data dependent approach overcomes the curse of dimensionality and leads to a scalable algorithm. We show empirical utility improvements over the prior work, and discuss performance of our algorithm on a downstream classification task on a real dataset",
    "volume": "main",
    "checked": true,
    "id": "d98ea6564d3a4b7220101f48ef1bc183b3769131",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/kulkarni23a.html": {
    "title": "Optimal Budget Allocation for Crowdsourcing Labels for Graphs",
    "abstract": "Crowdsourcing is an effective and efficient paradigm for obtaining labels for unlabeled corpus employing crowd workers. This work considers the budget allocation problem for a generalized setting on a graph of instances to be labeled where edges encode instance dependencies. Specifically, given a graph and a labeling budget, we propose an optimal policy to allocate the budget among the instances to maximize the overall labeling accuracy. We formulate the problem as a Bayesian Markov Decision Process (MDP), where we define our task as an optimization problem that maximizes the overall label accuracy under budget constraints. Then, we propose a novel stage-wise reward function that considers the effect of worker labels on the whole graph at each timestamp. This reward function is utilized to find an optimal policy for the optimization problem. Theoretically, we show that our proposed policies are consistent when the budget is infinite. We conduct extensive experiments on five real-world graph datasets and demonstrate the effectiveness of the proposed policies to achieve a higher label accuracy under budget constraints",
    "volume": "main",
    "checked": false,
    "id": "bac9c2737471978e9169318ed49a733e2757a2d7",
    "citation_count": 4
  },
  "https://proceedings.mlr.press/v216/lalitha23a.html": {
    "title": "Fixed-Budget Best-Arm Identification with Heterogeneous Reward Variances",
    "abstract": "We study the problem of best-arm identification (BAI) in the fixed-budget setting with heterogeneous reward variances. We propose two variance-adaptive BAI algorithms for this setting: SHVar for known reward variances and SHAdaVar for unknown reward variances. Our algorithms rely on non-uniform budget allocations among the arms where the arms with higher reward variances are pulled more often than those with lower variances. The main algorithmic novelty is in the design of SHAdaVar, which allocates budget greedily based on overestimating the unknown reward variances. We bound probabilities of misidentifying the best arms in both SHVar and SHAdaVar. Our analyses rely on novel lower bounds on the number of pulls of an arm that do not require closed-form solutions to the budget allocation problem. Since one of our budget allocation problems is analogous to the optimal experiment design with unknown variances, we believe that our results are of a broad interest. Our experiments validate our theory, and show that SHVar and SHAdaVar outperform algorithms from prior works with analytical guarantees",
    "volume": "main",
    "checked": true,
    "id": "963dfd5e214b63de9a21cb50cebaaed7e36e9b8f",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/lanners23a.html": {
    "title": "Variable importance matching for causal inference",
    "abstract": "Our goal is to produce methods for observational causal inference that are auditable, easy to troubleshoot, yield accurate treatment effect estimates, and scalable to high-dimensional data. We describe a general framework called Model-to-Match that achieves these goals by (i) learning a distance metric via outcome modeling, (ii) creating matched groups using the distance metric, and (iii) using the matched groups to estimate treatment effects. Model-to-Match uses variable importance measurements to construct a distance metric, making it a flexible framework that can be adapted to various applications. Concentrating on the scalability of the problem in the number of potential confounders, we operationalize the Model-to-Match framework with LASSO. We derive performance guarantees for settings where LASSO outcome modeling consistently identifies all confounders (importantly without requiring the linear model to be correctly specified). We also provide experimental results demonstrating the auditability of matches, as well as extensions to more general nonparametric outcome modeling",
    "volume": "main",
    "checked": true,
    "id": "31af7b0eafc4ae7a0788e62d860733a15b37e3f2",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/laousy23a.html": {
    "title": "Towards better certified segmentation via diffusion models",
    "abstract": "The robustness of image segmentation has been an important research topic in the past few years as segmentation models have reached production-level accuracy. However, like classification models, segmentation models can be vulnerable to adversarial perturbations, which hinders their use in critical-decision systems like healthcare or autonomous driving. Recently, randomized smoothing has been proposed to certify segmentation predictions by adding Gaussian noise to the input to obtain theoretical guarantees. However, this method exhibits a trade-off between the amount of added noise and the level of certification achieved. In this paper, we address the problem of certifying segmentation prediction using a combination of randomized smoothing and diffusion models. Our experiments show that combining randomized smoothing and diffusion models significantly improves certified robustness, with results indicating a mean improvement of 21 points in accuracy compared to previous state-of-the-art methods on Pascal-Context and Cityscapes public datasets. Our method is independent of the selected segmentation model and does not need any additional specialized training procedure",
    "volume": "main",
    "checked": true,
    "id": "7a75192e153180d3e3f4a34686ea7b7d3543a3f1",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/lee23a.html": {
    "title": "Finding Invariant Predictors Efficiently via Causal Structure",
    "abstract": "One fundamental problem in machine learning is out-of-distribution generalization. A method named the surgery estimator incorporates the causal structure in the form of a directed acyclic graph (DAG) to find predictors that are invariant across target domains using distributional invariances via Pearl’s do-calculus. However, finding a surgery estimator can take exponential time as the current methods need to search through all possible predictors. In this work, we first provide a graphical characterization of the identifiability of conditional causal queries. Next, we leverage this characterization together with a greedy search step to develop a polynomial-time algorithm for finding invariant predictors using the causal graph. Given the correct causal graph, our method is guaranteed to find at least one invariant predictor, if it exists. We show that our proposed algorithm can significantly reduce the run-time both in simulated and semi-synthetic data experiments and have predictive performance that is comparable to the existing work that runs in exponential time",
    "volume": "main",
    "checked": true,
    "id": "970d186d77ae00fe39c5a26112158810a2177554",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/leemann23a.html": {
    "title": "When are post-hoc conceptual explanations identifiable?",
    "abstract": "Interest in understanding and factorizing learned embedding spaces through conceptual explanations is steadily growing. When no human concept labels are available, concept discovery methods search trained embedding spaces for interpretable concepts like object shape or color that can provide post-hoc explanations for decisions. Unlike previous work, we argue that concept discovery should be identifiable, meaning that a number of known concepts can be provably recovered to guarantee reliability of the explanations. As a starting point, we explicitly make the connection between concept discovery and classical methods like Principal Component Analysis and Independent Component Analysis by showing that they can recover independent concepts under non-Gaussian distributions. For dependent concepts, we propose two novel approaches that exploit functional compositionality properties of image-generating processes. Our provably identifiable concept discovery methods substantially outperform competitors on a battery of experiments including hundreds of trained models and dependent concepts, where they exhibit up to 29 % better alignment with the ground truth. Our results highlight the strict conditions under which reliable concept discovery without human labels can be guaranteed and provide a formal foundation for the domain. Our code is available online",
    "volume": "main",
    "checked": true,
    "id": "806fa5f68362741ef30f8bb1cbd54d393caa2540",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/li23a.html": {
    "title": "Memory Mechanism for Unsupervised Anomaly Detection",
    "abstract": "Unsupervised anomaly detection is a binary classification that detects anomalies in unseen samples given only unlabeled normal data. Reconstruction-based approaches are widely used, which perform reconstruction error minimization on training data to learn normal patterns and quantify the degree of anomalies by reconstruction errors on testing data. However, this approach tends to miss anomalies when the normal data has multi-pattern. Because the model generalizes unrestrictedly beyond normal patterns even to include anomaly patterns. In this paper, we proposed a memory mechanism that memorizes typical normal patterns through a capacity-controlled external differentiable matrix so that the generalization of the model to anomalies is limited by the retrieval of the matrix. We achieved state-of-the-art performance on several public benchmarks",
    "volume": "main",
    "checked": false,
    "id": "6a6642bee623cefe732c3db991399c6692cd2353",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/li23b.html": {
    "title": "Nonconvex stochastic scaled gradient descent and generalized eigenvector problems",
    "abstract": "Motivated by the problem of online canonical correlation analysis, we propose the Stochastic Scaled-Gradient Descent (SSGD) algorithm for minimizing the expectation of a stochastic function over a generic Riemannian manifold. SSGD generalizes the idea of projected stochastic gradient descent and allows the use of scaled stochastic gradients instead of stochastic gradients. In the special case of a spherical constraint, which arises in generalized eigenvector problems, we establish a nonasymptotic finite-sample bound of $\\sqrt{1/T}$, and show that this rate is minimax optimal, up to a polylogarithmic factor of relevant parameters. On the asymptotic side, a novel trajectory-averaging argument allows us to achieve local asymptotic normality with a rate that matches that of Ruppert-Polyak-Juditsky averaging. We bring these ideas together in an application to online canonical correlation analysis, deriving, for the first time in the literature, an optimal one-time-scale algorithm with an explicit rate of local asymptotic convergence to normality. Numerical studies of canonical correlation analysis are also provided for synthetic data",
    "volume": "main",
    "checked": false,
    "id": "c7caf1075630e0124ecae79871fec9a8562ba636",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v216/li23c.html": {
    "title": "Gaussian Process Surrogate Models for Neural Networks",
    "abstract": "Not being able to understand and predict the behavior of deep learning systems makes it hard to decide what architecture and algorithm to use for a given problem. In science and engineering, modeling is a methodology used to understand complex systems whose internal processes are opaque. Modeling replaces a complex system with a simpler, more interpretable surrogate. Drawing inspiration from this, we construct a class of surrogate models for neural networks using Gaussian processes. Rather than deriving kernels for infinite neural networks, we learn kernels empirically from the naturalistic behavior of finite neural networks. We demonstrate our approach captures existing phenomena related to the spectral bias of neural networks, and then show that our surrogate models can be used to solve practical problems such as identifying which points most influence the behavior of specific neural networks and predicting which architectures and algorithms will generalize well for specific datasets",
    "volume": "main",
    "checked": true,
    "id": "17e2eadc63ac2e87d34983fe14f7cc5ea41bf24d",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/li23d.html": {
    "title": "CUE: An Uncertainty Interpretation Framework for Text Classifiers Built on Pre-Trained Language Models",
    "abstract": "Text classifiers built on Pre-trained Language Models (PLMs) have achieved remarkable progress in various tasks including sentiment analysis, natural language inference, and question-answering. However, the occurrence of uncertain predictions by these classifiers poses a challenge to their reliability when deployed in practical applications. Much effort has been devoted to designing various probes in order to understand what PLMs capture. But few studies have delved into factors influencing PLM-based classifiers’ predictive uncertainty. In this paper, we propose a novel framework, called CUE, which aims to interpret uncertainties inherent in the predictions of PLM-based models. In particular, we first map PLM-encoded representations to a latent space via a variational auto-encoder. We then generate text representations by perturbing the latent space which causes fluctuation in predictive uncertainty. By comparing the difference in predictive uncertainty between the perturbed and the original text representations, we are able to identify the latent dimensions responsible for uncertainty and subsequently trace back to the input features that contribute to such uncertainty. Our extensive experiments on four benchmark datasets encompassing linguistic acceptability classification, emotion classification, and natural language inference show the feasibility of our proposed framework. Our source code is available at https://github.com/lijiazheng99/CUE",
    "volume": "main",
    "checked": true,
    "id": "a3cc857a10898b2eedd04ff1dd33e8b6c9b1e04c",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/lippe23a.html": {
    "title": "BISCUIT: Causal Representation Learning from Binary Interactions",
    "abstract": "Identifying the causal variables of an environment and how to intervene on them is of core value in applications such as robotics and embodied AI. While an agent can commonly interact with the environment and may implicitly perturb the behavior of some of these causal variables, often the targets it affects remain unknown. In this paper, we show that causal variables can still be identified for many common setups, e.g., additive Gaussian noise models, if the agent’s interactions with a causal variable can be described by an unknown binary variable. This happens when each causal variable has two different mechanisms, e.g., an observational and an interventional one. Using this identifiability result, we propose BISCUIT, a method for simultaneously learning causal variables and their corresponding binary interaction variables. On three robotic-inspired datasets, BISCUIT accurately identifies causal variables and can even be scaled to complex, realistic environments for embodied AI",
    "volume": "main",
    "checked": true,
    "id": "d2516874dadcc6d37c9edcaebd067c3a200f2d95",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/liu23a.html": {
    "title": "Accelerating Voting by Quantum Computation",
    "abstract": "Studying the computational complexity and designing fast algorithms for determining winners under voting rules are classical and fundamental questions in computational social choice. In this paper, we accelerate voting by leveraging quantum computation: we propose a quantum-accelerated voting algorithm that can be applied to any anonymous voting rule. We show that our algorithm can be quadratically faster than any classical algorithm (based on sampling with replacement) under a wide range of common voting rules, including positional scoring rules, Copeland, and single transferable voting (STV). Precisely, our quantum-accelerated voting algorithm outputs the correct winner with high probability in $\\Theta\\left(\\frac{n}{\\text{MOV}}\\right)$ time, where $n$ is the number of votes and $\\text{MOV}$ is margin of victory, the smallest number of voters to change the winner. In contrast, any classical voting algorithm based on sampling with replacement requires $\\Omega\\left(\\frac{n^2}{\\text{MOV}^2}\\right)$ time under a large class of voting rules. Our theoretical results are supported by experiments under plurality, Borda, Copeland, and STV",
    "volume": "main",
    "checked": true,
    "id": "1e322240348565940a3f8531051202cfd22e0d54",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/liu23b.html": {
    "title": "Residual-based error bound for physics-informed neural networks",
    "abstract": "Neural networks are universal approximators and are studied for their use in solving differential equations.  However, a major criticism is the lack of error bounds for obtained solutions.  This paper proposes a technique to rigorously evaluate the error bound of Physics-Informed Neural Networks (PINNs) on most linear ordinary differential equations (ODEs), certain nonlinear ODEs, and first-order linear partial differential equations (PDEs).  The error bound is based purely on equation structure and residual information and does not depend on assumptions of how well the networks are trained.  We propose algorithms that bound the error efficiently. Some proposed algorithms provide tighter bounds than others at the cost of longer run time",
    "volume": "main",
    "checked": true,
    "id": "897929e7aec13c68034799072fd046dd9d5603da",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/liu23c.html": {
    "title": "No-Regret Linear Bandits beyond Realizability",
    "abstract": "We study linear bandits when the underlying reward function is not linear. Existing work relies on a uniform misspecification parameter $\\epsilon$ that measures the sup-norm error of the best linear approximation. This results in an unavoidable linear regret whenever $\\epsilon > 0$. We describe a more natural model of misspecification which only requires the approximation error at each input $x$ to be proportional to the suboptimality gap at $x$.  It captures the intuition that, for optimization problems, near-optimal regions should matter more and we can tolerate larger approximation errors in suboptimal regions. Quite surprisingly, we show that the classical LinUCB algorithm — designed for the realizable case — is automatically robust against such gap-adjusted misspecification.  It achieves a near-optimal $\\sqrt{T}$ regret for problems that the best-known regret is almost linear in time horizon $T$. Technically, our proof relies on a novel self-bounding argument that bounds the part of the regret due to misspecification by the regret itself",
    "volume": "main",
    "checked": true,
    "id": "b23a477a022ff9f571d76c70ee86957d07413b90",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/losalka23a.html": {
    "title": "Benefits of monotonicity in safe exploration with Gaussian processes",
    "abstract": "We consider the problem of sequentially maximising an unknown function over a set of actions while ensuring that every sampled point has a function value below a given safety threshold. We model the function using kernel-based and Gaussian process methods, while differing from previous works in our assumption that the function is monotonically increasing with respect to a safety variable. This assumption is motivated by various practical applications such as adaptive clinical trial design and robotics. Taking inspiration from the GP-UCB and SAFEOPT algorithms, we propose an algorithm, monotone safe UCB (M-SafeUCB) for this task.  We show that M-SafeUCB enjoys theoretical guarantees in terms of safety, a suitably-defined regret notion, and approximately finding the entire safe boundary. In addition, we illustrate that the monotonicity assumption yields significant benefits in terms of the guarantees obtained, as well as algorithmic simplicity and efficiency. We support our theoretical findings by performing empirical evaluations on a variety of functions, including a simulated clinical trial experiment",
    "volume": "main",
    "checked": true,
    "id": "762f6beb77cd9f58561c24e98258b8e609554747",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/luo23a.html": {
    "title": "Practical privacy-preserving Gaussian process regression via secret sharing",
    "abstract": "Gaussian process regression (GPR) is a non-parametric model that has been used in many real-world applications that involve sensitive personal data (e.g., healthcare, finance, etc.) from multiple data owners. To fully and securely exploit the value of different data sources, this paper proposes a privacy-preserving GPR method based on secret sharing (SS), a secure multi-party computation (SMPC) technique. In contrast to existing studies that protect the data privacy of GPR via homomorphic encryption, differential privacy, or federated learning, our proposed method is more practical and can be used to preserve the data privacy of both the model inputs and outputs for various data-sharing scenarios (e.g., horizontally/vertically-partitioned data). However, it is non-trivial to directly apply SS on the conventional GPR algorithm, as it includes some operations whose accuracy and/or efficiency have not been well-enhanced in the current SMPC protocol. To address this issue, we derive a new SS-based exponentiation operation through the idea of “confusion-correction” and construct an SS-based matrix inversion algorithm based on Cholesky decomposition. More importantly, we theoretically analyze the communication cost and the security of the proposed SS-based operations. Empirical results show that our proposed method can achieve reasonable accuracy and efficiency under the premise of preserving data privacy",
    "volume": "main",
    "checked": true,
    "id": "20a3843c930878d1775b54c606f8744dfa4be28e",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/ma23a.html": {
    "title": "DeepGD3: Unknown-Aware Deep Generative/Discriminative Hybrid Defect Detector for PCB Soldering Inspection",
    "abstract": "",
    "volume": "main",
    "checked": false,
    "id": null,
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/ma23b.html": {
    "title": "Federated learning of models pre-trained on different features with consensus graphs",
    "abstract": "Learning an effective global model on private and decentralized datasets has become an increasingly important challenge of machine learning when applied in practice. Existing distributed learning paradigms, such as Federated Learning, enable this via model aggregation which enforces a strong form of modeling homogeneity and synchronicity across clients. This is however not suitable to many practical scenarios. For example, in distributed sensing, heterogeneous sensors reading data from different views of the same phenomenon would need to use different models for different data modalities. Local learning therefore happens in isolation but inference requires merging the local models to achieve consensus. To enable consensus among local models, we propose a feature fusion approach that extracts local representations from local models and incorporates them into a global representation that improves the prediction performance. Achieving this requires addressing two non-trivial problems. First, we need to learn an alignment between similar feature components which are arbitrarily arranged across clients to enable representation aggregation. Second, we need to learn a consensus graph that captures the high-order interactions between local feature spaces and how to combine them to achieve a better prediction. This paper presents solutions to these problems and demonstrates them in real-world applications on time series data such as power grids and traffic networks",
    "volume": "main",
    "checked": true,
    "id": "d2149b7f99bdba7e1dcc7911a8c839f09c7767aa",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v216/malinovsky23a.html": {
    "title": "Random Reshuffling with Variance Reduction: New Analysis and Better Rates",
    "abstract": "Virtually all state-of-the-art methods for training supervised machine learning models are variants of Stochastic Gradient Descent (SGD), enhanced with a number of additional tricks, such as minibatching, momentum, and adaptive stepsizes. However, one of the most basic questions in the design of  successful SGD methods, one that is orthogonal to the aforementioned tricks, is the choice of the next training data point to be learning from. Standard variants of SGD employ a  sampling with replacement strategy, which means that the next training data point is sampled from the entire data set, often independently of all previous samples. While standard SGD is well understood theoretically,  virtually all widely used machine learning software is based on  sampling without replacement as this is often empirically superior. That is, the training data is randomly shuffled/permuted, either only once at the beginning, strategy known as random shuffling (RS), or before every epoch, strategy known as random reshuffling (RR),  and  training proceeds in the data order dictated by the shuffling.  RS and RR strategies  have for a long time remained beyond the reach of  theoretical analysis that would satisfactorily explain their success. However, very recently, Mishchenko et al. [2020] provided tight  sublinear convergence rates through a novel analysis, and showed that these strategies can improve upon standard SGD in certain regimes. Inspired by these results, we seek to further  improve the rates of shuffling-based methods. In particular, we show that it is possible to enhance them with a variance reduction mechanism, obtaining linear convergence rates.\tTo the best of our knowledge, our linear convergence rates are the best for any method based on sampling without replacement",
    "volume": "main",
    "checked": true,
    "id": "983e5aa3ab653c02f13e19a28d926eb65d8d0aaa",
    "citation_count": 10
  },
  "https://proceedings.mlr.press/v216/margossian23a.html": {
    "title": "The Shrinkage-Delinkage Trade-off: an Analysis of Factorized Gaussian Approximations for Variational Inference",
    "abstract": "When factorized approximations are used for variational inference (VI), they tend to underestimate the uncertainty—as measured in various ways—of the distributions they are meant to approximate. We consider two popular ways to measure the uncertainty deficit of VI: (i) the degree to which it underestimates the componentwise variance, and (ii) the degree to which it underestimates the entropy. To better understand these effects, and the relationship between them, we examine an informative setting where they can be explicitly (and elegantly) analyzed: the approximation of a Gaussian, $p$, with a dense covariance matrix, by a Gaussian, $q$, with a diagonal covariance matrix. We prove that $q$ always underestimates both the componentwise variance and the entropy of $p$, though not necessarily to the same degree. Moreover we demonstrate that the entropy of $q$ is determined by the trade-off of two competing forces: it is decreased by the shrinkage of its componentwise variances (our first measure of uncertainty) but it is increased by the factorized approximation which delinks the nodes in the graphical model of $p$. We study various manifestations of this trade-off, notably one where, as the dimension of the problem grows, the per-component entropy gap between $p$ and $q$ becomes vanishingly small even though $q$ underestimates every componentwise variance by a constant multiplicative factor. We also use the shrinkage-delinkage trade-off to bound the entropy gap in terms of the problem dimension and the condition number of the correlation matrix of $p$. Finally we present empirical results on both Gaussian and non-Gaussian targets, the former to validate our analysis and the latter to explore its limitations",
    "volume": "main",
    "checked": true,
    "id": "4cc2ad2bc7be1a2beaec9d6f6986467b7e5c0f39",
    "citation_count": 1
  }
}