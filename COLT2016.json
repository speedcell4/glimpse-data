{
  "https://proceedings.mlr.press/v49/azizzadenesheli16b.html": {
    "title": "Open Problem: Approximate Planning of POMDPs in the class of Memoryless Policies",
    "abstract": "Planning plays an important role in the broad class of decision theory. Planning has drawn much attention in recent work in the robotics and sequential decision making areas. Recently, Reinforcement Learning (RL), as an agent-environment interaction problem, has brought further attention to planning methods. Generally in RL, one can assume a generative model, e.g. graphical models, for the environment, and then the task for the RL agent is to learn the model parameters and find the optimal strategy based on these learnt parameters. Based on environment behavior, the agent can assume various types of generative models, e.g. Multi Armed Bandit for a static environment, or Markov Decision Process (MDP) for a dynamic environment. The advantage of these popular models is their simplicity, which results in tractable methods of learning the parameters and finding the optimal policy. The drawback of these models is again their simplicity: these models usually underfit and underestimate the actual environment behavior. For example, in robotics, the agent usually has noisy observations of the environment inner state and MDP is not a suitable model. \nMore complex models like Partially Observable Markov Decision Process (POMDP) can compensate for this drawback. Fitting this model to the environment, where the partial observation is given to the agent, generally gives dramatic performance improvement, sometimes unbounded improvement, compared to MDP. In general, finding the optimal policy for the POMDP model is computationally intractable and fully non convex, even for the class of memoryless policies. The open problem is to come up with a method to find an exact or an approximate optimal stochastic memoryless policy for POMDP models.",
    "volume": "main",
    "checked": true,
    "id": "7ecf92dd908be0dcb9f02ce95e96618e31561a53",
    "citation_count": 9
  },
  "https://proceedings.mlr.press/v49/chen16b.html": {
    "title": "Open Problem: Best Arm Identification: Almost Instance-Wise Optimality and the Gap Entropy Conjecture",
    "abstract": "The best arm identification problem (BEST-1-ARM) is the most basic pure exploration problem in stochastic multi-armed bandits. The problem has a long history and attracted significant attention for the last decade. However, we do not yet have a complete understanding of the optimal sample complexity of the problem: The state-of-the-art algorithms achieve a sample complexity of $O(\\sum_{i=2}^{n} \\Delta_{i}^{-2}(\\ln\\delta^{-1} + \\ln\\ln\\Delta_i^{-1}))$ ($\\Delta_{i}$ is the difference between the largest mean and the $i^{th}$ mean), while the best known lower bound is $\\Omega(\\sum_{i=2}^{n} \\Delta_{i}^{-2}\\ln\\delta^{-1})$ for general instances and $\\Omega(\\Delta^{-2} \\ln\\ln \\Delta^{-1})$ for the two-arm instances. We propose to study the instance-wise optimality for the BEST-1-ARM problem. Previous work has proved that it is impossible to have an instance optimal algorithm for the 2-arm problem. However, we conjecture that modulo the additive term $\\Omega(\\Delta_2^{-2} \\ln\\ln \\Delta_2^{-1})$ (which is an upper bound and worst case lower bound for the 2-arm problem), there is an instance optimal algorithm for BEST-1-ARM. Moreover, we introduce a new quantity, called the gap entropy for a best-arm problem instance, and conjecture that it is the instance-wise lower bound. Hence, resolving this conjecture would provide a final answer to the old and basic problem.",
    "volume": "main",
    "checked": true,
    "id": "468c34cbda647a734357b4b16445e81d383054c1",
    "citation_count": 5
  },
  "https://proceedings.mlr.press/v49/feragen16.html": {
    "title": "Open Problem: Kernel methods on manifolds and metric spaces. What is the probability of a positive definite geodesic exponential kernel?",
    "abstract": "Radial kernels are well-suited for machine learning over general geodesic metric spaces, where pairwise distances are often the only computable quantity available. We have recently shown that geodesic exponential kernels are only positive definite for all bandwidths when the input space has strong linear properties. This negative result hints that radial kernel are perhaps not suitable over geodesic metric spaces after all. Here, however, we present evidence that large intervals of bandwidths exist where geodesic exponential kernels have high probability of being positive definite over finite datasets, while still having significant predictive power. From this we formulate conjectures on the probability of a positive definite kernel matrix for a finite random sample, depending on the geometry of the data space and the spread of the sample.",
    "volume": "main",
    "checked": true,
    "id": "97f64963ad37af62936ec4420ad0f45768d743f4",
    "citation_count": 14
  },
  "https://proceedings.mlr.press/v49/freund16.html": {
    "title": "Open Problem: Second order regret bounds based on scaling time",
    "abstract": "We argue that the second order bounds given in Cesa-Bianchi et al. (2006), which accumulate the square of the loss of each action separately, are loose. We propose a different form of a second order bound and conjecture the it is satisfied by NormalHedge Chaudhuri et al. (2009). 1. Background 1.1. Motivation The upper bound on the regret of exponential weights algorithms Littlestone and Warmuth (1989); Cesa-Bianchi et al. (1993); Freund and Schapire (1999) have a leading term of the form √ n logN where n is the length of the sequence and N is the number of experts/actions. The bounds that the loss (gain) per iteration is in a bounded range, typically [0, 1]. Obviously, if the range is restricted (a priori) to [0, 1/2] then the bound will also be halved. Consider a scenario in which the range is [0, 1] but the actual observed losses are in the range [0, 1/2], we would like to have an algorithm which will perform (almost) as well as an algorithm that knew a-priori that the range is [0, 1/2]. The a-priori knowledge is consequential because multiplicative weights algorithms use it to choose the learning rate. For a more general formulation of the problem suppose that the losses in iteration t are in the range [0, at]. Then we are seeking an algorithm with a bound of the form √√√√ T ∑",
    "volume": "main",
    "checked": true,
    "id": "1f4e7074c03ae5ac21b23547a13fe561441762fa",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v49/frongillo16.html": {
    "title": "Open Problem: Property Elicitation and Elicitation Complexity",
    "abstract": "The study of property elicitation is gaining ground in statistics and machine learning as a way to view and reason about the expressive power of emiprical risk minimization (ERM). Yet beyond a widening frontier of special cases, the two most fundamental questions in this area remain open: which statistics are elicitable (computable via ERM), and which loss functions elicit them? Moreover, recent work suggests a complementary line of questioning: given a statistic, how many ERM parameters are needed to compute it? We give concrete instantiations of these important questions, which have numerous applications to machine learning and related fields.",
    "volume": "main",
    "checked": true,
    "id": "e958dc023bb0a0dfa3d39d63b216a735fed1384d",
    "citation_count": 2
  },
  "https://proceedings.mlr.press/v49/orabona16.html": {
    "title": "Open Problem: Parameter-Free and Scale-Free Online Algorithms",
    "abstract": "Existing vanilla algorithms for online linear optimization have O((ηR(u) + 1/η) √ T ) regret with respect to any competitor u, whereR(u) is a 1-strongly convex regularizer and η > 0 is a tuning parameter of the algorithm. For certain decision sets and regularizers, the so-called parameter-free algorithms have Õ( √ R(u)T ) regret with respect to any competitor u. Vanilla algorithm can achieve the same bound only for a fixed competitor u known ahead of time by setting η = 1/ √ R(u). A drawback of both vanilla and parameter-free algorithms is that they assume that the norm of the loss vectors is bounded by a constant known to the algorithm. There exist scale-free algorithms that haveO((ηR(u)+1/η) √ T max1≤t≤T ‖`t‖) regret with respect to any competitor u and for any sequence of loss vector `1, . . . , `T . Parameter-free analogue of scale-free algorithms have never been designed. Is is possible to design algorithms that are simultaneously parameter-free and scale-free?",
    "volume": "main",
    "checked": true,
    "id": "a40eba2a940a2632f6ed80d3b0a5aada9c1b39bd",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v49/agrawal16.html": {
    "title": "An efficient algorithm for contextual bandits with knapsacks, and an extension to concave objectives",
    "abstract": "We consider a contextual version of multi-armed bandit problem with global knapsack constraints. In each round, the outcome of pulling an arm is a scalar reward and a resource consumption vector, both dependent on the context, and the global knapsack constraints require the total consumption for each resource to be below some pre-fixed budget. The learning agent competes with an arbitrary set of context-dependent policies. This problem was introduced by Badanidiyuru et al. (2014), who gave a computationally inefficient algorithm with near-optimal regret bounds for it. We give a computationally efficient algorithm for this problem with slightly better regret bounds, by generalizing the approach of Agarwal et al. (2014) for the non-constrained version of the problem. The computational time of our algorithm scales logarithmically in the size of the policy space. This answers the main open question of Badanidiyuru et al. (2014). We also extend our results to a variant where there are no knapsack constraints but the objective is an arbitrary Lipschitz concave function of the sum of outcome vectors.",
    "volume": "main",
    "checked": true,
    "id": "6462b2684c83c6f05736ae121c2362fb9498c60c",
    "citation_count": 60
  },
  "https://proceedings.mlr.press/v49/aliakbarpour16.html": {
    "title": "Learning and Testing Junta Distributions",
    "abstract": "We consider the problem of learning distributions in the presence of irrelevant features. This problem is formalized by introducing a new notion of k-junta distributions. Informally, a distribution D over the domain X is a k-junta distribution with respect to another distribution U over the same domain if there is a set J ⊆ [n] of size |J | ≤ k that captures the difference between D and U . We show that it is possible to learn k-junta distributions with respect to the uniform distribution over the Boolean hypercube {0, 1} in time poly(n, 1/ ). This result is obtained via a new Fourier-based learning algorithm inspired by the Low-Degree Algorithm of Linial, Mansour, and Nisan (1993). We also consider the problem of testing whether an unknown distribution is a k-junta distribution with respect to the uniform distribution. We give a nearly-optimal algorithm for this task. Both the analysis of the algorithm and the lower bound showing its optimality are obtained by establishing connections between the problem of testing junta distributions and testing uniformity of weighted collections of distributions.",
    "volume": "main",
    "checked": true,
    "id": "b66ab920facbbeda363b6848b49a87cf284b5290",
    "citation_count": 10
  },
  "https://proceedings.mlr.press/v49/alon16.html": {
    "title": "Sign rank versus VC dimension",
    "abstract": "This work studies the maximum possible sign rank of $N \\times N$ sign matrices with a given VC dimension $d$. For $d=1$, this maximum is {three}. For $d=2$, this maximum is $\\tilde{\\Theta}(N^{1/2})$. For $d >2$, similar but slightly less accurate statements hold. {The lower bounds improve over previous ones by Ben-David et al., and the upper bounds are novel.} \nThe lower bounds are obtained by probabilistic constructions, using a theorem of Warren in real algebraic topology. The upper bounds are obtained using a result of Welzl about spanning trees with low stabbing number, and using the moment curve. \nThe upper bound technique is also used to: (i) provide estimates on the number of classes of a given VC dimension, and the number of maximum classes of a given VC dimension -- answering a question of Frankl from '89, and (ii) design an efficient algorithm that provides an $O(N/\\log(N))$ multiplicative approximation for the sign rank. \nWe also observe a general connection between sign rank and spectral gaps which is based on Forster's argument. Consider the $N \\times N$ adjacency matrix of a $\\Delta$ regular graph with a second eigenvalue of absolute value $\\lambda$ and $\\Delta \\leq N/2$. We show that the sign rank of the signed version of this matrix is at least $\\Delta/\\lambda$. We use this connection to prove the existence of a maximum class $C\\subseteq\\{\\pm 1\\}^N$ with VC dimension $2$ and sign rank $\\tilde{\\Theta}(N^{1/2})$. This answers a question of Ben-David et al.~regarding the sign rank of large VC classes. We also describe limitations of this approach, in the spirit of the Alon-Boppana theorem. \nWe further describe connections to communication complexity, geometry, learning theory, and combinatorics.",
    "volume": "main",
    "checked": true,
    "id": "06c752556638f616f485dac276b11b331fb0cf3b",
    "citation_count": 31
  },
  "https://proceedings.mlr.press/v49/anandkumar16.html": {
    "title": "Efficient approaches for escaping higher order saddle points  in non-convex optimization",
    "abstract": "Local search heuristics for non-convex optimizations are popular in applied machine learning. However, in general it is hard to guarantee that such algorithms even converge to a local minimum, due to the existence of complicated saddle point structures in high dimensions. Many functions have degenerate saddle points such that the first and second order derivatives cannot distinguish them with local optima. In this paper we use higher order derivatives to escape these saddle points: we design the first efficient algorithm guaranteed to converge to a third order local optimum (while existing techniques are at most second order). We also show that it is NP-hard to extend this further to finding fourth order local optima.",
    "volume": "main",
    "checked": true,
    "id": "80bd932f681eae54b4c4ee2894e6f8a403a7c5ca",
    "citation_count": 132
  },
  "https://proceedings.mlr.press/v49/anari16.html": {
    "title": "Monte Carlo Markov Chain Algorithms for Sampling Strongly Rayleigh Distributions and Determinantal Point Processes",
    "abstract": "Strongly Rayleigh distributions are natural generalizations of product and determinantal probability distributions and satisfy strongest form of negative dependence properties. We show that the \"natural\" Monte Carlo Markov Chain (MCMC) is rapidly mixing in the support of a {\\em homogeneous} strongly Rayleigh distribution. As a byproduct, our proof implies Markov chains can be used to efficiently generate approximate samples of a $k$-determinantal point process. This answers an open question raised by Deshpande and Rademacher.",
    "volume": "main",
    "checked": true,
    "id": "1a29685253327bfe9acf85bff33bf73e1c282b3c",
    "citation_count": 111
  },
  "https://proceedings.mlr.press/v49/auer16.html": {
    "title": "An algorithm with nearly optimal pseudo-regret for both stochastic and adversarial bandits",
    "abstract": "We present an algorithm that achieves almost optimal pseudo-regret bounds against adversarial and stochastic bandits. Against adversarial bandits the pseudo-regret is $O(K\\sqrt{n \\log n})$ and against stochastic bandits the pseudo-regret is $O(\\sum_i (\\log n)/\\Delta_i)$. We also show that no algorithm with $O(\\log n)$ pseudo-regret against stochastic bandits can achieve $\\tilde{O}(\\sqrt{n})$ expected regret against adaptive adversarial bandits. This complements previous results of Bubeck and Slivkins (2012) that show $\\tilde{O}(\\sqrt{n})$ expected adversarial regret with $O((\\log n)^2)$ stochastic pseudo-regret.",
    "volume": "main",
    "checked": true,
    "id": "bf01539ff68735fc4449e6761684387f74137417",
    "citation_count": 88
  },
  "https://proceedings.mlr.press/v49/avilapires16.html": {
    "title": "Policy Error Bounds for Model-Based Reinforcement Learning with Factored Linear Models",
    "abstract": "In this paper we study a model-based approach to calculating approximately optimal policies in Markovian Decision Processes. In particular, we derive novel bounds on the loss of using a policy derived from a factored linear model, a class of models which generalize numerous previous models out of those that come with strong computational guarantees. For the first time in the literature, we derive performance bounds for model-based techniques where the model inaccuracy is measured in weighted norms. Moreover, our bounds show a decreased sensitivity to the discount factor and, unlike similar bounds derived for other approaches, they are insensitive to measure mismatch. Similarly to previous works, our proofs are also based on contraction arguments, but with the main differences that we use carefully constructed norms building on Banach lattices, and the contraction property is only assumed for operators acting on \"compressed\" spaces, thus weakening previous assumptions, while strengthening previous results.",
    "volume": "main",
    "checked": true,
    "id": "e8a9c12060a8f7d6c1f17948424b306ec9bd685c",
    "citation_count": 22
  },
  "https://proceedings.mlr.press/v49/awasthi16.html": {
    "title": "Learning and 1-bit Compressed Sensing under Asymmetric Noise",
    "abstract": "We study the approximate recovery problem: Given corrupted 1-bit measurements of the form sign(w^*⋅x_i), recover a vector w that is a good approximation to w^* ∈ R^d. This problem has been studied by both the learning theory and signal processing communities. In learning theory, this is known as the problem of learning halfspaces with noise, and in signal processing, as 1-bit compressed sensing, in which there is an additional assumption that w^* is t-sparse. The challenge in both cases is to design computationally efficient algorithms that are tolerant to large amounts of noise under realistic noise models. Furthermore, in the case of 1-bit compressed sensing, we require the number of measurements x_i to scale polynomially in t and only polylogarithmically in d, the ambient dimension. In this work, we introduce algorithms with nearly optimal guarantees for both problems under two realistic noise models, bounded (Massart) noise and adversarial (agnostic) noise, when the measurements x_i’s are drawn from any isotropic log-concave distribution. In bounded (Massart) noise, an adversary can flip the measurement of each point x with probability η(x)≤η",
    "volume": "main",
    "checked": true,
    "id": "27963f8721da6e1352f6e3896d0d7dde0379ec85",
    "citation_count": 75
  },
  "https://proceedings.mlr.press/v49/azizzadenesheli16a.html": {
    "title": "Reinforcement Learning of POMDPs using Spectral Methods",
    "abstract": "Author(s): Azizzadenesheli, Kamyar; Lazaric, Alessandro; Anandkumar, Animashree | Abstract: We propose a new reinforcement learning algorithm for partially observable Markov decision processes (POMDP) based on spectral decomposition methods. While spectral methods have been previously employed for consistent learning of (passive) latent variable models such as hidden Markov models, POMDPs are more challenging since the learner interacts with the environment and possibly changes the future observations in the process. We devise a learning algorithm running through episodes, in each episode we employ spectral techniques to learn the POMDP parameters from a trajectory generated by a fixed policy. At the end of the episode, an optimization oracle returns the optimal memoryless planning policy which maximizes the expected reward based on the estimated POMDP model. We prove an order-optimal regret bound with respect to the optimal memoryless policy and efficient scaling with respect to the dimensionality of observation and action spaces.",
    "volume": "main",
    "checked": true,
    "id": "35b05886694ffaa0d5431b0510d2daa4560f37af",
    "citation_count": 93
  },
  "https://proceedings.mlr.press/v49/bach16.html": {
    "title": "Highly-Smooth Zero-th Order Online Optimization",
    "abstract": "The minimization of convex functions which are only available through partial and noisy information is a key methodological problem in many disciplines. In this paper we consider convex optimization with noisy zero-th order information, that is noisy function evaluations at any desired point. We focus on problems with high degrees of smoothness, such as logistic regression. We show that as opposed to gradient-based algorithms, high-order smoothness may be used to improve estimation rates, with a precise dependence of our upper-bounds on the degree of smoothness. In particular, we show that for infinitely differentiable functions, we recover the same dependence on sample size as gradient-based algorithms, with an extra dimension-dependent factor. This is done for both convex and strongly-convex functions, with finite horizon and anytime algorithms. Finally, we also recover similar results in the online optimization setting.",
    "volume": "main",
    "checked": true,
    "id": "11f90fb6b7c2309df6254cc8cc78692016cbda1a",
    "citation_count": 49
  },
  "https://proceedings.mlr.press/v49/balcan16a.html": {
    "title": "An Improved Gap-Dependency Analysis of the Noisy Power Method",
    "abstract": "We consider the noisy power method algorithm, which has wide applications in machine learning and statistics, especially those related to principal component analysis (PCA) under resource (communication, memory or privacy) constraints. Existing analysis of the noisy power method shows an unsatisfactory dependency over the \"consecutive\" spectral gap $(\\sigma_k-\\sigma_{k+1})$ of an input data matrix, which could be very small and hence limits the algorithm's applicability. In this paper, we present a new analysis of the noisy power method that achieves improved gap dependency for both sample complexity and noise tolerance bounds. More specifically, we improve the dependency over $(\\sigma_k-\\sigma_{k+1})$ to dependency over $(\\sigma_k-\\sigma_{q+1})$, where $q$ is an intermediate algorithm parameter and could be much larger than the target rank $k$. Our proofs are built upon a novel characterization of proximity between two subspaces that differ from canonical angle characterizations analyzed in previous works. Finally, we apply our improved bounds to distributed private PCA and memory-efficient streaming PCA and obtain bounds that are superior to existing results in the literature.",
    "volume": "main",
    "checked": true,
    "id": "72f146ff7c8a1d6a95997634c3d49f084da08e46",
    "citation_count": 52
  },
  "https://proceedings.mlr.press/v49/balcan16b.html": {
    "title": "Learning Combinatorial Functions from Pairwise Comparisons",
    "abstract": "A large body of work in machine learning has focused on the problem of learning a close approximation to an underlying combinatorial function, given a small set of labeled examples. However, for real-valued functions, cardinal labels might not be accessible, or it may be difficult for an expert to consistently assign real-valued labels over the entire set of examples. For instance, it is notoriously hard for consumers to reliably assign values to bundles of merchandise. Instead, it might be much easier for a consumer to report which of two bundles she likes better. With this motivation in mind, we consider an alternative learning model, wherein the algorithm must learn the underlying function up to pairwise comparisons, from pairwise comparisons. In this model, we present a series of novel algorithms that learn over a wide variety of combinatorial function classes. These range from graph functions to broad classes of valuation functions that are fundamentally important in microeconomic theory, the analysis of social networks, and machine learning, such as coverage, submodular, XOS, and subadditive functions, as well as functions with sparse Fourier support.",
    "volume": "main",
    "checked": true,
    "id": "3573023d4cdaecfcf45aea26e941b36d1a012f5c",
    "citation_count": 22
  },
  "https://proceedings.mlr.press/v49/balsubramani16.html": {
    "title": "Instance-dependent Regret Bounds for Dueling Bandits",
    "abstract": "We study the multi-armed dueling bandit problem in which feedback is provided in the form of relative comparisons between pairs of actions, with the goal of eventually learning to select actions that are close to the best. Following Dud´ ik et al. (2015), we aim for algorithms whose performance approaches that of the optimal randomized choice of actions, the von Neumann winner, expressly avoiding more restrictive assumptions, for instance, regarding the existence of a single best action (a Condorcet winner). In this general setting, the best known algorithms achieve regret ~ O( p KT ) inT rounds withK actions. In this paper, we present the first instance-dependent regret bounds for the general problem, focusing particularly on when the von Neumann winner is sparse. Specifically, we propose a new algorithm whose regret, relative to a unique von Neumann winner with sparsitys, is at most ~ O( p sT ), plus an instance-dependent constant. Thus, when the sparsity is much smaller",
    "volume": "main",
    "checked": true,
    "id": "87444f6015c7cf4364a224faca5a8e7cadae8725",
    "citation_count": 10
  },
  "https://proceedings.mlr.press/v49/bandeira16.html": {
    "title": "On the low-rank approach for semidefinite programs arising in synchronization and community detection",
    "abstract": "To address difficult optimization problems, convex relaxations based on semidefinite programming are now common place in many fields. Although solvable in polynomial time, large semidefinite programs tend to be computationally challenging. Over a decade ago, exploiting the fact that in many applications of interest the desired solutions are low rank, Burer and Monteiro proposed a heuristic to solve such semidefinite programs by restricting the search space to low-rank matrices. The accompanying theory does not explain the extent of the empirical success. We focus on Synchronization and Community Detection problems and provide theoretical guarantees shedding light on the remarkable efficiency of this heuristic.",
    "volume": "main",
    "checked": true,
    "id": "6edc1c2292e037769f7d4836f83ff5789e7bb062",
    "citation_count": 128
  },
  "https://proceedings.mlr.press/v49/banks16.html": {
    "title": "Information-theoretic thresholds for community detection in sparse networks",
    "abstract": "We give upper and lower bounds on the information-theoretic threshold for community detection in the stochastic block model. Specifically, consider the symmetric stochastic block model with $q$ groups, average degree $d$, and connection probabilities $c_\\text{in}/n$ and $c_\\text{out}/n$ for within-group and between-group edges respectively; let $\\lambda = (c_\\text{in}-c_\\text{out})/(qd)$. We show that, when $q$ is large, and $\\lambda = O(1/q)$, the critical value of $d$ at which community detection becomes possible---in physical terms, the condensation threshold---is \\[ d_\\text{c} = \\Theta\\!\\left( \\frac{\\log q}{q \\lambda^2} \\right) \\, , \\] with tighter results in certain regimes. Above this threshold, we show that any partition of the nodes into $q$ groups which is as `good' as the planted one, in terms of the number of within- and between-group edges, is correlated with it. This gives an exponential-time algorithm that performs better than chance; specifically, community detection becomes possible below the Kesten-Stigum bound for $q \\ge 5$ in the disassortative case $\\lambda 0$ (similar upper bounds were obtained independently by Abbe and Sandon). Conversely, below this threshold, we show that no algorithm can label the vertices better than chance, or even distinguish the block model from an \\ER\\ random graph with high probability. \nOur lower bound on $d_\\text{c}$ uses Robinson and Wormald's small subgraph conditioning method, and we also give (less explicit) results for non-symmetric stochastic block models. In the symmetric case, we obtain explicit results by using bounds on certain functions of doubly stochastic matrices due to Achlioptas and Naor; indeed, our lower bound on $d_\\text{c}$ is their second moment lower bound on the $q$-colorability threshold for random graphs with a certain effective degree.",
    "volume": "main",
    "checked": true,
    "id": "465ab04e8b6f4b38d96cde962b38a3b021f32c38",
    "citation_count": 110
  },
  "https://proceedings.mlr.press/v49/barak16.html": {
    "title": "Noisy Tensor Completion via the Sum-of-Squares Hierarchy",
    "abstract": null,
    "volume": "main",
    "checked": true,
    "id": "c994494cdf2393b6e13b216dc1941e4e2897abe4",
    "citation_count": 130
  },
  "https://proceedings.mlr.press/v49/belkin16.html": {
    "title": "Basis Learning as an Algorithmic Primitive",
    "abstract": "A number of important problems in theoretical computer science and machine learning can be interpreted as recovering a certain basis. These include symmetric matrix eigendecomposition, certain tensor decompositions, Independent Component Analysis (ICA), spectral clustering and Gaussian mixture learning. Each of these problems reduces to an instance of our general model, which we call a \"Basis Encoding Function\" (BEF). We show that learning a basis within this model can then be provably and efficiently achieved using a first order iteration algorithm (gradient iteration). Our algorithm goes beyond tensor methods while generalizing a number of existing algorithms---e.g., the power method for symmetric matrices, the tensor power iteration for orthogonal decomposable tensors, and cumulant-based FastICA---all within a broader function-based dynamical systems framework. Our framework also unifies the unusual phenomenon observed in these domains that they can be solved using efficient non-convex optimization. Specifically, we describe a class of BEFs such that their local maxima on the unit sphere are in one-to-one correspondence with the basis elements. This description relies on a certain \"hidden convexity\" property of these functions. \nWe provide a complete theoretical analysis of the gradient iteration even when the BEF is perturbed. We show convergence and complexity bounds polynomial in dimension and other relevant parameters, such as perturbation size. Our perturbation results can be considered as a non-linear version of the classical Davis-Kahan theorem for perturbations of eigenvectors of symmetric matrices. In addition we show that our algorithm exhibits fast (superlinear) convergence and relate the speed of convergence to the properties of the BEF. Moreover, the gradient iteration algorithm can be easily and efficiently implemented in practice.",
    "volume": "main",
    "checked": true,
    "id": "0bb2ee2b21718ab3bea8c9630df39166574000af",
    "citation_count": 7
  },
  "https://proceedings.mlr.press/v49/bellec16.html": {
    "title": "Aggregation of supports along the Lasso path",
    "abstract": "In linear regression with fixed design, we propose two procedures that aggregate a data-driven collection of supports. The collection is a subset of the $2^p$ possible supports and both its cardinality and its elements can depend on the data. The procedures satisfy oracle inequalities with no assumption on the design matrix. Then we use these procedures to aggregate the supports that appear on the regularization path of the Lasso in order to construct an estimator that mimics the best Lasso estimator. If the restricted eigenvalue condition on the design matrix is satisfied, then this estimator achieves optimal prediction bounds. Finally, we discuss the computational cost of these procedures.",
    "volume": "main",
    "checked": true,
    "id": "7da94ca3d721e8686960924ae67ed72ffff95654",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v49/bhojanapalli16.html": {
    "title": "Dropping Convexity for Faster Semi-definite Optimization",
    "abstract": "We study the minimization of a convex function $f(X)$ over the set of $n\\times n$ positive semi-definite matrices, but when the problem is recast as $\\min_U g(U) := f(UU^\\top)$, with $U \\in \\mathbb{R}^{n \\times r}$ and $r \\leq n$. We study the performance of gradient descent on $g$---which we refer to as Factored Gradient Descent (FGD)---under standard assumptions on the original function $f$. \nWe provide a rule for selecting the step size and, with this choice, show that the local convergence rate of FGD mirrors that of standard gradient descent on the original $f$: i.e., after $k$ steps, the error is $O(1/k)$ for smooth $f$, and exponentially small in $k$ when $f$ is (restricted) strongly convex. In addition, we provide a procedure to initialize FGD for (restricted) strongly convex objectives and when one only has access to $f$ via a first-order oracle; for several problem instances, such proper initialization leads to global convergence guarantees. \nFGD and similar procedures are widely used in practice for problems that can be posed as matrix factorization. To the best of our knowledge, this is the first paper to provide precise convergence rate guarantees for general convex functions under standard convex assumptions.",
    "volume": "main",
    "checked": true,
    "id": "0f6876edded1131af861447406b77aa6e07e257b",
    "citation_count": 156
  },
  "https://proceedings.mlr.press/v49/bubeck16.html": {
    "title": "Multi-scale exploration of convex functions and bandit convex optimization",
    "abstract": "We construct a new map from a convex function to a distribution on its domain, with the property that this distribution is a multi-scale exploration of the function. We use this map to solve a decade-old open problem in adversarial bandit convex optimization by showing that the minimax regret for this problem is $\\tilde{O}(\\mathrm{poly}(n) \\sqrt{T})$, where $n$ is the dimension and $T$ the number of rounds. This bound is obtained by studying the dual Bayesian maximin regret via the information ratio analysis of Russo and Van Roy, and then using the multi-scale exploration to solve the Bayesian problem.",
    "volume": "main",
    "checked": true,
    "id": "e536ca04b972b22de5455b0d116e92fc940d48c3",
    "citation_count": 62
  },
  "https://proceedings.mlr.press/v49/carpentier16.html": {
    "title": "Tight (Lower) Bounds for the Fixed Budget Best Arm Identification Bandit Problem",
    "abstract": "We consider the problem of \\textit{best arm identification} with a \\textit{fixed budget $T$}, in the $K$-armed stochastic bandit setting, with arms distribution defined on $[0,1]$. We prove that any bandit strategy, for at least one bandit problem characterized by a complexity $H$, will misidentify the best arm with probability lower bounded by $$\\exp\\Big(-\\frac{T}{\\log(K)H}\\Big),$$ where $H$ is the sum for all sub-optimal arms of the inverse of the squared gaps. Our result disproves formally the general belief - coming from results in the fixed confidence setting - that there must exist an algorithm for this problem whose probability of error is upper bounded by $\\exp(-T/H)$. This also proves that some existing strategies based on the Successive Rejection of the arms are optimal - closing therefore the current gap between upper and lower bounds for the fixed budget best arm identification problem.",
    "volume": "main",
    "checked": true,
    "id": "d5dde3a401cc15defd867e2b00bb06339dfa9895",
    "citation_count": 93
  },
  "https://proceedings.mlr.press/v49/cesa-bianchi16.html": {
    "title": "Delay and Cooperation in Nonstochastic Bandits",
    "abstract": "We study networks of communicating learning agents that cooperate to solve a common nonstochastic bandit problem. Agents use an underlying communication network to get messages about actions selected by other agents, and drop messages that took more than d hops to arrive, whered is a delay parameter. We introduce EXP3-COOP, a cooperative version of the EXP3 algorithm and prove that with K actions and N agents the average per-agent regret after T rounds is at most of order q d + 1 + K d (T lnK), where d is the independence number of the d-th power of the communication graphG. We then show that for any connected graph, ford = p K the regret bound isK 1=4 p T , strictly better than the minimax regret p KT for noncooperating agents. More informed choices ofd lead to bounds which are arbitrarily close to the full information minimax regret p T lnK when G is dense. When G has sparse components, we show that a variant of EXP3-COOP, allowing agents to choose their parameters according to their centrality inG, strictly improves the regret. Finally, as a by-product of our analysis, we provide the first characterization of the minimax regret for bandit learning with delay.",
    "volume": "main",
    "checked": true,
    "id": "820f16297fbe8b73197eebc7e5bd4d00eeb8d093",
    "citation_count": 103
  },
  "https://proceedings.mlr.press/v49/chan16.html": {
    "title": "On the Approximability of Sparse PCA",
    "abstract": "It is well known that Sparse PCA (Sparse Principal Component Analysis) is NP-hard to solve exactly on worst-case instances. What is the complexity of solving Sparse PCA approximately? Our contributions include: 1. a simple and efficient algorithm that achieves ann 1=3 -approximation; 2. NP-hardness of approximation to within (1 \"), for some small constant\" > 0; 3. SSE-hardness of approximation to within any constant factor; and 4. an exp exp p log logn (“quasi-quasi-polynomial”) gap for the standard semidefinite program.",
    "volume": "main",
    "checked": true,
    "id": "47494cb62e98896ec1656ae47d69a0d4122690c9",
    "citation_count": 23
  },
  "https://proceedings.mlr.press/v49/chen16a.html": {
    "title": "Pure Exploration of Multi-armed Bandit Under Matroid Constraints",
    "abstract": "We study the pure exploration problem subject to a matroid constraint (Best-Basis) in a stochastic multi-armed bandit game. In a Best-Basis instance, we are given $n$ stochastic arms with unknown reward distributions, as well as a matroid $\\mathcal{M}$ over the arms. Let the weight of an arm be the mean of its reward distribution. Our goal is to identify a basis of $\\mathcal{M}$ with the maximum total weight, using as few samples as possible. \nThe problem is a significant generalization of the best arm identification problem and the top-$k$ arm identification problem, which have attracted significant attentions in recent years. We study both the exact and PAC versions of Best-Basis, and provide algorithms with nearly-optimal sample complexities for these versions. Our results generalize and/or improve on several previous results for the top-$k$ arm identification problem and the combinatorial pure exploration problem when the combinatorial constraint is a matroid.",
    "volume": "main",
    "checked": true,
    "id": "dd90ae674635e726a9e9ed044dd5e54b04eb205c",
    "citation_count": 40
  },
  "https://proceedings.mlr.press/v49/christiano16.html": {
    "title": "Provably manipulation-resistant reputation systems",
    "abstract": "We consider a community of users who must make periodic decisions about whether to interact with one another. We propose a protocol which allows honest users to reliably interact with each other, while limiting the damage done by each malicious or incompetent user. The worst-case cost per user is sublinear in the average number of interactions per user and is independent of the number of users. Our guarantee holds simultaneously for every group of honest users. For example, multiple groups of users with incompatible tastes or preferences can coexist. \nAs a motivating example, we consider a game where players have periodic opportunities to do one another favors but minimal ability to determine when a favor was done. In this setting, our protocol achieves nearly optimal collective welfare while remaining resistant to exploitation. \nOur results also apply to a collaborative filtering setting where users must make periodic decisions about whether to interact with resources such as movies or restaurants. In this setting, we guarantee that any set of honest users achieves a payoff nearly as good as if they had identified the optimal set of items in advance and then chosen to interact only with resources from that set.",
    "volume": "main",
    "checked": true,
    "id": "5aea24470796a9d9b5d43e50c92ba6f3ccc0c9ea",
    "citation_count": 4
  },
  "https://proceedings.mlr.press/v49/cohen16.html": {
    "title": "On the Expressive Power of Deep Learning: A Tensor Analysis",
    "abstract": "It has long been conjectured that hypotheses spaces suitable for data that is compositional in nature, such as text or images, may be more efficiently represented with deep hierarchical networks than with shallow ones. Despite the vast empirical evidence supporting this belief, theoretical justifications to date are limited. In particular, they do not account for the locality, sharing and pooling constructs of convolutional networks, the most successful deep learning architecture to date. In this work we derive a deep network architecture based on arithmetic circuits that inherently employs locality, sharing and pooling. An equivalence between the networks and hierarchical tensor factorizations is established. We show that a shallow network corresponds to CP (rank-1) decomposition, whereas a deep network corresponds to Hierarchical Tucker decomposition. Using tools from measure theory and matrix algebra, we prove that besides a negligible set, all functions that can be implemented by a deep network of polynomial size, require exponential size in order to be realized (or even approximated) by a shallow network. Since log-space computation transforms our networks into SimNets, the result applies directly to a deep learning architecture demonstrating promising empirical performance. The construction and theory developed in this paper shed new light on various practices and ideas employed by the deep learning community.",
    "volume": "main",
    "checked": true,
    "id": "2d9bc3e1b82e5deef9de69488f51005092d44822",
    "citation_count": 390
  },
  "https://proceedings.mlr.press/v49/cotter16.html": {
    "title": "A Light Touch for Heavily Constrained SGD",
    "abstract": "Minimizing empirical risk subject to a set of constraints can be a useful strategy for learning restricted classes of functions, such as monotonic functions, submodular functions, classifiers that guarantee a certain class label for some subset of examples, etc. However, these restrictions may result in a very large number of constraints. Projected stochastic gradient descent (SGD) is often the default choice for large-scale optimization in machine learning, but requires a projection after each update. For heavily-constrained objectives, we propose an efficient extension of SGD that stays close to the feasible region while only applying constraints probabilistically at each iteration. Theoretical analysis shows a compelling trade-off between per-iteration work and the number of iterations needed on problems with a large number of constraints.",
    "volume": "main",
    "checked": true,
    "id": "70115dd8641dc6e5a99cc8319a6dfe9c6ba96fb7",
    "citation_count": 25
  },
  "https://proceedings.mlr.press/v49/cummings16.html": {
    "title": "Adaptive Learning with Robust Generalization Guarantees",
    "abstract": "The traditional notion of generalization---i.e., learning a hypothesis whose empirical error is close to its true error---is surprisingly brittle. As has recently been noted in [DFH+15b], even if several algorithms have this guarantee in isolation, the guarantee need not hold if the algorithms are composed adaptively. In this paper, we study three notions of generalization---increasing in strength---that are robust to postprocessing and amenable to adaptive composition, and examine the relationships between them. We call the weakest such notion Robust Generalization. A second, intermediate, notion is the stability guarantee known as differential privacy. The strongest guarantee we consider we call Perfect Generalization. We prove that every hypothesis class that is PAC learnable is also PAC learnable in a robustly generalizing fashion, with almost the same sample complexity. It was previously known that differentially private algorithms satisfy robust generalization. In this paper, we show that robust generalization is a strictly weaker concept, and that there is a learning task that can be carried out subject to robust generalization guarantees, yet cannot be carried out subject to differential privacy. We also show that perfect generalization is a strictly stronger guarantee than differential privacy, but that, nevertheless, many learning tasks can be carried out subject to the guarantees of perfect generalization.",
    "volume": "main",
    "checked": true,
    "id": "2f1f0edcd5e8e409910bfb1644d7b42e1f8c33e4",
    "citation_count": 51
  },
  "https://proceedings.mlr.press/v49/daniely16.html": {
    "title": "Complexity Theoretic Limitations on Learning DNF’s",
    "abstract": "Using the recently developed framework of [Daniely et al, 2014], we show that under a natural assumption on the complexity of refuting random K-SAT formulas, learning DNF formulas is hard. Furthermore, the same assumption implies the hardness of learning intersections of $\\omega(\\log(n))$ halfspaces, agnostically learning conjunctions, as well as virtually all (distribution free) learning problems that were previously shown hard (under complexity assumptions).",
    "volume": "main",
    "checked": true,
    "id": "44e4a5cfac737066d445b8908eb9bee49d751dbf",
    "citation_count": 107
  },
  "https://proceedings.mlr.press/v49/diakonikolas16a.html": {
    "title": "Optimal Learning via the Fourier Transform for Sums of Independent Integer Random Variables",
    "abstract": "We study the structure and learnability of sums of independent integer random variables (SIIRVs). For $k \\in \\mathbb{Z}_{+}$, a $k$-SIIRV of order $n \\in \\mathbb{Z}_{+}$ is the probability distribution of the sum of $n$ independent random variables each supported on $\\{0, 1, \\dots, k-1\\}$. We denote by ${\\cal S}_{n,k}$ the set of all $k$-SIIRVs of order $n$. \nIn this paper, we tightly characterize the sample and computational complexity of learning $k$-SIIRVs. More precisely, we design a computationally efficient algorithm that uses $\\widetilde{O}(k/\\epsilon^2)$ samples, and learns an arbitrary $k$-SIIRV within error $\\epsilon,$ in total variation distance. Moreover, we show that the {\\em optimal} sample complexity of this learning problem is $\\Theta((k/\\epsilon^2)\\sqrt{\\log(1/\\epsilon)}).$ Our algorithm proceeds by learning the Fourier transform of the target $k$-SIIRV in its effective support. Its correctness relies on the {\\em approximate sparsity} of the Fourier transform of $k$-SIIRVs -- a structural property that we establish, roughly stating that the Fourier transform of $k$-SIIRVs has small magnitude outside a small set. \nAlong the way we prove several new structural results about $k$-SIIRVs. As one of our main structural contributions, we give an efficient algorithm to construct a sparse {\\em proper} $\\epsilon$-cover for ${\\cal S}_{n,k},$ in total variation distance. We also obtain a novel geometric characterization of the space of $k$-SIIRVs. Our characterization allows us to prove a tight lower bound on the size of $\\epsilon$-covers for ${\\cal S}_{n,k}$, and is the key ingredient in our tight sample complexity lower bound. \nOur approach of exploiting the sparsity of the Fourier transform in distribution learning is general, and has recently found additional applications.",
    "volume": "main",
    "checked": true,
    "id": "42ee1c35aef0904dd0dc8afe80dec1a88ceefe89",
    "citation_count": 33
  },
  "https://proceedings.mlr.press/v49/diakonikolas16b.html": {
    "title": "Properly Learning Poisson Binomial Distributions in Almost Polynomial Time",
    "abstract": "We give an algorithm for properly learning Poisson binomial distributions. A Poisson binomial distribution (PBD) of order $n$ is the discrete probability distribution of the sum of $n$ mutually independent Bernoulli random variables. Given $\\widetilde{O}(1/\\epsilon^2)$ samples from an unknown PBD $\\mathbf{p}$, our algorithm runs in time $(1/\\epsilon)^{O(\\log \\log (1/\\epsilon))}$, and outputs a hypothesis PBD that is $\\epsilon$-close to $\\mathbf{p}$ in total variation distance. The previously best known running time for properly learning PBDs was $(1/\\epsilon)^{O(\\log(1/\\epsilon))}$. \nAs one of our main contributions, we provide a novel structural characterization of PBDs. We prove that, for all $\\epsilon >0,$ there exists an explicit collection $\\cal{M}$ of $(1/\\epsilon)^{O(\\log \\log (1/\\epsilon))}$ vectors of multiplicities, such that for any PBD $\\mathbf{p}$ there exists a PBD $\\mathbf{q}$ with $O(\\log(1/\\epsilon))$ distinct parameters whose multiplicities are given by some element of ${\\cal M}$, such that $\\mathbf{q}$ is $\\epsilon$-close to $\\mathbf{p}$. Our proof combines tools from Fourier analysis and algebraic geometry. \nOur approach to the proper learning problem is as follows: Starting with an accurate non-proper hypothesis, we fit a PBD to this hypothesis. More specifically, we essentially start with the hypothesis computed by the computationally efficient non-proper learning algorithm in our recent work~\\cite{DKS15}. Our aforementioned structural characterization allows us to reduce the corresponding fitting problem to a collection of $(1/\\epsilon)^{O(\\log \\log(1/\\epsilon))}$ systems of low-degree polynomial inequalities. We show that each such system can be solved in time $(1/\\epsilon)^{O(\\log \\log(1/\\epsilon))}$, which yields the overall running time of our algorithm.",
    "volume": "main",
    "checked": true,
    "id": "f9ca7a9ab4fbfcc10876f2f74bd3204147496acb",
    "citation_count": 26
  },
  "https://proceedings.mlr.press/v49/elalaoui16.html": {
    "title": "Asymptotic behavior of \\ell_p-based Laplacian regularization in semi-supervised learning",
    "abstract": "Given a weighted graph with $N$ vertices, consider a real-valued regression problem in a semi-supervised setting, where one observes $n$ labeled vertices, and the task is to label the remaining ones. We present a theoretical study of $\\ell_p$-based Laplacian regularization under a $d$-dimensional geometric random graph model. We provide a variational characterization of the performance of this regularized learner as $N$ grows to infinity while $n$ stays constant, the associated optimality conditions lead to a partial differential equation that must be satisfied by the associated function estimate $\\hat{f}$. From this formulation we derive several predictions on the limiting behavior the $d$-dimensional function $\\hat{f}$, including (a) a phase transition in its smoothness at the threshold $p = d + 1$, and (b) a tradeoff between smoothness and sensitivity to the underlying unlabeled data distribution $P$. Thus, over the range $p \\leq d$, the function estimate $\\hat{f}$ is degenerate and \"spiky,\" whereas for $p\\geq d+1$, the function estimate $\\hat{f}$ is smooth. We show that the effect of the underlying density vanishes monotonically with $p$, such that in the limit $p = \\infty$, corresponding to the so-called Absolutely Minimal Lipschitz Extension, the estimate $\\hat{f}$ is independent of the distribution $P$. Under the assumption of semi-supervised smoothness, ignoring $P$ can lead to poor statistical performance, in particular, we construct a specific example for $d=1$ to demonstrate that $p=2$ has lower risk than $p=\\infty$ due to the former penalty adapting to $P$ and the latter ignoring it. We also provide simulations that verify the accuracy of our predictions for finite sample sizes. Together, these properties show that $p = d+1$ is an optimal choice, yielding a function estimate $\\hat{f}$ that is both smooth and non-degenerate, while remaining maximally sensitive to $P$.",
    "volume": "main",
    "checked": false,
    "id": "f21d5c4e037dec4119e646a56a969335dd152cee",
    "citation_count": 40
  },
  "https://proceedings.mlr.press/v49/eldan16.html": {
    "title": "The Power of Depth for Feedforward Neural Networks",
    "abstract": "We show that there is a simple (approximately radial) function on $\\reals^d$, expressible by a small 3-layer feedforward neural networks, which cannot be approximated by any 2-layer network, to more than a certain constant accuracy, unless its width is exponential in the dimension. The result holds for virtually all known activation functions, including rectified linear units, sigmoids and thresholds, and formally demonstrates that depth -- even if increased by 1 -- can be exponentially more valuable than width for standard feedforward neural networks. Moreover, compared to related results in the context of Boolean functions, our result requires fewer assumptions, and the proof techniques and construction are very different.",
    "volume": "main",
    "checked": true,
    "id": "a9da71715d54e33959751c88bb69a5875a23e324",
    "citation_count": 596
  },
  "https://proceedings.mlr.press/v49/flesch16.html": {
    "title": "Online Learning and Blackwell Approachability in Quitting Games",
    "abstract": "We consider the sequential decision problem known as regret minimization, or more precisely its generalization to the vectorial or multi-criteria setup called Blackwell approachability. We assume that Nature, the decision maker, or both, might have some quitting (or terminating) actions so that the stream of payoffs is constant whenever they are chosen. We call those environments “quitting games”. We characterize convex target sets C that are Blackwell approachable, in the sense that the decision maker has a policy ensuring that the expected average vector payoff converges to C at some given horizon known in advance. Moreover, we also compare these results to the cases where the horizon is not known and show that, unlike in standard online learning literature, the necessary or sufficient conditions for the anytime version of this problem are drastically different than those for the fixed horizon.",
    "volume": "main",
    "checked": true,
    "id": "bd784de4b2235b149782937df5c213b0e39df44b",
    "citation_count": 1
  },
  "https://proceedings.mlr.press/v49/florescu16.html": {
    "title": "Spectral thresholds in the bipartite stochastic block model",
    "abstract": "We consider a bipartite stochastic block model on vertex sets $V_1$ and $V_2$, with planted partitions in each, and ask at what densities efficient algorithms can recover the partition of the smaller vertex set. \nWhen $|V_2| \\gg |V_1|$, multiple thresholds emerge. We first locate a sharp threshold for detection of the partition, in the sense of the results of \\cite{mossel2012stochastic,mossel2013proof} and \\cite{massoulie2014community} for the stochastic block model. We then show that at a higher edge density, the singular vectors of the rectangular biadjacency matrix exhibit a localization / delocalization phase transition, giving recovery above the threshold and no recovery below. Nevertheless, we propose a simple spectral algorithm, Diagonal Deletion SVD, which recovers the partition at a nearly optimal edge density. \nThe bipartite stochastic block model studied here was used by \\cite{feldman2014algorithm} to give a unified algorithm for recovering planted partitions and assignments in random hypergraphs and random $k$-SAT formulae respectively. Our results give the best known bounds for the clause density at which solutions can be found efficiently in these models as well as showing a barrier to further improvement via this reduction to the bipartite block model.",
    "volume": "main",
    "checked": true,
    "id": "aaf5f5f1a790e4ae170faa54654634ca9a4e435a",
    "citation_count": 48
  },
  "https://proceedings.mlr.press/v49/foster16.html": {
    "title": "Online Sparse Linear Regression",
    "abstract": "Online sparse linear regression is an online problem where an algorithm repeatedly chooses a subset of coordinates to observe in an adversarially chosen feature vector, makes a real-valued prediction, receives the true label, and incurs the squared loss. The goal is to design an online learning algorithm with sublinear regret to the best sparse linear predictor in hindsight. Without any assumptions, this problem is known to be computationally intractable. In this paper, we make the assumption that data matrix satisfies restricted isometry property, and show that this assumption leads to computationally efficient algorithms with sublinear regret for two variants of the problem. In the first variant, the true label is generated according to a sparse linear model with additive Gaussian noise. In the second, the true label is chosen adversarially.",
    "volume": "main",
    "checked": false,
    "id": "0f8de305ad9ca2227774423cc464c14fb848105a",
    "citation_count": 16
  },
  "https://proceedings.mlr.press/v49/gao16.html": {
    "title": "Preference-based Teaching",
    "abstract": null,
    "volume": "main",
    "checked": false,
    "id": "7f2fe8f8ece1f248a25af994d0738808e1582637",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v49/garivier16a.html": {
    "title": "Optimal Best Arm Identification with Fixed Confidence",
    "abstract": "We give a complete characterization of the complexity of best-arm identification in one-parameter bandit problems. We prove a new, tight lower bound on the sample complexity. We propose the `Track-and-Stop' strategy, which we prove to be asymptotically optimal. It consists in a new sampling rule (which tracks the optimal proportions of arm draws highlighted by the lower bound) and in a stopping rule named after Chernoff, for which we give a new analysis.",
    "volume": "main",
    "checked": true,
    "id": "e89b2f97516b99debb293a2751af937da7e10f92",
    "citation_count": 205
  },
  "https://proceedings.mlr.press/v49/garivier16b.html": {
    "title": "Maximin Action Identification: A New Bandit Framework for Games",
    "abstract": "We study an original problem of pure exploration in a strategic bandit model motivated by Monte Carlo Tree Search. It consists in identifying the best action in a game, when the player may sample random outcomes of sequentially chosen pairs of actions. We propose two strategies for the fixed-confidence setting: Maximin-LUCB, based on lower-and upper-confidence bounds; and Maximin-Racing, which operates by successively eliminating the sub-optimal actions. We discuss the sample complexity of both methods and compare their performance empirically. We sketch a lower bound analysis, and possible connections to an optimal algorithm.",
    "volume": "main",
    "checked": true,
    "id": "e43ab9778cb218cbdc2b772280c9a5f951231fe2",
    "citation_count": 29
  },
  "https://proceedings.mlr.press/v49/hajek16.html": {
    "title": "Semidefinite Programs for Exact Recovery of a Hidden Community",
    "abstract": "We study a semidefinite programming (SDP) relaxation of the maximum likelihood estimation for exactly recovering a hidden community of cardinality $K$ from an $n \\times n$ symmetric data matrix $A$, where for distinct indices $i,j$, $A_{ij} \\sim P$ if $i, j$ are both in the community and $A_{ij} \\sim Q$ otherwise, for two known probability distributions $P$ and $Q$. We identify a sufficient condition and a necessary condition for the success of SDP for the general model. For both the Bernoulli case ($P={\\rm Bern}(p)$ and $Q={\\rm Bern}(q)$ with $p>q$) and the Gaussian case ($P=\\mathcal{N}(\\mu,1)$ and $Q=\\mathcal{N}(0,1)$ with $\\mu>0$), which correspond to the problem of planted dense subgraph recovery and submatrix localization respectively, the general results lead to the following findings: (1) If $K=\\omega( n /\\log n)$, SDP attains the information-theoretic recovery limits with sharp constants; (2) If $K=\\Theta(n/\\log n)$, SDP is order-wise optimal, but strictly suboptimal by a constant factor; (3) If $K=o(n/\\log n)$ and $K \\to \\infty$, SDP is order-wise suboptimal. The same critical scaling for $K$ is found to hold, up to constant factors, for the performance of SDP on the stochastic block model of $n$ vertices partitioned into multiple communities of equal size $K$. A key ingredient in the proof of the necessary condition is a construction of a primal feasible solution based on random perturbation of the true cluster matrix.",
    "volume": "main",
    "checked": true,
    "id": "a26f61a5dd0e126f25b0552533e83138da1e2a3e",
    "citation_count": 28
  },
  "https://proceedings.mlr.press/v49/hazan16.html": {
    "title": "Online Learning with Low Rank Experts",
    "abstract": "We consider the problem of prediction with expert advice when the losses of the experts have low-dimensional structure: they are restricted to an unknown $d$-dimensional subspace. We devise algorithms with regret bounds that are independent of the number of experts and depend only on the rank $d$. For the stochastic model we show a tight bound of $\\Theta(\\sqrt{dT})$, and extend it to a setting of an approximate $d$ subspace. For the adversarial model we show an upper bound of $O(d\\sqrt{T})$ and a lower bound of $\\Omega(\\sqrt{dT})$.",
    "volume": "main",
    "checked": true,
    "id": "622a417c8c1206281932c64a2e7b1e0982cfc227",
    "citation_count": 12
  },
  "https://proceedings.mlr.press/v49/huetter16.html": {
    "title": "Optimal rates for total variation denoising",
    "abstract": "Motivated by its practical success, we show that the 2D total variation denoiser satisfies a sharp oracle inequality that leads to near optimal rates of estimation for a large class of image models such as bi-isotonic, Hölder smooth and cartoons. Our analysis hinges on properties of the unnormalized Laplacian of the two-dimensional grid such as eigenvector delocalization and spectral decay. We also present extensions to more than two dimensions as well as several other graphs.",
    "volume": "main",
    "checked": true,
    "id": "0ed09173c260102d4539b5767867f83f4d854a8e",
    "citation_count": 64
  },
  "https://proceedings.mlr.press/v49/jain16.html": {
    "title": "Streaming PCA: Matching Matrix Bernstein and Near-Optimal Finite Sample Guarantees for Oja’s Algorithm",
    "abstract": "This work provides improved guarantees for streaming principle component analysis (PCA). Given $A_1, \\ldots, A_n\\in \\mathbb{R}^{d\\times d}$ sampled independently from distributions satisfying $\\mathbb{E}[A_i] = \\Sigma$ for $\\Sigma \\succeq \\mathbf{0}$, this work provides an $O(d)$-space linear-time single-pass streaming algorithm for estimating the top eigenvector of $\\Sigma$. The algorithm nearly matches (and in certain cases improves upon) the accuracy obtained by the standard batch method that computes top eigenvector of the empirical covariance $\\frac{1}{n} \\sum_{i \\in [n]} A_i$ as analyzed by the matrix Bernstein inequality. Moreover, to achieve constant accuracy, our algorithm improves upon the best previous known sample complexities of streaming algorithms by either a multiplicative factor of $O(d)$ or $1/\\mathrm{gap}$ where $\\mathrm{gap}$ is the relative distance between the top two eigenvalues of $\\Sigma$. \nThese results are achieved through a novel analysis of the classic Oja's algorithm, one of the oldest and most popular algorithms for streaming PCA. In particular, this work shows that simply picking a random initial point $w_0$ and applying the update rule $w_{i + 1} = w_i + \\eta_i A_i w_i$ suffices to accurately estimate the top eigenvector, with a suitable choice of $\\eta_i$. We believe our result sheds light on how to efficiently perform streaming PCA both in theory and in practice and we hope that our analysis may serve as the basis for analyzing many variants and extensions of streaming PCA.",
    "volume": "main",
    "checked": true,
    "id": "458ac5ba63da2efb42058e2d057d712f64b71729",
    "citation_count": 107
  },
  "https://proceedings.mlr.press/v49/kotlowski16.html": {
    "title": "Online Isotonic Regression",
    "abstract": null,
    "volume": "main",
    "checked": false,
    "id": "d9ca33ebac66ef91b26585f8dbb359923db7c78c",
    "citation_count": 0
  },
  "https://proceedings.mlr.press/v49/kuznetsov16.html": {
    "title": "Time series prediction and online learning",
    "abstract": "We present a series of theoretical and algorithmic results for time series prediction leveraging recent advances in the statistical learning analysis of this problem and on-line learning. We prove the first generalization bounds for a hypothesis derived by online-to-batch conversion of the sequence of hypotheses output by an online algorithm, in the general setting of a non-stationary non-mixing stochastic process. Our learning guarantees hold for adapted sequences of hypotheses both for convex and non-convex losses. We further give generalization bounds for sequences of hypotheses that may not be adapted but that admit a stability property. Our learning bounds are given in terms of a discrepancy measure, which we show can be accurately estimated from data under a mild assumption. Our theory enables us to devise a principled solution for the notoriously difficult problem of model section in the time series scenario. It also helps us devise new ensemble methods with favorable theoretical guarantees for forecasting non-stationary time series.",
    "volume": "main",
    "checked": true,
    "id": "fd8cc20ff13a819b48097146425eb7ab0279e2a5",
    "citation_count": 30
  },
  "https://proceedings.mlr.press/v49/lattimore16.html": {
    "title": "Regret Analysis of the Finite-Horizon Gittins Index Strategy for Multi-Armed Bandits",
    "abstract": "I analyse the frequentist regret of the famous Gittins index strategy for multi-armed bandits with Gaussian noise and a finite horizon. Remarkably it turns out that this approach leads to finite-time regret guarantees comparable to those available for the popular UCB algorithm. Along the way I derive finite-time bounds on the Gittins index that are asymptotically exact and may be of independent interest. I also discuss some computational issues and present experimental results suggesting that a particular version of the Gittins index strategy is a modest improvement on existing algorithms with finite-time regret guarantees such as UCB and Thompson sampling.",
    "volume": "main",
    "checked": true,
    "id": "b0a169e861dc50a0e02a21bcaa1377fdf53ca095",
    "citation_count": 40
  },
  "https://proceedings.mlr.press/v49/lee16.html": {
    "title": "Gradient Descent Only Converges to Minimizers",
    "abstract": "We show that gradient descent converges to a local minimizer, almost surely with random initialization. This is proved by applying the Stable Manifold Theorem from dynamical systems theory.",
    "volume": "main",
    "checked": true,
    "id": "9dd705a9974c6ac7bb8a32d89ce2841bb1ac66af",
    "citation_count": 483
  },
  "https://proceedings.mlr.press/v49/makarychev16.html": {
    "title": "Learning Communities in the Presence of Errors",
    "abstract": "We study the problem of learning communities in the presence of modeling errors and give robust recovery algorithms for the Stochastic Block Model (SBM). This model, which is also known as the Planted Partition Model, is widely used for community detection and graph partitioning in various fields, including machine learning, statistics, and social sciences. Many algorithms exist for learning communities in the Stochastic Block Model, but they do not work well in the presence of errors. \nIn this paper, we initiate the study of robust algorithms for partial recovery in SBM with modeling errors or noise. We consider graphs generated according to the Stochastic Block Model and then modified by an adversary. We allow two types of adversarial errors, Feige---Kilian or monotone errors, and edge outlier errors. Mossel, Neeman and Sly (STOC 2015) posed an open question about whether an almost exact recovery is possible when the adversary is allowed to add $o(n)$ edges. Our work answers this question affirmatively even in the case of $k>2$ communities. \nWe then show that our algorithms work not only when the instances come from SBM, but also work when the instances come from any distribution of graphs that is $\\epsilon m$ close to SBM in the Kullback---Leibler divergence. This result also works in the presence of adversarial errors. Finally, we present almost tight lower bounds for two communities.",
    "volume": "main",
    "checked": true,
    "id": "f923f4dd2094cddde6d20571dcd448b7db58e5b9",
    "citation_count": 30
  },
  "https://proceedings.mlr.press/v49/massoulie16.html": {
    "title": "On the capacity of information processing systems",
    "abstract": "We propose and analyze a family of information processing systems, where a finite set of experts or servers are employed to extract information about a stream of incoming jobs. Each job is associated with a hidden label drawn from some prior distribution. An inspection by an expert produces a noisy outcome that depends both on the job’s hidden label and the type of the expert, and occupies the expert for a finite time duration. A decision maker’s task is to dynamically assign inspections so that the resulting outcomes can be used to accurately recover the labels of all jobs, while keeping the system stable. Among our chief motivations are applications in crowd-sourcing, diagnostics, and experiment designs, where one wishes to efficiently discover the nature of a large number of items, using a finite pool of computational resources or human agents. \n \nWe focus on the capacity of such an information processing system. Given a level of accuracy guarantee, we ask how many experts are needed in order to stabilize the system, and through what inspection architecture. Our main result provides an adaptive inspection policy that is asymptotically optimal in the following sense: the ratio between the required number of experts under our policy and the theoretical optimal converges to one, as the probability of error in label recovery tends to zero.",
    "volume": "main",
    "checked": true,
    "id": "c3c9132931d7257a2dec3effc51e7f16b4b922a5",
    "citation_count": 43
  },
  "https://proceedings.mlr.press/v49/morgenstern16.html": {
    "title": "Learning Simple Auctions",
    "abstract": "We present a general framework for proving polynomial sample complexity bounds for the problem of learning from samples the best auction in a class of \"simple\" auctions. Our framework captures all of the most prominent examples of \"simple\" auctions, including anonymous and non-anonymous item and bundle pricings, with either a single or multiple buyers. The technique we propose is to break the analysis of auctions into two natural pieces. First, one shows that the set of allocation rules have large amounts of structure; second, fixing an allocation on a sample, one shows that the set of auctions agreeing with this allocation on that sample have revenue functions with low dimensionality. Our results effectively imply that whenever it's possible to compute a near-optimal simple auction with a known prior, it is also possible to compute such an auction with an unknown prior (given a polynomial number of samples).",
    "volume": "main",
    "checked": true,
    "id": "41368adaecd216cabf2391dfd26a88bf02efbcb2",
    "citation_count": 100
  },
  "https://proceedings.mlr.press/v49/mossel16.html": {
    "title": "Density Evolution in the Degree-correlated Stochastic Block Model",
    "abstract": "There is a recent surge of interest in identifying the sharp recovery thresholds for cluster recovery under the stochastic block model. In this paper, we address the more refined question of how many vertices that will be misclassified on average. We consider the binary form of the stochastic block model, where $n$ vertices are partitioned into two clusters with edge probability $a/n$ within the first cluster, $c/n$ within the second cluster, and $b/n$ across clusters. Suppose that as $n \\to \\infty$, $a= b+ \\mu \\sqrt{ b} $, $c=b+ \\nu \\sqrt{ b} $ for two fixed constants $\\mu, \\nu$, and $b \\to \\infty$ with $b=n^{o(1)}$. When the cluster sizes are balanced and $\\mu \\neq \\nu$, we show that the minimum fraction of misclassified vertices on average is given by $Q(\\sqrt{v^*})$, where $Q(x)$ is the Q-function for standard normal, $v^*$ is the unique fixed point of $v= \\frac{(\\mu-\\nu)^2}{16} + \\frac{ (\\mu+\\nu)^2 }{16} \\mathbb{E}[ \\tanh(v+ \\sqrt{v} Z)],$ and $Z$ is standard normal. Moreover, the minimum misclassified fraction on average is attained by a local algorithm, namely belief propagation, in time linear in the number of edges. Our proof techniques are based on connecting the cluster recovery problem to tree reconstruction problems, and analyzing the density evolution of belief propagation on trees with Gaussian approximations.",
    "volume": "main",
    "checked": true,
    "id": "b8277c02343e3911942315b3727cf83753748748",
    "citation_count": 35
  },
  "https://proceedings.mlr.press/v49/papadimitriou16.html": {
    "title": "Cortical Computation via Iterative Constructions",
    "abstract": "We study Boolean functions of an arbitrary number of input variables that can be realized by simple iterative constructions based on constant-size primitives. This restricted type of construction needs little global coordination or control and thus is a candidate for neurally feasible computation. Valiant's construction of a majority function can be realized in this manner and, as we show, can be generalized to any uniform threshold function. We study the rate of convergence, finding that while linear convergence to the correct function can be achieved for any threshold using a fixed set of primitives, for quadratic convergence, the size of the primitives must grow as the threshold approaches 0 or 1. We also study finite realizations of this process and the learnability of the functions realized. We show that the constructions realized are accurate outside a small interval near the target threshold, where the size of the construction grows as the inverse square of the interval width. This phenomenon, that errors are higher closer to thresholds (and thresholds closer to the boundary are harder to represent), is a well-known cognitive finding.",
    "volume": "main",
    "checked": true,
    "id": "87c6bc4a1c2be24f89b6a2d542bbe7866644c563",
    "citation_count": 3
  },
  "https://proceedings.mlr.press/v49/rajkumar16.html": {
    "title": "When can we rank well from comparisons of O(n\\log(n)) non-actively chosen pairs?",
    "abstract": "Ranking from pairwise comparisons is a ubiquitous problem and has been studied in disciplines ranging from statistics to operations research and from theoretical computer science to machine learning. Here we consider a general setting where outcomes of pairwise comparisons between items i and j are drawn probabilistically by flipping a coin with unknown bias Pij , and ask under what conditions on these unknown probabilities one can learn a good ranking from comparisons of only O(n log n) non-actively chosen pairs. Recent work has established this is possible under the Bradley-Terry-Luce (BTL) and noisy permutation (NP) models. Here we introduce a broad family of ‘low-rank’ conditions on the probabilities Pij under which the resulting preference matrix P has low rank under some link function, and show these conditions encompass the BTL and Thurstone classes as special cases, but are considerably more general. We then give a new algorithm called low-rank pairwise ranking (LRPR) which provably learns a good ranking from comparisons of only O(n log n) randomly chosen comparisons under such low-rank models. Our algorithm and analysis make use of tools from the theory of low-rank matrix completion, and provide a new perspective on the problem of ranking from pairwise comparisons in non-active settings.",
    "volume": "main",
    "checked": false,
    "id": "7b249f09a46776410f3c6de5a67f57459a45ad6a",
    "citation_count": 25
  },
  "https://proceedings.mlr.press/v49/risteski16.html": {
    "title": "How to calculate partition functions using convex programming hierarchies: provable bounds for variational methods",
    "abstract": "We consider the problem of approximating partition functions for Ising models. We make use of recent tools in combinatorial optimization: the Sherali-Adams and Lasserre convex programming hierarchies, in combination with variational methods to get algorithms for calculating partition functions in these families. These techniques give new, non-trivial approximation guarantees for the partition function beyond the regime of correlation decay. They also generalize some classical results from statistical physics about the Curie-Weiss ferromagnetic Ising model, as well as provide a partition function counterpart of classical results about max-cut on dense graphs (Arora et al., 1995). With this, we connect techniques from two apparently disparate research areas – optimization and counting/partition function approximations. (i.e. #-P type of problems). Furthermore, we design to the best of our knowledge the first provable, convex variational methods. Though in the literature there are a host of convex versions of variational methods (Wainwright et al.; 2005; Heskes, 2006; Meshi et al., 2009), they come with no guarantees (apart from some extremely special cases, like e.g. the graph has a single cycle (Weiss, 2000)). We consider dense and low threshold rank graphs, and interestingly, the reason our approach works on these types of graphs is because local correlations propagate to global correlations – completely the opposite of algorithms based on correlation decay. In the process we design novel entropy approximations based on the low-order moments of a distribution. Our proof techniques are very simple and generic, and likely to be applicable to many other settings other than Ising models.",
    "volume": "main",
    "checked": true,
    "id": "071424732071350ed0bdec33521af903a2eeb9dc",
    "citation_count": 16
  },
  "https://proceedings.mlr.press/v49/russo16.html": {
    "title": "Simple Bayesian Algorithms for Best Arm Identification",
    "abstract": "This paper considers the optimal adaptive allocation of measurement effort for identifying the best among a finite set of options or designs. An experimenter sequentially chooses designs to measure and observes noisy signals of their quality with the goal of confidently identifying the best design after a small number of measurements. Just as the multiarmed bandit problem crystallizes the tradeoff between exploration and exploitation, this “pure exploration” variant crystallizes the challenge of rapidly gathering information before committing to a final decision. The paper proposes several simple Bayesian algorithms for allocating measurement effort and, by characterizing fundamental asymptotic limits on the performance of any algorithm, formalizes a sense in which these seemingly naive algorithms are the best possible.",
    "volume": "main",
    "checked": true,
    "id": "a4668ef49df712cf0d66351885c38e9d2ce2a6a2",
    "citation_count": 166
  },
  "https://proceedings.mlr.press/v49/sabato16.html": {
    "title": "Interactive Algorithms: from Pool to Stream",
    "abstract": "We consider interactive algorithms in the pool-based setting, and in the stream-based setting. Interactive algorithms observe suggested elements (representing actions or queries), and interactively select some of them and receive responses. Pool-based algorithms can select elements at any order, while stream-based algorithms observe elements in sequence, and can only select elements immediately after observing them. We assume that the suggested elements are generated independently from some source distribution, and ask what is the stream size required for emulating a pool algorithm with a given pool size. We provide algorithms and matching lower bounds for general pool algorithms, and for utility-based pool algorithms. We further show that a maximal gap between the two settings exists also in the special case of active learning for binary classification.",
    "volume": "main",
    "checked": true,
    "id": "0c96e1c0e6aee5099b1ba7783985bc5b85ca7165",
    "citation_count": 13
  },
  "https://proceedings.mlr.press/v49/simchowitz16.html": {
    "title": "Best-of-K-bandits",
    "abstract": "This paper studies the Best-of-K Bandit game: At each time the player chooses a subset S among all N-choose-K possible options and observes reward max(X(i) : i in S) where X is a random vector drawn from a joint distribution. The objective is to identify the subset that achieves the highest expected reward with high probability using as few queries as possible. We present distribution-dependent lower bounds based on a particular construction which force a learner to consider all N-choose-K subsets, and match naive extensions of known upper bounds in the bandit setting obtained by treating each subset as a separate arm. Nevertheless, we present evidence that exhaustive search may be avoided for certain, favorable distributions because the influence of high-order order correlations may be dominated by lower order statistics. Finally, we present an algorithm and analysis for independent arms, which mitigates the surprising non-trivial information occlusion that occurs due to only observing the max in the subset. This may inform strategies for more general dependent measures, and we complement these result with independent-arm lower bounds.",
    "volume": "main",
    "checked": true,
    "id": "6d5a527be074a7090289fd1307dd7dcbdba22d67",
    "citation_count": 10
  },
  "https://proceedings.mlr.press/v49/steinhardt16.html": {
    "title": "Memory, Communication, and Statistical Queries",
    "abstract": "If a concept class can be represented with a certain amount of memory, can it be efficiently learned with the same amount of memory? What concepts can be efficiently learned by algorithms that extract only a few bits of information from each example? We introduce a formal framework for studying these questions, and investigate the relationship between the fundamental resources of memory or communication and the sample complexity of the learning task. We relate our memory-bounded and communication-bounded learning models to the well-studied statistical query model. This connection can be leveraged to obtain both upper and lower bounds: we show strong lower bounds on learning parity functions with bounded communication, as well as the first upper bounds on solving generic sparse linear regression problems with limited memory.",
    "volume": "main",
    "checked": true,
    "id": "4de44bbbddb6c654301f54390712574e108a2983",
    "citation_count": 67
  },
  "https://proceedings.mlr.press/v49/telgarsky16.html": {
    "title": "benefits of depth in neural networks",
    "abstract": "For any positive integer $k$, there exist neural networks with $\\Theta(k^3)$ layers, $\\Theta(1)$ nodes per layer, and $\\Theta(1)$ distinct parameters which can not be approximated by networks with $\\mathcal{O}(k)$ layers unless they are exponentially large --- they must possess $\\Omega(2^k)$ nodes. This result is proved here for a class of nodes termed \"semi-algebraic gates\" which includes the common choices of ReLU, maximum, indicator, and piecewise polynomial functions, therefore establishing benefits of depth against not just standard networks with ReLU gates, but also convolutional networks with ReLU and maximization gates, sum-product networks, and boosted decision trees (in this last case with a stronger separation: $\\Omega(2^{k^3})$ total tree nodes are required).",
    "volume": "main",
    "checked": true,
    "id": "4206c84525a7904df3613b843491c0ae6a5507eb",
    "citation_count": 479
  },
  "https://proceedings.mlr.press/v49/volkovich16.html": {
    "title": "A Guide to Learning Arithmetic Circuits",
    "abstract": "An arithmetic circuit is a directed acyclic graph in which the operations aref+;g . In this paper, we exhibit several connections between learning algorithms for arithmetic circuits and other problems. In particular, we show that: Ecient learning algorithms for arithmetic circuit classes imply explicit exponential lower bounds. General circuits and formulas can be learned eciently with membership and equivalence queries i they can be learned eciently with membership queries only. Low-query learning algorithms for certain classes of circuits imply explicit rigid matrices. Learning algorithms for multilinear depth-3 and depth-4 circuits must compute square roots.",
    "volume": "main",
    "checked": true,
    "id": "01d435a85c8d3268b1c6faed4dc1c74139c88b7f",
    "citation_count": 13
  },
  "https://proceedings.mlr.press/v49/weed16.html": {
    "title": "Online learning in repeated auctions",
    "abstract": "Motivated by online advertising auctions, we consider repeated Vickrey auctions where goods of unknown value are sold sequentially and bidders only learn (potentially noisy) information about a good's value once it is purchased. We adopt an online learning approach with bandit feedback to model this problem and derive bidding strategies for two models: stochastic and adversarial. In the stochastic model, the observed values of the goods are random variables centered around the true value of the good. In this case, logarithmic regret is achievable when competing against well behaved adversaries. In the adversarial model, the goods need not be identical and we simply compare our performance against that of the best fixed bid in hindsight. We show that sublinear regret is also achievable in this case and prove matching minimax lower bounds. To our knowledge, this is the first complete set of strategies for bidders participating in auctions of this type.",
    "volume": "main",
    "checked": true,
    "id": "4636c0426ba9373086dab07a76a72c5f4fe79746",
    "citation_count": 60
  },
  "https://proceedings.mlr.press/v49/zhang16a.html": {
    "title": "The Extended Littlestone’s Dimension for Learning with Mistakes and Abstentions",
    "abstract": "This paper studies classification with an abstention option in the online setting. In this setting, examples arrive sequentially, the learner is given a hypothesis class $\\mathcal H$, and the goal of the learner is to either predict a label on each example or abstain, while ensuring that it does not make more than a pre-specified number of mistakes when it does predict a label. \nPrevious work on this problem has left open two main challenges. First, not much is known about the optimality of algorithms, and in particular, about what an optimal algorithmic strategy is for any individual hypothesis class. Second, while the realizable case has been studied, the more realistic non-realizable scenario is not well-understood. In this paper, we address both challenges. First, we provide a novel measure, called the Extended Littlestone's Dimension, which captures the number of abstentions needed to ensure a certain number of mistakes. Second, we explore the non-realizable case, and provide upper and lower bounds on the number of abstentions required by an algorithm to guarantee a specified number of mistakes.",
    "volume": "main",
    "checked": true,
    "id": "321331b997b6cd718552b0df919aeae2afcf3a7f",
    "citation_count": 14
  },
  "https://proceedings.mlr.press/v49/zhang16b.html": {
    "title": "First-order Methods for Geodesically Convex Optimization",
    "abstract": "Geodesic convexity generalizes the notion of (vector space) convexity to nonlinear metric spaces. But unlike convex optimization, geodesically convex (g-convex) optimization is much less developed. In this paper we contribute to the understanding of g-convex optimization by developing iteration complexity analysis for several first-order algorithms on Hadamard manifolds. Specifically, we prove upper bounds for the global complexity of deterministic and stochastic (sub)gradient methods for optimizing smooth and nonsmooth g-convex functions, both with and without strong g-convexity. Our analysis also reveals how the manifold geometry, especially \\emph{sectional curvature}, impacts convergence rates. To the best of our knowledge, our work is the first to provide global complexity analysis for first-order algorithms for general g-convex optimization.",
    "volume": "main",
    "checked": true,
    "id": "a0a2ad6d3225329f55766f0bf332c86a63f6e14e",
    "citation_count": 192
  }
}