{
  "https://www.isca-speech.org/archive/interspeech_2021/pucher21_interspeech.html": {
    "title": "Conversion of Airborne to Bone-Conducted Speech with Deep Neural Networks",
    "volume": "main",
    "abstract": "It is a common experience of most speakers that the playback of one's own voice sounds strange. This can be mainly attributed to the missing bone-conducted speech signal that is not present in the playback signal. It was also shown that some phonemes have a high bone-conducted relative to air-conducted sound transmission, which means that the bone-conduction filter is phone-dependent. To achieve such a phone-dependent modeling we train different speaker dependent and speaker adaptive speech conversion systems using airborne and bone-conducted speech data from 8 speakers (5 male, 3 female), which allow for the conversion of airborne speech to bone-conducted speech. The systems are based on Long Short-Term Memory (LSTM) deep neural networks, where the speaker adaptive versions with speaker embedding can be used without bone-conduction signals from the target speaker. Additionally we also used models that apply a global filtering. The different models are then evaluated by an objective error metric and a subjective listening experiment, which show that the LSTM based models outperform the global filters",
    "checked": true,
    "id": "fa04146b59a5a17c00b28c223b415b4df45f0991",
    "semantic_title": "conversion of airborne to bone-conducted speech with deep neural networks",
    "citation_count": 1
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rezackova21_interspeech.html": {
    "title": "T5G2P: Using Text-to-Text Transfer Transformer for Grapheme-to-Phoneme Conversion",
    "volume": "main",
    "abstract": "Despite the increasing popularity of end-to-end text-to-speech (TTS) systems, the correct grapheme-to-phoneme (G2P) module is still a crucial part of those relying on a phonetic input. In this paper, we, therefore, introduce a T5G2P model, a Text-to-Text Transfer Transformer (T5) neural network model which is able to convert an input text sentence into a phoneme sequence with a high accuracy. The evaluation of our trained T5 model is carried out on English and Czech, since there are different specific properties of G2P, including homograph disambiguation, cross-word assimilation and irregular pronunciation of loanwords. The paper also contains an analysis of a homographs issue in English and offers another approach to Czech phonetic transcription using the detection of pronunciation exceptions",
    "checked": true,
    "id": "8ca9702be6bb1a9af323b778ad96894db284313e",
    "semantic_title": "t5g2p: using text-to-text transfer transformer for grapheme-to-phoneme conversion",
    "citation_count": 7
  },
  "https://www.isca-speech.org/archive/interspeech_2021/perrotin21_interspeech.html": {
    "title": "Evaluating the Extrapolation Capabilities of Neural Vocoders to Extreme Pitch Values",
    "volume": "main",
    "abstract": "Neural vocoders are systematically evaluated on homogeneous train and test databases. This kind of evaluation is efficient to compare neural vocoders in their \"comfort zone\", yet it hardly reveals their limits towards unseen data during training. To compare their extrapolation capabilities, we introduce a methodology that aims at quantifying the robustness of neural vocoders in synthesising unseen data, by precisely controlling the ranges of seen/unseen data in the training database. By focusing in this study on the pitch (F ) parameter, our methodology involves a careful splitting of a dataset to control which F values are seen/unseen during training, followed by both global (utterance) and local (frame) evaluation of vocoders. Comparison of four types of vocoders (autoregressive, sourcefilter, flows, GAN) displays a wide range of behaviour towards unseen input pitch values, including excellent extrapolation (WaveGlow); widely-spread F errors (WaveRNN); and systematic generation of the training set median F (LPCNet, Parallel WaveGAN). In contrast, fewer differences between vocoders were observed when using homogeneous train and test sets, thus demonstrating the potential and need for such evaluation to better discriminate the neural vocoders abilities to generate out-of-training-range data",
    "checked": true,
    "id": "2a1d555165bbde06837b0b8eca013f59f54c7ed7",
    "semantic_title": "evaluating the extrapolation capabilities of neural vocoders to extreme pitch values",
    "citation_count": 2
  },
  "https://www.isca-speech.org/archive/interspeech_2021/do21_interspeech.html": {
    "title": "A Systematic Review and Analysis of Multilingual Data Strategies in Text-to-Speech for Low-Resource Languages",
    "volume": "main",
    "abstract": "We provide a systematic review of past studies that use multilingual data for text-to-speech (TTS) of low-resource languages (LRLs). We focus on the strategies used by these studies for incorporating multilingual data and how they affect output speech quality. To investigate the difference in output quality between corresponding monolingual and multilingual models, we propose a novel measure to compare this difference across the included studies and their various evaluation metrics. This measure, called the Multilingual Model Effect (MLME), is found to be affected by: acoustic model architecture, the difference ratio of target language data between corresponding multilingual and monolingual experiments, the balance ratio of target language data to total data, and the amount of target language data used. These findings can act as reference for data strategies in future experiments with multilingual TTS models for LRLs. Language family classification, despite being widely used, is not found to be an effective criterion for selecting source languages",
    "checked": true,
    "id": "016064c068dfe3dd3ae8b2a8c8940c2a4e2db866",
    "semantic_title": "a systematic review and analysis of multilingual data strategies in text-to-speech for low-resource languages",
    "citation_count": 7
  },
  "https://www.isca-speech.org/archive/interspeech_2021/talkar21_interspeech.html": {
    "title": "Acoustic Indicators of Speech Motor Coordination in Adults With and Without Traumatic Brain Injury",
    "volume": "main",
    "abstract": "A traumatic brain injury (TBI) can lead to various long-term effects on memory, attention, and mood, as well as the occurrence of headaches, speech, and hearing problems. There is a need to better understand the long-term effects of a TBI for objective tracking of an individual's recovery, which could be used to determine intervention trajectories. This study utilizes acoustic features derived from recordings of speech tasks completed by active-duty service members and veterans (SMVs) enrolled in the Defense and Veterans Brain Injury (DVBIC)/Traumatic Brain Injury Center of Excellence (TBICoE) 15-Year Longitudinal TBI Study. We hypothesize that the individuals diagnosed with moderate to severe TBI would demonstrate motor speech impairments through decreased coordination of the speech production subsystems as compared to individuals with no history of TBI. Speech motor coordination is measured through correlations of acoustic feature time series representing speech subsystems. Eigenspectra derived from these correlations are utilized in machine learning models to discriminate between the two groups. The fusion of correlation features derived from the recordings achieves an AUC of 0.78. This suggests that residual motor impairments from moderate to severe TBI could be detectable through objective measures of speech motor coordination",
    "checked": true,
    "id": "29a7bc914934229c5c190d4e7e5cb2b17aa9cbc8",
    "semantic_title": "acoustic indicators of speech motor coordination in adults with and without traumatic brain injury",
    "citation_count": 1
  },
  "https://www.isca-speech.org/archive/interspeech_2021/vasquezcorrea21_interspeech.html": {
    "title": "On Modeling Glottal Source Information for Phonation Assessment in Parkinson's Disease",
    "volume": "main",
    "abstract": "Parkinson's disease produces several motor symptoms, including different speech impairments that are known as hypokinetic dysarthria. Symptoms associated to dysarthria affect different dimensions of speech such as phonation, articulation, prosody, and intelligibility. Studies in the literature have mainly focused on the analysis of articulation and prosody because they seem to be the most prominent symptoms associated to dysarthria severity. However, phonation impairments also play a significant role to evaluate the global speech severity of Parkinson's patients. This paper proposes an extensive comparison of different methods to automatically evaluate the severity of specific phonation impairments in Parkinson's patients. The considered models include the computation of perturbation and glottal-based features, in addition to features extracted from a zero frequency filtered signals. We consider as well end-to-end models based on 1D CNNs, which are trained to learn features from the raw speech waveform, reconstructed glottal signals, and zero-frequency filtered signals. The results indicate that it is possible to automatically classify between speakers with low versus high phonation severity due to the presence of dysarthria and at the same time to evaluate the severity of the phonation impairments on a continuous scale, posed as a regression problem",
    "checked": true,
    "id": "7dfa3283092c0c780cff9228153196b2cb84d7d6",
    "semantic_title": "on modeling glottal source information for phonation assessment in parkinson's disease",
    "citation_count": 5
  },
  "https://www.isca-speech.org/archive/interspeech_2021/daoudi21_interspeech.html": {
    "title": "Distortion of Voiced Obstruents for Differential Diagnosis Between Parkinson's Disease and Multiple System Atrophy",
    "volume": "main",
    "abstract": "Parkinson's disease (PD) and the parkinsonian variant of Multiple System Atrophy (MSA-P) are two neurodegenerative diseases which share similar clinical features, particularly in early disease stages. The differential diagnosis can be thus very challenging. Dysarthria is known to be a frequent and early clinical feature of PD and MSA. It can be thus used as a vehicle to provide a vocal biomarker which could help in the differential diagnosis. In particular, distortion of consonants is known to be a frequent impairment in these diseases. The aim of this study is to investigate distinctive patterns in the distortion of voiced obstruents (plosives and fricatives). It is the first study which attempts to examine such distortions in the French language for the purpose of the differential diagnosis between PD and MSA-P (and among the very few studies if we consider all languages). We carry out a perceptual and objective analysis of voiced obstruents extracted from isolated pseudo-words initials. We first show that devoicing is a significant impairment which predominates in MSA-P. We then show that voice onset time (VOT) of voiced plosives (prevoicing duration) can be a complementary feature to improve the accuracy in discrimination between PD and MSA-P",
    "checked": true,
    "id": "07b9da3899e66c7dbd79de23a294811f8b1c34dc",
    "semantic_title": "distortion of voiced obstruents for differential diagnosis between parkinson's disease and multiple system atrophy",
    "citation_count": 3
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21_interspeech.html": {
    "title": "A Study into Pre-Training Strategies for Spoken Language Understanding on Dysarthric Speech",
    "volume": "main",
    "abstract": "End-to-end (E2E) spoken language understanding (SLU) systems avoid an intermediate textual representation by mapping speech directly into intents with slot values. This approach requires considerable domain-specific training data. In low-resource scenarios this is a major concern, e.g., in the present study dealing with SLU for dysarthric speech. Pretraining part of the SLU model for automatic speech recognition targets helps but no research has shown to which extent SLU on dysarthric speech benefits from knowledge transferred from other dysarthric speech tasks. This paper investigates the efficiency of pre-training strategies for SLU tasks on dysarthric speech. The designed SLU system consists of a TDNN acoustic model for feature encoding and a capsule network for intent and slot decoding. The acoustic model is pre-trained in two stages: initialization with a corpus of normal speech and finetuning on a mixture of dysarthric and normal speech. By introducing the intelligibility score as a metric of the impairment severity, this paper quantitatively analyzes the relation between generalization and pathology severity for dysarthric speech",
    "checked": true,
    "id": "c19084b61d05c32320a6caaa739eb68c4eb9d07a",
    "semantic_title": "a study into pre-training strategies for spoken language understanding on dysarthric speech",
    "citation_count": 7
  },
  "https://www.isca-speech.org/archive/interspeech_2021/turrisi21_interspeech.html": {
    "title": "EasyCall Corpus: A Dysarthric Speech Dataset",
    "volume": "main",
    "abstract": "This paper introduces a new dysarthric speech command dataset in Italian, called EasyCall corpus. The dataset consists of 21386 audio recordings from 24 healthy and 31 dysarthric speakers, whose individual degree of speech impairment was assessed by neurologists through the Therapy Outcome Measure. The corpus aims at providing a resource for the development of ASR-based assistive technologies for patients with dysarthria. In particular, it may be exploited to develop a voice-controlled contact application for commercial smartphones, aiming at improving dysarthric patients' ability to communicate with their family and caregivers. Before recording the dataset, participants were administered a survey to evaluate which commands are more likely to be employed by dysarthric individuals in a voice-controlled contact application. In addition, the dataset includes a list of non-commands (i.e., words near/inside commands or phonetically close to commands) that can be leveraged to build a more robust command recognition system. At present commercial ASR systems perform poorly on the EasyCall Corpus as we report in this paper. This result corroborates the need for dysarthric speech corpora for developing effective assistive technologies. To the best of our knowledge, this database represents the richest corpus of dysarthric speech to date",
    "checked": true,
    "id": "6524f8f7692c43e000bea2f68677a0b3dae69015",
    "semantic_title": "easycall corpus: a dysarthric speech dataset",
    "citation_count": 11
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bie21_interspeech.html": {
    "title": "A Benchmark of Dynamical Variational Autoencoders Applied to Speech Spectrogram Modeling",
    "volume": "main",
    "abstract": "The Variational Autoencoder (VAE) is a powerful deep generative model that is now extensively used to represent high-dimensional complex data via a low-dimensional latent space learned in an unsupervised manner. In the original VAE model, input data vectors are processed independently. In recent years, a series of papers have presented different extensions of the VAE to process sequential data, that not only model the latent space, but also model the temporal dependencies within a sequence of data vectors and corresponding latent vectors, relying on recurrent neural networks. We recently performed a comprehensive review of those models and unified them into a general class called Dynamical Variational Autoencoders (DVAEs). In the present paper, we present the results of an experimental benchmark comparing six of those DVAE models on the speech analysis-resynthesis task, as an illustration of the high potential of DVAEs for speech modeling",
    "checked": true,
    "id": "5ace2ad34b19f668232a45806429ab0bfbd2c387",
    "semantic_title": "a benchmark of dynamical variational autoencoders applied to speech spectrogram modeling",
    "citation_count": 9
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yurt21_interspeech.html": {
    "title": "Fricative Phoneme Detection Using Deep Neural Networks and its Comparison to Traditional Methods",
    "volume": "main",
    "abstract": "Accurate phoneme detection and processing can enhance speech intelligibility in hearing aids and audio & speech codecs. As fricative phonemes have an important part of their energy concentrated in high frequency bands, frequency lowering algorithms are used in hearing aids to improve fricative intelligibility for people with high-frequency hearing loss. In traditional audio codecs, while processing speech in blocks, spectral smearing around fricative phoneme borders results in pre and post echo artifacts. Hence, detecting the fricative borders and adapting the processing accordingly could enhance the quality of speech. Until recently, phoneme detection and analysis were mostly done by extracting features specific to the class of phonemes. In this paper, we present a deep learning based fricative phoneme detection algorithm that exceeds the state-of-the-art fricative phoneme detection accuracy on the TIMIT speech corpus. Moreover, we compare our method to other approaches that employ classical signal processing for fricative detection and also evaluate it on the TIMIT files coded with AAC codec followed by bandwidth limitation. Reported results of our deep learning approach on original TIMIT files are reproducible and come with an easy to use code that could serve as a baseline for any future research on this topic",
    "checked": true,
    "id": "e8bd30368ce8d8103b4404bbc5bb1f619743c541",
    "semantic_title": "fricative phoneme detection using deep neural networks and its comparison to traditional methods",
    "citation_count": 2
  },
  "https://www.isca-speech.org/archive/interspeech_2021/prasad21_interspeech.html": {
    "title": "Identification of F1 and F2 in Speech Using Modified Zero Frequency Filtering",
    "volume": "main",
    "abstract": "Formants are major resonances in the vocal tract system. Identification of formants is important for study of speech. In the literature, formants are typically identified by first deriving formant frequency candidates (e.g., using linear prediction) and then applying a tracking mechanism. In this paper, we propose a simple tracking-free formant identification approach based on zero frequency filtering. More precisely, formants F1-F2 are identified by modifying the trend removal operation in zero frequency filtering and picking simply the dominant peak in the short-term discrete Fourier transform spectra. We demonstrate the potential of the approach by comparing it against state-of-the-art formant identification approaches on a typical speech data set (TIMIT-VTR) and an atypical speech data set (PC-GITA)",
    "checked": true,
    "id": "418936459718355b4c59a3b0c7698882428639c3",
    "semantic_title": "identification of f1 and f2 in speech using modified zero frequency filtering",
    "citation_count": 2
  },
  "https://www.isca-speech.org/archive/interspeech_2021/teytaut21_interspeech.html": {
    "title": "Phoneme-to-Audio Alignment with Recurrent Neural Networks for Speaking and Singing Voice",
    "volume": "main",
    "abstract": "Phoneme-to-audio alignment is the task of synchronizing voice recordings and their related phonetic transcripts. In this work, we introduce a new system to forced phonetic alignment with Recurrent Neural Networks (RNN). With the Connectionist Temporal Classification (CTC) loss as training objective, and an additional reconstruction cost, we learn to infer relevant per-frame phoneme probabilities from which alignment is derived. The core of the neural architecture is a context-aware attention mechanism between mel-spectrograms and side information. We investigate two contexts given by either phoneme sequences (model PhAtt) or spectrograms themselves (model SpAtt). Evaluations show that these models produce precise alignments for both speaking and singing voice. Best results are obtained with the model PhAtt, which outperforms baseline reference with an average imprecision of 16.3ms and 29.8ms on speech and singing, respectively. The model SpAtt also appears as an interesting alternative, capable of aligning longer audio files without requiring phoneme sequences on small audio segments",
    "checked": true,
    "id": "bfba22e6b5774780e18fb348db365df211280f2a",
    "semantic_title": "phoneme-to-audio alignment with recurrent neural networks for speaking and singing voice",
    "citation_count": 7
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21_interspeech.html": {
    "title": "Adaptive Convolutional Neural Network for Text-Independent Speaker Recognition",
    "volume": "main",
    "abstract": "In text-independent speaker recognition, each speech is composed of different phonemes depending on spoken text. The conventional neural networks for speaker recognition are static models, so they do not reflect this phoneme-varying characteristic well. To tackle this limitation, we propose an adaptive convolutional neural network (ACNN) for text-independent speaker recognition. The utterance is divided along the time axis into short segments with small fluctuating phonemes. Frame-level features are extracted by applying input-dependent kernels adaptive to each segment. By applying time average pooling and linear layers, utterance-level embeddings extraction and speaker recognition are performed. Adaptive VGG-M using 0.356 seconds segmentation shows better speaker recognition performance than baseline models, with a Top-1 of 86.51% and an EER of 5.68%. It extracts more accurate frame-level embeddings for vowel and nasal phonemes compared to the conventional method without overfitting and large parameters. This framework for text-independent speaker recognition effectively utilizes phonemes and text-varying characteristic of speech",
    "checked": true,
    "id": "4c653bd510d5c1bbf2e5690e7075c1b5b6ce104f",
    "semantic_title": "adaptive convolutional neural network for text-independent speaker recognition",
    "citation_count": 15
  },
  "https://www.isca-speech.org/archive/interspeech_2021/qi21_interspeech.html": {
    "title": "Bidirectional Multiscale Feature Aggregation for Speaker Verification",
    "volume": "main",
    "abstract": "In this paper, we propose a novel bidirectional multiscale feature aggregation (BMFA) network with attentional fusion modules for text-independent speaker verification. The feature maps from different stages of the backbone network are iteratively combined and refined in both a bottom-up and top-down manner. Furthermore, instead of simple concatenation or elementwise addition of feature maps from different stages, an attentional fusion module is designed to compute the fusion weights. Experiments are conducted on the NIST SRE16 and VoxCeleb1 datasets. The experimental results demonstrate the effectiveness of the bidirectional aggregation strategy and show that the proposed attentional fusion module can further improve the performance",
    "checked": true,
    "id": "588856b77b4e8709746dda0db3ed5e626bf87aba",
    "semantic_title": "bidirectional multiscale feature aggregation for speaker verification",
    "citation_count": 6
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21_interspeech.html": {
    "title": "Improving Time Delay Neural Network Based Speaker Recognition with Convolutional Block and Feature Aggregation Methods",
    "volume": "main",
    "abstract": "In this paper, we develop a system that integrates multiple ideas and techniques inspired by the convolutional block and feature aggregation methods. We begin with the state-of-the-art speaker-embedding model for speaker recognition, namely the model of Emphasized Channel Attention, Propagation, and Aggregation in Time Delay Neural Network, and then gradually experiment with the proposed network modules, including bottleneck residual blocks, attention mechanisms, and feature aggregation methods. In our final model, we replace the Res2Block with SC-Block and we use a hierarchical architecture for feature aggregation. We evaluate the performance of our model on the VoxCeleb1 test set and the 2020 VoxCeleb Speaker Recognition Challenge (VoxSRC20) validation set. The relative improvement of the proposed models over ECAPA-TDNN is 22.8% on VoxCeleb1 and 18.2% on VoxSRC20",
    "checked": true,
    "id": "1b4de223d5393bb2abac0ecb6e46de0a020ad18e",
    "semantic_title": "improving time delay neural network based speaker recognition with convolutional block and feature aggregation methods",
    "citation_count": 5
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wu21_interspeech.html": {
    "title": "Improving Deep CNN Architectures with Variable-Length Training Samples for Text-Independent Speaker Verification",
    "volume": "main",
    "abstract": "Deep Convolutional Neural Network (CNN) based speaker embeddings, such as r-vectors, have shown great success in text-independent speaker verification (TI-SV) task. However, previous deep CNN models usually use fixed-length samples for training and employ variable-length utterances for speaker embeddings, which generates a mismatch between training and embedding. To address this issue, we investigate the effect of employing variable-length training samples on CNN-based TI-SV systems and explore two approaches to improve the performance of deep CNN architectures on TI-SV through capturing variable-term contexts. Firstly, we present an improved selective kernel convolution which allows the networks to adaptively switch between short-term and long-term contexts based on variable-length utterances. Secondly, we propose a multi-scale statistics pooling method to aggregate multiple time-scale features from different layers of the networks. We build a novel ResNet34 based architecture with two proposed approaches. Experiments are conducted on the VoxCeleb datasets. The results demonstrate that the effect of using variable-length samples is diverse in different networks and the architecture with two proposed approaches achieves significant improvement over r-vectors baseline system",
    "checked": true,
    "id": "899172bf6b54aeb4359fcf6c18d50b63358f34b6",
    "semantic_title": "improving deep cnn architectures with variable-length training samples for text-independent speaker verification",
    "citation_count": 6
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhu21_interspeech.html": {
    "title": "Binary Neural Network for Speaker Verification",
    "volume": "main",
    "abstract": "Although deep neural networks are successful for many tasks in the speech domain, the high computational and memory costs of deep neural networks make it difficult to directly deploy high-performance Neural Network systems on low-resource embedded devices. There are several mechanisms to reduce the size of the neural networks i.e. parameter pruning, parameter quantization, etc. This paper focuses on how to apply binary neural networks to the task of speaker verification. The proposed binarization of training parameters can largely maintain the performance while significantly reducing storage space requirements and computational costs. Experiment results show that, after binarizing the Convolutional Neural Network, the ResNet34-based network achieves an EER of around 5% on the Voxceleb1 testing dataset and even outperforms the traditional real number network on the text-dependent dataset: Xiaole while having a 32× memory saving",
    "checked": true,
    "id": "08b1a85ca48ca7f723b0b5e331c89561158d7b2e",
    "semantic_title": "binary neural network for speaker verification",
    "citation_count": 7
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tu21_interspeech.html": {
    "title": "Mutual Information Enhanced Training for Speaker Embedding",
    "volume": "main",
    "abstract": "Mutual information (MI) is useful in unsupervised and self-supervised learning. Maximizing the MI between the low-level features and the learned embeddings can preserve meaningful information in the embeddings, which can contribute to performance gains. This strategy is called deep InfoMax (DIM) in representation learning. In this paper, we follow the DIM framework so that the speaker embeddings can capture more information from the frame-level features. However, a straightforward implementation of DIM may pose a dimensionality imbalance problem because the dimensionality of the frame-level features is much larger than that of the speaker embeddings. This problem can lead to unreliable MI estimation and can even cause detrimental effects on speaker verification. To overcome this problem, we propose to squeeze the frame-level features before MI estimation through some global pooling methods. We call the proposed method squeeze-DIM. Although the squeeze operation inevitably introduces some information loss, we empirically show that the squeeze-DIM can achieve performance gains on both Voxceleb1 and VOiCES-19 tasks. This suggests that the squeeze operation facilitates the MI estimation and maximization in a balanced dimensional space, which helps learn more informative speaker embeddings",
    "checked": true,
    "id": "289c4486a6f54644b2c6285d6640bb30ba71fbbe",
    "semantic_title": "mutual information enhanced training for speaker embedding",
    "citation_count": 4
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhu21b_interspeech.html": {
    "title": "Y-Vector: Multiscale Waveform Encoder for Speaker Embedding",
    "volume": "main",
    "abstract": "State-of-the-art text-independent speaker verification systems typically use cepstral features or filter bank energies as speech features. Recent studies attempted to extract speaker embeddings directly from raw waveforms and have shown competitive results. In this paper, we propose a novel multi-scale waveform encoder that uses three convolution branches with different time scales to compute speech features from the waveform. These features are then processed by squeeze-and-excitation blocks, a multi-level feature aggregator, and a time delayed neural network (TDNN) to compute speaker embedding. We show that the proposed embeddings outperform existing raw-waveform-based speaker embeddings on speaker verification by a large margin. A further analysis of the learned filters shows that the multi-scale encoder attends to different frequency bands at its different scales while resulting in a more flat overall frequency response than any of the single-scale counterparts",
    "checked": true,
    "id": "165c4715fdf6a7a0229f2810f2d32a526444b216",
    "semantic_title": "y-vector: multiscale waveform encoder for speaker embedding",
    "citation_count": 16
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21_interspeech.html": {
    "title": "Phoneme-Aware and Channel-Wise Attentive Learning for Text Dependent Speaker Verification",
    "volume": "main",
    "abstract": "This paper proposes a multi-task learning network with phoneme-aware and channel-wise attentive learning strategies for text-dependent Speaker Verification (SV). In the proposed structure, the frame-level multi-task learning along with the segment-level adversarial learning is adopted for speaker embedding extraction. The phoneme-aware attentive pooling is exploited on frame-level features in the main network for speaker classifier, with the corresponding posterior probability for the phoneme distribution in the auxiliary subnet. Further, the introduction of Squeeze and Excitation (SE-block) performs dynamic channel-wise feature recalibration, which improves the representational ability. The proposed method exploits speaker idiosyncrasies associated with pass-phrases, and is further improved by the phoneme-aware attentive pooling and SE-block from temporal and channel-wise aspects, respectively. The experiments conducted on RSR2015 Part 1 database confirm that the proposed system achieves outstanding results for text-dependent SV",
    "checked": false,
    "id": "923a03112032a81c77ed3e8f4498e60225263442",
    "semantic_title": "phoneme-aware and channel-wise attentive learning for text dependentspeaker verification",
    "citation_count": 8
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhu21c_interspeech.html": {
    "title": "Serialized Multi-Layer Multi-Head Attention for Neural Speaker Embedding",
    "volume": "main",
    "abstract": "This paper proposes a serialized multi-layer multi-head attention for neural speaker embedding in text-independent speaker verification. In prior works, frame-level features from one layer are aggregated to form an utterance-level representation. Inspired by the Transformer network, our proposed method utilizes the hierarchical architecture of stacked self-attention mechanisms to derive refined features that are more correlated with speakers. Serialized attention mechanism contains a stack of self-attention modules to create fixed-dimensional representations of speakers. Instead of utilizing multi-head attention in parallel, the proposed serialized multi-layer multi-head attention is designed to aggregate and propagate attentive statistics from one layer to the next in a serialized manner. In addition, we employ an input-aware query for each utterance with the statistics pooling. With more layers stacked, the neural network can learn more discriminative speaker embeddings. Experiment results on VoxCeleb1 dataset and SITW dataset show that our proposed method outperforms other baseline methods, including x-vectors and other x-vectors + conventional attentive pooling approaches by 9.7% in EER and 8.1% in DCF10 ",
    "checked": true,
    "id": "c3241cacfbb0ef38b87444634652a9202ac3da4e",
    "semantic_title": "serialized multi-layer multi-head attention for neural speaker embedding",
    "citation_count": 14
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gong21_interspeech.html": {
    "title": "TacoLPCNet: Fast and Stable TTS by Conditioning LPCNet on Mel Spectrogram Predictions",
    "volume": "main",
    "abstract": "The combination of the recently proposed LPCNet vocoder and a seq-to-seq acoustic model, i.e., Tacotron, has successfully achieved lightweight speech synthesis systems. However, the quality of synthesized speech is often unstable because the precision of the pitch parameters predicted by acoustic models is insufficient, especially for some tonal languages like Chinese and Japanese. In this paper, we propose an end-to-end speech synthesis system, TacoLPCNet, by conditioning LPCNet on Mel spectrogram predictions. First, we extend LPCNet for the Mel spectrogram instead of using explicit pitch information and pitch-related network. Furthermore, we optimize the system by model pruning, multi-frame inference, and increasing frame length, to enable it to meet the conditions required for real-time applications. The objective and subjective evaluation results for various languages show that the proposed system is more stable for tonal languages within the proposed optimization strategies. The experimental results also verify that our model improves synthesis runtime by 3.12 times than that of the baseline on a standard CPU while maintaining naturalness",
    "checked": true,
    "id": "c84bec97770c7851af0516f18bf1121d780897d1",
    "semantic_title": "tacolpcnet: fast and stable tts by conditioning lpcnet on mel spectrogram predictions",
    "citation_count": 1
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bak21_interspeech.html": {
    "title": "FastPitchFormant: Source-Filter Based Decomposed Modeling for Speech Synthesis",
    "volume": "main",
    "abstract": "Methods for modeling and controlling prosody with acoustic features have been proposed for neural text-to-speech (TTS) models. Prosodic speech can be generated by conditioning acoustic features. However, synthesized speech with a large pitch-shift scale suffers from audio quality degradation, and speaker characteristics deformation. To address this problem, we propose a feed-forward Transformer based TTS model that is designed based on the source-filter theory. This model, called , has a unique structure that handles text and acoustic features in parallel. With modeling each feature separately, the tendency that the model learns the relationship between two features can be mitigated. Owing to its structural characteristics, FastPitchFormant is robust and accurate for pitch control and generates prosodic speech preserving speaker characteristics. The experimental results show that proposed model outperforms the baseline FastPitch",
    "checked": true,
    "id": "034869f2f55b01f240b30923983ea197ff9fc32c",
    "semantic_title": "fastpitchformant: source-filter based decomposed modeling for speech synthesis",
    "citation_count": 12
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nakamura21_interspeech.html": {
    "title": "Sequence-to-Sequence Learning for Deep Gaussian Process Based Speech Synthesis Using Self-Attention GP Layer",
    "volume": "main",
    "abstract": "This paper presents a speech synthesis method based on deep Gaussian process (DGP) and sequence-to-sequence (Seq2Seq) learning toward high-quality end-to-end speech synthesis. Feed-forward and recurrent models using DGP are known to produce more natural synthetic speech than deep neural networks (DNNs) because of Bayesian learning and kernel regression. However, such DGP models consist of a pipeline architecture of independent models, acoustic and duration models, and require a high level of expertise in text processing. The proposed model is based on Seq2Seq learning, which enables a unified training of acoustic and duration models. The encoder and decoder layers are represented by Gaussian process regressions (GPRs) and the parameters are trained as a Bayesian model. We also propose a self-attention mechanism with Gaussian processes to effectively model character-level input in the encoder. The subjective evaluation results show that the proposed Seq2Seq-SA-DGP can synthesize more natural speech than DNNs with self-attention and recurrent structures. Besides, Seq2Seq-SA-DGP reduces the smoothing problems of recurrent structures and is effective when a simple input for an end-to-end system is given",
    "checked": true,
    "id": "9758aae98703469691e454ee622e5201ebfc7ae3",
    "semantic_title": "sequence-to-sequence learning for deep gaussian process based speech synthesis using self-attention gp layer",
    "citation_count": 1
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kakegawa21_interspeech.html": {
    "title": "Phonetic and Prosodic Information Estimation from Texts for Genuine Japanese End-to-End Text-to-Speech",
    "volume": "main",
    "abstract": "The biggest obstacle to develop end-to-end Japanese text-to-speech (TTS) systems is to estimate phonetic and prosodic information (PPI) from Japanese texts. The following are the reasons: (1) the Kanji characters of the Japanese writing system have multiple corresponding pronunciations, (2) there is no separation mark between words, and (3) an accent nucleus must be assigned at appropriate positions. In this paper, we propose to solve the problems by neural machine translation (NMT) on the basis of encoder-decoder models, and compare NMT models of recurrent neural networks and the Transformer architecture. The proposed model handles texts on token (character) basis, although conventional systems handle them on word basis. To ensure the potential of the proposed approach, NMT models are trained using pairs of sentences and their PPIs that are generated by a conventional Japanese TTS system from 5 million sentences. Evaluation experiments were performed using PPIs that are manually annotated for 5,142 sentences. The experimental results showed that the Transformer architecture has the best performance, with 98.0% accuracy for phonetic information estimation and 95.0% accuracy for PPI estimation. Judging from the results, NMT models are promising toward end-to-end Japanese TTS",
    "checked": true,
    "id": "8fb7bf026379d6e2a51ee95b6dc3aa09ca53b4bc",
    "semantic_title": "phonetic and prosodic information estimation from texts for genuine japanese end-to-end text-to-speech",
    "citation_count": 3
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dai21_interspeech.html": {
    "title": "Information Sieve: Content Leakage Reduction in End-to-End Prosody Transfer for Expressive Speech Synthesis",
    "volume": "main",
    "abstract": "Expressive neural text-to-speech (TTS) systems incorporate a style encoder to learn a latent embedding as the style information. However, this embedding process may encode redundant textual information. This phenomenon is called content leakage. Researchers have attempted to resolve this problem by adding an ASR or other auxiliary supervision loss functions. In this study, we propose an unsupervised method called the \"information sieve\" to reduce the effect of content leakage in prosody transfer. The rationale of this approach is that the style encoder can be forced to focus on style information rather than on textual information contained in the reference speech by a well-designed downsample-upsample filter, i.e., the extracted style embeddings can be downsampled at a certain interval and then upsampled by duplication. Furthermore, we used instance normalization in convolution layers to help the system learn a better latent style space. Objective metrics such as the significantly lower word error rate (WER) demonstrate the effectiveness of this model in mitigating content leakage. Listening tests indicate that the model retains its prosody transferability compared with the baseline models such as the original GST-Tacotron and ASR-guided Tacotron",
    "checked": false,
    "id": "155e69f30da7726a584bb293c1b8c9ff227d11fe",
    "semantic_title": "information sieve: content leakage reduction in end-to-end prosody for expressive speech synthesis",
    "citation_count": 2
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dou21_interspeech.html": {
    "title": "Deliberation-Based Multi-Pass Speech Synthesis",
    "volume": "main",
    "abstract": "Sequence-to-sequence (seq2seq) models have achieved state-of-the-art performance in a wide range of tasks including Neural Machine Translation (NMT) and Text-To-Speech (TTS). These models are usually trained with teacher forcing, where the reference back-history is used to predict the next token. This makes training efficient, but limits performance, because during inference the free-running back-history must be used. To address this problem, deliberation-based multi-pass seq2seq has been used in NMT. Here the output sequence is generated in multiple passes, each one conditioned on the initial input and the free-running output of the previous pass. This paper investigates, and compares, deliberation-based multi-pass seq2seq for TTS and NMT. For NMT the simplest form of multi-pass approaches, where the free-running first-pass output is combined with the initial input, improves performance. However, applying this scheme to TTS is challenging: the multi-pass model tends to converge to the standard single-pass model, ignoring the previous output. To tackle this issue, a guided attention loss is added, enabling the system to make more extensive use of the free-running output. Experimental results confirm the above analysis and demonstrate that the proposed TTS model outperforms a strong baseline",
    "checked": true,
    "id": "b8233798ff4bd3b98c884a61b84e1fa02fd1aefa",
    "semantic_title": "deliberation-based multi-pass speech synthesis",
    "citation_count": 2
  },
  "https://www.isca-speech.org/archive/interspeech_2021/elias21_interspeech.html": {
    "title": "Parallel Tacotron 2: A Non-Autoregressive Neural TTS Model with Differentiable Duration Modeling",
    "volume": "main",
    "abstract": "This paper introduces , a non-autoregressive neural text-to-speech model with a fully differentiable duration model which does not require supervised duration signals. The duration model is based on a novel attention mechanism and an iterative reconstruction loss based on Soft Dynamic TimeWarping, this model can learn token-frame alignments as well as token durations automatically. Experimental results show that Parallel Tacotron 2 outperforms baselines in subjective naturalness in several diverse multi speaker evaluations",
    "checked": true,
    "id": "d500d4147509749e10d388fd4900372d01a7c5df",
    "semantic_title": "parallel tacotron 2: a non-autoregressive neural tts model with differentiable duration modeling",
    "citation_count": 43
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wu21b_interspeech.html": {
    "title": "Transformer-Based Acoustic Modeling for Streaming Speech Synthesis",
    "volume": "main",
    "abstract": "Transformer models have shown promising results in neural speech synthesis due to their superior ability to model long-term dependencies compared to recurrent networks. The computation complexity of transformers increases quadratically with sequence length, making it impractical for many real-time applications. To address the complexity issue in speech synthesis domain, this paper proposes an efficient transformer-based acoustic model that is constant-speed regardless of input sequence length, making it ideal for streaming speech synthesis applications. The proposed model uses a transformer network that predicts the prosody features at phone rate and then an Emformer network to predict the frame-rate spectral features in a streaming manner. Both the transformer and Emformer in the proposed architecture use a self-attention mechanism that involves explicit long-term information, thus providing improved speech naturalness for long utterances. In our experiments, we use a WaveRNN neural vocoder that takes in the predicted spectral features and generates the final audio. The overall architecture achieves human-like speech quality both on short and long utterances while maintaining a low latency and low real-time factor. Our mean opinion score (MOS) evaluation shows that for short utterances, the proposed model achieves a MOS of 4.213 compared to ground-truth with MOS of 4.307; and for long utterances, it also produces high-quality speech with a MOS of 4.201 compared to ground-truth with MOS of 4.360",
    "checked": true,
    "id": "3b0e51ad9b89f87538f6256cda0b7a22dd71a0b8",
    "semantic_title": "transformer-based acoustic modeling for streaming speech synthesis",
    "citation_count": 8
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jia21_interspeech.html": {
    "title": "PnG BERT: Augmented BERT on Phonemes and Graphemes for Neural TTS",
    "volume": "main",
    "abstract": "This paper introduces , a new encoder model for neural TTS. This model is augmented from the original BERT model, by taking both phoneme and grapheme representations of text as input, as well as the word-level alignment between them. It can be pre-trained on a large text corpus in a self-supervised manner, and fine-tuned in a TTS task. Experimental results show that a neural TTS model using a pre-trained PnG BERT as its encoder yields more natural prosody and more accurate pronunciation than a baseline model using only phoneme input with no pre-training. Subjective side-by-side preference evaluations show that raters have no statistically significant preference between the speech synthesized using a PnG BERT and ground truth recordings from professional speakers",
    "checked": true,
    "id": "c437b1f260f294af628483d77a49239fa613aa89",
    "semantic_title": "png bert: augmented bert on phonemes and graphemes for neural tts",
    "citation_count": 50
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ge21_interspeech.html": {
    "title": "Speed up Training with Variable Length Inputs by Efficient Batching Strategies",
    "volume": "main",
    "abstract": "In the model training with neural networks, although the model performance is always the first priority to optimize, training efficiency also plays an important role in model deployment. There are many ways to speed up training with minimal performance loss, such as training with more GPUs, or with mixed precisions, optimizing training parameters, or making features more compact but more representable. Since mini-batch training is now the go-to approach for many machine learning tasks, minimizing the zero-padding to incorporate samples of different lengths into one batch, is an alternative approach to save training time. Here we propose a batching strategy based on semi-sorted samples, with dynamic batch sizes and batch randomization. By replacing the random batching with the proposed batching strategies, it saves more than 40% training time without compromising performance in training seq2seq neural text-to-speech models based on the Tacotron framework. We also compare it with two other batching strategies and show it performs similarly in terms of saving time and maintaining performance, but with a simpler concept and a smoother tuning parameter to balance between zero-padding and randomness level",
    "checked": true,
    "id": "e8aea5f6152a76f6c552789343c248873a204246",
    "semantic_title": "speed up training with variable length inputs by efficient batching strategies",
    "citation_count": 1
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sun21_interspeech.html": {
    "title": "Funnel Deep Complex U-Net for Phase-Aware Speech Enhancement",
    "volume": "main",
    "abstract": "The emergence of deep neural networks has made speech enhancement well developed. Most of the early models focused on estimating the magnitude of spectrum while ignoring the phase, this gives the evaluation result a certain upper limit. Some recent researches proposed deep complex network, which can handle complex inputs, and realize joint estimation of magnitude spectrum and phase spectrum by outputting real and imaginary parts respectively. The encoder-decoder structure in Deep Complex U-net (DCU) has been proven to be effective for complex-valued data. To further improve the performance, in this paper, we design a new network called Funnel Deep Complex U-net (FDCU), which could process magnitude information and phase information separately through one-encoder-two-decoders structure. Moreover, in order to achieve better training effect, we define negative stretched-SI-SNR as the loss function to avoid errors caused by the negative vector angle. Experimental results show that our FDCU model outperforms state-of-the-art approaches in all evaluation metrics",
    "checked": true,
    "id": "c9ca35b78e5f19eb955d9173ce019adba9045854",
    "semantic_title": "funnel deep complex u-net for phase-aware speech enhancement",
    "citation_count": 5
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21b_interspeech.html": {
    "title": "Temporal Convolutional Network with Frequency Dimension Adaptive Attention for Speech Enhancement",
    "volume": "main",
    "abstract": "Despite much progress, most temporal convolutional networks (TCN) based speech enhancement models are mainly focused on modeling the long-term temporal contextual dependencies of speech frames, without taking into account the distribution information of speech signal in frequency dimension. In this study, we propose a frequency dimension adaptive attention (FAA) mechanism to improve TCNs, which guides the model selectively emphasize the frequency-wise features with important speech information and also improves the representation capability of network. Our extensive experimental investigation demonstrates that the proposed FAA mechanism is able to consistently provide significant improvements in terms of speech quality (PESQ), intelligibility (STOI) and three other composite metrics. More promisingly, it has better generalization ability to real-world noisy environment",
    "checked": true,
    "id": "30e79104624988e9a4da0c58044ffd59e53f4ab9",
    "semantic_title": "temporal convolutional network with frequency dimension adaptive attention for speech enhancement",
    "citation_count": 8
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pan21_interspeech.html": {
    "title": "Perceptual Contributions of Vowels and Consonant-Vowel Transitions in Understanding Time-Compressed Mandarin Sentences",
    "volume": "main",
    "abstract": "Many early studies reported the importance of vowels and vowel-consonant transitions to speech intelligibility. The present work assessed their perceptual impacts to the understanding of time-compressed sentences, which could be used to measure the temporal acuity during speech understanding. Mandarin sentences were edited to selectively preserve vowel centers or vowel-consonant transitional segments, and compress the rest regions with equipment time compression rates (TCRs) up to 3, including conditions only preserving vowel centers or vowel-consonant transitions. The processed stimuli were presented to normal-hearing listeners to recognize. Results showed that, consistent with the segmental contributions in understanding uncompressed speech, the vowel-only time-compressed stimuli were highly intelligible (i.e., intelligibility score >85%) at a TCR around 3, and vowel-consonant transitions carried important intelligibility information in understanding time-compressed sentences. The time-compression conditions in the present work provided higher intelligibility scores than their counterparties in understanding the PSOLA-processed time-compressed sentences with TCRs around 3. The findings in this work suggested that the design of time compression processing could be guided towards selectively preserving perceptually important speech segments (e.g., vowels) in the future",
    "checked": true,
    "id": "3fc7c3e0b439ff6ddf30ea0168f02311e323d1ce",
    "semantic_title": "perceptual contributions of vowels and consonant-vowel transitions in understanding time-compressed mandarin sentences",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/biswas21_interspeech.html": {
    "title": "Transfer Learning for Speech Intelligibility Improvement in Noisy Environments",
    "volume": "main",
    "abstract": "In a recent work [1], a novel Delta Function-based Formant Shifting approach was proposed for speech intelligibility improvement. The underlying principle is to dynamically relocate the formants based on their occurrence in the spectrum away from the region of noise. The manner in which the formants are shifted is decided by the parameters of the Delta Function, the optimal values of which are evaluated using Comprehensive Learning Particle Swarm Optimization (CLPSO). Although effective, CLPSO is computationally expensive to the extent that it overshadows its merits in intelligibility improvement. As a solution to this, the current work aims to improve the Short-Time Objective Intelligibility (STOI) of (target) speech using a Delta Function that has been generated using a different (source) language. This transfer learning is based upon the relative positioning of the formant frequencies and pitch values of the source & target language datasets. The proposed approach is demonstrated and validated by subjecting it to experimentation with three different languages under variable noisy conditions",
    "checked": true,
    "id": "89a3c322ce4acf30e2d3298759fc47d2f6e5627b",
    "semantic_title": "transfer learning for speech intelligibility improvement in noisy environments",
    "citation_count": 2
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yamamoto21_interspeech.html": {
    "title": "Comparison of Remote Experiments Using Crowdsourcing and Laboratory Experiments on Speech Intelligibility",
    "volume": "main",
    "abstract": "Many subjective experiments have been performed to develop objective speech intelligibility measures, but the novel coronavirus outbreak has made it difficult to conduct experiments in a laboratory. One solution is to perform remote testing using crowdsourcing; however, because we cannot control the listening conditions, it is unclear whether the results are entirely reliable. In this study, we compared the speech intelligibility scores obtained from remote and laboratory experiments. The results showed that the mean and standard deviation (SD) of the remote experiments' speech reception threshold (SRT) were higher than those of the laboratory experiments. However, the variance in the SRTs across the speech-enhancement conditions revealed similarities, implying that remote testing results may be as useful as laboratory experiments to develop an objective measure. We also show that practice session scores are correlated with SRT values. This is a priori information before performing the main tests and would be useful for data screening to reduce the variability of the SRT distribution",
    "checked": true,
    "id": "6318311b8dad29622cf6fda76af9c2f249b62bfc",
    "semantic_title": "comparison of remote experiments using crowdsourcing and laboratory experiments on speech intelligibility",
    "citation_count": 5
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21b_interspeech.html": {
    "title": "Know Your Enemy, Know Yourself: A Unified Two-Stage Framework for Speech Enhancement",
    "volume": "main",
    "abstract": "Traditional spectral subtraction-type single channel speech enhancement (SE) algorithms often need to estimate interference components including noise and/or reverberation before subtracting them while deep neural network-based SE methods often aim to realize the end-to-end target mapping. In this paper, we show that both denoising and dereverberation can be unified into a common problem by introducing a two-stage paradigm, namely for interference components estimation and speech recovery. In the first stage, we propose to explicitly extract the magnitude of interference components, which serves as the prior information. In the second stage, with the guidance of this estimated magnitude prior, we can expect to better recover the target speech. In addition, we propose a transform module to facilitate the interaction between interference components and the desired speech modalities. Meanwhile, a temporal fusion module is designed to model long-term dependencies without ignoring short-term details. We conduct the experiments on the WSJ0-SI84 corpus and the results on both denoising and dereverberation tasks show that our approach outperforms previous advanced systems and achieves state-of-the-art performance in terms of many objective metrics",
    "checked": true,
    "id": "7caad4b855165f3f19501c105b7302a4401893a4",
    "semantic_title": "know your enemy, know yourself: a unified two-stage framework for speech enhancement",
    "citation_count": 9
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kong21_interspeech.html": {
    "title": "Speech Enhancement with Weakly Labelled Data from AudioSet",
    "volume": "main",
    "abstract": "Speech enhancement is a task to improve the intelligibility and perceptual quality of degraded speech signals. Recently, neural network-based methods have been applied to speech enhancement. However, many neural network-based methods require users to collect clean speech and background noise for training, which can be time-consuming. In addition, speech enhancement systems trained on particular types of background noise may not generalize well to a wide range of noise. To tackle those problems, we propose a speech enhancement framework trained on weakly labelled data. We first apply a pretrained sound event detection system to detect anchor segments that contain sound events in audio clips. Then, we randomly mix two detected anchor segments as a mixture. We build a conditional source separation network using the mixture and a conditional vector as input. The conditional vector is obtained from the audio tagging predictions on the anchor segments. In inference, we input a noisy speech signal with the one-hot encoding of \"Speech\" as a condition to the trained system to predict enhanced speech. Our system achieves a PESQ of 2.28 and an SSNR of 8.75 dB on the VoiceBank-DEMAND dataset, outperforming the previous SEGAN system of 2.16 and 7.73 dB respectively",
    "checked": true,
    "id": "89db5d6c26219fbc09ab4b1ac1853a514281f848",
    "semantic_title": "speech enhancement with weakly labelled data from audioset",
    "citation_count": 12
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hsieh21_interspeech.html": {
    "title": "Improving Perceptual Quality by Phone-Fortified Perceptual Loss Using Wasserstein Distance for Speech Enhancement",
    "volume": "main",
    "abstract": "Speech enhancement (SE) aims to improve speech quality and intelligibility, which are both related to a smooth transition in speech segments that may carry linguistic information, e.g. phones and syllables. In this study, we propose a novel phone-fortified perceptual loss (PFPL) that takes phonetic information into account for training SE models. To effectively incorporate the phonetic information, the PFPL is computed based on latent representations of the model, a powerful self-supervised encoder that renders rich phonetic information. To more accurately measure the distribution distances of the latent representations, the PFPL adopts the Wasserstein distance as the distance measure. Our experimental results first reveal that the PFPL is more correlated with the perceptual evaluation metrics, as compared to signal-level losses. Moreover, the results showed that the PFPL can enable a deep complex U-Net SE model to achieve highly competitive performance in terms of standardized quality and intelligibility evaluations on the Voice Bank–DEMAND dataset",
    "checked": true,
    "id": "27fe7a76098c9344024fa5c70c8f53e9df637040",
    "semantic_title": "improving perceptual quality by phone-fortified perceptual loss using wasserstein distance for speech enhancement",
    "citation_count": 33
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fu21_interspeech.html": {
    "title": "MetricGAN+: An Improved Version of MetricGAN for Speech Enhancement",
    "volume": "main",
    "abstract": "The discrepancy between the cost function used for training a speech enhancement model and human auditory perception usually makes the quality of enhanced speech unsatisfactory. Objective evaluation metrics which consider human perception can hence serve as a bridge to reduce the gap. Our previously proposed MetricGAN was designed to optimize objective metrics by connecting the metric with a discriminator. Because only the scores of the target evaluation functions are needed during training, the metrics can even be non-differentiable. In this study, we propose a MetricGAN+ in which three training techniques incorporating domain-knowledge of speech processing are proposed. With these techniques, experimental results on the VoiceBank-DEMAND dataset show that MetricGAN+ can increase PESQ score by 0.3 compared to the previous MetricGAN and achieve state-of-the-art results (PESQ score = 3.15)",
    "checked": true,
    "id": "686a302e00af17433aa10d8c38725b58668ad52e",
    "semantic_title": "metricgan+: an improved version of metricgan for speech enhancement",
    "citation_count": 106
  },
  "https://www.isca-speech.org/archive/interspeech_2021/edraki21_interspeech.html": {
    "title": "A Spectro-Temporal Glimpsing Index (STGI) for Speech Intelligibility Prediction",
    "volume": "main",
    "abstract": "We propose a monaural intrusive speech intelligibility prediction (SIP) algorithm called STGI based on detecting in short-time segments in a spectro-temporal modulation decomposition of the input speech signals. Unlike existing glimpse-based SIP methods, the application of STGI is not limited to additive uncorrelated noise; STGI can be employed in a broad range of degradation conditions. Our results show that STGI performs consistently well across 15 datasets covering degradation conditions including modulated noise, noise reduction processing, reverberation, near-end listening enhancement, checkerboard noise, and gated noise",
    "checked": true,
    "id": "88ac79710f0ff8696c8e98d7a28adcf8c183cbd9",
    "semantic_title": "a spectro-temporal glimpsing index (stgi) for speech intelligibility prediction",
    "citation_count": 5
  },
  "https://www.isca-speech.org/archive/interspeech_2021/qiu21_interspeech.html": {
    "title": "Self-Supervised Learning Based Phone-Fortified Speech Enhancement",
    "volume": "main",
    "abstract": "For speech enhancement, deep complex network based methods have shown promising performance due to their effectiveness in dealing with complex-valued spectrums. Recent speech enhancement methods focus on further optimization of network structures and hyperparameters, however, ignore inherent speech characteristics (e.g., phonetic characteristics), which are important for networks to learn and reconstruct speech information. In this paper, we propose a novel self-supervised learning based phone-fortified (SSPF) method for speech enhancement. Our method explicitly imports phonetic characteristics into a deep complex convolutional network via a Contrastive Predictive Coding (CPC) model pre-trained with self-supervised learning. This operation can greatly improve speech representation learning and speech enhancement performance. Moreover, we also apply the self-attention mechanism to our model for learning long-range dependencies of a speech sequence, which further improves the performance of speech enhancement. The experimental results demonstrate that our SSPF method outperforms existing methods and achieves state-of-the-art performance in terms of speech quality and intelligibility",
    "checked": true,
    "id": "b71441f85b95b0274675159c3cc1022f91bb75d3",
    "semantic_title": "self-supervised learning based phone-fortified speech enhancement",
    "citation_count": 5
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nayem21_interspeech.html": {
    "title": "Incorporating Embedding Vectors from a Human Mean-Opinion Score Prediction Model for Monaural Speech Enhancement",
    "volume": "main",
    "abstract": "Objective measures of success, such as the perceptual evaluation of speech quality (PESQ), signal-to-distortion ratio (SDR), and short-time objective intelligibility (STOI), have recently been used to optimize deep-learning based speech enhancement algorithms, in an effort to incorporate perceptual constraints into the learning process. Optimizing with these measures, however, may be sub-optimal, since the objective scores do not always strongly correlate with a listener's evaluation. This motivates the need for approaches that either are optimized with scores that are strongly correlated with human assessments or that use alternative strategies for incorporating perceptual constraints. In this work, we propose an attention-based approach that uses learned speech embedding vectors from a mean-opinion score (MOS) prediction model and a speech enhancement module to jointly enhance noisy speech. Our loss function is jointly optimized with signal approximation and MOS prediction loss terms. We train the model using real-world noisy speech data that has been captured in everyday environments. The results show that our proposed model significantly outperforms other approaches that are optimized with objective measures",
    "checked": true,
    "id": "c1078dcb98cee7e6c5b67ff0adda5f62a4644398",
    "semantic_title": "incorporating embedding vectors from a human mean-opinion score prediction model for monaural speech enhancement",
    "citation_count": 2
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21c_interspeech.html": {
    "title": "Restoring Degraded Speech via a Modified Diffusion Model",
    "volume": "main",
    "abstract": "There are many deterministic mathematical operations (e.g. compression, clipping, downsampling) that degrade speech quality considerably. In this paper we introduce a neural network architecture, based on a modification of the DiffWave model, that aims to restore the original speech signal. DiffWave, a recently published diffusion-based vocoder, has shown state-of-the-art synthesized speech quality and relatively shorter waveform generation times, with only a small set of parameters. We replace the mel-spectrum upsampler in DiffWave with a deep CNN upsampler, which is trained to alter the degraded speech mel-spectrum to match that of the original speech. The model is trained using the original speech waveform, but conditioned on the degraded speech mel-spectrum. Post-training, only the degraded mel-spectrum is used as input and the model generates an estimate of the original speech. Our model results in improved speech quality (original DiffWave model as baseline) on several different experiments. These include improving the quality of speech degraded by LPC-10 compression, AMR-NB compression, and signal clipping. Compared to the original DiffWave architecture, our scheme achieves better performance on several objective perceptual metrics and in subjective comparisons. Improvements over baseline are further amplified in a out-of-corpus evaluation setting",
    "checked": true,
    "id": "28db8fd711ac13599c9921db08cd586235d303ba",
    "semantic_title": "restoring degraded speech via a modified diffusion model",
    "citation_count": 13
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nguyen21_interspeech.html": {
    "title": "User-Initiated Repetition-Based Recovery in Multi-Utterance Dialogue Systems",
    "volume": "main",
    "abstract": "Recognition errors are common in human communication. Similar errors often lead to unwanted behaviour in dialogue systems or virtual assistants. In human communication, we can recover from them by repeating misrecognized words or phrases; however in human-machine communication this recovery mechanism is not available. In this paper, we attempt to bridge this gap and present a system that allows a user to correct speech recognition errors in a virtual assistant by repeating misunderstood words. When a user repeats part of the phrase the system rewrites the original query to incorporate the correction. This rewrite allows the virtual assistant to understand the original query successfully. We present an end-to-end 2-step attention pointer network that can generate the the rewritten query by merging together the incorrectly understood utterance with the correction follow-up. We evaluate the model on data collected for this task and compare the proposed model to a rule-based baseline and a standard pointer network. We show that rewriting the original query is an effective way to handle repetition-based recovery and that the proposed model outperforms the rule based baseline, reducing Word Error Rate by 19% relative at 2% False Alarm Rate on annotated data",
    "checked": true,
    "id": "3722c06603b144ecdb8bb9f594751934f52b214d",
    "semantic_title": "user-initiated repetition-based recovery in multi-utterance dialogue systems",
    "citation_count": 1
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21_interspeech.html": {
    "title": "Self-Supervised Dialogue Learning for Spoken Conversational Question Answering",
    "volume": "main",
    "abstract": "In spoken conversational question answering (SCQA), the answer to the corresponding question is generated by retrieving and then analyzing a fixed spoken document, including multi-part conversations. Most SCQA systems have considered only retrieving information from ordered utterances. However, the sequential order of dialogue is important to build a robust spoken conversational question answering system, and the changes of utterances order may severely result in low-quality and incoherent corpora. To this end, we introduce a self-supervised learning approach, including , and , to explicitly capture the coreference resolution and dialogue coherence among spoken documents. Specifically, we design a joint learning framework where the auxiliary self-supervised tasks can enable the pre-trained SCQA systems towards more coherent and meaningful spoken dialogue learning. We also utilize the proposed self-supervised learning tasks to capture intra-sentence coherence. Experimental results demonstrate that our proposed method provides more coherent, meaningful, and appropriate responses, yielding superior performance gains compared to the original pre-trained language models. Our method achieves state-of-the-art results on the Spoken-CoQA dataset",
    "checked": true,
    "id": "904afb6696575bb7d74f5e4e74d9cfced480a645",
    "semantic_title": "self-supervised dialogue learning for spoken conversational question answering",
    "citation_count": 24
  },
  "https://www.isca-speech.org/archive/interspeech_2021/su21_interspeech.html": {
    "title": "Act-Aware Slot-Value Predicting in Multi-Domain Dialogue State Tracking",
    "volume": "main",
    "abstract": "As an essential component in task-oriented dialogue systems, dialogue state tracking (DST) aims to track human-machine interactions and generate state representations for managing the dialogue. Representations of dialogue states are dependent on the domain ontology and the user's goals. In several task-oriented dialogues with a limited scope of objectives, dialogue states can be represented as a set of slot-value pairs. As the capabilities of dialogue systems expand to support increasing naturalness in communication, incorporating dialogue act processing into dialogue model design becomes essential. The lack of such consideration limits the scalability of dialogue state tracking models for dialogues having specific objectives and ontology. To address this issue, we formulate and incorporate dialogue acts, and leverage recent advances in machine reading comprehension to predict both categorical and non-categorical types of slots for multi-domain dialogue state tracking. Experimental results show that our models can improve the overall accuracy of dialogue state tracking on the MultiWOZ 2.1 dataset, and demonstrate that incorporating dialogue acts can guide dialogue state design for future task-oriented dialogue systems",
    "checked": true,
    "id": "8fe6ac053bc961093f46d8592e743215ad33bbad",
    "semantic_title": "act-aware slot-value predicting in multi-domain dialogue state tracking",
    "citation_count": 3
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chiba21_interspeech.html": {
    "title": "Dialogue Situation Recognition for Everyday Conversation Using Multimodal Information",
    "volume": "main",
    "abstract": "In recent years, dialogue systems have been applied to daily living. Such systems should be able to associate conversations with dialogue situations, such as a place where a dialogue occurs and the relationship between participants. In this study, we propose a dialogue situation recognition method that understands the perspective of dialogue scenes. The target dialogue situations contain dialogue styles, places, activities, and relations between participants. We used the Corpus of Everyday Japanese Conversation (CEJC), which records natural everyday conversations in various situations for experiments. We experimentally verified the effectiveness of our proposed method using multimodal information for situation recognition",
    "checked": true,
    "id": "c5be70f553d46a6f6413fb48c044f6b8093bbefc",
    "semantic_title": "dialogue situation recognition for everyday conversation using multimodal information",
    "citation_count": 4
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yamazaki21_interspeech.html": {
    "title": "Neural Spoken-Response Generation Using Prosodic and Linguistic Context for Conversational Systems",
    "volume": "main",
    "abstract": "Spoken dialogue systems have become widely used in daily life. Such a system must interact with the user socially to truly operate as a partner with humans. In studies of recent dialogue systems, neural response generation led to natural response generation. However, these studies have not considered the acoustic aspects of conversational phenomena, such as the adaptation of prosody. We propose a spoken-response generation model that extends a neural conversational model to deal with pitch control signals. Our proposed model is trained using multimodal dialogue between humans. The generated pitch control signals are input to a speech synthesis system to control the pitch of synthesized speech. Our experiment shows that the proposed system can generate synthesized speech with an appropriate F0 contour as an utterance in context compared to the output of a system without pitch control, although language generation remains an issue",
    "checked": true,
    "id": "202c9b9e772fe9a8f26ea886268420e96376fcc3",
    "semantic_title": "neural spoken-response generation using prosodic and linguistic context for conversational systems",
    "citation_count": 4
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xu21_interspeech.html": {
    "title": "Semantic Transportation Prototypical Network for Few-Shot Intent Detection",
    "volume": "main",
    "abstract": "Few-shot intent detection is a problem that only a few annotated examples are available for unseen intents, and deep models could suffer from the overfitting problem because of scarce data. Existing state-of-the-art few-shot model, Prototypical Network (PN), mainly focus on computing the similarity between examples in a metric space by leveraging sentence-level instance representations. However, sentence-level representations may incorporate highly noisy signals from unrelated words which leads to performance degradation. In this paper, we propose Semantic Transportation Prototypical Network (STPN) to alleviate this issue. Different from the original PN, our approach takes word-level representation as input and uses a new distance metric to obtain better sample matching result. And we reformulate the few-shot classification task into an instance of optimal matching, in which the key word semantic information between examples are expected to be matched and the matching cost is treated as similarity. Specifically, we design Mutual-Semantic mechanism to generate word semantic information, which could reduce the unrelated word noise and enrich key word information. Then, Earth Mover's Distance (EMD) is applied to find an optimal matching solution. Comprehensive experiments on two benchmark datasets are conducted to validate the effectiveness and generalization of our proposed model",
    "checked": true,
    "id": "8decba8a86d69c19aa87edf53e06b31298ab22c8",
    "semantic_title": "semantic transportation prototypical network for few-shot intent detection",
    "citation_count": 11
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tang21_interspeech.html": {
    "title": "Domain-Specific Multi-Agent Dialog Policy Learning in Multi-Domain Task-Oriented Scenarios",
    "volume": "main",
    "abstract": "Traditional dialog policy learning methods train a generic dialog agent to address all situations. However, when the dialog agent encounters a complicated task that involves more than one domain, it becomes difficult to perform concordant actions due to the hybrid information in the multi-domain ontology. Inspired by a real-life scenario at a bank, there are always several specialized departments that deal with different businesses. In this paper, we propose Domain-Specific Multi-Agent Dialog Policy Learning (DSMADPL), in which the dialog system is composed of a set of agents where each agent represents a specialized skill in a particular domain. Every domain-specific agent is first pretrained with supervised learning using a dialog corpus, and then they are jointly improved with multi-agent reinforcement learning. When the dialog system interacts with the user, in each turn the system action is decided by the actions of relevant agents. Experiments conducted on the commonly used MultiWOZ dataset prove the effectiveness of the proposed method, in which dialog success rate increases from 55.0% for the traditional method to 67.2% for our method in multi-domain scenarios",
    "checked": true,
    "id": "e0a9a3e463bbc7b65fd562c5c9a8dbc6217218c9",
    "semantic_title": "domain-specific multi-agent dialog policy learning in multi-domain task-oriented scenarios",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21b_interspeech.html": {
    "title": "Leveraging ASR N-Best in Deep Entity Retrieval",
    "volume": "main",
    "abstract": "Entity Retrieval (ER) in spoken dialog systems is a task that retrieves entities in a catalog for the entity mentions in user utterances. ER systems are susceptible to upstream errors, with Automatic Speech Recognition (ASR) errors being particularly troublesome. In this work, we propose a robust deep learning based ER system by leveraging ASR N-best hypotheses. Specifically, we evaluate different neural architectures to infuse ASR N-best through an attention mechanism. On 750 hours of audio data taken from live traffic, our best model achieves 11.07% relative error reduction while maintaining the same performance on rejecting out-of-domain ER requests",
    "checked": true,
    "id": "e90aa6debe3bdc089f174bb8f6671e8f47798592",
    "semantic_title": "leveraging asr n-best in deep entity retrieval",
    "citation_count": 4
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21d_interspeech.html": {
    "title": "End-to-End Spelling Correction Conditioned on Acoustic Feature for Code-Switching Speech Recognition",
    "volume": "main",
    "abstract": "In this work, we propose a new end-to-end (E2E) spelling correction method for post-processing of code-switching automatic speech recognition (ASR). Existing E2E spelling correction models take the hypotheses of ASR as inputs and annotated text as the targets. Due to the powerful modeling capabilities of the E2E model, the training of the correction system is extremely prone to over-fitting. It usually requires sufficient data diversity for reliable training. Therefore, it is difficult to apply the E2E correction models to the code-switching ASR task because of the data shortage. In this paper, we introduce the acoustic features into the spelling correction model. Our method can alleviate the problem of over-fitting and has better performance. Meanwhile, because the acoustic features are encode-free, our proposed model can be applied to the ASR model without significantly increasing the computational cost. The experimental results on ASRU 2019 Mandarin-English Code-switching Challenge data set show that the proposed method achieves 11.14% relative error rate reduction compared with baseline",
    "checked": true,
    "id": "832344b4e8dcdebca7a78e4d1dab1b73cbc08b9b",
    "semantic_title": "end-to-end spelling correction conditioned on acoustic feature for code-switching speech recognition",
    "citation_count": 8
  },
  "https://www.isca-speech.org/archive/interspeech_2021/siminyu21_interspeech.html": {
    "title": "Phoneme Recognition Through Fine Tuning of Phonetic Representations: A Case Study on Luhya Language Varieties",
    "volume": "main",
    "abstract": "Models pre-trained on multiple languages have shown significant promise for improving speech recognition, particularly for low-resource languages. In this work, we focus on phoneme recognition using Allosaurus, a method for multilingual recognition based on phonetic annotation, which incorporates phonological knowledge through a language-dependent allophone layer that associates a universal narrow phone-set with the phonemes that appear in each language. To evaluate in a challenging real-world scenario, we curate phone recognition datasets for Bukusu and Saamia, two varieties of the Luhya language cluster of western Kenya and eastern Uganda. To our knowledge, these datasets are the first of their kind. We carry out similar experiments on the dataset of an endangered Tangkhulic language, East Tusom, a Tibeto-Burman language variety spoken mostly in India. We explore both zero-shot and few-shot recognition by fine-tuning using datasets of varying sizes (10 to 1000 utterances). We find that fine-tuning of Allosaurus, even with just 100 utterances, leads to significant improvements in phone error rates",
    "checked": true,
    "id": "bad5d2d6d1f3282ebbcb602a6f3a5dd9488fd713",
    "semantic_title": "phoneme recognition through fine tuning of phonetic representations: a case study on luhya language varieties",
    "citation_count": 5
  },
  "https://www.isca-speech.org/archive/interspeech_2021/loweimi21_interspeech.html": {
    "title": "Speech Acoustic Modelling Using Raw Source and Filter Components",
    "volume": "main",
    "abstract": "Source-filter modelling is among the fundamental techniques in speech processing with a wide range of applications. In acoustic modelling, features such as MFCC and PLP which parametrise the filter component are widely employed. In this paper, we investigate the efficacy of building acoustic models from the raw filter and source components. The raw magnitude spectrum, as the primary information stream, is decomposed into the excitation and vocal tract information streams via cepstral liftering. Then, acoustic models are built via multi-head CNNs which, among others, allow for processing each individual stream via a sequence of bespoke transforms and fusing them at an optimal level of abstraction. We discuss the possible advantages of such information factorisation and recombination, investigate the dynamics of these models and explore the optimal fusion level. Furthermore, we illustrate the CNN's learned filters and provide some interpretation for the captured patterns. The proposed approach with optimal fusion scheme results in up to 14% and 7% relative WER reduction in WSJ and Aurora-4 tasks",
    "checked": true,
    "id": "956404c3e5ad68fcf7e416792889630f0f5c76f9",
    "semantic_title": "speech acoustic modelling using raw source and filter components",
    "citation_count": 4
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fujimoto21_interspeech.html": {
    "title": "Noise Robust Acoustic Modeling for Single-Channel Speech Recognition Based on a Stream-Wise Transformer Architecture",
    "volume": "main",
    "abstract": "This paper addresses a noise-robust automatic speech recognition (ASR) method under the constraints of real-time, one-pass, and single-channel processing. Under such strong constraints, single-channel speech enhancement becomes a key technology because methods with multiple-passes or batch processing, such as acoustic model adaptation, are not suitable for use. However, single-channel speech enhancement often degrades ASR performance due to speech distortion. To overcome this problem, we propose a noise robust acoustic modeling method based on the stream-wise transformer model. The proposed method accepts multi-stream features obtained by multiple single-channel speech enhancement methods as input and selectively uses an appropriate feature stream according to the noise environment by paying attention to the noteworthy stream on the basis of multi-head attention. The proposed method considers the attention for the stream direction instead of the time series direction, and it is thus capable of real-time and low-latency processing. Comparative evaluations reveal that the proposed method successfully improves the accuracy of ASR in noisy environments and reduces the number of model parameters even under strong constraints",
    "checked": true,
    "id": "59dfc48ad807150a8db4a0b8b7e1eb8f8ac33103",
    "semantic_title": "noise robust acoustic modeling for single-channel speech recognition based on a stream-wise transformer architecture",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ratnarajah21_interspeech.html": {
    "title": "IR-GAN: Room Impulse Response Generator for Far-Field Speech Recognition",
    "volume": "main",
    "abstract": "We present a Generative Adversarial Network (GAN) based room impulse response generator (IR-GAN) for generating realistic synthetic room impulse responses (RIRs). IR-GAN extracts acoustic parameters from captured real-world RIRs and uses these parameters to generate new synthetic RIRs. We use these generated synthetic RIRs to improve far-field automatic speech recognition in new environments that are different from the ones used in training datasets. In particular, we augment the far-field speech training set by convolving our synthesized RIRs with a clean LibriSpeech dataset [1]. We evaluate the quality of our synthetic RIRs on the far-field LibriSpeech test set created using real-world RIRs from the BUT ReverbDB [2] and AIR [3] datasets. Our IR-GAN reports up to an 8.95% lower error rate than Geometric Acoustic Simulator (GAS) in far-field speech recognition benchmarks. We further improve the performance when we combine our synthetic RIRs with synthetic impulse responses generated using GAS. This combination can reduce the word error rate by up to 14.3% in far-field speech recognition benchmarks",
    "checked": true,
    "id": "23e208eb3251fd3521c14bcbd3ee2d97a369ed89",
    "semantic_title": "ir-gan: room impulse response generator for far-field speech recognition",
    "citation_count": 21
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21b_interspeech.html": {
    "title": "Scaling Sparsemax Based Channel Selection for Speech Recognition with ad-hoc Microphone Arrays",
    "volume": "main",
    "abstract": "Recently, speech recognition with ad-hoc microphone arrays has received much attention. It is known that channel selection is an important problem of ad-hoc microphone arrays, however, this topic seems far from explored in speech recognition yet, particularly with a large-scale ad-hoc microphone array. To address this problem, we propose a algorithm for the channel selection problem of the speech recognition with large-scale ad-hoc microphone arrays. Specifically, we first replace the conventional Softmax operator in the stream attention mechanism of a multichannel end-to-end speech recognition system with Sparsemax, which conducts channel selection by forcing the channel weights of noisy channels to zero. Because Sparsemax punishes the weights of many channels to zero harshly, we propose Scaling Sparsemax which punishes the channels mildly by setting the weights of very noisy channels to zero only. Experimental results with ad-hoc microphone arrays of over 30 channels under the conformer speech recognition architecture show that the proposed Scaling Sparsemax yields a word error rate of over 30% lower than Softmax on simulation data sets, and over 20% lower on semi-real data sets, in test scenarios with both matched and mismatched channel numbers",
    "checked": true,
    "id": "d359eee45dc476c98324aff01240ad1163818a97",
    "semantic_title": "scaling sparsemax based channel selection for speech recognition with ad-hoc microphone arrays",
    "citation_count": 8
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chang21_interspeech.html": {
    "title": "Multi-Channel Transformer Transducer for Speech Recognition",
    "volume": "main",
    "abstract": "Multi-channel inputs offer several advantages over single-channel, to improve the robustness of on-device speech recognition systems. Recent work on multi-channel transformer, has proposed a way to incorporate such inputs into end-to-end ASR for improved accuracy. However, this approach is characterized by a high computational complexity, which prevents it from being deployed in on-device systems. In this paper, we present a novel speech recognition model, , which features end-to-end multi-channel training, low computation cost, and low latency so that it is suitable for streaming decoding in on-device speech recognition. In a far-field in-house dataset, our MCTT outperforms stagewise multi-channel models with transformer-transducer up to 6.01% relative WER improvement (WERR). In addition, MCTT outperforms the multi-channel transformer up to 11.62% WERR, and is 15.8 times faster in terms of inference speed. We further show that we can improve the computational cost of MCTT by constraining the future and previous context in attention computations",
    "checked": true,
    "id": "f35e8a7a2bafa8ccb12ae165294e165dfdb986d8",
    "semantic_title": "multi-channel transformer transducer for speech recognition",
    "citation_count": 13
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tsunoo21_interspeech.html": {
    "title": "Data Augmentation Methods for End-to-End Speech Recognition on Distant-Talk Scenarios",
    "volume": "main",
    "abstract": "Although end-to-end automatic speech recognition (E2E ASR) has achieved great performance in tasks that have numerous paired data, it is still challenging to make E2E ASR robust against noisy and low-resource conditions. In this study, we investigated data augmentation methods for E2E ASR in distant-talk scenarios. E2E ASR models are trained on the series of CHiME challenge datasets, which are suitable tasks for studying robustness against noisy and spontaneous speech. We propose to use three augmentation methods and their combinations: 1) data augmentation using text-to-speech (TTS) data, 2) cycle-consistent generative adversarial network (Cycle-GAN) augmentation trained to map two different audio characteristics, the one of clean speech and of noisy recordings, to match the testing condition, and 3) pseudo-label augmentation provided by the pretrained ASR module for smoothing label distributions. Experimental results using the CHiME-6/CHiME-4 datasets show that each augmentation method individually improves the accuracy on top of the conventional SpecAugment; further improvements are obtained by combining these approaches. We achieved 4.3% word error rate (WER) reduction, which was more significant than that of the SpecAugment, when we combine all three augmentations for the CHiME-6 task",
    "checked": true,
    "id": "77cd3ae8a0b9ef6865d5324a4d62280e6f7a1053",
    "semantic_title": "data augmentation methods for end-to-end speech recognition on distant-talk scenarios",
    "citation_count": 10
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ma21_interspeech.html": {
    "title": "Leveraging Phone Mask Training for Phonetic-Reduction-Robust E2E Uyghur Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/likhomanenko21_interspeech.html": {
    "title": "Rethinking Evaluation in ASR: Are Our Models Robust Enough?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lam21_interspeech.html": {
    "title": "Raw Waveform Encoder with Multi-Scale Globally Attentive Locally Recurrent Networks for End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hou21_interspeech.html": {
    "title": "Attention-Based Cross-Modal Fusion for Audio-Visual Voice Activity Detection in Musical Video Streams",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21b_interspeech.html": {
    "title": "Noise-Tolerant Self-Supervised Learning for Audio-Visual Voice Activity Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/park21_interspeech.html": {
    "title": "Noisy Student-Teacher Training for Robust Keyword Spotting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ichikawa21_interspeech.html": {
    "title": "Multi-Channel VAD for Transcription of Group Discussion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhou21_interspeech.html": {
    "title": "Audio-Visual Information Fusion Using Cross-Modal Teacher-Student Learning for Voice Activity Detection in Realistic Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/makishima21_interspeech.html": {
    "title": "Enrollment-Less Training for Personalized Voice Activity Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nonaka21_interspeech.html": {
    "title": "Voice Activity Detection for Live Speech of Baseball Game Based on Tandem Connection with Speech/Noise Separation Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kwon21_interspeech.html": {
    "title": "FastICARL: Fast Incremental Classifier and Representation Learning with Efficient Budget Allocation in Audio Sensing Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wei21_interspeech.html": {
    "title": "End-to-End Transformer-Based Open-Vocabulary Keyword Spotting with Location-Guided Local Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bhati21_interspeech.html": {
    "title": "Segmental Contrastive Predictive Coding for Unsupervised Word Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xu21b_interspeech.html": {
    "title": "A Lightweight Framework for Online Voice Activity Detection in the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chlebowski21_interspeech.html": {
    "title": "See what I mean, huh?\" Evaluating Visual Inspection of F",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21c_interspeech.html": {
    "title": "System Performance as a Function of Calibration Methods, Sample Size and Sampling Variability in Likelihood Ratio-Based Forensic Voice Comparison",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bonneau21_interspeech.html": {
    "title": "Voicing Assimilations by French Speakers of German in Stop-Fricative Sequences",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chakraborty21_interspeech.html": {
    "title": "The Four-Way Classification of Stops with Voicing and Aspiration for Non-Native Speech Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/urooj21_interspeech.html": {
    "title": "Acoustic and Prosodic Correlates of Emotions in Urdu Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tamim21_interspeech.html": {
    "title": "Voicing Contrasts in the Singleton Stops of Palestinian Arabic: Production and Perception",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/coy21_interspeech.html": {
    "title": "A Comparison of the Accuracy of Dissen and Keshet's (2016) DeepFormants and Traditional LPC Methods for Semi-Automatic Speaker Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jessen21_interspeech.html": {
    "title": "MAP Adaptation Characteristics in Forensic Long-Term Formant Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lo21_interspeech.html": {
    "title": "Cross-Linguistic Speaker Individuality of Long-Term Formant Distributions: Phonetic and Forensic Perspectives",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/soo21_interspeech.html": {
    "title": "Sound Change in Spontaneous Bilingual Speech: A Corpus Study on the Cantonese n-l Merger in Cantonese-English Bilinguals",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lalhminghlui21_interspeech.html": {
    "title": "Characterizing Voiced and Voiceless Nasals in Mizo",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/schuller21_interspeech.html": {
    "title": "The INTERSPEECH 2021 Computational Paralinguistics Challenge: COVID-19 Cough, COVID-19 Speech, Escalation & Primates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/soleraurena21_interspeech.html": {
    "title": "Transfer Learning-Based Cough Representations for Automatic Detection of COVID-19",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/klumpp21_interspeech.html": {
    "title": "The Phonetic Footprint of Covid-19?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/casanova21_interspeech.html": {
    "title": "Transfer Learning and Data Augmentation Techniques to the COVID-19 Identification Tasks in ComParE 2021",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/illium21_interspeech.html": {
    "title": "Visual Transformers for Primates Classification and Covid Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pellegrini21_interspeech.html": {
    "title": "Deep-Learning-Based Central African Primate Species Classification with MixUp and SpecAugment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/muller21_interspeech.html": {
    "title": "A Deep and Recurrent Architecture for Primate Vocalization Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zwerts21_interspeech.html": {
    "title": "Introducing a Central African Primate Vocalisation Dataset for Automated Species Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rizos21_interspeech.html": {
    "title": "Multi-Attentive Detection of the Spider Monkey Whinny in the (Actual) Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/egaslopez21_interspeech.html": {
    "title": "Identifying Conflict Escalation and Primates by Using Ensemble X-Vectors and Fisher Vector Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/verkholyak21_interspeech.html": {
    "title": "Ensemble-Within-Ensemble Classification for Escalation Prediction from Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/schiller21_interspeech.html": {
    "title": "Analysis by Synthesis: Using an Expressive TTS Model as Feature Extractor for Paralinguistic Speech Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/christensen21_interspeech.html": {
    "title": "Towards Automatic Speech Recognition for People with Atypical Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/luu21_interspeech.html": {
    "title": "Leveraging Speaker Attribute Information Using Multi Task Learning for Speaker Verification and Diarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rybicka21_interspeech.html": {
    "title": "Spine2Net: SpineNet with Res2Net and Time-Squeeze-and-Excitation Blocks for Speaker Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/stafylakis21_interspeech.html": {
    "title": "Speaker Embeddings by Modeling Channel-Wise Correlations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/he21_interspeech.html": {
    "title": "Multi-Task Neural Network for Robust Multiple Speaker Embedding Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/peng21_interspeech.html": {
    "title": "ICSpk: Interpretable Complex Speaker Embedding Extractor from Raw Waveform",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xiao21_interspeech.html": {
    "title": "Prosodic Disambiguation Using Chironomic Stylization of Intonation with Native and Non-Native Speakers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/block21_interspeech.html": {
    "title": "Variation in Perceptual Sensitivity and Compensation for Coarticulation Across Adult and Child Naturally-Produced and TTS Voices",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/monesi21_interspeech.html": {
    "title": "Extracting Different Levels of Speech Information from EEG Using an LSTM-Based Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bosch21_interspeech.html": {
    "title": "Word Competition: An Entropy-Based Approach in the DIANA Model of Human Word Comprehension",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bosch21b_interspeech.html": {
    "title": "Time-to-Event Models for Analyzing Reaction Time Sequences",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/brand21_interspeech.html": {
    "title": "Models of Reaction Times in Auditory Lexical Decision: RTonset versus RToffset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21c_interspeech.html": {
    "title": "SpecMix : A Mixed Sample Data Augmentation Method for Training with Time-Frequency Domain Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21d_interspeech.html": {
    "title": "SpecAugment++: A Hidden Space Data Augmentation Method for Acoustic Scene Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zheng21_interspeech.html": {
    "title": "An Effective Mutual Mean Teaching Based Domain Adaptation Method for Sound Event Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nandi21_interspeech.html": {
    "title": "Acoustic Scene Classification Using Kervolution-Based SubSpectralNet",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sundar21_interspeech.html": {
    "title": "Event Specific Attention for Polyphonic Sound Event Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gong21b_interspeech.html": {
    "title": "AST: Audio Spectrogram Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/seo21_interspeech.html": {
    "title": "Shallow Convolution-Augmented Transformer with Differentiable Neural Computer for Low-Complexity Classification of Variable-Length Acoustic Scene",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bear21_interspeech.html": {
    "title": "An Evaluation of Data Augmentation Methods for Sound Scene Geotagging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hori21_interspeech.html": {
    "title": "Optimizing Latency for Online Video Captioning Using Audio-Visual Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/si21_interspeech.html": {
    "title": "Variational Information Bottleneck for Effective Low-Resource Audio Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/deshmukh21_interspeech.html": {
    "title": "Improving Weakly Supervised Sound Event Detection with Self-Supervised Auxiliary Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/komatsu21_interspeech.html": {
    "title": "Acoustic Event Detection with Classifier Chains",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tseng21_interspeech.html": {
    "title": "Segment and Tone Production in Continuous Speech of Hearing and Hearing-Impaired Children",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21e_interspeech.html": {
    "title": "Effect of Carrier Bandwidth on Understanding Mandarin Sentences in Simulated Electric-Acoustic Hearing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sharma21_interspeech.html": {
    "title": "A Comparative Study of Different EMG Features for Acoustics-to-EMG Mapping",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/abraham21_interspeech.html": {
    "title": "Image-Based Assessment of Jaw Parameters and Jaw Kinematics for Articulatory Simulation: Preliminary Results",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21f_interspeech.html": {
    "title": "An Attention Self-Supervised Contrastive Learning Based Three-Stage Model for Hand Shape Feature Representation in Cued Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dineley21_interspeech.html": {
    "title": "Remote Smartphone-Based Speech Collection: Acceptance and Barriers in Individuals with Major Depressive Disorder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21_interspeech.html": {
    "title": "An Automatic, Simple Ultrasound Biofeedback Parameter for Distinguishing Accurate and Misarticulated Rhotic Syllables",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ribeiro21_interspeech.html": {
    "title": "Silent versus Modal Multi-Speaker Speech Recognition from Ultrasound and Video",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ferreira21_interspeech.html": {
    "title": "RaSSpeR: Radar-Based Silent Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cao21_interspeech.html": {
    "title": "Investigating Speech Reconstruction for Laryngectomees for Silent Speech Interfaces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/schroter21_interspeech.html": {
    "title": "LACOPE: Latency-Constrained Pitch Estimation for Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fontaine21_interspeech.html": {
    "title": "Alpha-Stable Autoregressive Fast Multichannel Nonnegative Matrix Factorization for Joint Speech Enhancement and Dereverberation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21e_interspeech.html": {
    "title": "Microphone Array Generalization for Multichannel Narrowband Deep Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/song21_interspeech.html": {
    "title": "Multiple Sound Source Localization Based on Interchannel Phase Differences in All Frequencies with Spectral Masks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zarazaga21_interspeech.html": {
    "title": "Cancellation of Local Competing Speaker with Near-Field Localization for Distributed ad-hoc Sensor Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21f_interspeech.html": {
    "title": "A Deep Learning Method to Multi-Channel Active Noise Control",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/graetzer21_interspeech.html": {
    "title": "Clarity-2021 Challenges: Machine Learning Challenges for Advancing Hearing Aid Processing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tu21b_interspeech.html": {
    "title": "Optimising Hearing Aid Fittings for Speech in Noise with a Differentiable Hearing Loss Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sivasankaran21_interspeech.html": {
    "title": "Explaining Deep Learning Models for Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/huang21_interspeech.html": {
    "title": "Minimum-Norm Differential Beamforming for Linear Array with Directional Microphones",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cao21b_interspeech.html": {
    "title": "Improving Streaming Transformer Based ASR Under a Framework of Self-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sadhu21_interspeech.html": {
    "title": "wav2vec-C: A Self-Supervised Model for Speech Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wallington21_interspeech.html": {
    "title": "On the Learning Dynamics of Semi-Supervised Training for ASR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hsu21_interspeech.html": {
    "title": "Robust wav2vec 2.0: Analyzing Domain Shift in Self-Supervised Pre-Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/higuchi21_interspeech.html": {
    "title": "Momentum Pseudo-Labeling for Semi-Supervised Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/misra21_interspeech.html": {
    "title": "A Comparison of Supervised and Unsupervised Pre-Training of End-to-End Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21c_interspeech.html": {
    "title": "Semi-Supervision in ASR: Sequential MixMatch and Factorized TTS-Based Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/likhomanenko21b_interspeech.html": {
    "title": "slimIPL: Language-Model-Free Iterative Pseudo-Labeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yue21_interspeech.html": {
    "title": "Phonetically Motivated Self-Supervised Speech Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/deng21_interspeech.html": {
    "title": "Improving RNN-T for Domain Scaling Using Semi-Supervised Training with Neural TTS",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/seyfarth21_interspeech.html": {
    "title": "Speaker-Conversation Factorial Designs for Diarization Error Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mcgowan21_interspeech.html": {
    "title": "SmallER: Scaling Neural Entity Resolution for Edge Devices",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rocholl21_interspeech.html": {
    "title": "Disfluency Detection with Unlabeled Data and Small BERT Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21d_interspeech.html": {
    "title": "Discriminative Self-Training for Punctuation Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ihori21_interspeech.html": {
    "title": "Zero-Shot Joint Modeling of Multiple Spoken-Text-Style Conversion Tasks Using Switching Tokens",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lin21_interspeech.html": {
    "title": "A Noise Robust Method for Word-Level Pronunciation Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wintrode21_interspeech.html": {
    "title": "Targeted Keyword Filtering for Accelerated Spoken Topic Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/palaskar21_interspeech.html": {
    "title": "Multimodal Speech Summarization Through Semantic Concept Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lee21_interspeech.html": {
    "title": "Enhancing Semantic Understanding with Self-Supervised Methods for Abstractive Dialogue Summarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wodarczak21_interspeech.html": {
    "title": "Speaker Transition Patterns in Three-Party Conversation: Evidence from English, Estonian and Swedish",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/broughton21_interspeech.html": {
    "title": "Investigating Deep Neural Structures and their Interpretability in the Domain of Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhou21b_interspeech.html": {
    "title": "Limited Data Emotional Voice Conversion Leveraging Text-to-Speech: Two-Stage Sequence-to-Sequence Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ding21_interspeech.html": {
    "title": "Adversarial Voice Conversion Against Neural Spoofing Detectors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/he21b_interspeech.html": {
    "title": "An Improved StarGAN for Emotional Voice Conversion: Enhancing Voice Quality and Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21e_interspeech.html": {
    "title": "TVQVC: Transformer Based Vector Quantized Variational Autoencoder with CTC Loss for Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21g_interspeech.html": {
    "title": "Enriching Source Style Transfer in Recognition-Synthesis Based Non-Parallel Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lin21b_interspeech.html": {
    "title": "S2VC: A Framework for Any-to-Any Voice Conversion with Self-Supervised Pretrained Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liberatore21_interspeech.html": {
    "title": "An Exemplar Selection Algorithm for Native-Nonnative Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21h_interspeech.html": {
    "title": "Adversarially Learning Disentangled Speech Representations for Robust Multi-Factor Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/luong21_interspeech.html": {
    "title": "Many-to-Many Voice Conversion Based Feature Disentanglement Using Variational Autoencoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chouchane21_interspeech.html": {
    "title": "Privacy-Preserving Voice Anti-Spoofing Using Secure Multi-Party Computation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/aloufi21_interspeech.html": {
    "title": "Configurable Privacy-Preserving Automatic Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/novotney21_interspeech.html": {
    "title": "Adjunct-Emeritus Distillation for Semi-Supervised Language Model Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ro21_interspeech.html": {
    "title": "Communication-Efficient Agnostic Federated Averaging",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/koppelmann21_interspeech.html": {
    "title": "Privacy-Preserving Feature Extraction for Cloud-Based Wake Word Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yang21_interspeech.html": {
    "title": "PATE-AAE: Incorporating Adversarial Autoencoder into Private Aggregation of Teacher Ensembles for Spoken Command Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ma21b_interspeech.html": {
    "title": "Continual Learning for Fake Audio Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shah21_interspeech.html": {
    "title": "Evaluating the Vulnerability of End-to-End Automatic Speech Recognition Models to Membership Inference Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fazel21_interspeech.html": {
    "title": "SynthASR: Unlocking Synthetic Data for Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/muguli21_interspeech.html": {
    "title": "DiCOVA Challenge: Dataset, Task, and Baseline System for COVID-19 Diagnosis Using Acoustics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kamble21_interspeech.html": {
    "title": "PANACEA Cough Sound-Based Diagnosis of COVID-19 for the DiCOVA 2021 Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/karas21_interspeech.html": {
    "title": "Recognising Covid-19 from Coughing Using Ensembles of SVMs and LSTMs with Handcrafted and Deep Audio Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sodergren21_interspeech.html": {
    "title": "Detecting COVID-19 from Audio Recording of Coughs Using Random Forests and Support Vector Machines",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/das21_interspeech.html": {
    "title": "Diagnosis of COVID-19 Using Auditory Acoustic Cues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/harvill21_interspeech.html": {
    "title": "Classification of COVID-19 from Cough Using Autoregressive Predictive Coding Pretraining and Spectral Data Augmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/deshpande21_interspeech.html": {
    "title": "The DiCOVA 2021 Challenge — An Encoder-Decoder Approach for COVID-19 Recognition from Coughing Audio",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ritwik21_interspeech.html": {
    "title": "COVID-19 Detection from Spectral Features on the DiCOVA Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mallolragolta21_interspeech.html": {
    "title": "Cough-Based COVID-19 Detection with Contextual Attention Convolutional Neural Networks and Gender Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bhosale21_interspeech.html": {
    "title": "Contrastive Learning of Cough Descriptors for Automatic COVID-19 Preliminary Diagnosis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/avila21_interspeech.html": {
    "title": "Investigating Feature Selection and Explainability for COVID-19 Diagnostics from Cough Sounds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kiss21_interspeech.html": {
    "title": "Application for Detecting Depression, Parkinson's Disease and Dysphonic Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/weingartova21_interspeech.html": {
    "title": "Beey: More Than a Speech-to-Text Editor",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/arai21_interspeech.html": {
    "title": "Downsizing of Vocal-Tract Models to Line up Variations and Reduce Manufacturing Costs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fabien21_interspeech.html": {
    "title": "ROXANNE Research Platform: Automate Criminal Investigations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/flucha21_interspeech.html": {
    "title": "The LIUM Human Active Correction Platform for Speaker Diarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/oh21_interspeech.html": {
    "title": "On-Device Streaming Transformer-Based End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cmejla21_interspeech.html": {
    "title": "Advanced Semi-Blind Speaker Extraction and Tracking Implemented in Experimental Device with Revolving Dense Microphone Array",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ney21_interspeech.html": {
    "title": "Forty Years of Speech and Language Processing: From Bayes Decision Rule to Deep Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chorowski21_interspeech.html": {
    "title": "Information Retrieval for ZeroSpeech 2021: The Submission by University of Wroclaw",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chorowski21b_interspeech.html": {
    "title": "Aligned Contrastive Predictive Coding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/suter21_interspeech.html": {
    "title": "Neural Text Denormalization for Speech Transcripts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/joglekar21_interspeech.html": {
    "title": "Fearless Steps Challenge Phase-3 (FSC P3): Advancing SLT for Unseen Channel and Mission Data Across NASA Apollo Audio",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/leykum21_interspeech.html": {
    "title": "Voice Quality in Verbal Irony: Electroglottographic Analyses of Ironic Utterances in Standard Austrian German",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hutin21_interspeech.html": {
    "title": "Synchronic Fortition in Five Romance Languages? A Large Corpus-Based Study of Word-Initial Devoicing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kraljevski21_interspeech.html": {
    "title": "Glottal Stops in Upper Sorbian: A Data-Driven Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ludusan21_interspeech.html": {
    "title": "Cue Interaction in the Perception of Prosodic Prominence: The Role of Voice Quality",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rodriguez21_interspeech.html": {
    "title": "Glottal Sounds in Korebaju",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chanclu21_interspeech.html": {
    "title": "Automatic Classification of Phonation Types in Spontaneous Speech: Towards a New Workflow for the Characterization of Speakers' Voice Quality",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/son21_interspeech.html": {
    "title": "Measuring Voice Quality Parameters After Speaker Pseudonymization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/steinert21_interspeech.html": {
    "title": "Audio-Visual Recognition of Emotional Engagement of People with Dementia",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hecker21_interspeech.html": {
    "title": "Speaking Corona? Human and Machine Recognition of COVID-19 from Voice",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nguyen21b_interspeech.html": {
    "title": "Acoustic-Prosodic, Lexical and Demographic Cues to Persuasiveness in Competitive Debate Speeches",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/borgstrom21_interspeech.html": {
    "title": "Unsupervised Bayesian Adaptation of PLDA for Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21i_interspeech.html": {
    "title": "The DKU-Duke-Lenovo System Description for the Fearless Steps Challenge Phase III",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21f_interspeech.html": {
    "title": "Improved Meta-Learning Training for Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21j_interspeech.html": {
    "title": "Variational Information Bottleneck Based Regularization for Speaker Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/brummer21_interspeech.html": {
    "title": "Out of a Hundred Trials, How Many Errors Does Your Speaker Verifier Make?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chojnacka21_interspeech.html": {
    "title": "SpeakerStew: Scaling to Many Languages with a Triaged Multilingual Text-Dependent and Text-Independent Speaker Verification System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21k_interspeech.html": {
    "title": "AntVoice Neural Speaker Embedding System for FFSVC 2020",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21b_interspeech.html": {
    "title": "Gradient Regularization for Noise-Robust Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kataria21_interspeech.html": {
    "title": "Deep Feature CycleGANs: Speaker Identity Preserving Non-Parallel Microphone-Telephone Domain Adaptation for Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pu21_interspeech.html": {
    "title": "Scaling Effect of Self-Supervised Speech Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wu21c_interspeech.html": {
    "title": "Joint Feature Enhancement and Speaker Recognition with Multi-Objective Task-Oriented Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21g_interspeech.html": {
    "title": "Multi-Level Transfer Learning from Near-Field to Far-Field Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/patino21_interspeech.html": {
    "title": "Speaker Anonymisation Using the McAdams Coefficient",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/luo21_interspeech.html": {
    "title": "Multi-Stream Gated and Pyramidal Temporal Convolutional Neural Networks for Audio-Visual Speech Separation in Multi-Talker Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21l_interspeech.html": {
    "title": "TeCANet: Temporal-Contextual Attention Network for Environment-Aware Speech Dereverberation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gu21_interspeech.html": {
    "title": "Residual Echo and Noise Cancellation with Feature Attention Module and Multi-Domain Loss Function",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21c_interspeech.html": {
    "title": "MIMO Self-Attentive RNN Beamformer for Multi-Speaker Speech Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/giri21_interspeech.html": {
    "title": "Personalized PercepNet: Real-Time, Low-Complexity Target Voice Separation and Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yemini21_interspeech.html": {
    "title": "Scene-Agnostic Multi-Microphone Speech Dereverberation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tanaka21_interspeech.html": {
    "title": "Manifold-Aware Deep Clustering: Maximizing Angles Between Embedding Vectors Based on Regular Simplex",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21h_interspeech.html": {
    "title": "A Deep Learning Approach to Multi-Channel and Multi-Microphone Acoustic Echo Cancellation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/na21_interspeech.html": {
    "title": "Joint Online Multichannel Acoustic Echo Cancellation, Speech Dereverberation and Source Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sato21_interspeech.html": {
    "title": "Should We Always Separate?: Switching Between Enhanced and Observed Signals for Overlapping Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/udupa21_interspeech.html": {
    "title": "Estimating Articulatory Movements in Speech Production with Transformer Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yang21b_interspeech.html": {
    "title": "Unsupervised Multi-Target Domain Adaptation for Acoustic Scene Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jaramillo21_interspeech.html": {
    "title": "Speech Decomposition Based on a Hybrid Speech Model and Optimal Segmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/luo21b_interspeech.html": {
    "title": "Dropout Regularization for Self-Supervised Learning of Transformer Encoder Speech Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yarra21_interspeech.html": {
    "title": "Noise Robust Pitch Stylization Using Minimum Mean Absolute Error Criterion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/huang21b_interspeech.html": {
    "title": "An Attribute-Aligned Strategy for Learning Speech Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shahrebabaki21_interspeech.html": {
    "title": "Raw Speech-to-Articulatory Inversion by Temporal Filtering and Decimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lilley21_interspeech.html": {
    "title": "Unsupervised Training of a DNN-Based Formant Tracker",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yang21c_interspeech.html": {
    "title": "SUPERB: Speech Processing Universal PERformance Benchmark",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21i_interspeech.html": {
    "title": "Synchronising Speech Segments with Musical Beats in Mandarin and English Singing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/peplinski21_interspeech.html": {
    "title": "FRILL: A Non-Semantic Speech Embedding for Mobile Devices",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mori21_interspeech.html": {
    "title": "Pitch Contour Separation from Overlapping Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kumar21_interspeech.html": {
    "title": "Do Sound Event Representations Generalize to Other Audio Tasks? A Case Study in Audio Transfer Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/peng21b_interspeech.html": {
    "title": "Data Augmentation for Spoken Language Understanding via Pretrained Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/radfar21_interspeech.html": {
    "title": "FANS: Fusing ASR and NLU for On-Device SLU",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cao21c_interspeech.html": {
    "title": "Sequential End-to-End Intent and Slot Label Classification and Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/muralidharan21_interspeech.html": {
    "title": "DEXTER: Deep Encoding of External Knowledge for Named Entity Recognition in Virtual Assistants",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wu21d_interspeech.html": {
    "title": "A Context-Aware Hierarchical BERT Fusion Network for Multi-Turn Dialog Act Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21g_interspeech.html": {
    "title": "Pre-Training for Spoken Language Understanding with Joint Textual and Phonetic Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/do21b_interspeech.html": {
    "title": "Predicting Temporal Performance Drop of Deployed Production Spoken Language Understanding Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ganhotra21_interspeech.html": {
    "title": "Integrating Dialog History into End-to-End Spoken Language Understanding Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/han21_interspeech.html": {
    "title": "Coreference Augmentation for Multi-Domain Task-Oriented Dialogue State Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/arora21_interspeech.html": {
    "title": "Rethinking End-to-End Evaluation of Decomposable Tasks: A Case Study on Spoken Language Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sun21b_interspeech.html": {
    "title": "Semantic Data Augmentation for End-to-End Mandarin Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gong21c_interspeech.html": {
    "title": "Layer-Wise Fast Adaptation for End-to-End Multi-Accent Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21m_interspeech.html": {
    "title": "Low Resource German ASR with Untranscribed Data Spoken by Non-Native Children — INTERSPEECH 2021 Shared Task SPAPL System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sim21_interspeech.html": {
    "title": "Robust Continuous On-Device Personalization for Automatic Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kumar21b_interspeech.html": {
    "title": "Speaker Normalization Using Joint Variational Autoencoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xu21c_interspeech.html": {
    "title": "The TAL System for the INTERSPEECH2021 Shared Task on Automatic Speech Recognition for Non-Native Childrens Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lam21b_interspeech.html": {
    "title": "On-the-Fly Aligned Data Augmentation for Sequence-to-Sequence ASR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gao21_interspeech.html": {
    "title": "Zero-Shot Cross-Lingual Phonetic Recognition with External Language Embedding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/huang21c_interspeech.html": {
    "title": "Rapid Speaker Adaptation for Conformer Transducer: Attention and Bias Are All You Need",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/das21b_interspeech.html": {
    "title": "Best of Both Worlds: Robust Accented Speech Recognition with Adversarial Transfer Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chu21_interspeech.html": {
    "title": "Extending Pronunciation Dictionary with Automatically Detected Word Mispronunciations to Improve PAII's System for Interspeech 2021 Non-Native Child English Close Track ASR Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21d_interspeech.html": {
    "title": "CVC: Contrastive Learning for Non-Parallel Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/huang21d_interspeech.html": {
    "title": "A Preliminary Study of a Two-Stage Paradigm for Preserving Speaker Identity in Dysarthric Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/eskimez21_interspeech.html": {
    "title": "One-Shot Voice Conversion with Speaker-Agnostic StarGAN",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/koshizuka21_interspeech.html": {
    "title": "Fine-Tuning Pre-Trained Voice Conversion Model for Adding New Target Speakers with Limited Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21n_interspeech.html": {
    "title": "VQMIVC: Vector Quantization and Mutual Information-Based Unsupervised Speech Representation Disentanglement for One-Shot Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21e_interspeech.html": {
    "title": "StarGANv2-VC: A Diverse, Unsupervised, Non-Parallel Framework for Natural-Sounding Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kumar21c_interspeech.html": {
    "title": "Normalization Driven Zero-Shot Multi-Speaker Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sakamoto21_interspeech.html": {
    "title": "StarGAN-VC+ASR: StarGAN-Based Non-Parallel Voice Conversion Regularized by Automatic Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xu21d_interspeech.html": {
    "title": "Two-Pathway Style Embedding for Arbitrary Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21c_interspeech.html": {
    "title": "Non-Parallel Any-to-Many Voice Conversion by Replacing Speaker Statistics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhou21c_interspeech.html": {
    "title": "Cross-Lingual Voice Conversion with a Cycle Consistency Loss on Linguistic Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/du21_interspeech.html": {
    "title": "Improving Robustness of One-Shot Voice Conversion with Deep Discriminative Speaker Encoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/white21_interspeech.html": {
    "title": "Optimizing an Automatic Creaky Voice Detection Method for Australian English Speaking Females",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/penney21_interspeech.html": {
    "title": "A Comparison of Acoustic Correlates of Voice Quality Across Different Recording Devices: A Cautionary Tale",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sfakianaki21_interspeech.html": {
    "title": "Investigating Voice Function Characteristics of Greek Speakers with Hearing Loss Using Automatic Glottal Source Feature Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/huckvale21_interspeech.html": {
    "title": "Automated Detection of Voice Disorder in the Saarbrücken Voice Database: Effects of Pathology Subset and Audio Materials",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lulich21_interspeech.html": {
    "title": "Accelerometer-Based Measurements of Voice Quality in Children During Semi-Occluded Vocal Tract Exercise with a Narrow Straw in Air",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/perez21_interspeech.html": {
    "title": "Articulatory Coordination for Speech Motor Tracking in Huntington Disease",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ferrer21_interspeech.html": {
    "title": "Modeling Dysphonia Severity as a Function of Roughness and Breathiness Ratings in the GRBAS Scale",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/karpov21_interspeech.html": {
    "title": "Golos: Russian Dataset for Speech Research",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sadhu21b_interspeech.html": {
    "title": "Radically Old Way of Computing Spectra: Applications in End-to-End ASR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/alghezi21_interspeech.html": {
    "title": "Self-Supervised End-to-End ASR for Low Resource L2 Swedish",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/oneill21_interspeech.html": {
    "title": "SPGISpeech: 5,000 Hours of Transcribed Financial Audio for Fully Formatted End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/evain21_interspeech.html": {
    "title": "",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sturm21_interspeech.html": {
    "title": "Prosodic Accommodation in Face-to-Face and Telephone Dialogues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/riverincoutlee21_interspeech.html": {
    "title": "Dialect Features in Heterogeneous and Homogeneous Gheg Speaking Communities",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zellers21_interspeech.html": {
    "title": "An Exploration of the Acoustic Space of Rhotics and Laterals in Ruruuli",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bodur21_interspeech.html": {
    "title": "Domain-Initial Strengthening in Turkish: Acoustic Cues to Prosodic Hierarchy in Stop Consonants",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zmolikova21_interspeech.html": {
    "title": "Auxiliary Loss Function for Target Speech Extraction and Recognition with Weak Supervision Based on Speaker Characteristics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/borsdorf21_interspeech.html": {
    "title": "Universal Speaker Extraction in the Presence and Absence of Target Speakers for Speech of One and Two Talkers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mateju21_interspeech.html": {
    "title": "Using X-Vectors for Speech Activity Detection in Broadcast Streams",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/salvati21_interspeech.html": {
    "title": "Time Delay Estimation for Speaker Localization Using CNN-Based Parametrized GCC-PHAT Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yousefi21_interspeech.html": {
    "title": "Real-Time Speaker Counting in a Cocktail Party Scenario Using Attention-Guided Convolutional Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21d_interspeech.html": {
    "title": "End-to-End Language Diarization for Bilingual Code-Switching Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/duroselle21_interspeech.html": {
    "title": "Modeling and Training Strategies for Language Recognition Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21o_interspeech.html": {
    "title": "A Weight Moving Average Based Alternate Decoupled Learning Algorithm for Long-Tailed Language Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/deng21b_interspeech.html": {
    "title": "Improving Accent Identification and Accented Speech Recognition Under a Framework of Self-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fan21_interspeech.html": {
    "title": "Exploring wav2vec 2.0 on Speaker Verification and Language Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ramesh21_interspeech.html": {
    "title": "Self-Supervised Phonotactic Representations for Language Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21j_interspeech.html": {
    "title": "E2E-Based Multi-Task Learning Approach to Joint Speech and Accent Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tzudir21_interspeech.html": {
    "title": "Excitation Source Feature Based Dialect Identification in Ao — A Low Resource Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/khare21_interspeech.html": {
    "title": "Low Resource ASR: The Surprising Effectiveness of High Resource Transliteration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/feng21_interspeech.html": {
    "title": "Unsupervised Acoustic Unit Discovery by Leveraging a Language-Independent Subword Discriminative Feature Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kamper21_interspeech.html": {
    "title": "Towards Unsupervised Phone and Word Segmentation Using Self-Supervised Vector-Quantized Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jiang21_interspeech.html": {
    "title": "Speech SimCLR: Combining Contrastive and Reconstruction Objective for Self-Supervised Speech Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jacobs21_interspeech.html": {
    "title": "Multilingual Transfer of Acoustic Word Embeddings Improves When Training on Languages Related to the Target Zero-Resource Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/niekerk21_interspeech.html": {
    "title": "Analyzing Speaker Information in Self-Supervised Models to Improve Zero-Resource Speech Processing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/takahashi21_interspeech.html": {
    "title": "Unsupervised Neural-Based Graph Clustering for Variable-Length Speech Representation Discovery of Zero-Resource Languages",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/maekaku21_interspeech.html": {
    "title": "Speech Representation Learning Combining Conformer CPC with Deep Cluster for the ZeroSpeech Challenge 2021",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cui21_interspeech.html": {
    "title": "Identifying Indicators of Vulnerability from Short Speech Segments Using Acoustic and Textual Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dunbar21_interspeech.html": {
    "title": "The Zero Resource Speech Challenge 2021: Spoken Language Modelling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gudur21_interspeech.html": {
    "title": "Zero-Shot Federated Learning with New Classes for Audio Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rouditchenko21_interspeech.html": {
    "title": "AVLnet: Learning Audio-Visual Language Representations from Instructional Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lee21b_interspeech.html": {
    "title": "N-Singer: A Non-Autoregressive Korean Singing Voice Synthesis System for Pronunciation Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/maniati21_interspeech.html": {
    "title": "Cross-Lingual Low Resource Speaker Adaptation Using Phonological Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhan21_interspeech.html": {
    "title": "Improve Cross-Lingual Text-To-Speech Synthesis on Monolingual Corpora with Pitch Contour Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yang21d_interspeech.html": {
    "title": "Cross-Lingual Voice Conversion with Disentangled Universal Linguistic Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21e_interspeech.html": {
    "title": "EfficientSing: A Chinese Singing Voice Synthesis System Using Duration-Free Acoustic Model and HiFi-GAN Vocoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xin21_interspeech.html": {
    "title": "Cross-Lingual Speaker Adaptation Using Domain Adaptation and Speaker Consistency Loss for Text-To-Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shang21_interspeech.html": {
    "title": "Incorporating Cross-Speaker Style Transfer for Multi-Language Text-to-Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kesim21_interspeech.html": {
    "title": "Investigating Contributions of Speech and Facial Landmarks for Talking Head Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/si21b_interspeech.html": {
    "title": "Speech2Video: Cross-Modal Distillation for Speech to Video Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lee21c_interspeech.html": {
    "title": "NU-Wave: A Diffusion Probabilistic Model for Neural Audio Upsampling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lin21c_interspeech.html": {
    "title": "QISTA-Net-Audio: Audio Super-Resolution via Non-Convex ℓ_q-Norm Minimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wen21_interspeech.html": {
    "title": "X-net: A Joint Scale Down and Scale Up Method for Voice Call",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21k_interspeech.html": {
    "title": "WSRGlow: A Glow-Based Waveform Generative Model for Audio Super-Resolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yi21_interspeech.html": {
    "title": "Half-Truth: A Partially Fake Audio Detection Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chettri21_interspeech.html": {
    "title": "Data Quality as Predictor of Voice Anti-Spoofing Generalization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cheon21_interspeech.html": {
    "title": "Coded Speech Enhancement Using Neural Network-Based Vector-Quantized Residual Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/drude21_interspeech.html": {
    "title": "Multi-Channel Opus Compression for Far-Field Automatic Speech Recognition with a Fixed Bitrate Budget",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/siegert21_interspeech.html": {
    "title": "Effects of Prosodic Variations on Accidental Triggers of a Commercial Voice Assistant",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gabrys21_interspeech.html": {
    "title": "Improving the Expressiveness of Neural Vocoding with Non-Affine Normalizing Flows",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/prajapati21_interspeech.html": {
    "title": "Voice Privacy Through x-Vector and CycleGAN-Based Anonymization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lin21d_interspeech.html": {
    "title": "A Two-Stage Approach to Speech Bandwidth Extension",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/byun21_interspeech.html": {
    "title": "Development of a Psychoacoustic Loss Function for the Deep Neural Network (DNN)-Based Speech Coder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/stoidis21_interspeech.html": {
    "title": "Protecting Gender and Identity with Disentangled Speech Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/aldholmi21_interspeech.html": {
    "title": "Perception of Standard Arabic Synthetic Speech Rate",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kishiyama21_interspeech.html": {
    "title": "The Influence of Parallel Processing on Illusory Vowels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chingacham21_interspeech.html": {
    "title": "Exploring the Potential of Lexical Paraphrases for Mitigating Noise-Induced Comprehension Errors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/simantiraki21_interspeech.html": {
    "title": "SpeechAdjuster: A Tool for Investigating Listener Preferences and Speech Intelligibility",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/saito21_interspeech.html": {
    "title": "VocalTurk: Exploring Feasibility of Crowdsourced Speaker Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xu21e_interspeech.html": {
    "title": "Effects of Aging and Age-Related Hearing Loss on Talker Discrimination",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21l_interspeech.html": {
    "title": "Relationships Between Perceptual Distinctiveness, Articulatory Complexity and Functional Load in Speech Communication",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/terblanche21_interspeech.html": {
    "title": "Human Spoofing Detection Performance on Degraded Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/einfeldt21_interspeech.html": {
    "title": "Reliable Estimates of Interpretable Cue Effects with Active Learning in Psycholinguistic Research",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kumar21d_interspeech.html": {
    "title": "Towards the Explainability of Multimodal Speech Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zeng21_interspeech.html": {
    "title": "Primacy of Mouth over Eyes: Eye Movement Evidence from Audiovisual Mandarin Lexical Tones and Vowels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ashihara21_interspeech.html": {
    "title": "Investigating the Impact of Spectral and Temporal Degradation on End-to-End Automatic Speech Recognition Performance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nguyen21c_interspeech.html": {
    "title": "Super-Human Performance in Online Low-Latency Recognition of Conversational Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/joshi21_interspeech.html": {
    "title": "Multiple Softmax Architecture for Streaming Multilingual End-to-End ASR Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/le21_interspeech.html": {
    "title": "Contextualized Streaming End-to-End Speech Recognition with Trie-Based Deep Biasing and Shallow Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sainath21_interspeech.html": {
    "title": "An Efficient Streaming Non-Recurrent On-Device End-to-End Model with Improvements to Rare-Word Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lu21_interspeech.html": {
    "title": "Streaming Multi-Talker Speech Recognition with Joint Speaker Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/moriya21_interspeech.html": {
    "title": "Streaming End-to-End Speech Recognition for Hybrid RNN-T/Attention Architecture",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/schwarz21_interspeech.html": {
    "title": "Improving RNN-T ASR Accuracy Using Context Audio",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/huang21e_interspeech.html": {
    "title": "HMM-Free Encoder Pre-Training for Streaming RNN Transducer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cui21b_interspeech.html": {
    "title": "Reducing Exposure Bias in Training Recurrent Neural Network Transducers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/doutre21_interspeech.html": {
    "title": "Bridging the Gap Between Streaming and Non-Streaming ASR Systems by Distilling Ensembles of CTC and RNN-T Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/audhkhasi21_interspeech.html": {
    "title": "Mixture Model Attention: Flexible Streaming and Non-Streaming Automatic Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/inaguma21_interspeech.html": {
    "title": "StableEmit: Selection Probability Discount for Reducing Emission Latency of Streaming Monotonic Attention ASR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/moritz21_interspeech.html": {
    "title": "Dual Causal/Non-Causal Self-Attention for Streaming End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21d_interspeech.html": {
    "title": "Multi-Mode Transformer Transducer with Stochastic Future Context",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ren21_interspeech.html": {
    "title": "A Causal U-Net Based Neural Beamforming Network for Real-Time Multi-Channel Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhu21d_interspeech.html": {
    "title": "A Partitioned-Block Frequency-Domain Adaptive Kalman Filter for Stereophonic Acoustic Echo Cancellation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21p_interspeech.html": {
    "title": "Real-Time Independent Vector Analysis Using Semi-Supervised Nonnegative Matrix Factorization as a Source Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/han21b_interspeech.html": {
    "title": "Improving Channel Decorrelation for Multi-Channel Target Speech Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21f_interspeech.html": {
    "title": "Inplace Gated Convolutional Recurrent Neural Network for Dual-Channel Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/raj21_interspeech.html": {
    "title": "SRIB-LEAP Submission to Far-Field Multi-Channel Speech Enhancement Challenge for Video Conferencing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xue21_interspeech.html": {
    "title": "Real-Time Multi-Channel Speech Enhancement Based on Neural Network Masking with Attention Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ganapathy21_interspeech.html": {
    "title": "Uncovering the Acoustic Cues of COVID-19 Infection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fung21_interspeech.html": {
    "title": "Ethical and Technological Challenges of Conversational AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fohr21_interspeech.html": {
    "title": "BERT-Based Semantic Model for Rescoring N-Best Speech Recognition List",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/benes21_interspeech.html": {
    "title": "Text Augmentation for Language Models in High Error Recognition Scenario",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gao21b_interspeech.html": {
    "title": "On Sampling-Based Training Criteria for Neural Language Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pylkkonen21_interspeech.html": {
    "title": "Fast Text-Only Domain Adaptation of RNN-Transducer Prediction Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cieri21_interspeech.html": {
    "title": "Using Games to Augment Corpora for Language Recognition and Confusability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fenu21_interspeech.html": {
    "title": "Fair Voice Biometrics: Impact of Demographic Imbalance on Group Fairness in Speaker Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21m_interspeech.html": {
    "title": "Knowledge Distillation from Multi-Modality to Single-Modality for Person Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/noe21_interspeech.html": {
    "title": "Adversarial Disentanglement of Speaker Representation for Attribute-Driven Privacy Preservation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/romana21_interspeech.html": {
    "title": "Automatically Detecting Errors and Disfluencies in Read Speech to Predict Cognitive Impairment in People with Parkinson's Disease",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/vaysse21_interspeech.html": {
    "title": "Automatic Extraction of Speech Rhythm Descriptors for Speech Intelligibility Assessment in the Context of Head and Neck Cancers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/qi21b_interspeech.html": {
    "title": "Speech Disorder Classification Using Extended Factorized Hierarchical Variational Auto-Encoders",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mathad21_interspeech.html": {
    "title": "The Impact of Forced-Alignment Errors on Automatic Pronunciation Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/villatorotello21_interspeech.html": {
    "title": "Late Fusion of the Available Lexicon and Raw Waveform-Based Acoustic Modeling for Depression and Dementia Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shandiz21_interspeech.html": {
    "title": "Neural Speaker Embeddings for Ultrasound-Based Silent Speech Interfaces",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lamba21_interspeech.html": {
    "title": "Cross-Modal Learning for Audio-Visual Video Parsing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cook21_interspeech.html": {
    "title": "A Psychology-Driven Computational Analysis of Political Interviews",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/santoso21_interspeech.html": {
    "title": "Speech Emotion Recognition Based on Attention Weight Correction Using Word-Level Confidence Measure",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/silpachai21_interspeech.html": {
    "title": "Effects of Voice Type and Task on L2 Learners' Awareness of Pronunciation Errors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/menshikova21_interspeech.html": {
    "title": "Lexical Entrainment and Intra-Speaker Variability in Cooperative Dialogues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nasreen21_interspeech.html": {
    "title": "Detecting Alzheimer's Disease Using Interactional and Acoustic Features from Spontaneous Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kothare21_interspeech.html": {
    "title": "Investigating the Interplay Between Affective, Phonatory and Motoric Subsystems in Autism Spectrum Disorder Using a Multimodal Dialogue Agent",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ishi21_interspeech.html": {
    "title": "Analysis of Eye Gaze Reasons and Gaze Aversions During Three-Party Conversations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21e_interspeech.html": {
    "title": "Semantic Distance: A New Metric for ASR Performance Analysis Towards Spoken Language Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21q_interspeech.html": {
    "title": "A Light-Weight Contextual Spelling Correction Model for Customizing Transducer-Based Speech Recognition Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shi21_interspeech.html": {
    "title": "Incorporating External POS Tagger for Punctuation Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/papadourakis21_interspeech.html": {
    "title": "Phonetically Induced Subwords for End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mansfield21_interspeech.html": {
    "title": "Revisiting Parity of Human vs. Machine Conversational Speech Transcription",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/huang21f_interspeech.html": {
    "title": "Lookup-Table Recurrent Language Models for Long Tail Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/andresferrer21_interspeech.html": {
    "title": "Contextual Density Ratio for Language Model Biasing of Sequence to Sequence ASR Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/huang21g_interspeech.html": {
    "title": "Token-Level Supervised Contrastive Learning for Punctuation Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhao21_interspeech.html": {
    "title": "BART Based Semantic Correction for Mandarin Automatic Speech Recognition System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dai21b_interspeech.html": {
    "title": "Class-Based Neural Network Language Model for Second-Pass Rescoring in ASR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kurata21_interspeech.html": {
    "title": "Improving Customization of Neural Transducers by Mitigating Acoustic Mismatch of Synthesized Audio",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/saebi21_interspeech.html": {
    "title": "A Discriminative Entity-Aware Language Model for Virtual Assistants",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/namazifar21_interspeech.html": {
    "title": "Correcting Automated and Manual Speech Transcription Errors Using Warped Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shi21b_interspeech.html": {
    "title": "Dynamic Encoder Transducer: A Flexible Solution for Trading Off Accuracy for Latency",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21n_interspeech.html": {
    "title": "Domain-Aware Self-Attention for Multi-Domain Neural Machine Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zeyer21_interspeech.html": {
    "title": "Librispeech Transducer Model with Internal Language Model Prior Correction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mavandadi21_interspeech.html": {
    "title": "A Deliberation-Based Joint Acoustic and Text Decoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tuske21_interspeech.html": {
    "title": "On the Limit of English Conversational Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/an21_interspeech.html": {
    "title": "Deformable TDNN with Adaptive Receptive Fields for Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/you21_interspeech.html": {
    "title": "SpeechMoE: Scaling to Large Acoustic Models with Dynamic Routing Mixture of Experts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/leong21_interspeech.html": {
    "title": "Online Compressive Transformer for End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lin21e_interspeech.html": {
    "title": "End to End Transformer-Based Contextual Speech Recognition Based on Pointer Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/karita21_interspeech.html": {
    "title": "A Comparative Study on Neural Architectures and Training Methods for Japanese Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hori21b_interspeech.html": {
    "title": "Advanced Long-Context End-to-End Speech Recognition Using Context-Expanded Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/haidar21_interspeech.html": {
    "title": "Transformer-Based ASR Incorporating Time-Reduction Layer and Fine-Tuning with Self-Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mahadeokar21_interspeech.html": {
    "title": "Flexi-Transducer: Optimizing Latency, Accuracy and Compute for Multi-Domain On-Device Scenarios",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/falkowskigilski21_interspeech.html": {
    "title": "Difference in Perceived Speech Signal Quality Assessment Among Monolingual and Bilingual Teenage Students",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/schymura21_interspeech.html": {
    "title": "PILOT: Introducing Transformers for Probabilistic Sound Event Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/togami21_interspeech.html": {
    "title": "Sound Source Localization with Majorization Minimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mittag21_interspeech.html": {
    "title": "NISQA: A Deep CNN-Self-Attention Model for Multidimensional Speech Quality Prediction with Crowdsourced Datasets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/naderi21_interspeech.html": {
    "title": "Subjective Evaluation of Noise Suppression Algorithms in Crowdsourcing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/geng21_interspeech.html": {
    "title": "Reliable Intensity Vector Selection for Multi-Source Direction-of-Arrival Estimation Using a Single Acoustic Vector Sensor",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yu21_interspeech.html": {
    "title": "MetricNet: Towards Improved Modeling For Non-Intrusive Speech Quality Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/toma21_interspeech.html": {
    "title": "CNN-Based Processing of Acoustic and Radio Frequency Signals for Speaker Localization from MAVs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/itoyama21_interspeech.html": {
    "title": "Assessment of von Mises-Bernoulli Deep Neural Network in Sound Source Localization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21g_interspeech.html": {
    "title": "Feature Fusion by Attention Networks for Robust DOA Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lin21f_interspeech.html": {
    "title": "Far-Field Speaker Localization and Adaptive GLMB Tracking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/narayanaswamy21_interspeech.html": {
    "title": "On the Design of Deep Priors for Unsupervised Audio Restoration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21h_interspeech.html": {
    "title": "Cramér-Rao Lower Bound for DOA Estimation with an Array of Directional Microphones in Reverberant Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/you21b_interspeech.html": {
    "title": "GAN Vocoder: Multi-Resolution Discriminator Is All You Need",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cong21_interspeech.html": {
    "title": "Glow-WaveGAN: Learning Speech Representations from GAN-Based Variational Auto-Encoder for High Fidelity Flow-Based Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yoneyama21_interspeech.html": {
    "title": "Unified Source-Filter GAN: Unified Source-Filter Network Based On Factorization of Quasi-Periodic Parallel WaveGAN",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mizuta21_interspeech.html": {
    "title": "Harmonic WaveGAN: GAN-Based Speech Waveform Generation Model with Harmonic Structure Discriminator",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21f_interspeech.html": {
    "title": "Fre-GAN: Adversarial Frequency-Consistent Audio Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yang21e_interspeech.html": {
    "title": "GANSpeech: Adversarial Training for High-Fidelity Multi-Speaker Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jang21_interspeech.html": {
    "title": "UnivNet: A Neural Vocoder with Multi-Resolution Spectrogram Discriminators for High-Fidelity Waveform Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/alradhi21_interspeech.html": {
    "title": "Continuous Wavelet Vocoder-Based Decomposition of Parametric Speech Waveform Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tobing21_interspeech.html": {
    "title": "High-Fidelity and Low-Latency Universal Neural Vocoder Based on Multiband WaveRNN with Data-Driven Linear Prediction for Discrete Waveform Modeling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21h_interspeech.html": {
    "title": "Basis-MelGAN: Efficient Neural Vocoder Based on Audio Decomposition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hwang21_interspeech.html": {
    "title": "High-Fidelity Parallel WaveGAN with Multi-Band Harmonic-Plus-Noise Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21i_interspeech.html": {
    "title": "SpecRec: An Alternative Solution for Improving End-to-End Speech-to-Text Translation via Spectrogram Reconstruction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cherry21_interspeech.html": {
    "title": "Subtitle Translation as Markup Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21r_interspeech.html": {
    "title": "Large-Scale Self- and Semi-Supervised Learning for Speech Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21s_interspeech.html": {
    "title": "CoVoST 2 and Massively Multilingual Speech Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cheng21_interspeech.html": {
    "title": "AlloST: Low-Resource Speech Translation Without Source Transcription",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/effendi21_interspeech.html": {
    "title": "Weakly-Supervised Speech-to-Text Mapping with Visually Connected Non-Parallel Speech-Text Data Using Cyclic Partially-Aligned Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tokuyama21_interspeech.html": {
    "title": "Transcribing Paralinguistic Acoustic Cues to Target Language Text in Transformer-Based Speech-to-Text Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ye21_interspeech.html": {
    "title": "End-to-End Speech Translation via Cross-Modal Progressive Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ko21_interspeech.html": {
    "title": "ASR Posterior-Based Loss for Multi-Task End-to-End Speech Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/perezgonzalezdemartos21_interspeech.html": {
    "title": "Towards Simultaneous Machine Interpretation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/martucci21_interspeech.html": {
    "title": "Lexical Modeling of ASR Errors for Robust Speech Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/vyas21_interspeech.html": {
    "title": "Optimally Encoding Inductive Biases into the Transformer Improves End-to-End Speech Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ananthanarayana21_interspeech.html": {
    "title": "Effects of Feature Scaling and Fusion on Sign Language Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/alenin21_interspeech.html": {
    "title": "The ID R&D System Description for Short-Duration Speaker Verification Challenge 2021",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/thienpondt21_interspeech.html": {
    "title": "Integrating Frequency Translational Invariance in TDNNs and Frequency Positional Information in 2D ResNets to Enhance Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gusev21_interspeech.html": {
    "title": "SdSVC Challenge 2021: Tips and Tricks to Boost the Short-Duration Speaker Verification System Performance",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kang21_interspeech.html": {
    "title": "Team02 Text-Independent Speaker Verification System for SdSV Challenge 2021",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/qin21_interspeech.html": {
    "title": "Our Learned Lessons from Cross-Lingual Speaker Verification: The CRMI-DKU System Description for the Short-Duration Speaker Verification Challenge 2021",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21o_interspeech.html": {
    "title": "Investigation of IMU&Elevoc Submission for the Short-Duration Speaker Verification Challenge 2021",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yan21_interspeech.html": {
    "title": "The Sogou System for Short-Duration Speaker Verification Challenge 2021",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/han21c_interspeech.html": {
    "title": "The SJTU System for Short-Duration Speaker Verification Challenge 2021",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cho21_interspeech.html": {
    "title": "Multi-Speaker Emotional Text-to-Speech Synthesizer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/prazak21_interspeech.html": {
    "title": "Live TV Subtitling Through Respeaking",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fragner21_interspeech.html": {
    "title": "Autonomous Robot for Measuring Room Impulse Responses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/beskow21_interspeech.html": {
    "title": "Expressive Robot Performance Based on Facial Motion Capture",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dominguez21_interspeech.html": {
    "title": "ThemePro 2.0: Showcasing the Role of Thematic Progression in Engaging Human-Computer Interaction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/guruju21_interspeech.html": {
    "title": "Addressing Compliance in Call Centers with Entity Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gogineni21_interspeech.html": {
    "title": "Audio Segmentation Based Conversational Silence Detection for Contact Center Calls",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/raj21b_interspeech.html": {
    "title": "Reformulating DOVER-Lap Label Mapping as a Graph Partitioning Problem",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tak21_interspeech.html": {
    "title": "Graph Attention Networks for Anti-Spoofing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mingote21_interspeech.html": {
    "title": "Log-Likelihood-Ratio Cost Function as Objective Loss for Speaker Verification Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/peng21c_interspeech.html": {
    "title": "Effective Phase Encoding for End-To-End Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nguyen21d_interspeech.html": {
    "title": "Impact of Encoding and Segmentation Strategies on End-to-End Simultaneous Speech Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/machacek21_interspeech.html": {
    "title": "Lost in Interpreting: Speech Translation from Source or Interpreter?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pouthier21_interspeech.html": {
    "title": "Active Speaker Detection as a Multi-Objective Optimization with Uncertainty-Based Multimodal Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wallbridge21_interspeech.html": {
    "title": "It's Not What You Said, it's How You Said it: Discriminative Perception of Speech as a Multichannel Communication System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/michael21_interspeech.html": {
    "title": "Extending the Fullband E-Model Towards Background Noise, Bursty Packet Loss, and Conversational Degradations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bergler21_interspeech.html": {
    "title": "ORCA-SLANG: An Automatic Multi-Stage Semi-Supervised Deep Learning Framework for Large-Scale Killer Whale Call Type Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/boes21_interspeech.html": {
    "title": "Audiovisual Transfer Learning for Audio Tagging and Sound Event Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nessler21_interspeech.html": {
    "title": "Non-Intrusive Speech Quality Assessment with Transfer Learning and Subject-Specific Scaling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/oncescu21_interspeech.html": {
    "title": "Audio Retrieval with Natural Language Queries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/giollo21_interspeech.html": {
    "title": "Bootstrap an End-to-End ASR System by Multilingual Training, Transfer Learning, Text-to-Text Mapping and Synthetic Audio",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pham21_interspeech.html": {
    "title": "Efficient Weight Factorization for Multilingual Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/conneau21_interspeech.html": {
    "title": "Unsupervised Cross-Lingual Representation Learning for Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hayakawa21_interspeech.html": {
    "title": "Language and Speaker-Independent Feature Transformation for End-to-End Multilingual Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/n21_interspeech.html": {
    "title": "Using Large Self-Supervised Models for Low-Resource Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kumar21e_interspeech.html": {
    "title": "Dual Script E2E Framework for Multilingual and Code-Switching ASR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/diwan21_interspeech.html": {
    "title": "MUCS 2021: Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/winata21_interspeech.html": {
    "title": "Adapt-and-Adjust: Overcoming the Long-Tail Problem of Multilingual Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sailor21_interspeech.html": {
    "title": "SRI-B End-to-End System for Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21f_interspeech.html": {
    "title": "Hierarchical Phone Recognition with Compositional Phonetics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chowdhury21_interspeech.html": {
    "title": "Towards One Model to Rule All: Multilingual Strategy for Dialectal Code-Switching Arabic ASR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yan21b_interspeech.html": {
    "title": "Differentiable Allophone Graphs for Language-Universal Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/martin21_interspeech.html": {
    "title": "Automatic Speech Recognition Systems Errors for Objective Sleepiness Detection Through Voice",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gillick21_interspeech.html": {
    "title": "Robust Laughter Detection in Noisy Environments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nagano21_interspeech.html": {
    "title": "Impact of Emotional State on Estimation of Willingness to Buy from Advertising Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/alsofyani21_interspeech.html": {
    "title": "Stacked Recurrent Neural Networks for Speech-Based Inference of Attachment Condition in School Age Children",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/aloshban21_interspeech.html": {
    "title": "Language or Paralanguage, This is the Problem: Comparing Depressed and Non-Depressed Speakers Through the Analysis of Gated Multimodal Units",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tammewar21_interspeech.html": {
    "title": "Emotion Carrier Recognition from Personal Narratives",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/condron21_interspeech.html": {
    "title": "Non-Verbal Vocalisation and Laughter Detection Using Sequence-to-Sequence Models and Multi-Label Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cai21_interspeech.html": {
    "title": "TDCA-Net: Time-Domain Channel Attention Network for Depression Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/botelho21_interspeech.html": {
    "title": "Visual Speech for Obstructive Sleep Apnea Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/maruri21_interspeech.html": {
    "title": "Analysis of Contextual Voice Changes in Remote Meetings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/seneviratne21_interspeech.html": {
    "title": "Speech Based Depression Severity Level Classification Using a Multi-Stage Dilated CNN-LSTM Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21g_interspeech.html": {
    "title": "Multi-Domain Knowledge Distillation via Uncertainty-Matching for End-to-End ASR Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/macoskey21_interspeech.html": {
    "title": "Learning a Neural Diff for Speech Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21p_interspeech.html": {
    "title": "Stochastic Attention Head Removal: A Simple and Effective Method for Improving Transformer Based ASR Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xue21b_interspeech.html": {
    "title": "Model-Agnostic Fast Adaptive Multi-Objective Balancing Algorithm for Multilingual Automatic Speech Recognition Model Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chang21b_interspeech.html": {
    "title": "Towards Lifelong Learning of End-to-End ASR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/leal21_interspeech.html": {
    "title": "Self-Adaptive Distillation for Multilingual Speech Recognition: Leveraging Student Independence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xu21f_interspeech.html": {
    "title": "Regularizing Word Segmentation by Creating Misspellings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21t_interspeech.html": {
    "title": "Multitask Training with Text Data for End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21j_interspeech.html": {
    "title": "Emitting Word Timings with HMM-Free End-to-End System in Automatic Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/droppo21_interspeech.html": {
    "title": "Scaling Laws for Acoustic Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/billa21_interspeech.html": {
    "title": "Leveraging Non-Target Language Resources to Improve ASR Performance in a Target Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fasoli21_interspeech.html": {
    "title": "4-Bit Quantization of LSTM-Based Speech Recognition Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/masumura21_interspeech.html": {
    "title": "Unified Autoregressive Modeling for Joint End-to-End Multi-Talker Overlapped Speech Recognition and Speaker Attribute Estimation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/meng21_interspeech.html": {
    "title": "Minimum Word Error Rate Training with Language Model Fusion for End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jiang21b_interspeech.html": {
    "title": "Variable Frame Rate Acoustic Models Using Minimum Error Reinforcement Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kaland21_interspeech.html": {
    "title": "How f0 and Phrase Position Affect Papuan Malay Word Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jespersen21_interspeech.html": {
    "title": "On the Feasibility of the Danish Model of Intonational Transcription: Phonetic Evidence from Jutlandic Danish",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/meli21_interspeech.html": {
    "title": "An Experiment in Paratone Detection in a Prosodically Annotated EAP Spoken Corpus",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gerazov21_interspeech.html": {
    "title": "ProsoBeast Prosody Annotation Tool",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tran21_interspeech.html": {
    "title": "Assessing the Use of Prosody in Constituency Parsing of Imperfect Transcripts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21i_interspeech.html": {
    "title": "Targeted and Targetless Neutral Tones in Taiwanese Southern Min",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gosy21_interspeech.html": {
    "title": "The Interaction of Word Complexity and Word Duration in an Agglutinative Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pan21b_interspeech.html": {
    "title": "Taiwan Min Nan (Taiwanese) Checked Tones Sound Change",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jakob21_interspeech.html": {
    "title": "In-Group Advantage in the Perception of Emotions: Evidence from Three Varieties of German",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gobl21_interspeech.html": {
    "title": "The LF Model in the Frequency Domain for Glottal Airflow Modelling Without Aliasing Distortion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wagner21_interspeech.html": {
    "title": "Parsing Speech for Grouping and Prominence, and the Typology of Rhythm",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mumtaz21_interspeech.html": {
    "title": "Prosody of Case Markers in Urdu",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/stefansdottir21_interspeech.html": {
    "title": "Articulatory Characteristics of Icelandic Voiced Fricative Lenition: Gradience, Categoricity, and Speaker/Gesture-Specific Effects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/johnson21_interspeech.html": {
    "title": "Leveraging the Uniformity Framework to Examine Crosslinguistic Similarity for Long-Lag Stops in Spontaneous Cantonese-English Bilingual Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sivaraman21_interspeech.html": {
    "title": "Personalized Speech Enhancement Through Self-Supervised Data Augmentation and Purification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/saddler21_interspeech.html": {
    "title": "Speech Denoising with Auditory Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/eskimez21b_interspeech.html": {
    "title": "Human Listening and Live Captioning: Multi-Task Training for Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xu21g_interspeech.html": {
    "title": "Multi-Stage Progressive Speech Enhancement Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chang21c_interspeech.html": {
    "title": "Single-Channel Speech Enhancement Using Learnable Loss Mixup",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21q_interspeech.html": {
    "title": "A Maximum Likelihood Approach to SNR-Progressive Learning Using Generalized Gaussian Distribution for LSTM-Based Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/agrawal21_interspeech.html": {
    "title": "Whisper Speech Enhancement Using Joint Variational Autoencoder for Improved Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lee21d_interspeech.html": {
    "title": "DEMUCS-Mobile : On-Device Lightweight Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kashyap21_interspeech.html": {
    "title": "Speech Denoising Without Clean Training Data: A Noise2Noise Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dang21_interspeech.html": {
    "title": "Improved Speech Enhancement Using a Complex-Domain GAN with Fused Time-Domain and Time-Frequency Domain Constraints",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21r_interspeech.html": {
    "title": "Speech Enhancement with Topology-Enhanced Generative Adversarial Networks (GANs)",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bu21_interspeech.html": {
    "title": "Learning Speech Structure to Improve Time-Frequency Masks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21h_interspeech.html": {
    "title": "SE-Conformer: Time-Domain Speech Enhancement Using Conformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kongthaworn21_interspeech.html": {
    "title": "Spectral and Latent Speech Representation Distortion for TTS Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/valentinibotinhao21_interspeech.html": {
    "title": "Detection and Analysis of Attention Errors in Sequence-to-Sequence Text-to-Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zandie21_interspeech.html": {
    "title": "RyanSpeech: A Corpus for Conversational Text-to-Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shi21c_interspeech.html": {
    "title": "AISHELL-3: A Multi-Speaker Mandarin TTS Corpus",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/eng21_interspeech.html": {
    "title": "Comparing Speech Enhancement Techniques for Voice Adaptation-Based Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cui21c_interspeech.html": {
    "title": "EMOVIE: A Mandarin Emotion Speech Dataset with a Simple Emotional Text-to-Speech Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rallabandi21_interspeech.html": {
    "title": "Perception of Social Speaker Characteristics in Synthetic Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bakhturina21_interspeech.html": {
    "title": "Hi-Fi Multi-Speaker English TTS Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tseng21b_interspeech.html": {
    "title": "Utilizing Self-Supervised Representations for MOS Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mussakhojayeva21_interspeech.html": {
    "title": "KazakhTTS: An Open-Source Kazakh Text-to-Speech Synthesis Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/taylor21_interspeech.html": {
    "title": "Confidence Intervals for ASR-Based TTS Evaluation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/reddy21_interspeech.html": {
    "title": "INTERSPEECH 2021 Deep Noise Suppression Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21g_interspeech.html": {
    "title": "A Simultaneous Denoising and Dereverberation Framework with Target Decoupling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xu21h_interspeech.html": {
    "title": "Deep Noise Suppression with Non-Intrusive PESQNet Supervision Enabling the Use of Real Training Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/le21b_interspeech.html": {
    "title": "DPCRN: Dual-Path Convolution Recurrent Network for Single Channel Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lv21_interspeech.html": {
    "title": "DCCRN+: Channel-Wise Subband DCCRN with SNR Estimation for Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21s_interspeech.html": {
    "title": "DBNet: A Dual-Branch Network Architecture Processing on Spectrum and Waveform for Single-Channel Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21t_interspeech.html": {
    "title": "Low-Delay Speech Enhancement Using Perceptually Motivated Target and Loss",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/oostermeijer21_interspeech.html": {
    "title": "Lightweight Causal Transformer with Local Self-Attention for Real-Time Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ristea21_interspeech.html": {
    "title": "Self-Paced Ensemble Learning for Speech and Audio Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kojima21_interspeech.html": {
    "title": "Knowledge Distillation for Streaming Transformer–Transducer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lohrenz21_interspeech.html": {
    "title": "Multi-Encoder Learning and Stream Fusion for Transformer-Based End-to-End Automatic Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zaiem21_interspeech.html": {
    "title": "Conditional Independence for Pretext Task Selection in Self-Supervised Speech Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zeineldeen21_interspeech.html": {
    "title": "Investigating Methods to Improve Language Model Integration for Attention-Based Encoder-Decoder ASR Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/vyas21b_interspeech.html": {
    "title": "Comparing CTC and LFMMI for Out-of-Domain Adaptation of wav2vec 2.0 Acoustic Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/moine21_interspeech.html": {
    "title": "Speaker Attentive Speech Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/leem21_interspeech.html": {
    "title": "Separation of Emotional and Reconstruction Embeddings on Ladder Network to Improve Speech Emotion Recognition Robustness in Noisy Conditions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/georgiou21_interspeech.html": {
    "title": "M",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/klejch21_interspeech.html": {
    "title": "The CSTR System for Multilingual and Code-Switching ASR Challenges for Low Resource Indian Languages",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhou21d_interspeech.html": {
    "title": "Acoustic Data-Driven Subword Modeling for End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhou21e_interspeech.html": {
    "title": "Equivalence of Segmental and Neural Transducer Modeling: A Proof of Concept",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/khosravani21_interspeech.html": {
    "title": "Modeling Dialectal Variation for Swiss German Automatic Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/egorova21_interspeech.html": {
    "title": "Out-of-Vocabulary Words Detection with Attention and CTC Alignments in an End-to-End ASR System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wiesner21_interspeech.html": {
    "title": "Training Hybrid Models on Noisy Transliterated Transcripts for Code-Switched Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xue21c_interspeech.html": {
    "title": "Speech Intelligibility of Dysarthric Speech: Human Scores and Acoustic-Phonetic Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21i_interspeech.html": {
    "title": "Analyzing Short Term Dynamic Speech Features for Understanding Behavioral Traits of Children with Autism Spectrum Disorder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jesko21_interspeech.html": {
    "title": "Vocalization Recognition of People with Profound Intellectual and Multiple Disabilities (PIMD) Using Machine Learning Algorithms",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fivela21_interspeech.html": {
    "title": "Phonetic Complexity, Speech Accuracy and Intelligibility Assessment of Italian Dysarthric Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ng21_interspeech.html": {
    "title": "Detection of Consonant Errors in Disordered Speech Based on Consonant-Vowel Segment Embedding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hair21_interspeech.html": {
    "title": "Assessing Posterior-Based Mispronunciation Detection on Field-Collected Recordings from Child Speech Therapy Sessions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mirheidari21_interspeech.html": {
    "title": "Identifying Cognitive Impairment Using Sentence Representation Vectors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yue21b_interspeech.html": {
    "title": "Parental Spoken Scaffolding and Narrative Skills in Crowd-Sourced Storytelling Samples of Young Children",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xia21_interspeech.html": {
    "title": "Uncertainty-Aware COVID-19 Detection from Imbalanced Sound Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21u_interspeech.html": {
    "title": "Unsupervised Domain Adaptation for Dysarthric Speech Detection via Domain Adversarial Training and Mutual Information Minimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bhattacharjee21_interspeech.html": {
    "title": "Source and Vocal Tract Cues for Speech-Based Classification of Patients with Parkinson's Disease and Healthy Subjects",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/haulcy21_interspeech.html": {
    "title": "CLAC: A Speech Corpus of Healthy English Speakers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nortje21_interspeech.html": {
    "title": "Direct Multimodal Few-Shot Learning of Speech and Images",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sanabria21_interspeech.html": {
    "title": "Talk, Don't Write: A Study of Direct Speech-Based Image Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhao21b_interspeech.html": {
    "title": "A Fast Discrete Two-Step Learning Hashing for Scalable Cross-Modal Retrieval",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21v_interspeech.html": {
    "title": "Cross-Modal Knowledge Distillation Method for Automatic Cued Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/olaleye21_interspeech.html": {
    "title": "Attention-Based Keyword Localisation in Speech Using Visual Grounding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/khorrami21_interspeech.html": {
    "title": "Evaluation of Audio-Visual Alignments in Visually Grounded Speech Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21k_interspeech.html": {
    "title": "Automatic Lip-Reading with Hierarchical Pyramidal Convolution and Self-Attention for Image Sequences with No Word Boundaries",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rouditchenko21b_interspeech.html": {
    "title": "Cascaded Multilingual Audio-Visual Learning from Videos",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ma21c_interspeech.html": {
    "title": "LiRA: Learning Visual Speech Representations from Audio Through Self-Supervision",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rose21_interspeech.html": {
    "title": "End-to-End Audio-Visual Speech Recognition for Overlapping Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wu21e_interspeech.html": {
    "title": "Audio-Visual Multi-Talker Speech Recognition in a Cocktail Party",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21l_interspeech.html": {
    "title": "Ultra Fast Speech Separation Model with Teacher Student Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ali21_interspeech.html": {
    "title": "Group Delay Based Re-Weighted Sparse Recovery Algorithms for Robust and High-Resolution Source Separation in DOA Framework",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/han21d_interspeech.html": {
    "title": "Continuous Speech Separation Using Speaker Inventory for Long Recording",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yuan21_interspeech.html": {
    "title": "Crossfire Conditional Generative Adversarial Networks for Singing Voice Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21w_interspeech.html": {
    "title": "End-to-End Speech Separation Using Orthogonal Representation in Complex and Real Time-Frequency Domain",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nakagome21_interspeech.html": {
    "title": "Efficient and Stable Adversarial Learning Using Unpaired Data for Unsupervised Multichannel Speech Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/huang21h_interspeech.html": {
    "title": "Stabilizing Label Assignment for Speech Separation by Self-Supervised Pre-Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21x_interspeech.html": {
    "title": "Dual-Path Filter Network: Speaker-Aware Modeling for Speech Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wu21f_interspeech.html": {
    "title": "Investigation of Practical Aspects of Single Channel Speech Separation for ASR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/luo21c_interspeech.html": {
    "title": "Implicit Filter-and-Sum Network for End-to-End Multi-Channel Speech Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xu21i_interspeech.html": {
    "title": "Generalized Spatio-Temporal RNN Beamformer for Target Speech Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21j_interspeech.html": {
    "title": "End-to-End Neural Diarization: From Transformer to Conformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jung21_interspeech.html": {
    "title": "Three-Class Overlapped Speech Detection Using a Convolutional Recurrent Neural Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wan21_interspeech.html": {
    "title": "Online Speaker Diarization Equipped with Discriminative Modeling and Guided Inference",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/takashima21_interspeech.html": {
    "title": "Semi-Supervised Training with Pseudo-Labeling for End-To-End Neural Diarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kwon21b_interspeech.html": {
    "title": "Adapting Speaker Embeddings for Speaker Diarisation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21y_interspeech.html": {
    "title": "Scenario-Dependent Speaker Diarization for DIHARD-III Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bredin21_interspeech.html": {
    "title": "End-To-End Speaker Segmentation for Overlap-Aware Resegmentation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xue21d_interspeech.html": {
    "title": "Online Streaming End-to-End Neural Diarization Handling Overlapping Speech and Flexible Numbers of Speakers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/anidjar21_interspeech.html": {
    "title": "A Thousand Words are Worth More Than One Recording:",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/futamata21_interspeech.html": {
    "title": "Phrase Break Prediction with Bidirectional Encoder Representations in Japanese Text-to-Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/vallesperez21_interspeech.html": {
    "title": "Improving Multi-Speaker TTS Prosody Variance with a Residual Encoder and Normalizing Flows",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/du21b_interspeech.html": {
    "title": "Rich Prosody Diversity Modelling with Phone-Level Mixture Density Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fujita21_interspeech.html": {
    "title": "Phoneme Duration Modeling Using Speech Rhythm-Based Speaker Embeddings for Multi-Speaker Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zou21_interspeech.html": {
    "title": "Fine-Grained Prosody Modeling in Neural Speech Synthesis Using ToBI Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sharma21b_interspeech.html": {
    "title": "Intra-Sentential Speaking Rate Control in Neural Text-To-Speech for Automatic Dubbing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21u_interspeech.html": {
    "title": "Applying the Information Bottleneck Principle to Prosodic Representation Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/baird21_interspeech.html": {
    "title": "A Prototypical Network Approach for Evaluating Generated Emotional Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yoshinaga21_interspeech.html": {
    "title": "A Simplified Model for the Vocal Tract of [s] with Inclined Incisors",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/arai21b_interspeech.html": {
    "title": "Vocal-Tract Models to Visualize the Airstream of Human Breath and Droplets While Producing Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tanji21_interspeech.html": {
    "title": "Using Transposed Convolution for Articulatory-to-Acoustic Conversion from Real-Time MRI Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/inaam21_interspeech.html": {
    "title": "Comparison Between Lumped-Mass Modeling and Flow Simulation of the Reed-Type Artificial Vocal Fold",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/werner21_interspeech.html": {
    "title": "Inhalations in Speech: Acoustic and Physiological Characteristics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xu21j_interspeech.html": {
    "title": "Model-Based Exploration of Linking Between Vowel Articulatory Space and Acoustic Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/elmers21_interspeech.html": {
    "title": "Take a Breath: Respiratory Sounds Improve Recollection in Synthetic Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21m_interspeech.html": {
    "title": "Modeling Sensorimotor Adaptation in Speech Through Alterations to Forward and Inverse Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kawahara21_interspeech.html": {
    "title": "Mixture of Orthogonal Sequences Made from Extended Time-Stretched Pulses Enables Measurement of Involuntary Voice Fundamental Frequency Response to Pitch Perturbation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/you21c_interspeech.html": {
    "title": "Contextualized Attention-Based Knowledge Transfer for Spoken Conversational Question Answering",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/duan21_interspeech.html": {
    "title": "Injecting Descriptive Meta-Information into Pre-Trained Language Models with Hypernetworks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rohmatillah21_interspeech.html": {
    "title": "Causal Confusion Reduction for Robust Multi-Domain Dialogue Policy",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fujie21_interspeech.html": {
    "title": "Timing Generating Networks: Neural Network Based Precise Turn-Taking Timing Prediction in Multiparty Conversation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21n_interspeech.html": {
    "title": "Human-to-Human Conversation Dataset for Learning Fine-Grained Turn-Taking Action",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sundararaman21_interspeech.html": {
    "title": "PhonemeBERT: Joint Language Modelling of Phoneme Sequence and ASR Transcript",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/luo21d_interspeech.html": {
    "title": "Joint Retrieval-Extraction Training for Evidence-Aware Dialog Response Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shenoy21_interspeech.html": {
    "title": "Adapting Long Context NLM for ASR Rescoring in Conversational Agents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21h_interspeech.html": {
    "title": "Oriental Language Recognition (OLR) 2020: Summary and Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/duroselle21b_interspeech.html": {
    "title": "Language Recognition on Unknown Conditions: The LORIA-Inria-MULTISPEECH System for AP20-OLR Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kong21b_interspeech.html": {
    "title": "Dynamic Multi-Scale Convolution for Dialect Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21z_interspeech.html": {
    "title": "An End-to-End Dialect Identification System with Transfer Learning from a Multilingual Automatic Speech Recognition Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yu21b_interspeech.html": {
    "title": "Language Recognition Based on Unsupervised Pretrained Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21i_interspeech.html": {
    "title": "Additive Phoneme-Aware Margin Softmax Loss for Language Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jahchan21_interspeech.html": {
    "title": "Towards an Accent-Robust Approach for ATC Communications Transcription",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/szoke21_interspeech.html": {
    "title": "Detecting English Speech in the Air Traffic Control Voice Communication",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ohneiser21_interspeech.html": {
    "title": "Robust Command Recognition for Lithuanian Air Traffic Control Tower Utterances",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zuluagagomez21_interspeech.html": {
    "title": "Contextual Semi-Supervised Learning: An Approach to Leverage Air-Surveillance and Untranscribed ATC Data in ASR Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kocour21_interspeech.html": {
    "title": "Boosting of Contextual Information in ASR for Air-Traffic Call-Sign Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/elie21_interspeech.html": {
    "title": "Modeling the Effect of Military Oxygen Masks on Speech Characteristics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/milde21_interspeech.html": {
    "title": "MoM: Minutes of Meeting Bot",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wilbrandt21_interspeech.html": {
    "title": "Articulatory Data Recorder: A Framework for Real-Time Articulatory Data Recording",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/codinafilba21_interspeech.html": {
    "title": "The INGENIOUS Multilingual Operations App",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rownicka21_interspeech.html": {
    "title": "Digital Einstein Experience: Fast Text-to-Speech for Conversational AI",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/geislinger21_interspeech.html": {
    "title": "Live Subtitling for BigBlueButton with Open-Source Software",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nicmanis21_interspeech.html": {
    "title": "Expressive Latvian Speech Synthesis for Dialog Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kachare21_interspeech.html": {
    "title": "ViSTAFAE: A Visual Speech-Training Aid with Feedback of Articulatory Efforts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/livescu21_interspeech.html": {
    "title": "Learning Speech Models from Multi-Modal Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/elhilali21_interspeech.html": {
    "title": "Adaptive Listening to Everyday Soundscapes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ribeiro21b_interspeech.html": {
    "title": "Towards the Prediction of the Vocal Tract Shape from the Sequence of Phonemes to be Articulated",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/blandin21_interspeech.html": {
    "title": "Comparison of the Finite Element Method, the Multimodal Method and the Transmission-Line Model for the Computation of Vocal Tract Transfer Functions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wagner21b_interspeech.html": {
    "title": "Effects of Time Pressure and Spontaneity on Phonotactic Innovations in German Dialogues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/medina21_interspeech.html": {
    "title": "Importance of Parasagittal Sensor Information in Tongue Motion Capture Through a Diphonic Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/georges21_interspeech.html": {
    "title": "Learning Robust Speech Representation with an Articulatory-Regularized Variational Autoencoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/weston21_interspeech.html": {
    "title": "Changes in Glottal Source Parameter Values with Light to Moderate Physical Load",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/vali21_interspeech.html": {
    "title": "End-to-End Optimized Multi-Stage Vector Quantization of Spectral Envelopes for Speech and Audio Coding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nareddula21_interspeech.html": {
    "title": "Fusion-Net: Time-Frequency Information Fusion Y-Network for Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/marcinek21_interspeech.html": {
    "title": "N-MTTL SI Model: Non-Intrusive Multi-Task Transfer Learning-Based Speech Intelligibility Prediction Model with Scenery Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xia21b_interspeech.html": {
    "title": "Temporal Context in Speech Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21j_interspeech.html": {
    "title": "Learning Fine-Grained Cross Modality Excitement for Speech Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/vaaras21_interspeech.html": {
    "title": "Automatic Analysis of the Emotional Content of Speech in Daylong Child-Centered Recordings from a Neonatal Intensive Care Unit",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/qian21_interspeech.html": {
    "title": "Multimodal Sentiment Analysis with Temporal Modality Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/t21_interspeech.html": {
    "title": "Stochastic Process Regression for Cross-Cultural Speech Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21k_interspeech.html": {
    "title": "Acted vs. Improvised: Domain Adaptation for Elicitation Approaches in Audio-Visual Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pepino21_interspeech.html": {
    "title": "Emotion Recognition from Speech Using wav2vec 2.0 Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21k_interspeech.html": {
    "title": "Graph Isomorphism Network for Speech Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kumawat21_interspeech.html": {
    "title": "Applying TDNN Architectures for Analyzing Duration Dependencies on Speech Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/keesing21_interspeech.html": {
    "title": "Acoustic Features and Neural Representations for Categorical Emotion Recognition from Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shon21_interspeech.html": {
    "title": "Leveraging Pre-Trained Language Model for Speech Sentiment Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hou21b_interspeech.html": {
    "title": "Cross-Domain Speech Recognition with Unsupervised Character-Level Distribution Matching",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kanda21_interspeech.html": {
    "title": "Large-Scale Pre-Training of End-to-End Multi-Talker ASR for Meeting Transcription with Single Distant Microphone",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lu21b_interspeech.html": {
    "title": "On Minimum Word Error Rate Training of the Hybrid Autoregressive Transducer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21j_interspeech.html": {
    "title": "Reducing Streaming ASR Model Delay with Self Alignment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/diwan21b_interspeech.html": {
    "title": "Reduce and Reconstruct: ASR for Low-Resource Phonetic Languages",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fukuda21_interspeech.html": {
    "title": "Knowledge Distillation Based Training of Universal ASR Source Models for Cross-Lingual Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ray21_interspeech.html": {
    "title": "Listen with Intent: Improving Speech Recognition with Audio-to-Intent Front-End",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lu21c_interspeech.html": {
    "title": "Exploring Targeted Universal Adversarial Perturbations to End-to-End ASR Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/delrio21_interspeech.html": {
    "title": "Earnings-21: A Practical Benchmark for ASR in the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sun21c_interspeech.html": {
    "title": "Improving Multilingual Transformer Transducer Models by Reducing Language Confusions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ali21b_interspeech.html": {
    "title": "Arabic Code-Switching Speech Recognition Using Monolingual Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/eisenberg21_interspeech.html": {
    "title": "Online Blind Audio Source Separation Using Recursive Expectation-Maximization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/luo21e_interspeech.html": {
    "title": "Empirical Analysis of Generalized Iterative Speech Separation Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/neumann21_interspeech.html": {
    "title": "Graph-PIT: Generalized Permutation Invariant Training for Continuous Separation of Arbitrary Numbers of Speakers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21v_interspeech.html": {
    "title": "Teacher-Student MixIT for Unsupervised and Semi-Supervised Speech Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/delcroix21_interspeech.html": {
    "title": "Few-Shot Learning of New Sound Classes for Target Sound Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/han21e_interspeech.html": {
    "title": "Binaural Speech Separation of Moving Speakers With Preserved Spatial Cues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hu21_interspeech.html": {
    "title": "AvaTr: One-Shot Speaker Extraction with Transformers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sarkar21_interspeech.html": {
    "title": "Vocal Harmony Separation Using Time-Domain Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/maciejewski21_interspeech.html": {
    "title": "Speaker Verification-Based Evaluation of Single-Channel Speech Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lan21_interspeech.html": {
    "title": "Improved Speech Separation with Time-and-Frequency Cross-Domain Feature Selection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/deng21c_interspeech.html": {
    "title": "Robust Speaker Extraction Network Based on Iterative Refined Adaptation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21aa_interspeech.html": {
    "title": "Neural Speaker Extraction with Speaker-Speech Cross-Attention Network",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rigal21_interspeech.html": {
    "title": "Deep Audio-Visual Speech Separation Based on Facial Motion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/singh21_interspeech.html": {
    "title": "LEAP Submission for the Third DIHARD Diarization Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21w_interspeech.html": {
    "title": "Investigation of Spatial-Acoustic Features for Overlapping Speech Detection in Multiparty Meetings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/he21c_interspeech.html": {
    "title": "Target-Speaker Voice Activity Detection with Improved i-Vector Estimation for Unknown Number of Speaker",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dawalatabad21_interspeech.html": {
    "title": "ECAPA-TDNN Embeddings for Speaker Diarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kinoshita21_interspeech.html": {
    "title": "Advances in Integration of End-to-End Neural and Clustering-Based Diarization for Real Conversational Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ryant21_interspeech.html": {
    "title": "The Third DIHARD Diarization Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/leung21_interspeech.html": {
    "title": "Robust End-to-End Speaker Diarization with Conformer and Additive Margin Penalty",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/obrien21_interspeech.html": {
    "title": "Anonymous Speaker Clusters: Making Distinctions Between Anonymised Speech Recordings with Clustering Interface",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/karra21_interspeech.html": {
    "title": "Speaker Diarization Using Two-Pass Leave-One-Out Gaussian PLDA Clustering of DNN Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hong21_interspeech.html": {
    "title": "Federated Learning with Dynamic Transformer for Text to Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nguyen21e_interspeech.html": {
    "title": "LiteTTS: A Lightweight Mel-Spectrogram-Free Text-to-Wave Synthesizer Based on Generative Adversarial Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tang21b_interspeech.html": {
    "title": "Zero-Shot Text-to-Speech for Text-Based Insertion in Audio Narration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jeong21_interspeech.html": {
    "title": "Diff-TTS: A Denoising Diffusion Model for Text-to-Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bae21_interspeech.html": {
    "title": "Hierarchical Context-Aware Transformers for Non-Autoregressive Text to Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/polyak21_interspeech.html": {
    "title": "Speech Resynthesis from Discrete Disentangled Self-Supervised Representations",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/karanasou21_interspeech.html": {
    "title": "A Learned Conditional Prior for the VAE Acoustic Space of a TTS System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/paul21_interspeech.html": {
    "title": "A Universal Multi-Speaker Multi-Style Text-to-Speech via Disentangled Representation Learning Based on Rényi Divergence Minimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wu21g_interspeech.html": {
    "title": "Relational Data Selection for Data Augmentation of Speaker-Dependent Multi-Band MelGAN Vocoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chung21_interspeech.html": {
    "title": "Reinforce-Aligner: Reinforcement Alignment Search for Robust End-to-End Text-to-Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lin21g_interspeech.html": {
    "title": "Triple M: A Practical Text-to-Speech Synthesis System with Multi-Guidance Attention and Multi-Band Multi-Time LPCNet",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/casanova21b_interspeech.html": {
    "title": "SC-GlowTTS: An Efficient Zero-Shot Multi-Speaker Text-To-Speech Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/palmer21_interspeech.html": {
    "title": "Spoken ObjectNet: A Bias-Controlled Spoken Caption Dataset",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/salesky21_interspeech.html": {
    "title": "The Multilingual TEDx Corpus for Speech Recognition and Translation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mortensen21_interspeech.html": {
    "title": "Tusom2021: A Phonetically Transcribed Speech Dataset from an Endangered Language for Universal Phone Recognition Experiments",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fu21b_interspeech.html": {
    "title": "AISHELL-4: An Open Source Dataset for Speech Enhancement, Separation, Recognition and Speaker Diarization in Conference Scenario",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21o_interspeech.html": {
    "title": "GigaSpeech: An Evolving, Multi-Domain ASR Corpus with 10,000 Hours of Transcribed Audio",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21k_interspeech.html": {
    "title": "Look Who's Talking: Active Speaker Detection in the Wild",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ahmed21_interspeech.html": {
    "title": "AusKidTalk: An Auditory-Visual Corpus of 3- to 12-Year-Old Australian Children's Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fallgren21_interspeech.html": {
    "title": "Human-in-the-Loop Efficiency Analysis for Binary Classification in Edyson",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ryumina21_interspeech.html": {
    "title": "Annotation Confidence vs. Training Sample Size: Trade-Off Solution for Partially-Continuous Categorical Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/garcesdiazmunio21_interspeech.html": {
    "title": "Europarl-ASR: A Large Corpus of Parliamentary Debates for Streaming ASR Benchmarking and Speech Data Filtering/Verbatimization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kapoor21_interspeech.html": {
    "title": "Towards Automatic Speech to Sign Language Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cho21b_interspeech.html": {
    "title": "kosp2e: Korean Speech to English Translation Corpus",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21x_interspeech.html": {
    "title": "speechocean762: An Open-Source Non-Native English Speech Corpus for Pronunciation Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fan21b_interspeech.html": {
    "title": "An Improved Single Step Non-Autoregressive Transformer for Automatic Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/guo21_interspeech.html": {
    "title": "Multi-Speaker ASR Combining Non-Autoregressive Conformer CTC and Conditional Speaker Chain",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ng21b_interspeech.html": {
    "title": "Pushing the Limits of Non-Autoregressive Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21l_interspeech.html": {
    "title": "Non-Autoregressive Predictive Coding for Learning Speech Representations from Local Dependencies",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nozaki21_interspeech.html": {
    "title": "Relaxing the Conditional Independence Assumption of CTC-Based ASR by Conditioning on Intermediate Predictions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fujita21b_interspeech.html": {
    "title": "Toward Streaming ASR with Non-Autoregressive Insertion-Based Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lee21e_interspeech.html": {
    "title": "Layer Pruning on Demand with Intermediate CTC",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21l_interspeech.html": {
    "title": "Real-Time End-to-End Monaural Multi-Speaker Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21ba_interspeech.html": {
    "title": "Streaming End-to-End ASR Based on Blockwise Non-Autoregressive Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/beliaev21_interspeech.html": {
    "title": "TalkNet: Non-Autoregressive Depth-Wise Separable Convolutional Model for Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21p_interspeech.html": {
    "title": "WaveGrad 2: Iterative Refinement for Text-to-Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21q_interspeech.html": {
    "title": "Align-Denoise: Single-Pass Non-Autoregressive Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lu21d_interspeech.html": {
    "title": "VAENAR-TTS: Variational Auto-Encoder Based Non-AutoRegressive Text-to-Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/luz21_interspeech.html": {
    "title": "Detecting Cognitive Decline Using Speech Only: The ADReSSo Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pereztoro21_interspeech.html": {
    "title": "Influence of the Interviewer on the Automatic Assessment of Alzheimer's Disease in the Context of the ADReSSo Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhu21e_interspeech.html": {
    "title": "WavBERT: Exploiting Semantic and Non-Semantic Speech Using Wav2vec and BERT for Dementia Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gauder21_interspeech.html": {
    "title": "Alzheimer Disease Recognition Using Speech-Based Embeddings From Pre-Trained Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/balagopalan21_interspeech.html": {
    "title": "Comparing Acoustic-Based Approaches for Alzheimer's Disease Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/qiao21_interspeech.html": {
    "title": "Alzheimer's Disease Detection from Spontaneous Speech Through Combining Linguistic Complexity and (Dis)Fluency Features with Pretrained Language Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pan21c_interspeech.html": {
    "title": "Using the Outputs of Different Automatic Speech Recognition Paradigms for Acoustic- and BERT-Based Alzheimer's Dementia Detection Through Spontaneous Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/syed21_interspeech.html": {
    "title": "Tackling the ADRESSO Challenge 2021: The MUET-RMIT System for Alzheimer's Dementia Recognition from Spontaneous Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rohanian21_interspeech.html": {
    "title": "Alzheimer's Dementia Recognition Using Acoustic, Lexical, Disfluency and Speech Pause Features Robust to Noisy Inputs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pappagari21_interspeech.html": {
    "title": "Automatic Detection and Assessment of Alzheimer Disease Using Speech and Language Technologies in Low-Resource Scenarios",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21r_interspeech.html": {
    "title": "Automatic Detection of Alzheimer's Disease Using Spontaneous Speech Only",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21ca_interspeech.html": {
    "title": "Modular Multi-Modal Attention Network for Alzheimer's Disease Detection Using Patient Audio and Language Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gong21d_interspeech.html": {
    "title": "Self-Attention Channel Combinator Frontend for End-to-End Multichannel Far-Field Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gretter21_interspeech.html": {
    "title": "ETLT 2021: Shared Task on Automatic Speech Recognition for Non-Native Children's Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rumberg21_interspeech.html": {
    "title": "Age-Invariant Training for End-to-End Child Speech Recognition Using Adversarial Multi-Task Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cornell21_interspeech.html": {
    "title": "Learning to Rank Microphones for Distant Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gelin21_interspeech.html": {
    "title": "Simulating Reading Mistakes for Child Speech Transformer-Based Phone Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/stephenson21_interspeech.html": {
    "title": "Alternate Endings: Improving Prosody for Incremental Neural TTS with Predicted Future Text Input",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rijn21_interspeech.html": {
    "title": "Exploring Emotional Prototypes in a High Dimensional TTS Latent Space",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mohan21_interspeech.html": {
    "title": "Ctrl-P: Temporal Control of Prosodic Variation for Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/torresquintero21_interspeech.html": {
    "title": "ADEPT: A Dataset for Evaluating Prosody Transfer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/trang21_interspeech.html": {
    "title": "Prosodic Boundary Prediction Model for Vietnamese Text-To-Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dovrat21_interspeech.html": {
    "title": "Many-Speakers Single Channel Speech Separation with Optimal Permutation Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fras21_interspeech.html": {
    "title": "Combating Reverberation in NTF-Based Speech Separation Using a Sub-Source Weighted Multichannel Wiener Filter and Linear Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/strauss21_interspeech.html": {
    "title": "A Hands-On Comparison of DNNs for Dialog Separation Using Transfer Learning from Music Source Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/borsdorf21b_interspeech.html": {
    "title": "GlobalPhone Mix-To-Separate Out of 2: A Multilingual 2000 Speakers Mixtures Database for Speech Separation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tsukada21_interspeech.html": {
    "title": "Cross-Linguistic Perception of the Japanese Singleton/Geminate Contrast: Korean, Mandarin and Mongolian Compared",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/korzekwa21_interspeech.html": {
    "title": "Detection of Lexical Stress Errors in Non-Native (L2) English with Data Augmentation and Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/braun21_interspeech.html": {
    "title": "Testing Acoustic Voice Quality Classification Across Languages and Speech Styles",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21y_interspeech.html": {
    "title": "Acquisition of Prosodic Focus Marking by Three- to Six-Year-Old Children Learning Mandarin Chinese",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mirzaei21_interspeech.html": {
    "title": "Adaptive Listening Difficulty Detection for L2 Learners Through Moderating ASR Resources",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ding21b_interspeech.html": {
    "title": "F",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lin21h_interspeech.html": {
    "title": "A Neural Network-Based Noise Compensation Method for Pronunciation Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kudera21_interspeech.html": {
    "title": "Phonetic Distance and Surprisal in Multilingual Priming: Evidence from Slavic",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21z_interspeech.html": {
    "title": "A Preliminary Study on Discourse Prosody Encoding in L1 and L2 English Spontaneous Narratives",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wu21h_interspeech.html": {
    "title": "Transformer Based End-to-End Mispronunciation Detection and Diagnosis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/graham21_interspeech.html": {
    "title": "L1 Identification from L2 Speech Using Neural Spectrogram Analysis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/oh21b_interspeech.html": {
    "title": "Leveraging Real-Time MRI for Illuminating Linguistic Velum Action",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21m_interspeech.html": {
    "title": "Segmental Alignment of English Syllables with Singleton and Cluster Onsets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hejna21_interspeech.html": {
    "title": "Exploration of Welsh English Pre-Aspiration: How Wide-Spread is it?",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/muhlack21_interspeech.html": {
    "title": "Revisiting Recall Effects of Filler Particles in German and English",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ge21b_interspeech.html": {
    "title": "How Reliable Are Phonetic Data Collected Remotely? Comparison of Recording Devices and Environments on Acoustic Measurements",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/huang21i_interspeech.html": {
    "title": "A Cross-Dialectal Comparison of Apical Vowels in Beijing Mandarin, Northeastern Mandarin and Southwestern Mandarin: An EMA and Ultrasound Study",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gibson21_interspeech.html": {
    "title": "Dissecting the Aero-Acoustic Parameters of Open Articulatory Transitions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gully21_interspeech.html": {
    "title": "Quantifying Vocal Tract Shape Variation and its Acoustic Impact: A Geometric Morphometric Approach",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/guevararukoz21_interspeech.html": {
    "title": "Speech Perception and Loanword Adaptations: The Case of Copy-Vowel Epenthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/guo21b_interspeech.html": {
    "title": "Speakers Coarticulate Less When Facing Real and Imagined Communicative Difficulties: An Analysis of Read and Spontaneous Speech from the LUCID Corpus",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/meister21_interspeech.html": {
    "title": "Developmental Changes of Vowel Acoustics in Adolescents",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dapolito21_interspeech.html": {
    "title": "Context and Co-Text Influence on the Accuracy Production of Italian L2 Non-Native Sounds",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/heeringa21_interspeech.html": {
    "title": "A New Vowel Normalization for Sociophonetics",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/billington21_interspeech.html": {
    "title": "The Pacific Expansion: Optimizing Phonetic Transcription of Archival Corpora",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tian21_interspeech.html": {
    "title": "FSR: Accelerating the Inference Process of Transducer-Based Models by Applying Fast-Skip Regularization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mitrofanov21_interspeech.html": {
    "title": "LT-LM: A Novel Non-Autoregressive Language Model for Single-Shot Lattice Rescoring",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/allauzen21_interspeech.html": {
    "title": "A Hybrid Seq-2-Seq ASR Design for On-Device and Server Applications",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/inaguma21b_interspeech.html": {
    "title": "VAD-Free Streaming Hybrid CTC/Attention ASR for Unsegmented Recording",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yao21_interspeech.html": {
    "title": "WeNet: Production Oriented Streaming and Non-Streaming End-to-End Speech Recognition Toolkit",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tanaka21b_interspeech.html": {
    "title": "Cross-Modal Transformer-Based Neural Correction Models for Automatic Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lee21f_interspeech.html": {
    "title": "Deep Neural Network Calibration for E2E Speech Recognition System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21m_interspeech.html": {
    "title": "Residual Energy-Based Models for End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/qiu21b_interspeech.html": {
    "title": "Multi-Task Learning for End-to-End ASR Word and Utterance Confidence with Deletion Prediction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ollerenshaw21_interspeech.html": {
    "title": "Insights on Neural Representations for End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/afshan21_interspeech.html": {
    "title": "Sequence-Level Confidence Classifier for ASR Utterance Accuracy and Application to Acoustic Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tjandra21_interspeech.html": {
    "title": "Unsupervised Learning of Disentangled Speech Content and Style Representation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/choi21_interspeech.html": {
    "title": "Label Embedding for Chinese Grapheme-to-Phoneme Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21aa_interspeech.html": {
    "title": "PDF: Polyphone Disambiguation in Chinese by Using FLAT",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21n_interspeech.html": {
    "title": "Improving Polyphone Disambiguation for Mandarin Chinese by Combining Mix-Pooling Strategy and Window-Based Attention",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shi21d_interspeech.html": {
    "title": "Polyphone Disambiguation in Mandarin Chinese with Semi-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21s_interspeech.html": {
    "title": "A Neural-Network-Based Approach to Identifying Speakers in Novels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhou21f_interspeech.html": {
    "title": "UnitNet-Based Hybrid Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/novitasari21_interspeech.html": {
    "title": "Dynamically Adaptive Machine Speech Chain Inference for TTS in Noisy Environment: Listen and Speak Louder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21ba_interspeech.html": {
    "title": "LinearSpeech: Parallel Text-to-Speech with Linear Complexity",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mansbach21_interspeech.html": {
    "title": "An Agent for Competing with Humans in a Deceptive Game Based on Vocal Cues",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fakhry21_interspeech.html": {
    "title": "A Multi-Branch Deep Learning Network for Automated Detection of COVID-19",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ma21d_interspeech.html": {
    "title": "RW-Resnet: A Novel Speech Anti-Spoofing Model Using Raw Waveform",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dhamyal21_interspeech.html": {
    "title": "Fake Audio Detection in Resource-Constrained Settings Using Microfeatures",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yan21c_interspeech.html": {
    "title": "Coughing-Based Recognition of Covid-19 with Spatial Attentive ConvLSTM Recurrent Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/paul21b_interspeech.html": {
    "title": "Knowledge Distillation for Singing Voice Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/takeda21_interspeech.html": {
    "title": "Age Estimation with Speech-Age Model for Heterogeneous Speech Datasets",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/teh21_interspeech.html": {
    "title": "Open-Set Audio Classification with Limited Training Resources Based on Augmentation Enhanced Variational Auto-Encoder GAN with Detection-Classification Joint Training",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/fukumori21_interspeech.html": {
    "title": "Deep Spectral-Cepstral Fusion for Shouted and Normal Speech Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/baghel21_interspeech.html": {
    "title": "Automatic Detection of Shouted Speech Segments in Indian News Debates",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gao21c_interspeech.html": {
    "title": "Generalized Spoofing Detection Inspired from Audio Generation Artifacts",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21t_interspeech.html": {
    "title": "Overlapped Speech Detection Based on Spectral and Spatial Feature Fusion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/abdullah21_interspeech.html": {
    "title": "Do Acoustic Word Embeddings Capture Phonological Similarity? An Empirical Study",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gao21d_interspeech.html": {
    "title": "Paraphrase Label Alignment for Voice Application Retrieval in Spoken Language Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/rikhye21_interspeech.html": {
    "title": "Personalized Keyphrase Detection Using Speaker and Environment Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/garg21_interspeech.html": {
    "title": "Streaming Transformer for Hardware Efficient Voice Trigger Detection and False Trigger Mitigation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mazumder21_interspeech.html": {
    "title": "Few-Shot Keyword Spotting in Any Language",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21da_interspeech.html": {
    "title": "Text Anchor Based Metric Learning for Small-Footprint Keyword Spotting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21u_interspeech.html": {
    "title": "A Meta-Learning Approach for User-Defined Spoken Term Classification with Varying Classes and Examples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lee21g_interspeech.html": {
    "title": "Auxiliary Sequence Labeling Tasks for Disfluency Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhou21g_interspeech.html": {
    "title": "Energy-Friendly Keyword Spotting System Using Add-Based Convolution",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jia21b_interspeech.html": {
    "title": "The 2020 Personalized Voice Trigger Challenge: Open Datasets, Evaluation Metrics, Baseline System and Results",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21ea_interspeech.html": {
    "title": "Auto-KWS 2021 Challenge: Task, Datasets, and Baselines",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/berg21_interspeech.html": {
    "title": "Keyword Transformer: A Self-Attention Model for Keyword Spotting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/awasthi21_interspeech.html": {
    "title": "Teaching Keyword Spotters to Spot New Keywords with Limited Examples",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21fa_interspeech.html": {
    "title": "A Comparative Study on Recent Neural Spoofing Countermeasures for Synthetic Speech Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21ca_interspeech.html": {
    "title": "An Initial Investigation for Detecting Partially Spoofed Audio",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xie21_interspeech.html": {
    "title": "Siamese Network with wav2vec Feature for Spoofing Speech Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cheng21b_interspeech.html": {
    "title": "Cross-Database Replay Detection in Terminal-Dependent Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21da_interspeech.html": {
    "title": "The Effect of Silence and Dual-Band Fusion in Anti-Spoofing System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/peng21d_interspeech.html": {
    "title": "Pairing Weak with Strong: Twin Models for Defending Against Adversarial Attack on Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ling21_interspeech.html": {
    "title": "Attention-Based Convolutional Neural Network for ASV Spoofing Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wu21i_interspeech.html": {
    "title": "Voting for the Right Answer: Adversarial Defense for Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kinnunen21_interspeech.html": {
    "title": "Visualizing Classifier Adjacency Relations: A Case Study in Speaker Verification and Voice Anti-Spoofing",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/villalba21_interspeech.html": {
    "title": "Representation Learning to Classify and Detect Adversarial Attacks Against Speaker and Speech Recognition Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21ea_interspeech.html": {
    "title": "An Empirical Study on Channel Effects for Synthetic Voice Spoofing Countermeasure Systems",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21o_interspeech.html": {
    "title": "Channel-Wise Gated Res2Net: Towards Robust Detection of Synthetic Speech Attacks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ge21c_interspeech.html": {
    "title": "Partially-Connected Differentiable Architecture Search for Deepfake and Spoofing Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/peterson21_interspeech.html": {
    "title": "OpenASR20: An Open Challenge for Automatic Speech Recognition of Conversational Telephone Speech in Low-Resource Languages",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/madikeri21_interspeech.html": {
    "title": "Multitask Adaptation with Lattice-Free MMI for Multi-Genre Speech Recognition of Low Resource Languages",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhu21f_interspeech.html": {
    "title": "An Improved Wav2Vec 2.0 Pre-Training Approach Using Enhanced Local Dependency Modeling for Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lin21i_interspeech.html": {
    "title": "Systems for Low-Resource Speech Recognition Tasks in Open Automatic Speech Recognition and Formosa Speech Recognition Challenges",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhao21c_interspeech.html": {
    "title": "The TNT Team System Descriptions of Cantonese and Mongolian for IARPA OpenASR20",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/alumae21_interspeech.html": {
    "title": "Combining Hybrid and End-to-End Approaches for the OpenASR20 Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/morris21_interspeech.html": {
    "title": "One Size Does Not Fit All in Resource-Constrained ASR",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cristia21_interspeech.html": {
    "title": "Child Language Acquisition Studied with Wearables",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mikolov21_interspeech.html": {
    "title": "Language Modeling and Artificial Intelligence",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gimeno21_interspeech.html": {
    "title": "Unsupervised Representation Learning for Speech Activity Detection in the Fearless Steps Challenge 2021",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/vuong21_interspeech.html": {
    "title": "The Application of Learnable STRF Kernels to the 2021 Fearless Steps Phase-03 SAD Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sarfjoo21_interspeech.html": {
    "title": "Speech Activity Detection Based on Multilingual Speech Recognition System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/luckenbaugh21_interspeech.html": {
    "title": "Voice Activity Detection with Teacher-Student Domain Emulation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ghahabi21_interspeech.html": {
    "title": "EML Online Speech Activity Detection for the Fearless Steps Challenge Phase-III",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/opatka21_interspeech.html": {
    "title": "Device Playback Augmentation with Echo Cancellation for Keyword Spotting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yusuf21_interspeech.html": {
    "title": "End-to-End Open Vocabulary Keyword Search",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/merkx21_interspeech.html": {
    "title": "Semantic Sentence Similarity: Size does not Always Matter",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/svec21_interspeech.html": {
    "title": "Spoken Term Detection and Relevance Score Estimation Using Dot-Product of Pronunciation Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/buet21_interspeech.html": {
    "title": "Toward Genre Adapted Closed Captioning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/korzekwa21b_interspeech.html": {
    "title": "Weakly-Supervised Word-Level Pronunciation Error Detection in Non-Native English Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kanda21b_interspeech.html": {
    "title": "End-to-End Speaker-Attributed ASR with Transformer",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/soltau21_interspeech.html": {
    "title": "Understanding Medical Conversations: Rich Transcription, Confidence Scores & Information Extraction",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/vidal21_interspeech.html": {
    "title": "Phone-Level Pronunciation Scoring for Spanish Speakers Learning English Using a GOP-DNN System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xu21k_interspeech.html": {
    "title": "Explore wav2vec 2.0 for Mispronunciation Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ando21_interspeech.html": {
    "title": "Lexical Density Analysis of Word Productions in Japanese English Using Acoustic Word Embeddings",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lin21j_interspeech.html": {
    "title": "Deep Feature Transfer Learning for Automatic Pronunciation Assessment",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21fa_interspeech.html": {
    "title": "Multilingual Speech Evaluation: Case Studies on English, Malay and Tamil",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/peng21e_interspeech.html": {
    "title": "A Study on Fine-Tuning wav2vec2.0 Model for the Task of Mispronunciation Detection and Diagnosis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/qiao21b_interspeech.html": {
    "title": "The Impact of ASR on the Automatic Analysis of Linguistic Complexity and Sophistication in Spontaneous L2 Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tanaka21c_interspeech.html": {
    "title": "End-to-End Rich Transcription-Style Automatic Speech Recognition with Semi-Supervised Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cumbal21_interspeech.html": {
    "title": "You don't understand me!\": Comparing ASR Results for L1 and L2 Speakers of Swedish",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21ga_interspeech.html": {
    "title": "NeMo Inverse Text Normalization: From Development to Production",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/naijo21_interspeech.html": {
    "title": "Improvement of Automatic English Pronunciation Assessment with Small Number of Utterances Using Sentence Speakability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/haider21_interspeech.html": {
    "title": "Affect Recognition Through Scalogram and Multi-Resolution Cochleagram Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21n_interspeech.html": {
    "title": "A Speech Emotion Recognition Framework for Better Discrimination of Confusions",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21p_interspeech.html": {
    "title": "Speech Emotion Recognition via Multi-Level Cross-Modal Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ito21_interspeech.html": {
    "title": "Audio-Visual Speech Emotion Recognition by Disentangling Emotion and Identity Attributes",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/bose21_interspeech.html": {
    "title": "Parametric Distributions to Model Numerical Emotion Labels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gao21e_interspeech.html": {
    "title": "Metric Learning Based Feature Representation with Gated Fusion Model for Speech Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cai21b_interspeech.html": {
    "title": "Speech Emotion Recognition with Multi-Task Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/seneviratne21b_interspeech.html": {
    "title": "Generalized Dilated CNN Models for Depression Detection Using Inverted Vocal Tract Variables",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21ga_interspeech.html": {
    "title": "Learning Mutual Correlation in Multimodal Transformer for Speech Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21o_interspeech.html": {
    "title": "Time-Frequency Representation Learning with Graph Convolutional Network for Dialogue-Level Speech Emotion Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mordido21_interspeech.html": {
    "title": "Compressing 1D Time-Channel Separable Convolutions Using Sparse Random Ternary Matrices",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cheng21c_interspeech.html": {
    "title": "Weakly Supervised Construction of ASR Systems from Massive Video Data",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21l_interspeech.html": {
    "title": "Broadcasted Residual Learning for Efficient Keyword Spotting",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/swaminathan21_interspeech.html": {
    "title": "CoDERT: Distilling Encoder Representations with Co-Learning for Transducer-Based Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gao21f_interspeech.html": {
    "title": "Extremely Low Footprint End-to-End ASR System for Smart Device",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shangguan21_interspeech.html": {
    "title": "Dissecting User-Perceived Latency of On-Device E2E Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/macoskey21b_interspeech.html": {
    "title": "Amortized Neural Networks for Low-Latency Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/botros21_interspeech.html": {
    "title": "Tied & Reduced RNN-T Decoder",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21m_interspeech.html": {
    "title": "PQK: Model Compression via Pruning, Quantization, and Knowledge Distillation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nagaraja21_interspeech.html": {
    "title": "Collaborative Training of Acoustic Encoders for Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21ha_interspeech.html": {
    "title": "Efficient Conformer with Prob-Sparse Attention Mechanism for End-to-End Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/parcollet21_interspeech.html": {
    "title": "The Energy and Carbon Footprint of Training End-to-End Speech Recognizers",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21v_interspeech.html": {
    "title": "Graph-Based Label Propagation for Semi-Supervised Speaker Identification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21q_interspeech.html": {
    "title": "Fusion of Embeddings Networks for Robust Combination of Text Dependent and Independent Speaker Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cumani21_interspeech.html": {
    "title": "A Generative Model for Duration-Dependent Score Calibration",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pelecanos21_interspeech.html": {
    "title": "Dr-Vectors: Decision Residual Networks and an Improved Loss for Speaker Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kataria21b_interspeech.html": {
    "title": "Multi-Channel Speaker Verification for Single and Multi-Talker Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/padfield21_interspeech.html": {
    "title": "Chronological Self-Training for Real-Time Speaker Diarization",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xiao21b_interspeech.html": {
    "title": "Adaptive Margin Circle Loss for Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/obrien21b_interspeech.html": {
    "title": "Presentation Matters: Evaluating Speaker Identification Tasks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tong21_interspeech.html": {
    "title": "Automatic Error Correction for Speaker Embedding Learning with Noisy Labels",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liao21_interspeech.html": {
    "title": "An Integrated Framework for Two-Pass Personalized Voice Trigger",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lian21_interspeech.html": {
    "title": "Masked Proxy Loss for Text-Independent Speaker Verification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lee21h_interspeech.html": {
    "title": "STYLER: Style Factor Modeling with Rapidity and Robustness via Speech Decomposition for Expressive and Controllable Neural Text to Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/liu21p_interspeech.html": {
    "title": "Reinforcement Learning for Emotional Text-to-Speech Synthesis with Improved Emotion Discriminability",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/sivaprasad21_interspeech.html": {
    "title": "Emotional Prosody Control for Speech Generation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cong21b_interspeech.html": {
    "title": "Controllable Context-Aware Conversational Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kim21n_interspeech.html": {
    "title": "Expressive Text-to-Speech Using Style Tag",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yan21d_interspeech.html": {
    "title": "Adaptive Text to Speech for Spontaneous Style",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/li21r_interspeech.html": {
    "title": "Towards Multi-Scale Style Control for Expressive Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pan21d_interspeech.html": {
    "title": "Cross-Speaker Style Transfer with Prosody Bottleneck in Neural Speech Synthesis",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tan21_interspeech.html": {
    "title": "Fine-Grained Style Modeling, Transfer and Prediction in Text-to-Speech Synthesis via Phone-Level Content-Style Disentanglement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/an21b_interspeech.html": {
    "title": "Improving Performance of Seen and Unseen Speech Style Transfer in End-to-End Neural TTS",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shechtman21_interspeech.html": {
    "title": "Synthesis of Expressive Speaking Styles with Limited Training Data in a Multi-Speaker, Prosody-Controllable Sequence-to-Sequence Architecture",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/dao21_interspeech.html": {
    "title": "Intent Detection and Slot Filling for Vietnamese",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/lin21k_interspeech.html": {
    "title": "Augmenting Slot Values and Contexts for Spoken Language Understanding with Pretrained Models",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gaspers21_interspeech.html": {
    "title": "The Impact of Intent Distribution Mismatch on Semi-Supervised Spoken Language Understanding",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jiang21c_interspeech.html": {
    "title": "Knowledge Distillation from BERT Transformer to Speech Transformer for Intent Classification",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21ia_interspeech.html": {
    "title": "Three-Module Modeling For End-to-End Spoken Language Understanding Using Pre-Trained DNN-HMM-Based Acoustic-Phonetic Model",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cha21_interspeech.html": {
    "title": "Speak or Chat with Me: End-to-End Spoken Language Understanding System with Flexible Inputs",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21ha_interspeech.html": {
    "title": "End-to-End Cross-Lingual Spoken Language Understanding Model with Multilingual Pretraining",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/saghir21_interspeech.html": {
    "title": "Factorization-Aware Training of Transformers for Natural Language Understanding on the Edge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/saxon21_interspeech.html": {
    "title": "End-to-End Spoken Language Understanding for Generalized Voice Assistants",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/han21f_interspeech.html": {
    "title": "Bi-Directional Joint Neural Networks for Intent Classification and Slot Filling",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cutler21_interspeech.html": {
    "title": "INTERSPEECH 2021 Acoustic Echo Cancellation Challenge",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/pfeifenberger21_interspeech.html": {
    "title": "Acoustic Echo Cancellation with Cross-Domain Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21ia_interspeech.html": {
    "title": "F-T-LSTM Based Complex Network for Joint Acoustic Echo Cancellation and Speech Enhancement",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/seidel21_interspeech.html": {
    "title": "Y",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/peng21f_interspeech.html": {
    "title": "Acoustic Echo Cancellation Using Deep Complex Neural Network with Nonlinear Magnitude Compression and Phase Information",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/ivry21_interspeech.html": {
    "title": "Nonlinear Acoustic Echo Cancellation with Deep Learning",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/green21_interspeech.html": {
    "title": "Automatic Speech Recognition of Disordered Speech: Personalized Models Outperforming Human Listeners on Short Phrases",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/neumann21b_interspeech.html": {
    "title": "Investigating the Utility of Multimodal Conversational Technology and Audiovisual Analytic Measures for the Assessment and Monitoring of Amyotrophic Lateral Sclerosis at Scale",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hermann21_interspeech.html": {
    "title": "Handling Acoustic Variation in Dysarthric Speech Recognition Systems Through Model Combination",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/geng21b_interspeech.html": {
    "title": "Spectro-Temporal Deep Features for Disordered Speech Assessment and Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/gutz21_interspeech.html": {
    "title": "Speaking with a KN95 Face Mask: ASR Performance and Speaker Compensation",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jin21_interspeech.html": {
    "title": "Adversarial Data Augmentation for Disordered Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/xie21b_interspeech.html": {
    "title": "Variational Auto-Encoder Based Variability Encoding for Dysarthric Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/wang21ja_interspeech.html": {
    "title": "Learning Explicit Prosody Models and Deep Speaker Embeddings for Atypical Voice Conversion",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/deng21d_interspeech.html": {
    "title": "Bayesian Parametric and Architectural Domain Adaptation of LF-MMI Trained TDNNs for Elderly and Dysarthric Speech Recognition",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/cai21c_interspeech.html": {
    "title": "A Voice-Activated Switch for Persons with Motor and Speech Impairments: Isolated-Vowel Spotting Using Neural Networks",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/chen21w_interspeech.html": {
    "title": "Conformer Parrotron: A Faster and Stronger End-to-End Speech Conversion and Recognition Model for Atypical Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/macdonald21_interspeech.html": {
    "title": "Disordered Speech Data Collection: Lessons Learned at 1 Million Utterances from Project Euphonia",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/yeo21_interspeech.html": {
    "title": "Automatic Severity Classification of Korean Dysarthric Speech Using Phoneme-Level Pronunciation Features",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/venugopalan21_interspeech.html": {
    "title": "Comparing Supervised Models and Learned Speech Representations for Classifying Intelligibility of Disordered Speech on Selected Phrases",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/mitra21_interspeech.html": {
    "title": "Analysis and Tuning of a Voice Assistant System for Dysfluent Speech",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/kawahara21b_interspeech.html": {
    "title": "Interactive and Real-Time Acoustic Measurement Tools for Speech Data Acquisition and Presentation: Application of an Extended Member of Time Stretched Pulses",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/tihelka21_interspeech.html": {
    "title": "Save Your Voice: Voice Banking and TTS for Anyone",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/zhang21ja_interspeech.html": {
    "title": "NeMo (Inverse) Text Normalization: From Development to Production",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/hembise21_interspeech.html": {
    "title": "Lalilo: A Reading Assistant for Children Featuring Speech Recognition-Based Reading Mistake Detection",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/nguyen21f_interspeech.html": {
    "title": "Automatic Radiology Report Editing Through Voice",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/shi21e_interspeech.html": {
    "title": "WittyKiddy: Multilingual Spoken Language Learning for Kids",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/jin21b_interspeech.html": {
    "title": "Duplex Conversation in Outbound Agent System",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  },
  "https://www.isca-speech.org/archive/interspeech_2021/udupa21b_interspeech.html": {
    "title": "Web Interface for Estimating Articulatory Movements in Speech Production from Acoustics and Text",
    "volume": "main",
    "abstract": "",
    "checked": false,
    "id": null,
    "semantic_title": "",
    "citation_count": 0
  }
}